<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:41:43Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|10001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2785</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2785</id><created>2009-11-14</created><authors><author><keyname>Greco</keyname><forenames>Sergio</forenames></author><author><keyname>Molinaro</keyname><forenames>Cristian</forenames></author><author><keyname>Trubitsyna</keyname><forenames>Irina</forenames></author><author><keyname>Zumpano</keyname><forenames>Ester</forenames></author></authors><title>NP Datalog: a Logic Language for Expressing NP Search and Optimization
  Problems</title><categories>cs.LO</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a logic language for expressing NP search and
optimization problems. Specifically, first a language obtained by extending
(positive) Datalog with intuitive and efficient constructs (namely, stratified
negation, constraints and exclusive disjunction) is introduced. Next, a further
restricted language only using a restricted form of disjunction to define
(non-deterministically) subsets (or partitions) of relations is investigated.
This language, called NP Datalog, captures the power of Datalog with
unstratified negation in expressing search and optimization problems. A system
prototype implementing NP Datalog is presented. The system translates NP
Datalog queries into OPL programs which are executed by the ILOG OPL
Development Studio. Our proposal combines easy formulation of problems,
expressed by means of a declarative logic language, with the efficiency of the
ILOG System. Several experiments show the effectiveness of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2801</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2801</id><created>2009-11-14</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author><author><keyname>Jacquot</keyname><forenames>Alice</forenames><affiliation>LIP6</affiliation></author></authors><title>Boltzmann Samplers for Colored Combinatorial Objects</title><categories>cs.DM cs.DS math.CO</categories><proxy>ccsd hal-00432211</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give a general framework for the Boltzmann generation of
colored objects belonging to combinatorial constructible classes. We propose an
intuitive notion called profiled objects which allows the sampling of
size-colored objects (and also of k-colored objects) although the corresponding
class cannot be described by an analytic ordinary generating function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2802</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2802</id><created>2009-11-14</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author><author><keyname>Jacquot</keyname><forenames>Alice</forenames><affiliation>LIP6</affiliation></author></authors><title>Boltzmann Samplers for v-balanced Colored Necklaces</title><categories>cs.DM cs.DS math.CO</categories><proxy>ccsd hal-00432215</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to the random generation of particular colored
necklaces for which the number of beads of a given color is constrained (these
necklaces are called v-balanced). We propose an efficient sampler (its expected
time complexity is linear) which satisfies the Boltzmann model principle
introduced by Duchon, Flajolet, Louchard and Schaeffer. Our main motivation is
to show that the absence of a decomposable specification can be circumvented by
mixing the Boltzmann samplers with other types of samplers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2804</identifier>
 <datestamp>2011-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2804</id><created>2009-11-14</created><updated>2011-03-09</updated><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames></author><author><keyname>Fernique</keyname><forenames>Thomas</forenames></author><author><keyname>Rao</keyname><forenames>Michael</forenames></author><author><keyname>Remila</keyname><forenames>Eric</forenames></author></authors><title>Distances on Rhombus Tilings</title><categories>cs.DM cs.DS math.CO</categories><comments>18 pages, 9 figures, submitted to Theoretical Computer Science
  (special issue of DGCI'09)</comments><proxy>ccsd hal-00432218</proxy><msc-class>52C30, 52C20, 52C23, 68T15</msc-class><acm-class>F.2.2; G.2.1; G.2.2; I.2.3; I.2.8</acm-class><journal-ref>Theor. Comput. Sci. 412(36): 4787-4794 (2011)</journal-ref><doi>10.1016/j.tcs.2011.04.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rhombus tilings of a simply connected domain of the Euclidean plane are
known to form a flip-connected space (a flip is the elementary operation on
rhombus tilings which rotates 180{\deg} a hexagon made of three rhombi).
Motivated by the study of a quasicrystal growth model, we are here interested
in better understanding how &quot;tight&quot; rhombus tiling spaces are flip-connected.
We introduce a lower bound (Hamming-distance) on the minimal number of flips to
link two tilings (flip-distance), and we investigate whether it is sharp. The
answer depends on the number n of different edge directions in the tiling:
positive for n=3 (dimer tilings) or n=4 (octogonal tilings), but possibly
negative for n=5 (decagonal tilings) or greater values of n. A standard proof
is provided for the n=3 and n=4 cases, while the complexity of the n=5 case led
to a computer-assisted proof (whose main result can however be easily checked
by hand).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2805</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2805</id><created>2009-11-14</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author><author><keyname>Lumbroso</keyname><forenames>J&#xe9;r&#xe9;mie</forenames><affiliation>LIP6</affiliation></author></authors><title>Optimal Partial Tiling of Manhattan Polyominoes</title><categories>cs.DM cs.DS math.CO</categories><proxy>ccsd hal-00432217</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding an efficient optimal partial tiling algorithm is still an open
problem. We have worked on a special case, the tiling of Manhattan polyominoes
with dominoes, for which we give an algorithm linear in the number of columns.
Some techniques are borrowed from traditional graph optimisation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2807</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2807</id><created>2009-11-14</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author></authors><title>On the Minimum Size of a Contraction-Universal Tree</title><categories>cs.DM</categories><proxy>ccsd hal-00432221</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A tree T_uni is m-universal for the class of trees if for every tree T of
size m, T can be obtained from T_uni by successive contractions of edges. We
prove that a m-universal tree for the class of trees has at least mln(m) +
(gamma-1)m + O(1) edges where is the Euler's constant and we build such a tree
with less than mc edges for a fixed constant c = 1.984...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2829</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2829</id><created>2009-11-14</created><authors><author><keyname>Cooper</keyname><forenames>S. Barry</forenames></author><author><keyname>Danos</keyname><forenames>Vincent</forenames></author></authors><title>Proceedings Fifth Workshop on Developments in Computational
  Models--Computational Models From Nature</title><categories>cs.CE cs.AI cs.CC cs.FL cs.LO cs.NE cs.PL</categories><journal-ref>EPTCS 9, 2009</journal-ref><doi>10.4204/EPTCS.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The special theme of DCM 2009, co-located with ICALP 2009, concerned
Computational Models From Nature, with a particular emphasis on computational
models derived from physics and biology. The intention was to bring together
different approaches - in a community with a strong foundational background as
proffered by the ICALP attendees - to create inspirational cross-boundary
exchanges, and to lead to innovative further research. Specifically DCM 2009
sought contributions in quantum computation and information, probabilistic
models, chemical, biological and bio-inspired ones, including spatial models,
growth models and models of self-assembly. Contributions putting to the test
logical or algorithmic aspects of computing (e.g., continuous computing with
dynamical systems, or solid state computing models) were also very much
welcomed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2847</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2847</id><created>2009-11-15</created><authors><author><keyname>Gao</keyname><forenames>Jie</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author></authors><title>Cooperative Precoding/Resource Allocation Games under Spectral Mask and
  Total Power Constraints</title><categories>cs.IT math.IT</categories><comments>33 pages, 8 figures, Submitted to the IEEE Trans. Signal Processing
  in Oct. 2009</comments><journal-ref>J. Gao, S.A. Vorobyov, and H. Jiang, &quot;Cooperative resource
  allocation games under spectral mask and total power constraints,&quot; IEEE
  Trans. Signal Processing, vol. 58, no. 8, pp. 4379-4395, Aug. 2010</journal-ref><doi>10.1109/TSP.2010.2048320</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of orthogonal signaling schemes such as time-, frequency-, or
code-division multiplexing (T-, F-, CDM) in multi-user systems allows for
power-efficient simple receivers. It is shown in this paper that by using
orthogonal signaling on frequency selective fading channels, the cooperative
Nash bargaining (NB)-based precoding games for multi-user systems, which aim at
maximizing the information rates of all users, are simplified to the
corresponding cooperative resource allocation games. The latter provides
additional practically desired simplifications to transmitter design and
significantly reduces the overhead during user cooperation. The complexity of
the corresponding precoding/resource allocation games, however, depends on the
constraints imposed on the users. If only spectral mask constraints are
present, the corresponding cooperative NB problem can be formulated as a convex
optimization problem and solved efficiently in a distributed manner using dual
decomposition based algorithm. However, the NB problem is non-convex if total
power constraints are also imposed on the users. In this case, the complexity
associate with finding the NB solution is unacceptably high. Therefore, the
multi-user systems are categorized into bandwidth- and power-dominant based on
a bottleneck resource, and different manners of cooperation are developed for
each type of systems for the case of two-users. Such classification guarantees
that the solution obtained in each case is Pareto-optimal and actually can be
identical to the optimal solution, while the complexity is significantly
reduced. Simulation results demonstrate the efficiency of the proposed
cooperative precoding/resource allocation strategies and the reduced complexity
of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2865</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2865</id><created>2009-11-15</created><updated>2010-05-30</updated><authors><author><keyname>Nallusamy</keyname><forenames>R.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Neural Networks for Dynamic Shortest Path Routing Problems - A Survey</title><categories>cs.NE cs.AI</categories><comments>This article has been withdrawn by the authors. Misplaced equation 1</comments><journal-ref>CiiT International Journal of Artificial Intelligent Systems and
  Machine Learning, Vol. 1, No. 2, pp. 31-34, May 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews the overview of the dynamic shortest path routing problem
and the various neural networks to solve it. Different shortest path
optimization problems can be solved by using various neural networks
algorithms. The routing in packet switched multi-hop networks can be described
as a classical combinatorial optimization problem i.e. a shortest path routing
problem in graphs. The survey shows that the neural networks are the best
candidates for the optimization of dynamic shortest path routing problems due
to their fastness in computation comparing to other softcomputing and
metaheuristics algorithms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2873</identifier>
 <datestamp>2011-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2873</id><created>2009-11-15</created><updated>2011-11-01</updated><authors><author><keyname>Amblard</keyname><forenames>Pierre-Olivier</forenames></author><author><keyname>Michel</keyname><forenames>Olivier J. J.</forenames></author></authors><title>Relating Granger causality to directed information theory for networks
  of stochastic processes</title><categories>cs.IT math.IT</categories><comments>submitted, completely rehaul, new title, added recent references,
  more emphasis on general case</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of inferring circulation of information
between multiple stochastic processes. We discuss two possible frameworks in
which the problem can be studied: directed information theory and Granger
causality. The main goal of the paper is to study the connection between these
two frameworks. In the case of directed information theory, we stress the
importance of Kramer's causal conditioning. This type of conditioning is
necessary not only in the definition of the directed information but also for
handling causal side information. We also show how directed information
decomposes into the sum of two measures, the first one related to Schreiber's
transfer entropy quantifies the dynamical aspects of causality, whereas the
second one, termed instantaneous information exchange, quantifies the
instantaneous aspect of causality. After having recalled the definition of
Granger causality, we establish its connection with directed information
theory. The connection is particularly studied in the Gaussian case, showing
that Geweke's measures of Granger causality correspond to the transfer entropy
and the instantaneous information exchange. This allows to propose an
information theoretic formulation of Granger causality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2889</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2889</id><created>2009-11-15</created><authors><author><keyname>Karlin</keyname><forenames>V.</forenames></author></authors><title>Global communications in multiprocessor simulations of flames</title><categories>cs.DC cs.CE cs.MS cs.PF</categories><comments>16 pages, 8 figures</comments><acm-class>I.6.3; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate performance of global communications in a
particular parallel code. The code simulates dynamics of expansion of premixed
spherical flames using an asymptotic model of Sivashinsky type and a spectral
numerical algorithm. As a result, the code heavily relies on global all-to-all
interprocessor communications implementing transposition of the distributed
data array in which numerical solution to the problem is stored. This global
data interdependence makes interprocessor connectivity of the HPC system as
important as the floating-point power of the processors of which the system is
built. Our experiments show that efficient numerical simulation of this
particular model, with global data interdependence, on modern HPC systems is
possible. Prospects of performance of more sophisticated models of flame
dynamics are analysed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2899</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2899</id><created>2009-11-15</created><updated>2011-05-17</updated><authors><author><keyname>Covington</keyname><forenames>Michael A.</forenames><affiliation>Institute for Artificial Intelligence, The University of Georgia, Athens, Georgia, U.S.A.</affiliation></author><author><keyname>Bagnara</keyname><forenames>Roberto</forenames><affiliation>Department of Mathematics, University of Parma, and BUGSENG srl, Italy</affiliation></author><author><keyname>O'Keefe</keyname><forenames>Richard A.</forenames><affiliation>Department of Computer Science, University of Otago, Dunedin, New Zealand</affiliation></author><author><keyname>Wielemaker</keyname><forenames>Jan</forenames><affiliation>Department of Computer Science, VU University Amsterdam, The Netherlands</affiliation></author><author><keyname>Price</keyname><forenames>Simon</forenames><affiliation>Intelligent Systems Laboratory, University of Bristol, United Kingdom</affiliation></author></authors><title>Coding Guidelines for Prolog</title><categories>cs.PL</categories><comments>39 pages, 4 figures, 2 tables</comments><acm-class>D.1.6; D.2.3; D.2.9; K.6.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coding standards and good practices are fundamental to a disciplined approach
to software projects, whatever programming languages they employ. Prolog
programming can benefit from such an approach, perhaps more than programming in
other languages. Despite this, no widely accepted standards and practices seem
to have emerged up to now. The present paper is a first step towards filling
this void: it provides immediate guidelines for code layout, naming
conventions, documentation, proper use of Prolog features, program development,
debugging and testing. Presented with each guideline is its rationale and,
where sensible options exist, illustrations of the relative pros and cons for
each alternative. A coding standard should always be selected on a per-project
basis, based on a host of issues pertinent to any given programming project;
for this reason the paper goes beyond the mere provision of normative
guidelines by discussing key factors and important criteria that should be
taken into account when deciding on a fully-fledged coding standard for the
project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2900</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2900</id><created>2009-11-15</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author></authors><title>Computation Speed of the F.A.S.T. Model</title><categories>cs.MA physics.soc-ph</categories><comments>Accepted as contribution to &quot;Traffic and Granular Flow 2009&quot;
  proceedings. This is a slightly extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The F.A.S.T. model for microscopic simulation of pedestrians was formulated
with the idea of parallelizability and small computation times in general in
mind, but so far it was never demonstrated, if it can in fact be implemented
efficiently for execution on a multi-core or multi-CPU system. In this
contribution results are given on computation times for the F.A.S.T. model on
an eight-core PC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2902</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2902</id><created>2009-11-15</created><authors><author><keyname>Boenisch</keyname><forenames>Cornelia</forenames></author><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author></authors><title>Simulation of Pedestrians Crossing a Street</title><categories>cs.MA</categories><comments>Accepted as contribution to &quot;Traffic and Granular Flow 09&quot;
  proceedings. This is a slightly extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simulation of vehicular traffic as well as pedestrian dynamics meanwhile
both have a decades long history. The success of this conference series, PED
and others show that the interest in these topics is still strongly increasing.
This contribution deals with a combination of both systems: pedestrians
crossing a street. In a VISSIM simulation for varying demand jam sizes of
vehicles as well as pedestrians and the travel times of the pedestrians are
measured and compared. The study is considered as a study of VISSIM's con ict
area functionality as such, as there is no empirical data available to use for
calibration issues. Above a vehicle demand threshold the results show a
non-monotonic dependence of pedestrians' travel time on pedestrian demand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2904</identifier>
 <datestamp>2012-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2904</id><created>2009-11-15</created><updated>2012-03-13</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author><author><keyname>Willett</keyname><forenames>Rebecca</forenames></author><author><keyname>Horn</keyname><forenames>Corinne</forenames></author><author><keyname>Silva</keyname><forenames>Jorge</forenames></author><author><keyname>Marcia</keyname><forenames>Roummel</forenames></author></authors><title>Sequential anomaly detection in the presence of noise and limited
  feedback</title><categories>cs.LG</categories><comments>19 pages, 12 pdf figures; final version to be published in IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a methodology for detecting anomalies from sequentially
observed and potentially noisy data. The proposed approach consists of two main
elements: (1) {\em filtering}, or assigning a belief or likelihood to each
successive measurement based upon our ability to predict it from previous noisy
observations, and (2) {\em hedging}, or flagging potential anomalies by
comparing the current belief against a time-varying and data-adaptive
threshold. The threshold is adjusted based on the available feedback from an
end user. Our algorithms, which combine universal prediction with recent work
on online convex programming, do not require computing posterior distributions
given all current observations and involve simple primal-dual parameter
updates. At the heart of the proposed approach lie exponential-family models
which can be used in a wide variety of contexts and applications, and which
yield methods that achieve sublinear per-round regret against both static and
slowly varying product distributions with marginals drawn from the same
exponential family. Moreover, the regret against static distributions coincides
with the minimax value of the corresponding online strongly convex game. We
also prove bounds on the number of mistakes made during the hedging step
relative to the best offline choice of the threshold with access to all
estimated beliefs and feedback signals. We validate the theory on synthetic
data drawn from a time-varying distribution over binary vectors of high
dimensionality, as well as on the Enron email dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2907</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2907</id><created>2009-11-15</created><authors><author><keyname>Bradley</keyname><forenames>William F.</forenames></author></authors><title>A Recursive Definition of the Holographic Standard Signature</title><categories>cs.CC cs.DM</categories><comments>Fixed small typo in Section 3.6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a recursive description of the signatures realizable on the
standard basis by a holographic algorithm. The description allows us to prove
tight bounds on the size of planar matchgates and efficiently test for standard
signatures. Over finite fields, it allows us to count the number of n-bit
standard signatures and calculate their expected sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2922</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2922</id><created>2009-11-15</created><authors><author><keyname>Bradley</keyname><forenames>William F.</forenames></author></authors><title>Sparse Eigenvectors of the Discrete Fourier Transform</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a basis of sparse eigenvectors for the N-dimensional discrete
Fourier transform. The sparsity differs from the optimal by at most a factor of
four. When N is a perfect square, the basis is orthogonal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2924</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2924</id><created>2009-11-16</created><updated>2010-08-14</updated><authors><author><keyname>G&#xf6;&#xf6;s</keyname><forenames>Mika</forenames></author><author><keyname>Orponen</keyname><forenames>Pekka</forenames></author></authors><title>Synthesizing Minimal Tile Sets for Patterned DNA Self-Assembly</title><categories>cs.DS</categories><comments>12 pages, 6 figures</comments><acm-class>F.2.2; G.2.1; F.1.1; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Pattern self-Assembly Tile set Synthesis (PATS) problem is to determine a
set of coloured tiles that self-assemble to implement a given rectangular
colour pattern. We give an exhaustive branch-and-bound algorithm to find tile
sets of minimum cardinality for the PATS problem. Our algorithm makes use of a
search tree in the lattice of partitions of the ambient rectangular grid, and
an efficient bounding function to prune this search tree. Empirical data on the
performance of the algorithm shows that it compares favourably to previously
presented heuristic solutions to the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2942</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2942</id><created>2009-11-15</created><updated>2013-01-02</updated><authors><author><keyname>Giannella</keyname><forenames>Chris</forenames></author><author><keyname>Liu</keyname><forenames>Kun</forenames></author><author><keyname>Kargupta</keyname><forenames>Hillol</forenames></author></authors><title>Breaching Euclidean Distance-Preserving Data Perturbation Using Few
  Known Inputs</title><categories>cs.DB cs.CR</categories><comments>This is a major revision accounting for journal peer-review. Changes
  include: removal of known sample attack, more citations added, an empirical
  comparison against the algorithm of Kaplan et al. added</comments><journal-ref>Data &amp; Knowledge Engineering 83, pages 93-110, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine Euclidean distance-preserving data perturbation as a tool for
privacy-preserving data mining. Such perturbations allow many important data
mining algorithms e.g. hierarchical and k-means clustering), with only minor
modification, to be applied to the perturbed data and produce exactly the same
results as if applied to the original data. However, the issue of how well the
privacy of the original data is preserved needs careful study. We engage in
this study by assuming the role of an attacker armed with a small set of known
original data tuples (inputs). Little work has been done examining this kind of
attack when the number of known original tuples is less than the number of data
dimensions. We focus on this important case, develop and rigorously analyze an
attack that utilizes any number of known original tuples. The approach allows
the attacker to estimate the original data tuple associated with each perturbed
tuple and calculate the probability that the estimation results in a privacy
breach. On a real 16-dimensional dataset, we show that the attacker, with 4
known original tuples, can estimate an original unknown tuple with less than 7%
error with probability exceeding 0.8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2948</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2948</id><created>2009-11-15</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Spatial Analysis of Opportunistic Downlink Relaying in a Two-Hop
  Cellular System</title><categories>cs.IT cs.NI math.IT stat.ME</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-hop cellular system in which the mobile nodes help the base
station by relaying information to the dead spots. While two-hop cellular
schemes have been analyzed previously, the distribution of the node locations
has not been explicitly taken into account. In this paper, we model the node
locations of the base stations and the mobile stations as a point process on
the plane and then analyze the performance of two different two-hop schemes in
the downlink. In one scheme the node nearest to the destination that has
decoded information from the base station in the first hop is used as the
relay. In the second scheme the node with the best channel to the relay that
received information in the first hop acts as a relay. In both these schemes we
obtain the success probability of the two hop scheme, accounting for the
interference from all other cells. We use tools from stochastic geometry and
point process theory to analyze the two hop schemes. Besides the results
obtained a main contribution of the paper is to introduce a mathematical
framework that can be used to analyze arbitrary relaying schemes. Some of the
main contributions of this paper are the analytical techniques introduced for
the inclusion of the spatial locations of the nodes into the mathematical
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2952</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2952</id><created>2009-11-16</created><updated>2010-10-15</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cooperative Feedback for Multi-Antenna Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>26 pages; to appear in IEEE Trans. Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive beamforming (CB) is a multi-antenna technique for efficient
spectrum sharing between primary users (PUs) and secondary users (SUs) in a
cognitive radio network. Specifically, a multi-antenna SU transmitter applies
CB to suppress the interference to the PU receivers as well as enhance the
corresponding SU-link performance. In this paper, for a
multiple-input-single-output (MISO) SU channel coexisting with a
single-input-single-output (SISO) PU channel, we propose a new and practical
paradigm for designing CB based on the finite-rate cooperative feedback from
the PU receiver to the SU transmitter. Specifically, the PU receiver
communicates to the SU transmitter the quantized SU-to-PU channel direction
information (CDI) for computing the SU transmit beamformer, and the
interference power control (IPC) signal that regulates the SU transmission
power according to the tolerable interference margin at the PU receiver. Two CB
algorithms based on cooperative feedback are proposed: one restricts the SU
transmit beamformer to be orthogonal to the quantized SU-to-PU channel
direction and the other relaxes such a constraint. In addition, cooperative
feedforward of the SU CDI from the SU transmitter to the PU receiver is
exploited to allow more efficient cooperative feedback. The outage
probabilities of the SU link for different CB and cooperative
feedback/feedforward algorithms are analyzed, from which the optimal
bit-allocation tradeoff between the CDI and IPC feedback is characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2974</identifier>
 <datestamp>2014-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2974</id><created>2009-11-16</created><updated>2014-04-08</updated><authors><author><keyname>Agrawal</keyname><forenames>Shipra</forenames></author><author><keyname>Wang</keyname><forenames>Zizhuo</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>A Dynamic Near-Optimal Algorithm for Online Linear Programming</title><categories>cs.DS cs.LG</categories><msc-class>Primary: 68W27, 90B99, Secondary: 90B05, 90B50, 90C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural optimization model that formulates many online resource allocation
and revenue management problems is the online linear program (LP) in which the
constraint matrix is revealed column by column along with the corresponding
objective coefficient. In such a model, a decision variable has to be set each
time a column is revealed without observing the future inputs and the goal is
to maximize the overall objective function. In this paper, we provide a
near-optimal algorithm for this general class of online problems under the
assumption of random order of arrival and some mild conditions on the size of
the LP right-hand-side input. Specifically, our learning-based algorithm works
by dynamically updating a threshold price vector at geometric time intervals,
where the dual prices learned from the revealed columns in the previous period
are used to determine the sequential decisions in the current period. Due to
the feature of dynamic learning, the competitiveness of our algorithm improves
over the past study of the same problem. We also present a worst-case example
showing that the performance of our algorithm is near-optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2993</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2993</id><created>2009-11-16</created><updated>2010-09-01</updated><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author><author><keyname>Miller</keyname><forenames>Dale</forenames></author><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>A two-level logic approach to reasoning about computations</title><categories>cs.LO cs.PL</categories><comments>To appear in the Journal of Automated Reasoning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relational descriptions have been used in formalizing diverse computational
notions, including, for example, operational semantics, typing, and acceptance
by non-deterministic machines. We therefore propose a (restricted) logical
theory over relations as a language for specifying such notions. Our
specification logic is further characterized by an ability to explicitly treat
binding in object languages. Once such a logic is fixed, a natural next
question is how we might prove theorems about specifications written in it. We
propose to use a second logic, called a reasoning logic, for this purpose. A
satisfactory reasoning logic should be able to completely encode the
specification logic. Associated with the specification logic are various
notions of binding: for quantifiers within formulas, for eigenvariables within
sequents, and for abstractions within terms. To provide a natural treatment of
these aspects, the reasoning logic must encode binding structures as well as
their associated notions of scope, free and bound variables, and
capture-avoiding substitution. Further, to support arguments about provability,
the reasoning logic should possess strong mechanisms for constructing proofs by
induction and co-induction. We provide these capabilities here by using a logic
called G which represents relations over lambda-terms via definitions of atomic
judgments, contains inference rules for induction and co-induction, and
includes a special generic quantifier. We show how provability in the
specification logic can be transparently encoded in G. We also describe an
interactive theorem prover called Abella that implements G and this two-level
logic approach and we present several examples that demonstrate the efficacy of
Abella in reasoning about computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3005</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3005</id><created>2009-11-16</created><updated>2009-11-19</updated><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author></authors><title>How to combine diagrammatic logics</title><categories>cs.LO math.CT</categories><proxy>ccsd hal-00432330</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a submission to the contest: How to combine logics? at the
World Congress and School on Universal Logic III, 2010. We claim that combining
&quot;things&quot;, whatever these things are, is made easier if these things can be seen
as the objects of a category. We define the category of diagrammatic logics, so
that categorical constructions can be used for combining diagrammatic logics.
As an example, a combination of logics using an opfibration is presented, in
order to study computational side-effects due to the evolution of the state
during the execution of an imperative program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3024</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3024</id><created>2009-11-16</created><authors><author><keyname>Naves</keyname><forenames>Guyslain</forenames><affiliation>LGS</affiliation></author></authors><title>The hardness of routing two pairs on one face</title><categories>cs.DM</categories><proxy>ccsd hal-00313944</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the NP-completeness of the integer multiflow problem in planar
graphs, with the following restrictions: there are only two demand edges, both
lying on the infinite face of the routing graph. This was one of the open
challenges concerning disjoint paths, explicitly asked by M\&quot;uller. It also
strengthens Schw\&quot;arzler's recent proof of one of the open problems of
Schrijver's book, about the complexity of the edge-disjoint paths problem with
terminals on the outer boundary of a planar graph. We also give a directed
acyclic reduction. This proves that the arc-disjoint paths problem is
NP-complete in directed acyclic graphs, even with only two demand arcs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3086</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3086</id><created>2009-11-16</created><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Marx</keyname><forenames>Werner</forenames></author></authors><title>Citation Environment of Angewandte Chemie</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Lutz Bornmann, Loet Leydesdorff, and Werner Marx, Citation
  Environment of Angewandte Chemie, CHIMIA 61(3), 104-109, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, aggregated journal-journal citation networks were made accessible
from the perspective of each journal included in the Science Citation Index see
(http://www.leydesdorff.net/). The local matrices can be used to inspect the
relevant citation environment of a journal using statistical analysis and
visualization techniques from social network analysis. The inspection gives an
answer to the question what the local impact of this and other journals in the
environment is. In this study the citation environment of Angewandte Chemie was
analysed. Angewandte Chemie is one of the prime chemistry journals in the
world. Its environment was compared with that of the Journal of the American
Chemical Society. The results of the environment analyses give a detailed
insight into the field-embeddedness of Angewandte Chemie. The impacts of the
German and international editions of this journal are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3087</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3087</id><created>2009-11-16</created><authors><author><keyname>Zhou</keyname><forenames>Ping</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>A Comparison between the China Scientific and Technical Papers and
  Citations Database and the Science Citation Index in terms of journal
  hierarchies and inter-journal citation relations</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science and
  Technology 58(2), 223-236, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The journal structure in the China Scientific and Technical Papers and
Citations Database (CSTPCD) is analysed from three perspectives: the database
level, the specialty level and the institutional level (i.e., university
journals versus journals issued by the Chinese Academy of Sciences). The
results are compared with those for (Chinese) journals included in the Science
Citation Index. The frequency of journal-journal citation relations in the
CSTPCD is an order of magnitude lower than in the SCI. Chinese journals,
especially high-quality journals, prefer to cite international journals rather
than domestic ones. However, Chinese journals do not get an equivalent
reception from their international counterparts. The international visibility
of Chinese journals is low, but varies among fields of science. Journals of the
Chinese Academy of Sciences (CAS) have a better reception in the international
scientific community than university journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3091</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3091</id><created>2009-11-16</created><authors><author><keyname>Zhou</keyname><forenames>Ping</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Citation Impacts and Citation Environments of Chinese Journals in
  Mathematics</title><categories>cs.DL math.HO physics.soc-ph</categories><journal-ref>Zhou, Ping &amp; Loet Leydesdorff, The Citation Impacts and Citation
  Environments of Chinese Journals in Mathematics, Scientometrics 72(2),
  185-200, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the citation data of journals covered by the China Scientific and
Technical Papers and Citations Database (CSTPCD), we obtained aggregated
journal-journal citation environments by applying routines developed
specifically for this purpose. Local citation impact of journals is defined as
the share of the total citations in a local citation environment, which is
expressed as a ratio and can be visualized by the size of the nodes. The
vertical size of the nodes varies proportionally to a journal's total citation
share, while the horizontal size of the nodes is used to provide citation
information after correction for the within-journal (self-) citations. In this
study, we analyze citation impacts of three Chinese journals in mathematics and
compare local citation impacts with impact factors. Local citation impacts
reflect a journal's status and function better than (global) impact factors. We
also found that authors in Chinese journals prefer international instead of
domestic ones as sources for their citations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3092</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3092</id><created>2009-11-16</created><updated>2009-11-17</updated><authors><author><keyname>Vassev</keyname><forenames>Emil</forenames></author><author><keyname>Nguyen</keyname><forenames>Que Thu Dung</forenames></author><author><keyname>Kuang</keyname><forenames>Heng</forenames></author></authors><title>Fault-Tolerance through Message-logging and Check-pointing: Disaster
  Recovery for CORBA-based Distributed Bank Servers</title><categories>cs.DC cs.SE</categories><comments>42 pages,11 figues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report presents results of our endeavor towards developing a
failure-recovery variant of a CORBA-based bank server that provides fault
tolerance features through message logging and checkpoint logging. In this
group of projects, three components were developed to satisfy the requirements:
1) a message-logging protocol for the branch servers of the distributed banking
system to log required information; 2) a recovery module that restarts the bank
server using the message log to help the restarted bank server process
subsequent requests for various operations; 3) a monitor module that
periodically checks whether the bank server is down and helps the recovery
module restart the bank server if the latter has crashed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3093</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3093</id><created>2009-11-16</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Indicators of Structural Change in the Dynamics of Science: Entropy
  Statistics of the SCI Journal Citation Reports</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Scientometrics 53(1) (2002) 131-159</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can change in citation patterns among journals be used as an indicator of
structural change in the organization of the sciences? Aggregated
journal-journal citations for 1999 are compared with similar data in the
Journal Citation Reports 1998 of the Science Citation Index. In addition to
indicating local change, probabilistic entropy measures enable us to analyze
changes in distributions at different levels of aggregation. The results of
various statistics are discussed and compared by elaborating the
journal-journal mappings. The relevance of this indicator for science and
technology policies is further specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3095</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3095</id><created>2009-11-16</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Environment and Planning B as a Journal: The interdisciplinarity of its
  environment and the citation impact</title><categories>cs.DL physics.soc-ph</categories><journal-ref>In: T. Braun (ed.), The Impact Factors of Scientific and Scholarly
  Journals. Its Use and Misuse. Budapest: Akademiai Kiado, 2007, pp. 127-148</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The citation impact of Environment and Planning B can be visualized using its
citation relations with journals in its environment as the links of a network.
The size of the nodes is varied in correspondence to the relative citation
impact in this environment. Additionally, one can correct for the effect of
within-journal &quot;self&quot;-citations. The network can be partitioned and clustered
using algorithms from social network analysis. After transposing the matrix in
terms of rows and columns, the citing patterns can be mapped analogously.
Citing patterns reflect the activity of the community of authors who publish in
the journal, while being cited indicates reception. Environment and Planning B
is cited across the interface between the social sciences and the natural
sciences, but its authors cite almost exclusively from the domain of the Social
Science Citation Index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3108</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3108</id><created>2009-11-16</created><updated>2011-01-28</updated><authors><author><keyname>Gluskin</keyname><forenames>Emanuel</forenames></author></authors><title>On game psychology: an experiment on the chess board/screen, should you
  always &quot;do your best&quot;, and why the programs with prescribed weaknesses cannot
  be our good friends?</title><categories>cs.AI cs.GT math.HO</categories><comments>This is a somewhat contracted (compared to v1,2)version of my
  original manuscript motivated by observation of a very unusual weakness of a
  chess program that plays, generally, much stronger than I do, and by the wish
  to consider chess not just as competition, also as a model for human
  weaknesses. Some details of the experiment suggest a new version of the game.
  5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is noted that some unusual moves against a strong chess program greatly
weaken its ability to see the serious targets of the game, and its whole level
of play... It is suggested to create programs with different weaknesses in
order to analyze similar human behavior. Finally, a new version of chess,
&quot;Chess Corrida&quot; is suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3110</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3110</id><created>2009-11-16</created><authors><author><keyname>Harvey</keyname><forenames>David</forenames></author></authors><title>Faster exponentials of power series</title><categories>cs.SC cs.DS</categories><comments>3 pages, requires algorithm2e package</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new algorithm for computing exp(f) where f is a power series in
C[[x]]. If M(n) denotes the cost of multiplying polynomials of degree n, the
new algorithm costs (2.1666... + o(1)) M(n) to compute exp(f) to order n. This
improves on the previous best result, namely (2.333... + o(1)) M(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3125</identifier>
 <datestamp>2009-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3125</id><created>2009-11-16</created><updated>2009-11-22</updated><authors><author><keyname>Zorikov</keyname><forenames>T.</forenames></author></authors><title>A computational model of the bottlenose dolphin sonar:
  Feature-extracting method</title><categories>cs.CE</categories><comments>11 pages, 5 figures</comments><acm-class>I.5.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The data describing a process of echo-image formation in bottlenose dolphin
sonar perception were accumulated in our experimental explorations. These data
were formalized mathematically and used in the computational model, comparative
testing of which in echo-discrimination tasks revealed no less capabilities
then those of bottlenose dolphins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3162</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3162</id><created>2009-11-16</created><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Santhanam</keyname><forenames>Rahul</forenames></author></authors><title>Bounding Rationality by Discounting Time</title><categories>cs.GT cs.CC</categories><comments>To appear in Proceedings of The First Symposium on Innovations in
  Computer Science</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a game where Alice generates an integer and Bob wins if he can
factor that integer. Traditional game theory tells us that Bob will always win
this game even though in practice Alice will win given our usual assumptions
about the hardness of factoring.
  We define a new notion of bounded rationality, where the payoffs of players
are discounted by the computation time they take to produce their actions. We
use this notion to give a direct correspondence between the existence of
equilibria where Alice has a winning strategy and the hardness of factoring.
Namely, under a natural assumption on the discount rates, there is an
equilibriumwhere Alice has a winning strategy iff there is a linear-time
samplable distribution with respect to which Factoring is hard on average.
  We also give general results for discounted games over countable action
spaces, including showing that any game with bounded and computable payoffs has
an equilibrium in our model, even if each player is allowed a countable number
of actions. It follows, for example, that the Largest Integer game has an
equilibrium in our model though it has no Nash equilibria or epsilon-Nash
equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3189</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3189</id><created>2009-11-16</created><authors><author><keyname>Fr&#xf6;schle</keyname><forenames>Sibylle</forenames></author><author><keyname>Gorla</keyname><forenames>Daniele</forenames></author></authors><title>Proceedings 16th International Workshop on Expressiveness in Concurrency</title><categories>cs.LO</categories><acm-class>F.1.1; F.1.2; F.3.0; F.4.0</acm-class><journal-ref>EPTCS 8, 2009</journal-ref><doi>10.4204/EPTCS.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 16th International Workshop on
Expressiveness in Concurrency (EXPRESS'09), which took place on 5th September
2009 in Bologna, co-located with CONCUR'09. The EXPRESS workshop series aim at
bringing together researchers who are interested in the expressiveness and
comparison of formal models that broadly relate to concurrency. In particular,
this also includes emergent fields such as logic and interaction,
game-theoretic models, and service-oriented computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3195</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3195</id><created>2009-11-16</created><updated>2010-03-03</updated><authors><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Efficient Distributed Random Walks with Applications</title><categories>cs.DC cs.DS</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on the problem of performing random walks efficiently in a
distributed network. Given bandwidth constraints, the goal is to minimize the
number of rounds required to obtain a random walk sample. We first present a
fast sublinear time distributed algorithm for performing random walks whose
time complexity is sublinear in the length of the walk. Our algorithm performs
a random walk of length $\ell$ in $\tilde{O}(\sqrt{\ell D})$ rounds (with high
probability) on an undirected network, where $D$ is the diameter of the
network. This improves over the previous best algorithm that ran in
$\tilde{O}(\ell^{2/3}D^{1/3})$ rounds (Das Sarma et al., PODC 2009). We further
extend our algorithms to efficiently perform $k$ independent random walks in
$\tilde{O}(\sqrt{k\ell D} + k)$ rounds. We then show that there is a
fundamental difficulty in improving the dependence on $\ell$ any further by
proving a lower bound of $\Omega(\sqrt{\frac{\ell}{\log \ell}} + D)$ under a
general model of distributed random walk algorithms. Our random walk algorithms
are useful in speeding up distributed algorithms for a variety of applications
that use random walks as a subroutine. We present two main applications. First,
we give a fast distributed algorithm for computing a random spanning tree (RST)
in an arbitrary (undirected) network which runs in $\tilde{O}(\sqrt{m}D)$
rounds (with high probability; here $m$ is the number of edges). Our second
application is a fast decentralized algorithm for estimating mixing time and
related parameters of the underlying network. Our algorithm is fully
decentralized and can serve as a building block in the design of
topologically-aware networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3209</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3209</id><created>2009-11-16</created><authors><author><keyname>Pang</keyname><forenames>Chao-Yang</forenames></author><author><keyname>Liu</keyname><forenames>Hui</forenames></author><author><keyname>Li</keyname><forenames>Xia</forenames></author><author><keyname>Wang</keyname><forenames>Yun-Fei</forenames></author><author><keyname>Hu</keyname><forenames>Ben-Qiong</forenames></author></authors><title>Apply Ant Colony Algorithm to Search All Extreme Points of Function</title><categories>cs.AI cs.NE</categories><comments>23 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To find all extreme points of multimodal functions is called extremum
problem, which is a well known difficult issue in optimization fields. Applying
ant colony optimization (ACO) to solve this problem is rarely reported. The
method of applying ACO to solve extremum problem is explored in this paper.
Experiment shows that the solution error of the method presented in this paper
is less than 10^-8. keywords: Extremum Problem; Ant Colony Optimization (ACO)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3213</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3213</id><created>2009-11-17</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Optimum estimation via gradients of partition functions and information
  measures: a statistical-mechanical perspective</title><categories>cs.IT math.IT</categories><comments>21 pages; submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In continuation to a recent work on the statistical--mechanical analysis of
minimum mean square error (MMSE) estimation in Gaussian noise via its relation
to the mutual information (the I-MMSE relation), here we propose a simple and
more direct relationship between optimum estimation and certain information
measures (e.g., the information density and the Fisher information), which can
be viewed as partition functions and hence are amenable to analysis using
statistical--mechanical techniques. The proposed approach has several
advantages, most notably, its applicability to general sources and channels, as
opposed to the I-MMSE relation and its variants which hold only for certain
classes of channels (e.g., additive white Gaussian noise channels). We then
demonstrate the derivation of the conditional mean estimator and the MMSE in a
few examples. Two of these examples turn out to be generalizable to a fairly
wide class of sources and channels. For this class, the proposed approach is
shown to yield an approximate conditional mean estimator and an MMSE formula
that has the flavor of a single-letter expression. We also show how our
approach can easily be generalized to situations of mismatched estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3214</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3214</id><created>2009-11-17</created><updated>2010-01-13</updated><authors><author><keyname>Droste</keyname><forenames>Manfred</forenames></author><author><keyname>Zhang</keyname><forenames>Guo-Qiang</forenames></author></authors><title>Bifinite Chu Spaces</title><categories>cs.LO cs.DM</categories><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (January
  14, 2010) lmcs:1183</journal-ref><doi>10.2168/LMCS-6(1:3)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies colimits of sequences of finite Chu spaces and their
ramifications. Besides generic Chu spaces, we consider extensional and
biextensional variants. In the corresponding categories we first characterize
the monics and then the existence (or the lack thereof) of the desired
colimits. In each case, we provide a characterization of the finite objects in
terms of monomorphisms/injections. Bifinite Chu spaces are then expressed with
respect to the monics of generic Chu spaces, and universal, homogeneous Chu
spaces are shown to exist in this category. Unanticipated results driving this
development include the fact that while for generic Chu spaces monics consist
of an injective first and a surjective second component, in the extensional and
biextensional cases the surjectivity requirement can be dropped. Furthermore,
the desired colimits are only guaranteed to exist in the extensional case.
Finally, not all finite Chu spaces (considered set-theoretically) are finite
objects in their categories. This study opens up opportunities for further
investigations into recursively defined Chu spaces, as well as constructive
models of linear logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3241</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3241</id><created>2009-11-17</created><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author><author><keyname>De Pellegrini</keyname><forenames>Francesco</forenames></author></authors><title>Optimal Control in Two-Hop Relay Routing</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimal control of propagation of packets in delay tolerant
mobile ad-hoc networks. We consider a two-hop forwarding policy under which the
expected number of nodes carrying copies of the packets obeys a linear
dynamics. We exploit this property to formulate the problem in the framework of
linear quadratic optimal control which allows us to obtain closed-form
expressions for the optimal control and to study numerically the tradeoffs by
varying various parameters that define the cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3256</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3256</id><created>2009-11-17</created><updated>2010-08-28</updated><authors><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Enumerative Coding for Grassmannian Space</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Grassmannian space $\Gr$ is the set of all $k-$dimensional subspaces of
the vector space~\smash{$\F_q^n$}. Recently, codes in the Grassmannian have
found an application in network coding. The main goal of this paper is to
present efficient enumerative encoding and decoding techniques for the
Grassmannian. These coding techniques are based on two different orders for the
Grassmannian induced by different representations of $k$-dimensional subspaces
of $\F_q^n$. One enumerative coding method is based on a Ferrers diagram
representation and on an order for $\Gr$ based on this representation. The
complexity of this enumerative coding is $O(k^{5/2} (n-k)^{5/2})$ digit
operations. Another order of the Grassmannian is based on a combination of an
identifying vector and a reduced row echelon form representation of subspaces.
The complexity of the enumerative coding, based on this order, is
$O(nk(n-k)\log n\log\log n)$ digits operations. A combination of the two
methods reduces the complexity on average by a constant factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3262</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3262</id><created>2009-11-17</created><authors><author><keyname>Ouzan</keyname><forenames>Samuel</forenames></author><author><keyname>Be'ery</keyname><forenames>Yair</forenames></author></authors><title>Moderate-Density Parity-Check Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications, September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new type of short to moderate block-length, linear
error-correcting codes, called moderate-density parity-check (MDPC) codes. The
number of ones of the parity-check matrix of the codes presented is typically
higher than the number of ones of the parity-check matrix of low-density
parity-check (LDPC) codes. But, still lower than those of the parity-check
matrix of classical block codes. The proposed MDPC codes are cyclic and are
designed by constructing idempotents using cyclotomic cosets. The construction
is simple and allows finding short block-length, high-rate codes with good
minimum distance. Inspired by some recent iterative soft-input soft-output
(SISO) decoders used in a context of classical block codes, we propose a low
complexity, efficient, iterative decoder called Auto-Diversity (AD) decoder. AD
decoder is based on belief propagation (BP) decoder and takes advantage of the
fundamental property of automorphism group of the constructed cyclic code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3275</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3275</id><created>2009-11-17</created><authors><author><keyname>Van Tang</keyname><forenames>Nguyen</forenames><affiliation>AIST</affiliation></author></authors><title>A Tighter Bound for the Determinization of Visibly Pushdown Automata</title><categories>cs.FL cs.LO</categories><acm-class>F.4.3; F.4.1</acm-class><journal-ref>EPTCS 10, 2009, pp. 62-76</journal-ref><doi>10.4204/EPTCS.10.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visibly pushdown automata (VPA), introduced by Alur and Madhusuan in 2004, is
a subclass of pushdown automata whose stack behavior is completely determined
by the input symbol according to a fixed partition of the input alphabet. Since
its introduce, VPAs have been shown to be useful in various context, e.g., as
specification formalism for verification and as automaton model for processing
XML streams. Due to high complexity, however, implementation of formal
verification based on VPA framework is a challenge. In this paper we consider
the problem of implementing VPA-based model checking algorithms. For doing so,
we first present an improvement on upper bound for determinization of VPA.
Next, we propose simple on-the-fly algorithms to check universality and
inclusion problems of this automata class. Then, we implement the proposed
algorithms in a prototype tool. Finally, we conduct experiments on randomly
generated VPAs. The experimental results show that the proposed algorithms are
considerably faster than the standard ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3276</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3276</id><created>2009-11-17</created><authors><author><keyname>Fribourg</keyname><forenames>Laurent</forenames><affiliation>LSV Cachan</affiliation></author><author><keyname>Andr&#xe9;</keyname><forenames>Etienne</forenames><affiliation>LSV Cachan</affiliation></author></authors><title>An Inverse Method for Policy-Iteration Based Algorithms</title><categories>cs.DM cs.LO</categories><acm-class>F.4.3; F.4.1</acm-class><journal-ref>EPTCS 10, 2009, pp. 44-61</journal-ref><doi>10.4204/EPTCS.10.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension of two policy-iteration based algorithms on weighted
graphs (viz., Markov Decision Problems and Max-Plus Algebras). This extension
allows us to solve the following inverse problem: considering the weights of
the graph to be unknown constants or parameters, we suppose that a reference
instantiation of those weights is given, and we aim at computing a constraint
on the parameters under which an optimal policy for the reference instantiation
is still optimal. The original algorithm is thus guaranteed to behave well
around the reference instantiation, which provides us with some criteria of
robustness. We present an application of both methods to simple examples. A
prototype implementation has been done.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3277</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3277</id><created>2009-11-17</created><authors><author><keyname>Badban</keyname><forenames>Bahareh</forenames><affiliation>Konstanz university</affiliation></author><author><keyname>Leue</keyname><forenames>Stefan</forenames><affiliation>Konstanz university</affiliation></author><author><keyname>Smaus</keyname><forenames>Jan-Georg</forenames><affiliation>Freiburg University</affiliation></author></authors><title>Automated Predicate Abstraction for Real-Time Models</title><categories>cs.LO cs.FL</categories><acm-class>F.4.3; F.4.1</acm-class><journal-ref>EPTCS 10, 2009, pp. 36-43</journal-ref><doi>10.4204/EPTCS.10.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a technique designed to automatically compute predicate
abstractions for dense real-timed models represented as networks of timed
automata.
  We use the CIPM algorithm in our previous work which computes new invariants
for timed automata control locations and prunes the model, to compute a
predicate abstraction of the model. We do so by taking information regarding
control locations and their newly computed invariants into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3280</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3280</id><created>2009-11-17</created><updated>2012-07-02</updated><authors><author><keyname>Serva</keyname><forenames>Maurizio</forenames></author></authors><title>Automated languages phylogeny from Levenshtein distance</title><categories>cs.CL q-bio.PE q-bio.QM</categories><comments>Ideas and results in this paper were presented at the International
  Conference: Visitas Internationais, Instituto de Estudos Avancados
  Transdisciplinares, (Belo Horizonte, 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Languages evolve over time in a process in which reproduction, mutation and
extinction are all possible, similar to what happens to living organisms. Using
this similarity it is possible, in principle, to build family trees which show
the degree of relatedness between languages.
  The method used by modern glottochronology, developed by Swadesh in the
1950s, measures distances from the percentage of words with a common historical
origin. The weak point of this method is that subjective judgment plays a
relevant role.
  Recently we proposed an automated method that avoids the subjectivity, whose
results can be replicated by studies that use the same database and that
doesn't require a specific linguistic knowledge. Moreover, the method allows a
quick comparison of a large number of languages.
  We applied our method to the Indo-European and Austronesian families,
considering in both cases, fifty different languages. The resulting trees are
similar to those of previous studies, but with some important differences in
the position of few languages and subgroups. We believe that these differences
carry new information on the structure of the tree and on the phylogenetic
relationships within families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3283</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3283</id><created>2009-11-17</created><authors><author><keyname>Morvan</keyname><forenames>Christophe</forenames><affiliation>Universit&#xe9; Paris-Est</affiliation></author></authors><title>On external presentations of infinite graphs</title><categories>cs.FL cs.DM cs.LO</categories><acm-class>F.4.3; F.4.1</acm-class><journal-ref>EPTCS 10, 2009, pp. 23-35</journal-ref><doi>10.4204/EPTCS.10.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vertices of a finite state system are usually a subset of the natural
numbers. Most algorithms relative to these systems only use this fact to select
vertices.
  For infinite state systems, however, the situation is different: in
particular, for such systems having a finite description, each state of the
system is a configuration of some machine. Then most algorithmic approaches
rely on the structure of these configurations. Such characterisations are said
internal. In order to apply algorithms detecting a structural property (like
identifying connected components) one may have first to transform the system in
order to fit the description needed for the algorithm. The problem of internal
characterisation is that it hides structural properties, and each solution
becomes ad hoc relatively to the form of the configurations.
  On the contrary, external characterisations avoid explicit naming of the
vertices. Such characterisation are mostly defined via graph transformations.
  In this paper we present two kind of external characterisations:
deterministic graph rewriting, which in turn characterise regular graphs,
deterministic context-free languages, and rational graphs. Inverse substitution
from a generator (like the complete binary tree) provides characterisation for
prefix-recognizable graphs, the Caucal Hierarchy and rational graphs. We
illustrate how these characterisation provide an efficient tool for the
representation of infinite state systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3291</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3291</id><created>2009-11-17</created><authors><author><keyname>Magniez</keyname><forenames>F.</forenames></author><author><keyname>Mathieu</keyname><forenames>C.</forenames></author><author><keyname>Nayak</keyname><forenames>A.</forenames></author></authors><title>Recognizing well-parenthesized expressions in the streaming model</title><categories>cs.DS cs.CC</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a concrete problem and with the goal of understanding the sense
in which the complexity of streaming algorithms is related to the complexity of
formal languages, we investigate the problem Dyck(s) of checking matching
parentheses, with $s$ different types of parenthesis.
  We present a one-pass randomized streaming algorithm for Dyck(2) with space
$\Order(\sqrt{n}\log n)$, time per letter $\polylog (n)$, and one-sided error.
We prove that this one-pass algorithm is optimal, up to a $\polylog n$ factor,
even when two-sided error is allowed. For the lower bound, we prove a direct
sum result on hard instances by following the &quot;information cost&quot; approach, but
with a few twists. Indeed, we play a subtle game between public and private
coins. This mixture between public and private coins results from a balancing
act between the direct sum result and a combinatorial lower bound for the base
case.
  Surprisingly, the space requirement shrinks drastically if we have access to
the input stream in reverse. We present a two-pass randomized streaming
algorithm for Dyck(2) with space $\Order((\log n)^2)$, time $\polylog (n)$ and
one-sided error, where the second pass is in the reverse direction. Both
algorithms can be extended to Dyck(s) since this problem is reducible to
Dyck(2) for a suitable notion of reduction in the streaming model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3292</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3292</id><created>2009-11-17</created><updated>2009-12-05</updated><authors><author><keyname>Petroni</keyname><forenames>Filippo</forenames></author><author><keyname>Serva</keyname><forenames>Maurizio</forenames></author></authors><title>Automated words stability and languages phylogeny</title><categories>cs.CL physics.soc-ph q-bio.PE</categories><comments>XI International Conference &quot;Cognitive Modeling in Linguistics-2009&quot;
  Constanca, Romania, September, 7-14, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of measuring distance between languages seems to have its roots in
the work of the French explorer Dumont D'Urville (D'Urville 1832). He collected
comparative words lists of various languages during his voyages aboard the
Astrolabe from 1826 to1829 and, in his work about the geographical division of
the Pacific, he proposed a method to measure the degree of relation among
languages. The method used by modern glottochronology, developed by Morris
Swadesh in the 1950s (Swadesh 1952), measures distances from the percentage of
shared cognates, which are words with a common historical origin. Recently, we
proposed a new automated method which uses normalized Levenshtein distance
among words with the same meaning and averages on the words contained in a
list. Another classical problem in glottochronology is the study of the
stability of words corresponding to different meanings. Words, in fact, evolve
because of lexical changes, borrowings and replacement at a rate which is not
the same for all of them. The speed of lexical evolution is different for
different meanings and it is probably related to the frequency of use of the
associated words (Pagel et al. 2007). This problem is tackled here by an
automated methodology only based on normalized Levenshtein distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3298</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3298</id><created>2009-11-17</created><authors><author><keyname>Chinea</keyname><forenames>Alejandro</forenames></author></authors><title>Understanding the Principles of Recursive Neural networks: A Generative
  Approach to Tackle Model Complexity</title><categories>cs.NE cs.LG</categories><comments>11 pages, 4 figures, Recurrent Networks session ICANN 2009</comments><journal-ref>Alippi, C., Polycarpou, M. Panayiotou, C., Ellinas, G. (Eds.)
  ICANN 2009, LNCS, vol. 5768 pp. 952-963, Springer, Heidelberg (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recursive Neural Networks are non-linear adaptive models that are able to
learn deep structured information. However, these models have not yet been
broadly accepted. This fact is mainly due to its inherent complexity. In
particular, not only for being extremely complex information processing models,
but also because of a computational expensive learning phase. The most popular
training method for these models is back-propagation through the structure.
This algorithm has been revealed not to be the most appropriate for structured
processing due to problems of convergence, while more sophisticated training
methods enhance the speed of convergence at the expense of increasing
significantly the computational cost. In this paper, we firstly perform an
analysis of the underlying principles behind these models aimed at
understanding their computational power. Secondly, we propose an approximate
second order stochastic learning algorithm. The proposed algorithm dynamically
adapts the learning rate throughout the training phase of the network without
incurring excessively expensive computational effort. The algorithm operates in
both on-line and batch modes. Furthermore, the resulting learning scheme is
robust against the vanishing gradients problem. The advantages of the proposed
algorithm are demonstrated with a real-world application example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3299</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3299</id><created>2009-11-17</created><authors><author><keyname>Legay</keyname><forenames>Axel</forenames></author><author><keyname>Faella</keyname><forenames>Marco</forenames></author></authors><title>Some Models and Tools for Open Systems</title><categories>cs.LO</categories><comments>This is our invited paper to FIT 2005</comments><acm-class>F.4.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In computer science, there is a distinction between closed systems, whose
behavior is totally determined in advance, and open systems, that are systems
maintaining a constant interaction with an unspecified environment. Closed
systems are naturally modeled by transitions systems. Open systems have been
modeled in various ways, including process algebras, I/O automata, ``modules'',
and interfaces. Games provide a uniform setting in which all these models can
be cast and compared. In this paper, we discuss the features and costs related
to the game-based approach to open systems, referring to some of the existing
models. Finally, we describe a new model of interface, called sociable
interface, which is geared towards easier specification, improved reusability
of models, and efficient symbolic implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3301</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3301</id><created>2009-11-17</created><authors><author><keyname>Nourrissier</keyname><forenames>Patrick</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Sidhom</keyname><forenames>Sahbi</forenames><affiliation>LORIA</affiliation></author></authors><title>Le travail coop\'eratif comme vecteur d'\'evolution de nos syst\`emes
  d'information</title><categories>cs.OH</categories><proxy>ccsd inria-00426372</proxy><journal-ref>Conf\'erence internationale sur les &quot;Syst\`emes d'Information et
  Intelligence Economique&quot;, Hammamet : Tunisie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article focuses on presenting the cooperative tool DIMS, it is a
platform that can manage the participants's daily life, by providing
flexibility and speed in the organization's tasks. The main interest lies in
the possibility of organizing information system in a logical network, across
multiple physical sites, incorporating a specific protocol to making possible
the inter-server communication. This protocol, based on the Jabber standard,
that meets the needs of working everyday matters, allowing the distribution of
research and access to resources of the WAN. The technological objective
concerns the evolution of an information system architectures, where the
application may be a comprehensive set of tools and services on a distributed
network of remote sites. The challenge for users is the perception of a
collective role to each individual who cooperates in compliance with safety
rules and unlimited access to technical information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3304</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3304</id><created>2009-11-17</created><authors><author><keyname>Giot</keyname><forenames>Romain</forenames><affiliation>GREYC</affiliation></author><author><keyname>El-Abed</keyname><forenames>Mohamad</forenames><affiliation>GREYC</affiliation></author><author><keyname>Rosenberger</keyname><forenames>Christophe</forenames><affiliation>GREYC</affiliation></author></authors><title>Keystroke Dynamics Authentication For Collaborative Systems</title><categories>cs.LG</categories><proxy>ccsd hal-00432764</proxy><journal-ref>The IEEE International Symposium on Collaborative Technologies and
  Systems (CTS), Baltimore : United States (2009)</journal-ref><doi>10.1109/CTS.2009.5067478</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper a study on the ability and the benefits of using a
keystroke dynamics authentication method for collaborative systems.
Authentication is a challenging issue in order to guarantee the security of use
of collaborative systems during the access control step. Many solutions exist
in the state of the art such as the use of one time passwords or smart-cards.
We focus in this paper on biometric based solutions that do not necessitate any
additional sensor. Keystroke dynamics is an interesting solution as it uses
only the keyboard and is invisible for users. Many methods have been published
in this field. We make a comparative study of many of them considering the
operational constraints of use for collaborative systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3306</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3306</id><created>2009-11-17</created><authors><author><keyname>Boudjlida</keyname><forenames>Nacer</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Jacquot</keyname><forenames>Jean-Pierre</forenames><affiliation>LORIA</affiliation></author><author><keyname>Urso</keyname><forenames>Pascal</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Software Engineering Education by Example</title><categories>cs.SE</categories><proxy>ccsd hal-00432755</proxy><journal-ref>5th China - Europe International Symposium on Software Industry
  Oriented Education (CEISIE 2009), Bordeaux : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the old but famous distinction between &quot;in the small&quot; and &quot;in the
large&quot; software development, at Nancy Universit\'e, UHP Nancy 1, we experience
for a while software engineering education thanks to actual project
engineering. This education method has the merit to enable students to discover
and to overcome actual problems when faced to a large project which may be
conducted by a large development team. The mode of education is a simulation of
an actual software engineering project as encountered in &quot;real life\'e&quot;
activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3307</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3307</id><created>2009-11-17</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>On Some Sets of Dictionaries Whose omega-Powers Have a Given Complexity</title><categories>math.LO cs.FL cs.LO</categories><comments>To appear in Mathematical Logic Quarterly</comments><proxy>ccsd hal-00432736</proxy><msc-class>03E15, 03B70, 54H05, 68Q15, 68Q45</msc-class><journal-ref>Mathematical Logic Quarterly 56, 5 (2010) 452?460</journal-ref><doi>10.1002/malq.200810154</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dictionary is a set of finite words over some finite alphabet X. The
omega-power of a dictionary V is the set of infinite words obtained by infinite
concatenation of words in V. Lecomte studied in [Omega-powers and descriptive
set theory, JSL 2005] the complexity of the set of dictionaries whose
associated omega-powers have a given complexity. In particular, he considered
the sets $W({\bf\Si}^0_{k})$ (respectively, $W({\bf\Pi}^0_{k})$,
$W({\bf\Delta}_1^1)$) of dictionaries $V \subseteq 2^\star$ whose omega-powers
are ${\bf\Si}^0_{k}$-sets (respectively, ${\bf\Pi}^0_{k}$-sets, Borel sets). In
this paper we first establish a new relation between the sets
$W({\bf\Sigma}^0_{2})$ and $W({\bf\Delta}_1^1)$, showing that the set
$W({\bf\Delta}_1^1)$ is &quot;more complex&quot; than the set $W({\bf\Sigma}^0_{2})$. As
an application we improve the lower bound on the complexity of
$W({\bf\Delta}_1^1)$ given by Lecomte. Then we prove that, for every integer
$k\geq 2$, (respectively, $k\geq 3$) the set of dictionaries
$W({\bf\Pi}^0_{k+1})$ (respectively, $W({\bf\Si}^0_{k+1})$) is &quot;more complex&quot;
than the set of dictionaries $W({\bf\Pi}^0_{k})$ (respectively,
$W({\bf\Si}^0_{k})$) .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3318</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3318</id><created>2009-11-17</created><authors><author><keyname>Claude</keyname><forenames>Francisco</forenames></author><author><keyname>Farina</keyname><forenames>Antonio</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author></authors><title>Re-Pair Compression of Inverted Lists</title><categories>cs.IR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compression of inverted lists with methods that support fast intersection
operations is an active research topic. Most compression schemes rely on
encoding differences between consecutive positions with techniques that favor
small numbers. In this paper we explore a completely different alternative: We
use Re-Pair compression of those differences. While Re-Pair by itself offers
fast decompression at arbitrary positions in main and secondary memory, we
introduce variants that in addition speed up the operations required for
inverted list intersection. We compare the resulting data structures with
several recent proposals under various list intersection algorithms, to
conclude that our Re-Pair variants offer an interesting time/space tradeoff for
this problem, yet further improvements are required for it to improve upon the
state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3343</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3343</id><created>2009-11-17</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Repp</keyname><forenames>Juergen</forenames></author><author><keyname>Fhom</keyname><forenames>Hervais Simo</forenames></author><author><keyname>Fuchs</keyname><forenames>Andreas</forenames></author><author><keyname>Benaissa</keyname><forenames>Ine-Saf</forenames></author></authors><title>Final Architecture Specification of security, privacy, and incentive
  mechanisms</title><categories>cs.CR</categories><comments>Delieverable of the EU FP7 project Nanodatacenters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this document, we define the NADA security architecture based on refined
use case scenarios, a derived high level model and security analysis. For the
architecure design and verification we are applying the well known STRIDE
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3347</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3347</id><created>2009-11-17</created><authors><author><keyname>Kowshik</keyname><forenames>Hemant</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Optimal strategies for computing symmetric Boolean functions in
  collocated networks</title><categories>cs.IT math.IT</categories><comments>5 pages, To appear in Proceedings of the IEEE Information Theory
  Workshop, Cairo, January 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of finding optimal strategies for computing Boolean
symmetric functions. We consider a collocated network, where each node's
transmissions can be heard by every other node. Each node has a Boolean
measurement and we wish to compute a given Boolean function of these
measurements with zero error. We allow for block computation to enhance data
fusion efficiency, and determine the minimum worst-case total bits to be
communicated to perform the desired computation. We restrict attention to the
class of symmetric Boolean functions, which only depend on the number of 1s
among the n measurements.
  We define three classes of functions, namely threshold functions, delta
functions and interval functions. We provide exactly optimal strategies for the
first two classes, and an order-optimal strategy with optimal preconstant for
interval functions. Using these results, we can characterize the complexity of
computing percentile type functions, which is of great interest. In our
analysis, we use lower bounds from communication complexity theory, and provide
an achievable scheme using information theoretic tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3349</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3349</id><created>2009-11-17</created><authors><author><keyname>Goodman</keyname><forenames>Alyssa</forenames></author></authors><title>Seeing Science</title><categories>astro-ph.IM cs.CV cs.GR stat.AP</categories><comments>4 pages, including 3 figures. To appear in Proceedings of the
  International Festival of Scientific Visualization, held in Tokyo, Japan,
  March 2009. Publisher will be Universal Academy Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to represent scientific data and concepts visually is becoming
increasingly important due to the unprecedented exponential growth of
computational power during the present digital age. The data sets and
simulations scientists in all fields can now create are literally thousands of
times as large as those created just 20 years ago. Historically successful
methods for data visualization can, and should, be applied to today's huge data
sets, but new approaches, also enabled by technology, are needed as well.
Increasingly, &quot;modular craftsmanship&quot; will be applied, as relevant
functionality from the graphically and technically best tools for a job are
combined as-needed, without low-level programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3352</identifier>
 <datestamp>2010-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3352</id><created>2009-11-17</created><updated>2010-01-03</updated><authors><author><keyname>Sharir</keyname><forenames>Micha</forenames></author><author><keyname>Sheffer</keyname><forenames>Adam</forenames></author></authors><title>Counting Triangulations of Planar Point Sets</title><categories>cs.DM</categories><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the maximal number of triangulations that a planar set of $n$ points
can have, and show that it is at most $30^n$. This new bound is achieved by a
careful optimization of the charging scheme of Sharir and Welzl (2006), which
has led to the previous best upper bound of $43^n$ for the problem.
  Moreover, this new bound is useful for bounding the number of other types of
planar (i.e., crossing-free) straight-line graphs on a given point set.
Specifically, we derive new upper bounds for the number of planar graphs
($o(239.4^n)$), spanning cycles ($O(70.21^n)$), and spanning trees ($160^n$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3355</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3355</id><created>2009-11-17</created><authors><author><keyname>Xu</keyname><forenames>Zhi</forenames></author></authors><title>A Minimal Periods Algorithm with Applications</title><categories>cs.DS</categories><comments>14 pages</comments><acm-class>F.2.2; J.3</acm-class><doi>10.1007/978-3-642-13509-5_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kosaraju in ``Computation of squares in a string'' briefly described a
linear-time algorithm for computing the minimal squares starting at each
position in a word. Using the same construction of suffix trees, we generalize
his result and describe in detail how to compute in O(k|w|)-time the minimal
k-th power, with period of length larger than s, starting at each position in a
word w for arbitrary exponent $k\geq2$ and integer $s\geq0$. We provide the
complete proof of correctness of the algorithm, which is somehow not completely
clear in Kosaraju's original paper. The algorithm can be used as a sub-routine
to detect certain types of pseudo-patterns in words, which is our original
intention to study the generalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3357</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3357</id><created>2009-11-17</created><authors><author><keyname>Freris</keyname><forenames>Nikolaos M.</forenames></author><author><keyname>Kowshik</keyname><forenames>Hemant</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Fundamentals of Large Sensor Networks: Connectivity, Capacity, Clocks
  and Computation</title><categories>cs.NI cs.IT math.IT</categories><comments>10 pages, 3 figures, Submitted to the Proceedings of the IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor networks potentially feature large numbers of nodes that can sense
their environment over time, communicate with each other over a wireless
network, and process information. They differ from data networks in that the
network as a whole may be designed for a specific application. We study the
theoretical foundations of such large scale sensor networks, addressing four
fundamental issues- connectivity, capacity, clocks and function computation.
  To begin with, a sensor network must be connected so that information can
indeed be exchanged between nodes. The connectivity graph of an ad-hoc network
is modeled as a random graph and the critical range for asymptotic connectivity
is determined, as well as the critical number of neighbors that a node needs to
connect to. Next, given connectivity, we address the issue of how much data can
be transported over the sensor network. We present fundamental bounds on
capacity under several models, as well as architectural implications for how
wireless communication should be organized.
  Temporal information is important both for the applications of sensor
networks as well as their operation.We present fundamental bounds on the
synchronizability of clocks in networks, and also present and analyze
algorithms for clock synchronization. Finally we turn to the issue of gathering
relevant information, that sensor networks are designed to do. One needs to
study optimal strategies for in-network aggregation of data, in order to
reliably compute a composite function of sensor measurements, as well as the
complexity of doing so. We address the issue of how such computation can be
performed efficiently in a sensor network and the algorithms for doing so, for
some classes of functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3389</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3389</id><created>2009-11-17</created><updated>2010-02-18</updated><authors><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author></authors><title>Bounded Independence Fools Degree-2 Threshold Functions</title><categories>cs.CC</categories><comments>Using v1 numbering: removed Lemma G.5 from the Appendix (it was
  wrong). Net effect is that Theorem G.6 reduces the m^6 dependence of Theorem
  8.1 to m^4, not m^2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let x be a random vector coming from any k-wise independent distribution over
{-1,1}^n. For an n-variate degree-2 polynomial p, we prove that E[sgn(p(x))] is
determined up to an additive epsilon for k = poly(1/epsilon). This answers an
open question of Diakonikolas et al. (FOCS 2009). Using standard constructions
of k-wise independent distributions, we obtain a broad class of explicit
generators that epsilon-fool the class of degree-2 threshold functions with
seed length log(n)*poly(1/epsilon).
  Our approach is quite robust: it easily extends to yield that the
intersection of any constant number of degree-2 threshold functions is
epsilon-fooled by poly(1/epsilon)-wise independence. Our results also hold if
the entries of x are k-wise independent standard normals, implying for example
that bounded independence derandomizes the Goemans-Williamson hyperplane
rounding scheme.
  To achieve our results, we introduce a technique we dub multivariate
FT-mollification, a generalization of the univariate form introduced by Kane et
al. (SODA 2010) in the context of streaming algorithms. Along the way we prove
a generalized hypercontractive inequality for quadratic forms which takes the
operator norm of the associated matrix into account. These techniques may be of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3405</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3405</id><created>2009-11-17</created><authors><author><keyname>Bouchy</keyname><forenames>Florent</forenames></author><author><keyname>Finkel</keyname><forenames>Alain</forenames></author><author><keyname>Pietro</keyname><forenames>Pierluigi San</forenames></author></authors><title>Dense-choice Counter Machines revisited</title><categories>cs.LO</categories><acm-class>F.4.3; F.4.1</acm-class><journal-ref>EPTCS 10, 2009, pp. 3-22</journal-ref><doi>10.4204/EPTCS.10.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper clarifies the picture about Dense-choice Counter Machines, which
have been less studied than (discrete) Counter Machines. We revisit the
definition of &quot;Dense Counter Machines&quot; so that it now extends (discrete)
Counter Machines, and we provide new undecidability and decidability results.
Using the first-order additive mixed theory of reals and integers, we give a
logical characterization of the sets of configurations reachable by
reversal-bounded Dense-choice Counter Machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3411</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3411</id><created>2009-11-17</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Hellsten</keyname><forenames>Iina</forenames></author></authors><title>Measuring the Meaning of Words in Contexts: An automated analysis of
  controversies about Monarch butterflies, Frankenfoods, and stem cells</title><categories>cs.CL cs.IR physics.soc-ph</categories><journal-ref>Scientometrics 67(2), 2006, 231-258</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Co-words have been considered as carriers of meaning across different domains
in studies of science, technology, and society. Words and co-words, however,
obtain meaning in sentences, and sentences obtain meaning in their contexts of
use. At the science/society interface, words can be expected to have different
meanings: the codes of communication that provide meaning to words differ on
the varying sides of the interface. Furthermore, meanings and interfaces may
change over time. Given this structuring of meaning across interfaces and over
time, we distinguish between metaphors and diaphors as reflexive mechanisms
that facilitate the translation between contexts. Our empirical focus is on
three recent scientific controversies: Monarch butterflies, Frankenfoods, and
stem-cell therapies. This study explores new avenues that relate the study of
co-word analysis in context with the sociological quest for the analysis and
processing of meaning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3415</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3415</id><created>2009-11-17</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Can Scientific Journals be Classified in terms of Aggregated
  Journal-Journal Citation Relations using the Journal Citation Reports?</title><categories>cs.DL cs.IR physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science and
  Technology, 57(5) (2006) 601-613</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aggregated citation relations among journals included in the Science
Citation Index provide us with a huge matrix which can be analyzed in various
ways. Using principal component analysis or factor analysis, the factor scores
can be used as indicators of the position of the cited journals in the citing
dimensions of the database. Unrotated factor scores are exact, and the
extraction of principal components can be made stepwise since the principal
components are independent. Rotation may be needed for the designation, but in
the rotated solution a model is assumed. This assumption can be legitimated on
pragmatic or theoretical grounds. Since the resulting outcomes remain sensitive
to the assumptions in the model, an unambiguous classification is no longer
possible in this case. However, the factor-analytic solutions allow us to test
classifications against the structures contained in the database. This will be
demonstrated for the delineation of a set of biochemistry journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3416</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3416</id><created>2009-11-17</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bensman</keyname><forenames>Stephen</forenames></author></authors><title>Classification and Powerlaws: The Logarithmic Transformation</title><categories>cs.IR cs.DL physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science and
  Technology 57(11) (2006) 1470-1486</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logarithmic transformation of the data has been recommended by the literature
in the case of highly skewed distributions such as those commonly found in
information science. The purpose of the transformation is to make the data
conform to the lognormal law of error for inferential purposes. How does this
transformation affect the analysis? We factor analyze and visualize the
citation environment of the Journal of the American Chemical Society (JACS)
before and after a logarithmic transformation. The transformation strongly
reduces the variance necessary for classificatory purposes and therefore is
counterproductive to the purposes of the descriptive statistics. We recommend
against the logarithmic transformation when sets cannot be defined
unambiguously. The intellectual organization of the sciences is reflected in
the curvilinear parts of the citation distributions, while negative powerlaws
fit excellently to the tails of the distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3418</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3418</id><created>2009-11-17</created><authors><author><keyname>Shekhar</keyname><forenames>Shashank</forenames></author><author><keyname>Soni</keyname><forenames>Mohit</forenames></author><author><keyname>Chakravarthy</keyname><forenames>NVSN Kalyan</forenames></author></authors><title>Flare: Architecture for rapid and easy development of Internet-based
  Applications</title><categories>cs.NI</categories><comments>4 pages, 5 figures</comments><acm-class>K.6.3; H.3.4; H.3.3; K.6.5</acm-class><doi>10.5120/549-716</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an architecture, Flare, that is a structured and easy way to
develop applications rapidly, in a multitude of languages, which make use of
online storage of data and management of users. The architecture eliminates the
need for server-side programming in most cases, creation and management of
online database storage servers, re-creation of user management schemes and
writing a lot of unnecessary code for accessing different web-based services
using their APIs. A Web API provides a common API for various web-based
services like Blogger [2], Wordpress, MSN Live, Facebook [3] etc. Access
Libraries provided for major programming languages and platforms make it easy
to develop applications using the Flare Web Service. We demonstrate a simple
micro-blogging service developed using these APIs in two modes: a graphical
browser-based mode, and a command-line mode in C++, which provide two different
interfaces to the same account and data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3422</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3422</id><created>2009-11-17</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Vaughan</keyname><forenames>Liwen</forenames></author></authors><title>Co-occurrence Matrices and their Applications in Information Science:
  Extending ACA to the Web Environment</title><categories>cs.IR cs.DL physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science &amp;
  Technology 57(12) (2006) 1616-1628</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Co-occurrence matrices, such as co-citation, co-word, and co-link matrices,
have been used widely in the information sciences. However, confusion and
controversy have hindered the proper statistical analysis of this data. The
underlying problem, in our opinion, involved understanding the nature of
various types of matrices. This paper discusses the difference between a
symmetrical co-citation matrix and an asymmetrical citation matrix as well as
the appropriate statistical techniques that can be applied to each of these
matrices, respectively. Similarity measures (like the Pearson correlation
coefficient or the cosine) should not be applied to the symmetrical co-citation
matrix, but can be applied to the asymmetrical citation matrix to derive the
proximity matrix. The argument is illustrated with examples. The study then
extends the application of co-occurrence matrices to the Web environment where
the nature of the available data and thus data collection methods are different
from those of traditional databases such as the Science Citation Index. A set
of data collected with the Google Scholar search engine is analyzed using both
the traditional methods of multivariate analysis and the new visualization
software Pajek that is based on social network analysis and graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3438</identifier>
 <datestamp>2010-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3438</id><created>2009-11-17</created><updated>2010-05-20</updated><authors><author><keyname>Jorg</keyname><forenames>T.</forenames></author><author><keyname>Krzakala</keyname><forenames>F.</forenames></author><author><keyname>Semerjian</keyname><forenames>G.</forenames></author><author><keyname>Zamponi</keyname><forenames>F.</forenames></author></authors><title>First-order transitions and the performance of quantum algorithms in
  random optimization problems</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC quant-ph</categories><comments>4 pages, 4 figures; final version accepted on Phys.Rev.Lett</comments><journal-ref>Phys. Rev. Lett. 104, 207206 (2010)</journal-ref><doi>10.1103/PhysRevLett.104.207206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a study of the phase diagram of a random optimization problem in
presence of quantum fluctuations. Our main result is the characterization of
the nature of the phase transition, which we find to be a first-order quantum
phase transition. We provide evidence that the gap vanishes exponentially with
the system size at the transition. This indicates that the Quantum Adiabatic
Algorithm requires a time growing exponentially with system size to find the
ground state of this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3440</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3440</id><created>2009-11-17</created><authors><author><keyname>Legay</keyname><forenames>Axel</forenames><affiliation>INRIA/Irisa Rennes</affiliation></author></authors><title>Proceedings International Workshop on Verification of Infinite-State
  Systems</title><categories>cs.LO cs.DM cs.FL</categories><acm-class>F.4.3; F.4.1</acm-class><journal-ref>EPTCS 10, 2009</journal-ref><doi>10.4204/EPTCS.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 11th International Workshop on
Verification of Infinite-State Systems (INFINITY 2009). The workshop was held
in Bologna, Italy on August 31, 2009, as a satellite event to the 20th
International Conference on Concurrency Theory (CONCUR 2009). The aim of the
INFINITY workshop is to provide a forum for researchers interested in the
development of formal methods and algorithmic techniques for the analysis of
systems with infinitely many states, and their application in automated
verification of complex software and hardware systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3456</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3456</id><created>2009-11-17</created><updated>2011-03-29</updated><authors><author><keyname>Kl&#xf6;ckner</keyname><forenames>Andreas</forenames></author><author><keyname>Pinto</keyname><forenames>Nicolas</forenames></author><author><keyname>Lee</keyname><forenames>Yunsup</forenames></author><author><keyname>Catanzaro</keyname><forenames>Bryan</forenames></author><author><keyname>Ivanov</keyname><forenames>Paul</forenames></author><author><keyname>Fasih</keyname><forenames>Ahmed</forenames></author></authors><title>PyCUDA and PyOpenCL: A Scripting-Based Approach to GPU Run-Time Code
  Generation</title><categories>cs.DC cs.SE</categories><comments>Submitted to Parallel Computing, Elsevier</comments><acm-class>D.1.2</acm-class><doi>10.1016/j.parco.2011.09.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-performance computing has recently seen a surge of interest in
heterogeneous systems, with an emphasis on modern Graphics Processing Units
(GPUs). These devices offer tremendous potential for performance and efficiency
in important large-scale applications of computational science. However,
exploiting this potential can be challenging, as one must adapt to the
specialized and rapidly evolving computing environment currently exhibited by
GPUs. One way of addressing this challenge is to embrace better techniques and
develop tools tailored to their needs. This article presents one simple
technique, GPU run-time code generation (RTCG), along with PyCUDA and PyOpenCL,
two open-source toolkits that support this technique.
  In introducing PyCUDA and PyOpenCL, this article proposes the combination of
a dynamic, high-level scripting language with the massive performance of a GPU
as a compelling two-tiered computing platform, potentially offering significant
performance and productivity advantages over conventional single-tier, static
systems. The concept of RTCG is simple and easily implemented using existing,
robust infrastructure. Nonetheless it is powerful enough to support (and
encourage) the creation of custom application-specific tools by its users. The
premise of the paper is illustrated by a wide range of examples where the
technique has been applied with considerable success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3473</identifier>
 <datestamp>2009-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3473</id><created>2009-11-18</created><updated>2009-11-29</updated><authors><author><keyname>Ben-Eliezer</keyname><forenames>Ido</forenames></author><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author><author><keyname>Yadin</keyname><forenames>Ariel</forenames></author></authors><title>Polynomial Threshold Functions: Structure, Approximation and
  Pseudorandomness</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational power of polynomial threshold functions, that is,
threshold functions of real polynomials over the boolean cube. We provide two
new results bounding the computational power of this model.
  Our first result shows that low-degree polynomial threshold functions cannot
approximate any function with many influential variables. We provide a couple
of examples where this technique yields tight approximation bounds.
  Our second result relates to constructing pseudorandom generators fooling
low-degree polynomial threshold functions. This problem has received attention
recently, where Diakonikolas et al proved that $k$-wise independence suffices
to fool linear threshold functions. We prove that any low-degree polynomial
threshold function, which can be represented as a function of a small number of
linear threshold functions, can also be fooled by $k$-wise independence. We
view this as an important step towards fooling general polynomial threshold
functions, and we discuss a plausible approach achieving this goal based on our
techniques.
  Our results combine tools from real approximation theory, hyper-contractive
inequalities and probabilistic methods. In particular, we develop several new
tools in approximation theory which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3482</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3482</id><created>2009-11-18</created><updated>2011-07-27</updated><authors><author><keyname>Standish</keyname><forenames>Russell K.</forenames></author></authors><title>Complexity of Networks (reprise)</title><categories>cs.IT math.IT nlin.AO q-bio.PE</categories><comments>Accepted in Complexity</comments><acm-class>G.2.2</acm-class><journal-ref>Complexity, v 17, 50-61, (2012)</journal-ref><doi>10.1002/cplx.20393</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network or graph structures are ubiquitous in the study of complex systems.
Often, we are interested in complexity trends of these system as it evolves
under some dynamic. An example might be looking at the complexity of a food web
as species enter an ecosystem via migration or speciation, and leave via
extinction.
  In a previous paper, a complexity measure of networks was proposed based on
the {\em complexity is information content} paradigm. To apply this paradigm to
any object, one must fix two things: a representation language, in which
strings of symbols from some alphabet describe, or stand for the objects being
considered; and a means of determining when two such descriptions refer to the
same object. With these two things set, the information content of an object
can be computed in principle from the number of equivalent descriptions
describing a particular object.
  The previously proposed representation language had the deficiency that the
fully connected and empty networks were the most complex for a given number of
nodes. A variation of this measure, called zcomplexity, applied a compression
algorithm to the resulting bitstring representation, to solve this problem.
Unfortunately, zcomplexity proved too computationally expensive to be
practical.
  In this paper, I propose a new representation language that encodes the
number of links along with the number of nodes and a representation of the
linklist. This, like zcomplexity, exhibits minimal complexity for fully
connected and empty networks, but is as tractable as the original measure.
  ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3492</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3492</id><created>2009-11-18</created><updated>2010-04-30</updated><authors><author><keyname>Betzler</keyname><forenames>Nadja</forenames></author><author><keyname>Dorn</keyname><forenames>Britta</forenames></author></authors><title>Towards a Dichotomy for the Possible Winner Problem in Elections Based
  on Scoring Rules</title><categories>cs.CC</categories><comments>minor changes and updates; accepted for publication in JCSS, online
  version available.</comments><acm-class>F.2; I.2.11; G.2.1; J.4</acm-class><doi>10.1016/j.jcss.2010.04.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To make a joint decision, agents (or voters) are often required to provide
their preferences as linear orders. To determine a winner, the given linear
orders can be aggregated according to a voting protocol. However, in realistic
settings, the voters may often only provide partial orders. This directly leads
to the Possible Winner problem that asks, given a set of partial votes, whether
a distinguished candidate can still become a winner. In this work, we consider
the computational complexity of Possible Winner for the broad class of voting
protocols defined by scoring rules. A scoring rule provides a score value for
every position which a candidate can have in a linear order. Prominent examples
include plurality, k-approval, and Borda. Generalizing previous NP-hardness
results for some special cases, we settle the computational complexity for all
but one scoring rule. More precisely, for an unbounded number of candidates and
unweighted voters, we show that Possible Winner is NP-complete for all pure
scoring rules except plurality, veto, and the scoring rule defined by the
scoring vector (2,1,...,1,0), while it is solvable in polynomial time for
plurality and veto.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3503</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3503</id><created>2009-11-18</created><updated>2010-08-02</updated><authors><author><keyname>Alonso</keyname><forenames>Mariemi</forenames><affiliation>UCM</affiliation></author><author><keyname>Brachat</keyname><forenames>J&#xe9;rome</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>The Hilbert scheme of points and its link with border basis</title><categories>cs.SC math.AG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give new explicit representations of the Hilbert scheme of
$\mu$ points in $\PP^{r}$ as a projective subvariety of a Grassmanniann
variety. This new explicit description of the Hilbert scheme is simpler than
the previous ones and global. It involves equations of degree $2$. We show how
these equations are deduced from the commutation relations characterizing
border bases. Next, we consider infinitesimal perturbations of an input system
of equations on this Hilbert scheme and describe its tangent space. We propose
an effective criterion to test if it is a flat deformation, that is if the
perturbed system remains on the Hilbert scheme of the initial equations. This
criterion involves in particular formal reduction with respect to border bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3514</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3514</id><created>2009-11-18</created><updated>2009-12-02</updated><authors><author><keyname>Blumensath</keyname><forenames>Thomas</forenames></author></authors><title>Sampling and reconstructing signals from a union of linear subspaces</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we study the problem of sampling and reconstructing signals
which are assumed to lie on or close to one of several subspaces of a Hilbert
space. Importantly, we here consider a very general setting in which we allow
infinitely many subspaces in infinite dimensional Hilbert spaces. This general
approach allows us to unify many results derived recently in areas such as
compressed sensing, affine rank minimisation and analog compressed sensing.
  Our main contribution is to show that a conceptually simple iterative
projection algorithms is able to recover signals from a union of subspaces
whenever the sampling operator satisfies a bi-Lipschitz embedding condition.
Importantly, this result holds for all Hilbert spaces and unions of subspaces,
as long as the sampling procedure satisfies the condition for the set of
subspaces considered. In addition to recent results for finite unions of finite
dimensional subspaces and infinite unions of subspaces in finite dimensional
spaces, we also show that this bi-Lipschitz property can hold in an analog
compressed sensing setting in which we have an infinite union of infinite
dimensional subspaces living in infinite dimensional space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3528</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3528</id><created>2009-11-18</created><authors><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author><author><keyname>Manjunath</keyname><forenames>D.</forenames></author><author><keyname>Chakraborty</keyname><forenames>Supriyo</forenames></author></authors><title>Estimating Network Link Characteristics using Packet-Pair Dispersion: A
  Discrete Time Queueing Theoretic View</title><categories>cs.NI</categories><comments>32 pages, 12 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Packet-dispersion based measurement tools insert pairs of probe packets with
a known separation into the network for transmission over a unicast path or a
multicast tree. Samples of the separation between the probe pairs at the
destination(s) are observed. Heuristic techniques are then used by these tools
to estimate the path characteristics from the observations. In this paper we
present a queueing theoretic setting for packet-dispersion based probing.
Analogous to network tomography, we develop techniques to estimate the
parameters of the arrival process to the individual links from the samples of
the output separations, i.e., from the end-to-end measurements. The links are
modeled as independent discrete time queues with i.i.d. arrivals. We first
obtain an algorithm to obtain the (joint) distribution of the separation
between the probes at the destination(s) for a given distribution of the
spacing at the input. The parameter estimates of the arrival process are
obtained as the minimizer of a cost function between the empirical and
calculated distributions. We also carry out extensive simulations and numerical
experiments to study the performance of the estimation algorithm under the
fairly `harsh' conditions of non stationarity of the arrival process. We find
that the estimations work fairly well for two queues in series and for
multicast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3538</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3538</id><created>2009-11-18</created><authors><author><keyname>Malayeri</keyname><forenames>Amin Daneshmand</forenames></author></authors><title>Noise Speech wavelet analyzing in special time ranges</title><categories>cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech analyzing in special periods of time has been presented in this paper.
One of the most important periods in signal processing is near to Zero. By this
paper, we analyze noise speech signals when these signals are near to Zero. Our
strategy is defining some subfunctions and compress histograms when a noise
speech signal is in a special period. It can be so useful for wavelet signal
processing and spoken systems analyzing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3558</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3558</id><created>2009-11-18</created><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Besselaar</keyname><forenames>Peter van den</forenames></author></authors><title>A Meta-evaluation of Scientific Research Proposals: Different Ways of
  Comparing Rejected to Awarded Applications</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining different data sets with information on grant and fellowship
applications submitted to two renowned funding agencies, we are able to compare
their funding decisions (award and rejection) with scientometric performance
indicators across two fields of science (life sciences and social sciences).
The data sets involve 671 applications in social sciences and 668 applications
in life sciences. In both fields, awarded applicants perform on average better
than all rejected applicants. If only the most preeminent rejected applicants
are considered in both fields, they score better than the awardees on citation
impact. With regard to productivity we find differences between the fields:
While the awardees in life sciences outperform on average the most preeminent
rejected applicants, the situation is reversed in social sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3581</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3581</id><created>2009-11-18</created><authors><author><keyname>De Meo</keyname><forenames>P.</forenames></author><author><keyname>Garro</keyname><forenames>A.</forenames></author><author><keyname>Terracina</keyname><forenames>G.</forenames></author><author><keyname>Ursino</keyname><forenames>D.</forenames></author></authors><title>X-Learn: An XML-Based, Multi-agent System for Supporting &quot;User-Device&quot;
  Adaptive E-learning</title><categories>cs.CY cs.MA</categories><comments>18 pages, 5 figures</comments><journal-ref>Proceedings of the International Conference on Ontologies,
  Databases and Applications of SEmantics (ODBASE 2003), pages 739-756,
  Taormina, Italy, 2003. Lecture Notes in Computer Science, Springer</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present X-Learn, an XML-based, multi-agent system for
supporting &quot;user-device&quot; adaptive e-learning. X-Learn is characterized by the
following features: (i) it is highly subjective, since it handles quite a rich
and detailed user profile that plays a key role during the learning activities;
(ii) it is dynamic and flexible, i.e., it is capable of reacting to variations
of exigencies and objectives; (iii) it is device-adaptive, since it decides the
learning objects to present to the user on the basis of the device she/he is
currently exploiting; (iv) it is generic, i.e., it is capable of operating in a
large variety of learning contexts; (v) it is XML based, since it exploits many
facilities of XML technology for handling and exchanging information connected
to e-learning activities. The paper reports also various experimental results
as well as a comparison between X-Learn and other related e-learning management
systems already presented in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3600</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3600</id><created>2009-11-18</created><authors><author><keyname>De Meo</keyname><forenames>P.</forenames></author><author><keyname>Quattrone</keyname><forenames>G.</forenames></author><author><keyname>Terracina</keyname><forenames>G.</forenames></author><author><keyname>Ursino</keyname><forenames>D.</forenames></author></authors><title>&quot;Almost automatic&quot; and semantic integration of XML Schemas at various
  &quot;severity&quot; levels</title><categories>cs.DB</categories><comments>18 pages, 3 Figures, 3 Tables</comments><journal-ref>Proc. of the International Conference on Cooperative Information
  Systems (CoopIS 2003), pages 4 -21, Taormina, Italy, 2003. Lecture Notes in
  Computer Science, Springer</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach for the integration of a set of XML
Schemas. The proposed approach is specialized for XML, is almost automatic,
semantic and &quot;light&quot;. As a further, original, peculiarity, it is parametric
w.r.t. a &quot;severity&quot; level against which the integration task is performed. The
paper describes the approach in all details, illustrates various theoretical
results, presents the experiments we have performed for testing it and,
finally, compares it with various related approaches already proposed in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3633</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3633</id><created>2009-11-18</created><authors><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Rubinstein</keyname><forenames>J. Hyam</forenames></author></authors><title>A Geometric Approach to Sample Compression</title><categories>cs.LG math.CO math.GT stat.ML</categories><comments>37 pages, 18 figures, submitted to the Journal of Machine Learning
  Research</comments><acm-class>I.2.6; I.5.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sample Compression Conjecture of Littlestone &amp; Warmuth has remained
unsolved for over two decades. This paper presents a systematic geometric
investigation of the compression of finite maximum concept classes. Simple
arrangements of hyperplanes in Hyperbolic space, and Piecewise-Linear
hyperplane arrangements, are shown to represent maximum classes, generalizing
the corresponding Euclidean result. A main result is that PL arrangements can
be swept by a moving hyperplane to unlabeled d-compress any finite maximum
class, forming a peeling scheme as conjectured by Kuzmin &amp; Warmuth. A corollary
is that some d-maximal classes cannot be embedded into any maximum class of VC
dimension d+k, for any constant k. The construction of the PL sweeping involves
Pachner moves on the one-inclusion graph, corresponding to moves of a
hyperplane across the intersection of d other hyperplanes. This extends the
well known Pachner moves for triangulations to cubical complexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3641</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3641</id><created>2009-11-18</created><authors><author><keyname>Goldstone</keyname><forenames>Rob</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Import and Export of Cognitive Science</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Cognitive Science 30(6) (2006), 983-993</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From its inception, a large part of the motivation for Cognitive Science has
been the need for an interdisciplinary journal for the study of minds and
intelligent systems. One threat to the interdisciplinarity of Cognitive
Science, both the field and journal, is that it may become, or already be, too
dominated by psychologists. In 2005, psychology was a keyword for 51% of
submissions, followed distantly by linguistics (17%), artificial intelligence
(13%), neuroscience (10%), computer science (9%), and philosophy (8%). The
Institute for Scientific Information (ISI) gathers data not only on how
individual articles cite one another, but also on macroscopic citation patterns
among journals. Journals or sets of journals can be considered as proxies for
fields. As fields become established, they often create journals. By studying
the patterns of citations among journals that cite and are cited by Cognitive
Science, we can better: 1) appreciate the scholarly ecology surrounding the
journal and the journals role within this ecology, 2) establish competitor and
alternate journals, and 3) determine the natural clustering of fields related
to cognitive science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3643</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3643</id><created>2009-11-18</created><authors><author><keyname>Hellsten</keyname><forenames>Iina</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Wouters</keyname><forenames>Paul</forenames></author></authors><title>Multiple Presents: How Search Engines Re-write the Past</title><categories>cs.IR physics.soc-ph</categories><journal-ref>New Media &amp; Society, 8(6) (2006), 901-924</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet search engines function in a present which changes continuously. The
search engines update their indices regularly, overwriting Web pages with newer
ones, adding new pages to the index, and losing older ones. Some search engines
can be used to search for information at the internet for specific periods of
time. However, these 'date stamps' are not determined by the first occurrence
of the pages in the Web, but by the last date at which a page was updated or a
new page was added, and the search engine's crawler updated this change in the
database. This has major implications for the use of search engines in
scholarly research as well as theoretical implications for the conceptions of
time and temporality. We examine the interplay between the different updating
frequencies by using AltaVista and Google for searches at different moments of
time. Both the retrieval of the results and the structure of the retrieved
information erodes over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3644</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3644</id><created>2009-11-18</created><authors><author><keyname>Bernard</keyname><forenames>Franck Tarpin</forenames><affiliation>LIESP</affiliation></author><author><keyname>Marfisi-Schottman</keyname><forenames>Iza</forenames><affiliation>LIESP</affiliation></author><author><keyname>Habieb-Mammar</keyname><forenames>Halima</forenames><affiliation>ICTT</affiliation></author></authors><title>AnAmeter: The First Steps to Evaluating Adaptation</title><categories>cs.HC cs.OH</categories><proxy>ccsd hal-00433300</proxy><journal-ref>Sixth Workshop on User-Centred Design and Evaluation of Adaptive
  Systems, UMAP09 User Modeling, Adaptation, and Personalization, Trento :
  Italy (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the online AnAmeter framework that helps characterize the
different types of adaptations a system features by helping the evaluator fill
in a simple form. The provided information is then processed to obtain a
quantitative evaluation of three parameters called global, semi-global and
local adaptation degrees. By characterizing and quantifying adaptation,
AnAmeter provides the first steps towards the evaluation of the quality of a
system's adaptation. AnAmeter is an open tool available as freeware on the web
and has been applied to a selection of well known systems. To build this
evaluation grid we also collected a number of systems that cover the full range
of adaptation types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3672</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3672</id><created>2009-11-18</created><authors><author><keyname>Cieslinski</keyname><forenames>Jan L.</forenames></author></authors><title>On the exact discretization of the classical harmonic oscillator
  equation</title><categories>math-ph cs.NA math.MP nlin.SI</categories><comments>29 pages</comments><acm-class>G.1.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the exact discretization of the classical harmonic oscillator
equation (including the inhomogeneous case and multidimensional
generalizations) with a special stress on the energy integral. We present and
suggest some numerical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3674</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3674</id><created>2009-11-18</created><authors><author><keyname>Gim&#xe9;nez</keyname><forenames>Omer</forenames></author><author><keyname>Godoy</keyname><forenames>Guillem</forenames></author><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author></authors><title>Deciding Regularity of the Set of Instances of a Set of Terms with
  Regular Constraints is EXPTIME-Complete</title><categories>cs.SC cs.CC cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite-state tree automata are a well studied formalism for representing term
languages. This paper studies the problem of determining the regularity of the
set of instances of a finite set of terms with variables, where each variable
is restricted to instantiations of a regular set given by a tree automaton. The
problem was recently proved decidable, but with an unknown complexity. Here,
the exact complexity of the problem is determined by proving
EXPTIME-completeness. The main contribution is a new, exponential time
algorithm that performs various exponential transformations on the involved
terms and tree automata, and decides regularity by analyzing formulas over
inequality and height predicates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3676</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3676</id><created>2009-11-18</created><authors><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Pipelined Encoding for Deterministic and Noisy Relay Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, 1 table; Presented at the 2009 Workshop on
  Network Coding, Theory, and Applications, EPFL, Lausanne, Switzerland, June
  15-16, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent coding strategies for deterministic and noisy relay networks are
related to the pipelining of block Markov encoding. For deterministic networks,
it is shown that pipelined encoding improves encoding delay, as opposed to
end-to-end delay. For noisy networks, it is observed that decode-and-forward
exhibits good rate scaling when the signal-to-noise ratio (SNR) increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3708</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3708</id><created>2009-11-19</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Manipulability of Single Transferable Vote</title><categories>cs.AI cs.CC cs.GT cs.MA</categories><comments>Proceedings of the CARE'09 International Workshop on Collaborative
  Agents -- REsearch and Development, Melbourne 2009</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many voting rules, it is NP-hard to compute a successful manipulation.
However, NP-hardness only bounds the worst-case complexity. Recent theoretical
results suggest that manipulation may often be easy in practice. We study
empirically the cost of manipulating the single transferable vote (STV) rule.
This was one of the first rules shown to be NP-hard to manipulate. It also
appears to be one of the harder rules to manipulate since it involves multiple
rounds and since, unlike many other rules, it is NP-hard for a single agent to
manipulate without weights on the votes or uncertainty about how the other
agents have voted. In almost every election in our experiments, it was easy to
compute how a single agent could manipulate the election or to prove that
manipulation by a single agent was impossible. It remains an interesting open
question if manipulation by a coalition of agents is hard to compute in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3717</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3717</id><created>2009-11-19</created><authors><author><keyname>Dhar</keyname><forenames>V. K.</forenames></author><author><keyname>Tickoo</keyname><forenames>A. K.</forenames></author><author><keyname>Kaul</keyname><forenames>S. K.</forenames></author><author><keyname>Koul</keyname><forenames>R.</forenames></author><author><keyname>Dubey</keyname><forenames>B. P.</forenames></author></authors><title>Artificial Neural Network-based error compensation procedure for
  low-cost encoders</title><categories>cs.NE astro-ph.IM physics.comp-ph</categories><comments>16 pages, 4 figures. Accepted for Publication in Measurement Science
  and Technology (MST)</comments><doi>10.1088/0957-0233/21/1/015112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An Artificial Neural Network-based error compensation method is proposed for
improving the accuracy of resolver-based 16-bit encoders by compensating for
their respective systematic error profiles. The error compensation procedure,
for a particular encoder, involves obtaining its error profile by calibrating
it on a precision rotary table, training the neural network by using a part of
this data and then determining the corrected encoder angle by subtracting the
ANN-predicted error from the measured value of the encoder angle. Since it is
not guaranteed that all the resolvers will have exactly similar error profiles
because of the inherent differences in their construction on a micro scale, the
ANN has been trained on one error profile at a time and the corresponding
weight file is then used only for compensating the systematic error of this
particular encoder. The systematic nature of the error profile for each of the
encoders has also been validated by repeated calibration of the encoders over a
period of time and it was found that the error profiles of a particular encoder
recorded at different epochs show near reproducible behavior. The ANN-based
error compensation procedure has been implemented for 4 encoders by training
the ANN with their respective error profiles and the results indicate that the
accuracy of encoders can be improved by nearly an order of magnitude from
quoted values of ~6 arc-min to ~0.65 arc-min when their corresponding
ANN-generated weight files are used for determining the corrected encoder
angle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3723</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3723</id><created>2009-11-19</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author></authors><title>Applications of the Dynamic Distance Potential Field Method</title><categories>cs.MA</categories><comments>Accepted as contribution to &quot;Traffic and Granular Flow 09&quot;
  proceedings. This is a slightly extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently the dynamic distance potential field (DDPF) was introduced as a
computationally efficient method to make agents in a simulation of pedestrians
move rather on the quickest path than the shortest. It can be considered to be
an estimated-remaining-journey-time-based one-shot dynamic assignment method
for pedestrian route choice on the operational level of dynamics. In this
contribution the method is shortly introduced and the effect of the method on
RiMEA's test case 11 is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3753</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3753</id><created>2009-11-19</created><authors><author><keyname>Hochreiter</keyname><forenames>Ronald</forenames></author><author><keyname>Wozabal</keyname><forenames>David</forenames></author></authors><title>Evolutionary estimation of a Coupled Markov Chain credit risk model</title><categories>cs.NE cs.CE</categories><journal-ref>Studies in Computational Intelligence 293: 31-44. 2010</journal-ref><doi>10.1007/978-3-642-13950-5_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There exists a range of different models for estimating and simulating credit
risk transitions to optimally manage credit risk portfolios and products. In
this chapter we present a Coupled Markov Chain approach to model rating
transitions and thereby default probabilities of companies. As the likelihood
of the model turns out to be a non-convex function of the parameters to be
estimated, we apply heuristics to find the ML estimators. To this extent, we
outline the model and its likelihood function, and present both a Particle
Swarm Optimization algorithm, as well as an Evolutionary Optimization algorithm
to maximize the likelihood function. Numerical results are shown which suggest
a further application of evolutionary optimization techniques for credit risk
management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3784</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3784</id><created>2009-11-19</created><authors><author><keyname>Cordeiro</keyname><forenames>Lucas</forenames></author><author><keyname>Fischer</keyname><forenames>Bernd</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author></authors><title>Continuous Verification of Large Embedded Software using SMT-Based
  Bounded Model Checking</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of software in embedded systems has increased significantly
over the last years so that software verification now plays an important role
in ensuring the overall product quality. In this context, SAT-based bounded
model checking has been successfully applied to discover subtle errors, but for
larger applications, it often suffers from the state space explosion problem.
This paper describes a new approach called continuous verification to detect
design errors as quickly as possible by looking at the Software Configuration
Management (SCM) system and by combining dynamic and static verification to
reduce the state space to be explored. We also give a set of encodings that
provide accurate support for program verification and use different background
theories in order to improve scalability and precision in a completely
automatic way. A case study from the telecommunications domain shows that the
proposed approach improves the error-detection capability and reduces the
overall verification time by up to 50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3786</identifier>
 <datestamp>2012-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3786</id><created>2009-11-19</created><updated>2012-04-24</updated><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Echahed</keyname><forenames>Rachid</forenames><affiliation>LIG</affiliation></author><author><keyname>Prost</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LIG</affiliation></author></authors><title>Graph rewriting with polarized cloning</title><categories>cs.LO</categories><proxy>ccsd hal-00433379</proxy><acm-class>F.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of graph transformation with a particular focus on node
cloning. We propose a new approach to graph rewriting where nodes can be cloned
zero, one or more times. A node can be cloned together with all its incident
edges, with only its outgoing edges, with only its incoming edges or with none
of its incident edges. We thus subsume previous works such as the
sesqui-pushout, the heterogeneous pushout and the adaptive star grammars
approaches. A rewrite rule is defined as a span where the right-hand and
left-hand sides are graphs while the interface is a polarized graph. A
polarized graph is a graph endowed with some annotations on nodes. The way a
node is cloned is indicated by its polarization annotation. We use these
annotations for designing graph transformation with polarized cloning. We show
how a clone of a node can be built according to the different possible
polarizations and define a rewrite step as a final pullback complement followed
by a pushout. This is called the polarized sesqui-pushout approach. We also
provide an algorithmic presentation of the proposed graph transformation with
polarized cloning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3799</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3799</id><created>2009-11-19</created><updated>2011-01-13</updated><authors><author><keyname>Laubner</keyname><forenames>Bastian</forenames></author></authors><title>Capturing Polynomial Time on Interval Graphs</title><categories>cs.LO</categories><comments>17 pages</comments><acm-class>F.2.2; F.4.1; G.2.2</acm-class><journal-ref>Laubner, B.: Capturing polynomial time on interval graphs. In LICS
  2010, pp. 199-208. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a characterization of all polynomial-time computable queries on the
class of interval graphs by sentences of fixed-point logic with counting. More
precisely, it is shown that on the class of unordered interval graphs, any
query is polynomial-time computable if and only if it is definable in
fixed-point logic with counting. This result is one of the first establishing
the capturing of polynomial time on a graph class which is defined by forbidden
induced subgraphs. For this, we define a canonical form of interval graphs
using a type of modular decomposition, which is different from the method of
tree decomposition that is used in most known capturing results for other graph
classes, specifically those defined by forbidden minors. The method might also
be of independent interest for its conceptual simplicity. Furthermore, it is
shown that fixed-point logic with counting is not expressive enough to capture
polynomial time on the classes of chordal graphs or incomparability graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3823</identifier>
 <datestamp>2010-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3823</id><created>2009-11-19</created><authors><author><keyname>Ermann</keyname><forenames>Leonardo</forenames></author><author><keyname>Shepelyansky</keyname><forenames>Dima D. L.</forenames></author></authors><title>Google matrix and Ulam networks of intermittency maps</title><categories>cs.IR cond-mat.dis-nn nlin.AO nlin.CD physics.soc-ph</categories><comments>7 pages, 14 figures, research done at Quantware
  http://www.quantware.ups-tlse.fr/</comments><journal-ref>PhysRev E. 81, 03622 (2010)</journal-ref><doi>10.1103/PhysRevE.81.036221</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the properties of the Google matrix of an Ulam network generated by
intermittency maps. This network is created by the Ulam method which gives a
matrix approximant for the Perron-Frobenius operator of dynamical map. The
spectral properties of eigenvalues and eigenvectors of this matrix are
analyzed. We show that the PageRank of the system is characterized by a power
law decay with the exponent $\beta$ dependent on map parameters and the Google
damping factor $\alpha$. Under certain conditions the PageRank is completely
delocalized so that the Google search in such a situation becomes inefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3836</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3836</id><created>2009-11-19</created><authors><author><keyname>Beggs</keyname><forenames>E. J.</forenames></author><author><keyname>Costa</keyname><forenames>J. F.</forenames></author><author><keyname>Tucker</keyname><forenames>J. V.</forenames></author></authors><title>Limits to measurement in experiments governed by algorithms</title><categories>math.LO cs.CC</categories><comments>32 pages approx</comments><msc-class>03A10; 03D10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We pose the following question: If a physical experiment were to be
completely controlled by an algorithm, what effect would the algorithm have on
the physical measurements made possible by the experiment?
  In a programme to study the nature of computation possible by physical
systems, and by algorithms coupled with physical systems, we have begun to
analyse (i) the algorithmic nature of experimental procedures, and (ii) the
idea of using a physical experiment as an oracle to Turing Machines. To answer
the question, we will extend our theory of experimental oracles in order to use
Turing machines to model the experimental procedures that govern the conduct of
physical experiments. First, we specify an experiment that measures mass via
collisions in Newtonian Dynamics; we examine its properties in preparation for
its use as an oracle. We start to classify the computational power of
polynomial time Turing machines with this experimental oracle using non-uniform
complexity classes. Second, we show that modelling an experimenter and
experimental procedure algorithmically imposes a limit on what can be measured
with equipment. Indeed, the theorems suggest a new form of uncertainty
principle for our knowledge of physical quantities measured in simple physical
experiments. We argue that the results established here are representative of a
huge class of experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3842</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3842</id><created>2009-11-19</created><authors><author><keyname>Correa</keyname><forenames>Debora C.</forenames></author><author><keyname>Saito</keyname><forenames>Jose H.</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da F.</forenames></author></authors><title>Musical Genres: Beating to the Rhythms of Different Drums</title><categories>physics.data-an cs.IR cs.SD physics.soc-ph</categories><comments>35 pages, 13 figures, 13 tables</comments><doi>10.1088/1367-2630/12/5/053030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online music databases have increased signicantly as a consequence of the
rapid growth of the Internet and digital audio, requiring the development of
faster and more efficient tools for music content analysis. Musical genres are
widely used to organize music collections. In this paper, the problem of
automatic music genre classification is addressed by exploring rhythm-based
features obtained from a respective complex network representation. A Markov
model is build in order to analyse the temporal sequence of rhythmic notation
events. Feature analysis is performed by using two multivariate statistical
approaches: principal component analysis(unsupervised) and linear discriminant
analysis (supervised). Similarly, two classifiers are applied in order to
identify the category of rhythms: parametric Bayesian classifier under gaussian
hypothesis (supervised), and agglomerative hierarchical clustering
(unsupervised). Qualitative results obtained by Kappa coefficient and the
obtained clusters corroborated the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3856</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3856</id><created>2009-11-19</created><authors><author><keyname>Liebeherr</keyname><forenames>Jorg</forenames></author><author><keyname>Burchard</keyname><forenames>Almut</forenames></author><author><keyname>Ciucu</keyname><forenames>Florin</forenames></author></authors><title>Delay Bounds for Networks with Heavy-Tailed and Self-Similar Traffic</title><categories>cs.NI cs.PF</categories><comments>29 pages</comments><acm-class>G.3; C.4</acm-class><journal-ref>IEEE Transactions on Information Theory 58 (2), 1010-1024, 2012</journal-ref><doi>10.1109/TIT.2011.2173713</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide upper bounds on the end-to-end backlog and delay in a network with
heavy-tailed and self-similar traffic. The analysis follows a network calculus
approach where traffic is characterized by envelope functions and service is
described by service curves. A key contribution of this paper is the derivation
of a probabilistic sample path bound for heavy-tailed self-similar arrival
processes, which is enabled by a suitable envelope characterization, referred
to as `htss envelope'. We derive a heavy-tailed service curve for an entire
network path when the service at each node on the path is characterized by
heavy-tailed service curves. We obtain backlog and delay bounds for traffic
that is characterized by an htss envelope and receives service given by a
heavy-tailed service curve. The derived performance bounds are non-asymptotic
in that they do not assume a steady-state, large buffer, or many sources
regime. We also explore the scale of growth of delays as a function of the
length of the path. The appendix contains an analysis for self-similar traffic
with a Gaussian tail distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3872</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3872</id><created>2009-11-19</created><authors><author><keyname>Agarwal</keyname><forenames>Mukul</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>Equivalence perspectives in communication, source-channel connections
  and universal source-channel separation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An operational perspective is used to understand the relationship between
source and channel coding. This is based on a direct reduction of one problem
to another that uses random coding (and hence common randomness) but unlike all
prior work, does not involve any functional computations, in particular, no
mutual-information computations. This result is then used to prove a universal
source-channel separation theorem in the rate-distortion context where
universality is in the sense of a compound ``general channel.''
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3921</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3921</id><created>2009-11-19</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>Error Rates of the Maximum-Likelihood Detector for Arbitrary
  Constellations: Convex/Concave Behavior and Applications</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE IT Transactions</comments><journal-ref>IEEE Transactions on Information Theory, v. 56, N. 4, pp.
  1948-1960, Apr. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a recent surge of interest in convex optimization techniques,
convexity/concavity properties of error rates of the maximum likelihood
detector operating in the AWGN channel are studied and extended to
frequency-flat slow-fading channels. Generic conditions are identified under
which the symbol error rate (SER) is convex/concave for arbitrary
multi-dimensional constellations. In particular, the SER is convex in SNR for
any one- and two-dimensional constellation, and also in higher dimensions at
high SNR. Pairwise error probability and bit error rate are shown to be convex
at high SNR, for arbitrary constellations and bit mapping. Universal bounds for
the SER 1st and 2nd derivatives are obtained, which hold for arbitrary
constellations and are tight for some of them. Applications of the results are
discussed, which include optimum power allocation in spatial multiplexing
systems, optimum power/time sharing to decrease or increase (jamming problem)
error rate, an implication for fading channels (&quot;fading is never good in low
dimensions&quot;) and optimization of a unitary-precoded OFDM system. For example,
the error rate bounds of a unitary-precoded OFDM system with QPSK modulation,
which reveal the best and worst precoding, are extended to arbitrary
constellations, which may also include coding. The reported results also apply
to the interference channel under Gaussian approximation, to the bit error rate
when it can be expressed or approximated as a non-negative linear combination
of individual symbol error rates, and to coded systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3944</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3944</id><created>2009-11-19</created><authors><author><keyname>White</keyname><forenames>Christopher M.</forenames></author><author><keyname>Khudanpur</keyname><forenames>Sanjeev P.</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>Likelihood-based semi-supervised model selection with applications to
  speech processing</title><categories>stat.ML cs.CL cs.LG stat.AP</categories><comments>11 pages, 2 figures; submitted for publication</comments><journal-ref>IEEE Journal of Selected Topics in Signal Processing, vol. 4, pp.
  1016-1026, 2010</journal-ref><doi>10.1109/JSTSP.2010.2076050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In conventional supervised pattern recognition tasks, model selection is
typically accomplished by minimizing the classification error rate on a set of
so-called development data, subject to ground-truth labeling by human experts
or some other means. In the context of speech processing systems and other
large-scale practical applications, however, such labeled development data are
typically costly and difficult to obtain. This article proposes an alternative
semi-supervised framework for likelihood-based model selection that leverages
unlabeled data by using trained classifiers representing each model to
automatically generate putative labels. The errors that result from this
automatic labeling are shown to be amenable to results from robust statistics,
which in turn provide for minimax-optimal censored likelihood ratio tests that
recover the nonparametric sign test as a limiting case. This approach is then
validated experimentally using a state-of-the-art automatic speech recognition
system to select between candidate word pronunciations using unlabeled speech
data that only potentially contain instances of the words under test. Results
provide supporting evidence for the utility of this approach, and suggest that
it may also find use in other applications of machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3945</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3945</id><created>2009-11-19</created><authors><author><keyname>Zhang</keyname><forenames>Xiao Ming</forenames></author></authors><title>A Semantic Grid Oriented to E-Tourism</title><categories>cs.DC</categories><comments>12 PAGES, 7 Figures</comments><acm-class>C.2.4</acm-class><journal-ref>Xiao Ming Zhang, A Semantic Grid Oriented to E-Tourism, In:
  CloudCom 2009, LNCS 5931, pp. 485-496, 2009, M.G. Jaatun, G. Zhao, and C.
  Rong (Eds.), Springer-Verlag Berlin Heidelberg 2009</journal-ref><doi>10.1007/978-3-642-10665-1_44</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With increasing complexity of tourism business models and tasks, there is a
clear need of the next generation e-Tourism infrastructure to support flexible
automation, integration, computation, storage, and collaboration. Currently
several enabling technologies such as semantic Web, Web service, agent and grid
computing have been applied in the different e-Tourism applications, however
there is no a unified framework to be able to integrate all of them. So this
paper presents a promising e-Tourism framework based on emerging semantic grid,
in which a number of key design issues are discussed including architecture,
ontologies structure, semantic reconciliation, service and resource discovery,
role based authorization and intelligent agent. The paper finally provides the
implementation of the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3950</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3950</id><created>2009-11-19</created><updated>2015-11-15</updated><authors><author><keyname>Narayanan</keyname><forenames>Hariharan</forenames></author></authors><title>Randomized Interior Point methods for Sampling and Optimization</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Markov chain (Dikin walk) for sampling from a convex body
equipped with a self-concordant barrier, whose mixing time from a &quot;central
point&quot; is strongly polynomial in the description of the convex set. The mixing
time of this chain is invariant under affine transformations of the convex set,
thus eliminating the need for first placing the body in an isotropic position.
This recovers and extends previous results of from polytopes to more general
convex sets. On every convex set of dimension $n$, there exists a
self-concordant barrier whose &quot;complexity&quot; is polynomially bounded.
Consequently, a rapidly mixing Markov chain of the kind we describe can be
defined on any convex set. We use these results to design an algorithm
consisting of a single random walk for optimizing a linear function on a convex
set. We show that this random walk reaches an approximately optimal point in
polynomial time with high probability and that the corresponding objective
values converge with probability 1 to the optimal objective value as the number
of steps tends to infinity. One technical contribution is a family of lower
bounds for the isoperimetric constants of (weighted) Riemannian manifolds on
which, interior point methods perform a kind of steepest descent. Using results
of Barthe \cite{barthe} and Bobkov and Houdr\'e, on the isoperimetry of
products of (weighted) Riemannian manifolds, we obtain sharper upper bounds on
the mixing time of Dikin walk on products of convex sets than the bounds
obtained from a direct application of the Localization Lemma, on which, since
(Lov\'asz and Simonovits), the analyses of all random walks on convex sets have
relied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3961</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3961</id><created>2009-11-19</created><authors><author><keyname>Chenu</keyname><forenames>Olivier</forenames><affiliation>TIMC</affiliation></author><author><keyname>Vuillerme</keyname><forenames>Nicolas</forenames><affiliation>TIMC</affiliation></author><author><keyname>Demongeot</keyname><forenames>Jacques</forenames><affiliation>TIMC</affiliation></author><author><keyname>Payan</keyname><forenames>Yohan</forenames><affiliation>TIMC</affiliation></author></authors><title>A wireless lingual feedback device to reduce overpressures in seated
  posture: a feasibility study</title><categories>physics.med-ph cs.HC</categories><proxy>ccsd hal-00433552</proxy><journal-ref>PLoS ONE 4, 10 (2009) e7550</journal-ref><doi>10.1371/journal.pone.0007550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BACKGROUND: Pressure sores are localized injuries to the skin and underlying
tissues and are mainly resulting from overpressure. Paraplegic peoples are
particularly subjects to pressure sores because of long-time seated postures
and sensory deprivation at the lower limbs. METHODOLOGY/PRINCIPAL FINDINGS:
Here we report outcomes of a feasibility trial involving a biofeedback system
aimed at reducing buttock overpressure whilst an individual is seated. The
system consists of (1) pressure sensors, (2) a laptop coupling sensors and
actuator (3) a wireless Tongue Display Unit (TDU) consisting of a circuit
embedded in a dental retainer with electrodes put in contact with the tongue.
The principle consists in (1) detecting overpressures in people who are seated
over long periods of time, (2) estimating a postural change that could reduce
these overpressures and (3) communicating this change through directional
information transmitted by the TDU. Twenty-four healthy subjects voluntarily
participated in this study. CONCLUSIONS/SIGNIFICANCE: The findings suggest
that, in this trial, subjects were able to use a tongue tactile feedback system
to reduce buttock overpressure while seated. Further evaluation of this system
on paraplegic subjects remains to be done.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3979</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3979</id><created>2009-11-20</created><authors><author><keyname>Gayo-Avello</keyname><forenames>Daniel</forenames></author><author><keyname>Brenes</keyname><forenames>David J.</forenames></author></authors><title>Making the road by searching - A search engine based on Swarm
  Information Foraging</title><categories>cs.IR cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search engines are nowadays one of the most important entry points for
Internet users and a central tool to solve most of their information needs.
Still, there exist a substantial amount of users' searches which obtain
unsatisfactory results. Needless to say, several lines of research aim to
increase the relevancy of the results users retrieve. In this paper the authors
frame this problem within the much broader (and older) one of information
overload. They argue that users' dissatisfaction with search engines is a
currently common manifestation of such a problem, and propose a different angle
from which to tackle with it. As it will be discussed, their approach shares
goals with a current hot research topic (namely, learning to rank for
information retrieval) but, unlike the techniques commonly applied in that
field, their technique cannot be exactly considered machine learning and,
additionally, it can be used to change the search engine's response in
real-time, driven by the users behavior. Their proposal adapts concepts from
Swarm Intelligence (in particular, Ant Algorithms) from an Information Foraging
point of view. It will be shown that the technique is not only feasible, but
also an elegant solution to the stated problem; what's more, it achieves
promising results, both increasing the performance of a major search engine for
informational queries, and substantially reducing the time users require to
answer complex information needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.3992</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.3992</id><created>2009-11-20</created><authors><author><keyname>Anxiao</keyname><affiliation>Andrew</affiliation></author><author><keyname>Jiang</keyname></author><author><keyname>Mateescu</keyname><forenames>Robert</forenames></author><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author></authors><title>Storage Coding for Wear Leveling in Flash Memories</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flash memory is a non-volatile computer memory comprised of blocks of cells,
wherein each cell is implemented as either NAND or NOR floating gate. NAND
flash is currently the most widely used type of flash memory. In a NAND flash
memory, every block of cells consists of numerous pages; rewriting even a
single page requires the whole block to be erased and reprogrammed. Block
erasures determine both the longevity and the efficiency of a flash memory.
Therefore, when data in a NAND flash memory are reorganized, minimizing the
total number of block erasures required to achieve the desired data movement is
an important goal. This leads to the flash data movement problem studied in
this paper. We show that coding can significantly reduce the number of block
erasures required for data movement, and present several optimal or nearly
optimal data-movement algorithms based upon ideas from coding theory and
combinatorics. In particular, we show that the sorting-based (non-coding)
schemes require at least O(nlogn) erasures to move data among n blocks, whereas
coding-based schemes require only O(n) erasures. Furthermore, coding-based
schemes use only one auxiliary block, which is the best possible, and achieve a
good balance between the number of erasures in each of the n+1 blocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4033</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4033</id><created>2009-11-20</created><authors><author><keyname>Mostafa</keyname><forenames>Mahmoud</forenames><affiliation>IRIT</affiliation></author><author><keyname>Kalam</keyname><forenames>Anas Abou El</forenames><affiliation>IRIT</affiliation></author><author><keyname>Fraboul</keyname><forenames>Christian</forenames><affiliation>IRIT</affiliation></author></authors><title>Extending Firewall Session Table to Accelerate NAT, QoS Classification
  and Routing</title><categories>cs.CR cs.NI cs.PF</categories><proxy>ccsd hal-00433854</proxy><journal-ref>19th International Conference on Computer Theory and Applications
  (ICCTA 2009), Alexandria : Egypt (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  security and QoS are the two most precious objectives for network systems to
be attained. Unfortunately, they are in conflict, while QoS tries to minimize
processing delay, strong security protection requires more processing time and
cause packet delay. This article is a step towards resolving this conflict by
extending the firewall session table to accelerate NAT, QoS classification, and
routing processing time while providing the same level of security protection.
Index Terms ? stateful packet filtering; firewall; session/state table; QoS;
NAT; Routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4034</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4034</id><created>2009-11-20</created><updated>2009-12-09</updated><authors><author><keyname>Mostafa</keyname><forenames>Mahmoud</forenames><affiliation>IRIT</affiliation></author><author><keyname>Kalam</keyname><forenames>Anas Abou El</forenames><affiliation>IRIT</affiliation></author><author><keyname>Fraboul</keyname><forenames>Christian</forenames><affiliation>IRIT</affiliation></author></authors><title>Q-ESP: a QoS-compliant Security Protocol to enrich IPSec Framework</title><categories>cs.CR cs.NI cs.PF</categories><proxy>ccsd hal-00433850</proxy><journal-ref>Third IEEE / IFIP International Conference on New Technologies,
  Mobility and Security, Cairo : Egypt (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IPSec is a protocol that allows to make secure connections between branch
offices and allows secure VPN accesses. However, the efforts to improve IPSec
are still under way; one aspect of this improvement is to take Quality of
Service (QoS) requirements into account. QoS is the ability of the network to
provide a service at an assured service level while optimizing the global usage
of network resources. The QoS level that a flow receives depends on a six-bit
identifier in the IP header; the so-called Differentiated Services code point
(DSCP). Basically, Multi-Field classifiers classify a packet by inspecting
IP/TCP headers, to decide how the packet should be processed. The current IPSec
standard does hardly offer any guidance to do this, because the existing IPSec
ESP security protocol hides much of this information in its encrypted payloads,
preventing network control devices such as routers and switches from utilizing
this information in performing classification appropriately. To solve this
problem, we propose a QoS-friendly Encapsulated Security Payload (Q-ESP) as a
new IPSec security protocol that provides both security and QoS supports. We
also present our NetBSD kernel-based implementation as well as our evaluation
results of Q-ESP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4040</identifier>
 <datestamp>2009-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4040</id><created>2009-11-20</created><updated>2009-12-19</updated><authors><author><keyname>Maurice</keyname><forenames>Margenstern</forenames></author></authors><title>About a new splitting for the algorithmic study of the tilings $\{p,q\}$
  of the hyperbolic plane when $q$ is odd</title><categories>cs.CG</categories><comments>20 pages, 19 figures This version significantly improves version 1 of
  the paper, by answering questions remained open in the previous version and
  by bringing in a new solution to a case raised by the new study</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we remind previous results about the tilings $\{p,q\}$ of the
hyperbolic plane. We introduce two new ways to split the hyperbolic plane in
order to algorithmically construct the tilings $\{p,q\}$ when $q$ is odd.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4046</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4046</id><created>2009-11-20</created><updated>2011-01-02</updated><authors><author><keyname>Tomioka</keyname><forenames>Ryota</forenames></author><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author></authors><title>Super-Linear Convergence of Dual Augmented-Lagrangian Algorithm for
  Sparsity Regularized Estimation</title><categories>stat.ML cs.LG stat.ME</categories><comments>51 pages, 9 figures</comments><journal-ref>Journal of Machine Learning Research, 12(May):1537-1586, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the convergence behaviour of a recently proposed algorithm for
regularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is
based on a new interpretation of DAL as a proximal minimization algorithm. We
theoretically show under some conditions that DAL converges super-linearly in a
non-asymptotic and global sense. Due to a special modelling of sparse
estimation problems in the context of machine learning, the assumptions we make
are milder and more natural than those made in conventional analysis of
augmented Lagrangian algorithms. In addition, the new interpretation enables us
to generalize DAL to wide varieties of sparse estimation problems. We
experimentally confirm our analysis in a large scale $\ell_1$-regularized
logistic regression problem and extensively compare the efficiency of DAL
algorithm to previously proposed algorithms on both synthetic and benchmark
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4047</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4047</id><created>2009-11-20</created><authors><author><keyname>Puebla</keyname><forenames>G.</forenames></author><author><keyname>Albert</keyname><forenames>E.</forenames></author><author><keyname>Hermenegildo</keyname><forenames>M.</forenames></author></authors><title>Efficient Local Unfolding with Ancestor Stacks</title><categories>cs.PL cs.PF</categories><comments>Number of pages: 32 Number of figures: 7 Number of Tables: 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most successful unfolding rules used nowadays in the partial evaluation
of logic programs are based on well quasi orders (wqo) applied over (covering)
ancestors, i.e., a subsequence of the atoms selected during a derivation.
Ancestor (sub)sequences are used to increase the specialization power of
unfolding while still guaranteeing termination and also to reduce the number of
atoms for which the wqo has to be checked. Unfortunately, maintaining the
structure of the ancestor relation during unfolding introduces significant
overhead. We propose an efficient, practical local unfolding rule based on the
notion of covering ancestors which can be used in combination with a wqo and
allows a stack-based implementation without losing any opportunities for
specialization. Using our technique, certain non-leftmost unfoldings are
allowed as long as local unfolding is performed, i.e., we cover depth-first
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4051</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4051</id><created>2009-11-20</created><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>Dowek</keyname><forenames>Gilles</forenames></author></authors><title>A computational definition of the notion of vectorial space</title><categories>cs.LO cs.PL cs.SC</categories><comments>14 pages, latex</comments><journal-ref>Proc. of 5th International Workshop on Rewriting Logic and its
  Applications 2004 (WRLA) and ENTCS 117, 249-261, (2005).</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We usually define an algebraic structure by a set, some operations defined on
this set and some propositions that the algebraic structure must validate. In
some cases, we can replace these propositions by an algorithm on terms
constructed upon these operations that the algebraic structure must validate.
We show in this note that this is the case for the notions of vectorial space
and bilinear operation. KEYWORDS: Rewrite system, vector space, bilinear
operation, tensorial product, semantics, quantum programming languages,
probabilistic programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4146</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4146</id><created>2009-11-20</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Hilscher</keyname><forenames>Evan</forenames></author></authors><title>On convexification of polygons by pops</title><categories>cs.CG</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a polygon $P$ in the plane, a {\em pop} operation is the reflection of
a vertex with respect to the line through its adjacent vertices. We define a
family of alternating polygons, and show that any polygon from this family
cannot be convexified by pop operations. This family contains simple, as well
as non-simple (i.e., self-intersecting) polygons, as desired. We thereby answer
in the negative an open problem posed by Demaine and O'Rourke \cite[Open
Problem 5.3]{DO07}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4150</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4150</id><created>2009-11-20</created><authors><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author></authors><title>The Impact of Exponential Utility Costs in Bottleneck Routing Games</title><categories>cs.GT</categories><comments>AMS Latex 10 pages 2 Figures</comments><report-no>Louisiana State University Tech report LSU-CSC-09-01</report-no><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study bottleneck routing games where the social cost is determined by the
worst congestion on any edge in the network. Bottleneck games have been studied
in the literature by having the player's utility costs to be determined by the
worst congested edge in their paths. However, the Nash equilibria of such games
are inefficient since the price of anarchy can be very high with respect to the
parameters of the game. In order to obtain smaller price of anarchy we explore
{\em exponential bottleneck games} where the utility costs of the players are
exponential functions on the congestion of the edges in their paths. We find
that exponential bottleneck games are very efficient giving a poly-log bound on
the price of anarchy: O(log L log |E|), where L is the largest path length in
the players strategy sets and E is the set of edges in the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4167</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4167</id><created>2009-11-21</created><authors><author><keyname>Nayak</keyname><forenames>Jayanth</forenames></author><author><keyname>Tuncel</keyname><forenames>Ertem</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author></authors><title>Wyner-Ziv Coding over Broadcast Channels: Digital Schemes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses lossy transmission of a common source over a broadcast
channel when there is correlated side information at the receivers, with
emphasis on the quadratic Gaussian and binary Hamming cases. A digital scheme
that combines ideas from the lossless version of the problem, i.e.,
Slepian-Wolf coding over broadcast channels, and dirty paper coding, is
presented and analyzed. This scheme uses layered coding where the common layer
information is intended for both receivers and the refinement information is
destined only for one receiver. For the quadratic Gaussian case, a quantity
characterizing the overall quality of each receiver is identified in terms of
channel and side information parameters. It is shown that it is more
advantageous to send the refinement information to the receiver with &quot;better&quot;
overall quality. In the case where all receivers have the same overall quality,
the presented scheme becomes optimal. Unlike its lossless counterpart, however,
the problem eludes a complete characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4178</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4178</id><created>2009-11-21</created><authors><author><keyname>Harvey</keyname><forenames>Morgan</forenames></author><author><keyname>Baillie</keyname><forenames>Mark</forenames></author><author><keyname>Ruthven</keyname><forenames>Ian</forenames></author><author><keyname>Elsweiler</keyname><forenames>David</forenames></author></authors><title>Folksonomic Tag Clouds as an Aid to Content Indexing</title><categories>cs.IR cs.HC</categories><comments>SIGIR 2009 Workshop on Search in Social Media (SSM 2009)</comments><acm-class>H.5; H.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social tagging systems have recently developed as a popular method of data
organisation on the Internet. These systems allow users to organise their
content in a way that makes sense to them, rather than forcing them to use a
pre-determined and rigid set of categorisations. These folksonomies provide
well populated sources of unstructured tags describing web resources which
could potentially be used as semantic index terms for these resources. However
getting people to agree on what tags best describe a resource is a difficult
problem, therefore any feature which increases the consistency and stability of
terms chosen would be extremely beneficial. We investigate how the provision of
a tag cloud, a weighted list of terms commonly used to assist in browsing a
folksonomy, during the tagging process itself influences the tags produced and
how difficult the user perceived the task to be. We show that illustrating the
most popular tags to users assists in the tagging process and encourages a
stable and consistent folksonomy to form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4191</identifier>
 <datestamp>2010-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4191</id><created>2009-11-21</created><updated>2009-12-03</updated><authors><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>Theory and Applications of N-Fold Integer Programming</title><categories>math.OC cs.DM cs.DS math.CO</categories><comments>IMA Volume on Mixed Integer Nonlinear Programming, Frontier Series,
  Springer, to appear</comments><msc-class>05A, 15A, 51M, 52A, 52B, 52C, 62H, 68Q, 68R, 68U, 68W, 90B, 90C</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We overview our recently introduced theory of n-fold integer programming
which enables the polynomial time solution of fundamental linear and nonlinear
integer programming problems in variable dimension. We demonstrate its power by
obtaining the first polynomial time algorithms in several application areas
including multicommodity flows and privacy in statistical databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4202</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4202</id><created>2009-11-21</created><authors><author><keyname>Kolosovskiy</keyname><forenames>Maxim A.</forenames><affiliation>Altai State Technical University, Russia</affiliation></author><author><keyname>Kryuchkova</keyname><forenames>Elena N.</forenames><affiliation>Altai State Technical University, Russia</affiliation></author></authors><title>Network congestion control using NetFlow</title><categories>cs.NI</categories><comments>10 pages</comments><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of congestion control is to avoid congestion in network elements. A
network element is congested if it is being offered more traffic than it can
process. To detect such situations and to neutralize them we should monitor
traffic in the network. In this paper, we propose using Cisco's NetFlow
technology, which allows collecting statistics about traffic in the network by
generating special NetFlow packets. Cisco's routers can send NetFlow packets to
a special node, so we can collect these packets, analyze its content and detect
network congestion. We use Cisco's feature as example, some other vendors
(Juniper, 3COM, Alcatel, etc.) provide similar features for their routers. We
also consider a simple system, which collects statistical information about
network elements, determines overloaded elements and identifies flows, which
congest them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4203</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4203</id><created>2009-11-21</created><authors><author><keyname>Boespflug</keyname><forenames>Mathieu</forenames><affiliation>LIX</affiliation></author></authors><title>From Self-Interpreters to Normalization by Evaluation</title><categories>cs.PL cs.LO</categories><proxy>ccsd inria-00434284</proxy><journal-ref>2009 Workshop on Normalization by Evaluation, Los Angeles :
  \'Etats-Unis d'Am\'erique (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize normalization by evaluation as the composition of a
self-interpreter with a self-reducer using a special representation scheme, in
the sense of Mogensen (1992). We do so by deriving in a systematic way an
untyped normalization by evaluation algorithm from a standard interpreter for
the ?-calculus. The derived algorithm is not novel and indeed other published
algorithms may be obtained in the same manner through appropriate adaptations
to the representation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4207</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4207</id><created>2009-11-21</created><authors><author><keyname>Calsaverini</keyname><forenames>Rafael S.</forenames></author><author><keyname>Vicente</keyname><forenames>Renato</forenames></author></authors><title>An information theoretic approach to statistical dependence: copula
  information</title><categories>q-fin.ST cs.IT math.IT physics.data-an stat.AP</categories><comments>to appear in Europhysics Letters</comments><journal-ref>Europ. Phys. Lett. 88 68003 (2009)</journal-ref><doi>10.1209/0295-5075/88/68003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the connection between information and copula theories by showing
that a copula can be employed to decompose the information content of a
multivariate distribution into marginal and dependence components, with the
latter quantified by the mutual information. We define the information excess
as a measure of deviation from a maximum entropy distribution. The idea of
marginal invariant dependence measures is also discussed and used to show that
empirical linear correlation underestimates the amplitude of the actual
correlation in the case of non-Gaussian marginals. The mutual information is
shown to provide an upper bound for the asymptotic empirical log-likelihood of
a copula. An analytical expression for the information excess of T-copulas is
provided, allowing for simple model identification within this family. We
illustrate the framework in a financial data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4219</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4219</id><created>2009-11-21</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Message Passing Algorithms for Compressed Sensing: I. Motivation and
  Construction</title><categories>cs.IT math.IT</categories><comments>5 pages, IEEE Information Theory Workshop, Cairo 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, the authors proposed a new class of low-complexity
iterative thresholding algorithms for reconstructing sparse signals from a
small set of linear measurements \cite{DMM}. The new algorithms are broadly
referred to as AMP, for approximate message passing. This is the first of two
conference papers describing the derivation of these algorithms, connection
with the related literature, extensions of the original framework, and new
empirical evidence.
  In particular, the present paper outlines the derivation of AMP from standard
sum-product belief propagation, and its extension in several directions. We
also discuss relations with formal calculations based on statistical mechanics
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4222</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4222</id><created>2009-11-21</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Message Passing Algorithms for Compressed Sensing: II. Analysis and
  Validation</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 pdf figures, IEEE Information Theory Workshop, Cairo 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, the authors proposed a new class of low-complexity
iterative thresholding algorithms for reconstructing sparse signals from a
small set of linear measurements \cite{DMM}. The new algorithms are broadly
referred to as AMP, for approximate message passing. This is the second of two
conference papers describing the derivation of these algorithms, connection
with related literature, extensions of original framework, and new empirical
evidence.
  This paper describes the state evolution formalism for analyzing these
algorithms, and some of the conclusions that can be drawn from this formalism.
We carried out extensive numerical simulations to confirm these predictions. We
present here a few representative results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4223</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4223</id><created>2009-11-21</created><updated>2009-12-11</updated><authors><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>Collaboration in sensor network research: an in-depth longitudinal
  analysis of assortative mixing patterns</title><categories>physics.data-an cs.DL physics.soc-ph</categories><comments>Scientometrics (In press)</comments><journal-ref>Scientometrics. Volume 84, Number 3. 2010</journal-ref><doi>10.1007/s11192-009-0147-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many investigations of scientific collaboration are based on statistical
analyses of large networks constructed from bibliographic repositories. These
investigations often rely on a wealth of bibliographic data, but very little or
no other information about the individuals in the network, and thus, fail to
illustrate the broader social and academic landscape in which collaboration
takes place. In this article, we perform an in-depth longitudinal analysis of a
relatively small network of scientific collaboration (N = 291) constructed from
the bibliographic record of a research center involved in the development and
application of sensor network and wireless technologies. We perform a
preliminary analysis of selected structural properties of the network,
computing its range, configuration and topology. We then support our
preliminary statistical analysis with an in-depth temporal investigation of the
assortative mixing of selected node characteristics, unveiling the researchers'
propensity to collaborate preferentially with others with a similar academic
profile. Our qualitative analysis of mixing patterns offers clues as to the
nature of the scientific community being modeled in relation to its
organizational, disciplinary, institutional, and international arrangements of
collaboration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4230</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4230</id><created>2009-11-21</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author></authors><title>Introduction to Bioinformatics</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bioinformatics is a new discipline that addresses the need to manage and
interpret the data that in the past decade was massively generated by genomic
research. This discipline represents the convergence of genomics, biotechnology
and information technology, and encompasses analysis and interpretation of
data, modeling of biological phenomena, and development of algorithms and
statistics. This article presents an introduction to bioinformatics
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4238</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4238</id><created>2009-11-22</created><updated>2009-12-16</updated><authors><author><keyname>Yu</keyname><forenames>Chia-Mu</forenames></author><author><keyname>Lu</keyname><forenames>Chun-Shien</forenames></author><author><keyname>Kuo</keyname><forenames>Sy-Yen</forenames></author></authors><title>Secure Multidimensional Queries in Tiered Sensor Networks</title><categories>cs.NI cs.CR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, aiming at securing range query, top-k query, and skyline query
in tiered sensor networks, we propose the Secure Range Query (SRQ), Secure
Top-$k$ Query (STQ), and Secure Skyline Query (SSQ) schemes, respectively. In
particular, SRQ, by using our proposed \emph{prime aggregation} technique, has
the lowest communication overhead among prior works, while STQ and SSQ, to our
knowledge, are the first proposals in tiered sensor networks for securing
top-$k$ and skyline queries, respectively. Moreover, the relatively unexplored
issue of the security impact of sensor node compromises on multidimensional
queries is studied; two attacks incurred from the sensor node compromises,
\emph{collusion attack} and \emph{false-incrimination attack}, are investigated
in this paper. After developing a novel technique called \emph{subtree
sampling}, we also explore methods of efficiently mitigating the threat of
sensor node compromises. Performance analyses regarding the probability for
detecting incomplete query-results and communication cost of the proposed
schemes are also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4239</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4239</id><created>2009-11-22</created><authors><author><keyname>Yu</keyname><forenames>Chia-Mu</forenames></author><author><keyname>Lu</keyname><forenames>Chun-Shien</forenames></author><author><keyname>Kuo</keyname><forenames>Sy-Yen</forenames></author></authors><title>Constrained Function Based En-Route Filtering for Sensor Networks</title><categories>cs.NI cs.CR cs.DS</categories><comments>26 pages, single column, extension from a preliminary version
  appeared in IEEE WCNC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor networks are vulnerable to \emph{false data injection attack} and
\emph{path-based DoS} (PDoS) attack. While conventional authentication schemes
are insufficient for solving these security conflicts, an \emph{en-route
filtering} scheme acts as a defense against these two attacks. To construct an
efficient en-route filtering scheme, this paper first presents a Constrained
Function based message Authentication (CFA) scheme, which can be thought of as
a hash function directly supporting the en-route filtering functionality.
Together with the \emph{redundancy property} of sensor networks, which means
that an event can be simultaneously observed by multiple sensor nodes, the
devised CFA scheme is used to construct a CFA-based en-route filtering (CFAEF)
scheme. In contrast to most of the existing methods, which rely on complicated
security associations among sensor nodes, our design, which directly exploits
an en-route filtering hash function, appears to be novel. We examine the CFA
and CFAEF schemes from both the theoretical and numerical aspects to
demonstrate their efficiency and effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4262</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4262</id><created>2009-11-22</created><authors><author><keyname>Marfisi-Schottman</keyname><forenames>Iza</forenames><affiliation>LIESP</affiliation></author><author><keyname>Sghaier</keyname><forenames>Aymen</forenames><affiliation>LIESP</affiliation></author><author><keyname>George</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIESP</affiliation></author><author><keyname>Tarpin-Bernard</keyname><forenames>Franck</forenames><affiliation>LIESP</affiliation></author><author><keyname>Pr&#xe9;v&#xf4;t</keyname><forenames>Patrick</forenames><affiliation>LIESP</affiliation></author></authors><title>Towards Industrialized Conception and Production of Serious Games</title><categories>cs.LG cs.HC</categories><proxy>ccsd hal-00433350</proxy><journal-ref>ICTE INTERNATIONAL CONFERENCE ON TECHNOLOGY AND EDUCATION, Paris :
  France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Serious Games (SGs) have experienced a tremendous outburst these last years.
Video game companies have been producing fun, user-friendly SGs, but their
educational value has yet to be proven. Meanwhile, cognition research scientist
have been developing SGs in such a way as to guarantee an educational gain, but
the fun and attractive characteristics featured often would not meet the
public's expectations. The ideal SG must combine these two aspects while still
being economically viable. In this article, we propose a production chain model
to efficiently conceive and produce SGs that are certified for their
educational gain and fun qualities. Each step of this chain will be described
along with the human actors, the tools and the documents that intervene.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4288</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4288</id><created>2009-11-22</created><authors><author><keyname>Kim</keyname><forenames>Kyoung-Dae</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>The Importance, Design and Implementation of a Middleware for Networked
  Control Systems</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the advancement of computing and communication technology, networked
control systems may soon become prevalent in many control applications. While
the capability of employing the communication network in the control loop
certainly provides many benefits, it also raises several challenges which need
to be overcome to utilize the benefits.
  In this chapter, we focus on one major challenge: a middleware framework that
enables a networked control system to be implemented. Indeed our thesis is that
a middleware for networked control sys important for the future of networked
control systems.
  We discuss the fundamental issues which need to be considered in the design
and development of an appropriate middleware for networked control systems. We
describe \emph{Etherware}, a middleware for networked control system which has
been developed at the University of Illinois, as an example of such a
middleware framework, to illustrate how these issues can be addressed in the
design of a middleware. Using a networked inverted pendulum control system as
an example, we demonstrate the powerful capabilities provided by Etherware for
a networked control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4292</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4292</id><created>2009-11-22</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Similarity Measures, Author Cocitation Analysis, and Information Theory</title><categories>cs.IR physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science &amp;
  Technology, 56(7), 2005, 769-772</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of Pearson's correlation coefficient in Author Cocitation Analysis
was compared with Salton's cosine measure in a number of recent contributions.
Unlike the Pearson correlation, the cosine is insensitive to the number of
zeros. However, one has the option of applying a logarithmic transformation in
correlation analysis. Information calculus is based on both the logarithmic
transformation and provides a non-parametric statistics. Using this methodology
one can cluster a document set in a precise way and express the differences in
terms of bits of information. The algorithm is explained and used on the data
set which was made the subject of this discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4302</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4302</id><created>2009-11-22</created><authors><author><keyname>Lucio-Arias</keyname><forenames>Diana</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>An Indicator of Research Front Activity: Measuring Intellectual
  Organization as Uncertainty Reduction in Document Sets</title><categories>cs.DL cs.IR physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science &amp;
  Technology 60(12) (2009) 2488-2498</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When using scientific literature to model scholarly discourse, a research
specialty can be operationalized as an evolving set of related documents. Each
publication can be expected to contribute to the further development of the
specialty at the research front. The specific combinations of title words and
cited references in a paper can then be considered as a signature of the
knowledge claim in the paper: new words and combinations of words can be
expected to represent variation, while each paper is at the same time
selectively positioned into the intellectual organization of a field using
context-relevant references. Can the mutual information among these three
dimensions--title words, cited references, and sequence numbers--be used as an
indicator of the extent to which intellectual organization structures the
uncertainty prevailing at a research front? The effect of the discovery of
nanotubes (1991) on the previously existing field of fullerenes is used as a
test case. Thereafter, this method is applied to science studies with a focus
on scientometrics using various sample delineations. An emerging research front
about citation analysis can be indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4313</identifier>
 <datestamp>2009-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4313</id><created>2009-11-22</created><authors><author><keyname>Garcia-Alfaro</keyname><forenames>Joaquin</forenames></author><author><keyname>Barbeau</keyname><forenames>Michel</forenames></author><author><keyname>Kranakis</keyname><forenames>Evangelos</forenames></author></authors><title>Evaluation of Anonymized ONS Queries</title><categories>cs.CR cs.NI</categories><comments>14 pages</comments><journal-ref>Proc. 2008 Security of Autonomous and Spontaneous Networks,
  Editions Publibook Universite, pages 47-60, Loctudy, Brittany, France,
  October, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic Product Code (EPC) is the basis of a pervasive infrastructure for
the automatic identification of objects on supply chain applications (e.g.,
pharmaceutical or military applications). This infrastructure relies on the use
of the (1) Radio Frequency Identification (RFID) technology to tag objects in
motion and (2) distributed services providing information about objects via the
Internet. A lookup service, called the Object Name Service (ONS) and based on
the use of the Domain Name System (DNS), can be publicly accessed by EPC
applications looking for information associated with tagged objects. Privacy
issues may affect corporate infrastructures based on EPC technologies if their
lookup service is not properly protected. A possible solution to mitigate these
issues is the use of online anonymity. We present an evaluation experiment that
compares the of use of Tor (The second generation Onion Router) on a global
ONS/DNS setup, with respect to benefits, limitations, and latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4322</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4322</id><created>2009-11-22</created><authors><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author><author><keyname>Ahmadizadeh</keyname><forenames>Kiyan</forenames></author></authors><title>Markovian Network Interdiction and the Four Color Theorem</title><categories>cs.DM cs.CC</categories><comments>7 pages, 2 figures</comments><report-no>LA-UR-09-07611</report-no><acm-class>E.1; F.2; G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Unreactive Markovian Evader Interdiction Problem (UME) asks to optimally
place sensors on a network to detect Markovian motion by one or more &quot;evaders&quot;.
It was previously proved that finding the optimal sensor placement is NP-hard
if the number of evaders is unbounded. Here we show that the problem is NP-hard
with just 2 evaders using a connection to coloring of planar graphs. The
results suggest that approximation algorithms are needed even in applications
where the number of evaders is small. It remains an open problem to determine
the complexity of the 1-evader case or to devise efficient algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4329</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4329</id><created>2009-11-23</created><updated>2009-11-23</updated><authors><author><keyname>Lee</keyname><forenames>Ki-Hoon</forenames></author><author><keyname>Whang</keyname><forenames>Kyu-Young</forenames></author><author><keyname>Han</keyname><forenames>Wook-Shin</forenames></author><author><keyname>Kim</keyname><forenames>Min-Soo</forenames></author></authors><title>Structural Consistency: Enabling XML Keyword Search to Eliminate
  Spurious Results Consistently</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML keyword search is a user-friendly way to query XML data using only
keywords. In XML keyword search, to achieve high precision without sacrificing
recall, it is important to remove spurious results not intended by the user.
Efforts to eliminate spurious results have enjoyed some success by using the
concepts of LCA or its variants, SLCA and MLCA. However, existing methods still
could find many spurious results. The fundamental cause for the occurrence of
spurious results is that the existing methods try to eliminate spurious results
locally without global examination of all the query results and, accordingly,
some spurious results are not consistently eliminated. In this paper, we
propose a novel keyword search method that removes spurious results
consistently by exploiting the new concept of structural consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4332</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4332</id><created>2009-11-23</created><updated>2010-02-26</updated><authors><author><keyname>Sankararaman</keyname><forenames>Swaminathan</forenames></author><author><keyname>Efrat</keyname><forenames>Alon</forenames></author><author><keyname>Ramasubramanian</keyname><forenames>Srinivasan</forenames></author><author><keyname>Taheri</keyname><forenames>Javad</forenames></author></authors><title>Scheduling Sensors for Guaranteed Sparse Coverage</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor networks are particularly applicable to the tracking of objects in
motion. For such applications, it may not necessary that the whole region be
covered by sensors as long as the uncovered region is not too large. This
notion has been formalized by Balasubramanian et.al. as the problem of
$\kappa$-weak coverage. This model of coverage provides guarantees about the
regions in which the objects may move undetected. In this paper, we analyse the
theoretical aspects of the problem and provide guarantees about the lifetime
achievable. We introduce a number of practical algorithms and analyse their
significance. The main contribution is a novel linear programming based
algorithm which provides near-optimal lifetime. Through extensive
experimentation, we analyse the performance of these algorithms based on
several parameters defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4337</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4337</id><created>2009-11-23</created><authors><author><keyname>Arvind</keyname><forenames>Vikraman</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>Circuit Lower Bounds, Help Functions, and the Remote Point Problem</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the power of Algebraic Branching Programs (ABPs) augmented
with help polynomials, and constant-depth Boolean circuits augmented with help
functions. We relate the problem of proving explicit lower bounds in both these
models to the Remote Point Problem (introduced by Alon, Panigrahy, and Yekhanin
(RANDOM '09)). More precisely, proving lower bounds for ABPs with help
polynomials is related to the Remote Point Problem w.r.t. the rank metric, and
for constant-depth circuits with help functions it is related to the Remote
Point Problem w.r.t. the Hamming metric. For algebraic branching programs with
help polynomials with some degree restrictions we show exponential size lower
bounds for explicit polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4351</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4351</id><created>2009-11-23</created><updated>2010-06-20</updated><authors><author><keyname>Ben-Shimon</keyname><forenames>Sonny</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author></authors><title>Local resilience and Hamiltonicity Maker-Breaker games in random-regular
  graphs</title><categories>math.CO cs.DM math.PR</categories><comments>34 pages. 1 figure</comments><journal-ref>Combinatorics, Probability, and Computing, 20(2):173--211, 2011</journal-ref><doi>10.1017/S0963548310000453</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an increasing monotone graph property $\mP$ the \emph{local resilience}
of a graph $G$ with respect to $\mP$ is the minimal $r$ for which there exists
of a subgraph $H\subseteq G$ with all degrees at most $r$ such that the removal
of the edges of $H$ from $G$ creates a graph that does not possesses $\mP$.
This notion, which was implicitly studied for some ad-hoc properties, was
recently treated in a more systematic way in a paper by Sudakov and Vu. Most
research conducted with respect to this distance notion focused on the Binomial
random graph model $\GNP$ and some families of pseudo-random graphs with
respect to several graph properties such as containing a perfect matching and
being Hamiltonian, to name a few. In this paper we continue to explore the
local resilience notion, but turn our attention to random and pseudo-random
\emph{regular} graphs of constant degree. We investigate the local resilience
of the typical random $d$-regular graph with respect to edge and vertex
connectivity, containing a perfect matching, and being Hamiltonian. In
particular we prove that for every positive $\epsilon$ and large enough values
of $d$ with high probability the local resilience of the random $d$-regular
graph, $\GND$, with respect to being Hamiltonian is at least $(1-\epsilon)d/6$.
We also prove that for the Binomial random graph model $\GNP$, for every
positive $\epsilon&gt;0$ and large enough values of $K$, if $p&gt;\frac{K\ln n}{n}$
then with high probability the local resilience of $\GNP$ with respect to being
Hamiltonian is at least $(1-\epsilon)np/6$. Finally, we apply similar
techniques to Positional Games and prove that if $d$ is large enough then with
high probability a typical random $d$-regular graph $G$ is such that in the
unbiased Maker-Breaker game played on the edges of $G$, Maker has a winning
strategy to create a Hamilton cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4357</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4357</id><created>2009-11-23</created><authors><author><keyname>Shah</keyname><forenames>Virag</forenames></author><author><keyname>Mehta</keyname><forenames>Neelesh B.</forenames></author><author><keyname>Yim</keyname><forenames>Raymond</forenames></author></authors><title>Splitting Algorithms for Fast Relay Selection: Generalizations,
  Analysis, and a Unified View</title><categories>cs.NI</categories><comments>20 pages, 7 figures, 1 table, Accepted for publication in IEEE
  Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relay selection for cooperative communications promises significant
performance improvements, and is, therefore, attracting considerable attention.
While several criteria have been proposed for selecting one or more relays,
distributed mechanisms that perform the selection have received relatively less
attention. In this paper, we develop a novel, yet simple, asymptotic analysis
of a splitting-based multiple access selection algorithm to find the single
best relay. The analysis leads to simpler and alternate expressions for the
average number of slots required to find the best user. By introducing a new
`contention load' parameter, the analysis shows that the parameter settings
used in the existing literature can be improved upon. New and simple bounds are
also derived. Furthermore, we propose a new algorithm that addresses the
general problem of selecting the best $Q \ge 1$ relays, and analyze and
optimize it. Even for a large number of relays, the algorithm selects the best
two relays within 4.406 slots and the best three within 6.491 slots, on
average. We also propose a new and simple scheme for the practically relevant
case of discrete metrics. Altogether, our results develop a unifying
perspective about the general problem of distributed selection in cooperative
systems and several other multi-node systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4366</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4366</id><created>2009-11-23</created><updated>2010-03-21</updated><authors><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Pietropaoli</keyname><forenames>Ugo</forenames></author></authors><title>Hitting Diamonds and Growing Cacti</title><categories>cs.DS cs.DM</categories><comments>v2: several minor changes.</comments><doi>10.1007/978-3-642-13036-6_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following NP-hard problem: in a weighted graph, find a
minimum cost set of vertices whose removal leaves a graph in which no two
cycles share an edge. We obtain a constant-factor approximation algorithm,
based on the primal-dual method. Moreover, we show that the integrality gap of
the natural LP relaxation of the problem is \Theta(\log n), where n denotes the
number of vertices in the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4375</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4375</id><created>2009-11-23</created><updated>2010-03-08</updated><authors><author><keyname>De Comite</keyname><forenames>Francesco</forenames></author><author><keyname>Delahaye</keyname><forenames>Jean-Paul</forenames></author></authors><title>Automated Proofs in Geometry : Computing Upper Bounds for the Heilbronn
  Problem for Triangles</title><categories>cs.CG cs.DM cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for computing upper bounds for the Heilbronn problem for
triangles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4384</identifier>
 <datestamp>2015-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4384</id><created>2009-11-23</created><updated>2015-07-02</updated><authors><author><keyname>Hetland</keyname><forenames>Magnus Lie</forenames></author></authors><title>Ptolemaic Indexing</title><categories>cs.DS</categories><acm-class>H.3.3</acm-class><journal-ref>Journ. of Comp. Geom., JoCG, vol 6, no 1 (2015) 165-184</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses a new family of bounds for use in similarity search,
related to those used in metric indexing, but based on Ptolemy's inequality,
rather than the metric axioms. Ptolemy's inequality holds for the well-known
Euclidean distance, but is also shown here to hold for quadratic form metrics
in general, with Mahalanobis distance as an important special case. The
inequality is examined empirically on both synthetic and real-world data sets
and is also found to hold approximately, with a very low degree of error, for
important distances such as the angular pseudometric and several Lp norms.
Indexing experiments demonstrate a highly increased filtering power compared to
existing, triangular methods. It is also shown that combining the Ptolemaic and
triangular filtering can lead to better results than using either approach on
its own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4385</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4385</id><created>2009-11-23</created><authors><author><keyname>Cerda</keyname><forenames>Mauricio</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Terissi</keyname><forenames>Lucas</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Girau</keyname><forenames>Bernard</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Bio-inspired speed detection and discrimination</title><categories>cs.CV cs.NE</categories><proxy>ccsd inria-00434466</proxy><journal-ref>4th International Conference on Bio-Inspired Models of Network,
  Information, and Computing Systems, Avignon : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of computer vision, a crucial task is the detection of motion
(also called optical flow extraction). This operation allows analysis such as
3D reconstruction, feature tracking, time-to-collision and novelty detection
among others. Most of the optical flow extraction techniques work within a
finite range of speeds. Usually, the range of detection is extended towards
higher speeds by combining some multiscale information in a serial
architecture. This serial multi-scale approach suffers from the problem of
error propagation related to the number of scales used in the algorithm. On the
other hand, biological experiments show that human motion perception seems to
follow a parallel multiscale scheme. In this work we present a bio-inspired
parallel architecture to perform detection of motion, providing a wide range of
operation and avoiding error propagation associated with the serial
architecture. To test our algorithm, we perform relative error comparisons
between both classical and proposed techniques, showing that the parallel
architecture is able to achieve motion detection with results similar to the
serial approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4395</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4395</id><created>2009-11-23</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author></authors><title>Introduction to Distributed Systems</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing has passed through many transformations since the birth of the
first computing machines. Developments in technology have resulted in the
availability of fast and inexpensive processors, and progresses in
communication technology have resulted in the availability of lucrative and
highly proficient computer networks. Among these, the centralized networks have
one component that is shared by users all the time. All resources are
accessible, but there is a single point of control as well as a single point of
failure. The integration of computer and networking technologies gave birth to
new paradigm of computing called distributed computing in the late 1970s.
Distributed computing has changed the face of computing and offered quick and
precise solutions for a variety of complex problems for different fields.
Nowadays, we are fully engrossed by the information age, and expending more
time communicating and gathering information through the Internet. The Internet
keeps on progressing along more than a few magnitudes, abiding end systems
increasingly to communicate in more and more different ways. Over the years,
several methods have evolved to enable these developments, ranging from
simplistic data sharing to advanced systems supporting a multitude of services.
This article provides an overview of distributed computing systems. The
definition, architecture, characteristics of distributed systems and the
various distributed computing fallacies are discussed in the beginning.
Finally, discusses client/server computing, World Wide Web and types of
distributed systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4414</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4414</id><created>2009-11-23</created><authors><author><keyname>Pal</keyname><forenames>Nikhil R.</forenames></author><author><keyname>Laha</keyname><forenames>Arijit</forenames></author><author><keyname>Das</keyname><forenames>J.</forenames></author></authors><title>Designing fuzzy rule based classifier using self-organizing feature map
  for analysis of multispectral satellite images</title><categories>cs.CV cs.NE</categories><comments>23 pages, 7 figures</comments><journal-ref>International Journal of Remote Sensing, Volume 26, No 10, Pages
  2219-2240, May 2005</journal-ref><doi>10.1080/01431160500033419</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel scheme for designing fuzzy rule based classifier. An SOFM
based method is used for generating a set of prototypes which is used to
generate a set of fuzzy rules. Each rule represents a region in the feature
space that we call the context of the rule. The rules are tuned with respect to
their context. We justified that the reasoning scheme may be different in
different context leading to context sensitive inferencing. To realize context
sensitive inferencing we used a softmin operator with a tunable parameter. The
proposed scheme is tested on several multispectral satellite image data sets
and the performance is found to be much better than the results reported in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4416</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4416</id><created>2009-11-23</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author><author><keyname>Pal</keyname><forenames>Nikhil R.</forenames></author><author><keyname>Das</keyname><forenames>J.</forenames></author></authors><title>Land cover classification using fuzzy rules and aggregation of
  contextual information through evidence theory</title><categories>cs.CV cs.NE</categories><comments>14 pages, 2 figures</comments><journal-ref>IEEE Transactions on Geoscience and Remote Sensing, Vol. 44, No.
  6, pp. 1633-1642, June 2006</journal-ref><doi>10.1109/TGRS.2006.864391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Land cover classification using multispectral satellite image is a very
challenging task with numerous practical applications. We propose a multi-stage
classifier that involves fuzzy rule extraction from the training data and then
generation of a possibilistic label vector for each pixel using the fuzzy rule
base. To exploit the spatial correlation of land cover types we propose four
different information aggregation methods which use the possibilistic class
label of a pixel and those of its eight spatial neighbors for making the final
classification decision. Three of the aggregation methods use Dempster-Shafer
theory of evidence while the remaining one is modeled after the fuzzy k-NN
rule. The proposed methods are tested with two benchmark seven channel
satellite images and the results are found to be quite satisfactory. They are
also compared with a Markov random field (MRF) model-based contextual
classification method and found to perform consistently better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4432</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4432</id><created>2009-11-23</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The Role of Feedback in Two-way Secure Communications</title><categories>cs.IT math.IT</categories><comments>51 pages. Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most practical communication links are bi-directional. In these models, since
the source node also receives signals, its encoder has the option of computing
its output based on the signals it received in the past. On the other hand,
from a practical point of view, it would also be desirable to identify the
cases where such an encoder design may not improve communication rates. This
question is particularly interesting for the case where the transmitted
messages and the feedback signals are subject to eavesdropping. In this work,
we investigate the question of how much impact the feedback has on the secrecy
capacity by studying two fundamental models. First, we consider the Gaussian
two-way wiretap channel and derive an outer bound for its secrecy capacity
region. We show that the secrecy rate loss can be unbounded when feedback
signals are not utilized except for a special case we identify, and thus
conclude that utilizing feedback can be highly beneficial in general. Second,
we consider a half-duplex Gaussian two-way relay channel where the relay node
is also an eavesdropper, and find that the impact of feedback is less
pronounced compared to the previous scenario. Specifically, the loss in secrecy
rate, when ignoring the feedback, is quantified to be less than 0.5 bit per
channel use when the relay power goes to infinity. This achievable rate region
is obtained with simple time sharing along with cooperative jamming, which,
with its simplicity and near optimum performance, is a viable alternative to an
encoder that utilizes feedback signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4459</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4459</id><created>2009-11-23</created><updated>2010-08-12</updated><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>Interval edge colorings of some products of graphs</title><categories>cs.DM</categories><comments>14 pages, 5 figures, minor changes</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An edge coloring of a graph $G$ with colors $1,2,\ldots ,t$ is called an
interval $t$-coloring if for each $i\in \{1,2,\ldots,t\}$ there is at least one
edge of $G$ colored by $i$, and the colors of edges incident to any vertex of
$G$ are distinct and form an interval of integers. A graph $G$ is interval
colorable, if there is an integer $t\geq 1$ for which $G$ has an interval
$t$-coloring. Let $\mathfrak{N}$ be the set of all interval colorable graphs.
In 2004 Kubale and Giaro showed that if $G,H\in \mathfrak{N}$, then the
  Cartesian product of these graphs belongs to $\mathfrak{N}$. Also, they
formulated a similar problem for the lexicographic product as an open problem.
In this paper we first show that if $G\in \mathfrak{N}$, then $G[nK_{1}]\in
\mathfrak{N}$ for any $n\in \mathbf{N}$. Furthermore, we show that if $G,H\in
\mathfrak{N}$ and $H$ is a regular graph, then strong and lexicographic
products of graphs $G,H$ belong to $\mathfrak{N}$. We also prove that tensor
and strong tensor products of graphs $G,H$ belong to $\mathfrak{N}$ if $G\in
\mathfrak{N}$ and $H$ is a regular graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4498</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4498</id><created>2009-11-23</created><updated>2010-04-13</updated><authors><author><keyname>Korobeynikov</keyname><forenames>Anton</forenames></author></authors><title>Computation- and Space-Efficient Implementation of SSA</title><categories>cs.NA</categories><comments>27 pages, 8 figures</comments><journal-ref>Statistics and Its Interface, 3 (3), 2010, pp 357-368</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational complexity of different steps of the basic SSA is
discussed. It is shown that the use of the general-purpose &quot;blackbox&quot; routines
(e.g. found in packages like LAPACK) leads to huge waste of time resources
since the special Hankel structure of the trajectory matrix is not taken into
account. We outline several state-of-the-art algorithms (for example,
Lanczos-based truncated SVD) which can be modified to exploit the structure of
the trajectory matrix. The key components here are hankel matrix-vector
multiplication and hankelization operator. We show that both can be computed
efficiently by the means of Fast Fourier Transform. The use of these methods
yields the reduction of the worst-case computational complexity from O(N^3) to
O(k N log(N)), where N is series length and k is the number of eigentriples
desired.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4507</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4507</id><created>2009-11-23</created><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Kayran</keyname><forenames>Ahmet H.</forenames></author></authors><title>On Feasibility of Interference Alignment in MIMO Interference Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the feasibility of interference alignment in signal vector space
-- based only on beamforming -- for K-user MIMO interference channels. Our main
contribution is to relate the feasibility issue to the problem of determining
the solvability of a multivariate polynomial system, considered extensively in
algebraic geometry. It is well known, e.g. from Bezout's theorem, that generic
polynomial systems are solvable if and only if the number of equations does not
exceed the number of variables. Following this intuition, we classify signal
space interference alignment problems as either proper or improper based on the
number of equations and variables. Rigorous connections between feasible and
proper systems are made through Bernshtein's theorem for the case where each
transmitter uses only one beamforming vector. The multi-beam case introduces
dependencies among the coefficients of a polynomial system so that the system
is no longer generic in the sense required by both theorems. In this case, we
show that the connection between feasible and proper systems can be further
strengthened (since the equivalency between feasible and proper systems does
not always hold) by including standard information theoretic outer bounds in
the feasibility analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4510</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4510</id><created>2009-11-23</created><authors><author><keyname>Bacci</keyname><forenames>Giorgio</forenames><affiliation>DiMI, University of Udine</affiliation></author><author><keyname>Grohmann</keyname><forenames>Davide</forenames><affiliation>DiMI, University of Udine</affiliation></author><author><keyname>Miculan</keyname><forenames>Marino</forenames><affiliation>DiMI, University of Udine</affiliation></author></authors><title>Bigraphical models for protein and membrane interactions</title><categories>cs.CE cs.LO q-bio.MN q-bio.QM</categories><acm-class>F.1.2; F.4.2; J.3</acm-class><journal-ref>EPTCS 11, 2009, pp. 3-18</journal-ref><doi>10.4204/EPTCS.11.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a bigraphical framework suited for modeling biological systems
both at protein level and at membrane level. We characterize formally bigraphs
corresponding to biologically meaningful systems, and bigraphic rewriting rules
representing biologically admissible interactions. At the protein level, these
bigraphic reactive systems correspond exactly to systems of kappa-calculus.
Membrane-level interactions are represented by just two general rules, whose
application can be triggered by protein-level interactions in a well-de\&quot;ined
and precise way. This framework can be used to compare and merge models at
different abstraction levels; in particular, higher-level (e.g. mobility)
activities can be given a formal biological justification in terms of low-level
(i.e., protein) interactions. As examples, we formalize in our framework the
vesiculation and the phagocytosis processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4511</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4511</id><created>2009-11-24</created><authors><author><keyname>Bellala</keyname><forenames>Gowtham</forenames></author><author><keyname>Bhavnani</keyname><forenames>Suresh</forenames></author><author><keyname>Scott</keyname><forenames>Clayton</forenames></author></authors><title>Group-based Query Learning for rapid diagnosis in time-critical
  situations</title><categories>stat.ML cs.IT math.IT</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In query learning, the goal is to identify an unknown object while minimizing
the number of &quot;yes or no&quot; questions (queries) posed about that object. We
consider three extensions of this fundamental problem that are motivated by
practical considerations in real-world, time-critical identification tasks such
as emergency response. First, we consider the problem where the objects are
partitioned into groups, and the goal is to identify only the group to which
the object belongs. Second, we address the situation where the queries are
partitioned into groups, and an algorithm may suggest a group of queries to a
human user, who then selects the actual query. Third, we consider the problem
of query learning in the presence of persistent query noise, and relate it to
group identification. To address these problems we show that a standard
algorithm for query learning, known as the splitting algorithm or generalized
binary search, may be viewed as a generalization of Shannon-Fano coding. We
then extend this result to the group-based settings, leading to new algorithms.
The performance of our algorithms is demonstrated on simulated data and on a
database used by first responders for toxic chemical identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4513</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4513</id><created>2009-11-23</created><authors><author><keyname>Bacci</keyname><forenames>Giorgio</forenames><affiliation>DiMI, University of Udine</affiliation></author><author><keyname>Grohmann</keyname><forenames>Davide</forenames><affiliation>DiMI, University of Udine</affiliation></author><author><keyname>Miculan</keyname><forenames>Marino</forenames><affiliation>DiMI, University of Udine</affiliation></author></authors><title>A framework for protein and membrane interactions</title><categories>cs.CE cs.LO q-bio.MN q-bio.QM</categories><acm-class>F.1.2; F.4.2; J.3</acm-class><journal-ref>EPTCS 11, 2009, pp. 19-33</journal-ref><doi>10.4204/EPTCS.11.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the BioBeta Framework, a meta-model for both protein-level and
membrane-level interactions of living cells. This formalism aims to provide a
formal setting where to encode, compare and merge models at different
abstraction levels; in particular, higher-level (e.g. membrane) activities can
be given a formal biological justification in terms of low-level (i.e.,
protein) interactions. A BioBeta specification provides a protein signature
together a set of protein reactions, in the spirit of the kappa-calculus.
Moreover, the specification describes when a protein configuration triggers one
of the only two membrane interaction allowed, that is &quot;pinch&quot; and &quot;fuse&quot;. In
this paper we define the syntax and semantics of BioBeta, analyse its
properties, give it an interpretation as biobigraphical reactive systems, and
discuss its expressivity by comparing with kappa-calculus and modelling
significant examples. Notably, BioBeta has been designed after a bigraphical
metamodel for the same purposes. Hence, each instance of the calculus
corresponds to a bigraphical reactive system, and vice versa (almost).
Therefore, we can inherith the rich theory of bigraphs, such as the automatic
construction of labelled transition systems and behavioural congruences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4521</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4521</id><created>2009-11-23</created><authors><author><keyname>Bauwens</keyname><forenames>Bruno</forenames></author></authors><title>On the equivalence between minimal sufficient statistics, minimal
  typical models and initial segments of the Halting sequence</title><categories>cs.CC cs.IT math.IT</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that the length of the algorithmic minimal sufficient statistic
of a binary string x, either in a representation of a finite set, computable
semimeasure, or a computable function, has a length larger than the
computational depth of x, and can solve the Halting problem for all programs
with length shorter than the m-depth of x. It is also shown that there are
strings for which the algorithmic minimal sufficient statistics can contain a
substantial amount of information that is not Halting information. The weak
sufficient statistic is introduced, and it is shown that a minimal weak
sufficient statistic for x is equivalent to a minimal typical model of x, and
to the Halting problem for all strings shorter than the BB-depth of x.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4522</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4522</id><created>2009-11-23</created><updated>2011-02-21</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author></authors><title>On the Number of Errors Correctable with Codes on Graphs</title><categories>cs.IT cs.DM math.IT</categories><comments>Published in the Ralf Koetter Memorial Issue of IEEE Transactions on
  Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 57, No. 2, February
  2011</journal-ref><doi>10.1109/TIT.2010.2094812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study ensembles of codes on graphs (generalized low-density parity-check,
or LDPC codes) constructed from random graphs and fixed local constrained
codes, and their extension to codes on hypergraphs. It is known that the
average minimum distance of codes in these ensembles grows linearly with the
code length. We show that these codes can correct a linearly growing number of
errors under simple iterative decoding algorithms. In particular, we show that
this property extends to codes constructed by parallel concatenation of Hamming
codes and other codes with small minimum distance. Previously known results
that proved this property for graph codes relied on graph expansion and
required the choice of local codes with large distance relative to their
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4530</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4530</id><created>2009-11-23</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>MIMO Z-Interference Channels: Capacity Under Strong and Noisy
  Interference</title><categories>cs.IT math.IT</categories><comments>5 pages, presented at Asilomar 09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity regions of multiple-input multiple-output Gaussian
Z-interference channels are established for the very strong interference and
aligned strong interference cases. The sum-rate capacity of such channels is
established under noisy interference. These results generalize known results
for scalar Gaussian Z-interference channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4544</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4544</id><created>2009-11-24</created><authors><author><keyname>Louis</keyname><forenames>Anand</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth</forenames></author></authors><title>Improved Algorithm for Degree Bounded Survivable Network Design Problem</title><categories>cs.DS</categories><doi>10.1007/978-3-642-13731-0_38</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Degree-Bounded Survivable Network Design Problem: the
objective is to find a minimum cost subgraph satisfying the given connectivity
requirements as well as the degree bounds on the vertices. If we denote the
upper bound on the degree of a vertex v by b(v), then we present an algorithm
that finds a solution whose cost is at most twice the cost of the optimal
solution while the degree of a degree constrained vertex v is at most 2b(v) +
2. This improves upon the results of Lau and Singh and that of Lau, Naor,
Salavatipour and Singh.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4590</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4590</id><created>2009-11-24</created><authors><author><keyname>Hasunuma</keyname><forenames>Toru</forenames></author><author><keyname>Ishii</keyname><forenames>Toshimasa</forenames></author><author><keyname>Ono</keyname><forenames>Hirotaka</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>A tight upper bound on the (2,1)-total labeling number of outerplanar
  graphs</title><categories>cs.DM</categories><comments>17 pages, 9figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $(2,1)$-total labeling of a graph $G$ is an assignment $f$ from the vertex
set $V(G)$ and the edge set $E(G)$ to the set $\{0,1,...,k\}$ of nonnegative
integers such that $|f(x)-f(y)|\ge 2$ if $x$ is a vertex and $y$ is an edge
incident to $x$, and $|f(x)-f(y)|\ge 1$ if $x$ and $y$ are a pair of adjacent
vertices or a pair of adjacent edges, for all $x$ and $y$ in $V(G)\cup E(G)$.
The $(2,1)$-total labeling number $\lambda^T_2(G)$ of a graph $G$ is defined as
the minimum $k$ among all possible assignments. In [D. Chen and W. Wang.
(2,1)-Total labelling of outerplanar graphs. Discr. Appl. Math. 155, 2585--2593
(2007)], Chen and Wang conjectured that all outerplanar graphs $G$ satisfy
  $\lambda^T_2(G) \leq \Delta(G)+2$, where $\Delta(G)$ is the maximum degree of
$G$, while they also showed that it is true for $G$ with $\Delta(G)\geq 5$. In
this paper, we solve their conjecture completely, by proving that
  $\lambda^T_2(G) \leq \Delta(G)+2$ even in the case of $\Delta(G)\leq 4 $.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4626</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4626</id><created>2009-11-24</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>A characterization of Konig-Egervary graphs using a common property of
  all maximum matchings</title><categories>cs.DM math.CO</categories><comments>9 pages, 5 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The independence number of a graph G, denoted by alpha(G), is the cardinality
of an independent set of maximum size in G, while mu(G) is the size of a
maximum matching in G, i.e., its matching number. G is a Konig-Egervary graph
if its order equals alpha(G)+mu(G). In this paper we give a new
characterization of Konig-Egervary graphs. We also deduce some properties of
vertices belonging to all maximum independent sets of a Konig-Egervary graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4640</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4640</id><created>2009-11-24</created><authors><author><keyname>Srinidhi</keyname><forenames>N.</forenames></author><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Near-ML Signal Detection in Large-Dimension Linear Vector Channels Using
  Reactive Tabu Search</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-complexity near-optimal signal detection in large dimensional
communication systems is a challenge. In this paper, we present a reactive tabu
search (RTS) algorithm, a heuristic based combinatorial optimization technique,
to achieve low-complexity near-maximum likelihood (ML) signal detection in
linear vector channels with large dimensions. Two practically important
large-dimension linear vector channels are considered: i) multiple-input
multiple-output (MIMO) channels with large number (tens) of transmit and
receive antennas, and ii) severely delay-spread MIMO inter-symbol interference
(ISI) channels with large number (tens to hundreds) of multipath components.
These channels are of interest because the former offers the benefit of
increased spectral efficiency (several tens of bps/Hz) and the latter offers
the benefit of high time-diversity orders. Our simulation results show that,
while algorithms including variants of sphere decoding do not scale well for
large dimensions, the proposed RTS algorithm scales well for signal detection
in large dimensions while achieving increasingly closer to ML performance for
increasing number of dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4642</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4642</id><created>2009-11-24</created><authors><author><keyname>Castagn&#xe9;</keyname><forenames>Nicolas</forenames><affiliation>ACROE</affiliation></author><author><keyname>Cadoz</keyname><forenames>Claude</forenames><affiliation>ACROE, ICA</affiliation></author><author><keyname>Allaoui</keyname><forenames>Ali</forenames><affiliation>ACROE, ICA</affiliation></author><author><keyname>Tache</keyname><forenames>Olivier Michel</forenames><affiliation>ACROE</affiliation></author></authors><title>G3 : GENESIS software envrionment update</title><categories>cs.SD cs.HC cs.MM cs.SE</categories><proxy>ccsd hal-00435699</proxy><journal-ref>International Computer Music Conference (ICMC), Montr\'eal :
  Canada (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GENESIS3 is the new version of the GENESIS software environment for musical
creation by means of mass-interaction physics network modeling. It was
designed, and developed from scratch, in hindsight of more than 10 years
working on and using the previous version. We take the opportunity of this
birth to provide in this article (1) an analysis of the peculiarities in
GENESIS, aiming at highlighting its core ?software paradigm?; and (2) an update
on the features of the new version as compared to the last.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4650</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4650</id><created>2009-11-24</created><authors><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Sadaghiani</keyname><forenames>Sepideh</forenames><affiliation>LCogn</affiliation></author><author><keyname>Poline</keyname><forenames>Jean Baptiste</forenames><affiliation>LNAO</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author></authors><title>CanICA: Model-based extraction of reproducible group-level ICA patterns
  from fMRI time series</title><categories>cs.CV stat.AP</categories><proxy>ccsd hal-00435262</proxy><journal-ref>Medical Image Computing and Computer Aided Intervention, London :
  United Kingdom (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial Independent Component Analysis (ICA) is an increasingly used
data-driven method to analyze functional Magnetic Resonance Imaging (fMRI)
data. To date, it has been used to extract meaningful patterns without prior
information. However, ICA is not robust to mild data variation and remains a
parameter-sensitive algorithm. The validity of the extracted patterns is hard
to establish, as well as the significance of differences between patterns
extracted from different groups of subjects. We start from a generative model
of the fMRI group data to introduce a probabilistic ICA pattern-extraction
algorithm, called CanICA (Canonical ICA). Thanks to an explicit noise model and
canonical correlation analysis, our method is auto-calibrated and identifies
the group-reproducible data subspace before performing ICA. We compare our
method to state-of-the-art multi-subject fMRI ICA methods and show that the
features extracted are more reproducible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4704</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4704</id><created>2009-11-24</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames></author><author><keyname>Kotagiri</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Cooperative Relaying with State Available Non-Causally at the Relay</title><categories>cs.IT math.IT</categories><comments>62 pages. To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a three-terminal state-dependent relay channel with the channel
state noncausally available at only the relay. Such a model may be useful for
designing cooperative wireless networks with some terminals equipped with
cognition capabilities, i.e., the relay in our setup. In the discrete
memoryless (DM) case, we establish lower and upper bounds on channel capacity.
The lower bound is obtained by a coding scheme at the relay that uses a
combination of codeword splitting, Gel'fand-Pinsker binning, and
decode-and-forward relaying. The upper bound improves upon that obtained by
assuming that the channel state is available at the source, the relay, and the
destination. For the Gaussian case, we also derive lower and upper bounds on
the capacity. The lower bound is obtained by a coding scheme at the relay that
uses a combination of codeword splitting, generalized dirty paper coding, and
decode-and-forward relaying; the upper bound is also better than that obtained
by assuming that the channel state is available at the source, the relay, and
the destination. In the case of degraded Gaussian channels, the lower bound
meets with the upper bound for some special cases, and, so, the capacity is
obtained for these cases. Furthermore, in the Gaussian case, we also extend the
results to the case in which the relay operates in a half-duplex mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4724</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4724</id><created>2009-11-24</created><authors><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Quantum algorithms to solve the hidden shift problem for quadratics and
  for functions of large Gowers norm</title><categories>quant-ph cs.CC</categories><comments>12 pages, no figures, Proc. MFCS'09, LNCS vol. 5734, pp. 663-674,
  2009. Mezzanine tranche of earlier paper arXiv:0811.3208</comments><journal-ref>Proceedings MFCS'09, LNCS vol. 5734, pp. 663-674, 2009</journal-ref><doi>10.1007/978-3-642-03816-7_56</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most quantum algorithms that give an exponential speedup over classical
algorithms exploit the Fourier transform in some way. In Shor's algorithm,
sampling from the quantum Fourier spectrum is used to discover periodicity of
the modular exponentiation function. In a generalization of this idea, quantum
Fourier sampling can be used to discover hidden subgroup structures of some
functions much more efficiently than it is possible classically. Another
problem for which the Fourier transform has been recruited successfully on a
quantum computer is the hidden shift problem. Quantum algorithms for hidden
shift problems usually have a slightly different flavor from hidden subgroup
algorithms, as they use the Fourier transform to perform a correlation with a
given reference function, instead of sampling from the Fourier spectrum
directly. In this paper we show that hidden shifts can be extracted efficiently
from Boolean functions that are quadratic forms. We also show how to identify
an unknown quadratic form on n variables using a linear number of queries, in
contrast to the classical case were this takes Theta(n^2) many queries to a
black box. What is more, we show that our quantum algorithm is robust in the
sense that it can also infer the shift if the function is close to a quadratic,
where we consider a Boolean function to be close to a quadratic if it has a
large Gowers U_3 norm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4727</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4727</id><created>2009-11-24</created><updated>2010-12-09</updated><authors><author><keyname>de Cooman</keyname><forenames>Gert</forenames></author><author><keyname>Quaeghebeur</keyname><forenames>Erik</forenames></author></authors><title>Exchangeability and sets of desirable gambles</title><categories>math.PR cs.AI math.ST stat.TH</categories><comments>40 pages</comments><doi>10.1016/j.ijar.2010.12.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sets of desirable gambles constitute a quite general type of uncertainty
model with an interesting geometrical interpretation. We give a general
discussion of such models and their rationality criteria. We study
exchangeability assessments for them, and prove counterparts of de Finetti's
finite and infinite representation theorems. We show that the finite
representation in terms of count vectors has a very nice geometrical
interpretation, and that the representation in terms of frequency vectors is
tied up with multivariate Bernstein (basis) polynomials. We also lay bare the
relationships between the representations of updated exchangeable models, and
discuss conservative inference (natural extension) under exchangeability and
the extension of exchangeable sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4729</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4729</id><created>2009-11-24</created><updated>2011-04-17</updated><authors><author><keyname>Sahai</keyname><forenames>Tuhin</forenames></author><author><keyname>Speranzon</keyname><forenames>Alberto</forenames></author><author><keyname>Banaszuk</keyname><forenames>Andrzej</forenames></author></authors><title>Hearing the clusters in a graph: A distributed algorithm</title><categories>cs.DM cs.DC physics.comp-ph physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel distributed algorithm to cluster graphs. The algorithm
recovers the solution obtained from spectral clustering without the need for
expensive eigenvalue/vector computations. We prove that, by propagating waves
through the graph, a local fast Fourier transform yields the local component of
every eigenvector of the Laplacian matrix, thus providing clustering
information. For large graphs, the proposed algorithm is orders of magnitude
faster than random walk based approaches. We prove the equivalence of the
proposed algorithm to spectral clustering and derive convergence rates. We
demonstrate the benefit of using this decentralized clustering algorithm for
community detection in social graphs, accelerating distributed estimation in
sensor networks and efficient computation of distributed multi-agent search
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4732</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4732</id><created>2009-11-24</created><updated>2010-02-10</updated><authors><author><keyname>Ge</keyname><forenames>Qi</forenames></author><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author></authors><title>A graph polynomial for independent sets of bipartite graphs</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new graph polynomial that encodes interesting properties of
graphs, for example, the number of matchings and the number of perfect
matchings. Most importantly, for bipartite graphs the polynomial encodes the
number of independent sets (#BIS).
  We analyze the complexity of exact evaluation of the polynomial at rational
points and show that for most points exact evaluation is #P-hard (assuming the
generalized Riemann hypothesis) and for the rest of the points exact evaluation
is trivial.
  We conjecture that a natural Markov chain can be used to approximately
evaluate the polynomial for a range of parameters. The conjecture, if true,
would imply an approximate counting algorithm for #BIS, a problem shown, by
[Dyer et al. 2004], to be complete (with respect to, so called, AP-reductions)
for a rich logically defined sub-class of #P. We give a mild support for our
conjecture by proving that the Markov chain is rapidly mixing on trees. As a
by-product we show that the &quot;single bond flip&quot; Markov chain for the random
cluster model is rapidly mixing on constant tree-width graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4752</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4752</id><created>2009-11-24</created><authors><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>MIMO Radar Using Compressive Sampling</title><categories>cs.IT math.IT</categories><comments>39 pages and 14 figures. Y. Yu, A. P. Petropulu and H. V. Poor, &quot;MIMO
  Radar Using Compressive Sampling,&quot; IEEE Journal of Selected Topics in Signal
  Processing, to appear in Feb. 2010</comments><doi>10.1109/JSTSP.2009.2038973</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A MIMO radar system is proposed for obtaining angle and Doppler information
on potential targets. Transmitters and receivers are nodes of a small scale
wireless network and are assumed to be randomly scattered on a disk. The
transmit nodes transmit uncorrelated waveforms. Each receive node applies
compressive sampling to the received signal to obtain a small number of
samples, which the node subsequently forwards to a fusion center. Assuming that
the targets are sparsely located in the angle- Doppler space, based on the
samples forwarded by the receive nodes the fusion center formulates an
l1-optimization problem, the solution of which yields target angle and Doppler
information. The proposed approach achieves the superior resolution of MIMO
radar with far fewer samples than required by other approaches. This implies
power savings during the communication phase between the receive nodes and the
fusion center. Performance in the presence of a jammer is analyzed for the case
of slowly moving targets. Issues related to forming the basis matrix that spans
the angle-Doppler space, and for selecting a grid for that space are discussed.
Extensive simulation results are provided to demonstrate the performance of the
proposed approach at difference jammer and noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4761</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4761</id><created>2009-11-24</created><updated>2010-04-12</updated><authors><author><keyname>Velden</keyname><forenames>Theresa A.</forenames></author><author><keyname>Haque</keyname><forenames>Asif-ul</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl J.</forenames></author></authors><title>A New Approach to Analyzing Patterns of Collaboration in Co-authorship
  Networks - Mesoscopic Analysis and Interpretation</title><categories>cs.CY cs.DL physics.soc-ph</categories><comments>An earlier version of the paper was presented at ISSI 2009, 14-17
  July, Rio de Janeiro, Brazil. Revised version accepted on 2 April 2010 for
  publication in Scientometrics. Removed part on node-role connectivity profile
  analysis after finding error in calculation and deciding to postpone
  analysis.</comments><doi>10.1007/s11192-010-0224-6</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper focuses on methods to study patterns of collaboration in
co-authorship networks at the mesoscopic level. We combine qualitative methods
(participant interviews) with quantitative methods (network analysis) and
demonstrate the application and value of our approach in a case study comparing
three research fields in chemistry. A mesoscopic level of analysis means that
in addition to the basic analytic unit of the individual researcher as node in
a co-author network, we base our analysis on the observed modular structure of
co-author networks. We interpret the clustering of authors into groups as
bibliometric footprints of the basic collective units of knowledge production
in a research specialty. We find two types of coauthor-linking patterns between
author clusters that we interpret as representing two different forms of
cooperative behavior, transfer-type connections due to career migrations or
one-off services rendered, and stronger, dedicated inter-group collaboration.
Hence the generic coauthor network of a research specialty can be understood as
the overlay of two distinct types of cooperative networks between groups of
authors publishing in a research specialty. We show how our analytic approach
exposes field specific differences in the social organization of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4792</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4792</id><created>2009-11-25</created><authors><author><keyname>Braud</keyname><forenames>Laurent</forenames></author></authors><title>Covering of ordinals</title><categories>cs.LO</categories><comments>Accepted at FSTTCS'09</comments><journal-ref>Proc. of FSTTCS 2009, pp.97-108</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on the structure of fundamental sequences of ordinals
smaller than $\epsilon_0$. A first result is the construction of a monadic
second-order formula identifying a given structure, whereas such a formula
cannot exist for ordinals themselves. The structures are precisely classified
in the pushdown hierarchy. Ordinals are also located in the hierarchy, and a
direct presentation is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4821</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4821</id><created>2009-11-25</created><updated>2010-05-31</updated><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard</forenames><affiliation>LIPN</affiliation></author><author><keyname>Tollu</keyname><forenames>Christophe</forenames><affiliation>LIPN</affiliation></author></authors><title>M\&quot;obius inversion formula for monoids with zero</title><categories>math.CO cs.DM</categories><comments>12 pages, r\'esum\'e \'etendu soumis \`a FPSAC 2010</comments><proxy>ccsd</proxy><journal-ref>Semigroup Forum (2010) 1-15</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The M\&quot;obius inversion formula, introduced during the 19th century in number
theory, was generalized to a wide class of monoids called locally finite such
as the free partially commutative, plactic and hypoplactic monoids for
instance. In this contribution are developed and used some topological and
algebraic notions for monoids with zero, similar to ordinary objects such as
the (total) algebra of a monoid, the augmentation ideal or the star operation
on proper series. The main concern is to extend the study of the M\&quot;obius
function to some monoids with zero, i.e., with an absorbing element, in
particular the so-called Rees quotients of locally finite monoids. Some
relations between the M\&quot;obius functions of a monoid and its Rees quotient are
also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4833</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4833</id><created>2009-11-25</created><updated>2010-01-12</updated><authors><author><keyname>Bouyer</keyname><forenames>Patricia</forenames></author><author><keyname>Brihaye</keyname><forenames>Thomas</forenames></author><author><keyname>Chevalier</keyname><forenames>Fabrice</forenames></author></authors><title>O-Minimal Hybrid Reachability Games</title><categories>cs.LO cs.GT</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (January
  12, 2010) lmcs:1206</journal-ref><doi>10.2168/LMCS-6(1:1)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider reachability games over general hybrid systems,
and distinguish between two possible observation frameworks for those games:
either the precise dynamics of the system is seen by the players (this is the
perfect observation framework), or only the starting point and the delays are
known by the players (this is the partial observation framework). In the first
more classical framework, we show that time-abstract bisimulation is not
adequate for solving this problem, although it is sufficient in the case of
timed automata . That is why we consider an other equivalence, namely the
suffix equivalence based on the encoding of trajectories through words. We show
that this suffix equivalence is in general a correct abstraction for games. We
apply this result to o-minimal hybrid systems, and get decidability and
computability results in this framework. For the second framework which assumes
a partial observation of the dynamics of the system, we propose another
abstraction, called the superword encoding, which is suitable to solve the
games under that assumption. In that framework, we also provide decidability
and computability results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4854</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4854</id><created>2009-11-25</created><authors><author><keyname>Barbuti</keyname><forenames>Roberto</forenames></author><author><keyname>Maggiolo-Schettini</keyname><forenames>Andrea</forenames></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames></author><author><keyname>Pardini</keyname><forenames>Giovanni</forenames></author><author><keyname>Rama</keyname><forenames>Aureliano</forenames></author></authors><title>A Process Calculus for Molecular Interaction Maps</title><categories>cs.CE cs.LO q-bio.MN</categories><comments>15 pages; 8 figures; To be published on EPTCS, proceedings of MeCBIC
  2009</comments><acm-class>J.3</acm-class><journal-ref>EPTCS 11, 2009, pp. 33-49</journal-ref><doi>10.4204/EPTCS.11.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the MIM calculus, a modeling formalism with a strong biological
basis, which provides biologically-meaningful operators for representing the
interaction capabilities of molecular species. The operators of the calculus
are inspired by the reaction symbols used in Molecular Interaction Maps (MIMs),
a diagrammatic notation used by biologists. Models of the calculus can be
easily derived from MIM diagrams, for which an unambiguous and executable
interpretation is thus obtained. We give a formal definition of the syntax and
semantics of the MIM calculus, and we study properties of the formalism. A case
study is also presented to show the use of the calculus for modeling
biomolecular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4863</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4863</id><created>2009-11-25</created><updated>2011-05-12</updated><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Garcia</keyname><forenames>Vincent</forenames></author></authors><title>Statistical exponential families: A digest with flash cards</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes concisely the ubiquitous class of exponential family
distributions met in statistics. The first part recalls definitions and
summarizes main properties and duality with Bregman divergences (all proofs are
skipped). The second part lists decompositions and related formula of common
exponential family distributions. We recall the Fisher-Rao-Riemannian
geometries and the dual affine connection information geometries of statistical
manifolds. It is intended to maintain and update this document and catalog by
adding new distribution items.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4874</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4874</id><created>2009-11-25</created><updated>2009-12-04</updated><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author><author><keyname>Marazzato</keyname><forenames>Roberto</forenames></author></authors><title>Non-photorealistic image processing: an Impressionist rendering</title><categories>cs.CV</categories><comments>Keywords: Image processing. Non-photorealistic processing.
  Image-based rendering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes an image processing for a non-photorealistic rendering.
The algorithm is based on a random choice of a set of pixels from those ot the
original image and substitution of them with colour spots. An iterative
procedure is applied to cover, at a desired level, the canvas. The resulting
effect mimics the impressionist painting and Pointillism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4880</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4880</id><created>2009-11-25</created><authors><author><keyname>Hormati</keyname><forenames>Ali</forenames></author><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>An Estimation Theoretic Approach for Sparsity Pattern Recovery in the
  Noisy Setting</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing deals with the reconstruction of sparse signals using a
small number of linear measurements. One of the main challenges in compressed
sensing is to find the support of a sparse signal. In the literature, several
bounds on the scaling law of the number of measurements for successful support
recovery have been derived where the main focus is on random Gaussian
measurement matrices. In this paper, we investigate the noisy support recovery
problem from an estimation theoretic point of view, where no specific
assumption is made on the underlying measurement matrix. The linear
measurements are perturbed by additive white Gaussian noise. We define the
output of a support estimator to be a set of position values in increasing
order. We set the error between the true and estimated supports as the
$\ell_2$-norm of their difference. On the one hand, this choice allows us to
use the machinery behind the $\ell_2$-norm error metric and on the other hand,
converts the support recovery into a more intuitive and geometrical problem.
First, by using the Hammersley-Chapman-Robbins (HCR) bound, we derive a
fundamental lower bound on the performance of any \emph{unbiased} estimator of
the support set. This lower bound provides us with necessary conditions on the
number of measurements for reliable $\ell_2$-norm support recovery, which we
specifically evaluate for uniform Gaussian measurement matrices. Then, we
analyze the maximum likelihood estimator and derive conditions under which the
HCR bound is achievable. This leads us to the number of measurements for the
optimum decoder which is sufficient for reliable $\ell_2$-norm support
recovery. Using this framework, we specifically evaluate sufficient conditions
for uniform Gaussian measurement matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4896</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4896</id><created>2009-11-25</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Diversity Order in ISI Channels with Single-Carrier Frequency-Domain
  Equalizers</title><categories>cs.IT math.IT</categories><comments>30 pages, 6 figures, to appear in the IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the diversity gain achieved by single-carrier
frequency-domain equalizer (SC-FDE) in frequency selective channels, and
uncovers the interplay between diversity gain $d$, channel memory length $\nu$,
transmission block length $L$, and the spectral efficiency $R$. We specifically
show that for the class of minimum means-square error (MMSE) SC-FDE receivers,
for rates $R\leq\log\frac{L}{\nu}$ full diversity of $d=\nu+1$ is achievable,
while for higher rates the diversity is given by $d=\lfloor2^{-R}L\rfloor+1$.
In other words, the achievable diversity gain depends not only on the channel
memory length, but also on the desired spectral efficiency and the transmission
block length. A similar analysis reveals that for zero forcing SC-FDE, the
diversity order is always one irrespective of channel memory length and
spectral efficiency. These results are supported by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4910</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4910</id><created>2009-11-25</created><authors><author><keyname>Jin</keyname><forenames>Ci-Hang</forenames></author><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Adaptive information filtering for dynamic recommender systems</title><categories>cs.IR cs.IT math.IT</categories><comments>6 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic environment in the real world calls for the adaptive techniques
for information filtering, namely to provide real-time responses to the changes
of system data. Where many incremental algorithms are designed for this
purpose, they are usually challenged by the worse and worse performance
resulted from the cumulative errors over time. In this Letter, we propose two
incremental diffusion-based algorithms for the personalized recommendations,
which integrate some pieces of local and fast updatings to achieve the
approximate results. In addition to the fast responses, the errors of the
proposed algorithms do not cumulate over time, that is to say, the global
recomputing is unnecessary. This remarkable advantage is demonstrated by
several metrics on algorithmic accuracy for two movie recommender systems and a
social bookmarking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4940</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4940</id><created>2009-11-25</created><authors><author><keyname>Walter</keyname><forenames>Sebastian F.</forenames></author></authors><title>Efficient Higher Order Derivatives of Objective Functions Composed of
  Matrix Operations</title><categories>cs.DS cs.SC</categories><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the efficient evaluation of higher-order
derivatives of functions $f$ that are composed of matrix operations. I.e., we
want to compute the $D$-th derivative tensor $\nabla^D f(X) \in \mathbb
R^{N^D}$, where $f:\mathbb R^{N} \to \mathbb R$ is given as an algorithm that
consists of many matrix operations. We propose a method that is a combination
of two well-known techniques from Algorithmic Differentiation (AD): univariate
Taylor propagation on scalars (UTPS) and first-order forward and reverse on
matrices. The combination leads to a technique that we would like to call
univariate Taylor propagation on matrices (UTPM). The method inherits many
desirable properties: It is easy to implement, it is very efficient and it
returns not only $\nabla^D f$ but yields in the process also the derivatives
$\nabla^d f$ for $d \leq D$. As performance test we compute the gradient
$\nabla f(X)$ % and the Hessian $\nabla_A^2 f(A)$ by a combination of forward
and reverse mode of $f(X) = \trace (X^{-1})$ in the reverse mode of AD for $X
\in \mathbb R^{n \times n}$. We observe a speedup of about 100 compared to
UTPS. Due to the nature of the method, the memory footprint is also small and
therefore can be used to differentiate functions that are not accessible by
standard methods due to limited physical memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4961</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4961</id><created>2009-11-25</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Jafarpour</keyname><forenames>Behnam</forenames></author></authors><title>A Sparse Bayesian Estimation Framework for Conditioning Prior Geologic
  Models to Nonlinear Flow Measurements</title><categories>cs.NA physics.data-an physics.geo-ph</categories><doi>10.1016/j.advwatres.2010.06.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Bayesian framework for reconstruction of subsurface hydraulic
properties from nonlinear dynamic flow data by imposing sparsity on the
distribution of the solution coefficients in a compression transform domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4963</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4963</id><created>2009-11-25</created><authors><author><keyname>Mozes</keyname><forenames>Shay</forenames></author><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Shortest Paths in Planar Graphs with Real Lengths in
  $O(n\log^2n/\log\log n)$ Time</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an $n$-vertex planar directed graph with real edge lengths and with no
negative cycles, we show how to compute single-source shortest path distances
in the graph in $O(n\log^2n/\log\log n)$ time with O(n) space. This is an
improvement of a recent time bound of $O(n\log^2n)$ by Klein et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4981</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4981</id><created>2009-11-25</created><updated>2012-04-01</updated><authors><author><keyname>Barbay</keyname><forenames>Jeremy</forenames></author><author><keyname>Claude</keyname><forenames>Francisco</forenames></author><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Efficient Fully-Compressed Sequence Representations</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a data structure that stores a sequence $s[1..n]$ over alphabet
$[1..\sigma]$ in $n\Ho(s) + o(n)(\Ho(s){+}1)$ bits, where $\Ho(s)$ is the
zero-order entropy of $s$. This structure supports the queries \access, \rank\
and \select, which are fundamental building blocks for many other compressed
data structures, in worst-case time $\Oh{\lg\lg\sigma}$ and average time
$\Oh{\lg \Ho(s)}$. The worst-case complexity matches the best previous results,
yet these had been achieved with data structures using $n\Ho(s)+o(n\lg\sigma)$
bits. On highly compressible sequences the $o(n\lg\sigma)$ bits of the
redundancy may be significant compared to the the $n\Ho(s)$ bits that encode
the data. Our representation, instead, compresses the redundancy as well.
Moreover, our average-case complexity is unprecedented. Our technique is based
on partitioning the alphabet into characters of similar frequency. The
subsequence corresponding to each group can then be encoded using fast
uncompressed representations without harming the overall compression ratios,
even in the redundancy. The result also improves upon the best current
compressed representations of several other data structures. For example, we
achieve $(i)$ compressed redundancy, retaining the best time complexities, for
the smallest existing full-text self-indexes; $(ii)$ compressed permutations
$\pi$ with times for $\pi()$ and $\pii()$ improved to loglogarithmic; and
$(iii)$ the first compressed representation of dynamic collections of disjoint
sets. We also point out various applications to inverted indexes, suffix
arrays, binary relations, and data compressors. ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4983</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4983</id><created>2009-11-25</created><authors><author><keyname>Basuki</keyname><forenames>Thomas Anung</forenames><affiliation>International Institute of Software Technology, United Nations University</affiliation></author><author><keyname>Cerone</keyname><forenames>Antonio</forenames><affiliation>International Institute of Software Technology, United Nations University</affiliation></author><author><keyname>Carvalho</keyname><forenames>Rafael V.</forenames><affiliation>International Institute of Software Technology, United Nations University</affiliation></author></authors><title>Modelling Cell Cycle using Different Levels of Representation</title><categories>cs.CE cs.LO q-bio.CB q-bio.QM</categories><journal-ref>EPTCS 11, 2009, pp. 51-69</journal-ref><doi>10.4204/EPTCS.11.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the behaviour of biological systems requires a complex setting
of in vitro and in vivo experiments, which attracts high costs in terms of time
and resources. The use of mathematical models allows researchers to perform
computerised simulations of biological systems, which are called in silico
experiments, to attain important insights and predictions about the system
behaviour with a considerably lower cost. Computer visualisation is an
important part of this approach, since it provides a realistic representation
of the system behaviour. We define a formal methodology to model biological
systems using different levels of representation: a purely formal
representation, which we call molecular level, models the biochemical dynamics
of the system; visualisation-oriented representations, which we call visual
levels, provide views of the biological system at a higher level of
organisation and are equipped with the necessary spatial information to
generate the appropriate visualisation. We choose Spatial CLS, a formal
language belonging to the class of Calculi of Looping Sequences, as the
formalism for modelling all representation levels. We illustrate our approach
using the budding yeast cell cycle as a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4984</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4984</id><created>2009-11-25</created><authors><author><keyname>Ciocchetta</keyname><forenames>Federica</forenames></author><author><keyname>Duguid</keyname><forenames>Adam</forenames></author><author><keyname>Guerriero</keyname><forenames>Maria Luisa</forenames></author></authors><title>A compartmental model of the cAMP/PKA/MAPK pathway in Bio-PEPA</title><categories>cs.CE cs.LO q-bio.MN q-bio.QM</categories><journal-ref>EPTCS 11, 2009, pp. 71-90</journal-ref><doi>10.4204/EPTCS.11.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast majority of biochemical systems involve the exchange of information
between different compartments, either in the form of transportation or via the
intervention of membrane proteins which are able to transmit stimuli between
bordering compartments. The correct quantitative handling of compartments is,
therefore, extremely important when modelling real biochemical systems. The
Bio-PEPA process algebra is equipped with the capability of explicitly defining
quantitative information such as compartment volumes and membrane surface
areas. Furthermore, the recent development of the Bio-PEPA Eclipse Plug-in
allows us to perform a correct stochastic simulation of multi-compartmental
models.
  Here we present a Bio-PEPA compartmental model of the cAMP/PKA/MAPK pathway.
We analyse the system using the Bio-PEPA Eclipse Plug-in and we show the
correctness of our model by comparison with an existing ODE model. Furthermore,
we perform computational experiments in order to investigate certain properties
of the pathway. Specifically, we focus on the system response to the inhibition
and strengthening of feedback loops and to the variation in the activity of key
pathway reactions and we observe how these modifications affect the behaviour
of the pathway. These experiments are useful to understand the control and
regulatory mechanisms of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4985</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4985</id><created>2009-11-25</created><authors><author><keyname>Dezani-Ciancaglini</keyname><forenames>Mariangiola</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Giannini</keyname><forenames>Paola</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; del Piemonte Orientale</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author></authors><title>A Type System for a Stochastic CLS</title><categories>cs.FL cs.PL q-bio.MN q-bio.QM</categories><acm-class>F.3.3; J.3; F.1.2</acm-class><journal-ref>EPTCS 11, 2009, pp. 91-105</journal-ref><doi>10.4204/EPTCS.11.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Stochastic Calculus of Looping Sequences is suitable to describe the
evolution of microbiological systems, taking into account the speed of the
described activities. We propose a type system for this calculus that models
how the presence of positive and negative catalysers can modify these speeds.
We claim that types are the right abstraction in order to represent the
interaction between elements without specifying exactly the element positions.
Our claim is supported through an example modelling the lactose operon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4986</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4986</id><created>2009-11-25</created><authors><author><keyname>Dinneen</keyname><forenames>Michael J.</forenames><affiliation>University of Auckland</affiliation></author><author><keyname>Kim</keyname><forenames>Yun-Bum</forenames><affiliation>University of Auckland</affiliation></author><author><keyname>Nicolescu</keyname><forenames>Radu</forenames><affiliation>University of Auckland</affiliation></author></authors><title>New Solutions to the Firing Squad Synchronization Problems for Neural
  and Hyperdag P Systems</title><categories>cs.CE cs.DC cs.NE</categories><acm-class>F.1.2; C.2.4</acm-class><journal-ref>EPTCS 11, 2009, pp. 107-122</journal-ref><doi>10.4204/EPTCS.11.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two uniform solutions to an open question: the Firing Squad
Synchronization Problem (FSSP), for hyperdag and symmetric neural P systems,
with anonymous cells. Our solutions take e_c+5 and 6e_c+7 steps, respectively,
where e_c is the eccentricity of the commander cell of the dag or digraph
underlying these P systems. The first and fast solution is based on a novel
proposal, which dynamically extends P systems with mobile channels. The second
solution is substantially longer, but is solely based on classical rules and
static channels. In contrast to the previous solutions, which work for
tree-based P systems, our solutions synchronize to any subset of the underlying
digraph; and do not require membrane polarizations or conditional rules, but
require states, as typically used in hyperdag and neural P systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4987</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4987</id><created>2009-11-25</created><authors><author><keyname>Freund</keyname><forenames>Rudolf</forenames><affiliation>Vienna University of Technology</affiliation></author><author><keyname>Kogler</keyname><forenames>Marian</forenames><affiliation>Vienna University of Technology</affiliation></author></authors><title>Drip and Mate Operations Acting in Test Tube Systems and Tissue-like P
  systems</title><categories>cs.CE</categories><journal-ref>EPTCS 11, 2009, pp. 123-135</journal-ref><doi>10.4204/EPTCS.11.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The operations drip and mate considered in (mem)brane computing resemble the
operations cut and recombination well known from DNA computing. We here
consider sets of vesicles with multisets of objects on their outside membrane
interacting by drip and mate in two different setups: in test tube systems, the
vesicles may pass from one tube to another one provided they fulfill specific
constraints; in tissue-like P systems, the vesicles are immediately passed to
specified cells after having undergone a drip or mate operation. In both
variants, computational completeness can be obtained, yet with different
constraints for the drip and mate operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4988</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4988</id><created>2009-11-25</created><authors><author><keyname>Gori</keyname><forenames>Roberta</forenames><affiliation>Dipartimento di informatica, Pisa.</affiliation></author><author><keyname>Levi</keyname><forenames>Francesca</forenames><affiliation>Dipartimento di informatica, Pisa</affiliation></author></authors><title>Abstract Interpretation for Probabilistic Termination of Biological
  Systems</title><categories>cs.LO cs.CE cs.FL q-bio.QM</categories><journal-ref>EPTCS 11, 2009, pp. 137-153</journal-ref><doi>10.4204/EPTCS.11.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper the authors applied the Abstract Interpretation approach
for approximating the probabilistic semantics of biological systems, modeled
specifically using the Chemical Ground Form calculus. The methodology is based
on the idea of representing a set of experiments, which differ only for the
initial concentrations, by abstracting the multiplicity of reagents present in
a solution, using intervals. In this paper, we refine the approach in order to
address probabilistic termination properties. More in details, we introduce a
refinement of the abstract LTS semantics and we abstract the probabilistic
semantics using a variant of Interval Markov Chains. The abstract probabilistic
model safely approximates a set of concrete experiments and reports
conservative lower and upper bounds for probabilistic termination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.4989</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.4989</id><created>2009-11-25</created><authors><author><keyname>Pinna</keyname><forenames>G. Michele</forenames></author><author><keyname>Saba</keyname><forenames>Andrea</forenames></author></authors><title>Dependencies and Simultaneity in Membrane Systems</title><categories>cs.CE cs.DC cs.LO</categories><acm-class>F.4.2; D.2.2</acm-class><journal-ref>EPTCS 11, 2009, pp. 155-169</journal-ref><doi>10.4204/EPTCS.11.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Membrane system computations proceed in a synchronous fashion: at each step
all the applicable rules are actually applied. Hence each step depends on the
previous one. This coarse view can be refined by looking at the dependencies
among rule occurrences, by recording, for an object, which was the a rule that
produced it and subsequently (in a later step), which was the a rule that
consumed it. In this paper we propose a way to look also at the other main
ingredient in membrane system computations, namely the simultaneity in the rule
applications. This is achieved using zero-safe nets that allows to synchronize
transitions, i.e., rule occurrences. Zero-safe nets can be unfolded into
occurrence nets in a classical way, and to this unfolding an event structure
can be associated. The capability of capturing simultaneity of zero-safe nets
is transferred on the level of event structure by adding a way to express which
events occur simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5017</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5017</id><created>2009-11-26</created><authors><author><keyname>Bae</keyname><forenames>Sang Won</forenames></author><author><keyname>Okamoto</keyname><forenames>Yoshio</forenames></author></authors><title>Querying Two Boundary Points for Shortest Paths in a Polygonal Domain</title><categories>cs.CG</categories><comments>12 pages, 3 figures, an extended abstract presented at ISAAC 2009</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variant of two-point Euclidean shortest path query problem:
given a polygonal domain, build a data structure for two-point shortest path
query, provided that query points always lie on the boundary of the domain. As
a main result, we show that a logarithmic-time query for shortest paths between
boundary points can be performed using O~ (n^5) preprocessing time and O(n^5)
space where n is the number of corners of the polygonal domain and the O~
notation suppresses the polylogarithmic factor. This is realized by observing a
connection between Davenport-Schinzel sequences and our problem in the
parameterized space. We also provide a tradeoff between space and query time; a
sublinear time query is possible using O(n^{3+epsilon}) space. Our approach
also extends to the case where query points should lie on a given set of line
segments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5018</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5018</id><created>2009-11-26</created><updated>2010-10-17</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Autosolvability of halting problem instances for instruction sequences</title><categories>cs.LO cs.PL</categories><comments>18 pages; notational mistakes in tables 5 and 6 corrected; erroneous
  definition in last paragraph of page 11 corrected</comments><report-no>PRG0914</report-no><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We position Turing's result regarding the undecidability of the halting
problem as a result about programs rather than machines. The mere requirement
that a program of a certain kind must solve the halting problem for all
programs of that kind leads to a contradiction in the case of a recent
unsolvability result regarding the halting problem for programs. In this paper,
we investigate this autosolvability requirement in a setting in which programs
take the form of instruction sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5026</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5026</id><created>2009-11-26</created><updated>2011-09-05</updated><authors><author><keyname>Kharitonov</keyname><forenames>Daniel</forenames></author></authors><title>Time-domain approach to energy efficiency in high-performance network
  element design</title><categories>cs.NI</categories><comments>Pre-print for publication at GlobeCom 2009 proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency is a corner stone of sustainability in data center and
high-performance networking. However, at present there is a notable structural
mismatch between network silicon development targets and network equipment
utilization patterns in the field. In particular, some aspects of network
energy utilization (eg load-proportional energy consumption) routinely stay out
of focus during system design and implementation. Drawing from hands-on
research and development in high-speed and grid networking, we identify a novel
approach to energy efficiency in network engineering. In this paper, we
demonstrate how the problem of efficient network system design can be dissected
into smaller sections based on timescales of traffic processing. The newly
proposed approach allows R&amp;D efforts to be tightly paired to resources and
sustainability targets to improve energy efficiency in many classes of network
and telecom devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5031</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5031</id><created>2009-11-26</created><updated>2010-04-18</updated><authors><author><keyname>Chowdhury</keyname><forenames>Shihabur Rahman</forenames></author><author><keyname>Hasan</keyname><forenames>Masud</forenames></author><author><keyname>Iqbal</keyname><forenames>Sumaiya</forenames></author><author><keyname>Rahman</keyname><forenames>M. Sohel</forenames></author></authors><title>An $O(n^2)$ Algorithm for Computing Longest Common Cyclic Subsequence</title><categories>cs.DS</categories><comments>This paper has been withdrawn by the author due to a crucial error in
  the proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\em longest common subsequence (LCS)} problem is a classic and
well-studied problem in computer science. LCS is a central problem in
stringology and finds broad applications in text compression, error-detecting
codes and biological sequence comparison. However, in numerous contexts, words
represent cyclic sequences of symbols and LCS must be generalized to consider
all circular shifts of the strings. This occurs especially in computational
biology when genetic material is sequenced form circular DNA or RNA molecules.
This initiates the problem of {\em longest common cyclic subsequence (LCCS)}
which finds the longest subsequence between all circular shifts of two strings.
In this paper, we give an $O(n^2)$ algorithm for solving LCCS problem where $n$
is the number of symbols in the strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5043</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5043</id><created>2009-11-26</created><authors><author><keyname>d'Amato</keyname><forenames>Claudia</forenames></author><author><keyname>Fanizzi</keyname><forenames>Nicola</forenames></author><author><keyname>Esposito</keyname><forenames>Floriana</forenames></author></authors><title>A Semantic Similarity Measure for Expressive Description Logics</title><categories>cs.AI cs.LO</categories><comments>13 pages, Appeared at CILC 2005, Convegno Italiano di Logica
  Computazionale also available at
  http://www.disp.uniroma2.it/CILC2005/downloads/papers/15.dAmato_CILC05.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A totally semantic measure is presented which is able to calculate a
similarity value between concept descriptions and also between concept
description and individual or between individuals expressed in an expressive
description logic. It is applicable on symbolic descriptions although it uses a
numeric approach for the calculus. Considering that Description Logics stand as
the theoretic framework for the ontological knowledge representation and
reasoning, the proposed measure can be effectively used for agglomerative and
divisional clustering task applied to the semantic web domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5046</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5046</id><created>2009-11-26</created><updated>2009-12-01</updated><authors><author><keyname>P&#xe9;rez-Iglesias</keyname><forenames>Joaqu&#xed;n</forenames></author><author><keyname>P&#xe9;rez-Ag&#xfc;era</keyname><forenames>Jos&#xe9; R.</forenames></author><author><keyname>Fresno</keyname><forenames>V&#xed;ctor</forenames></author><author><keyname>Feinstein</keyname><forenames>Yuval Z.</forenames></author></authors><title>Integrating the Probabilistic Models BM25/BM25F into Lucene</title><categories>cs.IR</categories><comments>Software can be downloaded from:
  http://nlp.uned.es/~jperezi/Lucene-BM25/</comments><acm-class>H.3.3; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the BM25 and BM25F implementation using the Lucene
Java Framework. Both models have stood out at TREC by their performance and are
considered as state-of-the-art in the IR community. BM25 is applied to
retrieval on plain text documents, that is for documents that do not contain
fields, while BM25F is applied to documents with structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5067</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5067</id><created>2009-11-26</created><authors><author><keyname>Cottatellucci</keyname><forenames>Laura</forenames></author><author><keyname>Mueller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Asynchronous CDMA Systems with Random Spreading-Part II: Design Criteria</title><categories>cs.IT math.IT math.PR</categories><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 4, pp.
  1498-1520, Apr. 2010</journal-ref><doi>10.1109/TIT.2010.2040898</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Totally asynchronous code-division multiple-access (CDMA) systems are
addressed. In Part I, the fundamental limits of asynchronous CDMA systems are
analyzed in terms of spectral efficiency and SINR at the output of the optimum
linear detector. The focus of Part II is the design of low-complexity
implementations of linear multiuser detectors in systems with many users that
admit a multistage representation, e.g. reduced rank multistage Wiener filters,
polynomial expansion detectors, weighted linear parallel interference
cancellers. The effects of excess bandwidth, chip-pulse shaping, and time delay
distribution on CDMA with suboptimum linear receiver structures are
investigated. Recursive expressions for universal weight design are given. The
performance in terms of SINR is derived in the large-system limit and the
performance improvement over synchronous systems is quantified. The
considerations distinguish between two ways of forming discrete-time
statistics: chip-matched filtering and oversampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5086</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5086</id><created>2009-11-26</created><updated>2011-06-13</updated><authors><author><keyname>Karavelas</keyname><forenames>Menelaos I.</forenames></author><author><keyname>Tzanaki</keyname><forenames>Eleni</forenames></author></authors><title>Convex hulls of spheres and convex hulls of convex polytopes lying on
  parallel hyperplanes</title><categories>cs.CG math.CO</categories><comments>22 pages, 5 figures, new proof of upper bound for the complexity of
  the convex hull of parallel polytopes (the new proof gives upper bounds for
  all face numbers of the convex hull of the parallel polytopes)</comments><msc-class>68U05 (Primary), 52B05, 52B11, 52C45 (Secondary)</msc-class><acm-class>F.2.2; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $\Sigma$ of spheres in $\mathbb{E}^d$, with $d\ge{}3$ and $d$
odd, having a fixed number of $m$ distinct radii $\rho_1,\rho_2,...,\rho_m$, we
show that the worst-case combinatorial complexity of the convex hull
$CH_d(\Sigma)$ of $\Sigma$ is
$\Theta(\sum_{1\le{}i\ne{}j\le{}m}n_in_j^{\lfloor\frac{d}{2}\rfloor})$, where
$n_i$ is the number of spheres in $\Sigma$ with radius $\rho_i$.
  To prove the lower bound, we construct a set of $\Theta(n_1+n_2)$ spheres in
$\mathbb{E}^d$, with $d\ge{}3$ odd, where $n_i$ spheres have radius $\rho_i$,
$i=1,2$, and $\rho_2\ne\rho_1$, such that their convex hull has combinatorial
complexity
$\Omega(n_1n_2^{\lfloor\frac{d}{2}\rfloor}+n_2n_1^{\lfloor\frac{d}{2}\rfloor})$.
Our construction is then generalized to the case where the spheres have
$m\ge{}3$ distinct radii.
  For the upper bound, we reduce the sphere convex hull problem to the problem
of computing the worst-case combinatorial complexity of the convex hull of a
set of $m$ $d$-dimensional convex polytopes lying on $m$ parallel hyperplanes
in $\mathbb{E}^{d+1}$, where $d\ge{}3$ odd, a problem which is of independent
interest. More precisely, we show that the worst-case combinatorial complexity
of the convex hull of a set $\{\mathcal{P}_1,\mathcal{P}_2,...,\mathcal{P}_m\}$
of $m$ $d$-dimensional convex polytopes lying on $m$ parallel hyperplanes of
$\mathbb{E}^{d+1}$ is
$O(\sum_{1\le{}i\ne{}j\le{}m}n_in_j^{\lfloor\frac{d}{2}\rfloor})$, where $n_i$
is the number of vertices of $\mathcal{P}_i$.
  We end with algorithmic considerations, and we show how our tight bounds for
the parallel polytope convex hull problem, yield tight bounds on the
combinatorial complexity of the Minkowski sum of two convex polytopes in
$\mathbb{E}^d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5094</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5094</id><created>2009-11-26</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author></authors><title>Faster FAST(Feedback Arc Set in Tournaments)</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm that finds a feedback arc set of size $k$ in a
tournament in time $n^{O(1)}2^{O(\sqrt{k})}$. This is asymptotically faster
than the running time of previously known algorithms for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5104</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5104</id><created>2009-11-26</created><updated>2009-12-30</updated><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>A Bayesian Rule for Adaptive Control based on Causal Interventions</title><categories>cs.AI cs.LG</categories><comments>AGI-2010. 6 pages, 2 figures</comments><journal-ref>AGI-2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Explaining adaptive behavior is a central problem in artificial intelligence
research. Here we formalize adaptive agents as mixture distributions over
sequences of inputs and outputs (I/O). Each distribution of the mixture
constitutes a `possible world', but the agent does not know which of the
possible worlds it is actually facing. The problem is to adapt the I/O stream
in a way that is compatible with the true world. A natural measure of
adaptation can be obtained by the Kullback-Leibler (KL) divergence between the
I/O distribution of the true world and the I/O distribution expected by the
agent that is uncertain about possible worlds. In the case of pure input
streams, the Bayesian mixture provides a well-known solution for this problem.
We show, however, that in the case of I/O streams this solution breaks down,
because outputs are issued by the agent itself and require a different
probabilistic syntax as provided by intervention calculus. Based on this
calculus, we obtain a Bayesian control rule that allows modeling adaptive
behavior with mixture distributions over I/O streams. This rule might allow for
a novel approach to adaptive control based on a minimum KL-principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5106</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5106</id><created>2009-11-26</created><updated>2009-12-30</updated><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>A conversion between utility and information</title><categories>cs.AI cs.IT math.IT</categories><comments>AGI-2010. 6 pages, 1 figure</comments><journal-ref>AGI-2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rewards typically express desirabilities or preferences over a set of
alternatives. Here we propose that rewards can be defined for any probability
distribution based on three desiderata, namely that rewards should be
real-valued, additive and order-preserving, where the latter implies that more
probable events should also be more desirable. Our main result states that
rewards are then uniquely determined by the negative information content. To
analyze stochastic processes, we define the utility of a realization as its
reward rate. Under this interpretation, we show that the expected utility of a
stochastic process is its negative entropy rate. Furthermore, we apply our
results to analyze agent-environment interactions. We show that the expected
utility that will actually be achieved by the agent is given by the negative
cross-entropy from the input-output (I/O) distribution of the coupled
interaction system and the agent's I/O distribution. Thus, our results allow
for an information-theoretic interpretation of the notion of utility and the
characterization of agent-environment interactions in terms of entropy
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5116</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5116</id><created>2009-11-26</created><authors><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Saclay - Ile de France, IDSL</affiliation></author></authors><title>Standardization of the formal representation of lexical information for
  NLP</title><categories>cs.CL</categories><proxy>ccsd hal-00436328</proxy><journal-ref>Dictionarie. An International Encyclopedia of Lexicography.
  Supplementary volume: Recent developments with special focus on computational
  lexicography (2010) -</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A survey of dictionary models and formats is presented as well as a
presentation of corresponding recent standardisation activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5143</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5143</id><created>2009-11-26</created><authors><author><keyname>Bateni</keyname><forenames>MohammadHossein</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author></authors><title>Approximation Schemes for Steiner Forest on Planar Graphs and Graphs of
  Bounded Treewidth</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first polynomial-time approximation scheme (PTAS) for the Steiner
forest problem on planar graphs and, more generally, on graphs of bounded
genus. As a first step, we show how to build a Steiner forest spanner for such
graphs. The crux of the process is a clustering procedure called
prize-collecting clustering that breaks down the input instance into separate
subinstances which are easier to handle; moreover, the terminals in different
subinstances are far from each other. Each subinstance has a relatively
inexpensive Steiner tree connecting all its terminals, and the subinstances can
be solved (almost) separately. Another building block is a PTAS for Steiner
forest on graphs of bounded treewidth. Surprisingly, Steiner forest is NP-hard
even on graphs of treewidth 3. Therefore, our PTAS for bounded treewidth graph
needs a nontrivial combination of approximation arguments and dynamic
programming on the tree decomposition. We further show that Steiner forest can
be solved in polynomial time for series-parallel graphs (graphs of treewidth at
most two) by a novel combination of dynamic programming and minimum cut
computations, completing our thorough complexity study of Steiner forest in the
range of bounded treewidth graphs, planar graphs, and bounded genus graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5153</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5153</id><created>2009-11-26</created><updated>2013-08-11</updated><authors><author><keyname>Doukeli</keyname><forenames>Aimilia P.</forenames></author><author><keyname>Lioumpas</keyname><forenames>Athanasios S.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Frangos</keyname><forenames>Panayiotis V.</forenames></author></authors><title>Self-Reference Ultra-Wideband Systems</title><categories>cs.NI</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Towards employing low complexity transceivers for signal reception in
Ultra-Wideband (UWB) systems, Transmitted Reference (TR) and Differential TR
(DTR) schemes have attracted researchers attention. In this letter, we
introduce an alternative, less complex scheme, called Self Reference (SR) UWB
transceiver, which uses a modified replica of the received signal itself as
reference pulse, resulting in double data rates compared to TR schemes.
Moreover, SR eliminates the need for delay lines at the receiver side, which
constitute a major drawback of the conventional TR and DTR schemes, while it
also requires no channel estimations, resulting in lower complexity
implementations and power savings. The performance of the SR scheme is
investigated in high-frequency (HF) channels, showing that it offers a better
or comparable performance to that of DTR, depending on the channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5157</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5157</id><created>2009-11-26</created><updated>2011-04-27</updated><authors><author><keyname>Prautzsch</keyname><forenames>Hartmut</forenames></author><author><keyname>Chen</keyname><forenames>Qi</forenames></author></authors><title>Analyzing Midpoint Subdivision</title><categories>cs.GR cs.CG</categories><comments>The paper was improved by adding more explanations and by adding an
  illustration of how the statements depend on each other. We combined a few
  theorems to simplify the structure of the paper and better described the
  meaning of the statements and how they fit into the overall proof. 24 pages,
  10 figures</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Midpoint subdivision generalizes the Lane-Riesenfeld algorithm for uniform
tensor product splines and can also be applied to non regular meshes. For
example, midpoint subdivision of degree 2 is a specific Doo-Sabin algorithm and
midpoint subdivision of degree 3 is a specific Catmull-Clark algorithm. In
2001, Zorin and Schroeder were able to prove C1-continuity for midpoint
subdivision surfaces analytically up to degree 9. Here, we develop general
analysis tools to show that the limiting surfaces under midpoint subdivision of
any degree &gt;= 2 are C1-continuous at their extraordinary points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5171</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5171</id><created>2009-11-26</created><authors><author><keyname>Thielemann</keyname><forenames>Henning</forenames></author></authors><title>Untangling Phase and Time in Monophonic Sounds</title><categories>cs.SD</categories><comments>16 pages, 22 figures</comments><doi>10.4236/jsip.2010.11001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are looking for a mathematical model of monophonic sounds with independent
time and phase dimensions. With such a model we can resynthesise a sound with
arbitrarily modulated frequency and progress of the timbre. We propose such a
model and show that it exactly fulfils some natural properties, like a kind of
time-invariance, robustness against non-harmonic frequencies, envelope
preservation, and inclusion of plain resampling as a special case. The
resulting algorithm is efficient and allows to process data in a streaming
manner with phase and shape modulation at sample rate, what we demonstrate with
an implementation in the functional language Haskell. It allows a wide range of
applications, namely pitch shifting and time scaling, creative FM synthesis
effects, compression of monophonic sounds, generating loops for sampled sounds,
synthesise sounds similar to wavetable synthesis, or making ultrasound audible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5203</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5203</id><created>2009-11-27</created><authors><author><keyname>Qi</keyname><forenames>Xiaochu</forenames></author></authors><title>An Implementation of the Language Lambda Prolog Organized around
  Higher-Order Pattern Unification</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis concerns the implementation of Lambda Prolog, a higher-order
logic programming language that supports the lambda-tree syntax approach to
representing and manipulating formal syntactic objects. Lambda Prolog achieves
its functionality by extending a Prolog-like language by using typed lambda
terms as data structures that it then manipulates via higher-order unification
and some new program-level abstraction mechanisms. These additional features
raise new implementation questions that must be adequately addressed for Lambda
Prolog to be an effective programming tool. We consider these questions here,
providing eventually a virtual machine and compilation based realization. A key
idea is the orientation of the computation model of Lambda Prolog around a
restricted version of higher-order unification with nice algorithmic properties
and appearing to encompass most interesting applications. Our virtual machine
embeds a treatment of this form of unification within the structure of the
Warren Abstract Machine that is used in traditional Prolog implementations.
Along the way, we treat various auxiliary issues such as the low-level
representation of lambda terms, the implementation of reduction on such terms
and the optimized processing of types in computation. We also develop an actual
implementation of Lambda Prolog called Teyjus Version 2. A characteristic of
this system is that it realizes an emulator for the virtual machine in the C
language a compiler in the OCaml language. We present a treatment of the
software issues that arise from this kind of mixing of languages within one
system and we discuss issues relevant to the portability of our virtual machine
emulator across arbitrary architectures. Finally, we assess the the efficacy of
our various design ideas through experiments carried out using the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5230</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5230</id><created>2009-11-27</created><authors><author><keyname>Oiwa</keyname><forenames>Yutaka</forenames></author><author><keyname>Watanabe</keyname><forenames>Hajime</forenames></author><author><keyname>Takagi</keyname><forenames>Hiromitsu</forenames></author></authors><title>PAKE-based mutual HTTP authentication for preventing phishing attacks</title><categories>cs.CR cs.NI</categories><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new password-based mutual authentication protocol for
Web systems which prevents various kinds of phishing attacks. This protocol
provides a protection of user's passwords against any phishers even if
dictionary attack is employed, and prevents phishers from imitating a false
sense of successful authentication to users. The protocol is designed
considering interoperability with many recent Web applications which requires
many features which current HTTP authentication does not provide. The protocol
is proposed as an Internet Draft submitted to IETF, and implemented in both
server side (as an Apache extension) and client side (as a Mozilla-based
browser and an IE-based one). The paper also proposes a new user-interface for
this protocol which is always distinguishable from fake dialogs provided by
phishers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5242</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5242</id><created>2009-11-27</created><updated>2010-01-04</updated><authors><author><keyname>Bailer-Jones</keyname><forenames>C. A. L.</forenames><affiliation>Max Planck Institute for Astronomy, Heidelberg</affiliation></author></authors><title>The ILIUM forward modelling algorithm for multivariate parameter
  estimation and its application to derive stellar parameters from Gaia
  spectrophotometry</title><categories>astro-ph.IM astro-ph.GA astro-ph.SR cs.NE stat.ML</categories><comments>MNRAS, in press. This revision corrects a few minor errors and typos.
  A better formatted version for A4 paper is available at
  http://www.mpia.de/home/calj/ilium.pdf</comments><doi>10.1111/j.1365-2966.2009.16125.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I introduce an algorithm for estimating parameters from multidimensional data
based on forward modelling. In contrast to many machine learning approaches it
avoids fitting an inverse model and the problems associated with this. The
algorithm makes explicit use of the sensitivities of the data to the
parameters, with the goal of better treating parameters which only have a weak
impact on the data. The forward modelling approach provides uncertainty (full
covariance) estimates in the predicted parameters as well as a goodness-of-fit
for observations. I demonstrate the algorithm, ILIUM, with the estimation of
stellar astrophysical parameters (APs) from simulations of the low resolution
spectrophotometry to be obtained by Gaia. The AP accuracy is competitive with
that obtained by a support vector machine. For example, for zero extinction
stars covering a wide range of metallicity, surface gravity and temperature,
ILIUM can estimate Teff to an accuracy of 0.3% at G=15 and to 4% for (lower
signal-to-noise ratio) spectra at G=20. [Fe/H] and logg can be estimated to
accuracies of 0.1-0.4dex for stars with G&lt;=18.5. If extinction varies a priori
over a wide range (Av=0-10mag), then Teff and Av can be estimated quite
accurately (3-4% and 0.1-0.2mag respectively at G=15), but there is a strong
and ubiquitous degeneracy in these parameters which limits our ability to
estimate either accurately at faint magnitudes. Using the forward model we can
map these degeneracies (in advance), and thus provide a complete probability
distribution over solutions. (Abridged)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5246</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5246</id><created>2009-11-27</created><updated>2009-12-01</updated><authors><author><keyname>D&#xfc;ntsch</keyname><forenames>Ivo</forenames></author><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author></authors><title>Complex Algebras of Arithmetic</title><categories>cs.LO</categories><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An 'arithmetic circuit' is a labeled, acyclic directed graph specifying a
sequence of arithmetic and logical operations to be performed on sets of
natural numbers. Arithmetic circuits can also be viewed as the elements of the
smallest subalgebra of the complex algebra of the semiring of natural numbers.
In the present paper, we investigate the algebraic structure of complex
algebras of natural numbers, and make some observations regarding the
complexity of various theories of such algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5258</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5258</id><created>2009-11-27</created><authors><author><keyname>Kamalian</keyname><forenames>R. R.</forenames></author><author><keyname>Petrosyan</keyname><forenames>P. A.</forenames></author></authors><title>A note on upper bounds for the maximum span in interval edge colorings
  of graphs</title><categories>cs.DM</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An edge coloring of a graph $G$ with colors $1,2,..., t$ is called an
interval $t$-coloring if for each $i\in \{1,2,...,t\}$ there is at least one
edge of $G$ colored by $i$, the colors of edges incident to any vertex of $G$
are distinct and form an interval of integers. In 1994 Asratian and Kamalian
proved that if a connected graph $G$ admits an interval $t$-coloring, then
$t\leq (d+1) (\Delta -1) +1$, and if $G$ is also bipartite, then this upper
bound can be improved to $t\leq d(\Delta -1) +1$, where $\Delta$ is the maximum
degree in $G$ and $d$ is the diameter of $G$. In this paper we show that these
upper bounds can not be significantly improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5262</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5262</id><created>2009-11-27</created><authors><author><keyname>van Son</keyname><forenames>R. J. J. H.</forenames></author></authors><title>Quantifying Resource Use in Computations</title><categories>cs.CC cs.CR</categories><comments>26 pages, no figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  It is currently not possible to quantify the resources needed to perform a
computation. As a consequence, it is not possible to reliably evaluate the
hardware resources needed for the application of algorithms or the running of
programs. This is apparent in both computer science, for instance, in
cryptanalysis, and in neuroscience, for instance, comparative neuro-anatomy. A
System versus Environment game formalism is proposed based on Computability
Logic that allows to define a computational work function that describes the
theoretical and physical resources needed to perform any purely algorithmic
computation. Within this formalism, the cost of a computation is defined as the
sum of information storage over the steps of the computation. The size of the
computational device, eg, the action table of a Universal Turing Machine, the
number of transistors in silicon, or the number and complexity of synapses in a
neural net, is explicitly included in the computational cost. The proposed cost
function leads in a natural way to known computational trade-offs and can be
used to estimate the computational capacity of real silicon hardware and neural
nets. The theory is applied to a historical case of 56 bit DES key recovery, as
an example of application to cryptanalysis. Furthermore, the relative
computational capacities of human brain neurons and the C. elegans nervous
system are estimated as an example of application to neural nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5296</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5296</id><created>2009-11-27</created><authors><author><keyname>Aldous</keyname><forenames>David J.</forenames></author></authors><title>Which Connected Spatial Networks on Random Points have Linear
  Route-Lengths?</title><categories>math.PR cs.DM</categories><msc-class>60D05; 90B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a model of a connected network on random points in the plane, one expects
that the mean length of the shortest route between vertices at distance $r$
apart should grow only as $O(r)$ as $r \to \infty$, but this is not always easy
to verify. We give a general sufficient condition for such linearity, in the
setting of a Poisson point process. In a $L \times L$ square, define a
subnetwork $\GG_L$ to have the edges which are present regardless of the
configuration outside the square; the condition is that the largest component
of $\GG_L$ should contain a proportion $1 - o(1)$ of the vertices, as $L \to
\infty$. The proof is by comparison with oriented percolation. We show that the
general result applies to the relative neighborhood graph, and establishing the
linearity property for this network immediately implies it for a large family
of proximity graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5300</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5300</id><created>2009-11-27</created><updated>2010-10-29</updated><authors><author><keyname>Cubitt</keyname><forenames>Toby S.</forenames></author><author><keyname>Leung</keyname><forenames>Debbie</forenames></author><author><keyname>Matthews</keyname><forenames>William</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Improving zero-error classical communication with entanglement</title><categories>quant-ph cs.IT math.IT</categories><comments>6 pages, 2 figures. Version 2 is the same as the journal version plus
  figure 1 and the non-signalling box example</comments><report-no>NSF-KITP-09-210</report-no><journal-ref>Phys. Rev. Lett. 104, 230503 (2010)</journal-ref><doi>10.1103/PhysRevLett.104.230503</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given one or more uses of a classical channel, only a certain number of
messages can be transmitted with zero probability of error. The study of this
number and its asymptotic behaviour constitutes the field of classical
zero-error information theory, the quantum generalisation of which has started
to develop recently. We show that, given a single use of certain classical
channels, entangled states of a system shared by the sender and receiver can be
used to increase the number of (classical) messages which can be sent with no
chance of error. In particular, we show how to construct such a channel based
on any proof of the Bell-Kochen-Specker theorem. This is a new example of the
use of quantum effects to improve the performance of a classical task. We
investigate the connection between this phenomenon and that of
``pseudo-telepathy'' games. The use of generalised non-signalling correlations
to assist in this task is also considered. In this case, a particularly elegant
theory results and, remarkably, it is sometimes possible to transmit
information with zero-error using a channel with no unassisted zero-error
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5372</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5372</id><created>2009-11-27</created><authors><author><keyname>Turaga</keyname><forenames>Srinivas C.</forenames></author><author><keyname>Briggman</keyname><forenames>Kevin L.</forenames></author><author><keyname>Helmstaedter</keyname><forenames>Moritz</forenames></author><author><keyname>Denk</keyname><forenames>Winfried</forenames></author><author><keyname>Seung</keyname><forenames>H. Sebastian</forenames></author></authors><title>Maximin affinity learning of image segmentation</title><categories>cs.CV cs.AI cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images can be segmented by first using a classifier to predict an affinity
graph that reflects the degree to which image pixels must be grouped together
and then partitioning the graph to yield a segmentation. Machine learning has
been applied to the affinity classifier to produce affinity graphs that are
good in the sense of minimizing edge misclassification rates. However, this
error measure is only indirectly related to the quality of segmentations
produced by ultimately partitioning the affinity graph. We present the first
machine learning algorithm for training a classifier to produce affinity graphs
that are good in the sense of producing segmentations that directly minimize
the Rand index, a well known segmentation performance measure. The Rand index
measures segmentation performance by quantifying the classification of the
connectivity of image pixel pairs after segmentation. By using the simple graph
partitioning algorithm of finding the connected components of the thresholded
affinity graph, we are able to train an affinity classifier to directly
minimize the Rand index of segmentations resulting from the graph partitioning.
Our learning algorithm corresponds to the learning of maximin affinities
between image pixel pairs, which are predictive of the pixel-pair connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5378</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5378</id><created>2009-11-28</created><authors><author><keyname>Odumuyiwa</keyname><forenames>Victor</forenames><affiliation>LORIA</affiliation></author></authors><title>De la recherche sociale d'information \`a la recherche collaborative
  d'information</title><categories>cs.IR</categories><proxy>ccsd inria-00436766</proxy><journal-ref>7\`eme colloque du chapitre fran\c{c}ais de l'ISKO, Lyon : France
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explain social information retrieval (SIR) and
collaborative information retrieval (CIR). We see SIR as a way of knowing who
to collaborate with in resolving an information problem while CIR entails the
process of mutual understanding and solving of an information problem among
collaborators. We are interested in the transition from SIR to CIR hence we
developed a communication model to facilitate knowledge sharing during CIR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5384</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5384</id><created>2009-11-30</created><authors><author><keyname>Crowston</keyname><forenames>Robert</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author></authors><title>Note on Max Lin-2 above Average</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Max Lin-2 problem we are given a system $S$ of $m$ linear equations in
$n$ variables over $\mathbb{F}_2$ in which Equation $j$ is assigned a positive
integral weight $w_j$ for each $j$. We wish to find an assignment of values to
the variables which maximizes the total weight of satisfied equations. This
problem generalizes Max Cut. The expected weight of satisfied equations is
$W/2$, where $W=w_1+... +w_m$; $W/2$ is a tight lower bound on the optimal
solution of Max Lin-2.
  Mahajan et al. (J. Comput. Syst. Sci. 75, 2009) stated the following
parameterized version of Max Lin-2: decide whether there is an assignment of
values to the variables that satisfies equations of total weight at least
$W/2+k$, where $k$ is the parameter. They asked whether this parameterized
problem is fixed-parameter tractable, i.e., can be solved in time
$f(k)(nm)^{O(1)}$, where $f(k)$ is an arbitrary computable function in $k$
only. Their question remains open, but using some probabilistic inequalities
and, in one case, a Fourier analysis inequality, Gutin et al. (IWPEC 2009)
proved that the problem is fixed-parameter tractable in three special cases.
  In this paper we significantly extend two of the three special cases using
only tools from combinatorics. We show that one of our results can be used to
obtain a combinatorial proof that another problem from Mahajan et al. (J.
Comput. Syst. Sci. 75, 2009), Max $r$-SAT above the Average, is fixed-parameter
tractable for each $r\ge 2.$ Note that Max $r$-SAT above the Average has been
already shown to be fixed-parameter tractable by Alon et al. (SODA 2010), but
the paper used the approach of Gutin et al. (IWPEC 2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5385</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5385</id><created>2009-11-28</created><authors><author><keyname>Cottatellucci</keyname><forenames>Laura</forenames></author><author><keyname>Mueller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Asynchronous CDMA Systems with Random Spreading-Part I: Fundamental
  Limits</title><categories>cs.IT math.IT math.PR</categories><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 4, pp.
  1477-1497, Apr. 2010</journal-ref><doi>10.1109/TIT.2010.2040890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral efficiency for asynchronous code division multiple access (CDMA)
with random spreading is calculated in the large system limit allowing for
arbitrary chip waveforms and frequency-flat fading. Signal to interference and
noise ratios (SINRs) for suboptimal receivers, such as the linear minimum mean
square error (MMSE) detectors, are derived. The approach is general and
optionally allows even for statistics obtained by under-sampling the received
signal.
  All performance measures are given as a function of the chip waveform and the
delay distribution of the users in the large system limit. It turns out that
synchronizing users on a chip level impairs performance for all chip waveforms
with bandwidth greater than the Nyquist bandwidth, e.g., positive roll-off
factors. For example, with the pulse shaping demanded in the UMTS standard,
user synchronization reduces spectral efficiency up to 12% at 10 dB normalized
signal-to-noise ratio. The benefits of asynchronism stem from the finding that
the excess bandwidth of chip waveforms actually spans additional dimensions in
signal space, if the users are de-synchronized on the chip-level. The analysis
of linear MMSE detectors shows that the limiting interference effects can be
decoupled both in the user domain and in the frequency domain such that the
concept of the effective interference spectral density arises. This generalizes
and refines Tse and Hanly's concept of effective interference.
  In Part II, the analysis is extended to any linear detector that admits a
representation as multistage detector and guidelines for the design of low
complexity multistage detectors with universal weights are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5394</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5394</id><created>2009-11-28</created><updated>2010-12-10</updated><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author></authors><title>Covering rough sets based on neighborhoods: An approach without using
  neighborhoods</title><categories>cs.AI</categories><comments>13 pages; to appear in International Journal of Approximate Reasoning</comments><journal-ref>International Journal of Approximate Reasoning, 52(3): 461-472,
  2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Rough set theory, a mathematical tool to deal with inexact or uncertain
knowledge in information systems, has originally described the indiscernibility
of elements by equivalence relations. Covering rough sets are a natural
extension of classical rough sets by relaxing the partitions arising from
equivalence relations to coverings. Recently, some topological concepts such as
neighborhood have been applied to covering rough sets. In this paper, we
further investigate the covering rough sets based on neighborhoods by
approximation operations. We show that the upper approximation based on
neighborhoods can be defined equivalently without using neighborhoods. To
analyze the coverings themselves, we introduce unary and composition operations
on coverings. A notion of homomorphismis provided to relate two covering
approximation spaces. We also examine the properties of approximations
preserved by the operations and homomorphisms, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5395</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5395</id><created>2009-11-28</created><updated>2010-05-25</updated><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author></authors><title>An axiomatic approach to the roughness measure of rough sets</title><categories>cs.AI</categories><comments>to appear in the Fundamenta Informaticae</comments><journal-ref>Fundamenta Informaticae, 109(4): 463-480, 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In Pawlak's rough set theory, a set is approximated by a pair of lower and
upper approximations. To measure numerically the roughness of an approximation,
Pawlak introduced a quantitative measure of roughness by using the ratio of the
cardinalities of the lower and upper approximations. Although the roughness
measure is effective, it has the drawback of not being strictly monotonic with
respect to the standard ordering on partitions. Recently, some improvements
have been made by taking into account the granularity of partitions. In this
paper, we approach the roughness measure in an axiomatic way. After
axiomatically defining roughness measure and partition measure, we provide a
unified construction of roughness measure, called strong Pawlak roughness
measure, and then explore the properties of this measure. We show that the
improved roughness measures in the literature are special instances of our
strong Pawlak roughness measure and introduce three more strong Pawlak
roughness measures as well. The advantage of our axiomatic approach is that
some properties of a roughness measure follow immediately as soon as the
measure satisfies the relevant axiomatic definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5404</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5404</id><created>2009-11-28</created><authors><author><keyname>Chowdhary</keyname><forenames>Atul</forenames></author><author><keyname>Agrawal</keyname><forenames>Vivek</forenames></author><author><keyname>Karmakar</keyname><forenames>Subhajit</forenames></author><author><keyname>Sarkar</keyname><forenames>Sandip</forenames></author></authors><title>Laser Actuated Presentation System</title><categories>cs.HC cs.CV</categories><comments>7 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here a pattern sensitive PowerPoint presentation scheme. The
presentation is actuated by simple patterns drawn on the presentation screen by
a laser pointer. A specific pattern corresponds to a particular command
required to operate the presentation. Laser spot on the screen is captured by a
RGB webcam with a red filter mounted, and its location is identified at the
blue layer of each captured frame by estimating the mean position of the pixels
whose intensity is above a given threshold value. Measured Reliability,
Accuracy and Latency of our system are 90%, 10 pixels (in the worst case) and
38 ms respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5425</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5425</id><created>2009-11-28</created><authors><author><keyname>Cieslinski</keyname><forenames>Jan L.</forenames></author></authors><title>Comment on `conservative discretizations of the Kepler motion'</title><categories>math-ph cs.NA math.MP math.NA physics.space-ph</categories><comments>6 pages</comments><doi>10.1088/1751-8113/43/22/228001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the exact integrator for the classical Kepler motion, recently
found by Kozlov ({\it J. Phys. A: Math. Theor.\} {\bf 40} (2007) 4529-4539),
can be derived in a simple natural way (using well known exact discretization
of the harmonic oscillator). We also turn attention on important earlier
references, where the exact discretization of the 4-dimensional isotropic
harmonic oscillator has been applied to the perturbed Kepler problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5438</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5438</id><created>2009-11-28</created><authors><author><keyname>Leidner</keyname><forenames>Jochen L.</forenames></author><author><keyname>Berosik</keyname><forenames>Gary</forenames></author></authors><title>Building and Installing a Hadoop/MapReduce Cluster from Commodity
  Components</title><categories>cs.DC</categories><comments>Technical Report; 15 pages, 1 figure</comments><acm-class>C.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This tutorial presents a recipe for the construction of a compute cluster for
processing large volumes of data, using cheap, easily available personal
computer hardware (Intel/AMD based PCs) and freely available open source
software (Ubuntu Linux, Apache Hadoop).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5444</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5444</id><created>2009-11-28</created><authors><author><keyname>Carbone</keyname><forenames>Marco</forenames><affiliation>IT University of Copenhagen</affiliation></author><author><keyname>Guttman</keyname><forenames>Joshua</forenames><affiliation>Worcester Polytechnic Institute</affiliation></author></authors><title>Choreographies with Secure Boxes and Compromised Principals</title><categories>cs.CR cs.DC cs.PL</categories><journal-ref>EPTCS 12, 2009, pp. 1-15</journal-ref><doi>10.4204/EPTCS.12.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We equip choreography-level session descriptions with a simple abstraction of
a security infrastructure. Message components may be enclosed within (possibly
nested) &quot;boxes&quot; annotated with the intended source and destination of those
components. The boxes are to be implemented with cryptography. Strand spaces
provide a semantics for these choreographies, in which some roles may be played
by compromised principals. A skeleton is a partially ordered structure
containing local behaviors (strands) executed by regular (non-compromised)
principals. A skeleton is realized if it contains enough regular strands so
that it could actually occur, in combination with any possible activity of
compromised principals. It is delivery guaranteed (DG) realized if, in
addition, every message transmitted to a regular participant is also delivered.
We define a novel transition system on skeletons, in which the steps add
regular strands. These steps solve tests, i.e. parts of the skeleton that could
not occur without additional regular behavior. We prove three main results
about the transition system. First, each minimal DG realized skeleton is
reachable, using the transition system, from any skeleton it embeds. Second, if
no step is possible from a skeleton A, then A is DG realized. Finally, if a DG
realized B is accessible from A, then B is minimal. Thus, the transition system
provides a systematic way to construct the possible behaviors of the
choreography, in the presence of compromised principals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5445</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5445</id><created>2009-11-28</created><authors><author><keyname>Clarke</keyname><forenames>Dave</forenames><affiliation>Dept. Computer Science, Katholieke Universiteit Leuven</affiliation></author><author><keyname>Proen&#xe7;a</keyname><forenames>Jos&#xe9;</forenames><affiliation>CWI</affiliation></author></authors><title>Coordination via Interaction Constraints I: Local Logic</title><categories>cs.LO</categories><journal-ref>EPTCS 12, 2009, pp. 17-39</journal-ref><doi>10.4204/EPTCS.12.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wegner describes coordination as constrained interaction. We take this
approach literally and define a coordination model based on interaction
constraints and partial, iterative and interactive constraint satisfaction. Our
model captures behaviour described in terms of synchronisation and data flow
constraints, plus various modes of interaction with the outside world provided
by external constraint symbols, on-the-fly constraint generation, and
coordination variables. Underlying our approach is an engine performing
(partial) constraint satisfaction of the sets of constraints. Our model extends
previous work on three counts: firstly, a more advanced notion of external
interaction is offered; secondly, our approach enables local satisfaction of
constraints with appropriate partial solutions, avoiding global synchronisation
over the entire constraints set; and, as a consequence, constraint satisfaction
can finally occur concurrently, and multiple parts of a set of constraints can
be solved and interact with the outside world in an asynchronous manner, unless
synchronisation is required by the constraints. This paper describes the
underlying logic, which enables a notion of local solution, and relates this
logic to the more global approach of our previous work based on classical
logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5446</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5446</id><created>2009-11-29</created><authors><author><keyname>Jaber</keyname><forenames>Mohamad</forenames><affiliation>VERIMAG, Centre &#xc9;quation</affiliation></author><author><keyname>Basu</keyname><forenames>Ananda</forenames><affiliation>VERIMAG, Centre &#xc9;quation</affiliation></author><author><keyname>Bliudze</keyname><forenames>Simon</forenames><affiliation>CEA, LIST</affiliation></author></authors><title>Symbolic Implementation of Connectors in BIP</title><categories>cs.SE cs.LO</categories><journal-ref>EPTCS 12, 2009, pp. 41-55</journal-ref><doi>10.4204/EPTCS.12.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BIP is a component framework for constructing systems by superposing three
layers of modeling: Behavior, Interaction, and Priority. Behavior is
represented by labeled transition systems communicating through ports.
Interactions are sets of ports. A synchronization between components is
possible through the interactions specified by a set of connectors. When
several interactions are possible, priorities allow to restrict the
non-determinism by choosing an interaction, which is maximal according to some
given strict partial order.
  The BIP component framework has been implemented in a language and a
tool-set. The execution of a BIP program is driven by a dedicated engine, which
has access to the set of connectors and priority model of the program. A key
performance issue is the computation of the set of possible interactions of the
BIP program from a given state.
  Currently, the choice of the interaction to be executed involves a costly
exploration of enumerative representations for connectors. This leads to a
considerable overhead in execution times. In this paper, we propose a symbolic
implementation of the execution model of BIP, which drastically reduces this
overhead. The symbolic implementation is based on computing boolean
representation for components, connectors, and priorities with an existing BDD
package.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5447</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5447</id><created>2009-11-28</created><authors><author><keyname>Krause</keyname><forenames>Christian</forenames><affiliation>CWI</affiliation></author></authors><title>Integrated Structure and Semantics for Reo Connectors and Petri Nets</title><categories>cs.LO</categories><journal-ref>EPTCS 12, 2009, pp. 57-69</journal-ref><doi>10.4204/EPTCS.12.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an integrated structural and behavioral model of
Reo connectors and Petri nets, allowing a direct comparison of the two
concurrency models. For this purpose, we introduce a notion of connectors which
consist of a number of interconnected, user-defined primitives with fixed
behavior. While the structure of connectors resembles hypergraphs, their
semantics is given in terms of so-called port automata. We define both models
in a categorical setting where composition operations can be elegantly defined
and integrated. Specifically, we formalize structural gluings of connectors as
pushouts, and joins of port automata as pullbacks. We then define a semantical
functor from the connector to the port automata category which preserves this
composition. We further show how to encode Reo connectors and Petri nets into
this model and indicate applications to dynamic reconfigurations modeled using
double pushout graph transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5449</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5449</id><created>2009-11-28</created><authors><author><keyname>Padovani</keyname><forenames>Luca</forenames><affiliation>University of Urbino</affiliation></author></authors><title>Session Types at the Mirror</title><categories>cs.PL cs.DC</categories><journal-ref>EPTCS 12, 2009, pp. 71-86</journal-ref><doi>10.4204/EPTCS.12.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We (re)define session types as projections of process behaviors with respect
to the communication channels they use. In this setting, we give session types
a semantics based on fair testing. The outcome is a unified theory of
behavioral types that shares common aspects with conversation types and that
encompass features of both dyadic and multi-party session types. The point of
view we provide sheds light on the nature of session types and gives us a
chance to reason about them in a framework where every notion, from
well-typedness to the subtyping relation between session types, is semantically
-rather than syntactically- grounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5459</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5459</id><created>2009-11-28</created><updated>2010-07-22</updated><authors><author><keyname>Norton</keyname><forenames>Graham H.</forenames></author></authors><title>Shortest Two-way Linear Recurrences</title><categories>cs.IT cs.SC math.IT</categories><comments>This paper has been withdrawn by the author as the proof of Part (b)
  of Theorem 4.10(ii) is incorrect</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $s$ be a finite sequence over a field of length $n$. It is well-known
that if $s$ satisfies a linear recurrence of order $d$ with non-zero constant
term, then the reverse of $s$ also satisfies a recurrence of order $d$ (with
coefficients in reverse order). A recent article of A. Salagean proposed an
algorithm to find such a shortest 'two-way' recurrence -- which may be longer
than a linear recurrence for $s$ of shortest length $\LC_n$.
  We give a new and simpler algorithm to compute a shortest two-way linear
recurrence. First we show that the pairs of polynomials we use to construct a
minimal polynomial iteratively are always relatively prime; we also give the
extended multipliers. Then we combine degree lower bounds with a
straightforward rewrite of a published algorithm due to the author to obtain
our simpler algorithm. The increase in shortest length is
$\max\{n+1-2\LC_n,0\}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5462</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5462</id><created>2009-11-29</created><authors><author><keyname>Hosseini</keyname><forenames>Mahdi S.</forenames></author><author><keyname>Araabi</keyname><forenames>Babak N.</forenames></author><author><keyname>Soltanian-Zadeh</keyname><forenames>Hamid</forenames></author></authors><title>Pigment Melanin: Pattern for Iris Recognition</title><categories>cs.CV</categories><comments>To be Published on Special Issue on Biometrics, IEEE Transaction on
  Instruments and Measurements, Volume 59, Issue number 4, April 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognition of iris based on Visible Light (VL) imaging is a difficult
problem because of the light reflection from the cornea. Nonetheless, pigment
melanin provides a rich feature source in VL, unavailable in Near-Infrared
(NIR) imaging. This is due to biological spectroscopy of eumelanin, a chemical
not stimulated in NIR. In this case, a plausible solution to observe such
patterns may be provided by an adaptive procedure using a variational technique
on the image histogram. To describe the patterns, a shape analysis method is
used to derive feature-code for each subject. An important question is how much
the melanin patterns, extracted from VL, are independent of iris texture in
NIR. With this question in mind, the present investigation proposes fusion of
features extracted from NIR and VL to boost the recognition performance. We
have collected our own database (UTIRIS) consisting of both NIR and VL images
of 158 eyes of 79 individuals. This investigation demonstrates that the
proposed algorithm is highly sensitive to the patterns of cromophores and
improves the iris recognition rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5486</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5486</id><created>2009-11-29</created><authors><author><keyname>Zhang</keyname><forenames>Jinshan</forenames></author><author><keyname>Liang</keyname><forenames>Heng</forenames></author><author><keyname>Bai</keyname><forenames>Fengshan</forenames></author></authors><title>Approximating Partition Functions of Two-State Spin Systems</title><categories>cs.DM</categories><comments>15pages</comments><acm-class>G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-state spin systems is a classical topic in statistical physics. We
consider the problem of computing the partition function of the systems on a
bounded degree graph. Based on the self-avoiding tree, we prove the systems
exhibits strong correlation decay under the condition that the absolute value
of &quot;inverse temperature&quot; is small. Due to strong correlation decay property, an
FPTAS for the partition function is presented under the same condition. This
condition is sharp for Ising model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5487</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5487</id><created>2009-11-29</created><authors><author><keyname>Zhang</keyname><forenames>Jinshan</forenames></author><author><keyname>Liang</keyname><forenames>Heng</forenames></author><author><keyname>Bai</keyname><forenames>Fengshan</forenames></author></authors><title>Strong Spatial Mixing for Binary Markov Random Fields</title><categories>cs.IT cs.DM math.IT</categories><comments>13pages</comments><acm-class>G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gibbs distribution of binary Markov random fields on a sparse on average
graph is considered in this paper. The strong spatial mixing is proved under
the condition that the `external field' is uniformly large or small. Such
condition on `external field' is meaningful in physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5498</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5498</id><created>2009-11-30</created><updated>2010-03-11</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>The complexity of the normal surface solution space</title><categories>math.GT cs.CG</categories><comments>Extended abstract (i.e., conference-style), 14 pages, 8 figures, 2
  tables; v2: added minor clarifications</comments><acm-class>F.2.2; G.2.1</acm-class><journal-ref>SCG '10: Proceedings of the Twenty-Sixth Annual Symposium on
  Computational Geometry, ACM, 2010, pp. 201-209</journal-ref><doi>10.1145/1810959.1810995</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normal surface theory is a central tool in algorithmic three-dimensional
topology, and the enumeration of vertex normal surfaces is the computational
bottleneck in many important algorithms. However, it is not well understood how
the number of such surfaces grows in relation to the size of the underlying
triangulation. Here we address this problem in both theory and practice. In
theory, we tighten the exponential upper bound substantially; furthermore, we
construct pathological triangulations that prove an exponential bound to be
unavoidable. In practice, we undertake a comprehensive analysis of millions of
triangulations and find that in general the number of vertex normal surfaces is
remarkably small, with strong evidence that our pathological triangulations may
in fact be the worst case scenarios. This analysis is the first of its kind,
and the striking behaviour that we observe has important implications for the
feasibility of topological algorithms in three dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5508</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5508</id><created>2009-11-29</created><updated>2010-11-20</updated><authors><author><keyname>Forney</keyname><forenames>G. David</forenames><suffix>Jr</suffix></author></authors><title>Codes on graphs: Duality and MacWilliams identities</title><categories>cs.IT math.IT</categories><comments>30 pages, 20 figures. Accepted for IEEE Transactions on Information
  Theory. Preliminary versions presented at IEEE Information Theory Workshop,
  Taormina, Italy, October 2009 and 2010 IEEE International Symposium on
  Information Theory, Austin, TX, June 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conceptual framework involving partition functions of normal factor graphs
is introduced, paralleling a similar recent development by Al-Bashabsheh and
Mao. The partition functions of dual normal factor graphs are shown to be a
Fourier transform pair, whether or not the graphs have cycles. The original
normal graph duality theorem follows as a corollary. Within this framework,
MacWilliams identities are found for various local and global weight generating
functions of general group or linear codes on graphs; this generalizes and
provides a concise proof of the MacWilliams identity for linear time-invariant
convolutional codes that was recently found by Gluesing-Luerssen and Schneider.
Further MacWilliams identities are developed for terminated convolutional
codes, particularly for tail-biting codes, similar to those studied recently by
Bocharova, Hug, Johannesson and Kudryashov.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5509</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5509</id><created>2009-11-29</created><authors><author><keyname>Krishnamachari</keyname><forenames>Rajesh T</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K</forenames></author></authors><title>Interference Alignment Under Limited Feedback for MIMO Interference
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While interference alignment schemes have been employed to realize the full
multiplexing gain of $K$-user interference channels, the analyses performed so
far have predominantly focused on the case when global channel knowledge is
available at each node of the network. This paper considers the problem where
each receiver knows its channels from all the transmitters and feeds back this
information using a limited number of bits to all other terminals. In
particular, channel quantization over the composite Grassmann manifold is
proposed and analyzed. It is shown, for $K$-user multiple-input,
multiple-output (MIMO) interference channels, that when the transmitters use an
interference alignment strategy as if the quantized channel estimates obtained
via this limited feedback are perfect, the full sum degrees of freedom of the
interference channel can be achieved as long as the feedback bit rate scales
sufficiently fast with the signal-to-noise ratio. Moreover, this is only one
extreme point of a continuous tradeoff between achievable degrees of freedom
region and user feedback rate scalings which are allowed to be non-identical.
It is seen that a slower scaling of feedback rate for any one user leads to
commensurately fewer degrees of freedom for that user alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5515</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5515</id><created>2009-11-29</created><updated>2010-07-09</updated><authors><author><keyname>Ryan</keyname><forenames>&#xd8;.</forenames></author><author><keyname>Masucci</keyname><forenames>A.</forenames></author><author><keyname>Yang</keyname><forenames>S.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author></authors><title>Finite Dimensional Statistical Inference</title><categories>cs.IT math.IT</categories><comments>14 pages, 13 figures. Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive the explicit series expansion of the eigenvalue
distribution of various models, namely the case of non-central Wishart
distributions, as well as correlated zero mean Wishart distributions. The tools
used extend those of the free probability framework, which have been quite
successful for high dimensional statistical inference (when the size of the
matrices tends to infinity), also known as free deconvolution. This
contribution focuses on the finite Gaussian case and proposes algorithmic
methods to compute the moments. Cases where asymptotic results fail to apply
are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5524</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5524</id><created>2009-11-29</created><updated>2010-01-20</updated><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>LS-CS-residual (LS-CS): Compressive Sensing on Least Squares Residual</title><categories>cs.IT math.IT</categories><comments>Accepted (with mandatory minor revisions) to IEEE Trans. Signal
  Processing. 12 pages, 5 figures</comments><journal-ref>IEEE Trans. Signal Processing, pages 4108 - 4120, vol. 58(8),
  August 2010</journal-ref><doi>10.1109/TSP.2010.2048105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recursively and causally reconstructing time
sequences of sparse signals (with unknown and time-varying sparsity patterns)
from a limited number of noisy linear measurements. The sparsity pattern is
assumed to change slowly with time. The idea of our proposed solution,
LS-CS-residual (LS-CS), is to replace compressed sensing (CS) on the
observation by CS on the least squares (LS) residual computed using the
previous estimate of the support. We bound CS-residual error and show that when
the number of available measurements is small, the bound is much smaller than
that on CS error if the sparsity pattern changes slowly enough. We also obtain
conditions for &quot;stability&quot; of LS-CS over time for a signal model that allows
support additions and removals, and that allows coefficients to gradually
increase (decrease) until they reach a constant value (become zero). By
&quot;stability&quot;, we mean that the number of misses and extras in the support
estimate remain bounded by time-invariant values (in turn implying a
time-invariant bound on LS-CS error). The concept is meaningful only if the
bounds are small compared to the support size. Numerical experiments backing
our claims are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5525</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5525</id><created>2009-11-29</created><authors><author><keyname>Torrini</keyname><forenames>Paolo</forenames><affiliation>University of Leicester</affiliation></author><author><keyname>Heckel</keyname><forenames>Reiko</forenames><affiliation>University of Leicester</affiliation></author></authors><title>Towards an embedding of Graph Transformation in Intuitionistic Linear
  Logic</title><categories>cs.LO</categories><journal-ref>EPTCS 12, 2009, pp. 99-115</journal-ref><doi>10.4204/EPTCS.12.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear logics have been shown to be able to embed both rewriting-based
approaches and process calculi in a single, declarative framework. In this
paper we are exploring the embedding of double-pushout graph transformations
into quantified linear logic, leading to a Curry-Howard style isomorphism
between graphs and transformations on one hand, formulas and proof terms on the
other. With linear implication representing rules and reachability of graphs,
and the tensor modelling parallel composition of graphs and transformations, we
obtain a language able to encode graph transformation systems and their
computations as well as reason about their properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5526</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5526</id><created>2009-11-29</created><updated>2010-04-29</updated><authors><author><keyname>Barak</keyname><forenames>Boaz</forenames></author><author><keyname>Hardt</keyname><forenames>Moritz</forenames></author><author><keyname>Holenstein</keyname><forenames>Thomas</forenames></author><author><keyname>Steurer</keyname><forenames>David</forenames></author></authors><title>Subsampling Mathematical Relaxations and Average-case Complexity</title><categories>cs.CC cs.DS</categories><comments>Includes several more general results that subsume the previous
  version of the paper.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate a study of when the value of mathematical relaxations such as
linear and semidefinite programs for constraint satisfaction problems (CSPs) is
approximately preserved when restricting the instance to a sub-instance induced
by a small random subsample of the variables. Let $C$ be a family of CSPs such
as 3SAT, Max-Cut, etc., and let $\Pi$ be a relaxation for $C$, in the sense
that for every instance $P\in C$, $\Pi(P)$ is an upper bound the maximum
fraction of satisfiable constraints of $P$. Loosely speaking, we say that
subsampling holds for $C$ and $\Pi$ if for every sufficiently dense instance $P
\in C$ and every $\epsilon&gt;0$, if we let $P'$ be the instance obtained by
restricting $P$ to a sufficiently large constant number of variables, then
$\Pi(P') \in (1\pm \epsilon)\Pi(P)$. We say that weak subsampling holds if the
above guarantee is replaced with $\Pi(P')=1-\Theta(\gamma)$ whenever
$\Pi(P)=1-\gamma$. We show: 1. Subsampling holds for the BasicLP and BasicSDP
programs. BasicSDP is a variant of the relaxation considered by Raghavendra
(2008), who showed it gives an optimal approximation factor for every CSP under
the unique games conjecture. BasicLP is the linear programming analog of
BasicSDP. 2. For tighter versions of BasicSDP obtained by adding additional
constraints from the Lasserre hierarchy, weak subsampling holds for CSPs of
unique games type. 3. There are non-unique CSPs for which even weak subsampling
fails for the above tighter semidefinite programs. Also there are unique CSPs
for which subsampling fails for the Sherali-Adams linear programming hierarchy.
As a corollary of our weak subsampling for strong semidefinite programs, we
obtain a polynomial-time algorithm to certify that random geometric graphs (of
the type considered by Feige and Schechtman, 2002) of max-cut value $1-\gamma$
have a cut value at most $1-\gamma/10$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5527</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5527</id><created>2009-11-29</created><authors><author><keyname>Moshksar</keyname><forenames>Kamyar</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>A model for randomized resource allocation in decentralized wireless
  networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a decentralized wireless communication network
with a fixed number $u$ of frequency sub-bands to be shared among $N$
transmitter-receiver pairs. It is assumed that the number of active users is a
random variable with a given probability mass function. Moreover, users are
unaware of each other's codebooks and hence, no multiuser detection is
possible. We propose a randomized Frequency Hopping (FH) scheme in which each
transmitter randomly hops over a subset of $u$ sub-bands from transmission to
transmission. We derive lower and upper bounds on the mutual information of
each user and demonstrate that, for large Signal-to-Noise Ratio (SNR) values,
the two bounds coincide. This observation enables us to compute the sum
multiplexing gain of the system and obtain the optimum hopping strategy for
maximizing this quantity. We compare the performance of the FH system with that
of the Frequency Division (FD) system in terms of several performance measures
and show that (depending on the probability mass function of the number of
active users) the FH system can offer a significant improvement implying a more
efficient usage of the spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5548</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5548</id><created>2009-11-30</created><updated>2009-12-02</updated><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>A Decision-Optimization Approach to Quantum Mechanics and Game Theory</title><categories>cs.GT cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental laws of quantum world upsets the logical foundation of
classic physics. They are completely counter-intuitive with many bizarre
behaviors. However, this paper shows that they may make sense from the
perspective of a general decision-optimization principle for cooperation. This
principle also offers a generalization of Nash equilibrium, a key concept in
game theory, for better payoffs and stability of game playing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5553</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5553</id><created>2009-11-30</created><authors><author><keyname>Moshksar</keyname><forenames>Kamyar</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Randomized vs. orthogonal spectrum allocation in decentralized networks:
  Outage Analysis</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address a decentralized wireless communication network with a fixed number
$u$ of frequency sub-bands to be shared among $N$ transmitter-receiver pairs.
It is assumed that the number of users $N$ is a random variable with a given
distribution and the channel gains are quasi-static Rayleigh fading. The
transmitters are assumed to be unaware of the number of active users in the
network as well as the channel gains and not capable of detecting the presence
of other users in a given frequency sub-band. Moreover, the users are unaware
of each other's codebooks and hence, no multiuser detection is possible. We
consider a randomized Frequency Hopping (FH) scheme in which each transmitter
randomly hops over a subset of the $u$ sub-bands from transmission to
transmission. Developing a new upper bound on the differential entropy of a
mixed Gaussian random vector and using entropy power inequality, we offer a
series of lower bounds on the achievable rate of each user. Thereafter, we
obtain lower bounds on the maximum transmission rate per user to ensure a
specified outage probability at a given Signal-to-Noise Ratio (SNR) level. We
demonstrate that the so-called outage capacity can be considerably higher in
the FH scheme than in the Frequency Division (FD) scenario for reasonable
distributions on the number of active users. This guarantees a higher spectral
efficiency in FH compared to FD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5565</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5565</id><created>2009-11-30</created><updated>2010-05-29</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Communication of Meaning and the Structuration of Expectations:
  Giddens' &quot;structuration theory&quot; and Luhmann's &quot;self-organization&quot;</title><categories>cs.CY nlin.AO physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communication of meaning as different from (Shannon-type) information is
central to Luhmann's social systems theory and Giddens' structuration theory of
action. These theories share an emphasis on reflexivity, but focus on meaning
along a divide between inter-human communication and intentful action as two
different systems of reference. Recombining these two theories into a theory
about the structuration of expectations, interactions, organization, and
self-organization of intentional communications can be simulated based on
algorithms from the computation of anticipatory systems. The self-organizing
and organizing layers remain rooted in the double contingency of the human
encounter which provides the variation. Organization and self-organization of
communication are reflexive upon and therefore reconstructive of each other.
Using mutual information in three dimensions, the imprint of meaning processing
in the modeling system on the historical organization of uncertainty in the
modeled system can be measured. This is shown empirically in the case of
intellectual organization as &quot;structurating&quot; structure in the textual domain of
scientific articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5568</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5568</id><created>2009-11-30</created><authors><author><keyname>Messiant</keyname><forenames>C&#xe9;dric</forenames><affiliation>LIPN</affiliation></author><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author></authors><title>Acquisition d'informations lexicales \`a partir de corpus C\'edric
  Messiant et Thierry Poibeau</title><categories>cs.CL cs.AI</categories><comments>3 pages</comments><proxy>ccsd hal-00437194</proxy><journal-ref>Troisi\`eme colloque international de l'Association Fran\c{c}aise
  de Linguistique Cognitive (AFLICO), Nanterre : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about automatic acquisition of lexical information from
corpora, especially subcategorization acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5593</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5593</id><created>2009-11-30</created><authors><author><keyname>Cappello</keyname><forenames>Franck</forenames><affiliation>LRI</affiliation></author><author><keyname>Casanova</keyname><forenames>Henri</forenames><affiliation>ICS</affiliation></author><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme, LIP</affiliation></author></authors><title>Checkpointing vs. Migration for Post-Petascale Machines</title><categories>cs.DC</categories><proxy>ccsd inria-00437201</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We craft a few scenarios for the execution of sequential and parallel jobs on
future generation machines. Checkpointing or migration, which technique to
choose?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5642</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5642</id><created>2009-11-30</created><updated>2010-04-06</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author></authors><title>A Theory of Sampling for Continuous-time Metric Temporal Logic</title><categories>cs.LO</categories><comments>Revised version, 43 pages.</comments><journal-ref>ACM Transactions on Computational Logic, 12(1):1--40, October 2010</journal-ref><doi>10.1145/1838552.1838560</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper revisits the classical notion of sampling in the setting of
real-time temporal logics for the modeling and analysis of systems. The
relationship between the satisfiability of Metric Temporal Logic (MTL) formulas
over continuous-time models and over discrete-time models is studied. It is
shown to what extent discrete-time sequences obtained by sampling
continuous-time signals capture the semantics of MTL formulas over the two time
domains. The main results apply to &quot;flat&quot; formulas that do not nest temporal
operators and can be applied to the problem of reducing the verification
problem for MTL over continuous-time models to the same problem over
discrete-time, resulting in an automated partial practically-efficient
discretization technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5652</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5652</id><created>2009-11-30</created><authors><author><keyname>Loisel</keyname><forenames>Alain</forenames><affiliation>LITIS</affiliation></author><author><keyname>Chaignaud</keyname><forenames>Nathalie</forenames><affiliation>LITIS</affiliation></author><author><keyname>Kotowicz</keyname><forenames>Jean-Philippe</forenames><affiliation>LITIS</affiliation></author></authors><title>Modeling Human Interaction to Design a Human-Computer Dialog System</title><categories>cs.HC</categories><proxy>ccsd hal-00437362</proxy><journal-ref>International Conference on Entreprise Information System,
  ICEIS'08, Barcelone : Spain (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents the Cogni-CISMeF project, which aims at improving the
health information search engine CISMeF, by including a conversational agent
that interacts with the user in natural language. To study the cognitive
processes involved during information search, a bottom-up methodology was
adopted. An experiment has been set up to obtain human dialogs related to such
searches. The analysis of these dialogs underlines the establishment of a
common ground and accommodation effects to the user. A model of artificial
agent is proposed, that guides the user by proposing examples, assistance and
choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5660</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5660</id><created>2009-11-30</created><updated>2014-04-04</updated><authors><author><keyname>Paluch</keyname><forenames>Katarzyna</forenames></author></authors><title>Faster and simpler approximation of stable matchings</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a 3/2-approximation algorithm for stable matchings that runs in
$O(m)$ time. The previously best known algorithm by McDermid has the same
approximation ratio but runs in $O(n^{3/2}m)$ time, where $n$ denotes the
number of people and $m$ is the total length of the preference lists in a given
instance. Also the algorithm and the analysis are much simpler. We also give
the extension of the algorithm for the many-to-many setting.
  (This is the version of the paper from March 2011)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5667</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5667</id><created>2009-11-30</created><updated>2010-04-20</updated><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Schober</keyname><forenames>Steffen</forenames></author><author><keyname>Mao</keyname><forenames>Tong</forenames></author><author><keyname>Zeh</keyname><forenames>Alexander</forenames></author></authors><title>End-to-End Algebraic Network Coding for Wireless TCP/IP Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>Accepted for the 17th International Conference on Telecommunications
  2010 (ICT2010), Doha, Qatar, April 4 - 7, 2010. 6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Transmission Control Protocol (TCP) was designed to provide reliable
transport services in wired networks. In such networks, packet losses mainly
occur due to congestion. Hence, TCP was designed to apply congestion avoidance
techniques to cope with packet losses. Nowadays, TCP is also utilized in
wireless networks where, besides congestion, numerous other reasons for packet
losses exist. This results in reduced throughput and increased transmission
round-trip time when the state of the wireless channel is bad. We propose a new
network layer, that transparently sits below the transport layer and hides non
congestion-imposed packet losses from TCP. The network coding in this new layer
is based on the well-known class of Maximum Distance Separable (MDS) codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5682</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5682</id><created>2009-11-30</created><authors><author><keyname>Mo&#x15b;cicki</keyname><forenames>Jakub T.</forenames></author><author><keyname>Wo&#x15b;</keyname><forenames>Maciej</forenames></author><author><keyname>Lamanna</keyname><forenames>Massimo</forenames></author><author><keyname>de Forcrand</keyname><forenames>Philippe</forenames></author><author><keyname>Philipsen</keyname><forenames>Owe</forenames></author></authors><title>Lattice QCD Thermodynamics on the Grid</title><categories>cs.DC hep-lat</categories><journal-ref>Comput.Phys.Commun.181:1715-1726,2010</journal-ref><doi>10.1016/j.cpc.2010.06.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how we have used simultaneously ${\cal O}(10^3)$ nodes of the
EGEE Grid, accumulating ca. 300 CPU-years in 2-3 months, to determine an
important property of Quantum Chromodynamics. We explain how Grid resources
were exploited efficiently and with ease, using user-level overlay based on
Ganga and DIANE tools above standard Grid software stack. Application-specific
scheduling and resource selection based on simple but powerful heuristics
allowed to improve efficiency of the processing to obtain desired scientific
results by a specified deadline. This is also a demonstration of combined use
of supercomputers, to calculate the initial state of the QCD system, and Grids,
to perform the subsequent massively distributed simulations. The QCD simulation
was performed on a $16^3\times 4$ lattice. Keeping the strange quark mass at
its physical value, we reduced the masses of the up and down quarks until,
under an increase of temperature, the system underwent a second-order phase
transition to a quark-gluon plasma. Then we measured the response of this
system to an increase in the quark density. We find that the transition is
smoothened rather than sharpened. If confirmed on a finer lattice, this finding
makes it unlikely for ongoing experimental searches to find a QCD critical
point at small chemical potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5703</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5703</id><created>2009-11-30</created><authors><author><keyname>Picard</keyname><forenames>Olivier</forenames></author><author><keyname>Blondin-Masse</keyname><forenames>Alexandre</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author><author><keyname>Marcotte</keyname><forenames>Odile</forenames></author><author><keyname>Chicoisne</keyname><forenames>Guillaume</forenames></author><author><keyname>Gargouri</keyname><forenames>Yassine</forenames></author></authors><title>Hierarchies in Dictionary Definition Space</title><categories>cs.CL cs.LG</categories><comments>9 pages, 5 figues, 2 tables, 12 references, 23rd Annual Conference on
  Neural Information Processing Systems (NIPS): Workshop on Analyzing Networks
  and Learning With Graphs
  http://nips.cc/Conferences/2009/Program/event.php?ID=1504</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dictionary defines words in terms of other words. Definitions can tell you
the meanings of words you don't know, but only if you know the meanings of the
defining words. How many words do you need to know (and which ones) in order to
be able to learn all the rest from definitions? We reduced dictionaries to
their &quot;grounding kernels&quot; (GKs), about 10% of the dictionary, from which all
the other words could be defined. The GK words turned out to have
psycholinguistic correlates: they were learned at an earlier age and more
concrete than the rest of the dictionary. But one can compress still more: the
GK turns out to have internal structure, with a strongly connected &quot;kernel
core&quot; (KC) and a surrounding layer, from which a hierarchy of definitional
distances can be derived, all the way out to the periphery of the full
dictionary. These definitional distances, too, are correlated with
psycholinguistic variables (age of acquisition, concreteness, imageability,
oral and written frequency) and hence perhaps with the &quot;mental lexicon&quot; in each
of our heads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5707</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5707</id><created>2009-11-30</created><authors><author><keyname>Perrucci</keyname><forenames>Daniel</forenames></author></authors><title>Linear Solving for Sign Determination</title><categories>math.AG cs.SC</categories><msc-class>14P99; 15B35; 12Y05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a specific method to solve with quadratic complexity the linear
systems arising in known algorithms to deal with the sign determination
problem. In particular, this enable us to improve the complexity bound for sign
determination in the univariate case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.5708</identifier>
 <datestamp>2009-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.5708</id><created>2009-11-30</created><authors><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter L.</forenames></author><author><keyname>Huang</keyname><forenames>Ling</forenames></author><author><keyname>Taft</keyname><forenames>Nina</forenames></author></authors><title>Learning in a Large Function Space: Privacy-Preserving Mechanisms for
  SVM Learning</title><categories>cs.LG cs.CR cs.DB</categories><comments>21 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several recent studies in privacy-preserving learning have considered the
trade-off between utility or risk and the level of differential privacy
guaranteed by mechanisms for statistical query processing. In this paper we
study this trade-off in private Support Vector Machine (SVM) learning. We
present two efficient mechanisms, one for the case of finite-dimensional
feature mappings and one for potentially infinite-dimensional feature mappings
with translation-invariant kernels. For the case of translation-invariant
kernels, the proposed mechanism minimizes regularized empirical risk in a
random Reproducing Kernel Hilbert Space whose kernel uniformly approximates the
desired kernel with high probability. This technique, borrowed from large-scale
learning, allows the mechanism to respond with a finite encoding of the
classifier, even when the function class is of infinite VC dimension.
Differential privacy is established using a proof technique from algorithmic
stability. Utility--the mechanism's response function is pointwise
epsilon-close to non-private SVM with probability 1-delta--is proven by
appealing to the smoothness of regularized empirical risk minimization with
respect to small perturbations to the feature mapping. We conclude with a lower
bound on the optimal differential privacy of the SVM. This negative result
states that for any delta, no mechanism can be simultaneously
(epsilon,delta)-useful and beta-differentially private for small epsilon and
small beta.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0027</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0027</id><created>2009-11-30</created><updated>2010-05-12</updated><authors><author><keyname>Cook</keyname><forenames>Matthew</forenames></author><author><keyname>Fu</keyname><forenames>Yunhui</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author></authors><title>Temperature 1 Self-Assembly: Deterministic Assembly in 3D and
  Probabilistic Assembly in 2D</title><categories>cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the power of the Wang tile self-assembly model at temperature
1, a threshold value that permits attachment between any two tiles that share
even a single bond. When restricted to deterministic assembly in the plane, no
temperature 1 assembly system has been shown to build a shape with a tile
complexity smaller than the diameter of the shape. In contrast, we show that
temperature 1 self-assembly in 3 dimensions, even when growth is restricted to
at most 1 step into the third dimension, is capable of simulating a large class
of temperature 2 systems, in turn permitting the simulation of arbitrary Turing
machines and the assembly of $n\times n$ squares in near optimal $O(\log n)$
tile complexity. Further, we consider temperature 1 probabilistic assembly in
2D, and show that with a logarithmic scale up of tile complexity and shape
scale, the same general class of temperature $\tau=2$ systems can be simulated
with high probability, yielding Turing machine simulation and $O(\log^2 n)$
assembly of $n\times n$ squares with high probability. Our results show a sharp
contrast in achievable tile complexity at temperature 1 if either growth into
the third dimension or a small probability of error are permitted. Motivated by
applications in nanotechnology and molecular computing, and the plausibility of
implementing 3 dimensional self-assembly systems, our techniques may provide
the needed power of temperature 2 systems, while at the same time avoiding the
experimental challenges faced by those systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0032</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0032</id><created>2009-11-30</created><authors><author><keyname>Innocenti</keyname><forenames>Giacomo</forenames></author><author><keyname>Pretini</keyname><forenames>Luca</forenames></author></authors><title>Abstraction and control techniques for non-stationary scheduling
  problems</title><categories>nlin.AO cs.DC</categories><comments>26 pages, 10 figures, technical (internal) report of the Dipartimento
  di sistemi e Informatica, Universita' di Firenze</comments><report-no>R.T.2/2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper faces the problem of scheduling from a new perspective, trying to
bridge the gap between classical heuristic approaches and system identification
and control strategies. To this aim, a complete mathematical formulation of a
general scheduling process is derived, beginning from very broad assumptions.
This allows a greater freedom of manipulation and guarantee the resolution of
the identification (and control) techniques. Both an adaptive and a switching
strategies are presented in relation to the performances of a simple Round
Robin algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0034</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0034</id><created>2009-11-30</created><authors><author><keyname>Ciobanu</keyname><forenames>Gabriel</forenames></author></authors><title>Proceedings Third Workshop on Membrane Computing and Biologically
  Inspired Process Calculi 2009</title><categories>cs.CE cs.DC cs.FL cs.LO</categories><comments>In Memoriam Nadia Busi</comments><acm-class>F.1.1</acm-class><journal-ref>EPTCS 11, 2009</journal-ref><doi>10.4204/EPTCS.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the accepted papers at the third Workshop on Membrane
Computing and Biologically Inspired Process Calculi, held in Bologna on 5th
September 2009. The papers are devoted to both membrane computing and
biologically inspired process calculi, as well as to other related formalisms.
The papers of this volume are selected by the programme committee due to their
quality and relevance; they have defined an exciting programme highlighting
interesting problems and stimulating the search for novel ways of describing
related biological phenomena. In addition, we had an invited talk given by Luca
Cardelli on a spatial process algebra for developmental biology. Membrane
systems were introduced as a class of distributed parallel computing devices
inspired by the observation that any biological system is a complex
hierarchical structure, with a flow of materials and information that underlies
their functioning. The emphasis is on the computational properties of the
model, and it makes use of automata, languages, and complexity theoretic tools.
On the other hand, certain calculi such as mobile ambients and brane calculi
work with similar notions (compartments, membranes). These calculi are used to
model and analyze the various biological systems. The workshop on Membrane
Computing and Biologically Inspired Process Calculi brings together researchers
working in these fields to present their recent work and discuss new ideas
concerning the formalisms, their properties and relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0071</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0071</id><created>2009-11-30</created><updated>2011-02-16</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Monteleoni</keyname><forenames>Claire</forenames></author><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author></authors><title>Differentially Private Empirical Risk Minimization</title><categories>cs.LG cs.AI cs.CR cs.DB</categories><comments>40 pages, 7 figures, accepted to the Journal of Machine Learning
  Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy-preserving machine learning algorithms are crucial for the
increasingly common setting in which personal data, such as medical or
financial records, are analyzed. We provide general techniques to produce
privacy-preserving approximations of classifiers learned via (regularized)
empirical risk minimization (ERM). These algorithms are private under the
$\epsilon$-differential privacy definition due to Dwork et al. (2006). First we
apply the output perturbation ideas of Dwork et al. (2006), to ERM
classification. Then we propose a new method, objective perturbation, for
privacy-preserving machine learning algorithm design. This method entails
perturbing the objective function before optimizing over classifiers. If the
loss and regularizer satisfy certain convexity and differentiability criteria,
we prove theoretical results showing that our algorithms preserve privacy, and
provide generalization bounds for linear and nonlinear kernels. We further
present a privacy-preserving technique for tuning the parameters in general
machine learning algorithms, thereby providing end-to-end privacy guarantees
for the training process. We apply these results to produce privacy-preserving
analogues of regularized logistic regression and support vector machines. We
obtain encouraging results from evaluating their performance on real
demographic and benchmark data sets. Our results show that both theoretically
and empirically, objective perturbation is superior to the previous
state-of-the-art, output perturbation, in managing the inherent tradeoff
between privacy and learning performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0086</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0086</id><created>2009-12-01</created><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Dasgupta</keyname><forenames>Sanjoy</forenames></author><author><keyname>Vattani</keyname><forenames>Andrea</forenames></author></authors><title>Learning Mixtures of Gaussians using the k-means Algorithm</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most popular algorithms for clustering in Euclidean space is the
$k$-means algorithm; $k$-means is difficult to analyze mathematically, and few
theoretical guarantees are known about it, particularly when the data is {\em
well-clustered}. In this paper, we attempt to fill this gap in the literature
by analyzing the behavior of $k$-means on well-clustered data. In particular,
we study the case when each cluster is distributed as a different Gaussian --
or, in other words, when the input comes from a mixture of Gaussians.
  We analyze three aspects of the $k$-means algorithm under this assumption.
First, we show that when the input comes from a mixture of two spherical
Gaussians, a variant of the 2-means algorithm successfully isolates the
subspace containing the means of the mixture components. Second, we show an
exact expression for the convergence of our variant of the 2-means algorithm,
when the input is a very large number of samples from a mixture of spherical
Gaussians. Our analysis does not require any lower bound on the separation
between the mixture components.
  Finally, we study the sample requirement of $k$-means; for a mixture of 2
spherical Gaussians, we show an upper bound on the number of samples required
by a variant of 2-means to get close to the true solution. The sample
requirement grows with increasing dimensionality of the data, and decreasing
separation between the means of the Gaussians. To match our upper bound, we
show an information-theoretic lower bound on any algorithm that learns mixtures
of two spherical Gaussians; our lower bound indicates that in the case when the
overlap between the probability masses of the two distributions is small, the
sample requirement of $k$-means is {\em near-optimal}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0132</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0132</id><created>2009-12-01</created><authors><author><keyname>Badra</keyname><forenames>Fadi</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Cordier</keyname><forenames>Am&#xe9;lie</forenames><affiliation>LIRIS</affiliation></author><author><keyname>Lieber</keyname><forenames>Jean</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Opportunistic Adaptation Knowledge Discovery</title><categories>cs.AI</categories><proxy>ccsd inria-00437693</proxy><journal-ref>8th International Conference on Case-Based Reasoning, ICCBR 2009,
  Seattle : United States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptation has long been considered as the Achilles' heel of case-based
reasoning since it requires some domain-specific knowledge that is difficult to
acquire. In this paper, two strategies are combined in order to reduce the
knowledge engineering cost induced by the adaptation knowledge (CA) acquisition
task: CA is learned from the case base by the means of knowledge discovery
techniques, and the CA acquisition sessions are opportunistically triggered,
i.e., at problem-solving time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0134</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0134</id><created>2009-12-01</created><authors><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria Gradinariu</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Nesterenko</keyname><forenames>Mikhail</forenames><affiliation>LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Self-Stabilizing Byzantine Asynchronous Unison</title><categories>cs.DC cs.DS</categories><proxy>ccsd inria-00437691</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore asynchronous unison in the presence of systemic transient and
permanent Byzantine faults in shared memory. We observe that the problem is not
solvable under less than strongly fair scheduler or for system topologies with
maximum node degree greater than two. We present a self-stabilizing
Byzantine-tolerant solution to asynchronous unison for chain and ring
topologies. Our algorithm has minimum possible containment radius and optimal
stabilization time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0149</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0149</id><created>2009-12-01</created><authors><author><keyname>Pratas</keyname><forenames>Nuno</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author><author><keyname>Prasad</keyname><forenames>Neeli Rashmi</forenames></author><author><keyname>Rodrigues</keyname><forenames>Antonio</forenames></author><author><keyname>Prasad</keyname><forenames>Ramjee</forenames></author></authors><title>Robust Cooperative Spectrum Sensing for Disaster Relief Networks in
  Correlated Environments</title><categories>cs.NI cs.DC</categories><comments>10 Pages, 12 figures. Submitted to J-SAC - Special Issue on Advances
  in Cognitive Radio Networking and Communications on December 1st of 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Disaster relief networks are designed to be adaptable and resilient so to
encompass the demands of the emergency service. Cognitive Radio enhanced ad-hoc
architecture has been put forward as a candidate to enable such networks.
Spectrum sensing, the cornerstone of the Cognitive Radio paradigm, has been the
focus of intensive research, from which the main conclusion was that its
performance can be greatly enhanced through the use of cooperative sensing
schemes. To apply the Cognitive Radio paradigm to Ad-hoc disaster relief
networks, the design of effective cooperative spectrum sensing schemes is
essential. In this paper we propose a cluster based orchestration cooperative
sensing scheme, which adapts to the cluster nodes surrounding radio environment
state as well as to the degree of correlation observed between those nodes. The
proposed scheme is given both in a centralized as well as in a decentralized
approach. In the centralized approach, the cluster head controls and adapts the
distribution of the cluster sensing nodes according to the monitored spectrum
state. While in the decentralized approach, each of the cluster nodes decides
which spectrum it should monitor, according to the past local sensing decisions
of the cluster nodes. The centralized and decentralized schemes can be combined
to achieve a more robust cooperative spectrum sensing scheme. The proposed
scheme performance is evaluated through a framework, which allows measuring the
accuracy of the spectrum sensing cooperative scheme by measuring the error in
the estimation of the monitored spectrum state. Through this evaluation it is
shown that the proposed scheme outperforms the case where the choice of which
spectrum to sense is done without using the knowledge obtained in previous
sensing iterations, i.e. a implementation of a blind Round Robin scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0161</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0161</id><created>2009-12-01</created><updated>2010-09-03</updated><authors><author><keyname>Kovacs</keyname><forenames>Istvan A.</forenames></author><author><keyname>Palotai</keyname><forenames>Robin</forenames></author><author><keyname>Szalay</keyname><forenames>Mate S.</forenames></author><author><keyname>Csermely</keyname><forenames>Peter</forenames></author></authors><title>Community landscapes: an integrative approach to determine overlapping
  network module hierarchy, identify key nodes and predict network dynamics</title><categories>physics.comp-ph cond-mat.dis-nn cs.MS physics.data-an physics.soc-ph q-bio.MN</categories><comments>25 pages with 6 figures and a Glossary + Supporting Information
  containing pseudo-codes of all algorithms used, 14 Figures, 5 Tables (with 18
  module definitions, 129 different modularization methods, 13 module
  comparision methods) and 396 references. All algorithms can be downloaded
  from this web-site: http://www.linkgroup.hu/modules.php</comments><journal-ref>PLoS ONE 5, e12528 (2010)</journal-ref><doi>10.1371/journal.pone.0012528</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Network communities help the functional organization and
evolution of complex networks. However, the development of a method, which is
both fast and accurate, provides modular overlaps and partitions of a
heterogeneous network, has proven to be rather difficult. Methodology/Principal
Findings: Here we introduce the novel concept of ModuLand, an integrative
method family determining overlapping network modules as hills of an influence
function-based, centrality-type community landscape, and including several
widely used modularization methods as special cases. As various adaptations of
the method family, we developed several algorithms, which provide an efficient
analysis of weighted and directed networks, and (1) determine pervasively
overlapping modules with high resolution; (2) uncover a detailed hierarchical
network structure allowing an efficient, zoom-in analysis of large networks;
(3) allow the determination of key network nodes and (4) help to predict
network dynamics. Conclusions/Significance: The concept opens a wide range of
possibilities to develop new approaches and applications including network
routing, classification, comparison and prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0180</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0180</id><created>2009-12-01</created><updated>2010-06-14</updated><authors><author><keyname>Reps</keyname><forenames>Bram</forenames></author><author><keyname>Vanroose</keyname><forenames>Wim</forenames></author><author><keyname>Zubair</keyname><forenames>Hisham bin</forenames></author></authors><title>On the indefinite Helmholtz equation: complex stretched absorbing
  boundary layers, iterative analysis, and preconditioning</title><categories>cs.NA</categories><acm-class>G.1.8</acm-class><journal-ref>Journal of Computational Physics (2010)</journal-ref><doi>10.1016/j.jcp.2010.07.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies and analyzes a preconditioned Krylov solver for Helmholtz
problems that are formulated with absorbing boundary layers based on complex
coordinate stretching. The preconditioner problem is a Helmholtz problem where
not only the coordinates in the absorbing layer have an imaginary part, but
also the coordinates in the interior region. This results into a preconditioner
problem that is invertible with a multigrid cycle. We give a numerical analysis
based on the eigenvalues and evaluate the performance with several numerical
experiments. The method is an alternative to the complex shifted Laplacian and
it gives a comparable performance for the studied model problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0224</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0224</id><created>2009-12-01</created><authors><author><keyname>Barriga</keyname><forenames>Nicolas A.</forenames></author><author><keyname>Araya-L&#xf3;pez</keyname><forenames>Mauricio</forenames></author></authors><title>A Multi-stage Probabilistic Algorithm for Dynamic Path-Planning</title><categories>cs.AI cs.RO</categories><comments>7 pages, 5 figures. Presented in Ingelectra 2009 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic sampling methods have become very popular to solve single-shot
path planning problems. Rapidly-exploring Random Trees (RRTs) in particular
have been shown to be efficient in solving high dimensional problems. Even
though several RRT variants have been proposed for dynamic replanning, these
methods only perform well in environments with infrequent changes. This paper
addresses the dynamic path planning problem by combining simple techniques in a
multi-stage probabilistic algorithm. This algorithm uses RRTs for initial
planning and informed local search for navigation. We show that this
combination of simple techniques provides better responses to highly dynamic
environments than the RRT extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0226</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0226</id><created>2009-12-01</created><authors><author><keyname>Bonsma</keyname><forenames>Paul</forenames></author></authors><title>Max-Leaves Spanning Tree is APX-hard for Cubic Graphs</title><categories>cs.DM cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a spanning tree with maximum number of
leaves (MaxLeaf). A 2-approximation algorithm is known for this problem, and a
3/2-approximation algorithm when restricted to graphs where every vertex has
degree 3 (cubic graphs). MaxLeaf is known to be APX-hard in general, and
NP-hard for cubic graphs. We show that the problem is also APX-hard for cubic
graphs. The APX-hardness of the related problem Minimum Connected Dominating
Set for cubic graphs follows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0228</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0228</id><created>2009-12-01</created><updated>2009-12-03</updated><authors><author><keyname>Sauerbier</keyname><forenames>Charles</forenames></author></authors><title>Cantor's Problem</title><categories>cs.LO</categories><comments>7 pages, 0 figures; correct typographical errors, wording</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1891 a paper by Georg Cantor was published in which he addressed the
relative cardinality of two sets, the set of integers and the set of real
numbers, in effort to demonstrate that the two sets were of unequal
cardinality. This paper offers a contrary conclusion to Cantor's argument,
together with implication of such to the theory of computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0229</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0229</id><created>2009-12-01</created><authors><author><keyname>Gilbert</keyname><forenames>Anna C.</forenames></author><author><keyname>Li</keyname><forenames>Yi</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Strauss</keyname><forenames>Martin J.</forenames></author></authors><title>Approximate Sparse Recovery: Optimizing Time and Measurements</title><categories>cs.DS cs.IT math.IT</categories><journal-ref>SIAM J. Comput. 41(2), pp. 436-453, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approximate sparse recovery system consists of parameters $k,N$, an
$m$-by-$N$ measurement matrix, $\Phi$, and a decoding algorithm, $\mathcal{D}$.
Given a vector, $x$, the system approximates $x$ by $\widehat x
=\mathcal{D}(\Phi x)$, which must satisfy $\| \widehat x - x\|_2\le C \|x -
x_k\|_2$, where $x_k$ denotes the optimal $k$-term approximation to $x$. For
each vector $x$, the system must succeed with probability at least 3/4. Among
the goals in designing such systems are minimizing the number $m$ of
measurements and the runtime of the decoding algorithm, $\mathcal{D}$.
  In this paper, we give a system with $m=O(k \log(N/k))$
measurements--matching a lower bound, up to a constant factor--and decoding
time $O(k\log^c N)$, matching a lower bound up to $\log(N)$ factors.
  We also consider the encode time (i.e., the time to multiply $\Phi$ by $x$),
the time to update measurements (i.e., the time to multiply $\Phi$ by a
1-sparse $x$), and the robustness and stability of the algorithm (adding noise
before and after the measurements). Our encode and update times are optimal up
to $\log(N)$ factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0238</identifier>
 <datestamp>2015-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0238</id><created>2009-12-01</created><updated>2015-09-29</updated><authors><author><keyname>Vigna</keyname><forenames>Sebastiano</forenames></author></authors><title>Spectral Ranking</title><categories>cs.IR cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note tries to attempt a sketch of the history of spectral ranking, a
general umbrella name for techniques that apply the theory of linear maps (in
particular, eigenvalues and eigenvectors) to matrices that do not represent
geometric transformations, but rather some kind of relationship between
entities. Albeit recently made famous by the ample press coverage of Google's
PageRank algorithm, spectral ranking was devised more than sixty years ago,
almost exactly in the same terms, and has been studied in psychology and social
sciences. I will try to describe it in precise and modern mathematical terms,
highlighting along the way the contributions given by previous scholars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0250</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0250</id><created>2009-12-01</created><authors><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author><author><keyname>Wu</keyname><forenames>Yi</forenames></author><author><keyname>Zhou</keyname><forenames>Yuan</forenames></author></authors><title>Optimal lower bounds for locality sensitive hashing (except when q is
  tiny)</title><categories>cs.DS cs.CG</categories><comments>9 pages + abstract and references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study lower bounds for Locality Sensitive Hashing (LSH) in the strongest
setting: point sets in {0,1}^d under the Hamming distance. Recall that here H
is said to be an (r, cr, p, q)-sensitive hash family if all pairs x, y in
{0,1}^d with dist(x,y) at most r have probability at least p of collision under
a randomly chosen h in H, whereas all pairs x, y in {0,1}^d with dist(x,y) at
least cr have probability at most q of collision. Typically, one considers d
tending to infinity, with c fixed and q bounded away from 0.
  For its applications to approximate nearest neighbor search in high
dimensions, the quality of an LSH family H is governed by how small its &quot;rho
parameter&quot; rho = ln(1/p)/ln(1/q) is as a function of the parameter c. The
seminal paper of Indyk and Motwani showed that for each c, the extremely simple
family H = {x -&gt; x_i : i in d} achieves rho at most 1/c. The only known lower
bound, due to Motwani, Naor, and Panigrahy, is that rho must be at least .46/c
(minus o_d(1)).
  In this paper we show an optimal lower bound: rho must be at least 1/c (minus
o_d(1)). This lower bound for Hamming space yields a lower bound of 1/c^2 for
Euclidean space (or the unit sphere) and 1/c for the Jaccard distance on sets;
both of these match known upper bounds. Our proof is simple; the essence is
that the noise stability of a boolean function at e^{-t} is a log-convex
function of t.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0255</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0255</id><created>2009-12-01</created><authors><author><keyname>Dphep Study Group</keyname></author></authors><title>Data Preservation in High Energy Physics</title><categories>hep-ex cs.DL physics.data-an</categories><comments>Intermediate report of the ICFA-DPHEP Study Group (18 pages, 2
  figures)</comments><report-no>DPHEP-2009-001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data from high-energy physics (HEP) experiments are collected with
significant financial and human effort and are mostly unique. At the same time,
HEP has no coherent strategy for data preservation and re-use. An
inter-experimental Study Group on HEP data preservation and long-term analysis
was convened at the end of 2008 and held two workshops, at DESY (January 2009)
and SLAC (May 2009). This document is an intermediate report to the
International Committee for Future Accelerators (ICFA) of the reflections of
this Study Group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0265</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0265</id><created>2009-12-01</created><updated>2010-01-22</updated><authors><author><keyname>Buibas</keyname><forenames>Marius</forenames></author><author><keyname>Yu</keyname><forenames>Diana</forenames></author><author><keyname>Nizar</keyname><forenames>Krystal</forenames></author><author><keyname>Silva</keyname><forenames>Gabriel A.</forenames></author></authors><title>Mapping the spatiotemporal dynamics of calcium signaling in cellular
  neural networks using optical flow</title><categories>cs.CE cs.CV q-bio.NC</categories><comments>23 pages, 5 figures. Peer reviewed accepted version in press in
  Annals of Biomedical Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optical flow gradient algorithm was applied to spontaneously forming net-
works of neurons and glia in culture imaged by fluorescence optical microscopy
in order to map functional calcium signaling with single pixel resolution.
Optical flow estimates the direction and speed of motion of objects in an image
between subsequent frames in a recorded digital sequence of images (i.e. a
movie). Computed vector field outputs by the algorithm were able to track the
spatiotemporal dynamics of calcium signaling pat- terns. We begin by briefly
reviewing the mathematics of the optical flow algorithm, and then describe how
to solve for the displacement vectors and how to measure their reliability. We
then compare computed flow vectors with manually estimated vectors for the
progression of a calcium signal recorded from representative astrocyte
cultures. Finally, we applied the algorithm to preparations of primary
astrocytes and hippocampal neurons and to the rMC-1 Muller glial cell line in
order to illustrate the capability of the algorithm for capturing different
types of spatiotemporal calcium activity. We discuss the imaging requirements,
parameter selection and threshold selection for reliable measurements, and
offer perspectives on uses of the vector data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0266</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0266</id><created>2009-12-01</created><authors><author><keyname>Barriga</keyname><forenames>Nicolas A.</forenames></author><author><keyname>Araya-L&#xf3;pez</keyname><forenames>Mauricio</forenames></author><author><keyname>Solar</keyname><forenames>Mauricio</forenames></author></authors><title>Combining a Probabilistic Sampling Technique and Simple Heuristics to
  solve the Dynamic Path Planning Problem</title><categories>cs.AI cs.RO</categories><comments>8 pages, 7 figures. Presented at the XXVIII International Conference
  of the Chilean Computer Society 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic sampling methods have become very popular to solve single-shot
path planning problems. Rapidly-exploring Random Trees (RRTs) in particular
have been shown to be very efficient in solving high dimensional problems. Even
though several RRT variants have been proposed to tackle the dynamic replanning
problem, these methods only perform well in environments with infrequent
changes. This paper addresses the dynamic path planning problem by combining
simple techniques in a multi-stage probabilistic algorithm. This algorithm uses
RRTs as an initial solution, informed local search to fix unfeasible paths and
a simple greedy optimizer. The algorithm is capable of recognizing when the
local search is stuck, and subsequently restart the RRT. We show that this
combination of simple techniques provides better responses to a highly dynamic
environment than the dynamic RRT variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0270</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0270</id><created>2009-12-01</created><authors><author><keyname>Barriga</keyname><forenames>Nicolas A.</forenames></author></authors><title>Single-Agent On-line Path Planning in Continuous, Unpredictable and
  Highly Dynamic Environments</title><categories>cs.AI cs.RO</categories><comments>54 pages, Master of Science in Informatics Engineering thesis</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This document is a thesis on the subject of single-agent on-line path
planning in continuous,unpredictable and highly dynamic environments. The
problem is finding and traversing a collision-free path for a holonomic robot,
without kinodynamic restrictions, moving in an environment with several
unpredictably moving obstacles or adversaries. The availability of perfect
information of the environment at all times is assumed.
  Several static and dynamic variants of the Rapidly Exploring Random Trees
(RRT) algorithm are explored, as well as an evolutionary algorithm for planning
in dynamic environments called the Evolutionary Planner/Navigator. A
combination of both kinds of algorithms is proposed to overcome shortcomings in
both, and then a combination of a RRT variant for initial planning and informed
local search for navigation, plus a simple greedy heuristic for optimization.
We show that this combination of simple techniques provides better responses to
highly dynamic environments than the RRT extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0284</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0284</id><created>2009-12-01</created><updated>2011-11-24</updated><authors><author><keyname>Bartholdi</keyname><forenames>Laurent</forenames><affiliation>Georg-August-Universit&#xe4;t G&#xf6;ttingen</affiliation></author><author><keyname>Schick</keyname><forenames>Thomas</forenames><affiliation>Georg-August-Universit&#xe4;t G&#xf6;ttingen</affiliation></author><author><keyname>Smale</keyname><forenames>Nat</forenames><affiliation>University of Utah</affiliation></author><author><keyname>Smale</keyname><forenames>Steve</forenames><affiliation>City University of Hong Kong</affiliation></author><author><keyname>Baker</keyname><forenames>Anthony W.</forenames><affiliation>The Boing Company</affiliation></author></authors><title>Hodge Theory on Metric Spaces</title><categories>math.KT cs.CG math.GT math.NA stat.ML</categories><comments>appendix by Anthony W. Baker, 48 pages, AMS-LaTeX. v2: final version,
  to appear in Foundations of Computational Mathematics. Minor changes and
  additions</comments><msc-class>58A14, 54E05, 55P55, 57M50</msc-class><journal-ref>Foundations of Computational Mathematics 12:1 (2012), 1-48</journal-ref><doi>10.1007/s10208-011-9107-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hodge theory is a beautiful synthesis of geometry, topology, and analysis,
which has been developed in the setting of Riemannian manifolds. On the other
hand, spaces of images, which are important in the mathematical foundations of
vision and pattern recognition, do not fit this framework. This motivates us to
develop a version of Hodge theory on metric spaces with a probability measure.
We believe that this constitutes a step towards understanding the geometry of
vision.
  The appendix by Anthony Baker provides a separable, compact metric space with
infinite dimensional \alpha-scale homology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0287</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0287</id><created>2009-12-01</created><updated>2010-12-21</updated><authors><author><keyname>Dietzfelbinger</keyname><forenames>Martin</forenames></author><author><keyname>Goerdt</keyname><forenames>Andreas</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author><author><keyname>Rink</keyname><forenames>Michael</forenames></author></authors><title>Tight Thresholds for Cuckoo Hashing via XORSAT</title><categories>cs.DS</categories><comments>Revision 3 contains missing details of proofs, as appendix D</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We settle the question of tight thresholds for offline cuckoo hashing. The
problem can be stated as follows: we have n keys to be hashed into m buckets
each capable of holding a single key. Each key has k &gt;= 3 (distinct) associated
buckets chosen uniformly at random and independently of the choices of other
keys. A hash table can be constructed successfully if each key can be placed
into one of its buckets. We seek thresholds alpha_k such that, as n goes to
infinity, if n/m &lt;= alpha for some alpha &lt; alpha_k then a hash table can be
constructed successfully with high probability, and if n/m &gt;= alpha for some
alpha &gt; alpha_k a hash table cannot be constructed successfully with high
probability. Here we are considering the offline version of the problem, where
all keys and hash values are given, so the problem is equivalent to previous
models of multiple-choice hashing. We find the thresholds for all values of k &gt;
2 by showing that they are in fact the same as the previously known thresholds
for the random k-XORSAT problem. We then extend these results to the setting
where keys can have differing number of choices, and provide evidence in the
form of an algorithm for a conjecture extending this result to cuckoo hash
tables that store multiple keys in a bucket.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0309</identifier>
 <datestamp>2009-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0309</id><created>2009-12-01</created><updated>2009-12-04</updated><authors><author><keyname>Chauve</keyname><forenames>Cedric</forenames></author><author><keyname>Manuch</keyname><forenames>Jan</forenames></author><author><keyname>Patterson</keyname><forenames>Murray</forenames></author></authors><title>Hardness Results for the Gapped Consecutive-Ones Property</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by problems of comparative genomics and paleogenomics, in [Chauve
et al., 2009], the authors introduced the Gapped Consecutive-Ones Property
Problem (k,delta)-C1P: given a binary matrix M and two integers k and delta,
can the columns of M be permuted such that each row contains at most k blocks
of ones and no two consecutive blocks of ones are separated by a gap of more
than delta zeros. The classical C1P problem, which is known to be polynomial is
equivalent to the (1,0)-C1P problem. They showed that the (2,delta)-C1P Problem
is NP-complete for all delta &gt;= 2 and that the (3,1)-C1P problem is
NP-complete. They also conjectured that the (k,delta)-C1P Problem is
NP-complete for k &gt;= 2, delta &gt;= 1 and (k,delta) =/= (2,1). Here, we prove that
this conjecture is true. The only remaining case is the (2,1)-C1P Problem,
which could be polynomial-time solvable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0312</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0312</id><created>2009-12-01</created><authors><author><keyname>Gao</keyname><forenames>Zhi-Han</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>The minimal polynomial of sequence obtained from componentwise linear
  transformation of linear recurring sequence</title><categories>cs.IT math.IT</categories><comments>This paper was submitted to the journal Theoretical Computer Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S=(s_1,s_2,...,s_m,...)$ be a linear recurring sequence with terms in
$GF(q^n)$ and $T$ be a linear transformation of $GF(q^n)$ over $GF(q)$. Denote
$T(S)=(T(s_1),T(s_2),...,T(s_m),...)$. In this paper, we first present counter
examples to show the main result in [A.M. Youssef and G. Gong, On linear
complexity of sequences over $GF(2^n)$, Theoretical Computer Science,
352(2006), 288-292] is not correct in general since Lemma 3 in that paper is
incorrect. Then, we determine the minimal polynomial of $T(S)$ if the canonical
factorization of the minimal polynomial of $S$ without multiple roots is known
and thus present the solution to the problem which was mainly considered in the
above paper but incorrectly solved. Additionally, as a special case, we
determine the minimal polynomial of $T(S)$ if the minimal polynomial of $S$ is
primitive. Finally, we give an upper bound on the linear complexity of $T(S)$
when $T$ exhausts all possible linear transformations of $GF(q^n)$ over
$GF(q)$. This bound is tight in some cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0322</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0322</id><created>2009-12-01</created><updated>2011-11-06</updated><authors><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author></authors><title>Submodular Functions: Extensions, Distributions, and Algorithms. A
  Survey</title><categories>cs.DS</categories><comments>This revision corrects an error in definition 2.2, as well as
  provides additional intuition regarding the definitions of convex closure and
  concave closure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submodularity is a fundamental phenomenon in combinatorial optimization.
Submodular functions occur in a variety of combinatorial settings such as
coverage problems, cut problems, welfare maximization, and many more.
Therefore, a lot of work has been concerned with maximizing or minimizing a
submodular function, often subject to combinatorial constraints. Many of these
algorithmic results exhibit a common structure. Namely, the function is
extended to a continuous, usually non-linear, function on a convex domain.
Then, this relaxation is solved, and the fractional solution rounded to yield
an integral solution. Often, the continuous extension has a natural
interpretation in terms of distributions on subsets of the ground set. This
interpretation is often crucial to the results and their analysis. The purpose
of this survey is to highlight this connection between extensions,
distributions, relaxations, and optimization in the context of submodular
functions. We also present the first constant factor approximation algorithm
for minimizing symmetric submodular functions subject to a cardinality
constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0338</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0338</id><created>2009-12-02</created><authors><author><keyname>Gamarnik</keyname><forenames>David</forenames></author><author><keyname>Goldberg</keyname><forenames>David</forenames></author><author><keyname>Weber</keyname><forenames>Theophane</forenames></author></authors><title>Correlation Decay in Random Decision Networks</title><categories>math.PR cs.DC math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a decision network on an undirected graph in which each node
corresponds to a decision variable, and each node and edge of the graph is
associated with a reward function whose value depends only on the variables of
the corresponding nodes. The goal is to construct a decision vector which
maximizes the total reward. This decision problem encompasses a variety of
models, including maximum-likelihood inference in graphical models (Markov
Random Fields), combinatorial optimization on graphs, economic team theory and
statistical physics. The network is endowed with a probabilistic structure in
which costs are sampled from a distribution. Our aim is to identify sufficient
conditions to guarantee average-case polynomiality of the underlying
optimization problem. We construct a new decentralized algorithm called Cavity
Expansion and establish its theoretical performance for a variety of models.
Specifically, for certain classes of models we prove that our algorithm is able
to find near optimal solutions with high probability in a decentralized way.
The success of the algorithm is based on the network exhibiting a correlation
decay (long-range independence) property. Our results have the following
surprising implications in the area of average case complexity of algorithms.
Finding the largest independent (stable) set of a graph is a well known NP-hard
optimization problem for which no polynomial time approximation scheme is
possible even for graphs with largest connectivity equal to three, unless P=NP.
We show that the closely related maximum weighted independent set problem for
the same class of graphs admits a PTAS when the weights are i.i.d. with the
exponential distribution. Namely, randomization of the reward function turns an
NP-hard problem into a tractable one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0360</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0360</id><created>2009-12-02</created><authors><author><keyname>Pia</keyname><forenames>M. G.</forenames><affiliation>INFN Sezione di Genova</affiliation></author><author><keyname>Basaglia</keyname><forenames>T.</forenames><affiliation>European Organization for Nuclear Research</affiliation></author><author><keyname>Bell</keyname><forenames>Z. W.</forenames><affiliation>Oak Ridge National Laboratory</affiliation></author><author><keyname>Dressendorfer</keyname><forenames>P. V.</forenames><affiliation>Editor-in-Chief, IEEE TNS</affiliation></author></authors><title>Geant4 in Scientific Literature</title><categories>physics.comp-ph cs.DL</categories><comments>6 pages, 9 figures and images, to appear in proceedings of the
  Nuclear Science Symposium and Medical Imaging Conference 2009, Orlando</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Geant4 reference paper published in Nuclear Instruments and Methods A in
2003 has become the most cited publication in the whole Nuclear Science and
Technology category of Thomson-Reuter's Journal Citation Reports. It is
currently the second most cited article among the publications authored by two
major research institutes, CERN and INFN. An overview of Geant4 presence (and
absence) in scholarly literature is presented; the patterns of Geant4 citations
are quantitatively examined and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0368</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0368</id><created>2009-12-02</created><authors><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Dondi</keyname><forenames>Riccardo</forenames></author><author><keyname>Pirola</keyname><forenames>Yuri</forenames></author></authors><title>Variants of Constrained Longest Common Subsequence</title><categories>cs.DS cs.DM</categories><journal-ref>Information Processing Letters 110.20 (2010) 877-881</journal-ref><doi>10.1016/j.ipl.2010.07.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a variant of the classical Longest Common
Subsequence problem called Doubly-Constrained Longest Common Subsequence
(DC-LCS). Given two strings s1 and s2 over an alphabet A, a set C_s of strings,
and a function Co from A to N, the DC-LCS problem consists in finding the
longest subsequence s of s1 and s2 such that s is a supersequence of all the
strings in Cs and such that the number of occurrences in s of each symbol a in
A is upper bounded by Co(a). The DC-LCS problem provides a clear mathematical
formulation of a sequence comparison problem in Computational Biology and
generalizes two other constrained variants of the LCS problem: the Constrained
LCS and the Repetition-Free LCS. We present two results for the DC-LCS problem.
First, we illustrate a fixed-parameter algorithm where the parameter is the
length of the solution. Secondly, we prove a parameterized hardness result for
the Constrained LCS problem when the parameter is the number of the constraint
strings and the size of the alphabet A. This hardness result also implies the
parameterized hardness of the DC-LCS problem (with the same parameters) and its
NP-hardness when the size of the alphabet is constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0419</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0419</id><created>2009-12-02</created><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Baillot</keyname><forenames>Patrick</forenames><affiliation>LIP</affiliation></author><author><keyname>Madet</keyname><forenames>Antoine</forenames><affiliation>PPS</affiliation></author></authors><title>An affine-intuitionistic system of types and effects: confluence and
  termination</title><categories>cs.LO</categories><proxy>ccsd hal-00438101</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an affine-intuitionistic system of types and effects which can be
regarded as an extension of Barber-Plotkin Dual Intuitionistic Linear Logic to
multi-threaded programs with effects. In the system, dynamically generated
values such as references or channels are abstracted into a finite set of
regions. We introduce a discipline of region usage that entails the confluence
(and hence determinacy) of the typable programs. Further, we show that a
discipline of region stratification guarantees termination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0433</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0433</id><created>2009-12-02</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author></authors><title>On the issues of building Information Warehouses</title><categories>cs.HC cs.IR cs.SE</categories><comments>ACM Comptute 2010, January 22-23, 2010, Bangalore, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While performing knowledge-intensive tasks of professional nature, the
knowledge workers need to access and process large volume of information. Apart
from the quantity, they also require that the information received is of high
quality in terms of authenticity and details. This, in turn, requires that the
information delivered should also include argumentative support, exhibiting the
reasoning process behind their development and provenance to indicate their
lineage. In conventional document-centric practices for information management,
such details are difficult to capture, represent/archive and retrieve/deliver.
To achieve such capability we need to re-think some core issues of information
management from the above requirements perspective. In this paper we develop a
framework for comprehensive representation of information in archive, capturing
informational contents along with their context. We shall call it the
&quot;Information Warehouse (IW)&quot; framework of information archival. The IW is a
significant yet technologically realizable conceptual advancement which can
support efficiently some interesting classes of applications which can be very
useful to the knowledge workers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0448</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0448</id><created>2009-12-02</created><authors><author><keyname>W&#xe4;stlund</keyname><forenames>Johan</forenames></author></authors><title>The strange algebra of combinatorial games</title><categories>math.CO cs.GT</categories><comments>21 pages</comments><msc-class>91A46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algebraic framework for the analysis of combinatorial games.
This framework embraces the classical theory of partizan games as well as a
number of misere games, comply-constrain games, and card games that have been
studied more recently. It focuses on the construction of the quotient monoid of
a game, an idea that has been successively applied to several classes of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0453</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0453</id><created>2009-12-02</created><authors><author><keyname>Finiasz</keyname><forenames>Matthieu</forenames></author></authors><title>NP-completeness of Certain Sub-classes of the Syndrome Decoding Problem</title><categories>cs.CR cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of Syndrome Decoding was proven to be NP-complete in 1978 and,
since then, quite a few cryptographic applications have had their security rely
on the (provable) difficulty of solving some instances of it. However, in most
cases, the instances to be solved follow some specific constraint: the target
weight is a function of the dimension and length of the code. In these cases,
is the Syndrome Decoding problem still NP-complete? This is the question that
this article intends to answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0473</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0473</id><created>2009-12-02</created><authors><author><keyname>Fernandez-Amoros</keyname><forenames>David</forenames></author><author><keyname>Heradio</keyname><forenames>Ruben</forenames></author><author><keyname>Cerrada</keyname><forenames>Jose Antonio</forenames></author></authors><title>Inferring Information from Feature Diagrams to Product Line Economic
  Models</title><categories>cs.SE</categories><comments>latex2e, 10 pages, 6 figures</comments><journal-ref>Published in the Proceedings of the Software Product Line
  Conference 2009, San Francisco</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing economic models support the estimation of the costs and benefits of
developing and evolving a Software Product Line (SPL) as compared to
undertaking traditional software development approaches. In addition, Feature
Diagrams (FDs) are a valuable tool to scope the domain of a SPL. This paper
proposes an algorithm to calculate, from a FD, the following information for
economic models: the total number of products of a SPL, the SPL homogeneity and
the commonality of the SPL requirements. The algorithm running time belongs to
the complexity class $O(f^42^c)$. In contrast to related work, the algorithm is
free of dependencies on off-the-self tools and is generally specified for an
abstract FD notation, that works as a pivot language for most of the available
notations for feature modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0537</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0537</id><created>2009-12-02</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Mumford</keyname><forenames>Elena</forenames></author></authors><title>Steinitz Theorems for Orthogonal Polyhedra</title><categories>cs.CG math.CO</categories><comments>48 pages, 31 figures</comments><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a simple orthogonal polyhedron to be a three-dimensional polyhedron
with the topology of a sphere in which three mutually-perpendicular edges meet
at each vertex. By analogy to Steinitz's theorem characterizing the graphs of
convex polyhedra, we find graph-theoretic characterizations of three classes of
simple orthogonal polyhedra: corner polyhedra, which can be drawn by isometric
projection in the plane with only one hidden vertex, xyz polyhedra, in which
each axis-parallel line through a vertex contains exactly one other vertex, and
arbitrary simple orthogonal polyhedra. In particular, the graphs of xyz
polyhedra are exactly the bipartite cubic polyhedral graphs, and every
bipartite cubic polyhedral graph with a 4-connected dual graph is the graph of
a corner polyhedron. Based on our characterizations we find efficient
algorithms for constructing orthogonal polyhedra from their graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0549</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0549</id><created>2009-12-02</created><authors><author><keyname>Vetter</keyname><forenames>R. -M.</forenames></author><author><keyname>Lennartz</keyname><forenames>W.</forenames></author><author><keyname>Peetz</keyname><forenames>J. -V.</forenames></author></authors><title>Modular Workflow Engine for Distributed Services using Lightweight Java
  Clients</title><categories>cs.SE cs.CE</categories><comments>14 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we introduce the concept and the first implementation of a
lightweight client-server-framework as middleware for distributed computing. On
the client side an installation without administrative rights or privileged
ports can turn any computer into a worker node. Only a Java runtime environment
and the JAR files comprising the workflow client are needed. To connect all
clients to the engine one open server port is sufficient. The engine submits
data to the clients and orchestrates their work by workflow descriptions from a
central database. Clients request new task descriptions periodically, thus the
system is robust against network failures. In the basic set-up, data up- and
downloads are handled via HTTP communication with the server. The performance
of the modular system could additionally be improved using dedicated file
servers or distributed network file systems.
  We demonstrate the design features of the proposed engine in real-world
applications from mechanical engineering. We have used this system on a compute
cluster in design-of-experiment studies, parameter optimisations and robustness
validations of finite element structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0555</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0555</id><created>2009-12-02</created><authors><author><keyname>Soboci&#x144;ski</keyname><forenames>Pawe&#x142;</forenames><affiliation>ECS, University of Southampton</affiliation></author></authors><title>A non-interleaving process calculus for multi-party synchronisation</title><categories>cs.LO cs.PL</categories><journal-ref>EPTCS 12, 2009, pp. 87-98</journal-ref><doi>10.4204/EPTCS.12.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the wire calculus. Its dynamic features are inspired by Milner's
CCS: a unary prefix operation, binary choice and a standard recursion
construct. Instead of an interleaving parallel composition operator there are
operators for synchronisation along a common boundary and non-communicating
parallel composition. The (operational) semantics is a labelled transition
system obtained with SOS rules. Bisimilarity is a congruence with respect to
the operators of the language. Quotienting terms by bisimilarity results in a
compact closed category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0568</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0568</id><created>2009-12-02</created><authors><author><keyname>Beame</keyname><forenames>Paul</forenames></author><author><keyname>Huynh</keyname><forenames>Trinh</forenames></author><author><keyname>Pitassi</keyname><forenames>Toniann</forenames></author></authors><title>Hardness Amplification in Proof Complexity</title><categories>cs.CC</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general method for converting any family of unsatisfiable CNF
formulas that is hard for one of the simplest proof systems, tree resolution,
into formulas that require large rank in any proof system that manipulates
polynomials or polynomial threshold functions of degree at most k (known as
Th(k) proofs). Such systems include Lovasz-Schrijver and Cutting Planes proof
systems as well as their high degree analogues.
  These are based on analyzing two new proof systems, denoted by T^cc(k) and
R^cc(k). The proof lines of T^cc(k) are arbitrary Boolean functions, each of
which can be evaluated by an efficient k-party randomized communication
protocol. They include Th{k-1} proofs as a special case. R^cc(k) proofs are
stronger and only require that each inference be locally checkable by an
efficient k-party randomized communication protocol.
  Our main results are the following:
  (1) When k is O(loglogn), for any unsatisfiable CNF formula F requiring
resolution rank r, there is a related CNF formula G=Lift_k(F) requiring
refutation rank r^Omega(1/k) log^O(1) n in all R^cc(k) systems.
  (2) There are strict hierarchies for T^cc(k) and R^cc(k) systems with respect
to k when k is O(loglogn in that there are unsatisfiable CNF formulas requiring
large rank R^cc(k) refutations but having log^O(1) n rank Th(k) refutations.
  (3) When k is O(loglogn) there are 2^(n^Omega(1/k)) lower bounds on the size
of tree-like T^cc(k) refutations for large classes of lifted CNF formulas.
  (4) A general method for producing integrality gaps for low rank R^cc(2)
inference (and hence Cutting Planes and Th(1) inference) based on related gaps
for low rank resolution. These gaps are optimal for MAX-2t-SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0572</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0572</id><created>2009-12-02</created><authors><author><keyname>Fan</keyname><forenames>Mingyu</forenames></author><author><keyname>Qiao</keyname><forenames>Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Bo</forenames></author></authors><title>Isometric Multi-Manifolds Learning</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isometric feature mapping (Isomap) is a promising manifold learning method.
However, Isomap fails to work on data which distribute on clusters in a single
manifold or manifolds. Many works have been done on extending Isomap to
multi-manifolds learning. In this paper, we first proposed a new
multi-manifolds learning algorithm (M-Isomap) with help of a general procedure.
The new algorithm preserves intra-manifold geodesics and multiple
inter-manifolds edges precisely. Compared with previous methods, this algorithm
can isometrically learn data distributed on several manifolds. Secondly, the
original multi-cluster manifold learning algorithm first proposed in
\cite{DCIsomap} and called D-C Isomap has been revised so that the revised D-C
Isomap can learn multi-manifolds data. Finally, the features and effectiveness
of the proposed multi-manifolds learning algorithms are demonstrated and
compared through experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0578</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0578</id><created>2009-12-03</created><authors><author><keyname>Fang</keyname><forenames>Li</forenames></author><author><keyname>Leung</keyname><forenames>Maylor K. H.</forenames></author><author><keyname>Chian</keyname><forenames>Cheng Shao</forenames></author></authors><title>Making Palm Print Matching Mobile</title><categories>cs.CR</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 001-009, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing importance of personal identification and authentication in
todays highly advanced world where most business and personal tasks are being
replaced by electronic means, the need for a technology that is able to
uniquely identify an individual and has high fraud resistance see the rise of
biometric technologies. Making biometric based solution mobile is a promising
trend. A new RST invariant square based palm print ROI extraction method was
successfully implemented and integrated into the current application suite. A
new set of palm print image database captured using embedded cameras in mobile
phone was created to test its robustness. Comparing to those extraction methods
that are based on boundary tracking of the overall hand shape that has
limitation of being unable to process palm print images that has one or more
fingers closed, the system can now effectively handle the segmentation of palm
print images with varying finger positioning. The high flexibility makes palm
print matching mobile possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0579</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0579</id><created>2009-12-03</created><authors><author><keyname>Ali</keyname><forenames>Mohammad Ghulam</forenames></author></authors><title>A Multidatabase System as 4-Tiered Client-Server Distributed
  Heterogeneous Database System</title><categories>cs.DB</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 010-014, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe a multidatabase system as 4tiered Client-Server
DBMS architectures. We discuss their functional components and provide an
overview of their performance characteristics. The first component of this
proposed system is a web based interface or Graphical User Interface, which
resides on top of the Client Application Program, the second component of the
system is a client Application program running in an application server, which
resides on top of the Global Database Management System, the third component of
the system is a Global Database Management System and global schema of the
multidatabase system server, which resides on top of the distributed
heterogeneous local component database system servers, and the fourth component
is remote heterogeneous local component database system servers. Transaction
submitted from client interface to a multidatabase system server through an
application server will be decomposed into a set of sub queries and will be
executed at various remote heterogeneous local component database servers and
also in case of information retrieval all sub queries will be composed and will
get back results to the end users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0580</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0580</id><created>2009-12-03</created><authors><author><keyname>Lee</keyname><forenames>Yunho</forenames></author><author><keyname>Lee</keyname><forenames>Soojin</forenames></author></authors><title>A New Efficient Key Management Protocol for Wireless Sensor and Actor
  Networks</title><categories>cs.CR</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 015-022, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on sensor networks has become much more active and is currently
being applied to many different fields. However since sensor networks are
limited to only collecting and reporting information regarding a certain event,
and requires human intervention with that given information, it is often
difficult to react to an event or situation immediately and proactively. To
overcome this kind of limitation, Wireless Sensor and Actor Networks (WSANs)
with immediate-response actor nodes have been proposed which adds greater
mobility and activity to the existing sensor networks. Although WSANs share
many common grounds with sensor networks, it is difficult to apply existing
security technologies due to the fact that WSANs contain actor nodes that are
resource-independent and mobile. Therefore, this research seeks to demonstrate
ways to provide security, integrity, and authentication services for WSANs
secure operation, by separating networks into hierarchical structure by each
node's abilities and provides different encryption key based secure protocols
for each level of hierarchy, Pairwise key, node key, and region key for sensor
levels, and public key for actor
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0581</identifier>
 <datestamp>2013-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0581</id><created>2009-12-03</created><updated>2011-09-27</updated><authors><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author></authors><title>Log-concavity, ultra-log-concavity, and a maximum entropy property of
  discrete compound Poisson measures</title><categories>math.CO cs.IT math.IT math.PR</categories><comments>30 pages. This submission supersedes arXiv:0805.4112v1. Changes in
  v2: Updated references, typos corrected</comments><msc-class>94A17, 60E07, 60E15</msc-class><journal-ref>Discrete Applied Mathematics, vol 161/9, pages 1232-1250, 2013</journal-ref><doi>10.1016/j.dam.2011.08.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sufficient conditions are developed, under which the compound Poisson
distribution has maximal entropy within a natural class of probability measures
on the nonnegative integers. Recently, one of the authors [O. Johnson, {\em
Stoch. Proc. Appl.}, 2007] used a semigroup approach to show that the Poisson
has maximal entropy among all ultra-log-concave distributions with fixed mean.
We show via a non-trivial extension of this semigroup approach that the natural
analog of the Poisson maximum entropy property remains valid if the compound
Poisson distributions under consideration are log-concave, but that it fails in
general. A parallel maximum entropy result is established for the family of
compound binomial measures. Sufficient conditions for compound distributions to
be log-concave are discussed and applications to combinatorics are examined;
new bounds are derived on the entropy of the cardinality of a random
independent set in a claw-free graph, and a connection is drawn to Mason's
conjecture for matroids. The present results are primarily motivated by the
desire to provide an information-theoretic foundation for compound Poisson
approximation and associated limit theorems, analogous to the corresponding
developments for the central limit theorem and for Poisson approximation. Our
results also demonstrate new links between some probabilistic methods and the
combinatorial notions of log-concavity and ultra-log-concavity, and they add to
the growing body of work exploring the applications of maximum entropy
characterizations to problems in discrete mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0583</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0583</id><created>2009-12-03</created><authors><author><keyname>Meyer</keyname><forenames>David A.</forenames></author><author><keyname>Pommersheim</keyname><forenames>James</forenames></author></authors><title>Single query learning from abelian and non-abelian Hamming distance
  oracles</title><categories>quant-ph cs.CC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of identifying an n-bit string using a single quantum
query to an oracle that computes the Hamming distance between the query and
hidden strings. The standard action of the oracle on a response register of
dimension r is by powers of the cycle (1...r), all of which, of course,
commute. We introduce a new model for the action of an oracle--by general
permutations in S_r--and explore how the success probability depends on r and
on the map from Hamming distances to permutations. In particular, we prove that
when r = 2, for even n the success probability is 1 with the right choice of
the map, while for odd n the success probability cannot be 1 for any choice.
Furthermore, for small odd n and r = 3, we demonstrate numerically that the
image of the optimal map generates a non-abelian group of permutations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0597</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0597</id><created>2009-12-03</created><authors><author><keyname>Huber</keyname><forenames>Michael</forenames></author></authors><title>Constructing Optimal Authentication Codes with Perfect Multi-fold
  Secrecy</title><categories>cs.CR cs.IT math.IT</categories><comments>4 pages (double-column); to appear in Proc. 2010 International Zurich
  Seminar on Communications (IZS 2010, Zurich)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a construction of optimal authentication codes achieving perfect
multi-fold secrecy by means of combinatorial designs. This continues the
author's work (ISIT 2009) and answers an open question posed therein. As an
application, we present the first infinite class of optimal codes that provide
two-fold security against spoofing attacks and at the same time perfect two-
fold secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0599</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0599</id><created>2009-12-03</created><authors><author><keyname>Fedaghi</keyname><forenames>Sabah Al</forenames></author><author><keyname>Alsaqa</keyname><forenames>Alaa</forenames></author><author><keyname>Fadel</keyname><forenames>Zahraa</forenames></author></authors><title>Conceptual Model for Communication</title><categories>cs.NI cs.IT math.IT</categories><comments>13 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 029-041, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variety of idealized models of communication systems exist, and all may
have something in common. Starting with Shannons communication model and ending
with the OSI model, this paper presents progressively more advanced forms of
modeling of communication systems by tying communication models together based
on the notion of flow. The basic communication process is divided into
different spheres (sources, channels, and destinations), each with its own five
interior stages, receiving, processing, creating, releasing, and transferring
of information. The flow of information is ontologically distinguished from the
flow of physical signals, accordingly, Shannons model, network based OSI
models, and TCP IP are redesigned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0600</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0600</id><created>2009-12-03</created><authors><author><keyname>Ghahari</keyname><forenames>Alireza</forenames></author><author><keyname>Zoroofi</keyname><forenames>Reza Aghaeizadeh</forenames></author></authors><title>Sequential Clustering based Facial Feature Extraction Method for
  Automatic Creation of Facial Models from Orthogonal Views</title><categories>cs.CV</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 042-047, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiview 3D face modeling has attracted increasing attention recently and
has become one of the potential avenues in future video systems. We aim to make
more reliable and robust automatic feature extraction and natural 3D feature
construction from 2D features detected on a pair of frontal and profile view
face images. We propose several heuristic algorithms to minimize possible
errors introduced by prevalent nonperfect orthogonal condition and noncoherent
luminance. In our approach, we first extract the 2D features that are visible
to both cameras in both views. Then, we estimate the coordinates of the
features in the hidden profile view based on the visible features extracted in
the two orthogonal views. Finally, based on the coordinates of the extracted
features, we deform a 3D generic model to perform the desired 3D clone
modeling. Present study proves the scope of resulted facial models for
practical applications like face recognition and facial animation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0602</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0602</id><created>2009-12-03</created><authors><author><keyname>Ramesh</keyname><forenames>G.</forenames></author><author><keyname>SundaraVadivelu</keyname><forenames>S.</forenames></author></authors><title>A Reliable and Fault Tolerant Routing for Optical WDM Networks</title><categories>cs.NI</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 048-054, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In optical WDM networks, since each lightpath can carry a huge mount of
traffic, failures may seriously damage the end user applications. Hence fault
tolerance becomes an important issue on these networks. The light path which
carries traffic during normal operation is called as primary path. The traffic
is rerouted on a backup path in case of a failure. In this paper we propose to
design a reliable and fault tolerant routing algorithm for establishing primary
and backup paths. In order to establish the primary path, this algorithm uses
load balancing in which link cost metrics are estimated based on the current
load of the links. In backup path setup, the source calculates the blocking
probability through the received feedback from the destination by sending a
small fraction of probe packets along the existing paths. It then selects the
optimal light path with the lowest blocking probability. Based on the
simulation results, we show that the reliable and fault tolerant routing
algorithm reduces the blocking probability and latency while increasing the
throughput and channel utilization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0603</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0603</id><created>2009-12-03</created><authors><author><keyname>Ali</keyname><forenames>Mohammad Ghulam</forenames></author></authors><title>Object Oriented Approach for Integration of Heterogeneous Databases in a
  Multidatabase System and Local Schemas Modifications Propagation</title><categories>cs.DB</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 055-060, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenging problems in the multidatabase systems is to find the
most viable solution to the problem of interoperability of distributed
heterogeneous autonomous local component databases. This has resulted in the
creation of a global schema over set of these local component database schemas
to provide a uniform representation of local schemas. The aim of this paper is
to use object oriented approach to integrate schemas of distributed
heterogeneous autonomous local component database schemas into a global schema.
The resulting global schema provides a uniform interface and high level of
location transparency for retrieval of data from the local component databases.
A set of integration operators are defined to integrate local schemas based on
the semantic relevance of their classes and to provide a model independent
representation of virtual classes of the global schema. The schematic
representation and heterogeneity is also taken into account in the integration
process. Justifications about Object Oriented Modal are also discussed. Bottom
up local schema modifications propagation in Global schema is also considered
to maintain Global schema as local schemas are autonomous and evolve over time.
An example illustrates the applicability of the integration operator defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0606</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0606</id><created>2009-12-03</created><authors><author><keyname>Yaashuwanth</keyname><forenames>C.</forenames></author><author><keyname>Ramesh</keyname><forenames>Dr. R.</forenames></author></authors><title>A New Scheduling Algorithms For Real Time Tasks</title><categories>cs.OS</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 061-066, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of this paper is to develop the two different ways in
which round robin architecture is modified and made suitable to be implemented
in real time and embedded systems. The scheduling algorithm plays a significant
role in the design of real time embedded systems. Simple round robin
architecture is not efficient to be implemented in embedded systems because of
higher context switch rate, larger waiting time and larger response time.
Missing of deadlines will degrade the system performance in soft real time
systems. The main objective of this paper is to develop the scheduling
algorithm which removes the drawbacks in simple round robin architecture. A
comparison with round robin architecture to the proposed architectures has been
made. It is observed that the proposed architectures solves the problems
encountered in round robin architecture in soft real time by decreasing the
number of context switches waiting time and response time thereby increasing
the system throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0607</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0607</id><created>2009-12-03</created><authors><author><keyname>Devi</keyname><forenames>P. Meenakshi</forenames></author><author><keyname>Venkatesan</keyname><forenames>M.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Reversible Image Authentication with Tamper Localization Based on
  Integer Wavelet Transform</title><categories>cs.CR cs.CV</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 067-074, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new reversible image authentication technique with tamper
localization based on watermarking in integer wavelet transform is proposed. If
the image authenticity is verified, then the distortion due to embedding the
watermark can be completely removed from the watermarked image. If the image is
tampered, then the tampering positions can also be localized. Two layers of
watermarking are used. The first layer embedded in spatial domain verifies
authenticity and the second layer embedded in transform domain provides
reversibility. This technique utilizes selective LSB embedding and histogram
characteristics of the difference images of the wavelet coefficients and
modifies pixel values slightly to embed the watermark. Experimental results
demonstrate that the proposed scheme can detect any modifications of the
watermarked image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0625</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0625</id><created>2009-12-03</created><authors><author><keyname>Kaune</keyname><forenames>Sebastian</forenames></author><author><keyname>Rumin</keyname><forenames>Ruben Cuevas</forenames></author><author><keyname>Tyson</keyname><forenames>Gareth</forenames></author><author><keyname>Mauthe</keyname><forenames>Andreas</forenames></author><author><keyname>Guerrero</keyname><forenames>Carmen</forenames></author><author><keyname>Steinmetz</keyname><forenames>Ralf</forenames></author></authors><title>Unraveling BitTorrent's File Unavailability: Measurements, Analysis and
  Solution Exploration</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BitTorrent suffers from one fundamental problem: the long-term availability
of content. This occurs on a massive-scale with 38% of torrents becoming
unavailable within the first month. In this paper we explore this problem by
performing two large-scale measurement studies including 46K torrents and 29M
users. The studies go significantly beyond any previous work by combining
per-node, per-torrent and system-wide observations to ascertain the causes,
characteristics and repercussions of file unavailability. The study confirms
the conclusion from previous works that seeders have a significant impact on
both performance and availability. However, we also present some crucial new
findings: (i) the presence of seeders is not the sole factor involved in file
availability, (ii) 23.5% of nodes that operate in seedless torrents can finish
their downloads, and (iii) BitTorrent availability is discontinuous, operating
in cycles of temporary unavailability. Due to our new findings, we consider it
is important to revisit the solution space; to this end, we perform large-scale
trace-based simulations to explore the potential of two abstract approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0670</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0670</id><created>2009-12-03</created><authors><author><keyname>Weber</keyname><forenames>Richard</forenames></author></authors><title>The Anderson-Weber strategy is not optimal for symmetric rendezvous
  search on K4</title><categories>math.OC cs.GT</categories><comments>6 pages</comments><msc-class>90B40; 49N75; 90C22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the symmetric rendezvous search game on a complete graph of n
locations. In 1990, Anderson and Weber proposed a strategy in which, over
successive blocks of n-1 steps, the players independently choose either to stay
at their initial location or to tour the other n-1 locations, with
probabilities p and 1-p, respectively. Their strategy has been proved optimal
for n=2 with p=1/2, and for n=3 with p=1/3. The proof for n=3 is very
complicated and it has been difficult to guess what might be true for n&gt;3.
Anderson and Weber suspected that their strategy might not be optimal for n&gt;3,
but they had no particular reason to believe this and no one has been able to
find anything better. This paper describes a strategy that is better than
Anderson--Weber for n=4. However, it is better by only a tiny fraction of a
percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0681</identifier>
 <datestamp>2011-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0681</id><created>2009-12-03</created><updated>2011-10-20</updated><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Orecchia</keyname><forenames>Lorenzo</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>A Local Spectral Method for Graphs: with Applications to Improving Graph
  Partitions and Exploring Data Graphs Locally</title><categories>cs.DS</categories><comments>24 pages. Completely rewritten; substance is still the same, but the
  presentation is reworked</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second eigenvalue of the Laplacian matrix and its associated eigenvector
are fundamental features of an undirected graph, and as such they have found
widespread use in scientific computing, machine learning, and data analysis. In
many applications, however, graphs that arise have several \emph{local} regions
of interest, and the second eigenvector will typically fail to provide
information fine-tuned to each local region. In this paper, we introduce a
locally-biased analogue of the second eigenvector, and we demonstrate its
usefulness at highlighting local properties of data graphs in a semi-supervised
manner. To do so, we first view the second eigenvector as the solution to a
constrained optimization problem, and we incorporate the local information as
an additional constraint; we then characterize the optimal solution to this new
problem and show that it can be interpreted as a generalization of a
Personalized PageRank vector; and finally, as a consequence, we show that the
solution can be computed in nearly-linear time. In addition, we show that this
locally-biased vector can be used to compute an approximation to the best
partition \emph{near} an input seed set in a manner analogous to the way in
which the second eigenvector of the Laplacian can be used to obtain an
approximation to the best partition in the entire input graph. Such a primitive
is useful for identifying and refining clusters locally, as it allows us to
focus on a local region of interest in a semi-supervised manner. Finally, we
provide a detailed empirical evaluation of our method by showing how it can
applied to finding locally-biased sparse cuts around an input vertex seed set
in social and information networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0685</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0685</id><created>2009-12-03</created><updated>2010-03-05</updated><authors><author><keyname>Berger</keyname><forenames>Annabell</forenames></author><author><keyname>M&#xfc;ller-Hannemann</keyname><forenames>Matthias</forenames></author></authors><title>Uniform sampling of undirected and directed graphs with a fixed degree
  sequence</title><categories>cs.DM cs.DS</categories><acm-class>F.2.2; G.2.2; G.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications in network analysis require algorithms to sample uniformly
at random from the set of all graphs with a prescribed degree sequence. We
present a Markov chain based approach which converges to the uniform
distribution of all realizations for both the directed and undirected case. It
remains an open challenge whether these Markov chains are rapidly mixing.
  For the case of directed graphs, we also explain in this paper that a popular
switching algorithm fails in general to sample uniformly at random because the
state graph of the Markov chain decomposes into different isomorphic
components. We call degree sequences for which the state graph is strongly
connected arc swap sequences. To handle arbitrary degree sequences, we develop
two different solutions. The first uses an additional operation (a
reorientation of induced directed 3-cycles) which makes the state graph
strongly connected, the second selects randomly one of the isomorphic
components and samples inside it. Our main contribution is a precise
characterization of arc swap sequences, leading to an efficient recognition
algorithm. Finally, we point out some interesting consequences for network
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0717</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0717</id><created>2009-12-03</created><authors><author><keyname>Gregor</keyname><forenames>Karol</forenames></author><author><keyname>Griffin</keyname><forenames>Gregory</forenames></author></authors><title>Behavior and performance of the deep belief networks on image
  classification</title><categories>cs.NE cs.CV</categories><comments>8 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply deep belief networks of restricted Boltzmann machines to bags of
words of sift features obtained from databases of 13 Scenes, 15 Scenes and
Caltech 256 and study experimentally their behavior and performance. We find
that the final performance in the supervised phase is reached much faster if
the system is pre-trained. Pre-training the system on a larger dataset keeping
the supervised dataset fixed improves the performance (for the 13 Scenes case).
After the unsupervised pre-training, neurons arise that form approximate
explicit representations for several categories (meaning they are mostly active
for this category). The last three facts suggest that unsupervised training
really discovers structure in these data. Pre-training can be done on a
completely different dataset (we use Corel dataset) and we find that the
supervised phase performs just as good (on the 15 Scenes dataset). This leads
us to conjecture that one can pre-train the system once (e.g. in a factory) and
subsequently apply it to many supervised problems which then learn much faster.
The best performance is obtained with single hidden layer system suggesting
that the histogram of sift features doesn't have much high level structure. The
overall performance is almost equal, but slightly worse then that of the
support vector machine and the spatial pyramidal matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0741</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0741</id><created>2009-12-04</created><updated>2010-05-16</updated><authors><author><keyname>Neary</keyname><forenames>Turlough</forenames></author></authors><title>A boundary between universality and non-universality in spiking neural P
  systems</title><categories>cs.CC</categories><comments>Version 1 (arXiv:0912.0741v1) of this paper contained some technical
  errors that were mainly due to the restriction of counter machines used.
  Definition 3 given in this version differs from the definition given in
  version 1. This new definition necessitated some minor adjustments in proofs
  of Theorems 1, 2 and 3.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we offer a significant improvement on the previous smallest
spiking neural P systems and solve the problem of finding the smallest possible
extended spiking neural P system. Paun and Paun gave a universal spiking neural
P system with 84 neurons and another that has extended rules with 49 neurons.
Subsequently, Zhang et al. reduced the number of neurons used to give
universality to 67 for spiking neural P systems and to 41 for the extended
model. Here we give a small universal spiking neural P system that has only 17
neurons and another that has extended rules with 5 neurons. All of the above
mentioned spiking neural P systems suffer from an exponential slow down when
simulating Turing machines. Using a more relaxed encoding technique we get a
universal spiking neural P system that has extended rules with only 4 neurons.
This latter spiking neural P system simulates 2-counter machines in linear time
and thus suffer from a double exponential time overhead when simulating Turing
machines. We show that extended spiking neural P systems with 3 neurons are
simulated by log-space bounded Turing machines, and so there exists no such
universal system with 3 neurons. It immediately follows that our 4-neuron
system is the smallest possible extended spiking neural P system that is
universal. Finally, we show that if we generalise the output technique we can
give a universal spiking neural P system with extended rules that has only 3
neurons. This system is also the smallest of its kind as a universal spiking
neural P system with extended rules and generalised output is not possible with
2 neurons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0745</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0745</id><created>2009-12-04</created><authors><author><keyname>R.</keyname><forenames>Mary Lourde</forenames></author><author><keyname>Saji</keyname><forenames>Anjali Kuppayil</forenames></author></authors><title>A Digital Guitar Tuner</title><categories>cs.SD</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 082-088, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to understand the critical parameters that
need to be addressed while designing a guitar tuner. The focus of the design
lies in developing a suitable algorithm to accurately detect the fundamental
frequency of a plucked guitar string from its frequency spectrum. A
userfriendly graphical interface is developed using Matlab to allow any user to
easily tune his guitar using the developed program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0746</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0746</id><created>2009-12-03</created><authors><author><keyname>Altshuler</keyname><forenames>Boris</forenames></author><author><keyname>Krovi</keyname><forenames>Hari</forenames></author><author><keyname>Roland</keyname><forenames>Jeremie</forenames></author></authors><title>Anderson localization casts clouds over adiabatic quantum optimization</title><categories>quant-ph cond-mat.mes-hall cs.CC</categories><comments>14 pages, 4 figures</comments><journal-ref>Proceedings of the National Academy of Sciences of the United
  States of America, 107(28):12446-12450, 2010</journal-ref><doi>10.1073/pnas.1002116107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding NP-complete problems is a central topic in computer science.
This is why adiabatic quantum optimization has attracted so much attention, as
it provided a new approach to tackle NP-complete problems using a quantum
computer. The efficiency of this approach is limited by small spectral gaps
between the ground and excited states of the quantum computer's Hamiltonian. We
show that the statistics of the gaps can be analyzed in a novel way, borrowed
from the study of quantum disordered systems in statistical mechanics. It turns
out that due to a phenomenon similar to Anderson localization, exponentially
small gaps appear close to the end of the adiabatic algorithm for large random
instances of NP-complete problems. This implies that unfortunately, adiabatic
quantum optimization fails: the system gets trapped in one of the numerous
local minima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0750</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0750</id><created>2009-12-03</created><updated>2011-12-18</updated><authors><author><keyname>Nayebi</keyname><forenames>Aran</forenames></author></authors><title>Fast matrix multiplication techniques based on the Adleman-Lipton model</title><categories>q-bio.QM cs.DS cs.ET</categories><comments>To appear in the International Journal of Computer Engineering
  Research. Minor changes made to make the preprint as similar as possible to
  the published version</comments><msc-class>65F05, 03D10 (Primary) 68Q10, 68Q05, 03D80 (Secondary)</msc-class><journal-ref>International Journal of Computer Engineering Research,
  3(1):10-19, January 2012</journal-ref><doi>10.5897/IJCER10.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On distributed memory electronic computers, the implementation and
association of fast parallel matrix multiplication algorithms has yielded
astounding results and insights. In this discourse, we use the tools of
molecular biology to demonstrate the theoretical encoding of Strassen's fast
matrix multiplication algorithm with DNA based on an $n$-moduli set in the
residue number system, thereby demonstrating the viability of computational
mathematics with DNA. As a result, a general scalable implementation of this
model in the DNA computing paradigm is presented and can be generalized to the
application of \emph{all} fast matrix multiplication algorithms on a DNA
computer. We also discuss the practical capabilities and issues of this
scalable implementation. Fast methods of matrix computations with DNA are
important because they also allow for the efficient implementation of other
algorithms (i.e. inversion, computing determinants, and graph theory) with DNA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0756</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0756</id><created>2009-12-03</created><authors><author><keyname>Duarte</keyname><forenames>Melissa</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author><author><keyname>Dick</keyname><forenames>Chris</forenames></author><author><keyname>Rao</keyname><forenames>Raghu</forenames></author></authors><title>Beamforming in MISO Systems: Empirical Results and EVM-based Analysis</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications, November
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytical, simulation, and experimental-based study of
beamforming Multiple Input Single Output (MISO) systems. We analyze the
performance of beamforming MISO systems taking into account implementation
complexity and effects of imperfect channel estimate, delayed feedback, real
Radio Frequency (RF) hardware, and imperfect timing synchronization. Our
results show that efficient implementation of codebook-based beamforming MISO
systems with good performance is feasible in the presence of channel and
implementation-induced imperfections. As part of our study we develop a
framework for Average Error Vector Magnitude Squared (AEVMS)-based analysis of
beamforming MISO systems which facilitates comparison of analytical,
simulation, and experimental results on the same scale. In addition, AEVMS
allows fair comparison of experimental results obtained from different wireless
testbeds. We derive novel expressions for the AEVMS of beamforming MISO systems
and show how the AEVMS relates to important system characteristics like the
diversity gain, coding gain, and error floor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0758</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0758</id><created>2009-12-04</created><authors><author><keyname>Chattopadhyay</keyname><forenames>Sudipta</forenames></author><author><keyname>Sanyal</keyname><forenames>Salil Kumar</forenames></author></authors><title>Comparison of Performance Metrics for QPSK and OQPSK Transmission Using
  Root Raised Cosine and Raised Cosine Pulse shaping Filters for Applications
  in Mobile Communication</title><categories>cs.IT math.IT</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 106-112, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadrature Phase Shift Keying (QPSK) and Offset Quadrature Phase Shift Keying
(OQPSK) are two well accepted modulation techniques used in Code Division
Multiple Access (CDMA) system. The Pulse Shaping Filters play an important role
in digital transmission. The type of Pulse Shaping Filter used, and its
behavior would influence the performance of the communication system. This in
turn, would have an effect on the performance of the Mobile Communication
system, in which the digital communication technique has been employed. In this
paper we have presented comparative study of some performance parameters or
performance metrics of a digital communication system like, Error Vector
Magnitude (EVM), Magnitude Error, Phase Error and Bandwidth Efficiency for a
QPSK transmission system. Root Raised Cosine (RRC) and Raised Cosine (RC) Pulse
shaping filters have been used for comparison. The measurement results serve as
a guideline to the system designer to select the proper pulse shaping filter
with the appropriate value of filter roll off factor (a) in a QPSK modulated
mobile communication system for optimal values of its different performance
metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0759</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0759</id><created>2009-12-03</created><authors><author><keyname>Bonchi</keyname><forenames>Filippo</forenames><affiliation>CWI, Netherland</affiliation></author><author><keyname>Grohmann</keyname><forenames>Davide</forenames><affiliation>University of Udine, Italy</affiliation></author><author><keyname>Spoletini</keyname><forenames>Paola</forenames><affiliation>University of Insubria - Como, Italy</affiliation></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames><affiliation>University of Leicester, UK</affiliation></author></authors><title>Proceedings 2nd Interaction and Concurrency Experience: Structured
  Interactions</title><categories>cs.LO cs.CR cs.DC cs.PL</categories><journal-ref>EPTCS 12, 2009</journal-ref><doi>10.4204/EPTCS.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 2nd Workshop on Interaction and
Concurrency Experience (ICE'09). The workshop was held in Bologna, Italy on
31th of August 2009, as a satellite workshop of CONCUR'09. The previous edition
of ICE has been organized in Reykjavik (2008).
  The ICE workshop is intended as a series of international scientific meetings
oriented to researchers in various fields of theoretical computer science and,
each year, the workshop focuses on a specific topic: ICE 2009 focused on
structured interactions meant as the class of synchronisations that go beyond
the &quot;simple&quot; point-to-point synchronisations (e.g., multicast or broadcast
synchronisations, even-notification based interactions, time dependent
interactions, distributed transactions,...).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0765</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0765</id><created>2009-12-03</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Brown</keyname><forenames>J. David</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author><author><keyname>Pasupathy</keyname><forenames>Subbarayan</forenames></author></authors><title>On the Energy Efficiency of LT Codes in Proactive Wireless Sensor
  Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Wireless Communications (25 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the first in-depth analysis on the energy efficiency of
LT codes with Non Coherent M-ary Frequency Shift Keying (NC-MFSK), known as
green modulation [1], in a proactive Wireless Sensor Network (WSN) over
Rayleigh flat-fading channels with path-loss. We describe the proactive system
model according to a pre-determined time-based process utilized in practical
sensor nodes. The present analysis is based on realistic parameters including
the effect of channel bandwidth used in the IEEE 802.15.4 standard, and the
active mode duration. A comprehensive analysis, supported by some simulation
studies on the probability mass function of the LT code rate and coding gain,
shows that among uncoded NC-MFSK and various classical channel coding schemes,
the optimized LT coded NC-MFSK is the most energy-efficient scheme for distance
$d$ greater than the pre-determined threshold level $d_T$, where the
optimization is performed over coding and modulation parameters. In addition,
although uncoded NC-MFSK outperforms coded schemes for $d &lt; d_T$, the energy
gap between LT coded and uncoded NC-MFSK is negligible for $d &lt; d_T$ compared
to the other coded schemes. These results come from the flexibility of the LT
code to adjust its rate to suit instantaneous channel conditions, and suggest
that LT codes are beneficial in practical low-power WSNs with dynamic position
sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0779</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0779</id><created>2009-12-04</created><authors><author><keyname>Neven</keyname><forenames>Hartmut</forenames></author><author><keyname>Denchev</keyname><forenames>Vasil S.</forenames></author><author><keyname>Rose</keyname><forenames>Geordie</forenames></author><author><keyname>Macready</keyname><forenames>William G.</forenames></author></authors><title>Training a Large Scale Classifier with the Quantum Adiabatic Algorithm</title><categories>quant-ph cs.LG</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous publication we proposed discrete global optimization as a
method to train a strong binary classifier constructed as a thresholded sum
over weak classifiers. Our motivation was to cast the training of a classifier
into a format amenable to solution by the quantum adiabatic algorithm. Applying
adiabatic quantum computing (AQC) promises to yield solutions that are superior
to those which can be achieved with classical heuristic solvers. Interestingly
we found that by using heuristic solvers to obtain approximate solutions we
could already gain an advantage over the standard method AdaBoost. In this
communication we generalize the baseline method to large scale classifier
training. By large scale we mean that either the cardinality of the dictionary
of candidate weak classifiers or the number of weak learners used in the strong
classifier exceed the number of variables that can be handled effectively in a
single global optimization. For such situations we propose an iterative and
piecewise approach in which a subset of weak classifiers is selected in each
iteration via global optimization. The strong classifier is then constructed by
concatenating the subsets of weak classifiers. We show in numerical studies
that the generalized method again successfully competes with AdaBoost. We also
provide theoretical arguments as to why the proposed optimization method, which
does not only minimize the empirical loss but also adds L0-norm regularization,
is superior to versions of boosting that only minimize the empirical loss. By
conducting a Quantum Monte Carlo simulation we gather evidence that the quantum
adiabatic algorithm is able to handle a generic training problem efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0797</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0797</id><created>2009-12-04</created><updated>2010-04-15</updated><authors><author><keyname>Cappellari</keyname><forenames>Lorenzo</forenames></author></authors><title>On Syndrome Decoding for Slepian-Wolf Coding Based on Convolutional and
  Turbo Codes</title><categories>cs.IT math.IT</categories><comments>3 pages, 1 figure (2 graphic files arranged with subfigure); a note
  was added; to appear on IEEE Comm. Letters</comments><journal-ref>IEEE Comm. Letters, vol. 14, no. 6, pp. 554-556, Jun. 2010</journal-ref><doi>10.1109/LCOMM.2010.06.100283</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In source coding, either with or without side information at the decoder, the
ultimate performance can be achieved by means of random binning. Structured
binning into cosets of performing channel codes has been successfully employed
in practical applications. In this letter it is formally shown that various
convolutional- and turbo-syndrome decoding algorithms proposed in literature
lead in fact to the same estimate. An equivalent implementation is also
delineated by directly tackling syndrome decoding as a maximum a posteriori
probability problem and solving it by means of iterative message-passing. This
solution takes advantage of the exact same structures and algorithms used by
the conventional channel decoder for the code according to which the syndrome
is formed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0803</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0803</id><created>2009-12-04</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>New Algorithmic Approaches for Computing Optimal Network Paths with
  Several Types of QoS Constraints</title><categories>cs.DS cs.NI</categories><acm-class>G.2.2; G.2.1</acm-class><journal-ref>Proceedings of the 8th RoEduNet International Conference, pp.
  7-12, Galati, Romania, 3-4 December, 2009. (ISBN: 978-606-8085-15-9)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of efficiently delivering data within networks is very important
nowadays, especially in the context of the large volumes of data which are
being produced each year and of the increased data access needs of the users.
Efficient data delivery strategies must satisfy several types of Quality of
Service (QoS) constraints which are imposed by the data consumers. One
possibility of achieving this goal (particularly in the case of in-order data
transfers) is to choose a satisfactory network delivery path. In this paper we
present novel algorithmic approaches for computing optimal network paths which
satisfy several types of (QoS) constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0807</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0807</id><created>2009-12-04</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Practical Algorithmic Techniques for Several String Processing Problems</title><categories>cs.DS cs.FL</categories><acm-class>F.2.2; F.1.1</acm-class><journal-ref>Proceedings of the 8th RoEduNet International Conference, pp.
  136-141, Galati, Romania, 3-4 December, 2009. (ISBN: 978-606-8085-15-9)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The domains of data mining and knowledge discovery make use of large amounts
of textual data, which need to be handled efficiently. Specific problems, like
finding the maximum weight ordered common subset of a set of ordered sets or
searching for specific patterns within texts, occur frequently in this context.
In this paper we present several novel and practical algorithmic techniques for
processing textual data (strings) in order to efficiently solve multiple
problems. Our techniques make use of efficient string algorithms and data
structures, like KMP, suffix arrays, tries and deterministic finite automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0821</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0821</id><created>2009-12-04</created><updated>2009-12-09</updated><authors><author><keyname>Petroni</keyname><forenames>Filippo</forenames></author><author><keyname>Serva</keyname><forenames>Maurizio</forenames></author></authors><title>Lexical evolution rates by automated stability measure</title><categories>cs.CL physics.soc-ph</categories><doi>10.1088/1742-5468/2010/03/P03015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phylogenetic trees can be reconstructed from the matrix which contains the
distances between all pairs of languages in a family. Recently, we proposed a
new method which uses normalized Levenshtein distances among words with same
meaning and averages on all the items of a given list. Decisions about the
number of items in the input lists for language comparison have been debated
since the beginning of glottochronology. The point is that words associated to
some of the meanings have a rapid lexical evolution. Therefore, a large
vocabulary comparison is only apparently more accurate then a smaller one since
many of the words do not carry any useful information. In principle, one should
find the optimal length of the input lists studying the stability of the
different items. In this paper we tackle the problem with an automated
methodology only based on our normalized Levenshtein distance. With this
approach, the program of an automated reconstruction of languages relationships
is completed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0840</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0840</id><created>2009-12-04</created><authors><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames></author><author><keyname>Vion</keyname><forenames>Antoine</forenames></author><author><keyname>Dudouet</keyname><forenames>Francois-Xavier</forenames></author><author><keyname>Saint-Ghislain</keyname><forenames>Loic</forenames></author></authors><title>Applying an XML Warehouse to Social Network Analysis, Lessons from the
  WebStand Project</title><categories>cs.DB cs.CY</categories><comments>W3C Workshop on the Future of Social Networking</comments><acm-class>J.4</acm-class><journal-ref>W3C Workshop on the Future of Social Networking, electronic
  proceedings available at http://www.w3.org/2008/09/msnws/ Barcelona, Spain,
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the state of advancement of the French ANR WebStand
project. The objective of this project is to construct a customizable XML based
warehouse platform to acquire, transform, analyze, store, query and export data
from the web, in particular mailing lists, with the final intension of using
this data to perform sociological studies focused on social groups of World
Wide Web, with a specific emphasis on the temporal aspects of this data. We are
currently using this system to analyze the standardization process of the W3C,
through its social network of standard setters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0850</identifier>
 <datestamp>2010-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0850</id><created>2009-12-04</created><updated>2010-02-05</updated><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Gawrychowski</keyname><forenames>Pawel</forenames></author></authors><title>Grammar-Based Compression in a Streaming Model</title><categories>cs.DS</categories><comments>Section on recent work added, sketching how to improve bounds and
  support random access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that, given a string $s$ of length $n$, with constant memory and
logarithmic passes over a constant number of streams we can build a
context-free grammar that generates $s$ and only $s$ and whose size is within
an $\Oh{\min (g \log g, \sqrt{n \log g})}$-factor of the minimum $g$. This
stands in contrast to our previous result that, with polylogarithmic memory and
polylogarithmic passes over a single stream, we cannot build such a grammar
whose size is within any polynomial of $g$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0868</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0868</id><created>2009-12-04</created><updated>2011-01-19</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author></authors><title>Interference Alignment in Dense Wireless Networks</title><categories>cs.IT math.IT</categories><comments>21 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, pp. 2889-2901,
  May 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider arbitrary dense wireless networks, in which $n$ nodes are placed
in an arbitrary (deterministic) manner on a square region of unit area and
communicate with each other over Gaussian fading channels. We provide inner and
outer bounds for the $n\times n$-dimensional unicast and the $n\times
2^n$-dimensional multicast capacity regions of such a wireless network. These
inner and outer bounds differ only by a factor $O(\log(n))$, yielding a fairly
tight scaling characterization of the entire regions. The communication schemes
achieving the inner bounds use interference alignment as a central technique
and are, at least conceptually, surprisingly simple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0878</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0878</id><created>2009-12-04</created><updated>2010-08-04</updated><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>Nullity Invariance for Pivot and the Interlace Polynomial</title><categories>cs.DM math.CO</categories><comments>small revision of Section 8 w.r.t. v2, 14 pages, 6 figures</comments><journal-ref>Linear Algebra and its Applications, v. 435, 277-288, 2011</journal-ref><doi>10.1016/j.laa.2011.01.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the effect of principal pivot transform on the nullity values of
the principal submatrices of a given (square) matrix is described by the
symmetric difference operator (for sets). We consider its consequences for
graphs, and in particular generalize the recursive relation of the interlace
polynomial and simplify its proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0884</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0884</id><created>2009-12-04</created><updated>2009-12-09</updated><authors><author><keyname>Petroni</keyname><forenames>Filippo</forenames></author><author><keyname>Serva</keyname><forenames>Maurizio</forenames></author></authors><title>Measures of lexical distance between languages</title><categories>cs.CL physics.soc-ph</categories><doi>10.1016/j.physa.2010.02.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of measuring distance between languages seems to have its roots in
the work of the French explorer Dumont D'Urville \cite{Urv}. He collected
comparative words lists of various languages during his voyages aboard the
Astrolabe from 1826 to 1829 and, in his work about the geographical division of
the Pacific, he proposed a method to measure the degree of relation among
languages. The method used by modern glottochronology, developed by Morris
Swadesh in the 1950s, measures distances from the percentage of shared
cognates, which are words with a common historical origin. Recently, we
proposed a new automated method which uses normalized Levenshtein distance
among words with the same meaning and averages on the words contained in a
list. Recently another group of scholars \cite{Bak, Hol} proposed a refined of
our definition including a second normalization. In this paper we compare the
information content of our definition with the refined version in order to
decide which of the two can be applied with greater success to resolve
relationships among languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0893</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0893</id><created>2009-12-04</created><authors><author><keyname>Astuti</keyname><forenames>A. D.</forenames></author><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author></authors><title>Performance Analysis on Molecular Dynamics Simulation of Protein Using
  GROMACS</title><categories>cs.CE q-bio.BM</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of computer technology in chemistry, bring many application of
chemistry. Not only the application to visualize the structure of molecule but
also to molecular dynamics simulation. One of them is Gromacs. Gromacs is an
example of molecular dynamics application developed by Groningen University.
This application is a non-commercial and able to work in the operating system
Linux. The main ability of Gromacs is to perform molecular dynamics simulation
and minimization energy. In this paper, the author discusses about how to work
Gromacs in molecular dynamics simulation of some protein. In the molecular
dynamics simulation, Gromacs does not work alone. Gromacs interact with pymol
and Grace. Pymol is an application to visualize molecule structure and Grace is
an application in Linux to display graphs. Both applications will support
analysis of molecular dynamics simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0898</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0898</id><created>2009-12-04</created><authors><author><keyname>Diaz</keyname><forenames>Pablo Andres</forenames></author><author><keyname>Dudouet</keyname><forenames>Francois-Xavier</forenames></author><author><keyname>Graz</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames></author><author><keyname>Vion</keyname><forenames>Antoine</forenames></author></authors><title>Gouverner la standardisation par les changements d'arene. Le cas du XML</title><categories>cs.CY</categories><comments>Communication in the Economy of Politics and Politics of Economy
  session of the French Political Sciences Association Congress (AFSP),
  Grenoble, France 2009</comments><acm-class>K.1; K.4.2</acm-class><journal-ref>Congres de l'Association Francaise de Sciences Politiques,
  Grenoble, France, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss the available approches of the new governance
structures of standardization, in order to propose new hypothesis on the way
computer sciences languages are dealt with. We consider the example of the XML
language and its applications in order to propose a dynamic analysis of this
governance, focusing on the coordination that is done by companies, and the
strategic usage they have of these arenas to further their goals. We advocate
the development of more of such empirical analysis in order to cover all the
perspectives of possible international policies in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0913</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0913</id><created>2009-12-04</created><updated>2009-12-07</updated><authors><author><keyname>Carchiolo</keyname><forenames>Vincenza</forenames></author><author><keyname>Longheu</keyname><forenames>Alessandro</forenames></author><author><keyname>Malgeri</keyname><forenames>Michele</forenames></author><author><keyname>Mangioni</keyname><forenames>Giuseppe</forenames></author></authors><title>Search for overlapped communities by parallel genetic algorithms</title><categories>cs.IR cs.GL physics.soc-ph</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 113-118, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last decade the broad scope of complex networks has led to a rapid
progress. In this area a particular interest has the study of community
structures. The analysis of this type of structure requires the formalization
of the intuitive concept of community and the definition of indices of goodness
for the obtained results. A lot of algorithms has been presented to reach this
goal. In particular, an interesting problem is the search of overlapped
communities and it is field seems very interesting a solution based on the use
of genetic algorithms. The approach discusses in this paper is based on a
parallel implementation of a genetic algorithm and shows the performance
benefits of this solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0921</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0921</id><created>2009-12-04</created><authors><author><keyname>Iyengar</keyname><forenames>Janardhan</forenames><affiliation>Franklin and Marshall College</affiliation></author><author><keyname>Ford</keyname><forenames>Bryan</forenames><affiliation>Yale University</affiliation></author></authors><title>Flow Splitting with Fate Sharing in a Next Generation Transport Services
  Architecture</title><categories>cs.NI</categories><comments>12 pages, 11 figures, 1 table</comments><acm-class>C.2.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The challenges of optimizing end-to-end performance over diverse Internet
paths has driven widespread adoption of in-path optimizers, which can
destructively interfere with TCP's end-to-end semantics and with each other,
and are incompatible with end-to-end IPsec. We identify the architectural cause
of these conflicts and resolve them in Tng, an experimental next-generation
transport services architecture, by factoring congestion control from
end-to-end semantic functions. Through a technique we call &quot;queue sharing&quot;, Tng
enables in-path devices to interpose on, split, and optimize congestion
controlled flows without affecting or seeing the end-to-end content riding
these flows. Simulations show that Tng's decoupling cleanly addresses several
common performance problems, such as communication over lossy wireless links
and reduction of buffering-induced latency on residential links. A working
prototype and several incremental deployment paths suggest Tng's practicality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0926</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0926</id><created>2009-12-04</created><updated>2010-02-01</updated><authors><author><keyname>Aviram</keyname><forenames>Amittai</forenames><affiliation>Yale University</affiliation></author><author><keyname>Ford</keyname><forenames>Bryan</forenames><affiliation>Yale University</affiliation></author></authors><title>Deterministic Consistency: A Programming Model for Shared Memory
  Parallelism</title><categories>cs.OS</categories><comments>7 pages, 3 figures</comments><acm-class>C.1.4; D.1.3; D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The difficulty of developing reliable parallel software is generating
interest in deterministic environments, where a given program and input can
yield only one possible result. Languages or type systems can enforce
determinism in new code, and runtime systems can impose synthetic schedules on
legacy parallel code. To parallelize existing serial code, however, we would
like a programming model that is naturally deterministic without language
restrictions or artificial scheduling. We propose &quot;deterministic consistency&quot;,
a parallel programming model as easy to understand as the &quot;parallel assignment&quot;
construct in sequential languages such as Perl and JavaScript, where concurrent
threads always read their inputs before writing shared outputs. DC supports
common data- and task-parallel synchronization abstractions such as fork/join
and barriers, as well as non-hierarchical structures such as producer/consumer
pipelines and futures. A preliminary prototype suggests that software-only
implementations of DC can run applications written for popular parallel
environments such as OpenMP with low (&lt;10%) overhead for some applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0928</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0928</id><created>2009-12-04</created><authors><author><keyname>Neary</keyname><forenames>Turlough</forenames></author></authors><title>On the computational complexity of spiking neural P systems</title><categories>cs.CC q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that there is no standard spiking neural P system that simulates
Turing machines with less than exponential time and space overheads. The
spiking neural P systems considered here have a constant number of neurons that
is independent of the input length. Following this we construct a universal
spiking neural P system with exhaustive use of rules that simulates Turing
machines in linear time and has only 10 neurons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0930</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0930</id><created>2009-12-04</created><authors><author><keyname>Chakravarthy</keyname><forenames>C. Kalyana</forenames></author><author><keyname>Reddy</keyname><forenames>P. V. G. D. Prasad</forenames></author></authors><title>Modified Opportunistic Deficit Round Robin Scheduling for improved QOS
  in IEEE 802.16 WBA networks</title><categories>cs.NI</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 075-081, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Packet and flow scheduling algorithms for WiMAX has been a topic of interest
for a long time since the very inception of WiMAX networks. WiMAX offers
advantages particularly in terms of Quality of service it offers over a longer
range at the MAC level. In our work, we propose two credit based scheduling
schemes one in which completed flows distributes the left over credits equally
to all higher priority uncompleted flows(ODRREDC) and another in which
completed flows give away all the excess credits to the highest priority
uncompleted flow(ODRRSDC). Both the schemes are compatible with 802.16 MAC
protocol and can efficiently serve real time bursty traffic with reduced
latency and hence improved QOS for real time flows. We compare the two proposed
schemes for their latency, bandwidth utilization and throughput for real time
burst flows with the opportunity based Deficit Round Robin scheduling scheme.
While the ODRR scheduler focuses on reducing the credits for the flows with
errors, our approach also distributes these remaining credits together with the
credits from completed flows equally among the higher priority uncompleted
flows or totally to the highest priority uncompleted flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0931</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0931</id><created>2009-12-04</created><updated>2010-06-18</updated><authors><author><keyname>Jacobs</keyname><forenames>Bart</forenames></author></authors><title>Orthomodular lattices, Foulis Semigroups and Dagger Kernel Categories</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 2 (June 18,
  2010) lmcs:1083</journal-ref><doi>10.2168/LMCS-6(2:1)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a sequel to arXiv:0902.2355 and continues the study of quantum
logic via dagger kernel categories. It develops the relation between these
categories and both orthomodular lattices and Foulis semigroups. The relation
between the latter two notions has been uncovered in the 1960s. The current
categorical perspective gives a broader context and reconstructs this
relationship between orthomodular lattices and Foulis semigroups as special
instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0932</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0932</id><created>2009-12-04</created><authors><author><keyname>Elawady</keyname><forenames>Yasser . H.</forenames></author><author><keyname>Tolba</keyname><forenames>A. S.</forenames></author></authors><title>Educational Objectives Of Different Laboratory Types: A Comparative
  Study</title><categories>cs.CY</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 089-096, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Laboratory based courses play a critical role in scientific education.
Automation is changing the nature of the laboratories, and there is a long
running debate about the value of hands on versus simulated and remote
laboratories. The remote lab technology has brought a significant improvement
in communication within the Academic community and has improved students
learning experiences. There are different educational objectives as criteria
for judging the laboratories: Hands on advocates emphasize design skills, while
remote lab advocates focus on conceptual understanding. Remote laboratories
offer all the advantages of the new technology, but are often a poor
replacement for real laboratory work. Remote laboratories are similar to
simulation techniques in that they require minimal space and time, because the
experiments can be rapidly configured and run over the Internet [Web]. But
unlike simulations, they provide real data. This paper presents a comparative
analysis for the educational objectives of the three laboratory techniques,
hands on, simulated, and remote laboratories. In addition, it proposes
enhancements for the remote lab activities leading to improving its
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0936</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0936</id><created>2009-12-04</created><authors><author><keyname>Paes</keyname><forenames>F. F.</forenames></author><author><keyname>Velho</keyname><forenames>H. F. Campos</forenames></author></authors><title>Neural-estimator for the surface emission rate of atmospheric gases</title><categories>cs.NE</categories><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emission rate of minority atmospheric gases is inferred by a new approach
based on neural networks. The neural network applied is the multi-layer
perceptron with backpropagation algorithm for learning. The identification of
these surface fluxes is an inverse problem. A comparison between the new
neural-inversion and regularized inverse solution id performed. The results
obtained from the neural networks are significantly better. In addition, the
inversion with the neural netwroks is fster than regularized approaches, after
training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0942</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0942</id><created>2009-12-04</created><authors><author><keyname>Towhidi</keyname><forenames>Farnaz</forenames></author><author><keyname>Masrom</keyname><forenames>Maslin</forenames></author></authors><title>A Survey on Recognition Based Graphical User Authentication Algorithms</title><categories>cs.CR</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 119-127, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, user authentication is one of the important topics in information
security. Strong textbased password schemes could provide with certain degree
of security. However, the fact that strong passwords are difficult to memorize
often leads their owners to write them down on papers or even save them in a
computer file. Graphical authentication has been proposed as a possible
alternative solution to textbased authentication, motivated particularly by the
fact that humans can remember images better than text. In recent years, many
networks, computer systems and Internet based environments try used graphical
authentication technique for their users authentication. All of graphical
passwords have two different aspects which are usability and security.
Unfortunately none of these algorithms were being able to cover both of these
aspects at the same time. In this paper, we described eight recognition based
authentication algorithms in terms of their drawbacks and attacks. In the next
section, the usability standards from ISO and the related attributes for
graphical user authentication usability are discussed. The related attack
patterns for graphical user authentication security part are also discussed.
Finally, a comparison table of all recognition based algorithms is presented
based on ISO and attack patterns standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0946</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0946</id><created>2009-12-04</created><authors><author><keyname>Hasan</keyname><forenames>Md. Zahid</forenames></author><author><keyname>Hossain</keyname><forenames>Mohammad Reaz</forenames></author><author><keyname>Islam</keyname><forenames>Md. Ashraful</forenames></author><author><keyname>Hossain</keyname><forenames>Riaz</forenames></author></authors><title>Comparative Study of Different Guard Time Intervals to Improve the BER
  Performance of Wimax Systems to Minimize the Effects of ISI and ICI under
  Adaptive Modulation Techniques over SUI1 and AWGN Communication Channels</title><categories>cs.NI</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 128-132, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The WIMAX technology based on air interface standard 802.16 wireless MAN is
configured in the same way as a traditional cellular network with base stations
using point to multipoint architecture to drive a service over a radius up to
several kilometers. The range and the Non Line of Sight (NLOS) ability of WIMAX
make the system very attractive for users, but there will be slightly higher
BER at low SNR. The aim of this paper is the comparative study of different
guard time intervals effect for improving BER at different SNR under digital
modulation (QPSK, 16QAM and 64QAM) techniques and different communication
channels AWGN and fading channels Stanford University Interim (SUI 1) of an
WIMAX system. The comparison between these effects with Reed-Solomon (RS)
encoder with Convolutional encoder (half) rated codes in FEC channel coding
will be investigated. The simulation results of estimated Bit Error Rate (BER)
displays that the implementation of interleaved RS code (255,239,8) with (half)
rated Convolutional code of 0.25 guard time intervals under QPSK modulation
technique over AWGN channel is highly effective to combat in the Wimax
communication system. To complete this performance analysis in Wimax based
systems, a segment of audio signal is used for analysis. The transmitted audio
message is found to have retrieved effectively under noisy situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0947</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0947</id><created>2009-12-04</created><authors><author><keyname>Patel</keyname><forenames>Samir B.</forenames></author><author><keyname>Pradhan</keyname><forenames>Shrikant N.</forenames></author><author><keyname>Ambegaokar</keyname><forenames>Saumitra U.</forenames></author></authors><title>A novel approach for implementing Steganography with computing power
  obtained by combining Cuda and Matlab</title><categories>cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 133-137, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the current development of multiprocessor systems, strive for computing
data on such processor have also increased exponentially. If the multi core
processors are not fully utilized, then even though we have the computing power
the speed is not available to the end users for their respective applications.
In accordance to this, the users or application designers also have to design
newer applications taking care of the computing infrastructure available
within. Our approach is to use the CUDA (Compute Unified Device Architecture)
as backend and MATLAB as the front end to design an application for
implementing steganography. Steganography is the term used for hiding
information in the cover object like Image, Audio or Video data. As the
computing required for multimedia data is much more than the text information,
we have been successful in implementing image Steganography with the help of
technology for the next generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0950</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0950</id><created>2009-12-04</created><authors><author><keyname>Lavanya</keyname><forenames>B N</forenames></author><author><keyname>Raja</keyname><forenames>K B</forenames></author><author><keyname>Venugopal</keyname><forenames>K R</forenames></author></authors><title>Fingerprint Verification based on Gabor Filter Enhancement</title><categories>cs.CR cs.CV</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 138-144, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human fingerprints are reliable characteristics for personnel identification
as it is unique and persistence. A fingerprint pattern consists of ridges,
valleys and minutiae. In this paper we propose Fingerprint Verification based
on Gabor Filter Enhancement (FVGFE) algorithm for minutiae feature extraction
and post processing based on 9 pixel neighborhood. A global feature extraction
and fingerprints enhancement are based on Hong enhancement method which is
simultaneously able to extract local ridge orientation and ridge frequency. It
is observed that the Sensitivity and Specificity values are better compared to
the existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0951</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0951</id><created>2009-12-04</created><authors><author><keyname>Lashkari</keyname><forenames>Arash Habibi</forenames></author><author><keyname>Farmand</keyname><forenames>Samaneh</forenames></author><author><keyname>Zakaria</keyname><forenames>Dr. Omar Bin</forenames></author><author><keyname>Saleh</keyname><forenames>Dr. Rosli</forenames></author></authors><title>Shoulder Surfing attack in graphical password authentication</title><categories>cs.CR</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 145-154, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information and computer security is supported largely by passwords which are
the principle part of the authentication process. The most common computer
authentication method is to use alphanumerical username and password which has
significant drawbacks. To overcome the vulnerabilities of traditional methods,
visual or graphical password schemes have been developed as possible
alternative solutions to text based scheme. A potential drawback of graphical
password schemes is that they are more vulnerable to shoulder surfing than
conventional alphanumeric text passwords. When users input their passwords in a
public place, they may be at risk of attackers stealing their password. An
attacker can capture a password by direct observation or by recording the
individuals authentication session. This is referred to as shouldersurfing and
is a known risk, of special concern when authenticating in public places. In
this paper we will present a survey on graphical password schemes from 2005
till 2009 which are proposed to be resistant against shoulder surfing attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0954</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0954</id><created>2009-12-04</created><authors><author><keyname>Patel</keyname><forenames>Samir B.</forenames></author><author><keyname>Pradhan</keyname><forenames>Shrikant N.</forenames></author></authors><title>An approach to secure highly confidential documents of any size in the
  corporate or institutes having unsecured networks</title><categories>cs.CR</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 155-163, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the tremendous amount of computing because of the wide usage of internet
it is observed that some user(s) are not able to manage their desktop with
antivirus software properly installed. It is happening few times, that we allow
our friends, students and colleagues to sit on our networked PC. Sometimes the
user is unaware of the situation that there workstations are unsecured and so
some one else could also be monitoring your flow of information and your most
important data could go haywire, resulting into leakage of most confidential
data to unwanted or malicious user(s). Example of some such documents could be
question papers designed by the faculty member by various universities. Now a
day most of the universities are having the biggest threat about the question
papers and many other confidential documents designed by their faculty members.
We in this paper present the solution to over come such a situation using the
concept of Steganography. Steganography is a technique through which one can
hide information into some cover object. This technique, if used, in positive
direction could be of great help to solve such a problem and even other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0955</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0955</id><created>2009-12-04</created><authors><author><keyname>Boodoo</keyname><forenames>Nazmeen Bibi</forenames></author><author><keyname>Subramanian</keyname><forenames>R. K.</forenames></author></authors><title>Robust Multi biometric Recognition Using Face and Ear Images</title><categories>cs.CR cs.CV</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 164-169, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study investigates the use of ear as a biometric for authentication and
shows experimental results obtained on a newly created dataset of 420 images.
Images are passed to a quality module in order to reduce False Rejection Rate.
The Principal Component Analysis (eigen ear) approach was used, obtaining 90.7
percent recognition rate. Improvement in recognition results is obtained when
ear biometric is fused with face biometric. The fusion is done at decision
level, achieving a recognition rate of 96 percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0956</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0956</id><created>2009-12-04</created><authors><author><keyname>Sheikh</keyname><forenames>Rashid</forenames></author><author><keyname>Kumar</keyname><forenames>Beerendra</forenames></author><author><keyname>Mishra</keyname><forenames>Durgesh Kumar</forenames></author></authors><title>Privacy Preserving k Secure Sum Protocol</title><categories>cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 184-188, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure Multiparty Computation (SMC) allows parties to know the result of
cooperative computation while preserving privacy of individual data. Secure sum
computation is an important application of SMC. In our proposed protocols
parties are allowed to compute the sum while keeping their individual data
secret with increased computation complexity for hacking individual data. In
this paper the data of individual party is broken into a fixed number of
segments. For increasing the complexity we have used the randomization
technique with segmentation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0962</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0962</id><created>2009-12-04</created><authors><author><keyname>Bhagavatula</keyname><forenames>Ramya</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author></authors><title>Adaptive Limited Feedback for Sum-Rate Maximizing Beamforming in
  Cooperative Multicell Systems</title><categories>cs.IT math.IT</categories><comments>28 pages, submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Base station cooperation improves the sum-rates that can be achieved in
cellular systems. Conventional cooperation techniques require sharing large
amounts of information over finite-capacity backhaul links and assume that base
stations have full channel state information (CSI) of all the active users in
the system. In this paper, a new limited feedback strategy is proposed for
multicell beamforming where cooperation is restricted to sharing only the CSI
of active users among base stations. The system setup considered is a linear
array of cells based on the Wyner model. Each cell contains single-antenna
users and multi-antenna base stations. Closed-form expressions for the
beamforming vectors that approximately maximize the sum-rates in a multicell
system are first presented, assuming full CSI at the transmitter. For the more
practical case of a finite-bandwidth feedback link, CSI of the desired and
interfering channels is quantized at the receiver before being fed back to the
base station. An upper bound on the mean loss in sum rate due to random vector
quantization is derived. A new feedback-bit allocation strategy, to partition
the available bits between the desired and interfering channels, is developed
to approximately minimize the mean loss in sum-rate due to quantization. The
proposed feedback-bit partitioning algorithm is shown, using simulations, to
yield sum-rates close to the those obtained using full CSI at base stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0965</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0965</id><created>2009-12-04</created><updated>2010-04-30</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>Explicit Capacity-achieving Codes for Worst-Case Additive Errors</title><categories>cs.IT cs.CC math.CO math.IT</categories><comments>This preprint has been withdrawn since it is superseded by
  arXiv:1004.4017 [cs.IT] (same authors), which contains significantly more
  general results. This preprint will no longer be updated by the authors.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every p in (0,1/2), we give an explicit construction of binary codes of
rate approaching &quot;capacity&quot; 1-H(p) that enable reliable communication in the
presence of worst-case additive errors}, caused by a channel oblivious to the
codeword (but not necessarily the message). Formally, we give an efficient
&quot;stochastic&quot; encoding E(\cdot,\cdot) of messages combined with a small number
of auxiliary random bits, such that for every message m and every error vector
e (that could depend on m) that contains at most a fraction p of ones, w.h.p
over the random bits r chosen by the encoder, m can be efficiently recovered
from the corrupted codeword E(m,r) + e by a decoder without knowledge of the
encoder's randomness r.
  Our construction for additive errors also yields explicit deterministic codes
of rate approaching 1-H(p) for the &quot;average error&quot; criterion: for every error
vector e of at most p fraction 1's, most messages m can be efficiently
(uniquely) decoded from the corrupted codeword C(m)+e. Note that such codes
cannot be linear, as the bad error patterns for all messages are the same in a
linear code. We also give a new proof of the existence of such codes based on
list decoding and certain algebraic manipulation detection codes. Our proof is
simpler than the previous proofs from the literature on arbitrarily varying
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0970</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0970</id><created>2009-12-04</created><authors><author><keyname>Bushkov</keyname><forenames>Victor</forenames></author><author><keyname>Yevtushenko</keyname><forenames>Nina</forenames></author><author><keyname>Villa</keyname><forenames>Tiziano</forenames></author></authors><title>Discussion on Supervisory Control by Solving Automata Equation</title><categories>cs.OH math.OC</categories><comments>4 pages</comments><journal-ref>IEEE Proc. EWDTS'09 (2009) 77-80</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the supervisory control problem through language
equation solving. The equation solving approach allows to deal with more
general topologies and to find a largest supervisor which can be used as a
reservoir for deriving an optimal controller. We introduce the notions of
solutions under partial controllability and partial observability, and we show
how supervisory control problems with partial controllability and partial
observability can be solved by employing equation solving methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0975</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0975</id><created>2009-12-04</created><authors><author><keyname>McAuley</keyname><forenames>Julian J.</forenames></author><author><keyname>Caetano</keyname><forenames>Tib&#xe9;rio S.</forenames></author></authors><title>An expected-case sub-cubic solution to the all-pairs shortest path
  problem in R</title><categories>cs.DS</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown by Alon et al. that the so-called 'all-pairs shortest-path'
problem can be solved in O((MV)^2.688 * log^3(V)) for graphs with V vertices,
with integer distances bounded by M. We solve the more general problem for
graphs in R (assuming no negative cycles), with expected-case running time
O(V^2.5 * log(V)). While our result appears to violate the Omega(V^3)
requirement of &quot;Funny Matrix Multiplication&quot; (due to Kerr), we find that it has
a sub-cubic expected time solution subject to reasonable conditions on the data
distribution. The expected time solution arises when certain sub-problems are
uncorrelated, though we can do better/worse than the expected-case under
positive/negative correlation (respectively). Whether we observe
positive/negative correlation depends on the statistics of the graph in
question. In practice, our algorithm is significantly faster than
Floyd-Warshall, even for dense graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0982</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0982</id><created>2009-12-05</created><authors><author><keyname>Singaravel</keyname><forenames>G.</forenames></author><author><keyname>Palanisamy</keyname><forenames>Dr. V.</forenames></author><author><keyname>Krishnan</keyname><forenames>Dr. A.</forenames></author></authors><title>Ethics Understanding of Software Professional In Risk Reducing
  Reusability Coding Using Inclusion Set Theory</title><categories>cs.SE</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 189-193, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technical skill or ability of an individual is different to person in
software developments of projects. So, it is necessary to identify the talent
and attitude of an individual contribution can be uniformly distributed to the
different phases of software development cycle. The line of code analysis
metrics to understanding the various skills of the programmers in code
development. By using the inclusion set theory of n (AUB) refer to strength and
risk free code developed from union of software professionals and system must
comprise of achievement of the system goal, effective memory utilization and
intime delivery of the product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0983</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0983</id><created>2009-12-05</created><authors><author><keyname>Khaled</keyname><forenames>Lena</forenames></author></authors><title>Architectural Design Activities for JAS</title><categories>cs.SE</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 194-198, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The critical part for building any software system is its architecture.
Architectural design is a design at a higher level of abstraction. A good
architecture ensures that software will satisfy its requirement. This paper
defines the most important activities of architectural design that used through
building any software; also it applies these activities on one type of
Electronic Commerce (EC) applications that is Job Agency System(JAS) to show
how these activities can work through these types of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0984</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0984</id><created>2009-12-05</created><authors><author><keyname>Sabari</keyname><forenames>A.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Ant Based Adaptive Multicast Routing Protocol (AAMRP) for Mobile Ad Hoc
  Networks</title><categories>cs.NI</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 199-207, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicasting is effective when its group members are sparse and the speed is
low. On the other hand, broadcasting is effective when the group members dense
and the speed are high. Since mobile ad hoc networks are highly dynamic in
nature, either of the above two strategies can be adopted at different
scenarios. In this paper, we propose an ant agent based adaptive, multicast
protocol that exploits group members desire to simplify multicast routing and
invoke broadcast operations in appropriate localized regimes. By reducing the
number of group members that participate in the construction of the multicast
structure and by providing robustness to mobility by performing broadcasts in
densely clustered local regions, the proposed protocol achieves packet delivery
statistics that are comparable to that with a pure multicast protocol but with
significantly lower overheads. By our simulation results, we show that our
proposed protocol achieves increased Packet Delivery Fraction (PDF) with
reduced overhead and routing load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0985</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0985</id><created>2009-12-05</created><authors><author><keyname>Hosseini</keyname><forenames>Ehsan</forenames></author><author><keyname>Nematbakhsh</keyname><forenames>Mohammad Ali</forenames></author></authors><title>A New Approach to Cold Start in Peer to Peer File Sharing Networks</title><categories>cs.NI</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 208-214, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving free riding and selecting a reliable service provider in P2P networks
has been separately investigated in last few years. Using trust has shown to be
one of the best ways of solving these problems. But using this approach to
simultaneously deal with both problems makes it impossible for newcomers to
join the network and the expansion of network is prevented. In this paper we
used the game theory to model the behavior of peers and developed a mechanism
in which free riding and providing bad service are dominated strategies for
peers. At the same time newcomers can participate and are encouraged to be
active in the network. The proposed model has been simulated and the results
showed that the trust value of free riders and bad service providers converge
to a finite value and trust of peers who provide good service is monotonically
increased despite the time they join the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0986</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.0986</id><created>2009-12-05</created><authors><author><keyname>Alsmadi</keyname><forenames>Mutasem Khalil Sari</forenames></author><author><keyname>Omar</keyname><forenames>Khairuddin Bin</forenames></author><author><keyname>Noah</keyname><forenames>Shahrul Azman</forenames></author><author><keyname>Almarashdah</keyname><forenames>Ibrahim</forenames></author></authors><title>Fish recognition based on the combination between robust feature
  selection, image segmentation and geometrical parameter techniques using
  Artificial Neural Network and Decision Tree</title><categories>cs.CV cs.NE</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 215-221, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We presents in this paper a novel fish classification methodology based on a
combination between robust feature selection, image segmentation and
geometrical parameter techniques using Artificial Neural Network and Decision
Tree. Unlike existing works for fish classification, which propose descriptors
and do not analyze their individual impacts in the whole classification task
and do not make the combination between the feature selection, image
segmentation and geometrical parameter, we propose a general set of features
extraction using robust feature selection, image segmentation and geometrical
parameter and their correspondent weights that should be used as a priori
information by the classifier. In this sense, instead of studying techniques
for improving the classifiers structure itself, we consider it as a black box
and focus our research in the determination of which input information must
bring a robust fish discrimination.The main contribution of this paper is
enhancement recognize and classify fishes based on digital image and To develop
and implement a novel fish recognition prototype using global feature
extraction, image segmentation and geometrical parameters, it have the ability
to Categorize the given fish into its cluster and Categorize the clustered fish
into poison or non-poison fish, and categorizes the non-poison fish into its
family .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1004</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1004</id><created>2009-12-05</created><authors><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author><author><keyname>Mustafa</keyname><forenames>Adli</forenames></author><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Bano</keyname><forenames>Arjamand</forenames></author><author><keyname>Hosam</keyname><forenames>Al-Sammarraie</forenames></author></authors><title>Comparative Study Of Congestion Control Techniques In High Speed
  Networks</title><categories>cs.NI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 222-231, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Congestion in network occurs due to exceed in aggregate demand as compared to
the accessible capacity of the resources. Network congestion will increase as
network speed increases and new effective congestion control methods are
needed, especially to handle bursty traffic of todays very high speed networks.
Since late 90s numerous schemes i.e. [1]...[10] etc. have been proposed. This
paper concentrates on comparative study of the different congestion control
schemes based on some key performance metrics. An effort has been made to judge
the performance of Maximum Entropy (ME) based solution for a steady state
GE/GE/1/N censored queues with partial buffer sharing scheme against these key
performance metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1005</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1005</id><created>2009-12-05</created><authors><author><keyname>Padmavathi</keyname><forenames>Dr. G.</forenames></author><author><keyname>Subashini</keyname><forenames>Dr. P.</forenames></author><author><keyname>Kumar</keyname><forenames>Mr. M. Muthu</forenames></author><author><keyname>Thakur</keyname><forenames>Suresh Kumar</forenames></author></authors><title>Performance analysis of Non Linear Filtering Algorithms for underwater
  images</title><categories>cs.MM cs.CV cs.IR</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 232-238, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image filtering algorithms are applied on images to remove the different
types of noise that are either present in the image during capturing or
injected in to the image during transmission. Underwater images when captured
usually have Gaussian noise, speckle noise and salt and pepper noise. In this
work, five different image filtering algorithms are compared for the three
different noise types. The performances of the filters are compared using the
Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE). The modified
spatial median filter gives desirable results in terms of the above two
parameters for the three different noise. Forty underwater images are taken for
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1007</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1007</id><created>2009-12-05</created><authors><author><keyname>Haghighi</keyname><forenames>Mehdi Salkhordeh</forenames></author><author><keyname>Yazdi</keyname><forenames>Hadi Sadoghi</forenames></author><author><keyname>Vahedian</keyname><forenames>Abedin</forenames></author><author><keyname>Modaghegh</keyname><forenames>Hamed</forenames></author></authors><title>Designing Kernel Scheme for Classifiers Fusion</title><categories>cs.LG cs.NE</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 239-248, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a special fusion method for combining ensembles of
base classifiers utilizing new neural networks in order to improve overall
efficiency of classification. While ensembles are designed such that each
classifier is trained independently while the decision fusion is performed as a
final procedure, in this method, we would be interested in making the fusion
process more adaptive and efficient. This new combiner, called Neural Network
Kernel Least Mean Square1, attempts to fuse outputs of the ensembles of
classifiers. The proposed Neural Network has some special properties such as
Kernel abilities,Least Mean Square features, easy learning over variants of
patterns and traditional neuron capabilities. Neural Network Kernel Least Mean
Square is a special neuron which is trained with Kernel Least Mean Square
properties. This new neuron is used as a classifiers combiner to fuse outputs
of base neural network classifiers. Performance of this method is analyzed and
compared with other fusion methods. The analysis represents higher performance
of our new method as opposed to others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1008</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1008</id><created>2009-12-05</created><authors><author><keyname>Singh</keyname><forenames>Rajni Ranjan</forenames></author><author><keyname>Tomar</keyname><forenames>Deepak Singh</forenames></author></authors><title>Approaches for user profile Investigation in Orkut Social Network</title><categories>cs.CY</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 259-268, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet becomes a large and rich repository of information about us as
individually. Any thing form user profile information to friends links the user
subscribes to are reflection of social interactions as user has in real worlds.
Social networking has created new ways to communicate and share information.
Social networking websites are being used regularly by millions of people, and
it now seems that social networking will be an enduring part of everyday life.
Social networks such as Orkut, Bebo, MySpace, Flickr, Facebook, Friendster and
LinkedIn, have attracted millions of internet user who are involved in bogging,
participatory book reviewing, personal networking and photo sharing. Social
network services are increasingly being used in legal and criminal
investigations. Information posted on sites such as Orkut and Facebook has been
used by police, probation, and university officials to prosecute users of said
sites. In some situations, content posted on web social network has been used
in court. In the proposed work degree of closeness is identified by link weight
approaches and information matrices are generated and matched on the basis of
similarity in user profile information. The proposed technique is useful to
investigate a user profile and calculate closeness or interaction between
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1009</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1009</id><created>2009-12-05</created><authors><author><keyname>Panchal</keyname><forenames>V. K.</forenames></author><author><keyname>Singh</keyname><forenames>Parminder</forenames></author><author><keyname>Kaur</keyname><forenames>Navdeep</forenames></author><author><keyname>Kundra</keyname><forenames>Harish</forenames></author></authors><title>Biogeography based Satellite Image Classification</title><categories>cs.CV cs.LG</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 269-274, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biogeography is the study of the geographical distribution of biological
organisms. The mindset of the engineer is that we can learn from nature.
Biogeography Based Optimization is a burgeoning nature inspired technique to
find the optimal solution of the problem. Satellite image classification is an
important task because it is the only way we can know about the land cover map
of inaccessible areas. Though satellite images have been classified in past by
using various techniques, the researchers are always finding alternative
strategies for satellite image classification so that they may be prepared to
select the most appropriate technique for the feature extraction task in hand.
This paper is focused on classification of the satellite image of a particular
land cover using the theory of Biogeography based Optimization. The original
BBO algorithm does not have the inbuilt property of clustering which is
required during image classification. Hence modifications have been proposed to
the original algorithm and the modified algorithm is used to classify the
satellite image of a given region. The results indicate that highly accurate
land cover features can be extracted effectively when the proposed algorithm is
used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1010</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1010</id><created>2009-12-05</created><authors><author><keyname>Othman</keyname><forenames>Mohd Shahizan</forenames></author><author><keyname>Yusuf</keyname><forenames>Lizawati Mi</forenames></author><author><keyname>Salim</keyname><forenames>Juhana</forenames></author></authors><title>Web Document Analysis for Companies Listed in Bursa Malaysia</title><categories>cs.IR</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 275-280, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses a research on web document analysis for companies listed
on Bursa Malaysia which is the forerunner of financial and investment center in
Malaysia. Data set used in this research are from the company web documents
listed in the Main Board and Second Board on Bursa Malaysia. This research has
used the Web Resources Extraction System which was developed by the research
group mainly to extract information for the web documents involved. Our
research findings have shown that the level of website usage among the
companies on Bursa Malaysia is still minimal. Furthermore, research has also
found that 60.02 percent of the image files are utilized making it the most
used type of file in creating websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1011</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1011</id><created>2009-12-05</created><authors><author><keyname>Kumar</keyname><forenames>R. Ashok</forenames></author><author><keyname>Ganesan</keyname><forenames>K.</forenames></author></authors><title>A Reliable Replication Strategy for VoD System using Markov Chain</title><categories>cs.MM cs.NI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 281-290, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have investigated on the reliability of streams for a VoD
system. The objective of the paper is to maximize the availability of streams
for the peers in the VoD system. We have achieved this by using data
replication technique in the peers. Hence, we proposed a new data replication
technique to optimally store the videos in the peers. The new data replication
technique generates more number of replicas than the existing techniques such
as random, minimum request and maximize hit. We have also investigated by
applying the CTMC model for the reliability of replications during the peer
failures. Our result shows that the mean lifetime of replicas are more under
various circumstances. We have addressed the practical issues of efficient
utilization of overall bandwidth and buffer in the VoD system. We achieved
greater success playback probability of videos than the existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1013</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1013</id><created>2009-12-05</created><authors><author><keyname>Harini</keyname><forenames>Prof P.</forenames></author><author><keyname>Ramanaiah</keyname><forenames>Dr. O. B. V.</forenames></author></authors><title>An Efficient Admission Control Algorithm for Load Balancing In
  Hierarchical Mobile IPv6 Networks</title><categories>cs.NI</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 291-296, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In hierarchical Mobile IPv6 networks, Mobility Anchor Point (MAP) may become
a single point of bottleneck as it handles more and more mobile nodes (MNs). A
number of schemes have been proposed to achieve load balancing among different
MAPs. However, signaling reduction is still imperfect because these schemes
also avoid the effect of the number of CNs. Also only the balancing of MN is
performed, but not the balancing of the actual traffic load, since CN of each
MN may be different. This paper proposes an efficient admission control
algorithm along with a replacement mechanism for HMIPv6 networks. The admission
control algorithm is based on the number of serving CNs and achieves actual
load balancing among MAPs. Moreover, a replacement mechanism is introduced to
decrease the new MN blocking probability and the handoff MN dropping
probability. By simulation results, we show that, the handoff delay and packet
loss are reduced in our scheme, when compared with the standard HMIPv6 based
handoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1014</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1014</id><created>2009-12-05</created><authors><author><keyname>Singh</keyname><forenames>Shailendra</forenames></author><author><keyname>Silakari</keyname><forenames>Sanjay</forenames></author></authors><title>An ensemble approach for feature selection of Cyber Attack Dataset</title><categories>cs.CR cs.LG</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 297-302, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection is an indispensable preprocessing step when mining huge
datasets that can significantly improve the overall system performance.
Therefore in this paper we focus on a hybrid approach of feature selection.
This method falls into two phases. The filter phase select the features with
highest information gain and guides the initialization of search process for
wrapper phase whose output the final feature subset. The final feature subsets
are passed through the Knearest neighbor classifier for classification of
attacks. The effectiveness of this algorithm is demonstrated on DARPA KDDCUP99
cyber attack dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1015</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1015</id><created>2009-12-05</created><authors><author><keyname>Rothe</keyname><forenames>Mrs. J. P.</forenames></author><author><keyname>Wadhwani</keyname><forenames>Dr. A. K.</forenames></author><author><keyname>Wadhwani</keyname><forenames>Dr. Mrs. S.</forenames></author></authors><title>Short Term Load Forecasting Using Multi Parameter Regression</title><categories>cs.NE cs.CE</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 303-306, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short Term Load forecasting in this paper uses input data dependent on
parameters such as load for current hour and previous two hours, temperature
for current hour and previous two hours, wind for current hour and previous two
hours, cloud for current hour and previous two hours. Forecasting will be of
load demand for coming hour based on input parameters at that hour. In this
paper we are using multiparameter regression method for forecasting which has
error within tolerable range. Algorithms implementing these forecasting
techniques have been programmed using MATLAB and applied to the case study.
Other methodologies in this area are ANN, Fuzzy and Evolutionary Algorithms for
which investigations are under process. Adaptive multiparameter regression for
load forecasting, in near future will be possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1016</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1016</id><created>2009-12-05</created><authors><author><keyname>Dsousa</keyname><forenames>Ayeesha</forenames></author><author><keyname>Bhatia</keyname><forenames>Shalini</forenames></author></authors><title>Refactoring of a Database</title><categories>cs.DB</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 307-315, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technique of database refactoring is all about applying disciplined and
controlled techniques to change an existing database schema. The problem is to
successfully create a Database Refactoring Framework for databases. This paper
concentrates on the feasibility of adapting this concept to work as a generic
template. To retain the constraints regardless of the modifications to the
metadata, the paper proposes a MetaData Manipulation Tool to facilitate change.
The tool adopts a Template Design Pattern to make it database independent. The
paper presents a drawback of using java for constraint extraction and proposes
an alternative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1017</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1017</id><created>2009-12-05</created><authors><author><keyname>Ismail</keyname><forenames>Ismail A.</forenames></author><author><keyname>ElRamly</keyname><forenames>Nabawia A.</forenames></author><author><keyname>Abd-ElWahid</keyname><forenames>Mohammed A.</forenames></author><author><keyname>ElKafrawy</keyname><forenames>Passent M.</forenames></author><author><keyname>Nasef</keyname><forenames>Mohammed M.</forenames></author></authors><title>Genetic Programming Framework for Fingerprint Matching</title><categories>cs.CR cs.CV cs.MM</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 316-321, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fingerprint matching is a very difficult problem. Minutiae based matching
is the most popular and widely used technique for fingerprint matching. The
minutiae points considered in automatic identification systems are based
normally on termination and bifurcation points. In this paper we propose a new
technique for fingerprint matching using minutiae points and genetic
programming. The goal of this paper is extracting the mathematical formula that
defines the minutiae points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1019</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1019</id><created>2009-12-05</created><authors><author><keyname>Amutha</keyname><forenames>B.</forenames></author><author><keyname>Ponnavaikko</keyname><forenames>M.</forenames></author></authors><title>Location Update Accuracy in Human Tracking system using Zigbee modules</title><categories>cs.HC</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 322-331, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A location and tracking system becomes very important to our future world of
pervasive computing. An algorithm for accurate location information is being
incorporated in the human walking model and in the blind human walking model.
We want to implement an accurate location tracking mechanism using Zigbee along
with GPS, we have incorporated Markov chain algorithm for establishing
accuracy. Normal Human and blind human walking steps were actually taken in the
known environment within our campus and the Markov chain algorithm was used for
smoothening the stepwise variation in location updates. A comparison module is
also implemented to show the difference between normal human and blind human
walking step variations. This accuracy is used for designing a blind tracking
device so that the device can be used by the blind for finding the path without
obstacles. We present a system level approach to localizing and tracking Human
and blind users on a basis of different sources of location information [GPS
plus Zigbee]. The system can be applied outdoors especially for avoiding
accidents, GPS as the source of location data. Performance evaluation shows
that the system is accurate and it is a future path finding device with service
for the blind.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1020</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1020</id><created>2009-12-05</created><authors><author><keyname>Asif</keyname><forenames>Waqar</forenames></author><author><keyname>Qasim</keyname><forenames>Muhammad Bilal</forenames></author><author><keyname>Tirmzi</keyname><forenames>Syed Musa Raza</forenames></author><author><keyname>Khan</keyname><forenames>Usman Muhammad</forenames></author></authors><title>Performance Evaluation of WiMAX (802.16) Using Different Encoding
  Schemes</title><categories>cs.NI</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 332-336, November 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the performance of Worldwide Interoperability for
Microwave Access (WiMAX), when we enhance its physical layer attributes with
help of different encoding techniques. For this evaluation Space Time Block
Codes (STBC) and Turbo codes are separately introduced into the architecture of
WiMAX that works on adaptive modulation technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1023</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1023</id><created>2009-12-05</created><updated>2010-06-22</updated><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Luo</keyname><forenames>Hanwen</forenames></author><author><keyname>Chen</keyname><forenames>Wen</forenames></author></authors><title>Efficient Relay Beamforming Design with SIC Detection for Dual-Hop MIMO
  Relay Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>18 pages, 6 figures</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol. 59, no. 8, pp.
  4192-4197, Oct. 2010</journal-ref><doi>10.1109/TVT.2010.2065249</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a dual-hop Multiple Input Multiple Output (MIMO)
relay wireless network, in which a source-destination pair both equipped with
multiple antennas communicates through a large number of half-duplex
amplify-and-forward (AF) relay terminals. Two novel linear beamforming schemes
based on the matched filter (MF) and regularized zero-forcing (RZF) precoding
techniques are proposed for the MIMO relay system. We focus on the linear
process at the relay nodes and design the new relay beamformers by utilizing
the channel state information (CSI) of both backward channel and forward
channel. The proposed beamforming designs are based on the QR decomposition
(QRD) filter at the destination node which performs successive interference
cancellation (SIC) to achieve the maximum spatial multiplexing gain. Simulation
results demonstrate that the proposed beamformers that fulfil both the
intranode array gain and distributed array gain outperform other relaying
schemes under different system parameters in terms of the ergodic capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1034</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1034</id><created>2009-12-05</created><authors><author><keyname>Brzozowski</keyname><forenames>J.</forenames></author><author><keyname>Jir&#xe1;skov&#xe1;</keyname><forenames>G.</forenames></author><author><keyname>Zou</keyname><forenames>C.</forenames></author></authors><title>Quotient Complexity of Closed Languages</title><categories>cs.FL</categories><comments>12 pages, 5 eps figures, uses llncs</comments><doi>10.1007/978-3-642-13182-0_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A language L is prefix-closed if, whenever a word w is in L, then every
prefix of w is also in L. We define suffix-, factor-, and subword-closed
languages in the same way, where by subword we mean subsequence. We study the
quotient complexity (usually called state complexity) of operations on prefix-,
suffix-, factor-, and subword-closed languages. We find tight upper bounds on
the complexity of the prefix-, suffix-, factor-, and subword-closure of
arbitrary languages, and on the complexity of boolean operations,
concatenation, star and reversal in each of the four classes of closed
languages. We show that repeated application of positive closure and complement
to a closed language results in at most four distinct languages, while Kleene
closure and complement gives at most eight languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1045</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1045</id><created>2009-12-05</created><updated>2011-02-24</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author></authors><title>Thresholded Covering Algorithms for Robust and Max-Min Optimization</title><categories>cs.DS</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The general problem of robust optimization is this: one of several possible
scenarios will appear tomorrow, but things are more expensive tomorrow than
they are today. What should you anticipatorily buy today, so that the
worst-case cost (summed over both days) is minimized? Feige et al. and
Khandekar et al. considered the k-robust model where the possible outcomes
tomorrow are given by all demand-subsets of size k, and gave algorithms for the
set cover problem, and the Steiner tree and facility location problems in this
model, respectively.
  In this paper, we give the following simple and intuitive template for
k-robust problems: &quot;having built some anticipatory solution, if there exists a
single demand whose augmentation cost is larger than some threshold, augment
the anticipatory solution to cover this demand as well, and repeat&quot;. In this
paper we show that this template gives us improved approximation algorithms for
k-robust Steiner tree and set cover, and the first approximation algorithms for
k-robust Steiner forest, minimum-cut and multicut. All our approximation ratios
(except for multicut) are almost best possible.
  As a by-product of our techniques, we also get algorithms for max-min
problems of the form: &quot;given a covering problem instance, which k of the
elements are costliest to cover?&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1050</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1050</id><created>2009-12-05</created><authors><author><keyname>Fellows</keyname><forenames>M.</forenames></author><author><keyname>Giannopoulos</keyname><forenames>P.</forenames></author><author><keyname>Knauer</keyname><forenames>C.</forenames></author><author><keyname>Paul</keyname><forenames>C.</forenames></author><author><keyname>Rosamond</keyname><forenames>F.</forenames></author><author><keyname>Whitesides</keyname><forenames>S.</forenames></author><author><keyname>Yu</keyname><forenames>N.</forenames></author></authors><title>Abstract Milling with Turn Costs</title><categories>cs.CC cs.CG cs.DS cs.LO</categories><comments>18 pages, 2 figures</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Abstract Milling problem is a natural and quite general graph-theoretic
model for geometric milling problems. Given a graph, one asks for a walk that
covers all its vertices with a minimum number of turns, as specified in the
graph model by a 0/1 turncost function fx at each vertex x giving, for each
ordered pair of edges (e,f) incident at x, the turn cost at x of a walk that
enters the vertex on edge e and departs on edge f. We describe an initial study
of the parameterized complexity of the problem. Our main positive result shows
that Abstract Milling, parameterized by: number of turns, treewidth and maximum
degree, is fixed-parameter tractable, We also show that Abstract Milling
parameterized by (only) the number of turns and the pathwidth, is hard for W[1]
-- one of the few parameterized intractability results for bounded pathwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1059</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1059</id><created>2009-12-05</created><authors><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Reduced Complexity Angle-Doppler-Range Estimation for MIMO Radar That
  Employs Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, Asilomar 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The authors recently proposed a MIMO radar system that is implemented by a
small wireless network. By applying compressive sensing (CS) at the receive
nodes, the MIMO radar super-resolution can be achieved with far fewer
observations than conventional approaches. This previous work considered the
estimation of direction of arrival and Doppler. Since the targets are sparse in
the angle-velocity space, target information can be extracted by solving an l1
minimization problem. In this paper, the range information is exploited by
introducing step frequency to MIMO radar with CS. The proposed approach is able
to achieve high range resolution and also improve the ambiguous velocity.
However, joint angle-Doppler-range estimation requires discretization of the
angle-Doppler-range space which causes a sharp rise in the computational burden
of the l1 minimization problem. To maintain an acceptable complexity, a
technique is proposed to successively estimate angle, Doppler and range in a
decoupled fashion. The proposed approach can significantly reduce the
complexity without sacrificing performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1072</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1072</id><created>2009-12-05</created><updated>2011-12-19</updated><authors><author><keyname>Freer</keyname><forenames>Cameron E.</forenames></author><author><keyname>Roy</keyname><forenames>Daniel M.</forenames></author></authors><title>Computable de Finetti measures</title><categories>math.LO cs.LO cs.PL math.PR math.ST stat.ML stat.TH</categories><comments>32 pages. Final journal version; expanded somewhat, with minor
  corrections. To appear in Annals of Pure and Applied Logic. Extended abstract
  appeared in Proceedings of CiE '09, LNCS 5635, pp. 218-231</comments><msc-class>03D78, 60G09, 68Q10, 03F60, 68N18</msc-class><journal-ref>Annals of Pure and Applied Logic 163 (2012) pp. 530-546</journal-ref><doi>10.1016/j.apal.2011.06.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a computable version of de Finetti's theorem on exchangeable
sequences of real random variables. As a consequence, exchangeable stochastic
processes expressed in probabilistic functional programming languages can be
automatically rewritten as procedures that do not modify non-local state. Along
the way, we prove that a distribution on the unit interval is computable if and
only if its moments are uniformly computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1092</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1092</id><created>2009-12-06</created><authors><author><keyname>Malayeri</keyname><forenames>Amin Daneshmand</forenames></author><author><keyname>Abdollahi</keyname><forenames>Jalal</forenames></author></authors><title>Modern Symmetric Cryptography methodologies and its applications</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, using cryptographic systems play an effective role in security and
safety technologies. One of the most applied kind of cryptography is Symmetric
Cryptography and its applications. New aspects of symmetric Cryptography
methodologies and applications has been presented by this paper. Security-based
networks and some complex technologies such as RFID and parallel security
settings has been intro-duced by using Symmetric Cryptography is the main base
of discussion in this paper. Designing an unique protocol for Symmetric
Cryptography in security networks elements is our focus. Reviewing benefits of
using these methodologies has been pre-sented and discussed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1110</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1110</id><created>2009-12-06</created><authors><author><keyname>Boucher</keyname><forenames>Serge</forenames></author><author><keyname>Verhaegen</keyname><forenames>Boris</forenames></author><author><keyname>Zim&#xe1;nyi</keyname><forenames>Esteban</forenames></author></authors><title>XML Multidimensional Modelling and Querying</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As XML becomes ubiquitous and XML storage and processing becomes more
efficient, the range of use cases for these technologies widens daily. One
promising area is the integration of XML and data warehouses, where an
XML-native database stores multidimensional data and processes OLAP queries
written in the XQuery interrogation language. This paper explores issues
arising in the implementation of such a data warehouse. We first compare
approaches for multidimensional data modelling in XML, then describe how
typical OLAP queries on these models can be expressed in XQuery. We then show
how, regardless of the model, the grouping features of XQuery 1.1 improve
performance and readability of these queries. Finally, we evaluate the
performance of query evaluation in each modelling choice using the eXist
database, which we extended with a grouping clause implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1128</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1128</id><created>2009-12-06</created><authors><author><keyname>Baehrens</keyname><forenames>David</forenames></author><author><keyname>Schroeter</keyname><forenames>Timon</forenames></author><author><keyname>Harmeling</keyname><forenames>Stefan</forenames></author><author><keyname>Kawanabe</keyname><forenames>Motoaki</forenames></author><author><keyname>Hansen</keyname><forenames>Katja</forenames></author><author><keyname>Mueller</keyname><forenames>Klaus-Robert</forenames></author></authors><title>How to Explain Individual Classification Decisions</title><categories>stat.ML cs.LG</categories><comments>31 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After building a classifier with modern tools of machine learning we
typically have a black box at hand that is able to predict well for unseen
data. Thus, we get an answer to the question what is the most likely label of a
given unseen data point. However, most methods will provide no answer why the
model predicted the particular label for a single instance and what features
were most influential for that particular instance. The only method that is
currently able to provide such explanations are decision trees. This paper
proposes a procedure which (based on a set of assumptions) allows to explain
the decisions of any classification method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1135</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1135</id><created>2009-12-06</created><updated>2009-12-10</updated><authors><author><keyname>Rokhlin</keyname><forenames>Vladimir</forenames></author><author><keyname>Tygert</keyname><forenames>Mark</forenames></author></authors><title>A fast randomized algorithm for orthogonal projection</title><categories>cs.NA</categories><comments>13 pages, 6 tables</comments><journal-ref>SIAM Journal on Scientific Computing, 33 (2): 849-868, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm that, given any full-rank matrix A having fewer rows
than columns, can rapidly compute the orthogonal projection of any vector onto
the null space of A, as well as the orthogonal projection onto the row space of
A, provided that both A and its adjoint can be applied rapidly to arbitrary
vectors. As an intermediate step, the algorithm solves the overdetermined
linear least-squares regression involving the adjoint of A (and so can be used
for this, too). The basis of the algorithm is an obvious but numerically
unstable scheme; suitable use of a preconditioner yields numerical stability.
We generate the preconditioner rapidly via a randomized procedure that succeeds
with extremely high probability. In many circumstances, the method can
accelerate interior-point methods for convex optimization, such as linear
programming (Ming Gu, personal communication).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1137</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1137</id><created>2009-12-06</created><authors><author><keyname>Bateni</keyname><forenames>MohammadHossein</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author></authors><title>Euclidean Prize-collecting Steiner Forest</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider Steiner forest and its generalizations,
prize-collecting Steiner forest and k-Steiner forest, when the vertices of the
input graph are points in the Euclidean plane and the lengths are Euclidean
distances. First, we present a simpler analysis of the polynomial-time
approximation scheme (PTAS) of Borradaile et al. [12] for the Euclidean Steiner
forest problem. This is done by proving a new structural property and modifying
the dynamic programming by adding a new piece of information to each dynamic
programming state. Next we develop a PTAS for a well-motivated case, i.e., the
multiplicative case, of prize-collecting and budgeted Steiner forest. The ideas
used in the algorithm may have applications in design of a broad class of
bicriteria PTASs. At the end, we demonstrate why PTASs for these problems can
be hard in the general Euclidean case (and thus for PTASs we cannot go beyond
the multiplicative case).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1155</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1155</id><created>2009-12-06</created><updated>2009-12-21</updated><authors><author><keyname>Barth</keyname><forenames>Adam</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Sundararajan</keyname><forenames>Mukund</forenames></author><author><keyname>Mitchell</keyname><forenames>John C.</forenames></author><author><keyname>Song</keyname><forenames>Dawn</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter L.</forenames></author></authors><title>A Learning-Based Approach to Reactive Security</title><categories>cs.CR cs.GT cs.LG</categories><comments>22 pages, 4 figures; full version of paper to be published in
  Financial Cryptography and Data Security 2010 (FC'10)</comments><doi>10.1007/978-3-642-14577-3_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the conventional wisdom that proactive security is superior to
reactive security, we show that reactive security can be competitive with
proactive security as long as the reactive defender learns from past attacks
instead of myopically overreacting to the last attack. Our game-theoretic model
follows common practice in the security literature by making worst-case
assumptions about the attacker: we grant the attacker complete knowledge of the
defender's strategy and do not require the attacker to act rationally. In this
model, we bound the competitive ratio between a reactive defense algorithm
(which is inspired by online learning theory) and the best fixed proactive
defense. Additionally, we show that, unlike proactive defenses, this reactive
strategy is robust to a lack of information about the attacker's incentives and
knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1178</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1178</id><created>2009-12-07</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Saclay - Ile de France, CRAN</affiliation></author><author><keyname>Mboup</keyname><forenames>Mamadou</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Algebraic Change-Point Detection</title><categories>cs.NA math.RA</categories><proxy>ccsd inria-00439226</proxy><journal-ref>Applicable Algebra in Engineering, Communication and Computing
  (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Elementary techniques from operational calculus, differential algebra, and
noncommutative algebra lead to a new approach for change-point detection, which
is an important field of investigation in various areas of applied sciences and
engineering. Several successful numerical experiments are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1198</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1198</id><created>2009-12-07</created><authors><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Cui</keyname><forenames>Ying</forenames></author></authors><title>Delay-Optimal Power and Subcarrier Allocation for OFDMA Systems via
  Stochastic Approximation</title><categories>cs.LG</categories><comments>11 pages, 7 figures, TWC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider delay-optimal power and subcarrier allocation
design for OFDMA systems with $N_F$ subcarriers, $K$ mobiles and one base
station. There are $K$ queues at the base station for the downlink traffic to
the $K$ mobiles with heterogeneous packet arrivals and delay requirements. We
shall model the problem as a $K$-dimensional infinite horizon average reward
Markov Decision Problem (MDP) where the control actions are assumed to be a
function of the instantaneous Channel State Information (CSI) as well as the
joint Queue State Information (QSI). This problem is challenging because it
corresponds to a stochastic Network Utility Maximization (NUM) problem where
general solution is still unknown. We propose an {\em online stochastic value
iteration} solution using {\em stochastic approximation}. The proposed power
control algorithm, which is a function of both the CSI and the QSI, takes the
form of multi-level water-filling. We prove that under two mild conditions in
Theorem 1 (One is the stepsize condition. The other is the condition on
accessibility of the Markov Chain, which can be easily satisfied in most of the
cases we are interested.), the proposed solution converges to the optimal
solution almost surely (with probability 1) and the proposed framework offers a
possible solution to the general stochastic NUM problem. By exploiting the
birth-death structure of the queue dynamics, we obtain a reduced complexity
decomposed solution with linear $\mathcal{O}(KN_F)$ complexity and
$\mathcal{O}(K)$ memory requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1200</identifier>
 <datestamp>2010-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1200</id><created>2009-12-07</created><updated>2010-01-01</updated><authors><author><keyname>Shine</keyname><forenames>S.</forenames></author><author><keyname>Krishnan</keyname><forenames>K. Murali</forenames></author></authors><title>Extending Karger's randomized min-cut Algorithm for a Synchronous
  Distributed setting</title><categories>cs.DS cs.DC</categories><comments>6 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A min-cut that seperates vertices s and t in a network is an edge set of
minimum weight whose removal will disconnect s and t. This problem is the dual
of the well known s-t max-flow problem. Several algorithms for the min-cut
problem are based on max-flow computation although the fastest known min-cut
algorithms are not flow based. The well known Karger's randomized algorithm for
min-cut is a non-flow based method for solving the (global) min-cut problem of
finding the min s-t cut over all pair of vertices s,t in a weighted undirected
graph. This paper presents an adaptation of Karger's algorithm for a
synchronous distributed setting where each node is allowed to perform only
local computations. The paper essentially addresses the technicalities involved
in circumventing the limitations imposed by a distributed setting to the
working of Karger's algorithm. While the correctness proof follows directly
from Karger's algorithm, the complexity analysis differs significantly. The
algorithm achieves the same probability of success as the original algorithm
with O(mn^{2}) message complexity and O(n^{2}) time complexity, where n and m
denote the number of vertices and edges in the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1208</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1208</id><created>2009-12-07</created><authors><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Minimum Cycle Basis and All-Pairs Min Cut of a Planar Graph in
  Subquadratic Time</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A minimum cycle basis of a weighted undirected graph $G$ is a basis of the
cycle space of $G$ such that the total weight of the cycles in this basis is
minimized. If $G$ is a planar graph with non-negative edge weights, such a
basis can be found in $O(n^2)$ time and space, where $n$ is the size of $G$. We
show that this is optimal if an explicit representation of the basis is
required. We then present an $O(n^{3/2}\log n)$ time and $O(n^{3/2})$ space
algorithm that computes a minimum cycle basis \emph{implicitly}. From this
result, we obtain an output-sensitive algorithm that explicitly computes a
minimum cycle basis in $O(n^{3/2}\log n + C)$ time and $O(n^{3/2} + C)$ space,
where $C$ is the total size (number of edges and vertices) of the cycles in the
basis. These bounds reduce to $O(n^{3/2}\log n)$ and $O(n^{3/2})$,
respectively, when $G$ is unweighted. We get similar results for the all-pairs
min cut problem since it is dual equivalent to the minimum cycle basis problem
for planar graphs. We also obtain $O(n^{3/2}\log n)$ time and $O(n^{3/2})$
space algorithms for finding, respectively, the weight vector and a Gomory-Hu
tree of $G$. The previous best time and space bound for these two problems was
quadratic. From our Gomory-Hu tree algorithm, we obtain the following result:
with $O(n^{3/2}\log n)$ time and $O(n^{3/2})$ space for preprocessing, the
weight of a min cut between any two given vertices of $G$ can be reported in
constant time. Previously, such an oracle required quadratic time and space for
preprocessing. The oracle can also be extended to report the actual cut in time
proportional to its size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1216</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1216</id><created>2009-12-07</created><authors><author><keyname>Cui</keyname><forenames>Ying</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author></authors><title>Distributive Subband Allocation, Power and Rate Control for
  Relay-Assisted OFDMA Cellular System with Imperfect System State Knowledge</title><categories>cs.NI cs.IT math.IT</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider distributive subband, power and rate allocation
for a two-hop transmission in an orthogonal frequency-division multiple-access
(OFDMA) cellular system with fixed relays which operate in decode-and-forward
strategy. We take into account of system fairness by considering weighted sum
goodput as our optimization objective. Based on the cluster-based architecture,
we obtain a fast-converging distributive solution with only local imperfect
CSIT by using decomposition of the optimization problem. To further reduce the
signaling overhead and computational complexity, we propose a reduced feedback
distributive solution, which can achieve asymptotically optimal performance for
large number of users with arbitrarily small feedback overhead per user. We
also derive asymptotic average system throughput for the relay-assisted OFDMA
system so as to obtain useful design insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1221</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1221</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Clusters and Maps of Science Journals Based on Bi-connected Graphs in
  the Journal Citation Reports</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Journal of Documentation, 60(4), 2004, 317-427</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aggregated journal-journal citation matrix derived from the Journal
Citation Reports 2001 can be decomposed into a unique subject classification by
using the graph-analytical algorithm of bi-connected components. This technique
was recently incorporated in software tools for social network analysis. The
matrix can be assessed in terms of its decomposability using articulation
points which indicate overlap between the components. The articulation points
of this set did not exhibit a next-order network of 'general science' journals.
However, the clusters differ in size and in terms of the internal density of
their relations. A full classification of the journals is provided in an
Appendix. The clusters can also be extracted and mapped for the visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1224</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1224</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The university-industry knowledge relationship: Analyzing patents and
  the science base of technologies</title><categories>cs.DL cs.CY cs.IR physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science and
  Technology, 55(11), 2004, 991-1001</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Via the Internet, information scientists can obtain cost-free access to large
databases in the hidden or deep web. These databases are often structured far
more than the Internet domains themselves. The patent database of the U.S.
Patent and Trade Office is used in this study to examine the science base of
patents in terms of the literature references in these patents.
University-based patents at the global level are compared with results when
using the national economy of the Netherlands as a system of reference. Methods
for accessing the on-line databases and for the visualization of the results
are specified. The conclusion is that 'biotechnology' has historically
generated a model for theorizing about university-industry relations that
cannot easily be generalized to other sectors and disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1227</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1227</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bihui</keyname><forenames>Jin</forenames></author></authors><title>Mapping the Chinese Science Citation Database</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Proceedings of the 67th ASIS&amp;T Annual Meeting, Vol. 41 (Medford,
  NJ: Information Today, 2004), pp. 488-495</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods developed for mapping the journal structures contained in aggregated
journal-journal citations in the Science Citation Index are applied to the
Chinese Science Citation Database of the Chinese Academy of Sciences. This
database covers 991 journals, of which only 37 had originally English titles.
Using factor-analytical and graph-analytical techniques we show that this data
is dually structured. The main structure is the intellectual organization of
the journals in journal groups (as in the international SCI), but the
university-based journals provide an institutional layer that orients this
structure towards practical ends (e.g., agriculture). The Chinese Science
Citation Database exhibits the characteristics of Mode 2 in the production of
scientific knowledge more than its western counterparts. The contexts of
application lead to correlation (interfactorial complexity) among the
components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1231</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1231</id><created>2009-12-07</created><authors><author><keyname>Frenken</keyname><forenames>Koen</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Scientometrics and the evaluation of European integration</title><categories>physics.soc-ph cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, we elaborate on the topic of European integration in
science. We will not deal with questions related to the effects of European
integration, but only with the scientometric question how one can
quantitatively indicate integration of the European science system. Our study
is intended to facilitate and supplement debates rather than to provide a final
answer to the questions whether European integration 'exists'. In this chapter,
we first discuss the use of scientometric indicators in research evaluation
from a historical perspective in (section 2). A discussion of European science
policy follows (section 3). Then, we introduce a number of indicators of
integration and discuss our empirical results concerning the evolution of the
European science system in the 1980s and 1990s (section 4). We close the
chapter with a discussion of possible avenues of future research for enhancing
research evaluation (section 5).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1238</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1238</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Ward</keyname><forenames>Janelle</forenames></author></authors><title>Communication of Science Shop Mediation: A Kaleidoscope of
  University-Society Relations</title><categories>cs.CY cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Science Shop model was initiated in the Netherlands in the 1970s. Part of
the model is the modest scale of the operation. The crucial idea behind the
Science Shops involves a working relationship between knowledge-producing
institutions like universities and citizen groups that need relevant questions
answered. In providing this link, the relations between science and the public
can be stimulated by providing such groups with access to the university and by
offering active mediation of these questions. This research addresses the
question of the external visibility of Science Shop work in terms of
communications which reach beyond the local context of the participants. In
addition to the question of the effects of this specific type of communication
in terms of publications, institutional development, and curriculum
development, we study the communication of the results in the press, the
popular and grey literature, and other means of communication insofar as
retrievable on distance through the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1262</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1262</id><created>2009-12-07</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Open Access, Intellectual Property, and How Biotechnology Becomes a New
  Software Science</title><categories>cs.CY</categories><comments>7 pages</comments><acm-class>K.4; K.5</acm-class><journal-ref>CEPIS UPGRADE, vol. XI, no. 4, pp. 50-64, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Innovation is slowing greatly in the pharmaceutical sector. It is considered
here how part of the problem is due to overly limiting intellectual property
relations in the sector. On the other hand, computing and software in
particular are characterized by great richness of intellectual property
frameworks. Could the intellectual property ecosystem of computing come to the
aid of the biosciences and life sciences? We look at how the answer might well
be yes, by looking at (i) the extent to which a drug mirrors a software
program, and (ii) what is to be gleaned from trends in research publishing in
the life and biosciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1272</identifier>
 <datestamp>2013-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1272</id><created>2009-12-07</created><updated>2013-03-06</updated><authors><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Subshifts as Models for MSO Logic</title><categories>cs.DM cs.LO</categories><comments>arXiv admin note: substantial text overlap with arXiv:0904.2457</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Monadic Second Order (MSO) Hierarchy over colourings of the
discrete plane, and draw links between classes of formula and classes of
subshifts. We give a characterization of existential MSO in terms of
projections of tilings, and of universal sentences in terms of combinations of
&quot;pattern counting&quot; subshifts. Conversely, we characterise logic fragments
corresponding to various classes of subshifts (subshifts of finite type, sofic
subshifts, all subshifts). Finally, we show by a separation result how the
situation here is different from the case of tiling pictures studied earlier by
Giammarresi et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1294</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1294</id><created>2009-12-07</created><authors><author><keyname>Chahine</keyname><forenames>Carlo Abi</forenames><affiliation>LITIS</affiliation></author><author><keyname>Kotowicz</keyname><forenames>Jean-Philippe</forenames><affiliation>LITIS</affiliation></author><author><keyname>Chaignaud</keyname><forenames>Nathalie</forenames><affiliation>LITIS</affiliation></author><author><keyname>P&#xe9;cuchet</keyname><forenames>Jean-Pierre</forenames><affiliation>LITIS</affiliation></author></authors><title>Conception d'un outil d'aide \`a l'indexation de ressources
  p\'edagogiques - Extraction automatique des the?matiques et des mots-clefs de
  documents UNIT</title><categories>cs.IR</categories><proxy>ccsd hal-00439213</proxy><journal-ref>Environnements Informatiques pour l'Apprentissage Humain, Le Mans
  : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indexing learning documents using the Learning Object Metadata (LOM) is often
carried out manually by archivists. Filling out the LOM fields is a long and
difficult task, requiring a complete reading and a full knowledge on the topic
dealt within the document. In this paper, we present an innovative model and
method to assist the archivists in finding the important concepts and keywords
of a learning document. The application is performed using wikipedia's category
links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1310</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1310</id><created>2009-12-07</created><authors><author><keyname>Rosten</keyname><forenames>Edward</forenames></author><author><keyname>Loveland</keyname><forenames>Rohan</forenames></author><author><keyname>Hickman</keyname><forenames>Mark</forenames></author></authors><title>Automatic creation of urban velocity fields from aerial video</title><categories>cs.CV</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a system for modelling vehicle motion in an urban
scene from low frame-rate aerial video. In particular, the scene is modelled as
a probability distribution over velocities at every pixel in the image.
  We describe the complete system for acquiring this model. The video is
captured from a helicopter and stabilized by warping the images to match an
orthorectified image of the area. A pixel classifier is applied to the
stabilized images, and the response is segmented to determine car locations and
orientations. The results are fed in to a tracking scheme which tracks cars for
three frames, creating tracklets. This allows the tracker to use a combination
of velocity, direction, appearance, and acceleration cues to keep only tracks
likely to be correct. Each tracklet provides a measurement of the car velocity
at every point along the tracklet's length, and these are then aggregated to
create a histogram of vehicle velocities at every pixel in the image.
  The results demonstrate that the velocity probability distribution prior can
be used to infer a variety of information about road lane directions, speed
limits, vehicle speeds and common trajectories, and traffic bottlenecks, as
well as providing a means of describing environmental knowledge about traffic
rules that can be used in tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1329</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1329</id><created>2009-12-07</created><authors><author><keyname>Kuller</keyname><forenames>Samir</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Saha</keyname><forenames>Barna</forenames></author></authors><title>Energy Efficient Scheduling via Partial Shutdown</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by issues of saving energy in data centers we define a collection
of new problems referred to as &quot;machine activation&quot; problems. The central
framework we introduce considers a collection of $m$ machines (unrelated or
related) with each machine $i$ having an {\em activation cost} of $a_i$. There
is also a collection of $n$ jobs that need to be performed, and $p_{i,j}$ is
the processing time of job $j$ on machine $i$. We assume that there is an
activation cost budget of $A$ -- we would like to {\em select} a subset $S$ of
the machines to activate with total cost $a(S) \le A$ and {\em find} a schedule
for the $n$ jobs on the machines in $S$ minimizing the makespan (or any other
metric).
  For the general unrelated machine activation problem, our main results are
that if there is a schedule with makespan $T$ and activation cost $A$ then we
can obtain a schedule with makespan $\makespanconstant T$ and activation cost
$\costconstant A$, for any $\epsilon &gt;0$. We also consider assignment costs for
jobs as in the generalized assignment problem, and using our framework, provide
algorithms that minimize the machine activation and the assignment cost
simultaneously. In addition, we present a greedy algorithm which only works for
the basic version and yields a makespan of $2T$ and an activation cost $A
(1+\ln n)$.
  For the uniformly related parallel machine scheduling problem, we develop a
polynomial time approximation scheme that outputs a schedule with the property
that the activation cost of the subset of machines is at most $A$ and the
makespan is at most $(1+\epsilon) T$ for any $\epsilon &gt;0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1333</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1333</id><created>2009-12-07</created><authors><author><keyname>Taki</keyname><forenames>Mehrdad</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Spectral Efficiency Optimization for an Interfering Cognitive Radio with
  Adaptive Modulation and Coding</title><categories>cs.IT math.IT</categories><comments>26 pages, 7 figures submitted to IEEE journal on selected areas in
  communication</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we consider a primary and a cognitive user transmitting over a
wireless fading interference channel. The primary user transmits with a
constant power and utilizes an adaptive modulation and coding (AMC) scheme
satisfying a bit error rate requirement. We propose a link adaptation scheme to
maximize the average spectral efficiency of the cognitive radio, while a
minimum required spectral efficiency for the primary user is provisioned. The
resulting problem is constrained to also satisfy a bit error rate requirement
and a power constraint for the cognitive link. The AMC mode selection and power
control at the cognitive transmitter is optimized based on the modified signal
to noise plus interference ratio feedback of both links. The problem is then
cast as a nonlinear discrete optimization problem for which a fast and
efficient suboptimum solution is presented. We also present a scheme with rate
adaptive and constant power cognitive radio. An important characteristic of the
proposed schemes is that no computation or coordination overhead is imposed on
the primary radio due to the cognitive radio activity. Numerical results and
comparison with the interweave approach to cognitive radio demonstrate the
efficiency of the proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1357</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1357</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Construction and Globalization of the Knowledge Base in Inter-human
  Communication Systems</title><categories>cs.CY nlin.AO physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationship between the &quot;knowledge base&quot; and the &quot;globalization&quot; of
communication systems is discussed from the perspective of communication
theory. I argue that inter-human communication takes place at two levels. At
the first level information is exchanged and provided with meaning and at the
second level meaning can reflexively be communicated. Human language can be
considered as the evolutionary achievement which enables us to use these two
channels of communication simultaneously. Providing meaning from the
perspective of hindsight is a recursive operation: a meaning that makes a
difference can be considered as knowledge. If the production of knowledge is
socially organized, the perspective of hindsight can further be codified. This
adds globalization to the historically stabilized patterns of communications.
Globalization can be expected to transform the communications in an
evolutionary mode. However, the self-organization of a knowledge-based society
remains an expectation with the status of a hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1368</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1368</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Scharnhorst</keyname><forenames>Andrea</forenames></author></authors><title>Measuring the Knowledge Base: A Program of Innovation Studies</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Organized knowledge production can then be considered as the codification of
communication. Communications leave traces that can be studied as indicators.
Institutions can be considered as retention mechanisms functional for the
reproduction of ever more complex, that is, scientific and knowledge-based,
communications. The focus on communication enables us to operationalize the
research questions in terms of indicators by using the mathematical theory of
communication. The combination of two theories with a very different
status--i.e., a combination of theory and methods--enables us to update and
inform empirical hypotheses about how the knowledge base transforms the
institutional relations of an increasingly knowledge-based society. Policy
implications are specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1369</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1369</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Mutual Information of University-Industry-Government Relations: An
  Indicator of the Triple Helix Dynamics</title><categories>cs.CY cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  University-industry-government relations provide a networked infrastructure
for knowledge-based innovation systems. This infrastructure organizes the
dynamic fluxes locally and the knowledge base remains emergent given these
conditions. Whereas the relations between the institutions can be measured as
variables, the interacting fluxes generate a probabilistic entropy. The mutual
information among the three institutional dimensions provides us with an
indicator of this entropy. When this indicator is negative, self-organization
can be expected. The self-organizing dynamic may temporarily be stabilized in
the overlay of communications among the carrying agencies. The various dynamics
of Triple Helix relations at the global and national levels, in different
databases, and in different regions of the world, are distinguished by applying
this indicator to scientometric and webometric data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1370</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1370</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>'Interaction' versus 'action' in Luhmann's sociology of communication</title><categories>cs.CY cs.HC physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both 'actions' and 'interactions' can be considered as micro-operations that
can be aggregated from a systemic perspective. Whereas actions operate
historically, interactions provide the events retrospectively with meaning.
Luhmann's sociology of communication systems adds to the approach of symbolic
interactionism the question of what global dimensions of communication mean for
local interactions. When communication is functionally differentiated--for
example, in terms of media--tensions can be expected to develop between local
organizations and global developments of communication structures. Interfaces
enable us to translate selectively among (provisionally) stabilized
representations, for example, in professional practices. 'Big science' and
'high tech' can be considered as organizational acculturations of an emerging
level of sophistication in global communications. The global dimension remains
a hypothesis, but entertaining this hypothesis of 'globalization' restructures
the local expectations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1371</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1371</id><created>2009-12-07</created><authors><author><keyname>Wagner</keyname><forenames>Caroline S.</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>A study of seismology as a dynamic, distributed area of scientific
  research</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Scientometrics 58(1) (2003) 91-114</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismology has several features that suggest it is a highly internationalized
field: the subject matter is global, the tools used to analyse seismic waves
are dependent upon information technologies, and governments are interested in
funding cooperative research. We explore whether an emerging field like
seismology has a more internationalised structure than the older, related field
of geophysics. Using aggregated journal-journal citations, we first show that,
within the citing environment, seismology emerged from within geophysics as its
own field in the 1990s. The bibliographic analysis, however, does not show that
seismology is more internationalised than geophysics: in 2000, seismology had a
lower percentage of all articles co-authored on an international basis.
Nevertheless, social network analysis shows that the core group of cooperating
countries within seismology is proportionately larger and more distributed than
that within geophysics. While the latter exhibits an established network with a
hierarchy, the formation of a field in terms of new partnership relations is
ongoing in seismology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1372</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1372</id><created>2009-12-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Communication and Knowledge: How is the knowledge base of an economy
  constructed?</title><categories>cs.CY physics.soc-ph</categories><journal-ref>15th Annual Meeting of the Society for Social Economics (SASE),
  Aix-en-Provence, 27 June 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The competitive advantages in a knowledge-based economy can no longer be
attributed to single nodes in the network. Political economies are increasingly
reshaped by knowledge-based developments that upset market equilibria and
institutional arrangements. The network coordinates the subdynamics of (i)
wealth production, (ii) organized novelty production, and (iii) private
appropriation versus public control. The interaction terms generate a complex
dynamics which cannot be expected to contain central coordination. However, the
knowledge infrastructure of systems of innovations can be measured, for
example, in terms of university-industry-government relations. The mutual
information in these three dimensions indicates the globalization of the
knowledge base. Patent statistics and data from the Internet are compared in
terms of this indicator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1403</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1403</id><created>2009-12-07</created><updated>2010-12-30</updated><authors><author><keyname>Deshpande</keyname><forenames>Amit</forenames></author><author><keyname>Varadarajan</keyname><forenames>Kasturi</forenames></author><author><keyname>Tulsiani</keyname><forenames>Madhur</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>Algorithms and Hardness for Subspace Approximation</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subspace approximation problem Subspace($k$,$p$) asks for a
$k$-dimensional linear subspace that fits a given set of points optimally,
where the error for fitting is a generalization of the least squares fit and
uses the $\ell_{p}$ norm instead. Most of the previous work on subspace
approximation has focused on small or constant $k$ and $p$, using coresets and
sampling techniques from computational geometry.
  In this paper, extending another line of work based on convex relaxation and
rounding, we give a polynomial time algorithm, \emph{for any $k$ and any $p
\geq 2$}, with the approximation guarantee roughly $\gamma_{p} \sqrt{2 -
\frac{1}{n-k}}$, where $\gamma_{p}$ is the $p$-th moment of a standard normal
random variable N(0,1). We show that the convex relaxation we use has an
integrality gap (or &quot;rank gap&quot;) of $\gamma_{p} (1 - \epsilon)$, for any
constant $\epsilon &gt; 0$. Finally, we show that assuming the Unique Games
Conjecture, the subspace approximation problem is hard to approximate within a
factor better than $\gamma_{p} (1 - \epsilon)$, for any constant $\epsilon &gt;
0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1412</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1412</id><created>2009-12-08</created><authors><author><keyname>Shang</keyname><forenames>Yilun</forenames></author></authors><title>Topological Properties of an Exponential Random Geometric Graph Process</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>7 pages</comments><journal-ref>CyberC 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a one-dimensional random geometric graph process
with the inter-nodal gaps evolving according to an exponential AR(1) process,
which may serve as a mobile wireless network model. The transition probability
matrix and stationary distribution are derived for the Markov chains in terms
of network connectivity and the number of components. We characterize an
algorithm for the hitting time regarding disconnectivity. In addition, we also
study topological properties for static snapshots. We obtain the degree
distributions as well as asymptotic precise bounds and strong law of large
numbers for connectivity threshold distance and the largest nearest neighbor
distance amongst others. Both closed form results and limit theorems are
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1420</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1420</id><created>2009-12-08</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Nonlinear Effects in Stiffness Modeling of Robotic Manipulators</title><categories>cs.RO</categories><comments>ISSN 2070-3724</comments><proxy>ccsd hal-00439590</proxy><journal-ref>International Conference on Computer and Automation Technology,
  Venise : Italy (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on the enhanced stiffness modeling of robotic manipulators
by taking into account influence of the external force/torque acting upon the
end point. It implements the virtual joint technique that describes the
compliance of manipulator elements by a set of localized six-dimensional
springs separated by rigid links and perfect joints. In contrast to the
conventional formulation, which is valid for the unloaded mode and small
displacements, the proposed approach implicitly assumes that the loading leads
to the non-negligible changes of the manipulator posture and corresponding
amendment of the Jacobian. The developed numerical technique allows computing
the static equilibrium and relevant force/torque reaction of the manipulator
for any given displacement of the end-effector. This enables designer detecting
essentially nonlinear effects in elastic behavior of manipulator, similar to
the buckling of beam elements. It is also proposed the linearization procedure
that is based on the inversion of the dedicated matrix composed of the
stiffness parameters of the virtual springs and the Jacobians/Hessians of the
active and passive joints. The developed technique is illustrated by an
application example that deals with the stiffness analysis of a parallel
manipulator of the Orthoglide family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1421</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1421</id><created>2009-12-08</created><authors><author><keyname>Chahine</keyname><forenames>Carlo Abi</forenames><affiliation>LITIS</affiliation></author><author><keyname>Chaignaud</keyname><forenames>Nathalie</forenames><affiliation>LITIS</affiliation></author><author><keyname>Kotowicz</keyname><forenames>Jean-Philippe</forenames><affiliation>LITIS</affiliation></author><author><keyname>P&#xe9;cuchet</keyname><forenames>Jean-Pierre</forenames><affiliation>LITIS</affiliation></author></authors><title>Context and Keyword Extraction in Plain Text Using a Graph
  Representation</title><categories>cs.IR</categories><proxy>ccsd hal-00439215</proxy><journal-ref>IEEE International Conference on Signal Image Technology and
  Internet Based Systems, SITIS '08., Bali : Indonesia (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Document indexation is an essential task achieved by archivists or automatic
indexing tools. To retrieve relevant documents to a query, keywords describing
this document have to be carefully chosen. Archivists have to find out the
right topic of a document before starting to extract the keywords. For an
archivist indexing specialized documents, experience plays an important role.
But indexing documents on different topics is much harder. This article
proposes an innovative method for an indexing support system. This system takes
as input an ontology and a plain text document and provides as output
contextualized keywords of the document. The method has been evaluated by
exploiting Wikipedia's category links as a termino-ontological resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1424</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1424</id><created>2009-12-08</created><authors><author><keyname>Alvarez-Hamelin</keyname><forenames>Jos&#xe9; Ignacio</forenames><affiliation>FIUBA</affiliation></author><author><keyname>Gast&#xf3;n</keyname><forenames>Beir&#xf3; Mariano</forenames><affiliation>FIUBA</affiliation></author><author><keyname>Busch</keyname><forenames>Jorge Rodolfo</forenames><affiliation>FIUBA</affiliation></author></authors><title>Understanding edge-connectivity in the Internet through
  core-decomposition</title><categories>cs.DM cs.NI</categories><proxy>ccsd inria-00439597</proxy><journal-ref>Internet Mathematics 7, 1 (2011) 45-66</journal-ref><doi>10.1080/15427951.2011.560786</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet is a complex network composed by several networks: the Autonomous
Systems, each one designed to transport information efficiently. Routing
protocols aim to find paths between nodes whenever it is possible (i.e., the
network is not partitioned), or to find paths verifying specific constraints
(e.g., a certain QoS is required). As connectivity is a measure related to both
of them (partitions and selected paths) this work provides a formal lower bound
to it based on core-decomposition, under certain conditions, and low complexity
algorithms to find it. We apply them to analyze maps obtained from the
prominent Internet mapping projects, using the LaNet-vi open-source software
for its visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1440</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1440</id><created>2009-12-08</created><authors><author><keyname>Larsson</keyname><forenames>Jan-Ake</forenames></author><author><keyname>Lofvenberg</keyname><forenames>Jacob</forenames></author></authors><title>Comment on &quot;New Results on Frame-Proof Codes and Traceability Schemes&quot;</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><journal-ref>IEEE Transactions on Information Theory, 56(11): 5888-5889, 2010</journal-ref><doi>10.1109/TIT.2010.2070632</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper &quot;New Results on Frame-Proof Codes and Traceability Schemes&quot; by
Reihaneh Safavi-Naini and Yejing Wang [IEEE Trans. Inform. Theory, vol. 47, no.
7, pp. 3029-3033, Nov. 2001], there are lower bounds for the maximal number of
codewords in binary frame-proof codes and decoders in traceability schemes.
There are also existence proofs using a construction of binary frame-proof
codes and traceability schemes. Here it is found that the main results in the
referenced paper do not hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1452</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1452</id><created>2009-12-08</created><authors><author><keyname>Vanetik</keyname><forenames>N.</forenames></author></authors><title>Good characterization for path packing in a subclass of Karzanov
  networks</title><categories>cs.DM</categories><comments>17 pages, 12 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The path packing problem is stated finding the maximum number of
edge-disjoint paths between predefined pairs of nodes in an undirected
multigraph. Such a multigraph together with predefined node pairs is often
called a network. While in general the path packing problem is NP-hard, there
exists a class of networks for which the hope of better solution for the path
packing problem exists. In this paper we prove a combinatorial max-min theorem
(also called a good characterization) for a wide class of such networks, thus
showing that the path packing problem for this class of networks is in co-NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1457</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1457</id><created>2009-12-08</created><updated>2009-12-10</updated><authors><author><keyname>Habib</keyname><forenames>Michel</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>A survey on algorithmic aspects of modular decomposition</title><categories>cs.DM cs.DS</categories><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modular decomposition is a technique that applies but is not restricted
to graphs. The notion of module naturally appears in the proofs of many graph
theoretical theorems. Computing the modular decomposition tree is an important
preprocessing step to solve a large number of combinatorial optimization
problems. Since the first polynomial time algorithm in the early 70's, the
algorithmic of the modular decomposition has known an important development.
This paper survey the ideas and techniques that arose from this line of
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1523</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1523</id><created>2009-12-08</created><authors><author><keyname>Abal</keyname><forenames>G.</forenames></author><author><keyname>Donangelo</keyname><forenames>R.</forenames></author><author><keyname>Marquezino</keyname><forenames>F. L.</forenames></author><author><keyname>Oliveira</keyname><forenames>A. C.</forenames></author><author><keyname>Portugal</keyname><forenames>R.</forenames></author></authors><title>Decoherence in Search Algorithms</title><categories>quant-ph cs.CC cs.DS</categories><comments>14 pages, presented at 36th Seminar on Software and Hardware
  (SEMISH), XXIX Brazilian Computer Society Congress, Bento Concalves, Brazil</comments><journal-ref>Proceedings of the XXIX Brazilian Computer Society Congress
  (SEMISH), 2009, pages 293-306</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently several quantum search algorithms based on quantum walks were
proposed. Those algorithms differ from Grover's algorithm in many aspects. The
goal is to find a marked vertex in a graph faster than classical algorithms.
Since the implementation of those new algorithms in quantum computers or in
other quantum devices is error-prone, it is important to analyze their
robustness under decoherence. In this work we analyze the impact of decoherence
on quantum search algorithms implemented on two-dimensional grids and on
hypercubes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1534</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1534</id><created>2009-12-08</created><updated>2010-01-18</updated><authors><author><keyname>Hochreiter</keyname><forenames>Ronald</forenames></author></authors><title>Evolutionary multi-stage financial scenario tree generation</title><categories>cs.NE q-fin.CP q-fin.PM</categories><journal-ref>Lecture Notes in Computer Science 6025:182-191. 2010.</journal-ref><doi>10.1007/978-3-642-12242-2_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-stage financial decision optimization under uncertainty depends on a
careful numerical approximation of the underlying stochastic process, which
describes the future returns of the selected assets or asset categories.
Various approaches towards an optimal generation of discrete-time,
discrete-state approximations (represented as scenario trees) have been
suggested in the literature. In this paper, a new evolutionary algorithm to
create scenario trees for multi-stage financial optimization models will be
presented. Numerical results and implementation details conclude the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1580</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1580</id><created>2009-12-08</created><updated>2009-12-08</updated><authors><author><keyname>Fletcher</keyname><forenames>P. Thomas</forenames></author><author><keyname>Moeller</keyname><forenames>John</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Computing Hulls And Centerpoints In Positive Definite Space</title><categories>cs.CG math.MG</categories><comments>16 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present algorithms for computing approximate hulls and
centerpoints for collections of matrices in positive definite space. There are
many applications where the data under consideration, rather than being points
in a Euclidean space, are positive definite (p.d.) matrices. These applications
include diffusion tensor imaging in the brain, elasticity analysis in
mechanical engineering, and the theory of kernel maps in machine learning. Our
work centers around the notion of a horoball: the limit of a ball fixed at one
point whose radius goes to infinity. Horoballs possess many (though not all) of
the properties of halfspaces; in particular, they lack a strong separation
theorem where two horoballs can completely partition the space. In spite of
this, we show that we can compute an approximate &quot;horoball hull&quot; that strictly
contains the actual convex hull. This approximate hull also preserves geodesic
extents, which is a result of independent value: an immediate corollary is that
we can approximately solve problems like the diameter and width in positive
definite space. We also use horoballs to show existence of and compute
approximate robust centerpoints in positive definite space, via the
horoball-equivalent of the notion of depth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1585</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1585</id><created>2009-12-09</created><updated>2012-02-29</updated><authors><author><keyname>Sica</keyname><forenames>Francesco</forenames></author></authors><title>De Factorisatione Numerorum I : In Pursuit of the Erymanthian Boar</title><categories>math.NT cs.CR math.CV</categories><comments>13 pages, minor modification of a conjecture</comments><msc-class>11M06, 30J99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel glance at factoring. The technique broached here departs
from any known (at least to the author) factoring method. In this paper, we
show, given a product of two large primes $N$ (a RSA modulus), how to select a
multiplicative function $\sigma_k$ (dependent on $N$) related to the sum of
divisors function and produce a nontrivial small linear relation among
$\exp(\log^\epsilon N)$ values of $\sigma_k(n)$ for $|n-N| =
O(\exp(\log^\epsilon N))$, (subject to a plausible conjecture). The tools to
achieve this don't go beyond classical analytic number theory, as known one
hundred years ago.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1588</identifier>
 <datestamp>2012-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1588</id><created>2009-12-08</created><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>Self-organizing urban transportation systems</title><categories>nlin.AO cs.MA</categories><comments>Final version to be published in &quot;Complexity theories of cities have
  come of age&quot;, edited by Juval Portugali and Han Meyer, Springer, 2010</comments><journal-ref>In Portugali, Y., H. Meyer, E. Stolk &amp; E. Tan (Eds.) Complexity
  Theories of Cities Have Come of Age: An Overview with Implications to Urban
  Planning and Design, Springer, Berlin Heidelberg, pp. 269-279. 2012. ISBN
  978-3-642-24543-5</journal-ref><doi>10.1007/978-3-642-24544-2_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urban transportation is a complex phenomenon. Since many agents are
constantly interacting in parallel, it is difficult to predict the future state
of a transportation system. Because of this, optimization techniques tend to
give obsolete solutions, as the problem changes before it can be optimized. An
alternative lies in seeking adaptive solutions. This adaptation can be achieved
with self-organization. In a self-organizing transportation system, the
elements of the system follow local rules to achieve a global solution. Like
this, when the problem changes the system can adapt by itself to the new
configuration.
  In this chapter, I will review recent, current, and future work on
self-organizing transportation systems. Self-organizing traffic lights have
proven to improve traffic flow considerably over traditional methods. In public
transportation systems, simple rules are being explored to prevent the &quot;equal
headway instability&quot; phenomenon. The methods we have used can be also applied
to other urban transportation systems and their generality is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1623</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1623</id><created>2009-12-08</created><authors><author><keyname>Kolla</keyname><forenames>Alexandra</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author><author><keyname>Teng</keyname><forenames>Shanghua</forenames></author></authors><title>Subgraph Sparsification and Nearly Optimal Ultrasparsifiers</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variation of the spectral sparsification problem where we are
required to keep a subgraph of the original graph. Formally, given a union of
two weighted graphs $G$ and $W$ and an integer $k$, we are asked to find a
$k$-edge weighted graph $W_k$ such that $G+W_k$ is a good spectral sparsifer of
$G+W$. We will refer to this problem as the subgraph (spectral) sparsification.
We present a nontrivial condition on $G$ and $W$ such that a good sparsifier
exists and give a polynomial time algorithm to find the sparsifer.
  %$O(\frac{n}{k})\log n \tilde{O}(\log \log n)$ As a significant application
of our technique, we show that for each positive integer $k$, every $n$-vertex
weighted graph has an $(n-1+k)$-edge spectral sparsifier with relative
condition number at most $\frac{n}{k} \log n \tilde{O}(\log\log n)$ where
$\tilde{O}()$ hides lower order terms. Our bound is within a factor of
$\tilde{O}(\log \log n)$ from optimal. This nearly settles a question left open
by Spielman and Teng about ultrasparsifiers, which is a key component in their
nearly linear-time algorithms for solving diagonally dominant symmetric linear
systems.
  We also present another application of our technique to spectral optimization
in which the goal is to maximize the algebraic connectivity of a graph (e.g.
turn it into an expander) with a limited number of edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1628</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1628</id><created>2009-12-08</created><updated>2010-03-23</updated><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>KF-CS: Compressive Sensing on Kalman Filtered Residual</title><categories>cs.IT math.IT stat.ME</categories><comments>7 pages, 2 figures, submitted to the IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recursively reconstructing time sequences of
sparse signals (with unknown and time-varying sparsity patterns) from a limited
number of linear incoherent measurements with additive noise. The idea of our
proposed solution, KF CS-residual (KF-CS) is to replace compressed sensing (CS)
on the observation by CS on the Kalman filtered (KF) observation residual
computed using the previous estimate of the support. KF-CS error stability over
time is studied. Simulation comparisons with CS and LS-CS are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1649</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1649</id><created>2009-12-08</created><authors><author><keyname>Hou</keyname><forenames>Xiaorong</forenames></author><author><keyname>Shao</keyname><forenames>Junwei</forenames></author></authors><title>Completeness of the WDS method in Checking Positivity of Integral Forms</title><categories>cs.SC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Examples show that integral forms can be efficiently proved positive
semidefinite by the WDS method, but it was unknown that how many steps of
substitutions are needed, or furthermore, which integral forms is this method
applicable for. In this paper, we give upper bounds of step numbers of WDS
required in proving that an integral form is positive definite, positive
semidefinite, or not positive semidefinite, thus deducing that the WDS method
is complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1655</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1655</id><created>2009-12-08</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Maximum-likelihood co-channel interference cancellation with power
  control for cellular OFDM networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 9 figures, International Symposium on Communications and
  Information Technologies 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cellular Orthogonal Frequency Division Multiplexing (OFDM) networks,
Co-Channel Interference (CCI) leads to severe degradation in the BER
performance. To solve this problem, Maximum-Likelihood Estimation (MLE) CCI
cancellation scheme has been proposed in the literature. MLE CCI cancellation
scheme generates weighted replicas of the transmitted signals and selects
replica with the smallest Euclidean distance from the received signal. When the
received power of the desired and interference signals are nearly the same, the
BER performance is degraded. In this paper, we propose an improved MLE CCI
canceler with closed-loop Power Control (PC) scheme capable of detecting and
combating against the equal received power situation at the Mobile Station (MS)
receiver by using the newly introduced parameter Power Ratio (PR). At cell edge
where Signal to Interferer Ratio (SIR) is considered to have average value
between -5 and 10 dB, computer simulations show that the proposed closed-loop
PC scheme has a gain of 7 dB at 28 km/h and about 2 dB at 120 km/h.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1658</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1658</id><created>2009-12-08</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>On the achievable improvement by the linear minimum mean square error
  detector</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, 1 table, International Symposium on
  Communications and Information Technologies 2009</comments><journal-ref>International Symposium on Communications and Information
  Technologies 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear minimum mean square error (MMSE) detector has been shown to alleviate
the noise amplification problem, resulting in the conventional zero-forcing
(ZF) detector. In this paper, we analyze the performance improvement by the
MMSE detector in terms of the condition number of its filtering matrix, and in
terms of the post-precessing signal to noise ratio (SNR) improvement. To this
end, we derive explicit formulas for the condition numbers of the filtering
matrices and the post-processing SNRs. Analytical and simulation results
demonstrate that the improvement achieved by the MMSE detector over the ZF
detector is not only dependent on the noise variance and the condition number
of the channel matrix, but also on how close the smallest singular values are
to the noise variance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1661</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1661</id><created>2009-12-08</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Hui</keyname><forenames>Bing</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author><author><keyname>Ji</keyname><forenames>Seunghwan</forenames></author><author><keyname>Joung</keyname><forenames>Jinsoup</forenames></author></authors><title>Fixed-complexity vector perturbation with Block diagonalization for
  MU-MIMO systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 6 figures, Malaysia International Conference on
  Communications 2009</comments><journal-ref>Malaysia International Conference on Communications 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block diagonalization (BD) is an attractive technique that transforms the
multi-user multiple-input multiple-output (MU-MIMO) channel into parallel
single-user MIMO (SU-MIMO) channels with zero inter-user interference (IUI). In
this paper, we combine the BD technique with two deterministic vector
perturbation (VP) algorithms that reduce the transmit power in MU-MIMO systems
with linear precoding. These techniques are the fixed-complexity sphere encoder
(FSE) and the QR-decomposition with M-algorithm encoder (QRDM-E). In contrast
to the conventional BD VP technique, which is based on the sphere encoder (SE),
the proposed techniques have fixed complexity and a tradeoff between
performance and complexity can be achieved by controlling the size of the set
of candidates for the perturbation vector. Simulation results and analysis
demonstrate the properness of the proposed techniques for the next generation
mobile communications systems which are latency and computational complexity
limited. In MU-MIMO system with 4 users each equipped with 2 receive antennas,
simulation results show that the proposed BD-FSE and BD-QRDM-E outperforms the
conventional BD-THP (Tomlinson Harashima precoding) by 5.5 and 7.4dB,
respectively, at a target BER of 10^{-4}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1664</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1664</id><created>2009-12-08</created><authors><author><keyname>Hager</keyname><forenames>William</forenames></author><author><keyname>Phan</keyname><forenames>Dzung</forenames></author><author><keyname>Zhang</keyname><forenames>Hongchao</forenames></author></authors><title>An exact algorithm for graph partitioning</title><categories>math.OC cs.DS</categories><comments>20 pages, submitted to Mathematical Programming</comments><msc-class>90C35, 90C20, 90C27, 90C46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An exact algorithm is presented for solving edge weighted graph partitioning
problems. The algorithm is based on a branch and bound method applied to a
continuous quadratic programming formulation of the problem. Lower bounds are
obtained by decomposing the objective function into convex and concave parts
and replacing the concave part by an affine underestimate. It is shown that the
best affine underestimate can be expressed in terms of the center and the
radius of the smallest sphere containing the feasible set. The concave term is
obtained either by a constant diagonal shift associated with the smallest
eigenvalue of the objective function Hessian, or by a diagonal shift obtained
by solving a semidefinite programming problem. Numerical results show that the
proposed algorithm is competitive with state-of-the-art graph partitioning
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1746</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1746</id><created>2009-12-09</created><updated>2011-12-15</updated><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author><author><keyname>Matthieu</keyname><forenames>Perrinel</forenames><affiliation>LIP</affiliation></author></authors><title>On the Rationality of Escalation</title><categories>cs.GT</categories><comments>19 p. This paper is a duplicate of arXiv:1004.5257</comments><proxy>ccsd ensl-00439911</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Escalation is a typical feature of infinite games. Therefore tools conceived
for studying infinite mathematical structures, namely those deriving from
coinduction are essential. Here we use coinduction, or backward coinduction (to
show its connection with the same concept for finite games) to study carefully
and formally the infinite games especially those called dollar auctions, which
are considered as the paradigm of escalation. Unlike what is commonly admitted,
we show that, provided one assumes that the other agent will always stop,
bidding is rational, because it results in a subgame perfect equilibrium. We
show that this is not the only rational strategy profile (the only subgame
perfect equilibrium). Indeed if an agent stops and will stop at every step, we
claim that he is rational as well, if one admits that his opponent will never
stop, because this corresponds to a subgame perfect equilibrium. Amazingly, in
the infinite dollar auction game, the behavior in which both agents stop at
each step is not a Nash equilibrium, hence is not a subgame perfect
equilibrium, hence is not rational.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1767</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1767</id><created>2009-12-09</created><authors><author><keyname>Piker</keyname><forenames>Samuel</forenames></author></authors><title>An evaluation of Flickrs distributed classification system, from the
  perspective of its members, and as an image retrieval tool in comparison with
  a controlled vocabulary</title><categories>cs.DL cs.IT math.IT</categories><comments>Dissertation, 40 pages including appendices</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The profusion of online digital images presents new challenges for image
indexing. Images have always been problematic to describe and catalogue due to
lack of inherent textual data and ambiguity of meaning. An alternative to
time-consuming professionally-applied metadata has been sought in the form of
tags, simple keywords that form a flat structure known as distributed
classification, or more popularly as a folksonomy.
  This research aims to increase understanding of why people tag and how
effective they find it for searching, using as the focus. Open-ended
questionnaires were sent out to members of the photo-sharing website Flickr,
with the opportunity to post comments to an online discussion space. There is
also a systematic comparison between a tag-based system and a more traditional
controlled vocabulary, to test out the claims made regarding the suitability of
tagging for searching and browsing. For this purpose Flickr has been compared
with Getty Images using a series of test themes.
  The small number of people who replied to the questionnaire gave detailed
answers that confirmed several assertions made about tags: they are accepted
despite their flaws (sloppiness and potential for inaccuracy) because they
serve their purpose to a satisfactory level. Some answers challenged the
assumption that tagging is only done for personal benefit. The search
comparison found that while Getty allows highly specific queries and logical
semantic links, Flickr is more flexible and better placed to deal with subtle
concepts. The overall conclusion is that tags achieve most when used in
conjunction with groupings of people with a shared interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1768</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1768</id><created>2009-12-09</created><authors><author><keyname>Chong</keyname><forenames>Andrew</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Sankar</keyname><forenames>Lalitha</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Princeton University</affiliation></author></authors><title>Frequency of Occurrence and Information Entropy of American Sign
  Language</title><categories>cs.IT math.IT</categories><comments>8 pages, draft version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  American Sign Language (ASL) uses a series of hand based gestures as a
replacement for words to allow the deaf to communicate. Previous work has shown
that although it takes longer to make signs than to say the equivalent words,
on average sentences can be completed in about the same time. This leaves
unresolved, however, precisely why that should be the case. This paper reports
a determination of the empirical entropy and redundancy in the set of
handshapes of ASL. In this context, the entropy refers to the average
information content in a unit of data. It is found that the handshapes, as
fundamental units of ASL, are less redundant than phonemes, the equivalent
fundamental units of spoken English, and that their entropy is much closer to
the maximum possible information content. This explains why the slower signs
can produce sentences in the same time as speaking; the low redundancy
compensates for the slow rate of sign production. In addition to this precise
quantification, this work is also novel in its approach towards quantifying an
aspect of the ASL alphabet. Unlike spoken and written languages, frequency
analysis of ASL is difficult due to the fact that every sign is composed of
phonemes that are created through a combination of manual and a relatively
large and imprecise set of bodily features. Focusing on handshapes as the
ubiquitous and universal feature of all sign languages permits a precise
quantitative analysis. As interest in visual electronic communication explodes
within the deaf community, this work also paves the way for more precise
automated sign recognition and synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1776</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1776</id><created>2009-12-09</created><authors><author><keyname>Kumar</keyname><forenames>Amit</forenames></author><author><keyname>Manokaran</keyname><forenames>Rajsekar</forenames></author><author><keyname>Tulsiani</keyname><forenames>Madhur</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>On the Optimality of a Class of LP-based Algorithms</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will be concerned with a class of packing and covering
problems which includes Vertex Cover and Independent Set. Typically, one can
write an LP relaxation and then round the solution. In this paper, we explain
why the simple LP-based rounding algorithm for the \\VC problem is optimal
assuming the UGC. Complementing Raghavendra's result, our result generalizes to
a class of strict, covering/packing type CSPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1777</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1777</id><created>2009-12-09</created><updated>2010-09-16</updated><authors><author><keyname>Chacc</keyname><forenames>Eric Goles</forenames><affiliation>LAMA</affiliation></author><author><keyname>Meunier</keyname><forenames>Pierre-Etienne</forenames><affiliation>LAMA</affiliation></author><author><keyname>Rapaport</keyname><forenames>Ivan</forenames><affiliation>DIM</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Communication Complexity and Intrinsic Universality in Cellular Automata</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notions of universality and completeness are central in the theories of
computation and computational complexity. However, proving lower bounds and
necessary conditions remains hard in most of the cases. In this article, we
introduce necessary conditions for a cellular automaton to be &quot;universal&quot;,
according to a precise notion of simulation, related both to the dynamics of
cellular automata and to their computational power. This notion of simulation
relies on simple operations of space-time rescaling and it is intrinsic to the
model of cellular automata. Intrinsinc universality, the derived notion, is
stronger than Turing universality, but more uniform, and easier to define and
study. Our approach builds upon the notion of communication complexity, which
was primarily designed to study parallel programs, and thus is, as we show in
this article, particulary well suited to the study of cellular automata: it
allowed to show, by studying natural problems on the dynamics of cellular
automata, that several classes of cellular automata, as well as many natural
(elementary) examples, could not be intrinsically universal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1790</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1790</id><created>2009-12-09</created><authors><author><keyname>Bulygin</keyname><forenames>Stanislav</forenames></author><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>A Note on the Injection Distance</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Koetter and Kschischang showed in [R. Koetter and F.R. Kschischang, &quot;Coding
for Errors and Erasures in Random Network Coding,&quot; IEEE Trans. Inform. Theory,
{54(8), 2008] that the network coding counterpart of Gabidulin codes performs
asymptotically optimal with respect to the subspace distance. Recently, Silva
and Kschischang introduced in [D. Silva and F.R. Kschischang, &quot;On Metrics for
Error Correction in Network Coding,&quot; To appear in IEEE Trans. Inform. Theory,
ArXiv: 0805.3824v4[cs.IT], 2009] the injection distance to give a detailed
picture of what happens in noncoherent network coding. We show that the above
codes are also asymptotically optimal with respect to this distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1803</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1803</id><created>2009-12-09</created><authors><author><keyname>Holzner</keyname><forenames>Andr&#xe9; G.</forenames></author><author><keyname>Gokieli</keyname><forenames>Ryszard</forenames></author><author><keyname>Igo-Kemenes</keyname><forenames>Peter</forenames></author><author><keyname>Maggi</keyname><forenames>Marcello</forenames></author><author><keyname>Malgeri</keyname><forenames>Luca</forenames></author><author><keyname>Mele</keyname><forenames>Salvatore</forenames></author><author><keyname>Pape</keyname><forenames>Luc</forenames></author><author><keyname>Plane</keyname><forenames>David</forenames></author><author><keyname>Schr&#xf6;der</keyname><forenames>Matthias</forenames></author><author><keyname>Schwickerath</keyname><forenames>Ulrich</forenames></author><author><keyname>Tenchini</keyname><forenames>Roberto</forenames></author><author><keyname>Timmermans</keyname><forenames>Jan</forenames></author></authors><title>Data Preservation at LEP</title><categories>hep-ex cs.DL physics.data-an</categories><comments>7 pages, contribution to proceedings of the &quot;First Workshop on Data
  Preservation and Long Term Analysis in HEP&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The four LEP experiments ALEPH, DELPHI, L3 and OPAL successfully recorded
e+e- collision data during the years 1989 to 2000. As part of the ordinary
evolution in High Energy Physics, these experiments can not be repeated and
their data is therefore unique. This article briefly reviews the data
preservation efforts undertaken by the four experiments beyond the end of data
taking. The current status of the preserved data and associated tools is
summarised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1805</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1805</id><created>2009-12-09</created><authors><author><keyname>Outtagarts</keyname><forenames>Abdelkader</forenames></author><author><keyname>Martinot</keyname><forenames>Olivier</forenames></author></authors><title>iSSEE: IMS Sensors Search Engine Enabler for Sensors Mashups Convergent
  Application</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp1-7, November 2009</comments><journal-ref>A. Outtagarts and O. Martinot, &quot;iSSEE: IMS Sensors Search Engine
  Enabler for Sensors Mashups Convergent Application&quot;, International Journal of
  Computer Science Issues, IJCSI, Volume 6, pp1-7, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrating the sensing capabilities in Internet Protocol network will open
the opportunities to build a wide range of novel multimedia applications. The
problem when using sensors (e.g. temperature sensor, camera, audio, humidity,
etc.) connected to the network is to know dynamically at any time if they are
always connected or not, what type of data they can transmit and where they are
geographically located. This paper describes an application enabler: IMS Sensor
Search Engine Enabler (iSSEE), which allows IMS applications using sensors and
IMS based devices, to get information about the sensor availability, its
location and the type of the sensor. Using data collected by sensors and from
the web, mash-ups convergent applications use cases are proposed by combining
the contents from heterogeneous data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1810</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1810</id><created>2009-12-09</created><authors><author><keyname>Jungum</keyname><forenames>Nevin Vunka</forenames></author><author><keyname>Laurent</keyname><forenames>Eric</forenames></author></authors><title>Emotions in Pervasive Computing Environments</title><categories>cs.HC</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp8-22, November 2009</comments><journal-ref>N. Vunka Jungum and E. LAURENT, &quot;Emotions in Pervasive Computing
  Environments&quot;, International Journal of Computer Science Issues, IJCSI,
  Volume 6, pp8-22, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability of an intelligent environment to connect and adapt to real
internal sates, needs and behaviors' meaning of humans can be made possible by
considering users' emotional states as contextual parameters. In this paper, we
build on enactive psychology and investigate the incorporation of emotions in
pervasive systems. We define emotions, and discuss the coding of emotional
human markers by smart environments. In addition, we compare some existing
works and identify how emotions can be detected and modeled by a pervasive
system in order to enhance its service and response to users. Finally, we
analyze closely one XML-based language for representing and annotating emotions
known as EARL and raise two important issues which pertain to emotion
representation and modeling in XML-based languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1815</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1815</id><created>2009-12-09</created><authors><author><keyname>Rastegari</keyname><forenames>Samaneh</forenames></author><author><keyname>Saripan</keyname><forenames>M. Iqbal</forenames></author><author><keyname>Rasid</keyname><forenames>Mohd Fadlee A.</forenames></author></authors><title>Detection of Denial of Service Attacks against Domain Name System Using
  Neural Networks</title><categories>cs.CR cs.NE</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp23-27, November 2009</comments><journal-ref>S. Rastegari, M. I. Saripan and M. F. A. Rasid, &quot;Detection of
  Denial of Service Attacks against Domain Name System Using Neural Networks&quot;,
  IJCSI, Volume 6, Issue 1, pp23-27, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce an intrusion detection system for Denial of
Service (DoS) attacks against Domain Name System (DNS). Our system architecture
consists of two most important parts: a statistical preprocessor and a neural
network classifier. The preprocessor extracts required statistical features in
a shorttime frame from traffic received by the target name server. We compared
three different neural networks for detecting and classifying different types
of DoS attacks. The proposed system is evaluated in a simulated network and
showed that the best performed neural network is a feed-forward backpropagation
with an accuracy of 99%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1820</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1820</id><created>2009-12-09</created><authors><author><keyname>Rahman</keyname><forenames>Mirzanur</forenames></author><author><keyname>Das</keyname><forenames>Sufal</forenames></author><author><keyname>Sharma</keyname><forenames>Utpal</forenames></author></authors><title>Parsing of part-of-speech tagged Assamese Texts</title><categories>cs.CL</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp28-34, November 2009</comments><journal-ref>M. Rahman, S. Das and U. Sharma, &quot;Parsing of part-of-speech tagged
  Assamese Texts&quot;, International Journal of Computer Science Issues, IJCSI,
  Volume 6, Issue 1, pp28-34, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural language (or ordinary language) is a language that is spoken,
written, or signed by humans for general-purpose communication, as
distinguished from formal languages (such as computer-programming languages or
the &quot;languages&quot; used in the study of formal logic). The computational
activities required for enabling a computer to carry out information processing
using natural language is called natural language processing. We have taken
Assamese language to check the grammars of the input sentence. Our aim is to
produce a technique to check the grammatical structures of the sentences in
Assamese text. We have made grammar rules by analyzing the structures of
Assamese sentences. Our parsing program finds the grammatical errors, if any,
in the Assamese sentence. If there is no error, the program will generate the
parse tree for the Assamese sentence
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1822</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1822</id><created>2009-12-09</created><authors><author><keyname>Kannan</keyname><forenames>S.</forenames></author><author><keyname>Bhaskaran</keyname><forenames>R.</forenames></author></authors><title>Association Rule Pruning based on Interestingness Measures with
  Clustering</title><categories>cs.LG</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp35-43, November 2009</comments><journal-ref>S.Kannan and R.Bhaskaran, &quot;Association Rule Pruning based on
  Interestingness Measures with Clustering&quot;, International Journal of Computer
  Science Issues, IJCSI, Volume 6, Issue 1, pp35-43, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Association rule mining plays vital part in knowledge mining. The difficult
task is discovering knowledge or useful rules from the large number of rules
generated for reduced support. For pruning or grouping rules, several
techniques are used such as rule structure cover methods, informative cover
methods, rule clustering, etc. Another way of selecting association rules is
based on interestingness measures such as support, confidence, correlation, and
so on. In this paper, we study how rule clusters of the pattern Xi - Y are
distributed over different interestingness measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1826</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1826</id><created>2009-12-09</created><authors><author><keyname>Hussein</keyname><forenames>Jamal</forenames></author><author><keyname>Mohammed</keyname><forenames>Aree</forenames></author></authors><title>Robust Video Watermarking using Multi-Band Wavelet Transform</title><categories>cs.IT math.IT</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp44-49, November 2009</comments><journal-ref>J. HUSSEIN and A. MOHAMMED, &quot;Robust Video Watermarking using
  Multi-Band Wavelet Transform&quot;, International Journal of Computer Science
  Issues, IJCSI, Volume 6, Issue 1, pp44-49, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses copyright protection as a major security demand in
digital marketplaces. Two watermarking techniques are proposed and compared for
compressed and uncompressed video with the intention to show the advantages and
the possible weaknesses in the schemes working in the frequency domain and in
the spatial domain. In this paper a robust video watermarking method is
presented. This method embeds data to the specific bands in the wavelet domain
using motion estimation approach. The algorithm uses the HL and LH bands to add
the watermark where the motion in these bands does not affect the quality of
extracted watermark if the video is subjected to different types of malicious
attacks. Watermark is embedded in an additive way using random Gaussian
distribution in video sequences. The method is tested on different types of
video (compressed DVD quality movie and uncompressed digital camera movie). The
proposed watermarking method in frequency domain has strong robustness against
some attacks such as frame dropping, frame filtering and lossy compression. The
experimental results indicate that the similarity measure before and after
certain attacks is very close to each other in frequency domain in comparison
to the spatial domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1828</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1828</id><created>2009-12-09</created><authors><author><keyname>Nguyen</keyname><forenames>Vu Thanh</forenames></author></authors><title>Using social annotation and web log to enhance search engine</title><categories>cs.IR cs.CY</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp1-6, November 2009</comments><journal-ref>V. T. NGUYEN, &quot;Using social annotation and web log to enhance
  search engine&quot;, International Journal of Computer Science Issues, IJCSI,
  Volume 6, Issue 2, pp1-6, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search services have been developed rapidly in social Internet. It can help
web users easily to find their documents. So that, finding a best method search
is always an imagine. This paper would like introduce hybrid method of
LPageRank algorithm and Social Sim Rank algorithm. LPageRank is the method
using link structure to rank priority of page. It doesn't care content of page
and content of query. Therefore, we want to use benefit of social annotations
to create the latent semantic association between queries and annotations. This
model, we use algorithm SocialPageRank and LPageRank to enhance accuracy of
search system. To experiment and evaluate the proposed of the new model, we
have used this model for Music Machine Website with their web logs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1829</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1829</id><created>2009-12-09</created><authors><author><keyname>Nguyen</keyname><forenames>Dang Tuan</forenames></author><author><keyname>Luong</keyname><forenames>Ha Quy-Tinh</forenames></author></authors><title>Document Searching System based on Natural Language Query Processing for
  Vietnam Open Courseware Library</title><categories>cs.IR cs.CL</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp7-13, November 2009</comments><journal-ref>D. T. NGUYEN and H. Q. LUONG, &quot;Document Searching System based on
  Natural Language Query Processing for Vietnam Open Courseware Library&quot;,
  IJCSI, Volume 6, Issue 2, pp7-13, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The necessary of buiding the searching system being able to support users
expressing their searching by natural language queries is very important and
opens the researching direction with many potential. It combines the
traditional methods of information retrieval and the researching of Question
Answering (QA). In this paper, we introduce a searching system built by us for
searching courses on the Vietnam OpenCourseWare Program (VOCW). It can be
considered as the first tool to be able to perform the user's Vietnamese
questions. The experiment results are rather good when we evaluate this system
on the precision
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1830</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1830</id><created>2009-12-09</created><authors><author><keyname>Tanaka</keyname><forenames>Kazumoto</forenames></author></authors><title>Gesture Recognition with a Focus on Important Actions by Using a Path
  Searching Method in Weighted Graph</title><categories>cs.CV cs.LG</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp14-19, November 2009</comments><journal-ref>K. TANAKA, &quot;Gesture Recognition with a Focus on Important Actions
  by Using a Path Searching Method in Weighted Graph&quot;, International Journal of
  Computer Science Issues, IJCSI, Volume 6, Issue 2, pp14-19, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method of gesture recognition with a focus on important
actions for distinguishing similar gestures. The method generates a partial
action sequence by using optical flow images, expresses the sequence in the
eigenspace, and checks the feature vector sequence by applying an optimum
path-searching method of weighted graph to focus the important actions. Also
presented are the results of an experiment on the recognition of similar sign
language words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1832</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1832</id><created>2009-12-09</created><authors><author><keyname>Ojha</keyname><forenames>Dr. A. K.</forenames></author><author><keyname>Biswal</keyname><forenames>K. K.</forenames></author></authors><title>Lexicographic Multi-objective Geometric Programming Problems</title><categories>cs.DS cs.CG</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp20-24, November 2009</comments><journal-ref>Dr.A. K. Ojha and K. K. Biswal, &quot;Lexicographic Multi-objective
  Geometric Programming Problems&quot;, International Journal of Computer Science
  Issues, IJCSI, Volume 6, Issue 2, pp20-24, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Geometric programming (GP) is a type of mathematical problem characterized
by objective and constraint functions that have a special form. Many methods
have been developed to solve large scale engineering design GP problems. In
this paper GP technique has been used to solve multi-objective GP problem as a
vector optimization problem. The duality theory for lexicographic geometric
programming has been developed to solve the problems with posynomial in
objectives and constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1835</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1835</id><created>2009-12-09</created><authors><author><keyname>Lwin</keyname><forenames>T. T.</forenames></author><author><keyname>Thein</keyname><forenames>T.</forenames></author></authors><title>High Availability Cluster System for Local Disaster Recovery with Markov
  Modeling Approach</title><categories>cs.DC</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp25-32, November 2009</comments><journal-ref>T.T.Lwin and T.Thein, &quot;High Availability Cluster System for Local
  Disaster Recovery with Markov Modeling Approach&quot;, International Journal of
  Computer Science Issues, IJCSI, Volume 6, Issue 2, pp25-32, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for high availability (HA) and disaster recovery (DR) in IT
environment is more stringent than most of the other sectors of enterprises.
Many businesses require the availability of business-critical applications 24
hours a day, seven days a week, and can afford no data loss in the event of a
disaster. It is vital that the IT infrastructure is resilient with regard to
disruption, even site failures, and that business operations can continue
without significant impact. As a result, DR has gained great importance in IT.
Clustering of multiple industries standard servers together to allow workload
sharing and fail-over capabilities is a low cost approach. In this paper, we
present the availability model through Semi-Markov Process (SMP) and also
analyze the difference in downtime of the SMP model and the approximate
Continuous Time Markov Chain (CTMC) model. To acquire system availability, we
perform numerical analysis and SHARPE tool evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1838</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1838</id><created>2009-12-09</created><authors><author><keyname>Wan</keyname><forenames>Kaiyu</forenames></author></authors><title>A Brief History of Context</title><categories>cs.HC</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp33-43, November 2009</comments><journal-ref>K. Wan, &quot;A Brief History of Context&quot;, International Journal of
  Computer Science Issues, IJCSI, Volume 6, Issue 2, pp33-43, November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context is a rich concept and is an elusive concept to define. The concept of
context has been studied by philosophers, linguists, psychologists, and
recently by computer scientists. Within each research community the term
context was interpreted in a certain way that is well-suited for their goals,
however no attempt was made to define context. In many areas of research in
computer science, notably on web-based services, human-computer interaction
(HCI), ubiquitous computing applications, and context-aware systems there is a
need to provide a formal operational definition of context. In this brief
survey an account of the early work on context, as well as the recent work on
many working definitions of context, context modeling, and a formalization of
context are given. An attempt is made to unify the different context models
within the formalization. A brief commentary on the usefulness of the
formalization in the development of context-aware and dependable systems is
included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1839</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1839</id><created>2009-12-09</created><authors><author><keyname>Sharma</keyname><forenames>D.</forenames></author><author><keyname>Singh</keyname><forenames>V.</forenames></author></authors><title>ICT in Universities of the Western Himalayan Region in India: Status,
  Performance- An Assessment</title><categories>cs.CY</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp44-52, November 2009</comments><doi>10.5120/1111-1455</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper describes a live project study carried out for the
universities located in the western Himalayan region of India in the year 2009.
The objective of this study is to undertake the task of assessment regarding
initiative, utilization of ICT resources, its performance and impact in these
higher educational institutions/universities. In order to answer these,
initially basic four- tier framework was prepared. Followed by a questionnaire
containing different ICT components 18 different groups like vision, planning,
implementation, ICT infrastructure and related activities exhibiting
performance. Primary data in the form of feedback on the five point scale, of
the questionnaire, was gathered from six universities of the region. A simple
statistical analysis was undertaken using weighted mean, to assess the ICT
initiative, status and performance of various universities. In the process, a
question related to Performance Indicator was identified from each group, whose
Coefficient of Correlation was calculated. This study suggests that a
progressive vision, planning and initiative regarding academic syllabi, ICT
infrastructure, used in training the skilled human resource, is going to have a
favourable impact through actual placement, research and play a dominant role
at the National and International level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1855</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1855</id><created>2009-12-10</created><authors><author><keyname>Stanek</keyname><forenames>K. Z.</forenames><affiliation>The Ohio State University</affiliation></author></authors><title>Are astronomical papers with more authors cited more?</title><categories>physics.soc-ph astro-ph.IM cs.DL</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following my previous study of paper length vs. number of citations in
astronomy (Stanek 2008), some colleagues expressed an interest in knowing if
any correlation exists between citations and the number of authors on an
astronomical paper. At least naively, one would expect papers with more authors
to be cited more. I test this expectation with the same sample of papers as
analyzed in Stanek (2008), selecting all (~30,000) refereed papers from A&amp;A,
AJ, ApJ and MNRAS published between 2000 and 2004. (...) I find that indeed
papers with more authors are on average cited more, but only weakly so:
roughly, the number of citations doubles with ten-fold increase in the number
of authors. While the median number of citations to a 2 author paper is 17, the
median number of citations to a paper with 10 to 20 authors is 32. I find that
most of the papers are written by a small number of authors, with a mode of 2
authors and a median of 3 authors. I also find that papers with more authors
are not longer than papers with fewer authors, in fact a median number of 8 to
10 pages per paper holds for any number of authors. For the same sample of
papers, a median number of citations per paper grew from 15 in June 2008
(Stanek 2008) to 19 in November 2009. Unlike Stanek (2008), I do not conclude
with any career advice, semi-humorous or otherwise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1883</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1883</id><created>2009-12-09</created><updated>2012-03-08</updated><authors><author><keyname>Nutz</keyname><forenames>Marcel</forenames></author></authors><title>The Bellman equation for power utility maximization with semimartingales</title><categories>q-fin.PM cs.SY math.OC math.PR q-fin.CP</categories><comments>Published in at http://dx.doi.org/10.1214/11-AAP776 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP776</report-no><journal-ref>Annals of Applied Probability 2012, Vol. 22, No. 1, 363-406</journal-ref><doi>10.1214/11-AAP776</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study utility maximization for power utility random fields with and
without intermediate consumption in a general semimartingale model with closed
portfolio constraints. We show that any optimal strategy leads to a solution of
the corresponding Bellman equation. The optimal strategies are described
pointwise in terms of the opportunity process, which is characterized as the
minimal solution of the Bellman equation. We also give verification theorems
for this equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1897</identifier>
 <datestamp>2009-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1897</id><created>2009-12-10</created><authors><author><keyname>AlAttili</keyname><forenames>Israa</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Houben</keyname><forenames>Fred</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Igna</keyname><forenames>Georgeta</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Michels</keyname><forenames>Steffen</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Zhu</keyname><forenames>Feng</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Vaandrager</keyname><forenames>Frits</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>Adaptive Scheduling of Data Paths using Uppaal Tiga</title><categories>cs.FL cs.LO cs.PF</categories><journal-ref>EPTCS 13, 2009, pp. 1-11</journal-ref><doi>10.4204/EPTCS.13.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply Uppaal Tiga to automatically compute adaptive scheduling strategies
for an industrial case study dealing with a state-of-the-art image processing
pipeline of a printer. As far as we know, this is the first application of
timed automata technology to an industrial scheduling problem with uncertainty
in job arrivals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1899</identifier>
 <datestamp>2009-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1899</id><created>2009-12-09</created><authors><author><keyname>Bernardo</keyname><forenames>Marco</forenames></author></authors><title>Markovian Testing Equivalence and Exponentially Timed Internal Actions</title><categories>cs.LO cs.PF</categories><journal-ref>EPTCS 13, 2009, pp. 13-25</journal-ref><doi>10.4204/EPTCS.13.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the theory of testing for Markovian processes developed so far,
exponentially timed internal actions are not admitted within processes. When
present, these actions cannot be abstracted away, because their execution takes
a nonzero amount of time and hence can be observed. On the other hand, they
must be carefully taken into account, in order not to equate processes that are
distinguishable from a timing viewpoint. In this paper, we recast the
definition of Markovian testing equivalence in the framework of a Markovian
process calculus including exponentially timed internal actions. Then, we show
that the resulting behavioral equivalence is a congruence, has a sound and
complete axiomatization, has a modal logic characterization, and can be decided
in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1900</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1900</id><created>2009-12-09</created><authors><author><keyname>Ndukwu</keyname><forenames>Ukachukwu</forenames><affiliation>Department of Computing, Macquarie University, NSW 2109, Sydney, Australia.</affiliation></author></authors><title>Quantitative Safety: Linking Proof-Based Verification with Model
  Checking for Probabilistic Systems</title><categories>cs.LO</categories><journal-ref>EPTCS 13, 2009, pp. 27-39</journal-ref><doi>10.4204/EPTCS.13.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach for augmenting proof-based verification
with performance-style analysis of the kind employed in state-of-the-art model
checking tools for probabilistic systems. Quantitative safety properties
usually specified as probabilistic system invariants and modeled in proof-based
environments are evaluated using bounded model checking techniques.
  Our specific contributions include the statement of a theorem that is central
to model checking safety properties of proof-based systems, the establishment
of a procedure; and its full implementation in a prototype system (YAGA) which
readily transforms a probabilistic model specified in a proof-based environment
to its equivalent verifiable PRISM model equipped with reward structures. The
reward structures capture the exact interpretation of the probabilistic
invariants and can reveal succinct information about the model during
experimental investigations. Finally, we demonstrate the novelty of the
technique on a probabilistic library case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1901</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1901</id><created>2009-12-10</created><authors><author><keyname>Schuts</keyname><forenames>Mathijs</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Zhu</keyname><forenames>Feng</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Heidarian</keyname><forenames>Faranak</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Vaandrager</keyname><forenames>Frits</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>Modelling Clock Synchronization in the Chess gMAC WSN Protocol</title><categories>cs.LO cs.DC cs.FL cs.NI</categories><journal-ref>EPTCS 13, 2009, pp. 41-54</journal-ref><doi>10.4204/EPTCS.13.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a detailled timed automata model of the clock synchronization
algorithm that is currently being used in a wireless sensor network (WSN) that
has been developed by the Dutch company Chess. Using the Uppaal model checker,
we establish that in certain cases a static, fully synchronized network may
eventually become unsynchronized if the current algorithm is used, even in a
setting with infinitesimal clock drifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1902</identifier>
 <datestamp>2009-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1902</id><created>2009-12-09</created><authors><author><keyname>Tr&#x10d;ka</keyname><forenames>Nikola</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Strong, Weak and Branching Bisimulation for Transition Systems and
  Markov Reward Chains: A Unifying Matrix Approach</title><categories>cs.LO cs.PF</categories><acm-class>D.3.1; D.2.1; D.2.4; F.3.1</acm-class><journal-ref>EPTCS 13, 2009, pp. 55-65</journal-ref><doi>10.4204/EPTCS.13.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first study labeled transition systems with explicit successful
termination. We establish the notions of strong, weak, and branching
bisimulation in terms of boolean matrix theory, introducing thus a novel and
powerful algebraic apparatus. Next we consider Markov reward chains which are
standardly presented in real matrix theory. By interpreting the obtained matrix
conditions for bisimulations in this setting, we automatically obtain the
definitions of strong, weak, and branching bisimulation for Markov reward
chains. The obtained strong and weak bisimulations are shown to coincide with
some existing notions, while the obtained branching bisimulation is new, but
its usefulness is questionable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1903</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1903</id><created>2009-12-09</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames><affiliation>Centre for Logic and Information, St. Francis Xavier University, Canada</affiliation></author><author><keyname>MacCaull</keyname><forenames>Wendy</forenames><affiliation>Centre for Logic and Information, St. Francis Xavier University, Canada</affiliation></author></authors><title>Verifying Real-Time Systems using Explicit-time Description Methods</title><categories>cs.LO cs.SE</categories><journal-ref>EPTCS 13, 2009, pp. 67-78</journal-ref><doi>10.4204/EPTCS.13.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timed model checking has been extensively researched in recent years. Many
new formalisms with time extensions and tools based on them have been
presented. On the other hand, Explicit-Time Description Methods aim to verify
real-time systems with general untimed model checkers. Lamport presented an
explicit-time description method using a clock-ticking process (Tick) to
simulate the passage of time together with a group of global variables for time
requirements. This paper proposes a new explicit-time description method with
no reliance on global variables. Instead, it uses rendezvous synchronization
steps between the Tick process and each system process to simulate time. This
new method achieves better modularity and facilitates usage of more complex
timing constraints. The two explicit-time description methods are implemented
in DIVINE, a well-known distributed-memory model checker. Preliminary
experiment results show that our new method, with better modularity, is
comparable to Lamport's method with respect to time and memory efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1905</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1905</id><created>2009-12-09</created><authors><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Zhao</keyname><forenames>Liang</forenames></author><author><keyname>Wu</keyname><forenames>Xiaomin</forenames></author><author><keyname>Liu</keyname><forenames>Anna</forenames></author></authors><title>Peer-to-Peer Cloud Provisioning: Service Discovery and Load-Balancing</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter presents: (i) a layered peer-to-peer Cloud provisioning
architecture; (ii) a summary of the current state-of-the-art in Cloud
provisioning with particular emphasis on service discovery and load-balancing;
(iii) a classification of the existing peer-to-peer network management model
with focus on extending the DHTs for indexing and managing complex provisioning
information; and (iv) the design and implementation of novel, extensible
software fabric (Cloud peer) that combines public/private clouds, overlay
networking and structured peer-to-peer indexing techniques for supporting
scalable and self-managing service discovery and load-balancing in Cloud
computing environments. Finally, an experimental evaluation is presented that
demonstrates the feasibility of building next generation Cloud provisioning
systems based on peer-to-peer network management and information dissemination
models. The experimental test-bed has been deployed on a public cloud computing
platform, Amazon EC2, which demonstrates the effectiveness of the proposed
peer-to-peer Cloud provisioning software fabric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1909</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1909</id><created>2009-12-09</created><authors><author><keyname>Mohammed</keyname><forenames>Saif Khan</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author><author><keyname>Hong</keyname><forenames>Yi</forenames></author><author><keyname>Chockalingam</keyname><forenames>Ananthanarayanan</forenames></author></authors><title>MIMO Precoding with X- and Y-Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a time division duplex (TDD) $n_t \times n_r$ multiple-input
multiple-output (MIMO) system with channel state information (CSI) at both the
transmitter and receiver. We propose X- and Y-Codes to achieve high
multiplexing and diversity gains at low complexity. The proposed precoding
schemes are based upon the singular value decomposition (SVD) of the channel
matrix which transforms the MIMO channel into parallel subchannels. Then X- and
Y-Codes are used to improve the diversity gain by pairing the subchannels,
prior to SVD precoding. In particular, the subchannels with good diversity are
paired with those having low diversity gains. Hence, a pair of channels is
jointly encoded using a $2 \times 2$ real matrix, which is fixed {\em a priori}
and does not change with each channel realization. For X-Codes these matrices
are 2-dimensional rotation matrices parameterized by a single angle, while for
Y-Codes, these matrices are 2-dimensional upper left triangular matrices. The
complexity of the maximum likelihood decoding (MLD) for both X- and Y-Codes is
low. Specifically, the decoding complexity of Y-Codes is the same as that of a
scalar channel. Moreover, we propose X-, Y-Precoders with the same structure as
X-, Y-Codes, but the encoding matrices adapt to each channel realization. The
optimal encoding matrices for X-, Y-Codes/Precoders are derived analytically.
Finally, it is observed that X-Codes/Precoders perform better for
well-conditioned channels, while Y-Codes/Precoders perform better for
ill-conditioned channels, when compared to other precoding schemes in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1918</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1918</id><created>2009-12-10</created><updated>2009-12-11</updated><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Security analysis of a binary image permutation scheme based on Logistic
  map</title><categories>cs.CR</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [\textit{Pattern Recognition Letters}, in press,
doi:10.1016/j.patrec.2009.11.008], an image scrambling encryption algorithm of
pixel bit based on chaos map was proposed. Considering the algorithm as a
typical binary image scrambling/permutation algorithm exerting on plaintext of
size $M\times (8N)$, this paper proposes a novel optimal method to break it
with some known/chosen-plaintexts. The spatial complexity and computational
complexity of the attack are only $O(32\cdot MN)$ and $O(16\cdot n_0\cdot MN)$
respectively, where $n_0$ is the number of known/chosen-plaintexts used. The
method can be easily extended to break any permutation-only encryption scheme
exerting on plaintext of size $M\times N$ and with $L$ different levels of
values. The corresponding spatial complexity and computational complexity are
only $O(MN)$ and $O(n_0\cdot MN)$ respectively. In addition, some specific
remarks on the performance of the image scrambling encryption algorithm are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1927</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1927</id><created>2009-12-10</created><authors><author><keyname>Biasse</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LIX, INRIA Bordeaux - Sud-Ouest</affiliation></author></authors><title>An L(1/3) algorithm for ideal class group and regulator computation in
  certain number fields</title><categories>cs.CR</categories><proxy>ccsd inria-00440223</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the complexity of the computation of the class group structure,
regulator, and a system of fundamental units of a certain class of number
fields. Our approach differs from Buchmann's, who proved a complexity bound of
L(1/2,O(1)) when the discriminant tends to infinity with fixed degree. We
achieve a subexponential complexity in O(L(1/3,O(1))) when both the
discriminant and the degree of the extension tend to infinity by using
techniques due to Enge and Gaudry in the context of algebraic curves over
finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1934</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1934</id><created>2009-12-10</created><updated>2012-12-20</updated><authors><author><keyname>D&#xfc;tting</keyname><forenames>Paul</forenames></author><author><keyname>Henzinger</keyname><forenames>Monika</forenames></author><author><keyname>Weber</keyname><forenames>Ingmar</forenames></author></authors><title>Sponsored Search, Market Equilibria, and the Hungarian Method</title><categories>cs.GT</categories><acm-class>F.2; J.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Matching markets play a prominent role in economic theory. A prime example of
such a market is the sponsored search market. Here, as in other markets of that
kind, market equilibria correspond to feasible, envy free, and bidder optimal
outcomes. For settings without budgets such an outcome always exists and can be
computed in polynomial-time by the so-called Hungarian Method. Moreover, every
mechanism that computes such an outcome is incentive compatible. We show that
the Hungarian Method can be modified so that it finds a feasible, envy free,
and bidder optimal outcome for settings with budgets. We also show that in
settings with budgets no mechanism that computes such an outcome can be
incentive compatible for all inputs. For inputs in general position, however,
the presented mechanism---as any other mechanism that computes such an outcome
for settings with budgets---is incentive compatible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1987</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1987</id><created>2009-12-10</created><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Training and Feedback Optimization for Multiuser MIMO Downlink</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a MIMO fading broadcast channel where the fading channel
coefficients are constant over time-frequency blocks that span a coherent time
$\times$ a coherence bandwidth. In closed-loop systems, channel state
information at transmitter (CSIT) is acquired by the downlink training sent by
the base station and an explicit feedback from each user terminal. In open-loop
systems, CSIT is obtained by exploiting uplink training and channel
reciprocity. We use a tight closed-form lower bound on the ergodic achievable
rate in the presence of CSIT errors in order to optimize the overall system
throughput, by taking explicitly into account the overhead due to channel
estimation and channel state feedback. Based on three time-frequency block
models inspired by actual systems, we provide some useful guidelines for the
overall system optimization. In particular, digital (quantized) feedback is
found to offer a substantial advantage over analog (unquantized) feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.1999</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.1999</id><created>2009-12-10</created><authors><author><keyname>Meng</keyname><forenames>Delong</forenames></author></authors><title>Nice Bounds for the Generalized Ballot Problem</title><categories>math.CO cs.GT</categories><msc-class>05C30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives two sharp bounds for the generalized ballot problem with
candidate A receiving at least \mu times as candidate B for an arbitrary real
number \mu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2032</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2032</id><created>2009-12-10</created><authors><author><keyname>Briceno</keyname><forenames>Y.</forenames></author><author><keyname>Contreras</keyname><forenames>H. Y.</forenames></author><author><keyname>Nunez</keyname><forenames>L. A.</forenames></author><author><keyname>Salager-Meyer</keyname><forenames>F.</forenames></author><author><keyname>Rojas</keyname><forenames>A.</forenames></author><author><keyname>Torrens</keyname><forenames>R.</forenames></author></authors><title>Institutional Repository saber.ula.ve: A testimonial perspective</title><categories>cs.DL</categories><comments>7th International Conference on Open Access in Accra Ghana from 2nd
  to 3rd November 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe our decade-long experience of building and
operating one of the most active Institutional Repository in the world:
www.saber.ula.ve &lt;http://www.saber.ula.ve&gt; (University of the Andes,
Merida-Venezuela). In order to share our experience with other institutions, we
firstly explain the steps we followed to preserve and disseminate the
scientific production of the University of Los Andes' researchers. We then
present some recent quantitative results about our repository activities and we
outline some methodological guidelines that could be applied in order to
replicate similar experiences. These guidelines list the ingredients or
building blocks as well as the processes followed for developing and
maintaining the services of an Institutional Repository. These include
technological infrastructure; institutional policies on preservation,
publication and dissemination of knowledge; recommendations on incentives for
open access publication; the process of selection, testing and adaptation of
technological tools; the planning and organization of services, and the
dissemination and support within the scientific community that will eventually
lead to the adoption of the ideas that lie behind the open access movement. We
summarize the results obtained regarding the acceptance, adoption and use of
the technological tools used for the publication of our institution's
intellectual production, and we present the main obstacles encountered on the
way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2047</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2047</id><created>2009-12-10</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Efficient Gaussian Elimination on a 2D SIMD Array of Processors without
  Column Broadcasts</title><categories>cs.DC cs.DS cs.NA</categories><acm-class>G.1.3; C.1.2</acm-class><journal-ref>Politehnica University of Bucharest (UPB) Scientific Bulletin,
  Series C - Electrical Engineering and Computer Science, vol. 71, issue 4, pp.
  83-98, 2009. (ISSN: 1454-234X)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient method for implementing the Gaussian
elimination technique for an nxm (m&gt;=n) matrix, using a 2D SIMD array of nxm
processors. The described algorithm consists of 2xn-1=O(n) iterations, which
provides an optimal speed-up over the serial version. A particularity of the
algorithm is that it only requires broadcasts on the rows of the processor
matrix and not on its columns. The paper also presents several extensions and
applications of the Gaussian elimination algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2109</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2109</id><created>2009-12-10</created><updated>2009-12-22</updated><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Luttik</keyname><forenames>Bas</forenames></author><author><keyname>Trcka</keyname><forenames>Nikola</forenames></author></authors><title>Computation Tree Logic with Deadlock Detection</title><categories>cs.LO</categories><acm-class>F.4.1; D.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 4 (December
  22, 2009) lmcs:758</journal-ref><doi>10.2168/LMCS-5(4:5)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the equivalence relation on states of labelled transition systems of
satisfying the same formulas in Computation Tree Logic without the next state
modality (CTL-X). This relation is obtained by De Nicola &amp; Vaandrager by
translating labelled transition systems to Kripke structures, while lifting the
totality restriction on the latter. They characterised it as divergence
sensitive branching bisimulation equivalence.
  We find that this equivalence fails to be a congruence for interleaving
parallel composition. The reason is that the proposed application of CTL-X to
non-total Kripke structures lacks the expressiveness to cope with deadlock
properties that are important in the context of parallel composition. We
propose an extension of CTL-X, or an alternative treatment of non-totality,
that fills this hiatus. The equivalence induced by our extension is
characterised as branching bisimulation equivalence with explicit divergence,
which is, moreover, shown to be the coarsest congruence contained in divergence
sensitive branching bisimulation equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2125</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2125</id><created>2009-12-10</created><updated>2010-07-26</updated><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>Dispersion in disks</title><categories>cs.CG cs.DM</categories><comments>A preliminary version entitled &quot;Dispersion in unit disks&quot; appeared in
  Proceedings of the 27th International Symposium on Theoretical Aspects of
  Computer Science (STACS'10), pages 299-310</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three new approximation algorithms with improved constant ratios
for selecting $n$ points in $n$ disks such that the minimum pairwise distance
among the points is maximized.
  (1) A very simple $O(n\log n)$-time algorithm with ratio $0.511$ for disjoint
unit disks.
  (2) An LP-based algorithm with ratio $0.707$ for disjoint disks of arbitrary
radii that uses a linear number of variables and constraints, and runs in
polynomial time.
  (3) A hybrid algorithm with ratio either $0.4487$ or $0.4674$ for (not
necessarily disjoint) unit disks that uses an algorithm of Cabello in
combination with either the simple $O(n\log n)$-time algorithm or the LP-based
algorithm.
  The LP algorithm can be extended for disjoint balls of arbitrary radii in
$\RR^d$, for any (fixed) dimension $d$, while preserving the features of the
planar algorithm. The algorithm introduces a novel technique which combines
linear programming and projections for approximating Euclidean distances. The
previous best approximation ratio for dispersion in disjoint disks, even when
all disks have the same radius, was $1/2$. Our results give a partial answer to
an open question raised by Cabello, who asked whether the ratio $1/2$ could be
improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2128</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2128</id><created>2009-12-10</created><authors><author><keyname>Andova</keyname><forenames>Suzana</forenames></author><author><keyname>McIver</keyname><forenames>Annabelle</forenames></author><author><keyname>D'Argenio</keyname><forenames>Pedro</forenames></author><author><keyname>Cuijpers</keyname><forenames>Pieter</forenames></author><author><keyname>Markovski</keyname><forenames>Jasen</forenames></author><author><keyname>Morgan</keyname><forenames>Caroll</forenames></author><author><keyname>N&#xfa;&#xf1;ez</keyname><forenames>Manuel</forenames></author></authors><title>Proceedings First Workshop on Quantitative Formal Methods: Theory and
  Applications</title><categories>cs.LO cs.PF</categories><acm-class>D.2.1; D.2.4; D.3.1; F.3.1</acm-class><journal-ref>EPTCS 13, 2009</journal-ref><doi>10.4204/EPTCS.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the 1st workshop on Quantitative
Formal Methods: Theory and Applications, which was held in Eindhoven on 3
November 2009 as part of the International Symposium on Formal Methods 2009.
This volume contains the final versions of all contributions accepted for
presentation at the workshop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2134</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2134</id><created>2009-12-10</created><authors><author><keyname>Vassev</keyname><forenames>Emil</forenames></author></authors><title>Enterprise Multi-Branch Database Synchronization with MSMQ</title><categories>cs.DB cs.NI</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When we talk about databases there have always been problems concerning data
synchronization. The latter is a technique for maintaining consistency among
different copies of data (often called replicas). In general, there is no
universal solution to this problem and often a particular situation requires a
particular approach driven by specific conditions. This paper presents an
approach tackling the issue of data synchronization in a distributed
multi-branch enterprise database. The proposed solution is based on MSMQ
(Microsoft Message Queue), a mechanism for asynchronous messaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2138</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2138</id><created>2009-12-10</created><authors><author><keyname>Fu</keyname><forenames>Liqun</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author></authors><title>Effective Carrier Sensing in CSMA Networks under Cumulative Interference</title><categories>cs.NI</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes and investigates the concept of a safe carrier-sensing
range that can guarantee interference safe (also termed hidden-node-free)
transmissions in CSMA networks under the cumulative interference model.
Compared with the safe carrier-sensing range under the commonly assumed but
less realistic pairwise interference model, we show that the safe
carrier-sensing range required under the cumulative interference model is
larger by a constant multiplicative factor. The concept of a safe
carrier-sensing range, although amenable to elegant analytical results, is
inherently not compatible with the conventional power threshold carrier-sensing
mechanism (e.g., that used in IEEE 802.11). Specifically, the absolute power
sensed by a node in the conventional mechanism does not contain enough
information for it to derive its distances from other concurrent transmitter
nodes. We show that, fortunately, a carrier-sensing mechanism called
Incremental-Power Carrier-Sensing (IPCS) can realize the carrier-sensing range
concept in a simple way. Instead of monitoring the absolute detected power, the
IPCS mechanism monitors every increment in the detected power. This means that
IPCS can separate the detected power of every concurrent transmitter, and map
the power profile to the required distance information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2160</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2160</id><created>2009-12-11</created><authors><author><keyname>Velasco</keyname><forenames>Pedro Pablo Perez</forenames></author></authors><title>Matrix Graph Grammars: Transformation of Restrictions</title><categories>cs.DM</categories><comments>25 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the Matrix approach to graph transformation we represent simple digraphs
and rules with Boolean matrices and vectors, and the rewriting is expressed
using Boolean operations only. In previous works, we developed analysis
techniques enabling the study of the applicability of rule sequences, their
independence, stated reachability and the minimal digraph able to fire a
sequence. In [20], graph constraints and application conditions (so-called
restrictions) have been studied in detail. In the present contribution we
tackle the problem of translating post-conditions into pre-conditions and vice
versa. Moreover, we shall see that application conditions can be moved along
productions inside a sequence (restriction delocalization). As a
practical-theoretical application we show how application conditions allow us
to perform multidigraph rewriting (as opposed to simple digraph rewriting)
using Matrix Graph Grammars
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2174</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2174</id><created>2009-12-11</created><authors><author><keyname>Janson</keyname><forenames>Svante</forenames></author></authors><title>Renewal theory in analysis of tries and strings</title><categories>cs.DS math.PR</categories><comments>32 pages</comments><acm-class>G.3; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a survey of a number of simple applications of renewal theory to
problems on random strings and tries: insertion depth, size, insertion mode and
imbalance of tries; variations for b-tries and Patricia tries; Khodak and
Tunstall codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2190</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2190</id><created>2009-12-11</created><updated>2011-03-29</updated><authors><author><keyname>Camps</keyname><forenames>Rosa</forenames></author><author><keyname>Mora</keyname><forenames>Xavier</forenames></author><author><keyname>Saumell</keyname><forenames>Laia</forenames></author></authors><title>A continuous rating method for preferential voting. The complete case</title><categories>math.OC cs.GT</categories><comments>This is part one of a revised version of arxiv:0810.2263. Version 3
  is the result of certain modifications, both in the statement of the problem
  and in the concluding remarks, that enhance the results of the paper; the
  results themselves remain unchanged</comments><msc-class>05C20, 91B12, 91B14, 91C15, 91C20</msc-class><doi>10.1007/s00355-011-0548-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is given for quantitatively rating the social acceptance of
different options which are the matter of a complete preferential vote.
Completeness means that every voter expresses a comparison (a preference or a
tie) about each pair of options. The proposed method is proved to have certain
desirable properties, which include: the continuity of the rates with respect
to the data, a decomposition property that characterizes certain situations
opposite to a tie, the Condorcet-Smith principle, and a property of clone
consistency. One can view this rating method as a complement for the ranking
method introduced in 1997 by Markus Schulze. It is also related to certain
methods of one-dimensional scaling or cluster analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2195</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2195</id><created>2009-12-11</created><updated>2012-03-08</updated><authors><author><keyname>Camps</keyname><forenames>Rosa</forenames></author><author><keyname>Mora</keyname><forenames>Xavier</forenames></author><author><keyname>Saumell</keyname><forenames>Laia</forenames></author></authors><title>A continuous rating method for preferential voting. The incomplete case</title><categories>math.OC cs.GT</categories><comments>Part two of a revised version of arxiv:0810.2263. Version 3 is the
  result of several minor improvements</comments><msc-class>05C20, 91B12, 91B14, 91C15, 91C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is given for quantitatively rating the social acceptance of
different options which are the matter of a preferential vote. In contrast to a
previous article, here the individual votes are allowed to be incomplete, that
is, they need not express a comparison between every pair of options. This
includes the case where each voter gives an ordered list restricted to a subset
of most preferred options. In this connection, the proposed method (except for
one of the given variants) carefully distinguishes a lack of information about
a given pair of options from a proper tie between them. As in the special case
of complete individual votes, the proposed generalization is proved to have
certain desirable properties, which include: the continuity of the rates with
respect to the data, a decomposition property that characterizes certain
situations opposite to a tie, the Condorcet-Smith principle, and clone
consistency
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2199</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2199</id><created>2009-12-11</created><authors><author><keyname>Conti</keyname><forenames>Mauro</forenames></author><author><keyname>Di Pietro</keyname><forenames>Roberto</forenames></author><author><keyname>Gabrielli</keyname><forenames>Andrea</forenames></author><author><keyname>Mancini</keyname><forenames>Luigi V.</forenames></author><author><keyname>Mei</keyname><forenames>Alessandro</forenames></author></authors><title>The Smallville Effect: Social Ties Make Mobile Networks More Secure
  Against the Node Capture Attack</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad Hoc networks, due to the unattended nature of the network itself
and the dispersed location of nodes, are subject to several unique security
issues. One of the most vexed security threat is node capture. A few solutions
have already been proposed to address this problem; however, those solutions
are either centralized or focused on theoretical mobility models alone. In the
former case the solution does not fit well the distributed nature of the
network while, in the latter case, the quality of the solutions obtained for
realistic mobility models severely differs from the results obtained for
theoretical models. The rationale of this paper is inspired by the observation
that re-encounters of mobile nodes do elicit a form of social ties. Leveraging
these ties, it is possible to design efficient and distributed algorithms that,
with a moderated degree of node cooperation, enforce the emergent property of
node capture detection. In particular, in this paper we provide a proof of
concept proposing a set of algorithms that leverage, to different extent, node
mobility and node cooperation--that is, identifying social ties--to thwart node
capture attack. In particular, we test these algorithms on a realistic mobility
scenario. Extensive simulations show the quality of the proposed solutions and,
more important, the viability of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2269</identifier>
 <datestamp>2009-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2269</id><created>2009-12-11</created><updated>2009-12-29</updated><authors><author><keyname>Sauerbier</keyname><forenames>Charles</forenames></author></authors><title>Computing a Discrete Logarithm in O(n^3)</title><categories>cs.DS</categories><comments>5 pages, 0 figures, example source code in c#; v2 expanded to include
  computation without projection into real number field; v3 edits to more
  explicitly make the association with periodic functions of a specific form;
  v4 edits correct y periodic aside and to clarify loop identification, note
  respective difference expression and modular exponentiation</comments><acm-class>F.2.1; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a means with time complexity of at worst O(n^3) to
compute the discrete logarithm on cyclic finite groups of integers modulo p.
The algorithm makes use of reduction of the problem to that of finding the
concurrent zeros of two periodic functions in the real numbers. The problem is
treated as an analog to a form of analog rotor-code computed cipher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2282</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2282</id><created>2009-12-11</created><authors><author><keyname>Nihalani</keyname><forenames>Mrs. Neelu</forenames></author><author><keyname>Silakari</keyname><forenames>Dr. Sanjay</forenames></author><author><keyname>Motwani</keyname><forenames>Dr. Mahesh</forenames></author></authors><title>Design of Intelligent layer for flexible querying in databases</title><categories>cs.DB cs.AI</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 30-39</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-based information technologies have been extensively used to help
many organizations, private companies, and academic and education institutions
manage their processes and information systems hereby become their nervous
centre. The explosion of massive data sets created by businesses, science and
governments necessitates intelligent and more powerful computing paradigms so
that users can benefit from this data. Therefore most new-generation database
applications demand intelligent information management to enhance efficient
interactions between database and the users. Database systems support only a
Boolean query model. A selection query on SQL database returns all those tuples
that satisfy the conditions in the query.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2284</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2284</id><created>2009-12-11</created><authors><author><keyname>Agrawal</keyname><forenames>C. P.</forenames></author><author><keyname>Vyas</keyname><forenames>O. P.</forenames></author><author><keyname>Tiwari</keyname><forenames>M. K</forenames></author></authors><title>Evaluation of Varrying Mobility Models &amp; Network Loads on DSDV Protocol
  of MANETs</title><categories>cs.NI</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 40-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad-hoc network (MANET) is collection of intercommunicating mobile
hosts forming a spontaneous network without using established network
infrastructure. Unlike the cellular or infrastructure networks who have a wired
backbone connecting the base-station, the MANETs have neither fixed routers nor
fixed locations. Their performance largely depend upon the routing mechanism &amp;
nature of mobility. Earlier research hints that the Destination Sequenced
Distance Vector (DSDV) routing protocol is one of the most efficient and
popular protocols, as far as general parameters have been concerned.[1,6] We
have experimentally evaluated, the performance metrics for network load, packet
delivery fraction and end-to-end delay with DSDV Protocol using NS2
Simulator.This paper presents, the performance of DSDV protocol for four
different mobility models namely: Random Waypoint, Reference Point Group
Mobility, Gauss Markov &amp; Manhattan Mobility Model having varying network load &amp;
speed. The experimental results suggest that DSDV protocol with RPGM mobility
model has optimized results for varying network load and speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2289</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2289</id><created>2009-12-11</created><authors><author><keyname>Tri</keyname><forenames>Dand Tran</forenames></author><author><keyname>Dang</keyname><forenames>Tran Khanh</forenames></author></authors><title>Security Visualization for peer-to-peer resource sharing applications</title><categories>cs.NI cs.CR cs.HC</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 47-55</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security of an information system is only as strong as its weakest element.
Popular elements of such system include hardware, software, network and people.
Current approaches to computer security problems usually exclude people in
their studies even though it is an integral part of these systems. To fill that
gap, this paper discusses crucial people-related problems in computer security
and proposes a method of improving security in such systems by integrating
people tightly into the whole system. The integration is implemented via
visualization to provide visual feedbacks and capture people's awareness of
their actions and consequent results. By doing it, we can improve system
usability, shorten user's learning curve, and hence enable user uses computer
systems more securely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2293</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2293</id><created>2009-12-11</created><authors><author><keyname>Kumar</keyname><forenames>Shishir</forenames></author><author><keyname>Pant</keyname><forenames>Durgesh</forenames></author></authors><title>Detection and Prevention of New and Unknown Malware using Honeypots</title><categories>cs.NI cs.CR</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 56-61</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security has become ubiquitous in every domain today as newly emerging
malware pose an ever-increasing perilous threat to systems. Consequently,
honeypots are fast emerging as an indispensible forensic tool for the analysis
of malicious network traffic. Honeypots can be considered to be traps for
hackers and intruders and are generally deployed complimentary to Intrusion
Detection Systems (IDS) and Intrusion Prevention Systems (IPS) in a network.
They help system administrators perform a rigorous analysis of external and
internal attacks on their networks. They are also used by security firms and
research labs to capture the latest variants of malware. However, honeypots
would serve a slightly different purpose in our proposed system. We intend to
use honeypots for generating and broadcasting instant cures for new and unknown
malware in a network. The cures which will be in the form of on-the-fly
anti-malware signatures would spread in a fashion that is similar to the way
malware spreads across networks. The most striking advantage of implementing
this technology is that an effective initial control can be exercised on
malware. Proposed system would be capable of providing cures for new fatal
viruses which have not yet been discovered by prime security firms of the
world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2296</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2296</id><created>2009-12-11</created><authors><author><keyname>Ayyasamy</keyname><forenames>S.</forenames></author><author><keyname>Sivanandam</keyname><forenames>S. N.</forenames></author></authors><title>A QoS-Aware Intelligent Replica Management Architecture for Content
  Distribution in Peer-to-Peer Overlay Networks</title><categories>cs.NI</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 71-77</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The large scale content distribution systems were improved broadly using the
replication techniques. The demanded contents can be brought closer to the
clients by multiplying the source of information geographically, which in turn
reduce both the access latency and the network traffic. The system scalability
can be improved by distributing the load across multiple servers which is
proposed by replication. If a copy of the requested object (e.g., a web page or
an image) is located in its closer proximity then the clients would feel low
access latency. Depending on the position of the replicas, the effectiveness of
replication tends to a large extent. A QoS based overlay network architecture
involving an intelligent replica placement algorithm is proposed in this paper.
Its main goal is to improve the network utilization and fault tolerance of the
P2P system. In addition to the replica placement, it also has a caching
technique, to reduce the search latency. We are able to show that our proposed
architecture attains less latency and better throughput with reduced bandwidth
usage, through the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2298</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2298</id><created>2009-12-11</created><authors><author><keyname>Kini</keyname><forenames>N. Gopalakrishna</forenames></author><author><keyname>Kumar</keyname><forenames>M. Sathish</forenames></author><author><keyname>Mruthyunjaya</keyname><forenames>H. S.</forenames></author></authors><title>Performance Metrics Analysis of Torus Embedded Hypercube Interconnection
  Network</title><categories>cs.NI</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 78-80</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advantages of hypercube network and torus topology are used to derive an
embedded architecture for product network known as torus embedded hypercube
scalable interconnection network. This paper analyzes torus embedded hypercube
network pertinent to parallel architecture. The network metrics are used to
show how good embedded network can be designed for parallel computation.
Network parameter analysis and comparison of embedded network with basic
networks is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2301</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2301</id><created>2009-12-11</created><authors><author><keyname>Bremananth</keyname><forenames>R</forenames></author><author><keyname>Thushara</keyname><forenames>R</forenames></author></authors><title>Fault Predictions in Object Oriented Software</title><categories>cs.SE</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 81-88</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic software development organizations optimize the usage of
resources to deliver the products in the specified time with the fulfilled
requirements. This requires prevention or repairing of the faults as quick as
possible. In this paper an approach for predicting the run-time errors in java
is introduced. The paper is concerned with faults due to inheritance and
violation of java constraints. The proposed fault prediction model is designed
to separate the faulty classes in the field of software testing. Separated
faulty classes are classified according to the fault occurring in the specific
class. The results are papered by clustering the faults in the class. This
model can be used for predicting software reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2302</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2302</id><created>2009-12-11</created><authors><author><keyname>Douik</keyname><forenames>Ali</forenames></author><author><keyname>Jlassi</keyname><forenames>Mourad Moussa</forenames></author></authors><title>Synthesis of supervised classification algorithm using intelligent and
  statistical tools</title><categories>cs.CV cs.LG</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 89-97</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental task in detecting foreground objects in both static and dynamic
scenes is to take the best choice of color system representation and the
efficient technique for background modeling. We propose in this paper a
non-parametric algorithm dedicated to segment and to detect objects in color
images issued from a football sports meeting. Indeed segmentation by pixel
concern many applications and revealed how the method is robust to detect
objects, even in presence of strong shadows and highlights. In the other hand
to refine their playing strategy such as in football, handball, volley ball,
Rugby..., the coach need to have a maximum of technical-tactics information
about the on-going of the game and the players. We propose in this paper a
range of algorithms allowing the resolution of many problems appearing in the
automated process of team identification, where each player is affected to his
corresponding team relying on visual data. The developed system was tested on a
match of the Tunisian national competition. This work is prominent for many
next computer vision studies as it's detailed in this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2303</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2303</id><created>2009-12-11</created><authors><author><keyname>Agarwal</keyname><forenames>Ratish</forenames></author><author><keyname>Motwani</keyname><forenames>Dr. Mahesh</forenames></author></authors><title>Survey of clustering algorithms for MANET</title><categories>cs.DC cs.NI</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 98-104</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many clustering schemes have been proposed for ad hoc networks. A systematic
classification of these clustering schemes enables one to better understand and
make improvements. In mobile ad hoc networks, the movement of the network nodes
may quickly change the topology resulting in the increase of the overhead
message in topology maintenance. Protocols try to keep the number of nodes in a
cluster around a pre-defined threshold to facilitate the optimal operation of
the medium access control protocol. The clusterhead election is invoked
on-demand, and is aimed to reduce the computation and communication costs. A
large variety of approaches for ad hoc clustering have been developed by
researchers which focus on different performance metrics. This paper presents a
survey of different clustering schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2306</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2306</id><created>2009-12-11</created><authors><author><keyname>Malik</keyname><forenames>Nasir Mahmood</forenames></author><author><keyname>Khalil</keyname><forenames>Tehmina</forenames></author><author><keyname>Khalid</keyname><forenames>Samina</forenames></author><author><keyname>Malik</keyname><forenames>Faisal Munir</forenames></author></authors><title>PKI Implementation Issues: A Comparative Study of Pakistan with some
  Asian Countries</title><categories>cs.CR</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 105-110</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper includes Public Key Infrastructure (PKI), its need and requirements
and introduction of some renowned PKI products. However, the major thrust of
this work is that how PKI can enhance security of various systems. The paper is
intended to serve as a guide on how to adequately prepare for some of the
challenges that may be encountered especially in developing countries like
Pakistan. The detail of PKI implementation issues is also included in the paper
along with future challenges regarding implementation of PKI. Furthermore,
paper includes technical issues hindering the implementation of PKI through
comparison of PKI issues in Pakistan and some of Asian countries mainly Taiwan,
Japan and Singapore. The paper also highlights the PKI issues and learnt
lessons regarding PKI implementation and can act as a comprehensive guide for
successful future PKI deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2307</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2307</id><created>2009-12-11</created><authors><author><keyname>Manicassamy</keyname><forenames>Jayanthi</forenames></author><author><keyname>Dhavachelvan</keyname><forenames>P.</forenames></author></authors><title>Rank Based Clustering For Document Retrieval From Biomedical Databases</title><categories>cs.IR cs.DB</categories><journal-ref>IJCSE Volume 1 Issue 2 2009 111-115</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a day's, search engines are been most widely used for extracting
information's from various resources throughout the world. Where, majority of
searches lies in the field of biomedical for retrieving related documents from
various biomedical databases. Currently search engines lacks in document
clustering and representing relativeness level of documents extracted from the
databases. In order to overcome these pitfalls a text based search engine have
been developed for retrieving documents from Medline and PubMed biomedical
databases. The search engine has incorporated page ranking bases clustering
concept which automatically represents relativeness on clustering bases. Apart
from this graph tree construction is made for representing the level of
relatedness of the documents that are networked together. This advance
functionality incorporation for biomedical document based search engine found
to provide better results in reviewing related documents based on relativeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2310</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2310</id><created>2009-12-11</created><authors><author><keyname>Joseph</keyname><forenames>Vincy</forenames></author><author><keyname>Bhatia</keyname><forenames>Shalini</forenames></author></authors><title>NeuralNetwork Based 3D Surface Reconstruction</title><categories>cs.NE</categories><journal-ref>IJCSE Volume 1 Issue 3 2009 116-121</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel neural-network-based adaptive hybrid-reflectance
three-dimensional (3-D) surface reconstruction model. The neural network
combines the diffuse and specular components into a hybrid model. The proposed
model considers the characteristics of each point and the variant albedo to
prevent the reconstructed surface from being distorted. The neural network
inputs are the pixel values of the two-dimensional images to be reconstructed.
The normal vectors of the surface can then be obtained from the output of the
neural network after supervised learning, where the illuminant direction does
not have to be known in advance. Finally, the obtained normal vectors can be
applied to integration method when reconstructing 3-D objects. Facial images
were used for training in the proposed approach
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2311</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2311</id><created>2009-12-11</created><authors><author><keyname>Manicassamy</keyname><forenames>Jayanthi</forenames></author><author><keyname>Dhavachelvan</keyname><forenames>P.</forenames></author></authors><title>VirusPKT: A Search Tool For Assimilating Assorted Acquaintance For
  Viruses</title><categories>cs.IR q-bio.OT</categories><journal-ref>IJCSE Volume 1 Issue 3 2009 122-126</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Viruses utilize various means to circumvent the immune detection in the
biological systems. Several mathematical models have been investigated for the
description of viral dynamics in the biological system of human and various
other species. One common strategy for evasion and recognition of viruses is,
through acquaintance in the systems by means of search engines. In this
perspective a search tool have been developed to provide a wider comprehension
about the structure and other details on viruses which have been narrated in
this paper. This provides an adequate knowledge in evolution and building of
viruses, its functions through information extraction from various websites.
Apart from this, tool aim to automate the activities associated with it in a
self-maintainable, self-sustainable, proactive one which has been evaluated
through analysis made and have been discussed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2314</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2314</id><created>2009-12-11</created><authors><author><keyname>Rejani</keyname><forenames>Y. Ireaneus Anna</forenames></author><author><keyname>Selvi</keyname><forenames>S. Thamarai</forenames></author></authors><title>Early Detection of Breast Cancer using SVM Classifier Technique</title><categories>cs.LG</categories><journal-ref>IJCSE Volume 1 Issue 3 2009 127-130</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a tumor detection algorithm from mammogram. The proposed
system focuses on the solution of two problems. One is how to detect tumors as
suspicious regions with a very weak contrast to their background and another is
how to extract features which categorize tumors. The tumor detection method
follows the scheme of (a) mammogram enhancement. (b) The segmentation of the
tumor area. (c) The extraction of features from the segmented tumor area. (d)
The use of SVM classifier. The enhancement can be defined as conversion of the
image quality to a better and more understandable level. The mammogram
enhancement procedure includes filtering, top hat operation, DWT. Then the
contrast stretching is used to increase the contrast of the image. The
segmentation of mammogram images has been playing an important role to improve
the detection and diagnosis of breast cancer. The most common segmentation
method used is thresholding. The features are extracted from the segmented
breast area. Next stage include, which classifies the regions using the SVM
classifier. The method was tested on 75 mammographic images, from the mini-MIAS
database. The methodology achieved a sensitivity of 88.75%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2316</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2316</id><created>2009-12-11</created><authors><author><keyname>Kheder</keyname><forenames>G.</forenames></author><author><keyname>Kachouri</keyname><forenames>A.</forenames></author><author><keyname>Massoued</keyname><forenames>M. Ben</forenames></author><author><keyname>Samet</keyname><forenames>M.</forenames></author></authors><title>Heart Rate Variability Analysis Using Threshold of Wavelet Package
  Coefficients</title><categories>cs.CV physics.data-an physics.med-ph</categories><journal-ref>IJCSE Volume 1 Issue 3 2009 131-136</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new efficient feature extraction method based on the
adaptive threshold of wavelet package coefficients is presented. This paper
especially deals with the assessment of autonomic nervous system using the
background variation of the signal Heart Rate Variability HRV extracted from
the wavelet package coefficients. The application of a wavelet package
transform allows us to obtain a time-frequency representation of the signal,
which provides better insight in the frequency distribution of the signal with
time. A 6 level decomposition of HRV was achieved with db4 as mother wavelet,
and the above two bands LF and HF were combined in 12 specialized frequencies
sub-bands obtained in wavelet package transform. Features extracted from these
coefficients can efficiently represent the characteristics of the original
signal. ANOVA statistical test is used for the evaluation of proposed
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2319</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2319</id><created>2009-12-11</created><authors><author><keyname>Channalli</keyname><forenames>Shashikala</forenames></author><author><keyname>Jadhav</keyname><forenames>Ajay</forenames></author></authors><title>Steganography An Art of Hiding Data</title><categories>cs.CR</categories><journal-ref>IJCSE Volume 1 Issue 3 2009 137-141</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's world the art of sending &amp; displaying the hidden information
especially in public places, has received more attention and faced many
challenges. Therefore, different methods have been proposed so far for hiding
information in different cover media. In this paper a method for hiding of
information on the billboard display is presented. It is well known that
encryption provides secure channels for communicating entities. However, due to
lack of covertness on these channels, an eavesdropper can identify encrypted
streams through statistical tests and capture them for further cryptanalysis.
In this paper we propose a new form of steganography, on-line hiding of
information on the output screens of the instrument. This method can be used
for announcing a secret message in public place. It can be extended to other
means such as electronic advertising board around sports stadium, railway
station or airport. This method of steganography is very similar to image
steganography and video steganography. Private marking system using symmetric
key steganography technique and LSB technique is used here for hiding the
secret information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2320</identifier>
 <datestamp>2009-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2320</id><created>2009-12-11</created><authors><author><keyname>Hari</keyname><forenames>CH. V. M. K.</forenames></author><author><keyname>D</keyname><forenames>Prof. Prasad Reddy P. V. G.</forenames></author><author><keyname>Kumar</keyname><forenames>J. N. V. R Swarup</forenames></author><author><keyname>SriRamGanesh</keyname><forenames>G.</forenames></author></authors><title>Identifying the Importance of Software Reuse in COCOMO81, COCOMOII</title><categories>cs.SE</categories><journal-ref>IJCSE Volume 1 Issue 3 2009 142-147</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software project management is an interpolation of project planning, project
monitoring and project termination. The substratal goals of planning are to
scout for the future, to diagnose the attributes that are essentially done for
the consummation of the project successfully, animate the scheduling and
allocate resources for the attributes. Software cost estimation is a vital role
in preeminent software project decisions such as resource allocation and
bidding. This paper articulates the conventional overview of software cost
estimation modus operandi available. The cost, effort estimates of software
projects done by the various companies are congregated, the results are
segregated with the present cost models and the MRE (Mean Relative Error) is
enumerated. We have administered the historical data to COCOMO 81, COCOMOII
model and identified that the stellar predicament is that no cost model gives
the exact estimate of a software project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2349</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2349</id><created>2009-12-11</created><authors><author><keyname>Tasson</keyname><forenames>Christine</forenames><affiliation>PPS</affiliation></author></authors><title>Algebraic totality, towards completeness</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00440750</proxy><journal-ref>Logic in Computer Science, Brasilia : Brazil (2009)</journal-ref><doi>10.1007/978-3-642-02273-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finiteness spaces constitute a categorical model of Linear Logic (LL) whose
objects can be seen as linearly topologised spaces, (a class of topological
vector spaces introduced by Lefschetz in 1942) and morphisms as continuous
linear maps. First, we recall definitions of finiteness spaces and describe
their basic properties deduced from the general theory of linearly topologised
spaces. Then we give an interpretation of LL based on linear algebra. Second,
thanks to separation properties, we can introduce an algebraic notion of
totality candidate in the framework of linearly topologised spaces: a totality
candidate is a closed affine subspace which does not contain 0. We show that
finiteness spaces with totality candidates constitute a model of classical LL.
Finally, we give a barycentric simply typed lambda-calculus, with booleans
${\mathcal{B}}$ and a conditional operator, which can be interpreted in this
model. We prove completeness at type ${\mathcal{B}}^n\to{\mathcal{B}}$ for
every n by an algebraic method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2371</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2371</id><created>2009-12-11</created><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Rao</keyname><forenames>B. V. Raghavendra</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Faster Algorithms for Finding and Counting Subgraphs</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a natural generalization of both {\sc $k$-Path} and
{\sc $k$-Tree} problems, namely, the {\sc Subgraph Isomorphism} problem.
  In the {\sc Subgraph Isomorphism} problem we are given two graphs $F$ and $G$
on $k$ and $n$ vertices respectively as an input, and the question is whether
there exists a subgraph of $G$ isomorphic to $F$. We show that if the treewidth
of $F$ is at most $t$, then there is a randomized algorithm for the {\sc
Subgraph Isomorphism} problem running in time $\cO^*(2^k n^{2t})$. To do so, we
associate a new multivariate {Homomorphism polynomial} of degree at most $k$
with the {\sc Subgraph Isomorphism} problem and construct an arithmetic circuit
of size at most $n^{\cO(t)}$ for this polynomial. Using this polynomial, we
also give a deterministic algorithm to count the number of homomorphisms from
$F$ to $G$ that takes $n^{\cO(t)}$ time and uses polynomial space. For the
counting version of the {\sc Subgraph Isomorphism} problem, where the objective
is to count the number of distinct subgraphs of $G$ that are isomorphic to $F$,
we give a deterministic algorithm running in time and space $\cO^*({n \choose
k/2}n^{2p})$ or ${n\choose k/2}n^{\cO(t \log k)}$. We also give an algorithm
running in time $\cO^{*}(2^{k}{n \choose k/2}n^{5p})$ and taking space
polynomial in $n$. Here $p$ and $t$ denote the pathwidth and the treewidth of
$F$, respectively. Thus our work not only improves on known results on {\sc
Subgraph Isomorphism} but it also extends and generalize most of the known
results on {\sc $k$-Path} and {\sc $k$-Tree}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2378</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2378</id><created>2009-12-11</created><authors><author><keyname>Akoum</keyname><forenames>Salam</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author></authors><title>Limited Feedback for Temporally Correlated MIMO Channels with Other Cell
  Interference</title><categories>cs.IT math.IT</categories><comments>30 pages, submitted to IEEE transactions on Signal Processing</comments><doi>10.1109/TSP.2010.2055860</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Limited feedback improves link reliability with a small amount of feedback
from the receiver back to the transmitter. In cellular systems, the performance
of limited feedback will be degraded in the presence of other cell
interference, when the base stations have limited or no coordination. This
paper establishes the degradation in sum rate of users in a cellular system,
due to uncoordinated other cell interference and delay on the feedback channel.
A goodput metric is defined as the rate when the bits are successfully received
at the mobile station, and used to derive an upper bound on the performance of
limited feedback systems with delay. This paper shows that the goodput gained
from having delayed limited feedback decreases doubly exponentially as the
delay increases. The analysis is extended to precoded spatial multiplexing
systems where it is shown that the same upper bound can be used to evaluate the
decay in the achievable sum rate. To reduce the effects of interference, zero
forcing interference cancellation is applied at the receiver, where it is shown
that the effect of the interference on the achievable sum rate can be
suppressed by nulling out the interferer. Numerical results show that the decay
rate of the goodput decreases when the codebook quantization size increases and
when the doppler shift in the channel decreases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2381</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2381</id><created>2009-12-11</created><authors><author><keyname>Camacho</keyname><forenames>R.</forenames></author><author><keyname>Chacon</keyname><forenames>R.</forenames></author><author><keyname>Diaz</keyname><forenames>G.</forenames></author><author><keyname>Guada</keyname><forenames>C.</forenames></author><author><keyname>Hamar</keyname><forenames>V.</forenames></author><author><keyname>Hoeger</keyname><forenames>H.</forenames></author><author><keyname>Melfo</keyname><forenames>A.</forenames></author><author><keyname>Nunez</keyname><forenames>L. A.</forenames></author><author><keyname>Perez</keyname><forenames>Y.</forenames></author><author><keyname>Quintero</keyname><forenames>C.</forenames></author><author><keyname>Rosales</keyname><forenames>M.</forenames></author><author><keyname>Torrens</keyname><forenames>R.</forenames></author><author><keyname>Collaboration</keyname><forenames>the LAGO</forenames></author></authors><title>LAGOVirtual: A Collaborative Environment for the Large Aperture GRB
  Observatory</title><categories>cs.CE astro-ph.HE astro-ph.IM hep-ex</categories><comments>Second EELA-2 Conference Choroni, Venezuela, November 25th to 27th
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the LAGOVirtual Project: an ongoing project to develop platform to
collaborate in the Large Aperture GRB Observatory (LAGO). This continental-wide
observatory is devised to detect high energy (around 100 GeV) component of
Gamma Ray Bursts, by using the single particle technique in arrays of Water
Cherenkov Detectors (WCD) at high mountain sites (Chacaltaya, Bolivia, 5300 m
a.s.l., Pico Espejo, Venezuela, 4750 m a.s.l., Sierra Negra, Mexico, 4650 m
a.s.l). This platform will allow LAGO collaboration to share data, and computer
resources through its different sites. This environment has the possibility to
generate synthetic data by simulating the showers through AIRES application and
to store/preserve distributed data files collected by the WCD at the LAGO
sites. The present article concerns the implementation of a prototype of
LAGO-DR adapting DSpace, with a hierarchical structure (i.e. country,
institution, followed by collections that contain the metadata and data files),
for the captured/simulated data. This structure was generated by using the
community, sub-community, collection, item model; available at the DSpace
software. Each member institution-country of the project has the appropriate
permissions on the system to publish information (descriptive metadata and
associated data files). The platform can also associate multiple files to each
item of data (data from the instruments, graphics, postprocessed-data, etc.).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2385</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2385</id><created>2009-12-11</created><authors><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Siddiqi</keyname><forenames>Sajid M.</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey J.</forenames></author></authors><title>Closing the Learning-Planning Loop with Predictive State Representations</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in artificial intelligence is that of planning to maximize
future reward under uncertainty in a partially observable environment. In this
paper we propose and demonstrate a novel algorithm which accurately learns a
model of such an environment directly from sequences of action-observation
pairs. We then close the loop from observations to actions by planning in the
learned model and recovering a policy which is near-optimal in the original
environment. Specifically, we present an efficient and statistically consistent
spectral algorithm for learning the parameters of a Predictive State
Representation (PSR). We demonstrate the algorithm by learning a model of a
simulated high-dimensional, vision-based mobile robot planning task, and then
perform approximate point-based planning in the learned PSR. Analysis of our
results shows that the algorithm learns a state space which efficiently
captures the essential features of the environment. This representation allows
accurate prediction with a small number of parameters, and enables successful
and efficient planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2404</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2404</id><created>2009-12-12</created><updated>2010-04-08</updated><authors><author><keyname>Antonellis</keyname><forenames>Ioannis</forenames></author><author><keyname>Sarma</keyname><forenames>Anish Das</forenames></author><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author></authors><title>Succinct Coverage Oracles</title><categories>cs.DS cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we identify a fundamental algorithmic problem that we term
succinct dynamic covering (SDC), arising in many modern-day web applications,
including ad-serving and online recommendation systems in eBay and Netflix.
Roughly speaking, SDC applies two restrictions to the well-studied Max-Coverage
problem: Given an integer k, X={1,2,...,n} and I={S_1, ..., S_m}, S_i a subset
of X, find a subset J of I, such that |J| &lt;= k and the union of S in J is as
large as possible. The two restrictions applied by SDC are: (1) Dynamic: At
query-time, we are given a query Q, a subset of X, and our goal is to find J
such that the intersection of Q with the union of S in J is as large as
possible; (2) Space-constrained: We don't have enough space to store (and
process) the entire input; specifically, we have o(mn), and maybe as little as
O((m+n)polylog(mn)) space. The goal of SDC is to maintain a small data
structure so as to answer most dynamic queries with high accuracy. We call such
a scheme a Coverage Oracle.
  We present algorithms and complexity results for coverage oracles. We present
deterministic and probabilistic near-tight upper and lower bounds on the
approximation ratio of SDC as a function of the amount of space available to
the oracle. Our lower bound results show that to obtain constant-factor
approximations we need Omega(mn) space. Fortunately, our upper bounds present
an explicit tradeoff between space and approximation ratio, allowing us to
determine the amount of space needed to guarantee certain accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2415</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2415</id><created>2009-12-12</created><authors><author><keyname>Runarsson</keyname><forenames>Tomas Philip</forenames></author><author><keyname>Merelo-Guervos</keyname><forenames>Juan J.</forenames></author></authors><title>Adapting Heuristic Mastermind Strategies to Evolutionary Algorithms</title><categories>cs.NE cs.AI</categories><comments>Accepted at the NICSO'10 conference</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The art of solving the Mastermind puzzle was initiated by Donald Knuth and is
already more than 30 years old; despite that, it still receives much attention
in operational research and computer games journals, not to mention the
nature-inspired stochastic algorithm literature. In this paper we try to
suggest a strategy that will allow nature-inspired algorithms to obtain results
as good as those based on exhaustive search strategies; in order to do that, we
first review, compare and improve current approaches to solving the puzzle;
then we test one of these strategies with an estimation of distribution
algorithm. Finally, we try to find a strategy that falls short of being
exhaustive, and is then amenable for inclusion in nature inspired algorithms
(such as evolutionary or particle swarm algorithms). This paper proves that by
the incorporation of local entropy into the fitness function of the
evolutionary algorithm it becomes a better player than a random one, and gives
a rule of thumb on how to incorporate the best heuristic strategies to
evolutionary algorithms without incurring in an excessive computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2425</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2425</id><created>2009-12-12</created><updated>2011-02-25</updated><authors><author><keyname>Lu</keyname><forenames>Wenlian</forenames></author><author><keyname>Atay</keyname><forenames>Fatihcan M.</forenames></author><author><keyname>Jost</keyname><forenames>Jurgen</forenames></author></authors><title>Consensus and synchronization in discrete-time networks of multi-agents
  with stochastically switching topologies and time delays</title><categories>math.DS cs.SY math.OC</categories><comments>20 pages, 2 figures</comments><msc-class>93C05, 37H10, 15A51, 40A20, 05C50, 60J10</msc-class><journal-ref>Networks and Heterogeneous Media, 6:329-349, 2011</journal-ref><doi>10.3934/nhm.2011.6.329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze stability of consensus algorithms in networks of multi-agents with
time-varying topologies and delays. The topology and delays are modeled as
induced by an adapted process and are rather general, including i.i.d.\
topology processes, asynchronous consensus algorithms, and Markovian jumping
switching. In case the self-links are instantaneous, we prove that the network
reaches consensus for all bounded delays if the graph corresponding to the
conditional expectation of the coupling matrix sum across a finite time
interval has a spanning tree almost surely. Moreover, when self-links are also
delayed and when the delays satisfy certain integer patterns, we observe and
prove that the algorithm may not reach consensus but instead synchronize at a
periodic trajectory, whose period depends on the delay pattern. We also give a
brief discussion on the dynamics in the absence of self-links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2430</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2430</id><created>2009-12-12</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Zhenzhen</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Sun</keyname><forenames>Weifeng</forenames></author><author><keyname>Li</keyname><forenames>Mingchu</forenames></author></authors><title>Prediction-Based Data Transmission for Energy Conservation in Wireless
  Body Sensors</title><categories>cs.NI cs.DC</categories><comments>To appear in The Int Workshop on Ubiquitous Body Sensor Networks
  (UBSN), in conjunction with the 5th Annual Int Wireless Internet Conf
  (WICON), Singapore, March 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless body sensors are becoming popular in healthcare applications. Since
they are either worn or implanted into human body, these sensors must be very
small in size and light in weight. The energy consequently becomes an extremely
scarce resource, and energy conservation turns into a first class design issue
for body sensor networks (BSNs). This paper deals with this issue by taking
into account the unique characteristics of BSNs in contrast to conventional
wireless sensor networks (WSNs) for e.g. environment monitoring. A
prediction-based data transmission approach suitable for BSNs is presented,
which combines a dual prediction framework and a low-complexity prediction
algorithm that takes advantage of PID (proportional-integral-derivative)
control. Both the framework and the algorithm are generic, making the proposed
approach widely applicable. The effectiveness of the approach is verified
through simulations using real-world health monitoring datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2479</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2479</id><created>2009-12-13</created><updated>2010-01-12</updated><authors><author><keyname>Goyal</keyname><forenames>Vishal</forenames></author></authors><title>Pervasive Emotions in Pervasive Computing Environments</title><categories>cs.HC</categories><comments>This submission has been withdrawn by arXiv admin. It is a verbatim
  copy of arXiv:0912.1810 with only the author name and title changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This submission has been withdrawn by arXiv admin. It is a verbatim copy of
arXiv:0912.1810 with only the author name and title changed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2492</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2492</id><created>2009-12-13</created><authors><author><keyname>Nickisch</keyname><forenames>Hannes</forenames></author><author><keyname>Kohli</keyname><forenames>Pushmeet</forenames></author><author><keyname>Rother</keyname><forenames>Carsten</forenames></author></authors><title>Learning an Interactive Segmentation System</title><categories>stat.ML cs.CV stat.ME</categories><comments>11 pages, 7 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many successful applications of computer vision to image or video
manipulation are interactive by nature. However, parameters of such systems are
often trained neglecting the user. Traditionally, interactive systems have been
treated in the same manner as their fully automatic counterparts. Their
performance is evaluated by computing the accuracy of their solutions under
some fixed set of user interactions. This paper proposes a new evaluation and
learning method which brings the user in the loop. It is based on the use of an
active robot user - a simulated model of a human user. We show how this
approach can be used to evaluate and learn parameters of state-of-the-art
interactive segmentation systems. We also show how simulated user models can be
integrated into the popular max-margin method for parameter learning and
propose an algorithm to solve the resulting optimisation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2523</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2523</id><created>2009-12-13</created><authors><author><keyname>Rovatti</keyname><forenames>R.</forenames></author><author><keyname>Passerini</keyname><forenames>C.</forenames></author><author><keyname>Mazzini</keyname><forenames>G.</forenames></author></authors><title>Markov Modeling of Cooperative Multiplayer Coupon Collectors' Problems</title><categories>cs.DM</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces a modified version of the classical Coupon Collector's
Problem entailing exchanges and cooperation between multiple players. Results
of the development show that, within a proper Markov framework, the complexity
of the Cooperative Multiplayer Coupon Collectors' Problem can be attacked with
an eye to the modeling of resource harvesting and sharing within the context of
Next Generation Network. The cost of cooperation is computed in terms of
exchange protocol burden and found to be dependent on only ensemble parameters
such as the number of players and the number of coupons but not on the detailed
collection statistics. The benefits of cooperation are quantified in terms of
reduction of the average number of actions before collection completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2548</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2548</id><created>2009-12-13</created><updated>2010-01-26</updated><authors><author><keyname>Loukides</keyname><forenames>Grigorios</forenames></author><author><keyname>Gkoulalas-Divanis</keyname><forenames>Aris</forenames></author><author><keyname>Malin</keyname><forenames>Bradley</forenames></author></authors><title>Towards Utility-driven Anonymization of Transactions</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Publishing person-specific transactions in an anonymous form is increasingly
required by organizations. Recent approaches ensure that potentially
identifying information (e.g., a set of diagnosis codes) cannot be used to link
published transactions to persons' identities, but all are limited in
application because they incorporate coarse privacy requirements (e.g.,
protecting a certain set of m diagnosis codes requires protecting all m-sized
sets), do not integrate utility requirements, and tend to explore a small
portion of the solution space. In this paper, we propose a more general
framework for anonymizing transactional data under specific privacy and utility
requirements. We model such requirements as constraints, investigate how these
constraints can be specified, and propose COAT (COnstraint-based Anonymization
of Transactions), an algorithm that anonymizes transactions using a flexible
hierarchy-free generalization scheme to meet the specified constraints.
Experiments with benchmark datasets verify that COAT significantly outperforms
the current state-of-the-art algorithm in terms of data utility, while being
comparable in terms of efficiency. The effectiveness of our approach is also
demonstrated in a real-world scenario, which requires disseminating a private,
patient-specific transactional dataset in a way that preserves both privacy and
utility in intended studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2549</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2549</id><created>2009-12-13</created><authors><author><keyname>Kert&#xe9;sz</keyname><forenames>Attila</forenames><affiliation>MTA Sztaki</affiliation></author><author><keyname>N&#xe9;meth</keyname><forenames>Zsolt</forenames><affiliation>MTA Sztaki</affiliation></author></authors><title>Formal Aspects of Grid Brokering</title><categories>cs.DC cs.FL</categories><journal-ref>EPTCS 14, 2009, pp. 18-31</journal-ref><doi>10.4204/EPTCS.14.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordination in distributed environments, like Grids, involves selecting the
most appropriate services, resources or compositions to carry out the planned
activities. Such functionalities appear at various levels of the infrastructure
and in various means forming a blurry domain, where it is hard to see how the
participating components are related and what their relevant properties are. In
this paper we focus on a subset of these problems: resource brokering in Grid
middleware. This paper aims at establishing a semantical model for brokering
and related activities by defining brokering agents at three levels of the Grid
middleware for resource, host and broker selection. The main contribution of
this paper is the definition and decomposition of different brokering
components in Grids by providing a formal model using Abstract State Machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2550</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2550</id><created>2009-12-13</created><authors><author><keyname>Blom</keyname><forenames>Stefan</forenames><affiliation>University of Twente</affiliation></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames><affiliation>University of Twente</affiliation></author></authors><title>Distributed Branching Bisimulation Minimization by Inductive Signatures</title><categories>cs.LO cs.DC cs.DM cs.DS</categories><journal-ref>EPTCS 14, 2009, pp. 32-46</journal-ref><doi>10.4204/EPTCS.14.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new distributed algorithm for state space minimization modulo
branching bisimulation. Like its predecessor it uses signatures for refinement,
but the refinement process and the signatures have been optimized to exploit
the fact that the input graph contains no tau-loops.
  The optimization in the refinement process is meant to reduce both the number
of iterations needed and the memory requirements. In the former case we cannot
prove that there is an improvement, but our experiments show that in many cases
the number of iterations is smaller. In the latter case, we can prove that the
worst case memory use of the new algorithm is linear in the size of the state
space, whereas the old algorithm has a quadratic upper bound.
  The paper includes a proof of correctness of the new algorithm and the
results of a number of experiments that compare the performance of the old and
the new algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2551</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2551</id><created>2009-12-13</created><authors><author><keyname>Ballarini</keyname><forenames>Paolo</forenames><affiliation>CoSBi</affiliation></author><author><keyname>Forlin</keyname><forenames>Michele</forenames><affiliation>CoSBi</affiliation></author><author><keyname>Mazza</keyname><forenames>Tommaso</forenames><affiliation>CoSBi</affiliation></author><author><keyname>Prandi</keyname><forenames>Davide</forenames><affiliation>CoSBi</affiliation></author></authors><title>Efficient Parallel Statistical Model Checking of Biochemical Networks</title><categories>cs.CE cs.DC cs.LO q-bio.QM</categories><journal-ref>EPTCS 14, 2009, pp. 47-61</journal-ref><doi>10.4204/EPTCS.14.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of verifying stochastic models of biochemical
networks against behavioral properties expressed in temporal logic terms. Exact
probabilistic verification approaches such as, for example, CSL/PCTL model
checking, are undermined by a huge computational demand which rule them out for
most real case studies. Less demanding approaches, such as statistical model
checking, estimate the likelihood that a property is satisfied by sampling
executions out of the stochastic model. We propose a methodology for
efficiently estimating the likelihood that a LTL property P holds of a
stochastic model of a biochemical network. As with other statistical
verification techniques, the methodology we propose uses a stochastic
simulation algorithm for generating execution samples, however there are three
key aspects that improve the efficiency: first, the sample generation is driven
by on-the-fly verification of P which results in optimal overall simulation
time. Second, the confidence interval estimation for the probability of P to
hold is based on an efficient variant of the Wilson method which ensures a
faster convergence. Third, the whole methodology is designed according to a
parallel fashion and a prototype software tool has been implemented that
performs the sampling/verification process in parallel over an HPC
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2552</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2552</id><created>2009-12-13</created><authors><author><keyname>Wieringa</keyname><forenames>Siert</forenames><affiliation>Helsinki University of Technology TKK</affiliation></author><author><keyname>Niemenmaa</keyname><forenames>Matti</forenames><affiliation>Helsinki University of Technology TKK</affiliation></author><author><keyname>Heljanko</keyname><forenames>Keijo</forenames><affiliation>Helsinki University of Technology TKK</affiliation></author></authors><title>Tarmo: A Framework for Parallelized Bounded Model Checking</title><categories>cs.LO cs.DC</categories><journal-ref>EPTCS 14, 2009, pp. 62-76</journal-ref><doi>10.4204/EPTCS.14.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates approaches to parallelizing Bounded Model Checking
(BMC) for shared memory environments as well as for clusters of workstations.
We present a generic framework for parallelized BMC named Tarmo. Our framework
can be used with any incremental SAT encoding for BMC but for the results in
this paper we use only the current state-of-the-art encoding for full PLTL.
Using this encoding allows us to check both safety and liveness properties,
contrary to an earlier work on distributing BMC that is limited to safety
properties only.
  Despite our focus on BMC after it has been translated to SAT, existing
distributed SAT solvers are not well suited for our application. This is
because solving a BMC problem is not solving a set of independent SAT instances
but rather involves solving multiple related SAT instances, encoded
incrementally, where the satisfiability of each instance corresponds to the
existence of a counterexample of a specific length. Our framework includes a
generic architecture for a shared clause database that allows easy clause
sharing between SAT solver threads solving various such instances.
  We present extensive experimental results obtained with multiple variants of
our Tarmo implementation. Our shared memory variants have a significantly
better performance than conventional single threaded approaches, which is a
result that many users can benefit from as multi-core and multi-processor
technology is widely available. Furthermore we demonstrate that our framework
can be deployed in a typical cluster of workstations, where several multi-core
machines are connected by a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2553</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2553</id><created>2009-12-13</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames><affiliation>Centre for Logic and Information, St. Francis Xavier University, Canada</affiliation></author><author><keyname>MacCaull</keyname><forenames>Wendy</forenames><affiliation>Centre for Logic and Information, St. Francis Xavier University, Canada</affiliation></author></authors><title>An Efficient Explicit-time Description Method for Timed Model Checking</title><categories>cs.LO cs.DC cs.SE</categories><journal-ref>EPTCS 14, 2009, pp. 77-91</journal-ref><doi>10.4204/EPTCS.14.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timed model checking, the method to formally verify real-time systems, is
attracting increasing attention from both the model checking community and the
real-time community. Explicit-time description methods verify real-time systems
using general model constructs found in standard un-timed model checkers.
Lamport proposed an explicit-time description method using a clock-ticking
process (Tick) to simulate the passage of time together with a group of global
variables to model time requirements. Two methods, the Sync-based Explicit-time
Description Method using rendezvous synchronization steps and the
Semaphore-based Explicit-time Description Method using only one global variable
were proposed; they both achieve better modularity than Lamport's method in
modeling the real-time systems. In contrast to timed automata based model
checkers like UPPAAL, explicit-time description methods can access and store
the current time instant for future calculations necessary for many real-time
systems, especially those with pre-emptive scheduling. However, the Tick
process in the above three methods increments the time by one unit in each
tick; the state spaces therefore grow relatively fast as the time parameters
increase, a problem when the system's time period is relatively long. In this
paper, we propose a more efficient method which enables the Tick process to
leap multiple time units in one tick. Preliminary experimental results in a
high performance computing environment show that this new method significantly
reduces the state space and improves both the time and memory efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2554</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2554</id><created>2009-12-13</created><authors><author><keyname>Abujarad</keyname><forenames>Fuad</forenames><affiliation>Michigan State University</affiliation></author><author><keyname>Bonakdarpour</keyname><forenames>Borzoo</forenames><affiliation>VERIMAG</affiliation></author><author><keyname>Kulkarni</keyname><forenames>Sandeep S.</forenames><affiliation>Michigan State University</affiliation></author></authors><title>Parallelizing Deadlock Resolution in Symbolic Synthesis of Distributed
  Programs</title><categories>cs.DC cs.SC cs.SE</categories><journal-ref>EPTCS 14, 2009, pp. 92-106</journal-ref><doi>10.4204/EPTCS.14.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work has shown that there are two major complexity barriers in the
synthesis of fault-tolerant distributed programs: (1) generation of fault-span,
the set of states reachable in the presence of faults, and (2) resolving
deadlock states, from where the program has no outgoing transitions. Of these,
the former closely resembles with model checking and, hence, techniques for
efficient verification are directly applicable to it. Hence, we focus on
expediting the latter with the use of multi-core technology.
  We present two approaches for parallelization by considering different design
choices. The first approach is based on the computation of equivalence classes
of program transitions (called group computation) that are needed due to the
issue of distribution (i.e., inability of processes to atomically read and
write all program variables). We show that in most cases the speedup of this
approach is close to the ideal speedup and in some cases it is superlinear. The
second approach uses traditional technique of partitioning deadlock states
among multiple threads. However, our experiments show that the speedup for this
approach is small. Consequently, our analysis demonstrates that a simple
approach of parallelizing the group computation is likely to be the effective
method for using multi-core computing in the context of deadlock resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2555</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2555</id><created>2009-12-13</created><authors><author><keyname>Barnat</keyname><forenames>Ji&#x159;&#xed;</forenames><affiliation>Masaryk University, Czech Republic</affiliation></author><author><keyname>Brim</keyname><forenames>Lubo&#x161;</forenames><affiliation>Masaryk University, Czech Republic</affiliation></author><author><keyname>&#x10c;e&#x161;ka</keyname><forenames>Milan</forenames><affiliation>Masaryk University, Czech Republic</affiliation></author></authors><title>DiVinE-CUDA - A Tool for GPU Accelerated LTL Model Checking</title><categories>cs.DC cs.SE</categories><journal-ref>EPTCS 14, 2009, pp. 107-111</journal-ref><doi>10.4204/EPTCS.14.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a tool that performs CUDA accelerated LTL Model
Checking. The tool exploits parallel algorithm MAP adjusted to the NVIDIA CUDA
architecture in order to efficiently detect the presence of accepting cycles in
a directed graph. Accepting cycle detection is the core algorithmic procedure
in automata-based LTL Model Checking. We demonstrate that the tool outperforms
non-accelerated version of the algorithm and we discuss where the limits of the
tool are and what we intend to do in the future to avoid them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2561</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2561</id><created>2009-12-13</created><updated>2010-02-03</updated><authors><author><keyname>Schmidt</keyname><forenames>Jens M.</forenames></author></authors><title>Construction Sequences and Certifying 3-Connectedness</title><categories>cs.DS cs.DM</categories><comments>to be published in STACS 2010</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tutte proved that every 3-connected graph on more than 4 nodes has a
contractible edge. Barnette and Gruenbaum proved the existence of a removable
edge in the same setting. We show that the sequence of contractions and the
sequence of removals from G to the K_4 can be computed in O(|V|^2) time by
extending Barnette and Gruenbaum's theorem. As an application, we derive a
certificate for the 3-connectedness of graphs that can be easily computed and
verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2563</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2563</id><created>2009-12-13</created><authors><author><keyname>Narayanaswami</keyname><forenames>Karthik</forenames></author></authors><title>A Model-Based Approach to Predicting Predator-Prey &amp; Friend-Foe
  Relationships in Ant Colonies</title><categories>cs.AI cs.CV q-bio.PE</categories><comments>Graduate work done in Fall 2005 at the BORG Lab, College of
  Computing, Georgia Institute of Technology, under the advisement of Professor
  Tucker Balch</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding predator-prey relationships among insects is a challenging task
in the domain of insect-colony research. This is due to several factors
involved, such as determining whether a particular behavior is the result of a
predator-prey interaction, a friend-foe interaction or another kind of
interaction. In this paper, we analyze a series of predator-prey and friend-foe
interactions in two colonies of carpenter ants to better understand and predict
such behavior. Using the data gathered, we have also come up with a preliminary
model for predicting such behavior under the specific conditions the experiment
was conducted in. In this paper, we present the results of our data analysis as
well as an overview of the processes involved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2565</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2565</id><created>2009-12-13</created><authors><author><keyname>Jansen</keyname><forenames>Maurice</forenames></author><author><keyname>Qiao</keyname><forenames>Youming</forenames></author><author><keyname>Sarma</keyname><forenames>Jayalal</forenames></author></authors><title>Deterministic Identity Testing of Read-Once Algebraic Branching Programs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study polynomial identity testing of sums of $k$ read-once
algebraic branching programs ($\Sigma_k$-RO-ABPs), generalizing the work in
(Shpilka and Volkovich 2008,2009), who considered sums of $k$ read-once
formulas ($\Sigma_k$-RO-formulas). We show that $\Sigma_k$-RO-ABPs are strictly
more powerful than $\Sigma_k$-RO-formulas, for any $k \leq \lfloor n/2\rfloor$,
where $n$ is the number of variables. We obtain the following results:
  1) Given free access to the RO-ABPs in the sum, we get a deterministic
algorithm that runs in time $O(k^2n^7s) + n^{O(k)}$, where $s$ bounds the size
of any largest RO-ABP given on the input. This implies we have a deterministic
polynomial time algorithm for testing whether the sum of a constant number of
RO-ABPs computes the zero polynomial.
  2) Given black-box access to the RO-ABPs computing the individual polynomials
in the sum, we get a deterministic algorithm that runs in time $k^2n^{O(\log
n)} + n^{O(k)}$.
  3) Finally, given only black-box access to the polynomial computed by the sum
of the $k$ RO-ABPs, we obtain an $n^{O(k + \log n)}$ time deterministic
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2572</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2572</id><created>2009-12-13</created><authors><author><keyname>Agullo</keyname><forenames>Emmanuel</forenames></author><author><keyname>Coti</keyname><forenames>Camille</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author><author><keyname>Herault</keyname><forenames>Thomas</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author></authors><title>QR Factorization of Tall and Skinny Matrices in a Grid Computing
  Environment</title><categories>cs.DC cs.NA</categories><comments>Accepted at IPDPS10. (IEEE International Parallel &amp; Distributed
  Processing Symposium 2010 in Atlanta, GA, USA.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous studies have reported that common dense linear algebra operations do
not achieve speed up by using multiple geographical sites of a computational
grid. Because such operations are the building blocks of most scientific
applications, conventional supercomputers are still strongly predominant in
high-performance computing and the use of grids for speeding up large-scale
scientific problems is limited to applications exhibiting parallelism at a
higher level. We have identified two performance bottlenecks in the distributed
memory algorithms implemented in ScaLAPACK, a state-of-the-art dense linear
algebra library. First, because ScaLAPACK assumes a homogeneous communication
network, the implementations of ScaLAPACK algorithms lack locality in their
communication pattern. Second, the number of messages sent in the ScaLAPACK
algorithms is significantly greater than other algorithms that trade flops for
communication. In this paper, we present a new approach for computing a QR
factorization -- one of the main dense linear algebra kernels -- of tall and
skinny matrices in a grid computing environment that overcomes these two
bottlenecks. Our contribution is to articulate a recently proposed algorithm
(Communication Avoiding QR) with a topology-aware middleware (QCG-OMPI) in
order to confine intensive communications (ScaLAPACK calls) within the
different geographical sites. An experimental study conducted on the Grid'5000
platform shows that the resulting performance increases linearly with the
number of geographical sites on large-scale problems (and is in particular
consistently higher than ScaLAPACK's).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2577</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2577</id><created>2009-12-14</created><authors><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Global Alignment of Molecular Sequences via Ancestral State
  Reconstruction</title><categories>math.PR cs.DS math.ST q-bio.PE q-bio.QM stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular phylogenetic techniques do not generally account for such common
evolutionary events as site insertions and deletions (known as indels). Instead
tree building algorithms and ancestral state inference procedures typically
rely on substitution-only models of sequence evolution. In practice these
methods are extended beyond this simplified setting with the use of heuristics
that produce global alignments of the input sequences--an important problem
which has no rigorous model-based solution. In this paper we consider a new
version of the multiple sequence alignment in the context of stochastic indel
models. More precisely, we introduce the following {\em trace reconstruction
problem on a tree} (TRPT): a binary sequence is broadcast through a tree
channel where we allow substitutions, deletions, and insertions; we seek to
reconstruct the original sequence from the sequences received at the leaves of
the tree. We give a recursive procedure for this problem with strong
reconstruction guarantees at low mutation rates, providing also an alignment of
the sequences at the leaves of the tree. The TRPT problem without indels has
been studied in previous work (Mossel 2004, Daskalakis et al. 2006) as a
bootstrapping step towards obtaining optimal phylogenetic reconstruction
methods. The present work sets up a framework for extending these works to
evolutionary models with indels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2601</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2601</id><created>2009-12-14</created><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author><author><keyname>Costantini</keyname><forenames>Antonio</forenames></author></authors><title>The first Italian research assessment exercise: a bibliometric
  perspective</title><categories>cs.CY cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In December 2003, seventeen years after the first UK research assessment
exercise, Italy started up its first-ever national research evaluation, with
the aim to evaluate, using the peer review method, the excellence of the
national research production. The evaluation involved 20 disciplinary areas,
102 research structures, 18,500 research products and 6,661 peer reviewers
(1,465 from abroad); it had a direct cost of 3.55 millions Euros and a time
length spanning over 18 months. The introduction of ratings based on ex post
quality of output and not on ex ante respect for parameters and compliance is
an important leap forward of the national research evaluation system toward
meritocracy. From the bibliometric perspective, the national assessment offered
the unprecedented opportunity to perform a large-scale comparison of peer
review and bibliometric indicators for an important share of the Italian
research production. The present investigation takes full advantage of this
opportunity to test whether peer review judgements and (article and journal)
bibliometric indicators are independent variables and, in the negative case, to
measure the sign and strength of the association. Outcomes allow us to advocate
the use of bibliometric evaluation, suitably integrated with expert review, for
the forthcoming national assessment exercises, with the goal of shifting from
the assessment of research excellence to the evaluation of average research
performance without significant increase of expenses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2607</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2607</id><created>2009-12-14</created><updated>2012-10-04</updated><authors><author><keyname>Grenet</keyname><forenames>Bruno</forenames><affiliation>LIP</affiliation></author><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author><author><keyname>Portier</keyname><forenames>Natacha</forenames><affiliation>LIP</affiliation></author></authors><title>The Multivariate Resultant is NP-hard in any Characteristic</title><categories>cs.CC</categories><comments>13 pages</comments><proxy>ccsd</proxy><report-no>RRLIP2009-34</report-no><journal-ref>Dans Mathematical Foundations of Computer Science 2010 -
  Mathematical Foundations of Computer Science 2010, Brno : Czech Republic
  (2010)</journal-ref><doi>10.1007/978-3-642-15155-2_42</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multivariate resultant is a fundamental tool of computational algebraic
geometry. It can in particular be used to decide whether a system of n
homogeneous equations in n variables is satisfiable (the resultant is a
polynomial in the system's coefficients which vanishes if and only if the
system is satisfiable). In this paper we present several NP-hardness results
for testing whether a multivariate resultant vanishes, or equivalently for
deciding whether a square system of homogeneous equations is satisfiable. Our
main result is that testing the resultant for zero is NP-hard under
deterministic reductions in any characteristic, for systems of low-degree
polynomials with coefficients in the ground field (rather than in an
extension). We also observe that in characteristic zero, this problem is in the
Arthur-Merlin class AM if the generalized Riemann hypothesis holds true. In
positive characteristic, the best upper bound remains PSPACE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2625</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2625</id><created>2009-12-14</created><updated>2010-02-03</updated><authors><author><keyname>Kuske</keyname><forenames>Dietrich</forenames></author></authors><title>Is Ramsey's theorem omega-automatic?</title><categories>cs.LO cs.DM cs.FL</categories><acm-class>F.4.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study the existence of infinite cliques in omega-automatic (hyper-)graphs.
It turns out that the situation is much nicer than in general uncountable
graphs, but not as nice as for automatic graphs.
  More specifically, we show that every uncountable omega-automatic graph
contains an uncountable co-context-free clique or anticlique, but not
necessarily a context-free (let alone regular) clique or anticlique. We also
show that uncountable omega-automatic ternary hypergraphs need not have
uncountable cliques or anticliques at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2630</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2630</id><created>2009-12-14</created><updated>2011-09-19</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Transmission Capacity of Ad-hoc Networks with Multiple Antennas using
  Transmit Stream Adaptation and Interference Cancelation</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory,
  Sept 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transmission capacity of an ad-hoc network is the maximum density of
active transmitters per unit area, given an outage constraint at each receiver
for a fixed rate of transmission. Assuming that the transmitter locations are
distributed as a Poisson point process, this paper derives upper and lower
bounds on the transmission capacity of an ad-hoc network when each node is
equipped with multiple antennas. The transmitter either uses eigen multi-mode
beamforming or a subset of its antennas to transmit multiple data streams,
while the receiver uses partial zero forcing to cancel certain interferers
using some of its spatial receive degrees of freedom (SRDOF). The receiver
either cancels the nearest interferers or those interferers that maximize the
post-cancelation signal-to-interference ratio. Using the obtained bounds, the
optimal number of data streams to transmit, and the optimal SRDOF to use for
interference cancelation are derived that provide the best scaling of the
transmission capacity with the number of antennas. With beamforming, single
data stream transmission together with using all but one SRDOF for interference
cancelation is optimal, while without beamforming, single data stream
transmission together with using a fraction of the total SRDOF for interference
cancelation is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2652</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2652</id><created>2009-12-14</created><updated>2011-10-14</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author></authors><title>A complex analogue of Toda's Theorem</title><categories>math.AG cs.CC math.AT math.CO</categories><comments>31 pages. Final version to appear in Foundations of Computational
  Mathematics</comments><msc-class>14F25, 14Q20 (Primary), 68Q15 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Toda \cite{Toda} proved in 1989 that the (discrete) polynomial time
hierarchy, $\mathbf{PH}$, is contained in the class $\mathbf{P}^{#\mathbf{P}}$,
namely the class of languages that can be decided by a Turing machine in
polynomial time given access to an oracle with the power to compute a function
in the counting complexity class $#\mathbf{P}$. This result, which illustrates
the power of counting is considered to be a seminal result in computational
complexity theory. An analogous result (with a compactness hypothesis) in the
complexity theory over the reals (in the sense of Blum-Shub-Smale real machines
\cite{BSS89}) was proved in \cite{BZ09}. Unlike Toda's proof in the discrete
case, which relied on sophisticated combinatorial arguments, the proof in
\cite{BZ09} is topological in nature in which the properties of the topological
join is used in a fundamental way. However, the constructions used in
\cite{BZ09} were semi-algebraic -- they used real inequalities in an essential
way and as such do not extend to the complex case. In this paper, we extend the
techniques developed in \cite{BZ09} to the complex projective case. A key role
is played by the complex join of quasi-projective complex varieties. As a
consequence we obtain a complex analogue of Toda's theorem. The results
contained in this paper, taken together with those contained in \cite{BZ09},
illustrate the central role of the Poincar\'e polynomial in algorithmic
algebraic geometry, as well as, in computational complexity theory over the
complex and real numbers -- namely, the ability to compute it efficiently
enables one to decide in polynomial time all languages in the (compact)
polynomial hierarchy over the appropriate field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2706</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2706</id><created>2009-12-14</created><updated>2010-01-21</updated><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>On the theory of moveable objects</title><categories>cs.HC cs.GR</categories><comments>30 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User-driven applications belong to the new type of programs, in which users
get the full control of WHAT, WHEN, and HOW must appear on the screen. Such
programs can exist only if the screen view is organized not according with the
predetermined scenario, written by the developers, but if any screen object can
be moved, resized, and reconfigured by any user at any moment. This article
describes the algorithm, by which an object of an arbitrary shape can be turned
into moveable and resizable. It also explains some rules of such design and the
technique, which can be useful in many cases. Both the individual movements of
objects and their synchronous movements are analysed. After discussing the
individually moveable controls, different types of groups are analysed and the
arbitrary grouping of controls is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2709</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2709</id><created>2009-12-14</created><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author></authors><title>The Gaussian Surface Area and Noise Sensitivity of Degree-$d$
  Polynomials</title><categories>cs.CC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide asymptotically sharp bounds for the Gaussian surface area and the
Gaussian noise sensitivity of polynomial threshold functions. In particular we
show that if $f$ is a degree-$d$ polynomial threshold function, then its
Gaussian sensitivity at noise rate $\epsilon$ is less than some quantity
asymptotic to $\frac{d\sqrt{2\epsilon}}{\pi}$ and the Gaussian surface area is
at most $\frac{d}{\sqrt{2\pi}}$. Furthermore these bounds are asymptotically
tight as $\epsilon\to 0$ and $f$ the threshold function of a product of $d$
distinct homogeneous linear functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2737</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2737</id><created>2009-12-14</created><updated>2011-09-12</updated><authors><author><keyname>Cubitt</keyname><forenames>Toby S.</forenames></author><author><keyname>Smith</keyname><forenames>Graeme</forenames></author></authors><title>An Extreme form of Superactivation for Quantum Zero-Error Capacities</title><categories>quant-ph cs.IT math.IT</categories><comments>V1: 18 pages, single column. V2: title changed; includes additional
  explanation; 9 pages, 2 column</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The zero-error capacity of a channel is the rate at which it can send
information perfectly, with zero probability of error, and has long been
studied in classical information theory. We show that the zero-error capacity
of quantum channels exhibits an extreme form of non-additivity, one which is
not possible for classical channels, or even for the usual capacities of
quantum channels. By combining probabilistic arguments with algebraic geometry,
we prove that there exist channels E1 and E2 with no zero-error classical
capacity whatsoever, C_0(E1) = C_0(E2) = 0, but whose joint zero-error quantum
capacity is positive, Q_0(E1 x E2) &gt;= 1. This striking effect is an extreme
from of the superactivation phenomenon, as it implies that both the classical
and quantum zero-error capacities of these channels can be superactivated
simultaneously, whilst being a strictly stronger property of capacities.
Superactivation of the quantum zero-error capacity was not previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2785</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2785</id><created>2009-12-14</created><authors><author><keyname>Ciardo</keyname><forenames>Gianfranco</forenames><affiliation>University of California, Riverside</affiliation></author><author><keyname>Zhao</keyname><forenames>Yang</forenames><affiliation>University of California, Riverside</affiliation></author><author><keyname>Jin</keyname><forenames>Xiaoqing</forenames><affiliation>University of California, Riverside</affiliation></author></authors><title>Parallel symbolic state-space exploration is difficult, but what is the
  alternative?</title><categories>cs.LO cs.DC</categories><journal-ref>EPTCS 14, 2009, pp. 1-17</journal-ref><doi>10.4204/EPTCS.14.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-space exploration is an essential step in many modeling and analysis
problems. Its goal is to find the states reachable from the initial state of a
discrete-state model described. The state space can used to answer important
questions, e.g., &quot;Is there a dead state?&quot; and &quot;Can N become negative?&quot;, or as a
starting point for sophisticated investigations expressed in temporal logic.
  Unfortunately, the state space is often so large that ordinary explicit data
structures and sequential algorithms cannot cope, prompting the exploration of
(1) parallel approaches using multiple processors, from simple workstation
networks to shared-memory supercomputers, to satisfy large memory and runtime
requirements and (2) symbolic approaches using decision diagrams to encode the
large structured sets and relations manipulated during state-space generation.
  Both approaches have merits and limitations. Parallel explicit state-space
generation is challenging, but almost linear speedup can be achieved; however,
the analysis is ultimately limited by the memory and processors available.
Symbolic methods are a heuristic that can efficiently encode many, but not all,
functions over a structured and exponentially large domain; here the pitfalls
are subtler: their performance varies widely depending on the class of decision
diagram chosen, the state variable order, and obscure algorithmic parameters.
  As symbolic approaches are often much more efficient than explicit ones for
many practical models, we argue for the need to parallelize symbolic
state-space generation algorithms, so that we can realize the advantage of both
approaches. This is a challenging endeavor, as the most efficient symbolic
algorithm, Saturation, is inherently sequential. We conclude by discussing
challenges, efforts, and promising directions toward this goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2813</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2813</id><created>2009-12-15</created><updated>2010-04-10</updated><authors><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames></author></authors><title>Combining Partial Order Alignment and Progressive Near-Optimal Alignment</title><categories>cs.DS</categories><comments>Since the draft was too sketchy to be useful, I has decided to
  withdraw.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, I proposed to utilize partial-order alignment technique as a
heuristic method to cope with the state-space explosion problem in progressive
near-optimal alignment. The key idea of my approach is a formal treatment of
progressive partial order alignment based on the graph product construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2815</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2815</id><created>2009-12-15</created><updated>2010-02-03</updated><authors><author><keyname>Peleg</keyname><forenames>David</forenames></author><author><keyname>Roditty</keyname><forenames>Liam</forenames></author></authors><title>Relaxed spanners for directed disk graphs</title><categories>cs.DS cs.CG</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Let $(V,\delta)$ be a finite metric space, where $V$ is a set of $n$ points
and $\delta$ is a distance function defined for these points. Assume that
$(V,\delta)$ has a constant doubling dimension $d$ and assume that each point
$p\in V$ has a disk of radius $r(p)$ around it. The disk graph that corresponds
to $V$ and $r(\cdot)$ is a \emph{directed} graph $I(V,E,r)$, whose vertices are
the points of $V$ and whose edge set includes a directed edge from $p$ to $q$
if $\delta(p,q)\leq r(p)$. In \cite{PeRo08} we presented an algorithm for
constructing a $(1+\eps)$-spanner of size $O(n/\eps^d \log M)$, where $M$ is
the maximal radius $r(p)$. The current paper presents two results. The first
shows that the spanner of \cite{PeRo08} is essentially optimal, i.e., for
metrics of constant doubling dimension it is not possible to guarantee a
spanner whose size is independent of $M$. The second result shows that by
slightly relaxing the requirements and allowing a small perturbation of the
radius assignment, considerably better spanners can be constructed. In
particular, we show that if it is allowed to use edges of the disk graph
$I(V,E,r_{1+\eps})$, where $r_{1+\eps}(p) = (1+\eps)\cdot r(p)$ for every $p\in
V$, then it is possible to get a $(1+\eps)$-spanner of size $O(n/\eps^d)$ for
$I(V,E,r)$. Our algorithm is simple and can be implemented efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2820</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2820</id><created>2009-12-15</created><updated>2010-08-11</updated><authors><author><keyname>Appuswamy</keyname><forenames>Rathinakumar</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author><author><keyname>Karamchandani</keyname><forenames>Nikhil</forenames></author><author><keyname>Zeger</keyname><forenames>Ken</forenames></author></authors><title>Network Coding for Computing: Cut-Set Bounds</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory (Special
  Issue on Facets of Coding Theory: from Algorithms to Networks); Revised on
  Aug 9, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following \textit{network computing} problem is considered. Source nodes
in a directed acyclic network generate independent messages and a single
receiver node computes a target function $f$ of the messages. The objective is
to maximize the average number of times $f$ can be computed per network usage,
i.e., the ``computing capacity''. The \textit{network coding} problem for a
single-receiver network is a special case of the network computing problem in
which all of the source messages must be reproduced at the receiver. For
network coding with a single receiver, routing is known to achieve the capacity
by achieving the network \textit{min-cut} upper bound. We extend the definition
of min-cut to the network computing problem and show that the min-cut is still
an upper bound on the maximum achievable rate and is tight for computing (using
coding) any target function in multi-edge tree networks and for computing
linear target functions in any network. We also study the bound's tightness for
different classes of target functions. In particular, we give a lower bound on
the computing capacity in terms of the Steiner tree packing number and a
different bound for symmetric functions. We also show that for certain networks
and target functions, the computing capacity can be less than an arbitrarily
small fraction of the min-cut bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2822</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2822</id><created>2009-12-15</created><authors><author><keyname>Mayer</keyname><forenames>Gerhard</forenames></author></authors><title>Data management in Systems biology II - Outlook towards the semantic web</title><categories>cs.DB q-bio.OT</categories><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The benefit of using ontologies, defined by the respective data standards, is
shown. It is presented how ontologies can be used for the semantic enrichment
of data and how this can contribute to the vision of the semantic web to become
true. The problems existing today on the way to a true semantic web are
pinpointed, different semantic web standards, tools and development frameworks
are overlooked and an outlook towards artificial intelligence and agents for
searching and mining the data in the semantic web are given, paving the way
from data management to information and in the end true knowledge management
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2826</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2826</id><created>2009-12-15</created><authors><author><keyname>Gargiulo</keyname><forenames>Floriana</forenames></author><author><keyname>Ternes</keyname><forenames>Sonia</forenames></author><author><keyname>Huet</keyname><forenames>Sylvie</forenames></author><author><keyname>Deffuant</keyname><forenames>Guillaume</forenames></author></authors><title>An iterative approach for generating statistically realistic populations
  of households</title><categories>cs.MA cs.CY</categories><comments>16 oages, 11 figures</comments><doi>10.1371/journal.pone.0008828</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Many different simulation frameworks, in different topics, need
to treat realistic datasets to initialize and calibrate the system. A precise
reproduction of initial states is extremely important to obtain reliable
forecast from the model. Methodology/Principal Findings: This paper proposes an
algorithm to create an artificial population where individuals are described by
their age, and are gathered in households respecting a variety of statistical
constraints (distribution of household types, sizes, age of household head,
difference of age between partners and among parents and children). Such a
population is often the initial state of microsimulation or (agent)
individual-based models. To get a realistic distribution of households is often
very important, because this distribution has an impact on the demographic
evolution. Usual techniques from microsimulation approach cross different
sources of aggregated data for generating individuals. In our case the number
of combinations of different households (types, sizes, age of participants)
makes it computationally difficult to use directly such methods. Hence we
developed a specific algorithm to make the problem more easily tractable.
Conclusions/Significance: We generate the populations of two pilot
municipalities in Auvergne region (France), to illustrate the approach. The
generated populations show a good agreement with the available statistical
datasets (not used for the generation) and are obtained in a reasonable
computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2828</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2828</id><created>2009-12-15</created><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>Pulse Shaping, Localization and the Approximate Eigenstructure of LTV
  Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, invited paper</comments><journal-ref>Proc. IEEE WCNC 2008, p.1114-1119</journal-ref><doi>10.1109/WCNC.2008.201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we show the relation between the theory of pulse shaping for
WSSUS channels and the notion of approximate eigenstructure for time-varying
channels. We consider pulse shaping for a general signaling scheme, called
Weyl-Heisenberg signaling, which includes OFDM with cyclic prefix and
OFDM/OQAM. The pulse design problem in the view of optimal WSSUS--averaged SINR
is an interplay between localization and &quot;orthogonality&quot;. The localization
problem itself can be expressed in terms of eigenvalues of localization
operators and is intimately connected to the concept of approximate
eigenstructure of LTV channel operators. In fact, on the L_2-level both are
equivalent as we will show. The concept of &quot;orthogonality&quot; in turn can be
related to notion of tight frames. The right balance between these two sides is
still an open problem. However, several statements on achievable values of
certain localization measures and fundamental limits on SINR can already be
made as will be shown in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2843</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2843</id><created>2009-12-15</created><updated>2010-05-30</updated><authors><author><keyname>Nallusamy</keyname><forenames>R.</forenames></author><author><keyname>Jayarajan</keyname><forenames>K.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Intrusion Detection In Mobile Ad Hoc Networks Using GA Based Feature
  Selection</title><categories>cs.NE cs.CR cs.LG</categories><comments>This paper has been withdrawn by the authors. To improve the quality
  of the paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile ad hoc networking (MANET) has become an exciting and important
technology in recent years because of the rapid proliferation of wireless
devices. MANETs are highly vulnerable to attacks due to the open medium,
dynamically changing network topology and lack of centralized monitoring point.
It is important to search new architecture and mechanisms to protect the
wireless networks and mobile computing application. IDS analyze the network
activities by means of audit data and use patterns of well-known attacks or
normal profile to detect potential attacks. There are two methods to analyze:
misuse detection and anomaly detection. Misuse detection is not effective
against unknown attacks and therefore, anomaly detection method is used. In
this approach, the audit data is collected from each mobile node after
simulating the attack and compared with the normal behavior of the system. If
there is any deviation from normal behavior then the event is considered as an
attack. Some of the features of collected audit data may be redundant or
contribute little to the detection process. So it is essential to select the
important features to increase the detection rate. This paper focuses on
implementing two feature selection methods namely, markov blanket discovery and
genetic algorithm. In genetic algorithm, bayesian network is constructed over
the collected features and fitness function is calculated. Based on the fitness
value the features are selected. Markov blanket discovery also uses bayesian
network and the features are selected depending on the minimum description
length. During the evaluation phase, the performances of both approaches are
compared based on detection rate and false alarm rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2846</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2846</id><created>2009-12-15</created><authors><author><keyname>Dovier</keyname><forenames>Agostino</forenames></author><author><keyname>Formisano</keyname><forenames>Andrea</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author></authors><title>Multi-valued Action Languages in CLP(FD)</title><categories>cs.AI cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Action description languages, such as A and B, are expressive instruments
introduced for formalizing planning domains and planning problem instances. The
paper starts by proposing a methodology to encode an action language (with
conditional effects and static causal laws), a slight variation of B, using
Constraint Logic Programming over Finite Domains. The approach is then
generalized to raise the use of constraints to the level of the action language
itself. A prototype implementation has been developed, and the preliminary
results are presented and discussed.
  To appear in Theory and Practice of Logic Programming (TPLP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2861</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2861</id><created>2009-12-15</created><authors><author><keyname>Ventura</keyname><forenames>Artur</forenames></author></authors><title>JSC : A JavaScript Object System</title><categories>cs.PL</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The JSC language is a superset of JavaScript designed to ease the development
of large web applications. This language extends JavaScripts own object system
by isolating code in a class declaration, simplifying multiple inheritance and
using method implementation agreements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2881</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2881</id><created>2009-12-15</created><updated>2009-12-16</updated><authors><author><keyname>Lemnitzer</keyname><forenames>Lothar</forenames><affiliation>INRIA Saclay - Ile de France, IDSL</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Saclay - Ile de France, IDSL</affiliation></author><author><keyname>Witt</keyname><forenames>Andreas</forenames></author></authors><title>Representing human and machine dictionaries in Markup languages</title><categories>cs.CL</categories><proxy>ccsd inria-00441215</proxy><journal-ref>Dictionaries. An International Encyclopedia of Lexicography.
  Supplementary volume: Recent developments with special focus on computational
  lexicography, Ulrich Heid (Ed.) (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter we present the main issues in representing machine readable
dictionaries in XML, and in particular according to the Text Encoding
Dictionary (TEI) guidelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2952</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2952</id><created>2009-12-15</created><authors><author><keyname>Svenningsson</keyname><forenames>Josef</forenames></author><author><keyname>Sands</keyname><forenames>David</forenames></author></authors><title>Specification and Verification of Side Channel Declassification</title><categories>cs.CR</categories><report-no>2009-13</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Side channel attacks have emerged as a serious threat to the security of both
networked and embedded systems -- in particular through the implementations of
cryptographic operations. Side channels can be difficult to model formally, but
with careful coding and program transformation techniques it may be possible to
verify security in the presence of specific side-channel attacks. But what if a
program intentionally makes a tradeoff between security and efficiency and
leaks some information through a side channel? In this paper we study such
tradeoffs using ideas from recent research on declassification. We present a
semantic model of security for programs which allow for declassification
through side channels, and show how side-channel declassification can be
verified using off-the-shelf software model checking tools. Finally, to make it
simpler for verifiers to check that a program conforms to a particular
side-channel declassification policy we introduce a further tradeoff between
efficiency and verifiability: by writing programs in a particular &quot;manifest
form&quot; security becomes considerably easier to verify.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2979</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2979</id><created>2009-12-15</created><updated>2009-12-17</updated><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames><affiliation>KAIST</affiliation></author><author><keyname>Goaoc</keyname><forenames>Xavier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Nicaud</keyname><forenames>Cyril</forenames><affiliation>IGM</affiliation></author></authors><title>Set Systems and Families of Permutations with Small Traces</title><categories>cs.DM cs.CG</categories><proxy>ccsd inria-00441376</proxy><report-no>RR-7154</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the maximum size of a set system on $n$ elements whose trace on any
$b$ elements has size at most $k$. We show that if for some $b \ge i \ge 0$ the
shatter function $f_R$ of a set system $([n],R)$ satisfies $f_R(b) &lt;
2^i(b-i+1)$ then $|R| = O(n^i)$; this generalizes Sauer's Lemma on the size of
set systems with bounded VC-dimension. We use this bound to delineate the main
growth rates for the same problem on families of permutations, where the trace
corresponds to the inclusion for permutations. This is related to a question of
Raz on families of permutations with bounded VC-dimension that generalizes the
Stanley-Wilf conjecture on permutations with excluded patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.2986</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.2986</id><created>2009-12-15</created><updated>2011-01-18</updated><authors><author><keyname>Ranestad</keyname><forenames>Kristian</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author></authors><title>On the convex hull of a space curve</title><categories>math.AG cs.CG</categories><comments>19 pages, 4 figures, minor changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The boundary of the convex hull of a compact algebraic curve in real 3-space
defines a real algebraic surface. For general curves, that boundary surface is
reducible, consisting of tritangent planes and a scroll of stationary
bisecants. We express the degree of this surface in terms of the degree, genus
and singularities of the curve. We present algorithms for computing their
defining polynomials, and we exhibit a wide range of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3004</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3004</id><created>2009-12-15</created><authors><author><keyname>Cheilaris</keyname><forenames>Panagiotis</forenames></author><author><keyname>Toth</keyname><forenames>Geza</forenames></author></authors><title>Graph unique-maximum and conflict-free colorings</title><categories>cs.DM cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the relationship between two kinds of vertex colorings of
graphs: unique-maximum colorings and conflict-free colorings. In a
unique-maximum coloring, the colors are ordered, and in every path of the graph
the maximum color appears only once. In a conflict-free coloring, in every path
of the graph there is a color that appears only once. We also study
computational complexity aspects of conflict-free colorings and prove a
completeness result. Finally, we improve lower bounds for those chromatic
numbers of the grid graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3016</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3016</id><created>2009-12-15</created><authors><author><keyname>Kawamura</keyname><forenames>Akitoshi</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Tokuyama</keyname><forenames>Takeshi</forenames></author></authors><title>Zone Diagrams in Euclidean Spaces and in Other Normed Spaces</title><categories>cs.CG math.MG</categories><comments>Title page + 16 pages, 20 figures</comments><acm-class>F.2.2; G.0; F.0</acm-class><journal-ref>Mathematische Annalen 354(4):1201-1221, 2012</journal-ref><doi>10.1007/s00208-011-0761-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zone diagram is a variation on the classical concept of a Voronoi diagram.
Given n sites in a metric space that compete for territory, the zone diagram is
an equilibrium state in the competition. Formally it is defined as a fixed
point of a certain &quot;dominance&quot; map.
  Asano, Matousek, and Tokuyama proved the existence and uniqueness of a zone
diagram for point sites in Euclidean plane, and Reem and Reich showed existence
for two arbitrary sites in an arbitrary metric space. We establish existence
and uniqueness for n disjoint compact sites in a Euclidean space of arbitrary
(finite) dimension, and more generally, in a finite-dimensional normed space
with a smooth and rotund norm. The proof is considerably simpler than that of
Asano et al. We also provide an example of non-uniqueness for a norm that is
rotund but not smooth. Finally, we prove existence and uniqueness for two point
sites in the plane with a smooth (but not necessarily rotund) norm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3029</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3029</id><created>2009-12-15</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Interference Alignment and a Noisy Interference Regime for Many-to-One
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>21 pages. Partially presented at 47th Allerton Conference on
  Communication, Control, and Computing, Sep, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the capacity of discrete memoryless many-to-one interference
channels, i.e., K user interference channels where only one receiver faces
interference. For a class of many-to-one interference channels, we identify a
noisy interference regime, i.e., a regime where random coding and treating
interference as noise achieves sum-capacity. Specializing our results to the
Gaussian MIMO many-to-one interference channel, which is a special case of the
class of channels considered, we obtain new capacity results. Firstly, we
extend the noisy interference regime, previously studied for (many-to-one)
interference channels with average power constraints on the inputs, to a more
general class of inputs. This more general class includes the practical
scenario of inputs being restricted to fixed finite-size constellations such as
PSK or QAM. Secondly, we extend noisy interference results previously studied
in SISO interference channels with full channel state information (CSI) at all
nodes, to MIMO and parallel Gaussian many-to-one interference channels, and to
fading Gaussian many-to-one interference channels without CSI at the
transmitters. While the many-to-one interference channel requires interference
alignment, which in turn requires structured codes in general, we argue that in
the noisy interference regime, interference is implicitly aligned by random
coding irrespective of the input distribution. As a byproduct of our study, we
identify a second class of many-to-one interference channels (albeit
deterministic) where random coding is optimal (though interference is not
treated as noise). The optimality of random coding in this second class of
channels is due to an interference resolvability condition which precludes
interference alignment and hence obviates the need of structured codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3036</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3036</id><created>2009-12-15</created><authors><author><keyname>Brim</keyname><forenames>Lubos</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames><affiliation>University of Twente</affiliation></author></authors><title>Proceedings 8th International Workshop on Parallel and Distributed
  Methods in verifiCation</title><categories>cs.LO cs.CE cs.DC cs.SE</categories><journal-ref>EPTCS 14, 2009</journal-ref><doi>10.4204/EPTCS.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 8th International Workshop on Parallel and Distributed Methods in
verifiCation (PDMC 2009) took place on November 4, 2009 at the Eindhoven
University of Technology, in conjunction with Formal Methods 2009 and other
related events for the first time under the heading of Formal Methods Week.
This volume contains the final workshop proceedings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3050</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3050</id><created>2009-12-15</created><updated>2009-12-21</updated><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Breaking a modified substitution-diffusion image cipher based on chaotic
  standard and logistic maps</title><categories>cs.CR cs.MM</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, an image encryption scheme based on chaotic standard and logistic
maps was proposed by Patidar et al. It was later reported by Rhouma et al. that
an equivalent secret key can be reconstructed with only one
known/chosen-plaintext and the corresponding ciphertext. Patidar et al. soon
modified the original scheme and claimed that the modified scheme is secure
against Rhouma et al.'s attack. In this paper, we point out that the modified
scheme is still insecure against the same known/chosen-plaintext attack. In
addition, some other security defects existing in both the original and the
modified schemes are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3067</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3067</id><created>2009-12-16</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author><author><keyname>Yang</keyname><forenames>Seung-Hwan</forenames></author></authors><title>A Recursive Formula for Power Moments of 2-Dimensional Kloosterman Sums
  Assiciated with General Linear Groups</title><categories>math.NT cs.IT math.IT</categories><comments>9 pages</comments><msc-class>11T23; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct a binary linear code connected with the
Kloosterman sum for $GL(2,q)$. Here $q$ is a power of two. Then we obtain a
recursive formula generating the power moments 2-dimensional Kloosterman sum,
equivalently that generating the even power moments of Kloosterman sum in terms
of the frequencies of weights in the code. This is done via Pless power moment
identity and by utilizing the explicit expression of the Kloosterman sum for
$GL(2,q)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3089</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3089</id><created>2009-12-16</created><updated>2010-06-28</updated><authors><author><keyname>Duan</keyname><forenames>Lingjie</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Shou</keyname><forenames>Biying</forenames></author></authors><title>Investment and Pricing with Spectrum Uncertainty: A Cognitive Operator's
  Perspective</title><categories>cs.NI</categories><comments>A shorter version appears in IEEE INFOCOM 2010. This version has been
  submitted to IEEE Transactions on Mobile Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the optimal investment and pricing decisions of a
cognitive mobile virtual network operator (C-MVNO) under spectrum supply
uncertainty. Compared with a traditional MVNO who often leases spectrum via
long-term contracts, a C-MVNO can acquire spectrum dynamically in short-term by
both sensing the empty &quot;spectrum holes&quot; of licensed bands and dynamically
leasing from the spectrum owner. As a result, a C-MVNO can make flexible
investment and pricing decisions to match the current demands of the secondary
unlicensed users. Compared to dynamic spectrum leasing, spectrum sensing is
typically cheaper, but the obtained useful spectrum amount is random due to
primary licensed users' stochastic traffic. The C-MVNO needs to determine the
optimal amounts of spectrum sensing and leasing by evaluating the trade off
between cost and uncertainty. The C-MVNO also needs to determine the optimal
price to sell the spectrum to the secondary unlicensed users, taking into
account wireless heterogeneity of users such as different maximum transmission
power levels and channel gains. We model and analyze the interactions between
the C-MVNO and secondary unlicensed users as a Stackelberg game. We show
several interesting properties of the network equilibrium, including threshold
structures of the optimal investment and pricing decisions, the independence of
the optimal price on users' wireless characteristics, and guaranteed fair and
predictable QoS among users. We prove that these properties hold for general
SNR regime and general continuous distributions of sensing uncertainty. We show
that spectrum sensing can significantly improve the C-MVNO's expected profit
and users' payoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3097</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3097</id><created>2009-12-16</created><authors><author><keyname>VanderZee</keyname><forenames>Evan</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Guoy</keyname><forenames>Damrong</forenames></author><author><keyname>Zharnitsky</keyname><forenames>Vadim</forenames></author><author><keyname>Ramos</keyname><forenames>Edgar</forenames></author></authors><title>Geometric and Combinatorial Properties of Well-Centered Triangulations
  in Three and Higher Dimensions</title><categories>cs.CG cs.DM</categories><comments>Approximately 30 pages. Contains 25 figures. Some figures include
  multiple graphics</comments><acm-class>G.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An n-simplex is said to be n-well-centered if its circumcenter lies in its
interior. We introduce several other geometric conditions and an algebraic
condition that can be used to determine whether a simplex is n-well-centered.
These conditions, together with some other observations, are used to describe
restrictions on the local combinatorial structure of simplicial meshes in which
every simplex is well-centered. In particular, it is shown that in a
3-well-centered (2-well-centered) tetrahedral mesh there are at least 7 (9)
edges incident to each interior vertex, and these bounds are sharp. Moreover,
it is shown that, in stark contrast to the 2-dimensional analog, where there
are exactly two vertex links that prevent a well-centered triangle mesh in R^2,
there are infinitely many vertex links that prohibit a well-centered
tetrahedral mesh in R^3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3098</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3098</id><created>2009-12-16</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Salah</keyname><forenames>Alkim Almila Akdag</forenames></author></authors><title>Maps on the basis of the Arts &amp; Humanities Citation Index: The journals
  Leonardo and Art Journal versus &quot;Digital Humanities&quot; as a topic</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The possibilities of using the Arts &amp; Humanities Citation Index (A&amp;HCI) for
journal mapping have not been sufficiently recognized because of the absence of
a Journal Citations Report (JCR) for this database. A quasi-JCR for the A&amp;HCI
(2008) was constructed from the data contained in the Web-of-Science and is
used for the evaluation of two journals as examples: Leonardo and Art Journal.
The maps on the basis of the aggregated journal-journal citations within this
domain can be compared with maps including references to journals in the
Science Citation Index and Social Science Citation Index. Art journals are
cited by (social) science journals more than by other art journals, but these
journals draw upon one another in terms of their own references. This cultural
impact in terms of being cited is not found when documents with a topic such as
&quot;digital humanities&quot; are analyzed. This community of practice functions more as
an intellectual organizer than a journal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3134</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3134</id><created>2009-12-16</created><updated>2010-06-28</updated><authors><author><keyname>Creignou</keyname><forenames>Nadia</forenames></author><author><keyname>Schmidt</keyname><forenames>Johannes</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author></authors><title>Complexity of Propositional Abduction for Restricted Sets of Boolean
  Functions</title><categories>cs.CC cs.AI cs.LO</categories><comments>Proceedings version, the journal version is available at
  http://arxiv.org/abs/1006.4923</comments><acm-class>F.2.2; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abduction is a fundamental and important form of non-monotonic reasoning.
Given a knowledge base explaining how the world behaves it aims at finding an
explanation for some observed manifestation. In this paper we focus on
propositional abduction, where the knowledge base and the manifestation are
represented by propositional formulae. The problem of deciding whether there
exists an explanation has been shown to be SigmaP2-complete in general. We
consider variants obtained by restricting the allowed connectives in the
formulae to certain sets of Boolean functions. We give a complete
classification of the complexity for all considerable sets of Boolean
functions. In this way, we identify easier cases, namely NP-complete and
polynomial cases; and we highlight sources of intractability. Further, we
address the problem of counting the explanations and draw a complete picture
for the counting complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3162</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3162</id><created>2009-12-16</created><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames></author><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Kouck&#xfd;</keyname><forenames>Michal</forenames></author><author><keyname>Loff</keyname><forenames>Bruno</forenames></author></authors><title>Derandomizing from Random Strings</title><categories>cs.CC</categories><acm-class>F.1.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we show that BPP is truth-table reducible to the set of
Kolmogorov random strings R_K. It was previously known that PSPACE, and hence
BPP is Turing-reducible to R_K. The earlier proof relied on the adaptivity of
the Turing-reduction to find a Kolmogorov-random string of polynomial length
using the set R_K as oracle. Our new non-adaptive result relies on a new
fundamental fact about the set R_K, namely each initial segment of the
characteristic sequence of R_K is not compressible by recursive means. As a
partial converse to our claim we show that strings of high
Kolmogorov-complexity when used as advice are not much more useful than
randomly chosen strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3188</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3188</id><created>2009-12-16</created><updated>2010-02-03</updated><authors><author><keyname>Chechik</keyname><forenames>Shiri</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author></authors><title>Robust Fault Tolerant uncapacitated facility location</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the uncapacitated facility location problem, given a graph, a set of
demands and opening costs, it is required to find a set of facilities R, so as
to minimize the sum of the cost of opening the facilities in R and the cost of
assigning all node demands to open facilities. This paper concerns the robust
fault-tolerant version of the uncapacitated facility location problem (RFTFL).
In this problem, one or more facilities might fail, and each demand should be
supplied by the closest open facility that did not fail. It is required to find
a set of facilities R, so as to minimize the sum of the cost of opening the
facilities in R and the cost of assigning all node demands to open facilities
that did not fail, after the failure of up to \alpha facilities. We present a
polynomial time algorithm that yields a 6.5-approximation for this problem with
at most one failure and a 1.5 + 7.5\alpha-approximation for the problem with at
most \alpha &gt; 1 failures. We also show that the RFTFL problem is NP-hard even
on trees, and even in the case of a single failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3228</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3228</id><created>2009-12-16</created><authors><author><keyname>Bulitko</keyname><forenames>Valeriy K.</forenames></author><author><keyname>Bulitko</keyname><forenames>Vadim</forenames></author></authors><title>On Backtracking in Real-time Heuristic Search</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time heuristic search algorithms are suitable for situated agents that
need to make their decisions in constant time. Since the original work by Korf
nearly two decades ago, numerous extensions have been suggested. One of the
most intriguing extensions is the idea of backtracking wherein the agent
decides to return to a previously visited state as opposed to moving forward
greedily. This idea has been empirically shown to have a significant impact on
various performance measures. The studies have been carried out in particular
empirical testbeds with specific real-time search algorithms that use
backtracking. Consequently, the extent to which the trends observed are
characteristic of backtracking in general is unclear. In this paper, we present
the first entirely theoretical study of backtracking in real-time heuristic
search. In particular, we present upper bounds on the solution cost exponential
and linear in a parameter regulating the amount of backtracking. The results
hold for a wide class of real-time heuristic search algorithms that includes
many existing algorithms as a small subclass.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3245</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3245</id><created>2009-12-16</created><updated>2010-03-08</updated><authors><author><keyname>Li</keyname><forenames>Yunfan</forenames></author><author><keyname>Dumer</keyname><forenames>Ilya</forenames></author><author><keyname>Grassl</keyname><forenames>Markus</forenames></author><author><keyname>Pryadko</keyname><forenames>Leonid P.</forenames></author></authors><title>Structured Error Recovery for Codeword-Stabilized Quantum Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>13 pages, 9 eps figures</comments><journal-ref>Phys. Rev. A 81, 052337 (2010)</journal-ref><doi>10.1103/PhysRevA.81.052337</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codeword stabilized (CWS) codes are, in general, non-additive quantum codes
that can correct errors by an exhaustive search of different error patterns,
similar to the way that we decode classical non-linear codes. For an n-qubit
quantum code correcting errors on up to t qubits, this brute-force approach
consecutively tests different errors of weight t or less, and employs a
separate n-qubit measurement in each test. In this paper, we suggest an error
grouping technique that allows to simultaneously test large groups of errors in
a single measurement. This structured error recovery technique exponentially
reduces the number of measurements by about 3^t times. While it still leaves
exponentially many measurements for a generic CWS code, the technique is
equivalent to syndrome-based recovery for the special case of additive CWS
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3264</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3264</id><created>2009-12-16</created><authors><author><keyname>Minero</keyname><forenames>Paolo</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Random Access: An Information-Theoretic Perspective</title><categories>cs.IT math.IT</categories><comments>48 pages, 9 figures. Submitted to IEEE Transactions on Information
  Theory. Preliminary version presented at IEEE Information Theory Workshop,
  Taormina, Sicily, October 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a random access system where each sender can be in two
modes of operation, active or not active, and where the set of active users is
available to a common receiver only. Active transmitters encode data into
independent streams of information, a subset of which are decoded by the
receiver, depending on the value of the collective interference. The main
contribution is to present an information-theoretic formulation of the problem
which allows us to characterize, with a guaranteed gap to optimality, the rates
that can be achieved by different data streams.
  Our results are articulated as follows. First, we exactly characterize the
capacity region of a two-user system assuming a binary-expansion deterministic
channel model. Second, we extend this result to a two-user additive white
Gaussian noise channel, providing an approximate characterization within
$\sqrt{3}/2$ bit of the actual capacity. Third, we focus on the symmetric
scenario in which users are active with the same probability and subject to the
same received power constraint, and study the maximum achievable expected
sum-rate, or throughput, for any number of users. In this case, for the
symmetric binary expansion deterministic channel (which is related to the
packet collision model used in the networking literature), we show that a
simple coding scheme which does not employ superposition coding achieves the
system throughput. This result also shows that the performance of slotted ALOHA
systems can be improved by allowing encoding rate adaptation at the
transmitters. For the symmetric additive white Gaussian noise channel, we
propose a scheme that is within one bit of the system throughput for any value
of the underlying parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3269</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3269</id><created>2009-12-16</created><authors><author><keyname>Syta</keyname><forenames>Halyna</forenames><affiliation>Drahomanov National Pedagogical University, Kyiv, Ukraine</affiliation></author><author><keyname>van de Weygaert</keyname><forenames>Rien</forenames><affiliation>Kapteyn Astronomical Institute, University of Groningen, the Netherlands</affiliation></author></authors><title>Life and Times of Georgy Voronoi</title><categories>math.HO cs.CG math.NT</categories><comments>30 pages, 16 figures; invited review for the volume &quot;Tessellations in
  the Sciences: Virtues, Techniques and Applications of Geometric Tilings&quot;,
  eds. R. van de Weijgaert, G. Vegter, J. Ritzerveld and V. Icke, Springer
  (accepted). For high-res version see
  http://www.astro.rug.nl/~weygaert/jigsaw.syta-biogvoronoi.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Georgy Theodosiyovych Voronoi (1868-1908) is famous for his seminal
contributions to number theory,perhaps mostly those involving quadratic forms
and Voronoi tessellations. He was born and grew up in the town of Zhuravka in
the Ukraine, at the time part of the Russian Empire. Having studied at St.
Petersburg University under the supervision of Andrey Markov, in 1894 he became
a professor of pure mathematics at the University of Warsaw. In his career he
published six large memoirs and six short papers, each of which were so
profound and significant that they left a deep trace in modern number theory.
Together with Minkowski, he can be considered as the founder of the Geometry of
Numbers. In this contribution, a brief sketch will be given of his life, work
and legacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3275</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3275</id><created>2009-12-16</created><authors><author><keyname>Basilico</keyname><forenames>Nicola</forenames></author><author><keyname>Gatti</keyname><forenames>Nicola</forenames></author><author><keyname>Amigoni</keyname><forenames>Francesco</forenames></author></authors><title>A Formal Framework for Mobile Robot Patrolling in Arbitrary Environments
  with Adversaries</title><categories>cs.GT cs.MA</categories><acm-class>I.2.9; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using mobile robots for autonomous patrolling of environments to prevent
intrusions is a topic of increasing practical relevance. One of the most
challenging scientific issues is the problem of finding effective patrolling
strategies that, at each time point, determine the next moves of the patrollers
in order to maximize some objective function. In the very last years this
problem has been addressed in a game theoretical fashion, explicitly
considering the presence of an adversarial intruder. The general idea is that
of modeling a patrolling situation as a game, played by the patrollers and the
intruder, and of studying the equilibria of this game to derive effective
patrolling strategies. In this paper we present a game theoretical formal
framework for the determination of effective patrolling strategies that extends
the previous proposals appeared in the literature, by considering environments
with arbitrary topology and arbitrary preferences for the agents. The main
original contributions of this paper are the formulation of the patrolling game
for generic graph environments, an algorithm for finding a deterministic
equilibrium strategy, which is a fixed path through the vertices of the graph,
and an algorithm for finding a non-deterministic equilibrium strategy, which is
a set of probabilities for moving between adjacent vertices of the graph. Both
the algorithms are analytically studied and experimentally validated, to assess
their properties and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3309</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3309</id><created>2009-12-16</created><authors><author><keyname>Cortes</keyname><forenames>Corinna</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>New Generalization Bounds for Learning Kernels</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents several novel generalization bounds for the problem of
learning kernels based on the analysis of the Rademacher complexity of the
corresponding hypothesis sets. Our bound for learning kernels with a convex
combination of p base kernels has only a log(p) dependency on the number of
kernels, p, which is considerably more favorable than the previous best bound
given for the same problem. We also give a novel bound for learning with a
linear combination of p base kernels with an L_2 regularization whose
dependency on p is only in p^{1/4}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3310</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3310</id><created>2009-12-16</created><updated>2011-06-13</updated><authors><author><keyname>Kempe</keyname><forenames>David</forenames></author><author><keyname>Salek</keyname><forenames>Mahyar</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author></authors><title>Frugal and Truthful Auctions for Vertex Covers, Flows, and Cuts</title><categories>cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study truthful mechanisms for hiring a team of agents in three classes of
set systems: Vertex Cover auctions, k-flow auctions, and cut auctions. For
Vertex Cover auctions, the vertices are owned by selfish and rational agents,
and the auctioneer wants to purchase a vertex cover from them. For k-flow
auctions, the edges are owned by the agents, and the auctioneer wants to
purchase k edge-disjoint s-t paths, for given s and t. In the same setting, for
cut auctions, the auctioneer wants to purchase an s-t cut. Only the agents know
their costs, and the auctioneer needs to select a feasible set and payments
based on bids made by the agents.
  We present constant-competitive truthful mechanisms for all three set
systems. That is, the maximum overpayment of the mechanism is within a constant
factor of the maximum overpayment of any truthful mechanism, for every set
system in the class. The mechanism for Vertex Cover is based on scaling each
bid by a multiplier derived from the dominant eigenvector of a certain matrix.
The mechanism for k-flows prunes the graph to be minimally (k+1)-connected, and
then applies the Vertex Cover mechanism. Similarly, the mechanism for cuts
contracts the graph until all s-t paths have length exactly 2, and then applies
the Vertex Cover mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3323</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3323</id><created>2009-12-17</created><updated>2010-07-19</updated><authors><author><keyname>Tenenbaum</keyname><forenames>Adam J.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Minimizing Sum-MSE Implies Identical Downlink and Dual Uplink Power
  Allocations</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Communications Letters (9 pages, 1 figure,
  revised). Uses IEEEtran.cls V1.7a</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the multiuser downlink, power allocation for linear precoders that
minimize the sum of mean squared errors under a sum power constraint is a
non-convex problem. Many existing algorithms solve an equivalent convex problem
in the virtual uplink and apply a transformation based on uplink-downlink
duality to find a downlink solution. In this letter, we analyze the optimality
criteria for the power allocation subproblem in the virtual uplink, and
demonstrate that the optimal solution leads to identical power allocations in
the downlink and virtual uplink. We thus extend the known duality results and,
importantly, simplify the existing algorithms used for iterative transceiver
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3398</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3398</id><created>2009-12-17</created><authors><author><keyname>Gorochowski</keyname><forenames>Thomas E.</forenames></author><author><keyname>di Bernardo</keyname><forenames>Mario</forenames></author><author><keyname>Grierson</keyname><forenames>Claire S.</forenames></author></authors><title>NetEvo: A computational framework for the evolution of dynamical complex
  networks</title><categories>cs.MS</categories><acm-class>D.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NetEvo is a computational framework designed to help understand the evolution
of dynamical complex networks. It provides flexible tools for the simulation of
dynamical processes on networks and methods for the evolution of underlying
topological structures. The concept of a supervisor is used to bring together
both these aspects in a coherent way. It is the job of the supervisor to rewire
the network topology and alter model parameters such that a user specified
performance measure is minimised. This performance measure can make use of
current topological information and simulated dynamical output from the system.
Such an abstraction provides a suitable basis in which to study many
outstanding questions related to complex system design and evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3403</identifier>
 <datestamp>2012-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3403</id><created>2009-12-17</created><updated>2010-04-11</updated><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Petrov</keyname><forenames>Fedor</forenames></author></authors><title>Frugal Mechanism Design via Spectral Techniques</title><categories>cs.GT</categories><journal-ref>Proceedings of FOCS 2010</journal-ref><doi>10.1109/FOCS.2010.77</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of truthful mechanisms for set systems, i.e., scenarios
where a customer needs to hire a team of agents to perform a complex task. In
this setting, frugality [Archer&amp;Tardos'02] provides a measure to evaluate the
&quot;cost of truthfulness&quot;, that is, the overpayment of a truthful mechanism
relative to the &quot;fair&quot; payment. We propose a uniform scheme for designing
frugal truthful mechanisms for general set systems. Our scheme is based on
scaling the agents' bids using the eigenvector of a matrix that encodes the
interdependencies between the agents. We demonstrate that the r-out-of-k-system
mechanism and the \sqrt-mechanism for buying a path in a graph [Karlin et.
al'05] can be viewed as instantiations of our scheme. We then apply our scheme
to two other classes of set systems, namely, vertex cover systems and k-path
systems, in which a customer needs to purchase k edge-disjoint source-sink
paths. For both settings, we bound the frugality of our mechanism in terms of
the largest eigenvalue of the respective interdependency matrix. We show that
our mechanism is optimal for a large subclass of vertex cover systems
satisfying a simple local sparsity condition. For k-path systems, while our
mechanism is within a factor of k + 1 from optimal, we show that it is, in
fact, optimal, when one uses a modified definition of frugality proposed in
[Elkind et al.'07]. Our lower bound argument combines spectral techniques and
Young's inequality, and is applicable to all set systems. As both r-out-of-k
systems and single path systems can be viewed as special cases of k-path
systems, our result improves the lower bounds of [Karlin et al.'05] and answers
several open questions proposed in that paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3419</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3419</id><created>2009-12-17</created><updated>2010-02-02</updated><authors><author><keyname>Marsch</keyname><forenames>Patrick</forenames></author><author><keyname>Rost</keyname><forenames>Peter</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Application Driven Joint Uplink-Downlink Optimization in Wireless
  Communications</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at 2010 Workshop on Smart Antennas (WSA),
  23-24 Feb 2010, Bremen (Germany); submitted on 15 Nov 2009</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new mathematical framework, which is used to derive
joint uplink/downlink achievable rate regions for multi-user spatial
multiplexing between one base station and multiple terminals. The framework
consists of two models: the first one is a simple transmission model for uplink
and downlink, which is capable to give a lower bound on the capacity for the
case that the transmission is subject to imperfect CSI. A detailed model for
concrete channel estimation and feedback schemes provides parameter input to
the former model and covers the most important aspects such as pilot design
optimization, linear channel estimation, feedback delay, and feedback
quantization. We apply this framework to determine optimal pilot densities and
CSI feedback quantity, given that a weighted sum of uplink and downlink
throughput is to be maximized for a certain user velocity. We show that for low
speed, and if downlink throughput is of particular importance, a significant
portion of the uplink should be invested into CSI feedback. At higher velocity,
however, downlink performance becomes mainly affected by CSI feedback delay,
and hence CSI feedback brings little gain considering the inherent sacrifice of
uplink capacity. We further show that for high velocities, it becomes
beneficial to use no CSI feedback at all, but apply random beamforming in the
downlink and operate in time-division duplex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3429</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3429</id><created>2009-12-17</created><updated>2010-02-03</updated><authors><author><keyname>Montanari</keyname><forenames>A.</forenames></author><author><keyname>Puppis</keyname><forenames>G.</forenames></author><author><keyname>Sala</keyname><forenames>P.</forenames></author><author><keyname>Sciavicco</keyname><forenames>G.</forenames></author></authors><title>Decidability of the interval temporal logic ABBar over the natural
  numbers</title><categories>cs.LO</categories><acm-class>F.3; F.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we focus our attention on the interval temporal logic of the
Allen's relations &quot;meets&quot;, &quot;begins&quot;, and &quot;begun by&quot; (ABBar for short),
interpreted over natural numbers. We first introduce the logic and we show that
it is expressive enough to model distinctive interval properties,such as
accomplishment conditions, to capture basic modalities of point-based temporal
logic, such as the until operator, and to encode relevant metric constraints.
Then, we prove that the satisfiability problem for ABBar over natural numbers
is decidable by providing a small model theorem based on an original
contraction method. Finally, we prove the EXPSPACE-completeness of the problem
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3441</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3441</id><created>2009-12-17</created><authors><author><keyname>Jacquet</keyname><forenames>Philippe</forenames></author><author><keyname>Mans</keyname><forenames>Bernard</forenames></author><author><keyname>Rodolakis</keyname><forenames>Georgios</forenames></author></authors><title>On Space-Time Capacity Limits in Mobile and Delay Tolerant Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Part of this work will be presented in &quot;On Space-Time Capacity Limits
  in Mobile and Delay Tolerant Networks&quot;, P. Jacquet, B. Mans and G. Rodolakis,
  IEEE Infocom, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the fundamental capacity limits of space-time journeys of
information in mobile and Delay Tolerant Networks (DTNs), where information is
either transmitted or carried by mobile nodes, using store-carry-forward
routing. We define the capacity of a journey (i.e., a path in space and time,
from a source to a destination) as the maximum amount of data that can be
transferred from the source to the destination in the given journey. Combining
a stochastic model (conveying all possible journeys) and an analysis of the
durations of the nodes' encounters, we study the properties of journeys that
maximize the space-time information propagation capacity, in bit-meters per
second. More specifically, we provide theoretical lower and upper bounds on the
information propagation speed, as a function of the journey capacity. In the
particular case of random way-point-like models (i.e., when nodes move for a
distance of the order of the network domain size before changing direction), we
show that, for relatively large journey capacities, the information propagation
speed is of the same order as the mobile node speed. This implies that,
surprisingly, in sparse but large-scale mobile DTNs, the space-time information
propagation capacity in bit-meters per second remains proportional to the
mobile node speed and to the size of the transported data bundles, when the
bundles are relatively large. We also verify that all our analytical bounds are
accurate in several simulation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3448</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3448</id><created>2009-12-17</created><authors><author><keyname>van de Weygaert</keyname><forenames>Rien</forenames><affiliation>Kapteyn Astronomical Institute, University of Groningen, the Netherlands</affiliation></author><author><keyname>Aragon-Calvo</keyname><forenames>Miguel A.</forenames><affiliation>Dept. Physics &amp; Astronomy, the Johns Hopkins University, Baltimore, USA</affiliation></author><author><keyname>Jones</keyname><forenames>Bernard J. T.</forenames><affiliation>Kapteyn Astronomical Institute, University of Groningen, the Netherlands</affiliation></author><author><keyname>Platen</keyname><forenames>Erwin</forenames><affiliation>Kapteyn Astronomical Institute, University of Groningen, the Netherlands</affiliation></author></authors><title>Geometry and Morphology of the Cosmic Web: Analyzing Spatial Patterns in
  the Universe</title><categories>astro-ph.IM astro-ph.CO cs.CG</categories><comments>28 pages, 16 figures, invited review ISVD09 (International Symposium
  on Voronoi Diagrams and Engineering), Copenhagen, Denmark. IEEE CPS, E3781,
  ed. F. Anton. For high-res version see
  http://www.astro.rug.nl/~weygaert/isvd09wey.ieee.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the analysis of the Cosmic Web by means of an extensive toolset
based on the use of Delaunay and Voronoi tessellations. The Cosmic Web is the
salient and pervasive foamlike pattern in which matter has organized itself on
scales of a few up to more than a hundred Megaparsec. First, we describe the
Delaunay Tessellation Field Estimator (DTFE). The DTFE formalism is shown to
recover the hierarchical nature and the anisotropic morphology of the cosmic
matter distribution. The Multiscale Morphology Filter (MMF) uses the DTFE
density field to extract the diverse morphological elements - filaments, sheets
and clusters - on the basis of a ScaleSpace analysis which searches for these
morphologies over a range of scales. Subsequently, we discuss the Watershed
Voidfinder (WVF), which invokes the discrete watershed transform to identify
voids in the cosmic matter distribution. The WVF is able to determine the
location, size and shape of the voids. The watershed transform is also a key
element in the SpineWeb analysis of the cosmic matter distribution. It allows
the determination of the filamentary spine and connected walls in the cosmic
matter density field through the identification of the singularities and
corresponding separatrices. Finally, we describe the concept of Alphashapes for
assessing the topology of the cosmic matter distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3461</identifier>
 <datestamp>2010-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3461</id><created>2009-12-17</created><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Application of Graph Coloring to Biological Networks</title><categories>cs.CE q-bio.QM</categories><journal-ref>IET Syst. Biol. -- May 2010 -- Volume 4, Issue 3, p.185-192</journal-ref><doi>10.1049/iet-syb.2009.0038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the application of graph coloring to biological networks,
specifically protein-protein interaction (PPI) networks. First, we find that
given similar conditions (i.e. number of nodes, number of links, degree
distribution and clustering), fewer colors are needed to color disassortative
(high degree nodes tend to connect to low degree nodes and vice versa) than
assortative networks. Fewer colors create fewer independent sets which in turn
imply higher concurrency potential for a network. Since PPI networks tend to be
disassortative, we suggest that in addition to functional specificity and
stability proposed previously by Maslov and Sneppen (Science 296, 2002), the
disassortative nature of PPI networks may promote the ability of cells to
perform multiple, crucial and functionally diverse tasks concurrently. Second,
since graph coloring is closely related to the presence of cliques in a graph,
the significance of node coloring information to the problem of identifying
protein complexes, i.e. dense subgraphs in a PPI network, is investigated. We
find that for PPI networks where 1% to 11% of nodes participate in at least one
identified protein complex, such as H. sapien (DIP20070219, DIP20081014 and
HPRD070609), DSATUR (a well-known complete graph coloring algorithm) node
coloring information can improve the quality (homogeneity and separation) of
initial candidate complexes. This finding may help to improve existing protein
complex detection methods, and/or suggest new methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3503</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3503</id><created>2009-12-17</created><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author></authors><title>Absolutely Secure Communications by Johnson-like Noise and Kirchhoff's
  Laws</title><categories>physics.gen-ph cond-mat.stat-mech cs.IT math.IT quant-ph</categories><comments>Invited paper for the Journal of the Society of Instrument and
  Control Engineers (SICE), Japan, for the special issue on &quot;Fluctuations and
  Noise&quot;</comments><journal-ref>Journal of the Society of Instrument and Control Engineers (SICE,
  Japan) Vol. 49 (2010) 212-216</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey the most important results and some recent developments about the
secure key exchange protocol where the security is based on the Second Law of
Thermodynamics and the robustness of classical physical information. We
conclude that a classical physical system offers a higher level of control and
security during the communication. We also mention some recent attempts
inspired by this communicator to create other systems where Alice and Bob do
not form an organic single system and/or the Second Law is irrelevant. It seems
philosophically that they cannot be unconditionally secure, however it is yet
an open question how to crack them; how can they be best used for conditionally
secure communications, and what are the practical implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3510</identifier>
 <datestamp>2009-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3510</id><created>2009-12-17</created><updated>2009-12-27</updated><authors><author><keyname>Saha</keyname><forenames>Diptikalyan</forenames></author><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>A simple and efficient explicit parallelization of logic programs using
  low-level threading primitives</title><categories>cs.PL cs.DC</categories><acm-class>D.3.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work, we present an automatic way to parallelize logic programs for
finding all the answers to queries using a transformation to low level
threading primitives. Although much work has been done in parallelization of
logic programming more than a decade ago (e.g., Aurora, Muse, YapOR), the
current state of parallelizing logic programs is still very poor. This work
presents a way for parallelism of tabled logic programs in XSB Prolog under the
well founded semantics. An important contribution of this work relies in
merging answer-tables from multiple children threads without incurring copying
or full-sharing and synchronization of data-structures. The implementation of
the parent-children shared answer-tables surpasses in efficiency all the other
data-structures currently implemented for completion of answers in
parallelization using multi-threading. The transformation and its lower-level
answer merging predicates were implemented as an extension to the XSB system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3541</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3541</id><created>2009-12-17</created><updated>2009-12-23</updated><authors><author><keyname>Ahmad</keyname><forenames>Sahand</forenames></author><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Wu</keyname><forenames>Yunnan</forenames></author></authors><title>Spectrum Sharing as Network Congestion Games</title><categories>cs.IT cs.GT math.IT math.OC</categories><comments>24 pages, 6 figures, 2 tables, Submitted to Journal of special issues
  in communication(JSAC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the first author due to incomplete
bibliography and incorporation of multiple formats in the same file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3563</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3563</id><created>2009-12-18</created><authors><author><keyname>Sulc</keyname><forenames>P.</forenames></author><author><keyname>Zdeborova</keyname><forenames>L.</forenames></author></authors><title>Belief propagation for graph partitioning</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.DM cs.DS</categories><comments>16 pages, 4 figures</comments><journal-ref>J. Phys. A: Math. Theor. 43 (2010) 285003</journal-ref><doi>10.1088/1751-8113/43/28/285003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the belief propagation algorithm for the graph bi-partitioning
problem, i.e. the ground state of the ferromagnetic Ising model at a fixed
magnetization. Application of a message passing scheme to a model with a fixed
global parameter is not banal and we show that the magnetization can in fact be
fixed in a local way within the belief propagation equations. Our method
provides the full phase diagram of the bi-partitioning problem on random
graphs, as well as an efficient heuristic solver that we anticipate to be
useful in a wide range of application of the partitioning problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3573</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3573</id><created>2009-12-17</created><authors><author><keyname>Zhang</keyname><forenames>Ren</forenames></author></authors><title>An index to link scientific productivity with visibility</title><categories>physics.data-an cs.DL</categories><comments>6 pages; 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I here propose an index that links the number of papers a researcher has
published with impact factors (IFs) of the journals that publish these papers.
A researcher is said to have an index z if totally z of his/her papers are
published in journals with IFs of at least z/2. The z-index, not meant to
evaluate, compare and rank scientists, is a number that hopefully conveniently
summarizes the number of publications in journals with high IFs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3583</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3583</id><created>2009-12-17</created><authors><author><keyname>Levesque</keyname><forenames>Martin</forenames></author></authors><title>A Metamodel of Unit Testing for Object-Oriented Programming Languages</title><categories>cs.PL</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unit test is a method for verifying the accuracy and the proper functioning
of a portion of a program. This work consists to study the relation and the
approaches to test Object-Oriented Programming (OOP) programs and to propose a
metamodel that enables the programmer to write the tests while writing the
source code to be tested by exploiting the key features of OOP programming
languages such as inheritance, polymorphism, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3589</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3589</id><created>2009-12-18</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Brewer</keyname><forenames>Nathan</forenames></author></authors><title>Matching 2-D Ellipses to 3-D Circles with Application to Vehicle Pose
  Estimation</title><categories>cs.CV</categories><comments>16 LaTeX pages, 5 figures</comments><journal-ref>Proc. 24th Conf. on Image and Vision Computing New Zealand (IVCNZ
  2009) pages 153-158</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the three-dimensional representation of all or a part of a scene from
a single two dimensional image is a challenging task. In this paper we propose
a method for identifying the pose and location of objects with circular
protrusions in three dimensions from a single image and a 3d representation or
model of the object of interest. To do this, we present a method for
identifying ellipses and their properties quickly and reliably with a novel
technique that exploits intensity differences between objects and a geometric
technique for matching an ellipse in 2d to a circle in 3d.
  We apply these techniques to the specific problem of determining the pose and
location of vehicles, particularly cars, from a single image. We have achieved
excellent pose recovery performance on artificially generated car images and
show promising results on real vehicle images. We also make use of the ellipse
detection method to identify car wheels from images, with a very high
successful match rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3599</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3599</id><created>2009-12-18</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Li</keyname><forenames>Xiaodong</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Robust Principal Component Analysis?</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about a curious phenomenon. Suppose we have a data matrix,
which is the superposition of a low-rank component and a sparse component. Can
we recover each component individually? We prove that under some suitable
assumptions, it is possible to recover both the low-rank and the sparse
components exactly by solving a very convenient convex program called Principal
Component Pursuit; among all feasible decompositions, simply minimize a
weighted combination of the nuclear norm and of the L1 norm. This suggests the
possibility of a principled approach to robust principal component analysis
since our methodology and results assert that one can recover the principal
components of a data matrix even though a positive fraction of its entries are
arbitrarily corrupted. This extends to the situation where a fraction of the
entries are missing as well. We discuss an algorithm for solving this
optimization problem, and present applications in the area of video
surveillance, where our methodology allows for the detection of objects in a
cluttered background, and in the area of face recognition, where it offers a
principled way of removing shadows and specularities in images of faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3627</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3627</id><created>2009-12-18</created><authors><author><keyname>Voronenko</keyname><forenames>Andrey A.</forenames></author></authors><title>New Learning and Testing Problems for Read-Once Functions</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, we consider several types of queries for classical and new
problems of learning and testing read-once functions. In several cases, the
border between polynomial and exponential complexities is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3730</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3730</id><created>2009-12-18</created><updated>2011-02-24</updated><authors><author><keyname>Birget</keyname><forenames>Jean-Camille</forenames></author></authors><title>On the circuit-size of inverses</title><categories>cs.CC</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reprove a result of Boppana and Lagarias: If Pi_2^P is different from
Sigma_2^P then there exists a partial function f that is computable by a
polynomial-size family of circuits, but no inverse of f is computable by a
polynomial-size family of circuits. We strengthen this result by showing that
there exist length-preserving total functions that are one-way by circuit size
and that are computable in uniform polynomial time. We also prove, if Pi_2^P is
different from Sigma_2^P, that there exist polynomially balanced total
surjective functions that are one-way by circuit size; here non-uniformity is
used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3747</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3747</id><created>2009-12-18</created><updated>2010-05-30</updated><authors><author><keyname>Androutsopoulos</keyname><forenames>Ion</forenames></author><author><keyname>Malakasiotis</keyname><forenames>Prodromos</forenames></author></authors><title>A Survey of Paraphrasing and Textual Entailment Methods</title><categories>cs.CL cs.AI</categories><comments>Technical Report, Natural Language Processing Group, Department of
  Informatics, Athens University of Economics and Business, Greece, 2010</comments><acm-class>I.2.7</acm-class><journal-ref>I. Androutsopoulos and P. Malakasiotis, &quot;A Survey of Paraphrasing
  and Textual Entailment Methods&quot;. Journal of Artificial Intelligence Research,
  38:135-187, 2010</journal-ref><doi>10.1613/jair.2985</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paraphrasing methods recognize, generate, or extract phrases, sentences, or
longer natural language expressions that convey almost the same information.
Textual entailment methods, on the other hand, recognize, generate, or extract
pairs of natural language expressions, such that a human who reads (and trusts)
the first element of a pair would most likely infer that the other element is
also true. Paraphrasing can be seen as bidirectional textual entailment and
methods from the two areas are often similar. Both kinds of methods are useful,
at least in principle, in a wide range of natural language processing
applications, including question answering, summarization, text generation, and
machine translation. We summarize key ideas from the two areas by considering
in turn recognition, generation, and extraction methods, also pointing to
prominent articles and resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3802</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3802</id><created>2009-12-18</created><updated>2010-02-03</updated><authors><author><keyname>Egri</keyname><forenames>Laszlo</forenames></author><author><keyname>Krokhin</keyname><forenames>Andrei</forenames></author><author><keyname>Larose</keyname><forenames>Benoit</forenames></author><author><keyname>Tesson</keyname><forenames>Pascal</forenames></author></authors><title>The complexity of the list homomorphism problem for graphs</title><categories>cs.CC</categories><comments>12 pages, STACS 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We completely classify the computational complexity of the list H-colouring
problem for graphs (with possible loops) in combinatorial and algebraic terms:
for every graph H the problem is either NP-complete, NL-complete, L-complete or
is first-order definable; descriptive complexity equivalents are given as well
via Datalog and its fragments. Our algebraic characterisations match important
conjectures in the study of constraint satisfaction problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3824</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3824</id><created>2009-12-20</created><updated>2011-01-17</updated><authors><author><keyname>Colberg</keyname><forenames>Peter H.</forenames></author><author><keyname>H&#xf6;fling</keyname><forenames>Felix</forenames></author></authors><title>Highly accelerated simulations of glassy dynamics using GPUs: caveats on
  limited floating-point precision</title><categories>physics.comp-ph cond-mat.soft cs.DC</categories><comments>12 pages, 7 figures, to appear in Comp. Phys. Comm., HALMD package
  licensed under the GPL, see http://research.colberg.org/projects/halmd</comments><report-no>LMU-ASC 55/09</report-no><journal-ref>Comp. Phys. Comm. 182, 1120 (2011)</journal-ref><doi>10.1016/j.cpc.2011.01.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern graphics processing units (GPUs) provide impressive computing
resources, which can be accessed conveniently through the CUDA programming
interface. We describe how GPUs can be used to considerably speed up molecular
dynamics (MD) simulations for system sizes ranging up to about 1 million
particles. Particular emphasis is put on the numerical long-time stability in
terms of energy and momentum conservation, and caveats on limited
floating-point precision are issued. Strict energy conservation over 10^8 MD
steps is obtained by double-single emulation of the floating-point arithmetic
in accuracy-critical parts of the algorithm. For the slow dynamics of a
supercooled binary Lennard-Jones mixture, we demonstrate that the use of
single-floating point precision may result in quantitatively and even
physically wrong results. For simulations of a Lennard-Jones fluid, the
described implementation shows speedup factors of up to 80 compared to a serial
implementation for the CPU, and a single GPU was found to compare with a
parallelised MD simulation using 64 distributed cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3834</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3834</id><created>2009-12-21</created><authors><author><keyname>Lamar</keyname><forenames>M. Drew</forenames></author></authors><title>On uniform sampling simple directed graph realizations of degree
  sequences</title><categories>cs.DM</categories><comments>7 pages, 4 figures</comments><acm-class>G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Choosing a uniformly sampled simple directed graph realization of a degree
sequence has many applications, in particular in social networks where
self-loops are commonly not allowed. It has been shown in the past that one can
perform a Markov chain arc-switching algorithm to sample a simple directed
graph uniformly by performing two types of switches: a 2-switch and a directed
3-cycle reorientation. This paper discusses under what circumstances a directed
3-cycle reorientation is required. In particular, the class of degree sequences
where this is required is a subclass of the directed 3-cycle anchored degree
sequences. An important implication of this result is a reduced Markov chain
algorithm that uses only 2-switches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3848</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3848</id><created>2009-12-18</created><authors><author><keyname>Hammond</keyname><forenames>David K</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames></author></authors><title>Wavelets on Graphs via Spectral Graph Theory</title><categories>math.FA cs.IT math.IT</categories><msc-class>42C40; 65T90</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method for constructing wavelet transforms of functions
defined on the vertices of an arbitrary finite weighted graph. Our approach is
based on defining scaling using the the graph analogue of the Fourier domain,
namely the spectral decomposition of the discrete graph Laplacian $\L$. Given a
wavelet generating kernel $g$ and a scale parameter $t$, we define the scaled
wavelet operator $T_g^t = g(t\L)$. The spectral graph wavelets are then formed
by localizing this operator by applying it to an indicator function. Subject to
an admissibility condition on $g$, this procedure defines an invertible
transform. We explore the localization properties of the wavelets in the limit
of fine scales. Additionally, we present a fast Chebyshev polynomial
approximation algorithm for computing the transform that avoids the need for
diagonalizing $\L$. We highlight potential applications of the transform
through examples of wavelets on graphs corresponding to a variety of different
problem domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3852</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3852</id><created>2009-12-18</created><authors><author><keyname>Gopalakrishnan</keyname><forenames>Sathish</forenames></author></authors><title>Sharp utilization thresholds for some real-time scheduling problems</title><categories>cs.PF cs.DM cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling policies for real-time systems exhibit threshold behavior that is
related to the utilization of the task set they schedule, and in some cases
this threshold is sharp. For the rate monotonic scheduling policy, we show that
periodic workload with utilization less than a threshold $U_{RM}^{*}$ can be
scheduled almost surely and that all workload with utilization greater than
$U_{RM}^{*}$ is almost surely not schedulable. We study such sharp threshold
behavior in the context of processor scheduling using static task priorities,
not only for periodic real-time tasks but for aperiodic real-time tasks as
well. The notion of a utilization threshold provides a simple schedulability
test for most real-time applications. These results improve our understanding
of scheduling policies and provide an interesting characterization of the
typical behavior of policies. The threshold is sharp (small deviations around
the threshold cause schedulability, as a property, to appear or disappear) for
most policies; this is a happy consequence that can be used to address the
limitations of existing utilization-based tests for schedulability. We
demonstrate the use of such an approach for balancing power consumption with
the need to meet deadlines in web servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3856</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3856</id><created>2009-12-18</created><authors><author><keyname>Reddy</keyname><forenames>Vinith</forenames></author><author><keyname>Kim</keyname><forenames>Younghoon</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author><author><keyname>Reddy</keyname><forenames>A. L. Narasimha</forenames></author></authors><title>Designing ISP-friendly Peer-to-Peer Networks Using Game-based Control</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid growth of peer-to-peer (P2P) networks in the past few years has
brought with it increases in transit cost to Internet Service Providers (ISPs),
as peers exchange large amounts of traffic across ISP boundaries. This ISP
oblivious behavior has resulted in misalignment of incentives between P2P
networks--that seek to maximize user quality--and ISPs--that would seek to
minimize costs. Can we design a P2P overlay that accounts for both ISP costs as
well as quality of service, and attains a desired tradeoff between the two? We
design a system, which we call MultiTrack, that consists of an overlay of
multiple \emph{mTrackers} whose purpose is to align these goals. mTrackers
split demand from users among different ISP domains while trying to minimize
their individual costs (delay plus transit cost) in their ISP domain. We design
the signals in this overlay of mTrackers in such a way that potentially
competitive individual optimization goals are aligned across the mTrackers. The
mTrackers are also capable of doing admission control in order to ensure that
users who are from different ISP domains have a fair chance of being admitted
into the system, while keeping costs in check. We prove analytically that our
system is stable and achieves maximum utility with minimum cost. Our design
decisions and control algorithms are validated by Matlab and ns-2 simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3882</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3882</id><created>2009-12-19</created><authors><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author><author><keyname>Porter</keyname><forenames>Alan L.</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Science overlay maps: a new tool for research policy and library
  management</title><categories>cs.DL cs.IR physics.soc-ph</categories><comments>40 pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to visually locate bodies of research within the
sciences, both at each moment of time and dynamically. This article describes
how this approach fits with other efforts to locally and globally map
scientific outputs. We then show how these science overlay maps help benchmark,
explore collaborations, and track temporal changes, using examples of
universities, corporations, funding agencies, and research topics. We address
conditions of application, with their advantages, downsides and limitations.
Overlay maps especially help investigate the increasing number of scientific
developments and organisations that do not fit within traditional disciplinary
categories. We make these tools accessible to help researchers explore the
ongoing socio-cognitive transformation of science and technology systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3886</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3886</id><created>2009-12-19</created><updated>2010-04-04</updated><authors><author><keyname>Lee</keyname><forenames>Jiwoong</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Optimism in Games with Non-Probabilistic Uncertainty</title><categories>cs.GT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies one-shot two-player games with non-Bayesian uncertainty.
The players have an attitude that ranges from optimism to pessimism in the face
of uncertainty. Given the attitudes, each player forms a belief about the set
of possible strategies of the other player. If these beliefs are consistent,
one says that they form an uncertainty equilibrium. One then considers a
two-phase game where the players first choose their attitude and then play the
resulting game. The paper illustrates these notions with a number of games
where the approach provides a new insight into the plausible strategies of the
players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3907</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3907</id><created>2009-12-19</created><authors><author><keyname>Yufit</keyname><forenames>Alex</forenames></author><author><keyname>Lifshitz</keyname><forenames>Asi</forenames></author><author><keyname>Be'ery</keyname><forenames>Yair</forenames></author></authors><title>Efficient Linear Programming Decoding of HDPC Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications, November 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose several improvements for Linear Programming (LP) decoding
algorithms for High Density Parity Check (HDPC) codes. First, we use the
automorphism groups of a code to create parity check matrix diversity and to
generate valid cuts from redundant parity checks. Second, we propose an
efficient mixed integer decoder utilizing the branch and bound method. We
further enhance the proposed decoders by removing inactive constraints and by
adapting the parity check matrix prior to decoding according to the channel
observations. Based on simulation results the proposed decoders achieve near-ML
performance with reasonable complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3912</identifier>
 <datestamp>2013-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3912</id><created>2009-12-19</created><updated>2013-06-18</updated><authors><author><keyname>Garcia</keyname><forenames>Hector J.</forenames></author><author><keyname>Markov</keyname><forenames>Igor L.</forenames></author></authors><title>High-performance Energy Minimization with Applications to Adiabatic
  Quantum Computing</title><categories>quant-ph cond-mat.stat-mech cs.DS cs.ET</categories><comments>9 pages, 1 table, 10 figures</comments><journal-ref>Proc. Design Autom. and Test in Europe Conf. (DATE), pp. 160 -
  165, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy minimization of Ising spin-glasses has played a central role in
statistical and solid-state physics, facilitating studies of phase transitions
and magnetism. Recent proposals suggest using Ising spin-glasses for
non-traditional computing as a way to harness the nature's ability to find
min-energy configurations, and to take advantage of quantum tunneling to boost
combinatorial optimization. Laboratory demonstrations have been unconvincing so
far and lack a non-quantum baseline for definitive comparisons. In this work we
(i) design and evaluate new computational techniques to simulate natural energy
minimization in spin glasses and (ii) explore their application to study design
alternatives in quantum adiabatic computers. Unlike previous work, our
algorithms are not limited to planar Ising topologies. In one CPU-day, our
branch-and-bound algorithm finds ground states on 100 spins, while our local
search approximates ground states on 1, 000, 000 spins. We use this
computational tool as a simulator to study the significance of hyper-couplings
in the context of recently implemented adiabatic quantum computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3917</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3917</id><created>2009-12-19</created><authors><author><keyname>Guezouri</keyname><forenames>Mustapha</forenames></author><author><keyname>Mesbahi</keyname><forenames>Larbi</forenames></author><author><keyname>Benyettou</keyname><forenames>Abdelkader</forenames></author></authors><title>Speech Recognition Oriented Vowel Classification Using Temporal Radial
  Basis Functions</title><categories>cs.CL cs.MM</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 162-167, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent resurgence of interest in spatio-temporal neural network as speech
recognition tool motivates the present investigation. In this paper an approach
was developed based on temporal radial basis function &quot;TRBF&quot; looking to many
advantages: few parameters, speed convergence and time invariance. This
application aims to identify vowels taken from natural speech samples from the
Timit corpus of American speech. We report a recognition accuracy of 98.06
percent in training and 90.13 in test on a subset of 6 vowel phonemes, with the
possibility to expend the vowel sets in future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3920</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3920</id><created>2009-12-19</created><authors><author><keyname>Veronica</keyname><forenames>Alderete Maria</forenames></author></authors><title>E-commerce between a large firm and a SME supplier: a screening model</title><categories>cs.GT</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 158-161, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives a model of screening contracts in the presence of positive
network effects when building an electronic commerce network (e-commerce)
between a large firm and a small and medium sized enterprise (SME) supplier
based on Compte (2008). Compte (2008) main insight is that when several
potential candidates compete for the task, the principal will in general
improve the performance of his firm by inducing the member candidates to assess
their competence before signing the contract (through an appropriate choice of
contracts). The large firm (principal) must choose between different SME
suppliers (agents) to build a business to business e-commerce network. In the
presence of positive network externalities, we show that social surplus
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3921</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3921</id><created>2009-12-19</created><authors><author><keyname>Oludele</keyname><forenames>Awodele</forenames></author><author><keyname>Ayodele</keyname><forenames>Ogunnusi</forenames></author><author><keyname>Oladele</keyname><forenames>Omole</forenames></author><author><keyname>Olurotimi</keyname><forenames>Seton</forenames></author></authors><title>Design of an Automated Intrusion Detection System incorporating an Alarm</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 149-157, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security and safety are two intertwined terms. It is a common belief that
when a place or system is secure, it is safe. This paper shows a means of
integrating three devices for physical intrusion detection. This paper thus
suggests a means of increasing the level of security in an enclosed area with
the use three of the four security layers necessary for optimum security. This
paper intends to show that a system with more than one security device in place
tends to prevent unauthorized access. This paper would be illustrating the
implementation of this in an enclosed area whose security level must be kept on
the high at all times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3922</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3922</id><created>2009-12-19</created><authors><author><keyname>Bostan</keyname><forenames>I.</forenames></author><author><keyname>Mates</keyname><forenames>D.</forenames></author><author><keyname>Grosu</keyname><forenames>V.</forenames></author><author><keyname>Iancu</keyname><forenames>E.</forenames></author></authors><title>Alternate methods of evaluation for web sites concordant to IAS/IFRS
  Standards</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 141-148, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work has as the principal theme, the study, analysis and implementation
of the methodology for use the web sites in e-commerce. The authors try to deal
with particular methodological and applied aspects inherent in the analysis of
data from the interaction of man-Internet (Web-mining). The research
methodology of this work will be focused on a prevalent optic multidisciplinary
research based on the pillars of data mining and Web mining. The explosion of
Internet and electronic commerce has made the most of business to have its own
website. A company may engage internal costs for the development and operation
of their website. The website can be designed for internal access (in which
case it can be used for presentation and data storage company policies with
references of customers) or for external access (they are created and used for
promotional and advertising products and services company). The objective of
this research, primarily concerns the definition of a repertoire of tools in
analyzing e-business through the development process for web-usage mining; 2nd
objective is oriented to management, recognizing and evaluating the web-sites
in accountancy, as property intangible, which is a special case and very little
studied in economic literature financial specialty, the authors try to achieve
a national and international accounting treatment of the creation and
development of web-sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3923</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3923</id><created>2009-12-19</created><authors><author><keyname>Dharwadkar</keyname><forenames>Nagaraj V.</forenames></author><author><keyname>Amberker</keyname><forenames>B. B.</forenames></author></authors><title>Secure Watermarking Scheme for Color Image Using Intensity of Pixel and
  LSB Substitution</title><categories>cs.GR</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 1-6, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel spatial domain LSB based watermarking scheme for color
Images is proposed. The proposed scheme is of type blind and invisible
watermarking. Our scheme introduces the concept of storing variable number of
bits in each pixel based on the actual color value of pixel. Equal or higher
the color value of channels with respect to intensity of pixel stores higher
number of watermark bits. The Red, Green and Blue channel of the color image
has been used for watermark embedding. The watermark is embedded into selected
channels of pixel. The proposed method supports high watermark embedding
capacity, which is equivalent to the size of cover image. The security of
watermark is preserved by permuting the watermark bits using secret key. The
proposed scheme is found robust to various image processing operations such as
image compression, blurring, salt and pepper noise, filtering and cropping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3924</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3924</id><created>2009-12-19</created><authors><author><keyname>Ramaswami</keyname><forenames>M.</forenames></author><author><keyname>Bhaskaran</keyname><forenames>R.</forenames></author></authors><title>A Study on Feature Selection Techniques in Educational Data Mining</title><categories>cs.DB</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 7-11, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Educational data mining (EDM) is a new growing research area and the essence
of data mining concepts are used in the educational field for the purpose of
extracting useful information on the behaviors of students in the learning
process. In this EDM, feature selection is to be made for the generation of
subset of candidate variables. As the feature selection influences the
predictive accuracy of any performance model, it is essential to study
elaborately the effectiveness of student performance model in connection with
feature selection techniques. In this connection, the present study is devoted
not only to investigate the most relevant subset features with minimum
cardinality for achieving high predictive performance by adopting various
filtered feature selection techniques in data mining but also to evaluate the
goodness of subsets with different cardinalities and the quality of six
filtered feature selection algorithms in terms of F-measure value and Receiver
Operating Characteristics (ROC) value, generated by the NaiveBayes algorithm as
base-line classifier method. The comparative study carried out by us on six
filter feature section algorithms reveals the best method, as well as optimal
dimensionality of the feature subset. Benchmarking of filter feature selection
method is subsequently carried out by deploying different classifier models.
The result of the present study effectively supports the well known fact of
increase in the predictive accuracy with the existence of minimum number of
features. The expected outcomes show a reduction in computational time and
constructional cost in both training and classification phases of the student
performance model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3925</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3925</id><created>2009-12-19</created><updated>2010-03-15</updated><authors><author><keyname>Kundeti</keyname><forenames>Vamsi K.</forenames></author></authors><title>A Simplified Proof For The Application Of Freivalds' Technique to Verify
  Matrix Multiplication</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingerprinting is a well known technique, which is often used in designing
Monte Carlo algorithms for verifying identities involving ma- trices, integers
and polynomials. The book by Motwani and Raghavan [1] shows how this technique
can be applied to check the correctness of matrix multiplication -- check if AB
= C where A, B and C are three nxn matrices. The result is a Monte Carlo
algorithm running in time $Theta(n^2)$ with an exponentially decreasing error
probability after each indepen- dent iteration. In this paper we give a simple
alternate proof addressing the same problem. We also give further
generalizations and relax various assumptions made in the proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3926</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3926</id><created>2009-12-19</created><authors><author><keyname>Balasubramanie</keyname><forenames>P.</forenames></author><author><keyname>Florence</keyname><forenames>M. Lilly</forenames></author></authors><title>Application of Radial Basis Network Model for HIV/AIDs Regimen
  Specifications</title><categories>cs.CY</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 136-140, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  HIV/AIDs Regimen specification one of many problems for which
bioinformaticians have implemented and trained machine learning methods such as
neural networks. Predicting HIV resistance would be much easier, but
unfortunately we rarely have enough structural information available to train a
neural network. To network model designed to predict how long the HIV patient
can prolong his/her life time with certain regimen specification. To learn this
model 300 patient's details have taken as a training set to train the network
and 100 patients medical history has taken to test this model. This network
model is trained using MAT lab implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3927</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3927</id><created>2009-12-19</created><authors><author><keyname>Ojha</keyname><forenames>A. K.</forenames></author><author><keyname>Mallick</keyname><forenames>C.</forenames></author><author><keyname>Mallick</keyname><forenames>D.</forenames></author></authors><title>Logarithmic Barrier Optimization Problem Using Neural Network</title><categories>cs.NA cs.DS</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 12-19, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combinatorial optimization problem is one of the important applications
in neural network computation. The solutions of linearly constrained continuous
optimization problems are difficult with an exact algorithm, but the algorithm
for the solution of such problems is derived by using logarithm barrier
function. In this paper we have made an attempt to solve the linear constrained
optimization problem by using general logarithm barrier function to get an
approximate solution. In this case the barrier parameters behave as temperature
decreasing to zero from sufficiently large positive number satisfying convexity
of the barrier function. We have developed an algorithm to generate decreasing
sequence of solution converging to zero limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3929</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3929</id><created>2009-12-19</created><updated>2012-06-21</updated><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author></authors><title>Metric inequalities for polygons</title><categories>math.MG cs.DM</categories><comments>13 pages, 2 figures. This version replaces the previous version from
  8 Feb 2011. A new section has been added and the material has been
  reorganized; a correction has been done in the proof of Lemma 4 (analysis of
  Case 3)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $A_1,A_2,...,A_n$ be the vertices of a polygon with unit perimeter, that
is $\sum_{i=1}^n |A_i A_{i+1}|=1$. We derive various tight estimates on the
minimum and maximum values of the sum of pairwise distances, and respectively
sum of pairwise squared distances among its vertices. In most cases such
estimates on these sums in the literature were known only for convex polygons.
  In the second part, we turn to a problem of Bra\ss\ regarding the maximum
perimeter of a simple $n$-gon ($n$ odd) contained in a disk of unit radius. The
problem was solved by Audet et al. \cite{AHM09b}, who gave an exact formula.
Here we present an alternative simpler proof of this formula. We then examine
what happens if the simplicity condition is dropped, and obtain an exact
formula for the maximum perimeter in this case as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3953</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3953</id><created>2009-12-19</created><authors><author><keyname>Davis</keyname><forenames>Philip M.</forenames></author></authors><title>Studies on access: a review</title><categories>cs.DL cs.CY</categories><comments>18 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A review of the empirical literature on access to scholarly information. This
review focuses on surveys of authors, article download and citation analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3955</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3955</id><created>2009-12-19</created><authors><author><keyname>Liu</keyname><forenames>Chih-Hao</forenames></author><author><keyname>Jiu</keyname><forenames>Yi-Wen</forenames></author><author><keyname>Chen</keyname><forenames>Jason Jen-Yen</forenames></author></authors><title>Using Design Sketch to Teach Bubble Sort in High School</title><categories>cs.CY</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 20-25, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bubble Sort is simple. Yet, it seems a bit difficult for high school
students. This paper presents a pedagogical methodology: Using Design Sketch to
visualize the concepts in Bubble Sort, and to evaluate how this approach
assists students to understand the pseudo code of Bubble Sort. An experiment is
conducted in Wu-Ling Senior High School with 250 students taking part. The
statistical analysis of experimental results shows that, for relatively high
abstraction concepts, such as iteration number, Design Sketch helps
significantly. However, it is not so for low abstraction concepts such as
compare, swap, and iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3956</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3956</id><created>2009-12-19</created><authors><author><keyname>S</keyname><forenames>Arumugom.</forenames></author><author><keyname>S</keyname><forenames>Muthuraman.</forenames></author><author><keyname>V</keyname><forenames>Ponselvan.</forenames></author></authors><title>Modeling and Application of Series Elastic Actuators for Force Control
  Multi Legged Robots</title><categories>cs.RO</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 26-33, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Series Elastic Actuators provide many benefits in force control of robots in
unconstrained environments. These benefits include high force fidelity,
extremely low impedance, low friction, and good force control bandwidth. Series
Elastic Actuators employ a novel mechanical design architecture which goes
against the common machine design principal of &quot;stiffer is better&quot;. A compliant
element is placed between the gear train and driven load to intentionally
reduce the stiffness of the actuator. A position sensor measures the
deflection, and the force output is accurately calculated using Hooke's Law
(F=Kx). A control loop then servos the actuator to the desired output force.
The resulting actuator has inherent shock tolerance, high force fidelity and
extremely low impedance. These characteristics are desirable in many
applications including legged robots, exoskeletons for human performance
amplification, robotic arms, haptic interfaces, and adaptive suspensions. We
describe several variations of Series Elastic Actuators that have been
developed using both electric and hydraulic components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3957</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3957</id><created>2009-12-19</created><authors><author><keyname>Patel</keyname><forenames>Dhiren R.</forenames></author><author><keyname>Khuba</keyname><forenames>Sidheshwar A.</forenames></author></authors><title>Realization of Semantic Atom Blog</title><categories>cs.IR</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 34-38, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web blog is used as a collaborative platform to publish and share
information. The information accumulated in the blog intrinsically contains the
knowledge. The knowledge shared by the community of people has intangible value
proposition. The blog is viewed as a multimedia information resource available
on the Internet. In a blog, information in the form of text, image, audio and
video builds up exponentially. The multimedia information contained in an Atom
blog does not have the capability, which is required by the software processes
so that Atom blog content can be accessed, processed and reused over the
Internet. This shortcoming is addressed by exploring OWL knowledge modeling,
semantic annotation and semantic categorization techniques in an Atom blog
sphere. By adopting these techniques, futuristic Atom blogs can be created and
deployed over the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3959</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3959</id><created>2009-12-19</created><authors><author><keyname>Kent</keyname><forenames>Chow Kok</forenames></author><author><keyname>Salim</keyname><forenames>Naomie</forenames></author></authors><title>Web Based Cross Language Plagiarism Detection</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 39-43, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Internet help us cross language and cultural border by providing
different types of translation tools, cross language plagiarism, also known as
translation plagiarism are bound to arise. Especially among the academic works,
such issue will definitely affect the student's works including the quality of
their assignments and paper works. In this paper, we propose a new approach in
detecting cross language plagiarism. Our web based cross language plagiarism
detection system is specially tuned to detect translation plagiarism by
implementing different techniques and tools to assist the detection process.
Google Translate API is used as our translation tool and Google Search API,
which is used in our information retrieval process. Our system is also
integrated with the fingerprint matching technique, which is a widely used
plagiarism detection technique. In general, our proposed system is started by
translating the input documents from Malay to English, followed by removal of
stop words and stemming words, identification of similar documents in corpus,
comparison of similar pattern and finally summary of the result. Three
least-frequent 4-grams fingerprint matching is used to implement the core
comparison phase during the plagiarism detection process. In K-gram fingerprint
matching technique, although any value of K can be considered, yet K = 4 was
stated as an ideal choice. This is because smaller values of K (i.e., K = 1, 2,
or 3), do not provide good discrimination between sentences. On the other hand,
the larger the values of K (i.e., K = 5, 6, 7...etc), the better discrimination
of words in one sentence from words in another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3960</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3960</id><created>2009-12-19</created><updated>2009-12-23</updated><authors><author><keyname>Linda</keyname><forenames>M. Mary</forenames></author><author><keyname>Nair</keyname><forenames>N. Kesavan</forenames></author></authors><title>Optimal Design of Fuzzy Based Power System Stabilizer Self Tuned by
  Robust Search Algorithm</title><categories>cs.NE</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 44-48, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the interconnected power system network, instability problems are caused
mainly by the low frequency oscillations of 0.2 to 2.5 Hz. The supplementary
control signal in addition with AVR and high gain excitation systems are
provided by means of Power System Stabilizer (PSS). Conventional power system
stabilizers provide effective damping only on a particular operating point. But
fuzzy based PSS provides good damping for a wide range of operating points. The
bottlenecks faced in designing a fuzzy logic controller can be minimized by
using appropriate optimization techniques like Genetic Algorithm, Particle Swam
Optimization, Ant Colony Optimization etc.In this paper the membership
functions of FLC are optimized by the new breed optimization technique called
Genetic Algorithm. This design methodology is implemented on a Single Machine
Infinite Bus (SMIB) system. Simulation results on SMIB show the effectiveness
and robustness of the proposed PSS over a wide range of operating conditions
and system configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3961</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3961</id><created>2009-12-19</created><authors><author><keyname>Chen</keyname><forenames>Yee Ming</forenames></author><author><keyname>Wang</keyname><forenames>Bo-Yuan</forenames></author><author><keyname>Shiu</keyname><forenames>Hung-Ming</forenames></author></authors><title>Enhancing Multi-Agent Based Simulation with Human-Agents Interactive
  Spatial Behaviour</title><categories>cs.MA</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 49-56, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are exploring the enhancement of models of agent behaviour with more
&quot;human-like&quot; decision making strategies than are presently available. Our
motivation is to developed with a view to as the decision analysis and support
for electric taxi company under the mission of energy saving and reduction of
CO2, in particular car-pool and car-sharing management policies. In order to
achieve the object of decision analysis for user, we provide a human-agents
interactive spatial behaviour to support user making decision real time. We
adopt passenger average waiting time and electric taxi average idle time as the
performance measures and decision support fro electric taxi company. Finally,
according to the analysis result, we demonstrate that our multi-agent
simulation and GUI can help users or companies quickly make a quality and
accurate decision to reduce the decision-making cost and time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3962</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3962</id><created>2009-12-19</created><authors><author><keyname>MadhusudhanaRao</keyname><forenames>G.</forenames></author><author><keyname>SankerRam</keyname><forenames>B. V.</forenames></author></authors><title>Speed Control of Multi Level Inverter Designed DC Series Motor with
  Neuro-Fuzzy Controllers</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 179-186, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the speed control of a DC series motor for an accurate
and high-speed performance. A neural network based controlling operation with
fuzzy modeling is suggested in this paper. The driver units of these machines
are designed with a Multi-level inverter operation and are controlled by a
common current control mechanism for an accurate and efficient driving
technique for DC series motor. The neuro-fuzzy logic control technique is
introduced to eliminate uncertainties in the plant parameters of the DC Series
motors, and also considered as potential candidate for different applications
to prove adequacy of the proposed control algorithm through simulations. The
simulation result with such an approach is made and observed efficient over
other controlling technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3963</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3963</id><created>2009-12-19</created><authors><author><keyname>AL-Matari</keyname><forenames>Hani M.</forenames></author><author><keyname>Aboud</keyname><forenames>Sattar J.</forenames></author><author><keyname>Shilbayeh</keyname><forenames>Nidal F.</forenames></author></authors><title>Fast Fraction-Integer Method for Computing Multiplicative Inverse</title><categories>cs.DS</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 131-135, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiplicative inverse is a crucial operation in public key cryptography, and
been widely used in cryptography. Public key cryptography has given rise to
such a need, in which we need to generate a related public and private pair of
numbers, each of which is the inverse of the other. The basic method to find
multiplicative inverses is Extended-Euclidean method. In this paper we will
propose a new algorithm for computing the inverse, based on continues subtract
fraction from integer and divide by fraction to obtain integer that will be
used to compute the inverse d. The authors claim that the proposed method more
efficient and faster than the existed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3964</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3964</id><created>2009-12-19</created><authors><author><keyname>Jagatheeswari</keyname><forenames>P.</forenames></author><author><keyname>Rajaram</keyname><forenames>M.</forenames></author></authors><title>A Novel Channel Coding for Progressive Transmission of Medical Images</title><categories>cs.IT math.IT</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 57-60, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel channel coding scheme for progressive transmission of large images is
proposed. The transmission time, low distortion reconstructed image and low
complexity are most concerned in this paper. In the case of medical data
transmission, it is vital to keep the distortion level under control as in most
of the cases certain clinically important regions have to be transmitted
without any visible error. The proposed system significantly reduces the
transmission time and error. The progressive transmission is based on the
process that the input image is decomposed into many subblocks each to be
coded, compressed, and transmitted individually. Therefore, firstly the image
is segmented into a number of subblocks and then the discrete wavelet transform
decomposes each subblock into different time-frequency components. Finally the
components are coded for error control and transmitted. The complete system is
coded in VHDL. In the proposed system, we choose a 3-level Haar wavelet
transform to perform the wavelet transform for each subblock. It is simple,
faster and easier to implement when compared with other transform method. The
channel coding used here is Hamming code which is a simpler and efficient
forward error control code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3965</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3965</id><created>2009-12-19</created><authors><author><keyname>Rajendran</keyname><forenames>T.</forenames></author><author><keyname>Balasubramanie</keyname><forenames>P.</forenames></author></authors><title>Analysis on the Study of QoS-Aware Web Services Discovery</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 119-130, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web service technology has gained more important role in developing
distributed applications and systems on the Internet. Rapid growth of published
Web services makes their discovery more and more difficult. There exist many
web services which exhibit similar functional characteristics. It is imperative
to provide service consumers with facilities for selecting required web
services according to their non-functional characteristics or QoS. The
QoS-based web service discovery mechanisms will play an essential role in SOA,
as e-Business applications want to use services that most accurately meet their
requirements. However, representing and storing the values of QoS attributes
are problematic, as the current UDDI was not designed to accommodate these
emerging requirements. To solve the problems of storing QoS in UDDI and
aggregating QoS values using the tModel approach. The aim is to study these
approaches and other existing QoS tModel representation for their efficiency
and consistency in service discovery. This paper discusses a broad range of
research issues such as web service discovery or web service selection based on
QoS in the E-Business domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3966</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3966</id><created>2009-12-19</created><authors><author><keyname>Kumar</keyname><forenames>Shishir</forenames></author><author><keyname>Kumar</keyname><forenames>Mahesh</forenames></author></authors><title>Towards Expeditious and Unswerving Routing to Corroborate Nascent
  Internet</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 114-118, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The internet is now-a-days experiencing a stress due to some inherent
problems with the main interdomain routing protocol, boarder gateway protocol
(BGP), the amount of time it takes to converge, number of update message
exchanged followed by a failure to stabilize, the amount of time required to
get a valid alternate path following the failure, the way size of routing table
increasing, and security issues like integrity and privacy of routing tables
and routing updates exchanged among the routers, are of our primary concern. In
our proposed research work we plan to address aforementioned issues related to
internet routing specially in boarder gateway protocol to enable BGP to offer
expeditious unswerving routing to corroborate nascent internet. We plan to make
some changes in the design of boarder gateway protocol and may introduce
addition of extra features in BGP to help support above mentioned objective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3969</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3969</id><created>2009-12-19</created><authors><author><keyname>Danubianu</keyname><forenames>Mirela</forenames></author><author><keyname>Tobolcea</keyname><forenames>Iolanda</forenames></author><author><keyname>Pentiuc</keyname><forenames>Stefan Gheorghe</forenames></author></authors><title>Advanced Technology in Speech Disorder Therapy of Romanian Language</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 61-66, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key challenges of the society development is related to public
health and one of its specific targets includes better treatments of diseases.
It is true that there are affections which by their nature do not endanger the
life of a person, but they may have negative implications during his/her
lifetime. Various language or speech disorders are part of this category.
Discovered and treated in time, they can be corrected, most often in childhood.
Because the Romanian language is a phonetic one that has its own special
linguistic particularities, there is a real need to develop advanced
information systems, which can be used to assist and help specialists in
different speech disorders therapy. The aim of this paper is to present a few
CBTS developed for the treatment of various language and speech disorders
specific to the Romanian language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3970</identifier>
 <datestamp>2009-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3970</id><created>2009-12-19</created><updated>2009-12-26</updated><authors><author><keyname>Naik</keyname><forenames>Nitin A.</forenames></author><author><keyname>Kurundkar</keyname><forenames>Gajanan D.</forenames></author><author><keyname>Khamitkar</keyname><forenames>Santosh D.</forenames></author><author><keyname>Kalyankar</keyname><forenames>Namdeo V.</forenames></author></authors><title>Penetration Testing: A Roadmap to Network Security</title><categories>cs.NI cs.CR</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 187-190, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network penetration testing identifies the exploits and vulnerabilities those
exist within computer network infrastructure and help to confirm the security
measures. The objective of this paper is to explain methodology and methods
behind penetration testing and illustrate remedies over it, which will provide
substantial value for network security Penetration testing should model real
world attacks as closely as possible. An authorized and scheduled penetration
testing will probably detected by IDS (Intrusion Detection System). Network
penetration testing is done by either or manual automated tools. Penetration
test can gather evidence of vulnerability in the network. Successful testing
provides indisputable evidence of the problem as well as starting point for
prioritizing remediation. Penetration testing focuses on high severity
vulnerabilities and there are no false positive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3971</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3971</id><created>2009-12-19</created><authors><author><keyname>Rodthong</keyname><forenames>S.</forenames></author><author><keyname>Burapattanasiri</keyname><forenames>B.</forenames></author></authors><title>The Effected Oxide Capacitor in CMOS Structure of Integrated Circuit
  Level 5 Micrometer Technology</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 67-70, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is present the effected oxide capacitor in CMOS structure of
integrated circuit level 5 micrometer technology. It has designed and basic
structure of MOS diode. It establish with aluminum metallization layer by
sputtering method, oxide insulator layer mode from silicon dioxide, n+ and p+
semiconductor layer, it has high capacitance concentrate. From the MOS diode
structure silicon dioxide thickness 0.5 micrometer, it will get capacitance
between aluminum metal layer and p+ semiconductor at 28.62 pF, the capacitance
between aluminum metal layer and n+ semiconductor at 29.55 pF. In this article
establish second metal layer for measurement density values of first aluminum
metal layer with second aluminum metal layer, it has density values at 16 pF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3972</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3972</id><created>2009-12-19</created><authors><author><keyname>Kalyankar</keyname><forenames>Namdeo V.</forenames></author></authors><title>Network Traffic Management</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 191-194, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purposes of this paper have to discuss issues related to Network Traffic
Management. A relatively new category of network management is fast becoming a
necessity in converged business Networks. Mid-sized and large organizations are
finding they must control network traffic behavior to assure that their
strategic applications always get the resources they need to perform optimally.
Controlling network traffic requires limiting bandwidth to certain
applications, guaranteeing minimum bandwidth to others, and marking traffic
with high or low priorities. This exercise is called Network Traffic
Management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3973</identifier>
 <datestamp>2009-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3973</id><created>2009-12-19</created><updated>2009-12-26</updated><authors><author><keyname>Phinyomark</keyname><forenames>Angkoon</forenames></author><author><keyname>Limsakul</keyname><forenames>Chusak</forenames></author><author><keyname>Phukpattaranont</keyname><forenames>Pornchai</forenames></author></authors><title>A Novel Feature Extraction for Robust EMG Pattern Recognition</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 71-80, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Varieties of noises are major problem in recognition of Electromyography
(EMG) signal. Hence, methods to remove noise become most significant in EMG
signal analysis. White Gaussian noise (WGN) is used to represent interference
in this paper. Generally, WGN is difficult to be removed using typical
filtering and solutions to remove WGN are limited. In addition, noise removal
is an important step before performing feature extraction, which is used in
EMG-based recognition. This research is aimed to present a novel feature that
tolerate with WGN. As a result, noise removal algorithm is not needed. Two
novel mean and median frequencies (MMNF and MMDF) are presented for robust
feature extraction. Sixteen existing features and two novelties are evaluated
in a noisy environment. WGN with various signal-to-noise ratios (SNRs), i.e.
20-0 dB, was added to the original EMG signal. The results showed that MMNF
performed very well especially in weak EMG signal compared with others. The
error of MMNF in weak EMG signal with very high noise, 0 dB SNR, is about 5-10
percent and closed by MMDF and Histogram, whereas the error of other features
is more than 20 percent. While in strong EMG signal, the error of MMNF is
better than those from other features. Moreover, the combination of MMNF,
Histrogram of EMG and Willison amplitude is used as feature vector in
classification task. The experimental result shows the better recognition
result in noisy environment than other success feature candidates. From the
above results demonstrate that MMNF can be used for new robust feature
extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3974</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3974</id><created>2009-12-19</created><authors><author><keyname>Larrea</keyname><forenames>Martin</forenames></author><author><keyname>Urribarri</keyname><forenames>Dana</forenames></author><author><keyname>Martig</keyname><forenames>Sergio</forenames></author><author><keyname>Castro</keyname><forenames>Silvia</forenames></author></authors><title>Spherical Layout Implementation using Centroidal Voronoi Tessellations</title><categories>cs.CG</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 81-86, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3D tree visualization faces multiple challenges: the election of an
appropriate layout, the use of the interactions that make the data exploration
easier and a metaphor that helps in the process of information understanding. A
good combination of these elements will result in a visualization that
effectively conveys the key features of a complex structure or system to a wide
range of users and permits the analytical reasoning process. In previous works
we presented the Spherical Layout, a technique for 3D tree visualization that
provides an excellent base to achieve those key features. The layout was
implemented using the TriSphere algorithm, a method that discretized the
spheres's surfaces with triangles to achieve a uniform distribution of the
nodes. The goal of this work was centered in a new algorithm for the
implementation of the Spherical layout; we called it the Weighted Spherical
Centroidal Voronoi Tessellations (WSCVT). In this paper we present a detailed
description of this new implementation and a comparison with the TriSphere
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3975</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3975</id><created>2009-12-19</created><authors><author><keyname>Ramasubramanian</keyname><forenames>P.</forenames></author><author><keyname>Iyakutti</keyname><forenames>K.</forenames></author><author><keyname>Thangavelu</keyname><forenames>P.</forenames></author><author><keyname>Winston</keyname><forenames>J. Joy</forenames></author></authors><title>Teaching Result Analysis Using Rough Sets and Data Mining</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 168-174, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of IT and WWW provides different teaching strategies, which
are chosen by teachers. Students can acquire knowledge through different
learning models. The problem based learning is a popular teaching strategy for
teachers. Based on the educational theory, students increase their learning
motivation, which can increase learning effectiveness. In this paper, we
propose a concept map for each student and staff. This map finds the result of
the subjects and also recommends a sequence of remedial teaching. Here, rough
set theory is used for dealing with uncertainty in the hidden pattern of data.
For each competence the lower and upper approximations are calculated based on
the brainstorm maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3978</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3978</id><created>2009-12-20</created><authors><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Diversity-Multiplexing Tradeoff in Multi-Antenna Multi-Relay Networks:
  Improvements and Some Optimality Results</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE transaction on Information Theory in Dec. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the benefits of Amplify-and-Forward (AF) relaying in
the setup of multi-antenna wireless networks. The concept of Random Sequential
(RS) relaying is previously introduced in the literature and showed that it
achieves the maximum diversity gain in a general multi-antenna network. Here,
we show that random unitary matrix multiplication at the relay nodes empowers
the RS scheme to achieve a better Diversity-Multiplexing Tradeoff (DMT) as
compared to the traditional AF relaying. First, we study the case of a
multi-antenna full-duplex single-relay two-hop network, for which we show that
the RS achieves the optimum DMT. Applying this result, we derive a new
achievable DMT for the case of multi-antenna half-duplex parallel relay
network. Interestingly, it turns out that the DMT of the RS scheme is optimum
for the case of multi-antenna two parallel non-interfering half-duplex relays.
Next, we show that random unitary matrix multiplication also improves the DMT
of the Non-Orthogonal AF relaying scheme in the case of a multi-antenna single
relay channel. Finally, we study the general case of multi-antenna full-duplex
relay networks and derive a new lower-bound on its DMT using the RS scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3980</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3980</id><created>2009-12-20</created><authors><author><keyname>Hussein</keyname><forenames>Jamal A.</forenames></author><author><keyname>AlMukhtar</keyname><forenames>Mumtaz A.</forenames></author></authors><title>Fair Exchange of Digital Signatures using RSA-based CEMBS and Offline
  STTP</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 87-91, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the essential security services needed to safeguard online
transactions is fair exchange. In fair exchange protocols two parties can
exchange their signatures in a fair manner, so that either each party gain the
other's signature or no one obtain anything useful. This paper examines
security solutions for achieving fair exchange. It proposes new security
protocols based on the &quot;Certified Encrypted Message Being Signature&quot; (CEMBS) by
using RSA signature scheme. This protocol relies on the help of an &quot;off-line
Semi-Trusted Third Party&quot; (STTP) to achieve fairness. They provide with
confidential protection from the STTP for the exchanged items by limiting the
role and power of the STTP. Three different protocols have been proposed. In
the first protocol, the two main parties exchange their signatures on a common
message. In the second protocol, the signatures are exchanged on two different
messages. While in the third one, the exchange is between confidential data and
signature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3981</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3981</id><created>2009-12-20</created><authors><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Multiplexing Gain of Amplify-Forward Relaying in Wireless Multi-Antenna
  Relay Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE transaction on Information Theory in Dec. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the general multi-antenna multiple-relay network. Every
two nodes of the network are either connected together through a Rayleigh
fading channel or disconnected. We study the ergodic capacity of the network in
the high SNR regime. We prove that the traditional amplify-forward relaying
achieves the maximum multiplexing gain of the network. Furthermore, we show
that the maximum multiplexing gain of the network is equal to the minimum
vertex cut-set of the underlying graph of the network, which can be computed in
polynomial time in terms of the number of network nodes. Finally, the argument
is extended to the multicast and multi-access scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3982</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3982</id><created>2009-12-20</created><authors><author><keyname>Bhanu</keyname><forenames>D.</forenames></author><author><keyname>Madeshwari</keyname><forenames>S. Pavai</forenames></author></authors><title>Retail Market analysis in targeting sales based on Consumer Behaviour
  using Fuzzy Clustering - A Rule Based Mode</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 92-99, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product Bundling and offering products to customers is of critical importance
in retail marketing. In general, product bundling and offering products to
customers involves two main issues, namely identification of product taste
according to demography and product evaluation and selection to increase sales.
The former helps to identify, analyze and understand customer needs according
to the demo-graphical characteristics and correspondingly transform them into a
set of specifications and offerings for people. The latter, concerns with how
to determine the best product strategy and offerings for the customer in
helping the retail market to improve their sales. Existing research has focused
only on identifying patterns for a particular dataset and for a particular
setting. This work aims to develop an explicit decision support for the
retailers to improve their product segmentation for different settings based on
the people characteristics and thereby promoting sales by efficient knowledge
discovery from the existing sales and product records. The work presents a
framework, which models an association relation mapping between the customers
and the clusters of products they purchase in an existing location and helps in
finding rules for a new location. The methodology is based on the integration
of popular data mining approaches such as clustering and association rule
mining. It focuses on the discovery of rules that vary according to the
economic and demographic characteristics and concentrates on marketing of
products based on the population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3983</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3983</id><created>2009-12-20</created><authors><author><keyname>Borah</keyname><forenames>Samarjeet</forenames></author><author><keyname>Ghose</keyname><forenames>Mrinal Kanti</forenames></author></authors><title>Performance Analysis of AIM-K-means &amp; K-means in Quality Cluster
  Generation</title><categories>cs.LG</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 175-178, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among all the partition based clustering algorithms K-means is the most
popular and well known method. It generally shows impressive results even in
considerably large data sets. The computational complexity of K-means does not
suffer from the size of the data set. The main disadvantage faced in performing
this clustering is that the selection of initial means. If the user does not
have adequate knowledge about the data set, it may lead to erroneous results.
The algorithm Automatic Initialization of Means (AIM), which is an extension to
K-means, has been proposed to overcome the problem of initial mean generation.
In this paper an attempt has been made to compare the performance of the
algorithms through implementation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3984</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3984</id><created>2009-12-20</created><authors><author><keyname>Mishra</keyname><forenames>Durgesh Kumar</forenames></author><author><keyname>Shukla</keyname><forenames>Samiksha</forenames></author></authors><title>Multi-Agent Model using Secure Multi-Party Computing in e-Governance</title><categories>cs.MA</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 195-199, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information management and retrieval of all the citizen occurs in almost all
the public service functions. Electronic Government system is an emerging trend
in India through which efforts are made to strive maximum safety and security.
Various solutions for this have been proposed like Shibboleth, Public Key
Infrastructure, Smart Cards and Light Weight Directory Access Protocols. Still,
none of these guarantee 100 percent security. Efforts are being made to provide
common national identity solution to various diverse Government identity cards.
In this paper, we discuss issues related to these solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3985</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3985</id><created>2009-12-20</created><authors><author><keyname>Singh</keyname><forenames>Ram Kumar</forenames></author><author><keyname>Ramajujam</keyname><forenames>T.</forenames></author></authors><title>New Model of Network- a Future Aspect of the Computer Networks</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 100-107, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the number and size of the Network increases, the deficiencies persist,
including network security problems. But there is no shortage of technologies
offered as universal remedy - EIGRP,BGP, OSPF, VoIP, IPv6, IPTV, MPLS, WiFi, to
name a few. There are multiple factors for the current situation. Now a day
during emergent and blossoming stages of network development is no longer
sufficient when the networks are mature and have become everyday tool for
social and business interactions. A new model of network is necessary to find
solutions for today's pressing problems, especially those related to network
security. In this paper out factors leading to current stagnation discusses
critical assumptions behind current networks, how many of them are no longer
valid and have become barriers for implementing real solutions. The paper
concludes by offering new directions for future needs and solving current
challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3986</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3986</id><created>2009-12-20</created><authors><author><keyname>Jalab</keyname><forenames>Hamid. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B</forenames></author></authors><title>Frame Selected Approach for Hiding Data within MPEG Video Using Bit
  Plane Complexity Segmentation</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 108-113, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit Plane Complexity Segmentation (BPCS) digital picture steganography is a
technique to hide data inside an image file. BPCS achieves high embedding rates
with low distortion based on the theory that noise-like regions in an image's
bit-planes can be replaced with noise-like secret data without significant loss
in image quality. . In this framework we will propose a collaborate approach
for select frame for Hiding Data within MPEG Video Using Bit Plane Complexity
Segmentation. This approach will invent high secure data hidden using select
frame form MPEG Video and furthermore we will assign the well-built of the
approach; during this review the author will answer the question why they used
select frame steganography. In additional to the security issues we will use
the digital video as a cover to the data hidden. The reason behind opt the
video cover in this approach is the huge amount of single frames image per sec
which in turn overcome the problem of the data hiding quantity, as the
experiment result shows the success of the hidden data within select frame,
extract data from the frames sequence. These function without affecting the
quality of the video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.3995</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.3995</id><created>2009-12-20</created><updated>2010-06-09</updated><authors><author><keyname>Srinivas</keyname><forenames>Niranjan</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Seeger</keyname><forenames>Matthias</forenames></author></authors><title>Gaussian Process Optimization in the Bandit Setting: No Regret and
  Experimental Design</title><categories>cs.LG</categories><doi>10.1109/TIT.2011.2182033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications require optimizing an unknown, noisy function that is
expensive to evaluate. We formalize this task as a multi-armed bandit problem,
where the payoff function is either sampled from a Gaussian process (GP) or has
low RKHS norm. We resolve the important open problem of deriving regret bounds
for this setting, which imply novel convergence rates for GP optimization. We
analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its
cumulative regret in terms of maximal information gain, establishing a novel
connection between GP optimization and experimental design. Moreover, by
bounding the latter in terms of operator spectra, we obtain explicit sublinear
regret bounds for many commonly used covariance functions. In some important
cases, our bounds have surprisingly weak dependence on the dimensionality. In
our experiments on real sensor data, GP-UCB compares favorably with other
heuristical GP optimization approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4012</identifier>
 <datestamp>2010-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4012</id><created>2009-12-21</created><updated>2010-02-27</updated><authors><author><keyname>Mertikopoulos</keyname><forenames>Panayotis</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author></authors><title>Balancing Traffic in Networks: Redundancy, Learning and the Effect of
  Stochastic Fluctuations</title><categories>math.PR cs.GT cs.IT cs.NI math.IT</categories><comments>39 pages, 4 figures. Incorporated material on nonatomic potential
  games and Braess's paradox; some minor typos have now been corrected</comments><msc-class>Primary 60H10, 60K30, 90B20; secondary 60J70, 91A22, 91A26, 37H10.</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the distribution of traffic in networks whose users try to minimise
their delays by adhering to a simple learning scheme inspired by the replicator
dynamics of evolutionary game theory. The stable steady states of these
dynamics coincide with the network's Wardrop equilibria and form a convex
polytope whose dimension is determined by the network's redundancy (an
important concept which measures the &quot;linear dependence&quot; of the users' paths).
Despite this abundance of stationary points, the long-term behaviour of the
replicator dynamics turns out to be remarkably simple: every solution orbit
converges to a Wardrop equilibrium.
  On the other hand, a major challenge occurs when the users' delays fluctuate
unpredictably due to random external factors. In that case, interior equilibria
are no longer stationary, but strict equilibria remain stochastically stable
irrespective of the fluctuations' magnitude. In fact, if the network has no
redundancy and the users are patient enough, we show that the long-term
averages of the users' traffic flows converge to the vicinity of an
equilibrium, and we also estimate the corresponding invariant measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4023</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4023</id><created>2009-12-20</created><authors><author><keyname>van Glabbeek</keyname><forenames>R. J.</forenames></author><author><keyname>Plotkin</keyname><forenames>G. D.</forenames></author></authors><title>Configuration Structures, Event Structures and Petri Nets</title><categories>cs.LO</categories><comments>Contributed to the Festschrift for Mogens Nielsen's 60th birthday</comments><acm-class>F.3.2</acm-class><journal-ref>Theoretical Computer Science 410(41), 2009, pp. 4111-4159</journal-ref><doi>10.1016/j.tcs.2009.06.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the correspondence between safe Petri nets and event
structures, due to Nielsen, Plotkin and Winskel, is extended to arbitrary nets
without self-loops, under the collective token interpretation. To this end we
propose a more general form of event structure, matching the expressive power
of such nets. These new event structures and nets are connected by relating
both notions with configuration structures, which can be regarded as
representations of either event structures or nets that capture their behaviour
in terms of action occurrences and the causal relationships between them, but
abstract from any auxiliary structure.
  A configuration structure can also be considered logically, as a class of
propositional models, or - equivalently - as a propositional theory in
disjunctive normal from. Converting this theory to conjunctive normal form is
the key idea in the translation of such a structure into a net.
  For a variety of classes of event structures we characterise the associated
classes of configuration structures in terms of their closure properties, as
well as in terms of the axiomatisability of the associated propositional
theories by formulae of simple prescribed forms, and in terms of structural
properties of the associated Petri nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4048</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4048</id><created>2009-12-20</created><authors><author><keyname>Cappell</keyname><forenames>Sylvain E.</forenames></author><author><keyname>Miller</keyname><forenames>Edward Y.</forenames></author></authors><title>Eigenvalues of Transmission Graph Laplacians</title><categories>math.CO cs.DM</categories><msc-class>05C85, 57M15, 68R10, 94C15, 46N50, 52B60, 15A42, 35P15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard notion of the Laplacian of a graph is generalized to the setting
of a graph with the extra structure of a ``transmission`` system. A
transmission system is a mathematical representation of a means of transmitting
(multi-parameter) data along directed edges from vertex to vertex. The
associated transmission graph Laplacian is shown to have many of the former
properties of the classical case, including: an upper Cheeger type bound on the
second eigenvalue minus the first of a geometric isoperimetric character,
relations of this difference of eigenvalues to diameters for k-regular graphs,
eigenvalues for Cayley graphs with transmission systems. An especially natural
transmission system arises in the context of a graph endowed with an
association. Other relations to transmission systems arising naturally in
quantum mechanics, where the transmission matrices are scattering matrices, are
made. As a natural merging of graph theory and matrix theory, there are
numerous potential applications, for example to random graphs and random
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4062</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4062</id><created>2009-12-20</created><authors><author><keyname>Vassev</keyname><forenames>Emil</forenames></author></authors><title>Process Description of COM Object Life Cycle</title><categories>cs.OS cs.SE</categories><comments>15 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this article is to provide for the reader a basic
description of all the steps involved in the COM object life-cycle process. COM
is a software technology and process performer. The first section briefly
introduces the Component Object Model (COM), considering the process of the COM
object life cycle as the baseline of all COM issues. The second part describes
in detail the basic steps of the process - client request, server location,
object creation, interaction, and disconnection. A brief description is given
for the components involved in each step. Finally, the third section provides a
brief conclusion summarizing all the process steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4080</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4080</id><created>2009-12-20</created><updated>2012-07-03</updated><authors><author><keyname>Zirkind</keyname><forenames>Givon</forenames></author></authors><title>Windtalking Computers: Frequency Normalization, Binary Coding Systems
  and Encryption</title><categories>cs.CR</categories><comments>33 pages; 5 Flowcharts; 12 Tables; Glossary Replaced to correct title
  Replaced to add original date written</comments><msc-class>94A60, 14G50</msc-class><acm-class>D.2.11; E.0; E.3; E.m; F.2.0; F.2.1; F.2.2; F.2.m; H.0; H.1.0; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the application of known techniques, knowledge and
technology in a novel way for encryption. Two distinct and separate methods are
presented.
  Method 1: Alter the symbol set of the language by adding additional redundant
symbols for frequent symbols. This will reduce the high frequency of more
commonly used symbols. Hence, frequency analysis upon ciphertext will not be
possible. Hence, decryption will be possible.
  Method 2: Computers use binary base 2. Most encryption systems use ciphering
to convert data to ciphertext. The author presents the theory and several
possible implementations of a method for computers analogous to speaking
another language. This is done by using a binary base other than base 2. Ex.
Fibonacci, Phi or Prime.
  In addition, steganography may be used for creating alternate binary bases.
  This kind of encryption significantly increases the complexity of decryption.
First the binary base must be known. Only then, can decryption begin.
  This kind of encryption also breaks the transitivity of
plaintext-codebook-binary; the correlation of letters-ASCII-base2. With this
transitivity broken, decryption is logically impossible. Coupled with
encrypting the plaintext, binary encryption makes decryption uncrackable. It
may produce false positives--information theoretic secure, and requires much
more computing power to resolve than is currently used in brute force
decryption. Hence, the assertion that these combination of methods are
computationally secure--impervious to brute force.
  The proposed system has a drawback. It is not as compressed as a base2.
(Similar to adding random padding to the encryption.) However, this is
acceptable, since the goal is very strong encryption:
  Both methods are not decryptable by method uncrackable - by conventional,
statistical means.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4084</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4084</id><created>2009-12-21</created><updated>2011-07-28</updated><authors><author><keyname>Sauerbier</keyname><forenames>Charles</forenames></author></authors><title>Computing an Integer Prime Factoring in O(n^2.5)</title><categories>cs.DS cs.CC</categories><comments>This paper has been withdrawn by the author. Paper is withdrawn. On
  review the paper contributes nothing of significance. The runtime analysis of
  the algorithms presented, while correct in terms of number of operations,
  does not represent the complexity of the algorithms in terms of &quot;bits input&quot;.
  A naive mistake in reasoning</comments><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paper is withdrawn. On review the paper contributes little of significance.
The runtime analysis of the algorithms presented, while correct in terms of
number of operations, does not represent the complexity of the algorithms in
terms of &quot;bits input&quot;. A naive mistake in reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4087</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4087</id><created>2009-12-21</created><authors><author><keyname>Ren</keyname><forenames>Wei</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>On the Connectivity and Multihop Delay of Ad Hoc Cognitive Radio
  Networks</title><categories>cs.NI</categories><comments>28 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the multihop delay of ad hoc cognitive radio networks, where the
transmission delay of each hop consists of the propagation delay and the
waiting time for the availability of the communication channel (i.e., the
occurrence of a spectrum opportunity at this hop). Using theories and
techniques from continuum percolation and ergodicity, we establish the scaling
law of the minimum multihop delay with respect to the source-destination
distance in cognitive radio networks. When the propagation delay is negligible,
we show the starkly different scaling behavior of the minimum multihop delay in
instantaneously connected networks as compared to networks that are only
intermittently connected due to scarcity of spectrum opportunities.
Specifically, if the network is instantaneously connected, the minimum multihop
delay is asymptotically independent of the distance; if the network is only
intermittently connected, the minimum multihop delay scales linearly with the
distance. When the propagation delay is nonnegligible but small, we show that
although the scaling order is always linear, the scaling rate for an
instantaneously connected network can be orders of magnitude smaller than the
one for an intermittently connected network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4107</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4107</id><created>2009-12-21</created><authors><author><keyname>Kohnert</keyname><forenames>Axel</forenames></author></authors><title>New [48,16,16] Optimal Linear Binary Block Code</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new [48,16,16] optimal linear binary block code is given. To get this code
a general construction is used which is also described in this paper. The
construction of this new code settles an conjecture mentioned in a 2008 paper
by Janosov et al. where the authors found an new optimal [47,15,16]-code, which
is relevant to the applied construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4115</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4115</id><created>2009-12-21</created><updated>2010-02-26</updated><authors><author><keyname>Sankararaman</keyname><forenames>Swaminathan</forenames></author><author><keyname>Efrat</keyname><forenames>Alon</forenames></author><author><keyname>Ramasubramanian</keyname><forenames>Srinivasan</forenames></author><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author></authors><title>On Channel-Discontinuity-Constraint Routing in Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-channel wireless networks are increasingly being employed as
infrastructure networks, e.g. in metro areas. Nodes in these networks
frequently employ directional antennas to improve spatial throughput. In such
networks, given a source and destination, it is of interest to compute an
optimal path and channel assignment on every link in the path such that the
path bandwidth is the same as that of the link bandwidth and such a path
satisfies the constraint that no two consecutive links on the path are assigned
the same channel, referred to as &quot;Channel Discontinuity Constraint&quot; (CDC).
CDC-paths are also quite useful for TDMA system, where preferably every
consecutive links along a path are assigned different time slots.
  This paper contains several contributions. We first present an $O(N^{2})$
distributed algorithm for discovering the shortest CDC-path between given
source and destination. This improves the running time of the $O(N^{3})$
centralized algorithm of Ahuja et al. for finding the minimum-weight CDC-path.
Our second result is a generalized $t$-spanner for CDC-path; For any $\theta&gt;0$
we show how to construct a sub-network containing only $O(\frac{N}{\theta})$
edges, such that that length of shortest CDC-paths between arbitrary sources
and destinations increases by only a factor of at most
$(1-2\sin{\tfrac{\theta}{2}})^{-2}$. We propose a novel algorithm to compute
the spanner in a distributed manner using only $O(n\log{n})$ messages. An
important conclusion of this scheme is in the case of directional antennas are
used. In this case, it is enough to consider only the two closest nodes in each
cone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4117</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4117</id><created>2009-12-21</created><updated>2010-02-03</updated><authors><author><keyname>G&#xf6;ller</keyname><forenames>Stefan</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>Branching-time model checking of one-counter processes</title><categories>cs.LO cs.CC</categories><report-no>STACS 2010</report-no><acm-class>F.4.1; F.1.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  One-counter processes (OCPs) are pushdown processes which operate only on a
unary stack alphabet. We study the computational complexity of model checking
computation tree logic (CTL) over OCPs. A PSPACE upper bound is inherited from
the modal mu-calculus for this problem. First, we analyze the periodic
behaviour of CTL over OCPs and derive a model checking algorithm whose running
time is exponential only in the number of control locations and a syntactic
notion of the formula that we call leftward until depth. Thus, model checking
fixed OCPs against CTL formulas with a fixed leftward until depth is in P. This
generalizes a result of the first author, Mayr, and To for the expression
complexity of CTL's fragment EF. Second, we prove that already over some fixed
OCP, CTL model checking is PSPACE-hard. Third, we show that there already
exists a fixed CTL formula for which model checking of OCPs is PSPACE-hard. For
the latter, we employ two results from complexity theory: (i) Converting a
natural number in Chinese remainder presentation into binary presentation is in
logspace-uniform NC^1 and (ii) PSPACE is AC^0-serializable. We demonstrate that
our approach can be used to answer further open questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4141</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4141</id><created>2009-12-21</created><authors><author><keyname>Gonzalez-Pereira</keyname><forenames>Borja</forenames><affiliation>University of Extremadura, Department of Information and Communication, Scimago Group, Spain</affiliation></author><author><keyname>Guerrero-Bote</keyname><forenames>Vicente</forenames><affiliation>University of Extremadura, Department of Information and Communication, Scimago Group, Spain</affiliation></author><author><keyname>Moya-Anegon</keyname><forenames>Felix</forenames><affiliation>CSIC, CCHS, IPP, Scimago Group Spain</affiliation></author></authors><title>The SJR indicator: A new indicator of journals' scientific prestige</title><categories>cs.DL physics.soc-ph</categories><comments>21 pages with graphs and tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an indicator of journals' scientific prestige, the SJR
indicator, for ranking scholarly journals based on citation weighting schemes
and eigenvector centrality to be used in complex and heterogeneous citation
networks such Scopus. Its computation methodology is described and the results
after implementing the indicator over Scopus 2007 dataset are compared to an
ad-hoc Journal Impact Factor both generally and inside specific scientific
areas. The results showed that SJR indicator and JIF distributions fitted well
to a power law distribution and that both metrics were strongly correlated,
although there were also major changes in rank. There was an observable general
trend that might indicate that SJR indicator values decreased certain JIF
values whose citedeness was greater than would correspond to their scientific
influence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4164</identifier>
 <datestamp>2010-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4164</id><created>2009-12-21</created><authors><author><keyname>Imai</keyname><forenames>Keiko</forenames></author><author><keyname>Kawamura</keyname><forenames>Akitoshi</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Reem</keyname><forenames>Daniel</forenames></author><author><keyname>Tokuyama</keyname><forenames>Takeshi</forenames></author></authors><title>Distance k-Sectors Exist</title><categories>cs.CG math.MG</categories><comments>10 pages, 5 figures</comments><acm-class>F.2.2; G.0; F.0</acm-class><journal-ref>Computational Geometry 43(9):713-720, November 2010</journal-ref><doi>10.1016/j.comgeo.2010.05.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bisector of two nonempty sets P and Q in a metric space is the set of all
points with equal distance to P and to Q. A distance k-sector of P and Q, where
k is an integer, is a (k-1)-tuple (C_1, C_2, ..., C_{k-1}) such that C_i is the
bisector of C_{i-1} and C_{i+1} for every i = 1, 2, ..., k-1, where C_0 = P and
C_k = Q. This notion, for the case where P and Q are points in Euclidean plane,
was introduced by Asano, Matousek, and Tokuyama, motivated by a question of
Murata in VLSI design. They established the existence and uniqueness of the
distance trisector in this special case. We prove the existence of a distance
k-sector for all k and for every two disjoint, nonempty, closed sets P and Q in
Euclidean spaces of any (finite) dimension, or more generally, in proper
geodesic spaces (uniqueness remains open). The core of the proof is a new
notion of k-gradation for P and Q, whose existence (even in an arbitrary metric
space) is proved using the Knaster-Tarski fixed point theorem, by a method
introduced by Reem and Reich for a slightly different purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4184</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4184</id><created>2009-12-21</created><authors><author><keyname>Zhao</keyname><forenames>Jianhua</forenames></author><author><keyname>Li</keyname><forenames>Xuandong</forenames></author></authors><title>Scope Logic: Extending Hoare Logic for Pointer Program Verification</title><categories>cs.LO</categories><acm-class>F.3.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents an extension to Hoare logic for pointer program
verification. First, the Logic for Partial Function (LPF) used by VDM is
extended to specify memory access using pointers and memory layout of composite
types. Then, the concepts of data-retrieve functions (DRF) and memory-scope
functions (MSF) are introduced in this paper. People can define DRFs to
retrieve abstract values from interconnected concrete data objects. The
definition of the corresponding MSF of a DRF can be derived syntactically from
the definition of the DRF. This MSF computes the set of memory units accessed
when the DRF retrieves an abstract value. This memory unit set is called the
memory scope of the abstract value. Finally, the proof rule of assignment
statements in Hoare's logic is modified to deal with pointers. The basic idea
is that a virtual value keeps unmodified as long as no memory unit in its scope
is over-written. Another proof rule is added for memory allocation statements.
The consequence rule and the rules for control-flow statements are slightly
modified. They are essentially same as their original version in Hoare logic.
  An example is presented to show the efficacy of this logic. We also give some
heuristics on how to verify pointer programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4188</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4188</id><created>2009-12-21</created><updated>2010-02-15</updated><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author></authors><title>The skewness of computer science</title><categories>cs.DL cs.CY</categories><comments>I applied the goodness-of-fit methodology proposed in: A. Clauset, C.
  R. Shalizi, M. E. J. Newman. Power-law distributions in empirical data. SIAM
  Review 51, 661-703 (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer science is a relatively young discipline combining science,
engineering, and mathematics. The main flavors of computer science research
involve the theoretical development of conceptual models for the different
aspects of computing and the more applicative building of software artifacts
and assessment of their properties. In the computer science publication
culture, conferences are an important vehicle to quickly move ideas, and
journals often publish deeper versions of papers already presented at
conferences. These peculiarities of the discipline make computer science an
original research field within the sciences, and, therefore, the assessment of
classical bibliometric laws is particularly important for this field. In this
paper, we study the skewness of the distribution of citations to papers
published in computer science publication venues (journals and conferences). We
find that the skewness in the distribution of mean citedness of different
venues combines with the asymmetry in citedness of articles in each venue,
resulting in a highly asymmetric citation distribution with a power law tail.
Furthermore, the skewness of conference publications is more pronounced than
the asymmetry of journal papers. Finally, the impact of journal papers, as
measured with bibliometric indicators, largely dominates that of proceeding
papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4196</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4196</id><created>2009-12-21</created><authors><author><keyname>Chauve</keyname><forenames>Cedric</forenames></author><author><keyname>Haus</keyname><forenames>Utz-Uwe</forenames></author><author><keyname>Stephen</keyname><forenames>Tamon</forenames></author><author><keyname>You</keyname><forenames>Vivija P.</forenames></author></authors><title>Minimal Conflicting Sets for the Consecutive Ones Property in ancestral
  genome reconstruction</title><categories>q-bio.GN cs.DS</categories><comments>20 pages, 3 figures</comments><journal-ref>J Comput Biol. 2010 Sep;17(9):1167-81</journal-ref><doi>10.1089/cmb.2010.0113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binary matrix has the Consecutive Ones Property (C1P) if its columns can be
ordered in such a way that all 1's on each row are consecutive. A Minimal
Conflicting Set is a set of rows that does not have the C1P, but every proper
subset has the C1P. Such submatrices have been considered in comparative
genomics applications, but very little is known about their combinatorial
structure and efficient algorithms to compute them. We first describe an
algorithm that detects rows that belong to Minimal Conflicting Sets. This
algorithm has a polynomial time complexity when the number of 1's in each row
of the considered matrix is bounded by a constant. Next, we show that the
problem of computing all Minimal Conflicting Sets can be reduced to the joint
generation of all minimal true clauses and maximal false clauses for some
monotone boolean function. We use these methods on simulated data related to
ancestral genome reconstruction to show that computing Minimal Conflicting Set
is useful in discriminating between true positive and false positive ancestral
syntenies. We also study a dataset of yeast genomes and address the reliability
of an ancestral genome proposal of the Saccahromycetaceae yeasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4226</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4226</id><created>2009-12-21</created><updated>2010-02-03</updated><authors><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Gaiser</keyname><forenames>Andreas</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author></authors><title>Computing Least Fixed Points of Probabilistic Systems of Polynomials</title><categories>cs.DS cs.NA</categories><comments>Published in the Proceedings of the 27th International Symposium on
  Theoretical Aspects of Computer Science (STACS). Technical Report is also
  available via arxiv.org</comments><acm-class>F.2.1; G.3</acm-class><journal-ref>Proceedings of the 27th International Symposium on Theoretical
  Aspects of Computer Science (STACS) 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study systems of equations of the form X1 = f1(X1, ..., Xn), ..., Xn =
fn(X1, ..., Xn), where each fi is a polynomial with nonnegative coefficients
that add up to 1. The least nonnegative solution, say mu, of such equation
systems is central to problems from various areas, like physics, biology,
computational linguistics and probabilistic program verification. We give a
simple and strongly polynomial algorithm to decide whether mu=(1, ..., 1)
holds. Furthermore, we present an algorithm that computes reliable sequences of
lower and upper bounds on mu, converging linearly to mu. Our algorithm has
these features despite using inexact arithmetic for efficiency. We report on
experiments that show the performance of our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4241</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4241</id><created>2009-12-21</created><authors><author><keyname>Hammami</keyname><forenames>Oussama</forenames></author><author><keyname>Lathion</keyname><forenames>Christian</forenames></author><author><keyname>Gabrielyan</keyname><forenames>Emin</forenames></author></authors><title>Dynamic routing based on call quality</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The telephony over IP (ToIP) is becoming a new trend in technology widely
used nowadays in almost all business sectors. Its concepts rely on transiting
the telephone communications through the IP network. Today, this technology is
deployed increasingly what the cause of emergence of companies is offering this
service as Switzernet. For several highly demanded destinations, recently fake
vendors appeared in the market offering voice termination but providing only
false answer supervision. The answered signal is returned immediately and calls
are being charged without being connected. Different techniques are used to
keep the calling party on the line. One of these techniques is to play a record
of a ring back tone (while the call is already being charged). Another, more
sophisticated technique is to play a human voice randomly picked up from a set
of records containing contents similar to: hello, hello, I cannot hear you
Apart the fact that the fallaciously established calls are charged at rates of
real calls, such malicious routes seriously handicap the switching process. The
system does not detect a failure on signaling level and is unable to attempt
the call via backup routes, the call technically being already connected. Once
the call flow falls into such trap, the calls will continue being routed via
the fraudulent route until a manual intervention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4289</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4289</id><created>2009-12-21</created><updated>2009-12-23</updated><authors><author><keyname>Zanko</keyname><forenames>Avi</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Zehavi</keyname><forenames>Ephraim</forenames></author></authors><title>Turbo Analog Error Correcting Codes Decodable By Linear Programming</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new Turbo analog error correcting coding scheme
for real valued signals that are corrupted by impulsive noise. This Turbo code
improves Donoho's deterministic construction by using a probabilistic approach.
More specifically, our construction corrects more errors than the matrices of
Donoho by allowing a vanishingly small probability of error (with the increase
in block size). The problem of decoding the long block code is decoupled into
two sets of parallel Linear Programming problems. This leads to a significant
reduction in decoding complexity as compared to one-step Linear Programming
decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4323</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4323</id><created>2009-12-22</created><authors><author><keyname>Yadav</keyname><forenames>Mano</forenames></author><author><keyname>Rishiwal</keyname><forenames>Vinay</forenames></author><author><keyname>Arora</keyname><forenames>G.</forenames></author><author><keyname>Makka</keyname><forenames>S.</forenames></author></authors><title>Modified Minimum Connected Dominating Set formation for Wireless Adhoc
  Networks</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 200-203, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nodes of minimum connected dominating set (MCDS) form a virtual backbone in a
wireless adhoc network. In this paper, a modified approach is presented to
determine MCDS of an underlying graph of a Wireless Adhoc network. Simulation
results for a variety of graphs indicate that the approach is efficient in
determining the MCDS as compared to other existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4324</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4324</id><created>2009-12-22</created><authors><author><keyname>Yadav</keyname><forenames>Mano</forenames></author><author><keyname>Rishiwal</keyname><forenames>Vinay</forenames></author><author><keyname>Arya</keyname><forenames>K. V.</forenames></author></authors><title>Routing in Wireless Adhoc Networks: A New Horizon</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 1, Issue 1, pp 204-208, December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lot of work has been done on routing protocols for mobile ad hoc networks,
but still standardization of them requires some more issues less addressed by
the existing routing protocols. In this paper a new paradigm of maintaining
multiple connections in adhoc routing protocols has been highlighted which may
be crucial for efficient routing in mobile ad hoc networks. The problem of
multiple connections has been hardly worked on in adhoc networks. In this paper
the solution of route maintenance if nodes are maintaining multiple connections
has been proposed. This idea not only helps to solve the multiple connections
problem, but also take care of proper bandwidth distribution to different
connections as per different traffic types. Study has been incorporated on
existing AODV with changes. Simulation studies have been performed over packet
delivery ratio, throughput and message overheads. Results show that the
proposed solution for multiple connections is efficient and worth implementing
in existing as well as new protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4360</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4360</id><created>2009-12-22</created><authors><author><keyname>Nguyen</keyname><forenames>Manh Thang</forenames></author><author><keyname>De Schreye</keyname><forenames>Danny</forenames></author><author><keyname>Giesl</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Schneider-Kamp</keyname><forenames>Peter</forenames></author></authors><title>Polytool: polynomial interpretations as a basis for termination analysis
  of Logic programs</title><categories>cs.PL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our goal is to study the feasibility of porting termination analysis
techniques developed for one programming paradigm to another paradigm. In this
paper, we show how to adapt termination analysis techniques based on polynomial
interpretations - very well known in the context of term rewrite systems (TRSs)
- to obtain new (non-transformational) ter- mination analysis techniques for
definite logic programs (LPs). This leads to an approach that can be seen as a
direct generalization of the traditional techniques in termination analysis of
LPs, where linear norms and level mappings are used. Our extension general-
izes these to arbitrary polynomials. We extend a number of standard concepts
and results on termination analysis to the context of polynomial
interpretations. We also propose a constraint-based approach for automatically
generating polynomial interpretations that satisfy the termination conditions.
Based on this approach, we implemented a new tool, called Polytool, for
automatic termination analysis of LPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4389</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4389</id><created>2009-12-22</created><updated>2010-06-09</updated><authors><author><keyname>Evans</keyname><forenames>T. S.</forenames></author><author><keyname>Lambiotte</keyname><forenames>R.</forenames></author></authors><title>Line Graphs of Weighted Networks for Overlapping Communities</title><categories>physics.data-an cs.DS physics.soc-ph</categories><comments>8 Pages. New title and text revisions to emphasise differences from
  earlier papers</comments><report-no>Imperial/TP/09/TSE/3</report-no><journal-ref>Eur. Phys. J. B 77 (2010) 265-272</journal-ref><doi>10.1140/epjb/e2010-00261-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop the idea to partition the edges of a weighted graph
in order to uncover overlapping communities of its nodes. Our approach is based
on the construction of different types of weighted line graphs, i.e. graphs
whose nodes are the links of the original graph, that encapsulate differently
the relations between the edges. Weighted line graphs are argued to provide an
alternative, valuable representation of the system's topology, and are shown to
have important applications in community detection, as the usual node partition
of a line graph naturally leads to an edge partition of the original graph.
This identification allows us to use traditional partitioning methods in order
to address the long-standing problem of the detection of overlapping
communities. We apply it to the analysis of different social and geographical
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4390</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4390</id><created>2009-12-22</created><authors><author><keyname>Khodaian</keyname><forenames>Amir M.</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author></authors><title>Delay-Constrained Utility Maximization in Multihop Random Access
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-hop random access networks have received much attention due to their
distributed nature which facilitates deploying many new applications over the
sensor and computer networks. Recently, utility maximization framework is
applied in order to optimize performance of such networks however delay is not
limited and proposed algorithms result in very large transmission delays. In
this paper, we will analyze delay in random access multi-hop networks and solve
the delay-constrained utility maximization problem. We define the network
utility as a combination of rate utility and energy cost functions and solve
the following two problems: 'optimal medium access control with link delay
constraint' and, 'optimal congestion and contention control with end-to-end
delay constraint'. The optimal tradeoff between delay, rate, and energy is
achieved for different values of delay constraint and the scaling factors
between rate and energy. Different distributed solutions will be proposed for
each problem and their performance will be compared in terms of convergence and
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4430</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4430</id><created>2009-12-22</created><authors><author><keyname>Hou</keyname><forenames>Xiaorong</forenames></author><author><keyname>Xu</keyname><forenames>Song</forenames></author></authors><title>Simplex Subdivisions and Nonnegativity Decision of Forms</title><categories>cs.SC</categories><comments>10 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper mainly studies nonnegativity decision of forms based on variable
substitutions. Unlike existing research, the paper regards simplex subdivisions
as new perspectives to study variable substitutions, gives some subdivisions of
the simplex T_n, introduces the concept of convergence of the subdivision
sequence, and presents a sufficient and necessary condition for the convergent
self-similar subdivision sequence. Then the relationships between subdivisions
and their corresponding substitutions are established. Moreover, it is proven
that if the form F is indefinite on T_n and the sequence of the successive
L-substitution sets is convergent, then the sequence of sets {SLS^(m)(F)} is
negatively terminating, and an algorithm for deciding indefinite forms with a
counter-example is obtained. Thus, various effective substitutions for deciding
positive semi-definite forms and indefinite forms are gained, which are beyond
the weighted difference substitutions characterized by &quot;difference&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4438</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4438</id><created>2009-12-22</created><authors><author><keyname>Hou</keyname><forenames>Xiaorong</forenames></author><author><keyname>Xu</keyname><forenames>Song</forenames></author><author><keyname>Shao</keyname><forenames>Junwei</forenames></author></authors><title>The weighted difference substitutions and Nonnegativity Decision of
  Forms</title><categories>cs.SC cs.NA</categories><comments>10 pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the weighted difference substitutions from
geometrical views. First, we give the geometric meanings of the weighted
difference substitutions, and introduce the concept of convergence of the
sequence of substitution sets. Then it is proven that the sequence of the
successive weighted difference substitution sets is convergent. Based on the
convergence of the sequence of the successive weighted difference sets, a new,
simpler method to prove that if the form F is positive definite on T_n, then
the sequence of sets {SDS^m(F)} is positively terminating is presented, which
is different from the one given in [11]. That is, we can decide the
nonnegativity of a positive definite form by successively running the weighted
difference substitutions finite times. Finally, an algorithm for deciding an
indefinite form with a counter-example is obtained, and some examples are
listed by using the obtained algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4473</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4473</id><created>2009-12-22</created><updated>2010-06-26</updated><authors><author><keyname>Vembu</keyname><forenames>Shankar</forenames></author></authors><title>Learning to Predict Combinatorial Structures</title><categories>cs.LG cs.AI</categories><comments>PhD thesis, Department of Computer Science, University of Bonn
  (submitted, December 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The major challenge in designing a discriminative learning algorithm for
predicting structured data is to address the computational issues arising from
the exponential size of the output space. Existing algorithms make different
assumptions to ensure efficient, polynomial time estimation of model
parameters. For several combinatorial structures, including cycles, partially
ordered sets, permutations and other graph classes, these assumptions do not
hold. In this thesis, we address the problem of designing learning algorithms
for predicting combinatorial structures by introducing two new assumptions: (i)
The first assumption is that a particular counting problem can be solved
efficiently. The consequence is a generalisation of the classical ridge
regression for structured prediction. (ii) The second assumption is that a
particular sampling problem can be solved efficiently. The consequence is a new
technique for designing and analysing probabilistic structured prediction
models. These results can be applied to solve several complex learning problems
including but not limited to multi-label classification, multi-category
hierarchical classification, and label ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4506</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4506</id><created>2009-12-22</created><authors><author><keyname>Wittmann</keyname><forenames>Markus</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Multicore-aware parallel temporal blocking of stencil codes for shared
  and distributed memory</title><categories>cs.PF cs.DC</categories><comments>9 pages, 6 figures</comments><doi>10.1109/IPDPSW.2010.5470813</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New algorithms and optimization techniques are needed to balance the
accelerating trend towards bandwidth-starved multicore chips. It is well known
that the performance of stencil codes can be improved by temporal blocking,
lessening the pressure on the memory interface. We introduce a new pipelined
approach that makes explicit use of shared caches in multicore environments and
minimizes synchronization and boundary overhead. For clusters of shared-memory
nodes we demonstrate how temporal blocking can be employed successfully in a
hybrid shared/distributed-memory environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4546</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4546</id><created>2009-12-22</created><updated>2011-11-23</updated><authors><author><keyname>Wang</keyname><forenames>Yun-Jiang</forenames></author><author><keyname>Sanders</keyname><forenames>Barry C.</forenames></author><author><keyname>Bai</keyname><forenames>Bao-Ming</forenames></author><author><keyname>Wang</keyname><forenames>Xin-Mei</forenames></author></authors><title>Enhanced Feedback Iterative Decoding of Sparse Quantum Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>10 pages, 11 figures, Second version, To be appeared in IEEE
  Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory 58 (2): 1231-1241 (6
  February 2012)</journal-ref><doi>10.1109/TIT.2011.2169534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decoding sparse quantum codes can be accomplished by syndrome-based decoding
using a belief propagation (BP) algorithm.We significantly improve this
decoding scheme by developing a new feedback adjustment strategy for the
standard BP algorithm. In our feedback procedure, we exploit much of the
information from stabilizers, not just the syndrome but also the values of the
frustrated checks on individual qubits of the code and the channel model.
Furthermore we show that our decoding algorithm is superior to belief
propagation algorithms using only the syndrome in the feedback procedure for
all cases of the depolarizing channel. Our algorithm does not increase the
measurement overhead compared to the previous method, as the extra information
comes for free from the requisite stabilizer measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4553</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4553</id><created>2009-12-22</created><authors><author><keyname>Filho</keyname><forenames>Reginaldo J. da Silva</forenames></author><author><keyname>Brust</keyname><forenames>Matthias R.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Carlos H. C.</forenames></author></authors><title>Consensus Dynamics in a non-deterministic Naming Game with Shared Memory</title><categories>cs.MA cs.AI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the naming game, individuals or agents exchange pairwise local information
in order to communicate about objects in their common environment. The goal of
the game is to reach a consensus about naming these objects. Originally used to
investigate language formation and self-organizing vocabularies, we extend the
classical naming game with a globally shared memory accessible by all agents.
This shared memory can be interpreted as an external source of knowledge like a
book or an Internet site. The extended naming game models an environment
similar to one that can be found in the context of social bookmarking and
collaborative tagging sites where users tag sites using appropriate labels, but
also mimics an important aspect in the field of human-based image labeling.
Although the extended naming game is non-deterministic in its word selection,
we show that consensus towards a common vocabulary is reached. More
importantly, we show the qualitative and quantitative influence of the external
source of information, i.e. the shared memory, on the consensus dynamics
between the agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4556</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4556</id><created>2009-12-22</created><authors><author><keyname>Dusad</keyname><forenames>S.</forenames></author><author><keyname>Diggavi</keyname><forenames>S. N.</forenames></author></authors><title>On successive refinement of diversity for fading ISI channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rate and diversity impose a fundamental trade-off in communications. This
trade-off was investigated for flat-fading channels in [15] as well as for
Inter-symbol Interference (ISI) channels in [1]. A different point of view was
explored in [12] where high-rate codes were designed so that they have a
high-diversity code embedded within them. These diversity embedded codes were
investigated for flat fading channels both from an information theoretic
viewpoint [5] and from a coding theory viewpoint in [2]. In this paper we
explore the use of diversity embedded codes for inter-symbol interference
channels. In particular the main result of this paper is that the diversity
multiplexing trade-off for fading MISO/SIMO/SISO ISI channels is indeed
successively refinable. This implies that for fading ISI channels with a single
degree of freedom one can embed a high diversity code within a high rate code
without any performance loss (asymptotically). This is related to a
deterministic structural observation about the asymptotic behavior of frequency
response of channel with respect to fading strength of time domain taps as well
as a coding scheme to take advantage of this observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4564</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4564</id><created>2009-12-23</created><updated>2011-09-29</updated><authors><author><keyname>Shimada</keyname><forenames>Manabu</forenames></author><author><keyname>Amano</keyname><forenames>Kazuyuki</forenames></author></authors><title>A Note on the Middle Levels Conjecture</title><categories>cs.DM</categories><comments>10 pages, 7 figures; Note on the results of k=19 is added at the end
  of the paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The middle levels conjecture asserts that there is a Hamiltonian cycle in the
middle two levels of $2k+1$-dimensional hypercube. The conjecture is known to
be true for $k \leq 17$ [I.Shields, B.J.Shields and C.D.Savage, Disc. Math.,
309, 5271--5277 (2009)]. In this note, we verify that the conjecture is also
true for $k=18$ by constructing a Hamiltonian cycle in the middle two levels of
37-dimensional hypercube with the aid of the computer. We achieve this by
introducing a new decomposition technique and an efficient algorithm for
ordering the Narayana objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4569</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4569</id><created>2009-12-23</created><updated>2010-02-03</updated><authors><author><keyname>Chan</keyname><forenames>Ho-Leung</forenames></author><author><keyname>Lam</keyname><forenames>Tak-Wah</forenames></author><author><keyname>Lee</keyname><forenames>Lap-Kei</forenames></author><author><keyname>Ting</keyname><forenames>Hing-Fung</forenames></author></authors><title>Continuous Monitoring of Distributed Data Streams over a Time-based
  Sliding Window</title><categories>cs.DS</categories><comments>12 pages, to appear in the 27th International Symposium on
  Theoretical Aspects of Computer Science (STACS), 2010</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past decade has witnessed many interesting algorithms for maintaining
statistics over a data stream. This paper initiates a theoretical study of
algorithms for monitoring distributed data streams over a time-based sliding
window (which contains a variable number of items and possibly out-of-order
items). The concern is how to minimize the communication between individual
streams and the root, while allowing the root, at any time, to be able to
report the global statistics of all streams within a given error bound. This
paper presents communication-efficient algorithms for three classical
statistics, namely, basic counting, frequent items and quantiles. The
worst-case communication cost over a window is $O(\frac{k} {\epsilon} \log
\frac{\epsilon N}{k})$ bits for basic counting and $O(\frac{k}{\epsilon} \log
\frac{N}{k})$ words for the remainings, where $k$ is the number of distributed
data streams, $N$ is the total number of items in the streams that arrive or
expire in the window, and $\epsilon &lt; 1$ is the desired error bound. Matching
and nearly matching lower bounds are also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4571</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4571</id><created>2009-12-23</created><updated>2010-10-13</updated><authors><author><keyname>Goldfarb</keyname><forenames>Donald</forenames></author><author><keyname>Ma</keyname><forenames>Shiqian</forenames></author><author><keyname>Scheinberg</keyname><forenames>Katya</forenames></author></authors><title>Fast Alternating Linearization Methods for Minimizing the Sum of Two
  Convex Functions</title><categories>math.OC cs.CV math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper first-order alternating linearization algorithms
based on an alternating direction augmented Lagrangian approach for minimizing
the sum of two convex functions. Our basic methods require at most
$O(1/\epsilon)$ iterations to obtain an $\epsilon$-optimal solution, while our
accelerated (i.e., fast) versions of them require at most
$O(1/\sqrt{\epsilon})$ iterations, with little change in the computational
effort required at each iteration. For both types of methods, we present one
algorithm that requires both functions to be smooth with Lipschitz continuous
gradients and one algorithm that needs only one of the functions to be so.
Algorithms in this paper are Gauss-Seidel type methods, in contrast to the ones
proposed by Goldfarb and Ma in [21] where the algorithms are Jacobi type
methods. Numerical results are reported to support our theoretical conclusions
and demonstrate the practical potential of our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4584</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4584</id><created>2009-12-23</created><authors><author><keyname>Jain</keyname><forenames>Brijnesh</forenames></author><author><keyname>Obermayer</keyname><forenames>Klaus</forenames></author></authors><title>A Necessary and Sufficient Condition for Graph Matching Being Equivalent
  to the Maximum Weight Clique Problem</title><categories>cs.AI</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formulates a necessary and sufficient condition for a generic
graph matching problem to be equivalent to the maximum vertex and edge weight
clique problem in a derived association graph. The consequences of this results
are threefold: first, the condition is general enough to cover a broad range of
practical graph matching problems; second, a proof to establish equivalence
between graph matching and clique search reduces to showing that a given graph
matching problem satisfies the proposed condition; and third, the result sets
the scene for generic continuous solutions for a broad range of graph matching
problems. To illustrate the mathematical framework, we apply it to a number of
graph matching problems, including the problem of determining the graph edit
distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4595</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4595</id><created>2009-12-23</created><updated>2011-04-11</updated><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>On the Optimal Number of Cooperative Base Stations in Network MIMO</title><categories>cs.IT math.IT</categories><comments>A revised version of the corresponding journal paper can be found
  under the new title: &quot;Optimal Channel Training in Uplink Network MIMO
  Systems&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the multi-cell uplink (network MIMO) where M base-stations (BSs)
communicate simultaneously with M user terminals (UTs). Although the potential
benefit of multi-cell cooperation increases with M, the overhead related to
learning the uplink channels will rapidly dominate the uplink resource. In
other words, there exists a non-trivial tradeoff between the performance gains
of network MIMO and the related overhead in channel estimation for a finite
coherence time. We use a close approximation of the ergodic capacity to study
this tradeoff by taking some realistic aspects into account such as unreliable
backhaul links and different path losses between the BSs and UTs. Our results
provide some insight into practical limitations as well as realistic dimensions
of network MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4598</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4598</id><created>2009-12-23</created><authors><author><keyname>Jain</keyname><forenames>Brijnesh J.</forenames></author><author><keyname>Obermayer</keyname><forenames>Klaus</forenames></author></authors><title>Elkan's k-Means for Graphs</title><categories>cs.AI</categories><comments>21 pages; submitted to MLJ</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends k-means algorithms from the Euclidean domain to the domain
of graphs. To recompute the centroids, we apply subgradient methods for solving
the optimization-based formulation of the sample mean of graphs. To accelerate
the k-means algorithm for graphs without trading computational time against
solution quality, we avoid unnecessary graph distance calculations by
exploiting the triangle inequality of the underlying distance metric following
Elkan's k-means algorithm proposed in \cite{Elkan03}. In experiments we show
that the accelerated k-means algorithm are faster than the standard k-means
algorithm for graphs provided there is a cluster structure in the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4602</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4602</id><created>2009-12-23</created><updated>2010-02-03</updated><authors><author><keyname>Das</keyname><forenames>Bireswar</forenames></author><author><keyname>Datta</keyname><forenames>Samir</forenames></author><author><keyname>Nimbhorkar</keyname><forenames>Prajakta</forenames></author></authors><title>Log-space Algorithms for Paths and Matchings in k-trees</title><categories>cs.CC</categories><comments>Accepted in STACS 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Reachability and shortest path problems are NL-complete for general graphs.
They are known to be in L for graphs of tree-width 2 [JT07]. However, for
graphs of tree-width larger than 2, no bound better than NL is known. In this
paper, we improve these bounds for k-trees, where k is a constant. In
particular, the main results of our paper are log-space algorithms for
reachability in directed k-trees, and for computation of shortest and longest
paths in directed acyclic k-trees.
  Besides the path problems mentioned above, we also consider the problem of
deciding whether a k-tree has a perfect macthing (decision version), and if so,
finding a perfect match- ing (search version), and prove that these two
problems are L-complete. These problems are known to be in P and in RNC for
general graphs, and in SPL for planar bipartite graphs [DKR08].
  Our results settle the complexity of these problems for the class of k-trees.
The results are also applicable for bounded tree-width graphs, when a
tree-decomposition is given as input. The technique central to our algorithms
is a careful implementation of divide-and-conquer approach in log-space, along
with some ideas from [JT07] and [LMR07].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4613</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4613</id><created>2009-12-23</created><updated>2010-04-03</updated><authors><author><keyname>Arjona-Villica&#xf1;a</keyname><forenames>P. David</forenames></author><author><keyname>Constantinou</keyname><forenames>Costas C.</forenames></author><author><keyname>Stepanenko</keyname><forenames>Alexander S.</forenames></author></authors><title>Chain Routing: A new routing framework for the Internet based on
  complete orders</title><categories>cs.NI</categories><comments>Submitted to Computer Networks</comments><journal-ref>IET Communications 5(16), 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new framework to perform routing at the Autonomous System level is proposed
in this paper. This mechanism, called Chain Routing, uses complete orders as
its main topological unit. Since complete orders are acyclic digraphs that
possess a known topology, it is possible to define an acyclic structure to
route packets between a group of Autonomous Systems. The adoption of complete
orders also allows easy identification and avoidance of persistent route
oscillations, eliminates the possibility of developing transient loops in
paths, and provides a structure that facilitates the implementation of traffic
engineering. Moreover, by combining Chain Routing with other mechanisms that
implement complete orders in time, we suggest that it is possible to design a
new routing protocol which could be more reliable and stable than BGP's current
implementation. Although Chain Routing will require an increase of the message
overhead and greater coordination between network administrators, the rewards
in stability and resilience should more than compensate for this effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4637</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4637</id><created>2009-12-23</created><authors><author><keyname>Bergstra</keyname><forenames>Jan</forenames></author><author><keyname>Burgess</keyname><forenames>Mark</forenames></author></authors><title>Local and Global Trust Based on the Concept of Promises</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the notion of a promise to define local trust between agents
possessing autonomous decision-making. An agent is trustworthy if it is
expected that it will keep a promise. This definition satisfies most
commonplace meanings of trust. Reputation is then an estimation of this
expectation value that is passed on from agent to agent.
  Our definition distinguishes types of trust, for different behaviours, and
decouples the concept of agent reliability from the behaviour on which the
judgement is based. We show, however, that trust is fundamentally heuristic, as
it provides insufficient information for agents to make a rational judgement. A
global trustworthiness, or community trust can be defined by a proportional,
self-consistent voting process, as a weighted eigenvector-centrality function
of the promise theoretical graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4649</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4649</id><created>2009-12-23</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Reznikova</keyname><forenames>Zhanna</forenames></author></authors><title>The use of ideas of Information Theory for studying &quot;language&quot; and
  intelligence in ants</title><categories>cs.IT cs.AI math.IT nlin.AO</categories><journal-ref>Entropy 2009, 11(4), 836-853</journal-ref><doi>10.3390/e11040836</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this review we integrate results of long term experimental study on ant
&quot;language&quot; and intelligence which were fully based on fundamental ideas of
Information Theory, such as the Shannon entropy, the Kolmogorov complexity, and
the Shannon's equation connecting the length of a message ($l$) and its
frequency $(p)$, i.e. $l = - \log p$ for rational communication systems. This
approach, new for studying biological communication systems, enabled us to
obtain the following important results on ants' communication and intelligence:
i) to reveal &quot;distant homing&quot; in ants, that is, their ability to transfer
information about remote events; ii) to estimate the rate of information
transmission; iii) to reveal that ants are able to grasp regularities and to
use them for &quot;compression&quot; of information; iv) to reveal that ants are able to
transfer to each other the information about the number of objects; v) to
discover that ants can add and subtract small numbers. The obtained results
show that Information Theory is not only wonderful mathematical theory, but
many its results may be considered as Nature laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4660</identifier>
 <datestamp>2014-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4660</id><created>2009-12-23</created><authors><author><keyname>Rauh</keyname><forenames>Johannes</forenames></author></authors><title>Finding the Maximizers of the Information Divergence from an Exponential
  Family</title><categories>cs.IT math.IT</categories><comments>25 pages</comments><msc-class>94A17, 52A20, 13P25</msc-class><journal-ref>IEEE transactions on information theory, 57 (2011) 6, p. 3236-3247</journal-ref><doi>10.1109/TIT.2011.2136230</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates maximizers of the information divergence from an
exponential family $E$. It is shown that the $rI$-projection of a maximizer $P$
to $E$ is a convex combination of $P$ and a probability measure $P_-$ with
disjoint support and the same value of the sufficient statistics $A$. This
observation can be used to transform the original problem of maximizing
$D(\cdot||E)$ over the set of all probability measures into the maximization of
a function $\Dbar$ over a convex subset of $\ker A$. The global maximizers of
both problems correspond to each other. Furthermore, finding all local
maximizers of $\Dbar$ yields all local maximizers of $D(\cdot||E)$.
  This paper also proposes two algorithms to find the maximizers of $\Dbar$ and
applies them to two examples, where the maximizers of $D(\cdot||E)$ were not
known before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4694</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4694</id><created>2009-12-23</created><authors><author><keyname>Sauerbier</keyname><forenames>Charles</forenames></author></authors><title>Discovery of Elliptic Curve Cryptographic Private Key in O(n)</title><categories>cs.CR</categories><comments>2 pages, 0 figures</comments><acm-class>E.3; F.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm is presented that in context of public key use of Elliptic Curve
Cryptography allows discovery of the private key in worst case O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4742</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4742</id><created>2009-12-23</created><updated>2010-09-06</updated><authors><author><keyname>Li</keyname><forenames>Chao</forenames></author><author><keyname>Hay</keyname><forenames>Michael</forenames></author><author><keyname>Rastogi</keyname><forenames>Vibhor</forenames></author><author><keyname>Miklau</keyname><forenames>Gerome</forenames></author><author><keyname>McGregor</keyname><forenames>Andrew</forenames></author></authors><title>Optimizing Histogram Queries under Differential Privacy</title><categories>cs.DB cs.CR</categories><comments>22 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a robust privacy standard that has been successfully
applied to a range of data analysis tasks. Despite much recent work, optimal
strategies for answering a collection of correlated queries are not known.
  We study the problem of devising a set of strategy queries, to be submitted
and answered privately, that will support the answers to a given workload of
queries. We propose a general framework in which query strategies are formed
from linear combinations of counting queries, and we describe an optimal method
for deriving new query answers from the answers to the strategy queries. Using
this framework we characterize the error of strategies geometrically, and we
propose solutions to the problem of finding optimal strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4798</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4798</id><created>2009-12-24</created><authors><author><keyname>Chatpatanasiri</keyname><forenames>Ratthachat</forenames></author><author><keyname>Sriburi</keyname><forenames>Thavivongse</forenames></author></authors><title>Demand-Supply Optimization with Risk Management for a Multi-Connection
  Water Reservoir Network</title><categories>cs.DS</categories><comments>17 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a framework to solve a demand-supply optimization
problem of long-term water resource allocation on a multi-connection reservoir
network which, in two aspects, is different to the problem considered in
previous works. First, while all previous works consider a problem where each
reservoir can transfer water to only one fixed reservoir, we consider a
multi-connection network being constructed in Thailand in which each reservoir
can transfer water to many reservoirs in one period of time. Second, a
demand-supply plan considered here is static, in contrast to a dynamic policy
considered in previous works. Moreover, in order to efficiently develop a
long-term static plan, a severe loss (a risk) is taken into account, i.e. a
risk occurs if the real amount of water stored in each reservoir in each time
period is less than what planned by the optimizer. The multi-connection
function and the risk make the problem rather complex such that traditional
stochastic dynamic programming and deterministic/heuristic approaches are
inappropriate. Our framework is based on a novel convex programming formulation
in which stochastic information can be naturally taken into account and an
optimal solution is guaranteed to be found efficiently. Extensive experimental
results show promising results of the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4807</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4807</id><created>2009-12-24</created><authors><author><keyname>Schmidt</keyname><forenames>Arthur</forenames></author></authors><title>Quantum Algorithms for many-to-one Functions to Solve the Regulator and
  the Principal Ideal Problem</title><categories>quant-ph cs.CC</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose new quantum algorithms to solve the regulator and the principal
ideal problem in a real-quadratic number field. We improve the algorithms
proposed by Hallgren by using two different techniques. The first improvement
is the usage of a period function which is not one-to-one on its period. We
show that even in this case Shor's algorithm computes the period with constant
probability. The second improvement is the usage of reduced forms (a, b, c) of
discriminant D with a&gt;0 instead of reduced ideals of the same discriminant.
These improvements reduce the number of required qubits by at least 2 log D.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4861</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4861</id><created>2009-12-24</created><authors><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author><author><keyname>Boettcher</keyname><forenames>Stefan</forenames></author></authors><title>Conjecture on the maximum cut and bisection width in random regular
  graphs</title><categories>cond-mat.dis-nn cs.DM math.CO</categories><comments>12 pages</comments><journal-ref>J. Stat. Mech. (2010) P02020</journal-ref><doi>10.1088/1742-5468/2010/02/P02020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymptotic properties of random regular graphs are object of extensive study
in mathematics. In this note we argue, based on theory of spin glasses, that in
random regular graphs the maximum cut size asymptotically equals the number of
edges in the graph minus the minimum bisection size. Maximum cut and minimal
bisection are two famous NP-complete problems with no known general relation
between them, hence our conjecture is a surprising property of random regular
graphs. We further support the conjecture with numerical simulations. A
rigorous proof of this relation is obviously a challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4865</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4865</id><created>2009-12-24</created><updated>2010-01-28</updated><authors><author><keyname>Jorg</keyname><forenames>T.</forenames></author><author><keyname>Krzakala</keyname><forenames>F.</forenames></author><author><keyname>Kurchan</keyname><forenames>J.</forenames></author><author><keyname>Maggs</keyname><forenames>A. C.</forenames></author><author><keyname>Pujos</keyname><forenames>J.</forenames></author></authors><title>Energy gaps in quantum first-order mean-field-like transitions: The
  problems that quantum annealing cannot solve</title><categories>quant-ph cond-mat.dis-nn cs.CC</categories><comments>6 pages, 3 figures</comments><journal-ref>EPL, 89 (2010) 40004</journal-ref><doi>10.1209/0295-5075/89/40004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study first-order quantum phase transitions in models where the mean-field
traitment is exact, and the exponentially fast closure of the energy gap with
the system size at the transition. We consider exactly solvable ferromagnetic
models, and show that they reduce to the Grover problem in a particular limit.
We compute the coefficient in the exponential closure of the gap using an
instantonic approach, and discuss the (dire) consequences for quantum
annealing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4872</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4872</id><created>2009-12-24</created><authors><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Interpretations of Directed Information in Portfolio Theory, Data
  Compression, and Hypothesis Testing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the role of Massey's directed information in portfolio theory,
data compression, and statistics with causality constraints. In particular, we
show that directed information is an upper bound on the increment in growth
rates of optimal portfolios in a stock market due to {causal} side information.
This upper bound is tight for gambling in a horse race, which is an extreme
case of stock markets. Directed information also characterizes the value of
{causal} side information in instantaneous compression and quantifies the
benefit of {causal} inference in joint compression of two stochastic processes.
In hypothesis testing, directed information evaluates the best error exponent
for testing whether a random process $Y$ {causally} influences another process
$X$ or not. These results give a natural interpretation of directed information
$I(Y^n \to X^n)$ as the amount of information that a random sequence $Y^n =
(Y_1,Y_2,..., Y_n)$ {causally} provides about another random sequence $X^n =
(X_1,X_2,...,X_n)$. A new measure, {\em directed lautum information}, is also
introduced and interpreted in portfolio theory, data compression, and
hypothesis testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4877</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4877</id><created>2009-12-24</created><authors><author><keyname>Cohen</keyname><forenames>Julien</forenames><affiliation>LMI</affiliation></author></authors><title>Typing rule-based transformations over topological collections</title><categories>cs.PL</categories><proxy>ccsd hal-00442371</proxy><journal-ref>4th International Workshop on Rule-Based Programming, Valencia :
  Spain (2003)</journal-ref><doi>10.1016/S1571-0661(04)80676-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pattern-matching programming is an example of a rule-based programming style
developed in functional languages. This programming style is intensively used
in dialects of ML but is restricted to algebraic data-types. This restriction
limits the field of application. However, as shown by Giavitto and Michel at
RULE'02, case-based function definitions can be extended to more general data
structures called topological collections. We show in this paper that this
extension retains the benefits of the typed discipline of the functional
languages. More precisely, we show that topological collections and the
rule-based definition of functions associated with them fit in a polytypic
extension of mini-ML where type inference is still possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4878</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4878</id><created>2009-12-24</created><authors><author><keyname>Cohen</keyname><forenames>Julien</forenames><affiliation>LMI</affiliation></author></authors><title>Typage fort et typage souple des collections topologiques et des
  transformations</title><categories>cs.PL</categories><proxy>ccsd hal-00442431</proxy><journal-ref>Journ\'ees francophones des langages applicatifs,
  Sainte-Marie-de-R\'e : France (2004)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Topological collections allow to consider uniformly many data structures in
programming languages and are handled by functions defined by pattern matching
called transformations. We present two type systems for languages with
topological collections and transformations. The first one is a strong type
system \`a la Hindley/Milner which can be entirely typed at compile time. The
second one is a mixed static and dynamic type system allowing to handle
heterogeneous collections, that is collections which contain values with
different types. In the two cases, automatic type inference is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4879</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4879</id><created>2009-12-24</created><authors><author><keyname>Bonardi</keyname><forenames>Alain</forenames><affiliation>STMS</affiliation></author><author><keyname>Rousseaux</keyname><forenames>Francis</forenames><affiliation>STMS, CRESTIC</affiliation></author></authors><title>Similarit\'e en intension vs en extension : \`a la crois\'ee de
  l'informatique et du th\'e\^atre</title><categories>cs.AI</categories><proxy>ccsd hal-00442790</proxy><journal-ref>Revue d'Intelligence Artificielle (2005) 281-288</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional staging is based on a formal approach of similarity leaning on
dramaturgical ontologies and instanciation variations. Inspired by interactive
data mining, that suggests different approaches, we give an overview of
computer science and theater researches using computers as partners of the
actor to escape the a priori specification of roles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4880</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4880</id><created>2009-12-24</created><authors><author><keyname>Bonardi</keyname><forenames>Alain</forenames><affiliation>STMS</affiliation></author><author><keyname>Rousseaux</keyname><forenames>Francis</forenames><affiliation>STMS, CRESTIC</affiliation></author></authors><title>How Do Interactive Virtual Operas Shift Relationships between Music,
  Text and Image?</title><categories>cs.MM</categories><proxy>ccsd hal-00442801</proxy><journal-ref>Language, vision and music, John Benjamins Publishing Company
  (Ed.) (2002) 285-294</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the new genre of interactive operas implemented on
personal computers. They differ from traditional ones not only because they are
virtual, but mainly because they offer to composers and listeners new
perspectives of combinations and interactions between music, text and visual
aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4881</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4881</id><created>2009-12-24</created><authors><author><keyname>Rousseaux</keyname><forenames>Francis</forenames><affiliation>STMS, CRESTIC</affiliation></author><author><keyname>Bonardi</keyname><forenames>Alain</forenames><affiliation>STMS</affiliation></author></authors><title>Music-ripping: des pratiques qui provoquent la musicologie</title><categories>cs.MM cs.HC</categories><proxy>ccsd hal-00442805</proxy><journal-ref>Musicae Scientiae Special issue 2004 (2004)
  http://musicweb.hmt-hannover.de/escom/english/MusicScE/MSstart.htm</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Out of the scope of the usual positions of computing in the field of music
and musicology, one notices the emergence of human-computer systems that do
exist by breaking off. Though these singular systems take effect in the usual
fields of expansion of music, they do not make any systematic reference to
known musicological categories. On the contrary, they make possible experiments
that open uses where listening, composition and musical transmission get merged
in a gesture sometimes named as ?music-ripping?. We will show in which way the
music-ripping practices provoke traditional musicology, whose canonical
categories happen to be ineffectual to explain here. To achieve that purpose,
we shall need: - to make explicit a minimal set of categories that is
sufficient to underlie the usual models of computer assisted music;- to do the
same for human-computer systems (anti-musicological?) that disturb us; - to
examine the possibility conditions of reduction of the second set to the first;
- to conclude on the nature of music-ripping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4882</identifier>
 <datestamp>2009-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4882</id><created>2009-12-24</created><authors><author><keyname>Bonardi</keyname><forenames>Alain</forenames><affiliation>STMS</affiliation></author><author><keyname>Rousseaux</keyname><forenames>Francis</forenames><affiliation>STMS, CRESTIC</affiliation></author></authors><title>Interagir avec un contenu op\'eratique : le projet d'op\'era virtuel
  interactif Virtualis</title><categories>cs.HC</categories><proxy>ccsd hal-00442807</proxy><journal-ref>Revue d'Interaction Homme Machine 2, 1 (2001) /</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we present the interactive opera project on CD-ROM
Virtualis. This project includes a scientific dimension as well as artistic. It
gave us the opportunity to design a model of the opera performance using
formalisms from organization sciences. Moreover, our investigation on
interactions between a user and opera contents led us to use models of
relationships between entities based on physical forces, where the user is in a
way absent. We detail some aspects of a reading but also writing environment on
artistic complex contents between text, music and graphics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4883</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4883</id><created>2009-12-24</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames><affiliation>INRIA Futurs, Lifl</affiliation></author></authors><title>On Finding Predictors for Arbitrary Families of Processes</title><categories>cs.LG cs.AI cs.IT math.IT math.ST stat.TH</categories><proxy>ccsd inria-00442881</proxy><journal-ref>Journal of Machine Learning Research 11 (2010) 581-602</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem is sequence prediction in the following setting. A sequence
$x_1,...,x_n,...$ of discrete-valued observations is generated according to
some unknown probabilistic law (measure) $\mu$. After observing each outcome,
it is required to give the conditional probabilities of the next observation.
The measure $\mu$ belongs to an arbitrary but known class $C$ of stochastic
process measures. We are interested in predictors $\rho$ whose conditional
probabilities converge (in some sense) to the &quot;true&quot; $\mu$-conditional
probabilities if any $\mu\in C$ is chosen to generate the sequence. The
contribution of this work is in characterizing the families $C$ for which such
predictors exist, and in providing a specific and simple form in which to look
for a solution. We show that if any predictor works, then there exists a
Bayesian predictor, whose prior is discrete, and which works too. We also find
several sufficient and necessary conditions for the existence of a predictor,
in terms of topological characterizations of the family $C$, as well as in
terms of local behaviour of the measures in $C$, which in some cases lead to
procedures for constructing such predictors. It should be emphasized that the
framework is completely general: the stochastic processes considered are not
required to be i.i.d., stationary, or to belong to any parametric or countable
family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4884</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4884</id><created>2009-12-24</created><updated>2012-09-12</updated><authors><author><keyname>Harsha</keyname><forenames>Prahladh</forenames></author><author><keyname>Klivans</keyname><forenames>Adam</forenames></author><author><keyname>Meka</keyname><forenames>Raghu</forenames></author></authors><title>An Invariance Principle for Polytopes</title><categories>cs.CC cs.CG cs.DM cs.LG math.PR</categories><comments>Added a lowerbound and minor corrections</comments><journal-ref>JACM, 59(6):29, 2012</journal-ref><doi>10.1145/2395116.2395118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let X be randomly chosen from {-1,1}^n, and let Y be randomly chosen from the
standard spherical Gaussian on R^n. For any (possibly unbounded) polytope P
formed by the intersection of k halfspaces, we prove that
  |Pr [X belongs to P] - Pr [Y belongs to P]| &lt; log^{8/5}k * Delta, where Delta
is a parameter that is small for polytopes formed by the intersection of
&quot;regular&quot; halfspaces (i.e., halfspaces with low influence). The novelty of our
invariance principle is the polylogarithmic dependence on k. Previously, only
bounds that were at least linear in k were known. We give two important
applications of our main result: (1) A polylogarithmic in k bound on the
Boolean noise sensitivity of intersections of k &quot;regular&quot; halfspaces (previous
work gave bounds linear in k). (2) A pseudorandom generator (PRG) with seed
length O((log n)*poly(log k,1/delta)) that delta-fools all polytopes with k
faces with respect to the Gaussian distribution. We also obtain PRGs with
similar parameters that fool polytopes formed by intersection of regular
halfspaces over the hypercube. Using our PRG constructions, we obtain the first
deterministic quasi-polynomial time algorithms for approximately counting the
number of solutions to a broad class of integer programs, including dense
covering problems and contingency tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4935</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4935</id><created>2009-12-24</created><updated>2010-06-04</updated><authors><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>Inapproximability of maximal strip recovery</title><categories>cs.CC</categories><comments>A preliminary version of this paper appeared in two parts in the
  Proceedings of the 20th International Symposium on Algorithms and Computation
  (ISAAC 2009) and the Proceedings of the 4th International Frontiers of
  Algorithmics Workshop (FAW 2010)</comments><doi>10.1007/978-3-642-14553-7_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In comparative genomic, the first step of sequence analysis is usually to
decompose two or more genomes into syntenic blocks that are segments of
homologous chromosomes. For the reliable recovery of syntenic blocks, noise and
ambiguities in the genomic maps need to be removed first. Maximal Strip
Recovery (MSR) is an optimization problem proposed by Zheng, Zhu, and Sankoff
for reliably recovering syntenic blocks from genomic maps in the midst of noise
and ambiguities. Given $d$ genomic maps as sequences of gene markers, the
objective of \msr{d} is to find $d$ subsequences, one subsequence of each
genomic map, such that the total length of syntenic blocks in these
subsequences is maximized. For any constant $d \ge 2$, a polynomial-time
2d-approximation for \msr{d} was previously known. In this paper, we show that
for any $d \ge 2$, \msr{d} is APX-hard, even for the most basic version of the
problem in which all gene markers are distinct and appear in positive
orientation in each genomic map. Moreover, we provide the first explicit lower
bounds on approximating \msr{d} for all $d \ge 2$. In particular, we show that
\msr{d} is NP-hard to approximate within $\Omega(d/\log d)$. From the other
direction, we show that the previous 2d-approximation for \msr{d} can be
optimized into a polynomial-time algorithm even if $d$ is not a constant but is
part of the input. We then extend our inapproximability results to several
related problems including \cmsr{d}, \gapmsr{\delta}{d}, and
\gapcmsr{\delta}{d}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4936</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4936</id><created>2009-12-24</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author></authors><title>Genus Computing for 3D digital objects: algorithm and implementation</title><categories>cs.CV cs.CG</categories><comments>12 pages 7 figures. In Proceedings of the Workshop on Computational
  Topology in image context 2009, Aug. 26-28, Austria, Edited by W. Kropatsch,
  H. M. Abril and A. Ion, 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper deals with computing topological invariants such as connected
components, boundary surface genus, and homology groups. For each input data
set, we have designed or implemented algorithms to calculate connected
components, boundary surfaces and their genus, and homology groups. Due to the
fact that genus calculation dominates the entire task for 3D object in 3D
space, in this paper, we mainly discuss the calculation of the genus. The new
algorithms designed in this paper will perform:
  (1) pathological cases detection and deletion, (2) raster space to point
space (dual space) transformation, (3) the linear time algorithm for boundary
point classification, and (4) genus calculation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4941</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4941</id><created>2009-12-25</created><authors><author><keyname>Achilleos</keyname><forenames>Antonis</forenames></author><author><keyname>Lampis</keyname><forenames>Michael</forenames></author><author><keyname>Mitsou</keyname><forenames>Valia</forenames></author></authors><title>Parameterized Modal Satisfiability</title><categories>cs.LO cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the parameterized computational complexity of the
satisfiability problem for modal logic and attempt to pinpoint relevant
structural parameters which cause the problem's combinatorial explosion, beyond
the number of propositional variables v. To this end we study the modality
depth, a natural measure which has appeared in the literature, and show that,
even though modal satisfiability parameterized by v and the modality depth is
FPT, the running time's dependence on the parameters is a tower of exponentials
(unless P=NP). To overcome this limitation we propose several possible
alternative parameters, namely diamond dimension, box dimension and modal
width. We show fixed-parameter tractability results using these measures where
the exponential dependence on the parameters is much milder than in the case of
modality depth thus leading to FPT algorithms for modal satisfiability with
much more reasonable running times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4947</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4947</id><created>2009-12-30</created><updated>2010-02-25</updated><authors><author><keyname>Ketema</keyname><forenames>Jeroen</forenames></author><author><keyname>Simonsen</keyname><forenames>Jakob Grue</forenames></author></authors><title>Infinitary Combinatory Reduction Systems: Normalising Reduction
  Strategies</title><categories>cs.LO</categories><acm-class>D.3.1; F.3.2; F.4.1; F.4.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (February
  26, 2010) lmcs:841</journal-ref><doi>10.2168/LMCS-6(1:7)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study normalising reduction strategies for infinitary Combinatory
Reduction Systems (iCRSs). We prove that all fair, outermost-fair, and
needed-fair strategies are normalising for orthogonal, fully-extended iCRSs.
These facts properly generalise a number of results on normalising strategies
in first-order infinitary rewriting and provide the first examples of
normalising strategies for infinitary lambda calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4988</identifier>
 <datestamp>2011-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4988</id><created>2009-12-25</created><updated>2011-06-17</updated><authors><author><keyname>Boufounos</keyname><forenames>Petros T.</forenames></author><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Sparse Recovery from Combined Fusion Frame Measurements</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Trans. Info. Theory, Vol. 57, No. 6, pp. 3864-3876, June 2011</journal-ref><doi>10.1109/TIT.2011.2143890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representations have emerged as a powerful tool in signal and
information processing, culminated by the success of new acquisition and
processing techniques such as Compressed Sensing (CS). Fusion frames are very
rich new signal representation methods that use collections of subspaces
instead of vectors to represent signals. This work combines these exciting
fields to introduce a new sparsity model for fusion frames. Signals that are
sparse under the new model can be compressively sampled and uniquely
reconstructed in ways similar to sparse signals using standard CS. The
combination provides a promising new set of mathematical tools and signal
models useful in a variety of applications. With the new model, a sparse signal
has energy in very few of the subspaces of the fusion frame, although it does
not need to be sparse within each of the subspaces it occupies. This sparsity
model is captured using a mixed l1/l2 norm for fusion frames.
  A signal sparse in a fusion frame can be sampled using very few random
projections and exactly reconstructed using a convex optimization that
minimizes this mixed l1/l2 norm. The provided sampling conditions generalize
coherence and RIP conditions used in standard CS theory. It is demonstrated
that they are sufficient to guarantee sparse recovery of any signal sparse in
our model. Moreover, a probabilistic analysis is provided using a stochastic
model on the sparse signal that shows that under very mild conditions the
probability of recovery failure decays exponentially with increasing dimension
of the subspaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4991</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4991</id><created>2009-12-25</created><updated>2010-08-10</updated><authors><author><keyname>Ghaffari</keyname><forenames>Hamed. O.</forenames></author><author><keyname>Fall</keyname><forenames>Mamdou</forenames></author><author><keyname>Evgin</keyname><forenames>Erman.</forenames></author></authors><title>Complexity Analysis of Unsaturated Flow in Heterogeneous Media Using a
  Complex Network Approach</title><categories>cs.CE physics.geo-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we investigate the complexity of two-phase flow (air/water) in
a heterogeneous soil sample by using complex network theory, where the supposed
porous media is non-deformable media, under the time-dependent gas pressure.
Based on the different similarity measurements (i.e., correlation, Euclidean
metrics) over the emerged patterns from the evolution of saturation of
non-wetting phase of a multi-heterogeneous soil sample, the emerged complex
networks are recognized. Understanding of the properties of complex networks
(such degree distribution, mean path length, clustering coefficient) can be
supposed as a way to analysis of variation of saturation profiles structures
(as the solution of finite element method on the coupled PDEs) where complexity
is coming from the changeable connection and links between assumed nodes. Also,
the path of evolution of the supposed system will be illustrated on the state
space of networks either in correlation and Euclidean measurements. The results
of analysis showed in a closed system the designed complex networks approach to
small world network where the mean path length and clustering coefficient are
low and high, respectively. As another result, the evolution of macro -states
of system (such mean velocity of air or pressure) can be scaled with
characteristics of structure complexity of saturation. In other part, we tried
to find a phase transition criterion based on the variation of non-wetting
phase velocity profiles over a network which had been constructed over
correlation distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4993</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4993</id><created>2009-12-25</created><updated>2010-07-02</updated><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Cognitive MAC Protocols Using Memory for Distributed Spectrum Sharing
  Under Limited Spectrum Sensing</title><categories>cs.NI</categories><comments>24 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main challenges of cognitive radio include spectrum sensing at the
physical (PHY) layer to detect the activity of primary users and spectrum
sharing at the medium access control (MAC) layer to coordinate access among
coexisting secondary users. In this paper, we consider a cognitive radio
network in which a primary user shares a channel with secondary users that
cannot distinguish the signals of the primary user from those of a secondary
user. We propose a class of distributed cognitive MAC protocols to achieve
efficient spectrum sharing among the secondary users while protecting the
primary user from potential interference by the secondary users. By using a MAC
protocol with one-slot memory, we can obtain high channel utilization by the
secondary users while limiting interference to the primary user at a low level.
The results of this paper suggest the possibility of utilizing MAC design in
cognitive radio networks to overcome limitations in spectrum sensing at the PHY
layer as well as to achieve spectrum sharing at the MAC layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.4995</identifier>
 <datestamp>2010-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.4995</id><created>2009-12-28</created><updated>2010-01-08</updated><authors><author><keyname>Tajima</keyname><forenames>Masato</forenames></author><author><keyname>Okino</keyname><forenames>Koji</forenames></author><author><keyname>Miyagoshi</keyname><forenames>Takashi</forenames></author></authors><title>1-State Error-Trellis Decoding of LDPC Convolutional Codes Based on
  Circulant Matrices</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to the 2010 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the decoding of convolutional codes using an error trellis
constructed based on a submatrix of a given check matrix. In the proposed
method, the syndrome-subsequence computed using the remaining submatrix is
utilized as auxiliary information for decoding. Then the ML error path is
correctly decoded using the degenerate error trellis. We also show that the
decoding complexity of the proposed method is basically identical with that of
the conventional one based on the original error trellis. Next, we apply the
method to check matrices with monomial entries proposed by Tanner et al. By
choosing any row of the check matrix as the submatrix for error-trellis
construction, a 1-state error trellis is obtained. Noting the fact that a
likelihood-concentration on the all-zero state and the states with many 0's
occurs in the error trellis, we present a simplified decoding method based on a
1-state error trellis, from which decoding-complexity reduction is realized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5009</identifier>
 <datestamp>2014-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5009</id><created>2009-12-27</created><updated>2014-10-18</updated><authors><author><keyname>Guzeltepe</keyname><forenames>Murat</forenames></author><author><keyname>Ozen</keyname><forenames>Mehmet</forenames></author></authors><title>The MacWilliams Theorem for Four-Dimensional Modulo Metrics</title><categories>cs.IT cs.DM math.IT</categories><comments>A similar paper had been already published by Jay Wood</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, the MacWilliams theorem is stated for codes over finite field
with four-dimensional modulo metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5014</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5014</id><created>2009-12-26</created><authors><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author></authors><title>A User's Guide to Zot</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zot is an agile and easily extendible bounded model checker, which can be
downloaded at http://home.dei.polimi.it/pradella/. The tool supports different
logic languages through a multi-layered approach: its core uses PLTL, and on
top of it a decidable predicative fragment of TRIO is defined. An interesting
feature of Zot is its ability to support different encodings of temporal logic
as SAT problems by means of plug-ins. This approach encourages experimentation,
as plug-ins are expected to be quite simple, compact (usually around 500 lines
of code), easily modifiable, and extendible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5029</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5029</id><created>2009-12-26</created><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Complexity of stochastic branch and bound methods for belief tree search
  in Bayesian reinforcement learning</title><categories>cs.LG cs.AI</categories><comments>13 pages, 1 figure, ICAART 2010</comments><report-no>TR-UVA-09-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a lot of recent work on Bayesian methods for reinforcement
learning exhibiting near-optimal online performance. The main obstacle facing
such methods is that in most problems of interest, the optimal solution
involves planning in an infinitely large tree. However, it is possible to
obtain stochastic lower and upper bounds on the value of each tree node. This
enables us to use stochastic branch and bound algorithms to search the tree
efficiently. This paper proposes two such algorithms and examines their
complexity in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5043</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5043</id><created>2009-12-26</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>Bit Error Rate is Convex at High SNR</title><categories>cs.IT math.IT</categories><comments>to be presented at IZS-10, March 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a wide-spread use of convex optimization techniques, convexity
properties of bit error rate of the maximum likelihood detector operating in
the AWGN channel are studied for arbitrary constellations and bit mappings,
which may also include coding under maximum-likelihood decoding. Under this
generic setting, the pairwise probability of error and bit error rate are shown
to be convex functions of the SNR in the high SNR regime with
explicitly-determined boundary. The bit error rate is also shown to be a convex
function of the noise power in the low noise/high SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5055</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5055</id><created>2009-12-27</created><updated>2010-01-26</updated><authors><author><keyname>Li</keyname><forenames>Yao</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Rateless Codes for Single-Server Streaming to Diverse Users</title><categories>cs.IT math.IT</categories><comments>Invited paper, the 47th Annual Allerton Conference on Communication,
  Control, and Computing, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the performance of rateless codes for single-server streaming
to diverse users, assuming that diversity in users is present not only because
they have different channel conditions, but also because they demand different
amounts of information and have different decoding capabilities. The LT
encoding scheme is employed. While some users accept output symbols of all
degrees and decode using belief propagation, others only collect degree- 1
output symbols and run no decoding algorithm. We propose several performance
measures, and optimize the performance of the rateless code used at the server
through the design of the code degree distribution. Optimization problems are
formulated for the asymptotic regime and solved as linear programming problems.
Optimized performance shows great improvement in total bandwidth consumption
over using the conventional ideal soliton distribution, or simply sending
separately encoded streams to different types of user nodes. Simulation
experiments confirm the usability of the optimization results obtained for the
asymptotic regime as a guideline for finite-length code design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5073</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5073</id><created>2009-12-27</created><updated>2010-06-11</updated><authors><author><keyname>Han</keyname><forenames>Ji</forenames></author></authors><title>A Rational Decision Maker with Ordinal Utility under Uncertainty:
  Optimism and Pessimism</title><categories>cs.AI cs.GT</categories><comments>This paper has been withdrawn by the author</comments><acm-class>I.2.0; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In game theory and artificial intelligence, decision making models often
involve maximizing expected utility, which does not respect ordinal invariance.
In this paper, the author discusses the possibility of preserving ordinal
invariance and still making a rational decision under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5079</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5079</id><created>2009-12-27</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>A Lower Bound on the Complexity of Approximating the Entropy of a Markov
  Source</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that, for any (k \geq 1), (\epsilon &gt; 0) and sufficiently large
$\sigma$, we are given a black box that allows us to sample characters from a
$k$th-order Markov source over the alphabet (\{0, ..., \sigma - 1\}). Even if
we know the source has entropy either 0 or at least (\log (\sigma - k)), there
is still no algorithm that, with probability bounded away from (1 / 2), guesses
the entropy correctly after sampling at most ((\sigma - k)^{k / 2 - \epsilon})
characters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5101</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5101</id><created>2009-12-27</created><authors><author><keyname>Shabtai</keyname><forenames>A.</forenames><affiliation>Department of Information Systems Engineering Ben-Gurion University Israel</affiliation><affiliation>Deutsche Telekom Laboratories at Ben-Gurion University Israel</affiliation></author><author><keyname>Fledel</keyname><forenames>Y.</forenames><affiliation>Department of Information Systems Engineering Ben-Gurion University Israel</affiliation><affiliation>Deutsche Telekom Laboratories at Ben-Gurion University Israel</affiliation></author><author><keyname>Kanonov</keyname><forenames>U.</forenames><affiliation>Department of Information Systems Engineering Ben-Gurion University Israel</affiliation><affiliation>Deutsche Telekom Laboratories at Ben-Gurion University Israel</affiliation></author><author><keyname>Elovici</keyname><forenames>Y.</forenames><affiliation>Department of Information Systems Engineering Ben-Gurion University Israel</affiliation><affiliation>Deutsche Telekom Laboratories at Ben-Gurion University Israel</affiliation></author><author><keyname>Dolev</keyname><forenames>S.</forenames><affiliation>Department of Computer Science Ben-Gurion University Israel</affiliation><affiliation>Deutsche Telekom Laboratories at Ben-Gurion University Israel</affiliation></author></authors><title>Google Android: A State-of-the-Art Review of Security Mechanisms</title><categories>cs.CR</categories><comments>42 pages, 1 figure, 5 tables</comments><report-no>DTBGU-TR200912-01</report-no><acm-class>C.2.0; C.5.3; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Google's Android is a comprehensive software framework for mobile
communication devices (i.e., smartphones, PDAs). The Android framework includes
an operating system, middleware and a set of key applications. The
incorporation of integrated access services to the Internet on such mobile
devices, however, increases their exposure to damages inflicted by various
types of malware. This paper provides a comprehensive security assessment of
the Android framework and the security mechanisms incorporated into it. A
methodological qualitative risk analysis that we conducted identifies the
high-risk threats to the framework and any potential danger to information or
to the system resulting from vulnerabilities that have been uncovered and
exploited. Our review of current academic and commercial solutions in the area
of smartphone security yields a list of applied and recommended defense
mechanisms for hardening mobile devices in general and the Android in
particular. Lastly, we present five major (high-risk) threats to the Android
framework and propose security solutions to mitigate them. We conclude by
proposing a set of security mechanisms that should be explored and introduced
into Android-powered devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5166</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5166</id><created>2009-12-28</created><authors><author><keyname>Korsnes</keyname><forenames>Reinert</forenames></author><author><keyname>Ovsthus</keyname><forenames>Knut</forenames></author></authors><title>Inspiration from genetics to promote recognition and protection within
  ad hoc sensor networks</title><categories>cs.CR q-bio.CB q-bio.MN</categories><comments>14 pages, 5 figures, research article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work illustrates potentials for recognition within {\em ad hoc} sensor
networks if their nodes possess individual inter-related biologically inspired
genetic codes. The work takes ideas from natural immune systems protecting
organisms from infection. Nodes in the present proposal have individual gene
sets fitting into a self organised phylogenetic tree. Members of this
population are genetically ''relatives''. Outsiders cannot easily copy or
introduce a new node in the network without going through a process of
conception between two nodes in the population. Related nodes can locally
decide to check each other for their genetic relation without directly
revealing their gene sets. A copy/clone of a gene sequence or a random gene set
will appear as alien. Nodes go through a cycle of introduction (conception or
''birth'') with parents in the network and later exit from it (''death'').
Hence the phylogenetic tree is dynamic or possesses a genetic drift. Typical
lifetimes of gene sets and number of offspring from different parents affect
this genetic drift and the level of correlation between gene sets. The
frequency of mutations similarly affects the gene pool. Correlation between
genes of the nodes implies a common secret for cryptographic material for
communication and consistency check facilitating intrusion detection and
tracing of events. A node can by itself (non-specifically) recognise an
adversary if it does not respond properly according to its genes. Nodes can
also collaborate to recognise adversaries by communicating response from
intruders to check for consistency with the whole gene pool (phylogenetic
tree).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5176</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5176</id><created>2009-12-29</created><updated>2010-06-07</updated><authors><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>On the deletion channel with small deletion probability</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure v3: minor corrections</comments><journal-ref>IEEE Intl. Symp. Information Theory Proc. (2010) 1002-1006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deletion channel is the simplest point-to-point communication channel
that models lack of synchronization. Despite significant effort, little is
known about its capacity, and even less about optimal coding schemes. In this
paper we intiate a new systematic approach to this problem, by demonstrating
that capacity can be computed in a series expansion for small deletion
probability. We compute two leading terms of this expansion, and show that
capacity is achieved, up to this order, by i.i.d. uniform random distribution
of the input. We think that this strategy can be useful in a number of capacity
calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5182</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5182</id><created>2009-12-28</created><authors><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Sadri</keyname><forenames>Bardia</forenames></author></authors><title>Lipschitz Unimodal and Isotonic Regression on Paths and Trees</title><categories>cs.DS cs.CG</categories><comments>18 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe algorithms for finding the regression of t, a sequence of values,
to the closest sequence s by mean squared error, so that s is always increasing
(isotonicity) and so the values of two consecutive points do not increase by
too much (Lipschitz). The isotonicity constraint can be replaced with a
unimodular constraint, where there is exactly one local maximum in s. These
algorithm are generalized from sequences of values to trees of values. For each
scenario we describe near-linear time algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5187</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5187</id><created>2009-12-28</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author></authors><title>Statistical Complexity in Traveling Densities</title><categories>nlin.PS cs.IT math.IT quant-ph</categories><comments>4 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we analyze the behavior of statistical complexity in several
systems where two identical densities that travel in opposite direction cross
each other. The crossing between two Gaussian, rectangular and triangular
densities is studied in detail. For these three cases, the shape of the total
density presenting an extreme value in complexity is found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5193</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5193</id><created>2009-12-28</created><updated>2013-08-29</updated><authors><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author><author><keyname>Heller</keyname><forenames>Katherine</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author><author><keyname>Airoldi</keyname><forenames>Edoardo M.</forenames></author></authors><title>Ranking relations using analogies in biological and information networks</title><categories>stat.ME cs.LG physics.soc-ph q-bio.QM stat.AP</categories><comments>Published in at http://dx.doi.org/10.1214/09-AOAS321 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS321</report-no><journal-ref>Annals of Applied Statistics 2010, Vol. 4, No. 2, 615-644</journal-ref><doi>10.1214/09-AOAS321</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analogical reasoning depends fundamentally on the ability to learn and
generalize about relations between objects. We develop an approach to
relational learning which, given a set of pairs of objects
$\mathbf{S}=\{A^{(1)}:B^{(1)},A^{(2)}:B^{(2)},\ldots,A^{(N)}:B ^{(N)}\}$,
measures how well other pairs A:B fit in with the set $\mathbf{S}$. Our work
addresses the following question: is the relation between objects A and B
analogous to those relations found in $\mathbf{S}$? Such questions are
particularly relevant in information retrieval, where an investigator might
want to search for analogous pairs of objects that match the query set of
interest. There are many ways in which objects can be related, making the task
of measuring analogies very challenging. Our approach combines a similarity
measure on function spaces with Bayesian analysis to produce a ranking. It
requires data containing features of the objects of interest and a link matrix
specifying which relationships exist; no further attributes of such
relationships are necessary. We illustrate the potential of our method on text
analysis and information networks. An application on discovering functional
interactions between pairs of proteins is discussed in detail, where we show
that our approach can work in practice even if a small set of protein pairs is
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5218</identifier>
 <datestamp>2010-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5218</id><created>2009-12-28</created><authors><author><keyname>Arjona-Villica&#xf1;a</keyname><forenames>Pedro David</forenames></author><author><keyname>Constantinou</keyname><forenames>Costas C.</forenames></author><author><keyname>Stepanenko</keyname><forenames>Alexander S.</forenames></author></authors><title>The Internet's unexploited path diversity</title><categories>cs.NI</categories><comments>Submitted to IEEE Communications Letters</comments><journal-ref>IEEE Communications Letters, 14, pp.474-476, 2010</journal-ref><doi>10.1109/LCOMM.2010.05.092483</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The connectivity of the Internet at the Autonomous System level is influenced
by the network operator policies implemented. These in turn impose a direction
to the announcement of address advertisements and, consequently, to the paths
that can be used to reach back such destinations. We propose to use directed
graphs to properly represent how destinations propagate through the Internet
and the number of arc-disjoint paths to quantify this network's path diversity.
Moreover, in order to understand the effects that policies have on the
connectivity of the Internet, numerical analyses of the resulting directed
graphs were conducted. Results demonstrate that, even after policies have been
applied, there is still path diversity which the Border Gateway Protocol cannot
currently exploit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5235</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5235</id><created>2009-12-30</created><authors><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin</forenames></author><author><keyname>Di Milia</keyname><forenames>Giovanni</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author></authors><title>Using Multipartite Graphs for Recommendation and Discovery</title><categories>astro-ph.IM cs.DL cs.IR physics.soc-ph</categories><comments>To appear in ADASS XIX, ASP Conf Proc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Smithsonian/NASA Astrophysics Data System exists at the nexus of a dense
system of interacting and interlinked information networks. The syntactic and
the semantic content of this multipartite graph structure can be combined to
provide very specific research recommendations to the scientist/user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5237</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5237</id><created>2009-12-30</created><authors><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author></authors><title>&quot;On the Road&quot; - Reflections on the Security of Vehicular Communication
  Systems</title><categories>cs.CR</categories><journal-ref>EEE ICVES, Columbus, OH, USA, September 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular communication (VC) systems have recently drawn the attention of
industry, authorities, and academia. A consensus on the need to secure VC
systems and protect the privacy of their users led to concerted efforts to
design security architectures. Interestingly, the results different project
contributed thus far bear extensive similarities in terms of objectives and
mechanisms. As a result, this appears to be an auspicious time for setting the
corner-stone of trustworthy VC systems. Nonetheless, there is a considerable
distance to cover till their deployment. This paper ponders on the road ahead.
First, it presents a distillation of the state of the art, covering the
perceived threat model, security requirements, and basic secure VC system
components. Then, it dissects predominant assumptions and design choices and
considers alternatives. Under the prism of what is necessary to render secure
VC systems practical, and given possible non-technical influences, the paper
attempts to chart the landscape towards the deployment of secure VC systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5241</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5241</id><created>2009-12-30</created><authors><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Balazinska</keyname><forenames>Magdalena</forenames></author><author><keyname>Khoussainova</keyname><forenames>Nodira</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Believe It or Not: Adding Belief Annotations to Databases</title><categories>cs.DB cs.AI</categories><comments>17 pages, 10 figures</comments><report-no>University of Washington CSE Technical Report 08-12-01</report-no><acm-class>H.2.1</acm-class><journal-ref>Full version of: VLDB 2009 conference version; PVLDB 2(1):1-12
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a database model that allows users to annotate data with belief
statements. Our motivation comes from scientific database applications where a
community of users is working together to assemble, revise, and curate a shared
data repository. As the community accumulates knowledge and the database
content evolves over time, it may contain conflicting information and members
can disagree on the information it should store. For example, Alice may believe
that a tuple should be in the database, whereas Bob disagrees. He may also
insert the reason why he thinks Alice believes the tuple should be in the
database, and explain what he thinks the correct tuple should be instead.
  We propose a formal model for Belief Databases that interprets users'
annotations as belief statements. These annotations can refer both to the base
data and to other annotations. We give a formal semantics based on a fragment
of multi-agent epistemic logic and define a query language over belief
databases. We then prove a key technical result, stating that every belief
database can be encoded as a canonical Kripke structure. We use this structure
to describe a relational representation of belief databases, and give an
algorithm for translating queries over the belief database into standard
relational queries. Finally, we report early experimental results with our
prototype implementation on synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5269</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5269</id><created>2009-12-29</created><authors><author><keyname>Dua</keyname><forenames>Aditya</forenames></author><author><keyname>Tsamis</keyname><forenames>Dimitrios</forenames></author><author><keyname>Bambos</keyname><forenames>Nicholas</forenames></author><author><keyname>Singh</keyname><forenames>Jatinder Pal</forenames></author></authors><title>Dynamic Task Fetching Over Time Varying Wireless Channels for Mobile
  Computing Applications</title><categories>cs.NI</categories><comments>28 pages, 13 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The processing, computation and memory requirements posed by emerging mobile
broadband services require adaptive memory management and prefetching
techniques at the mobile terminals for satisfactory application performance and
sustained device battery lifetime. In this work we investigate a scenario where
tasks with varied computational requirements are fetched by a mobile device
from a central server over an error prone wireless link. We examine the buffer
dynamics at the mobile terminal and the central server under varying wireless
channel connectivity and device memory congestion states as variable sizes
tasks are executed on the terminal. Our goal is to minimize the latency
experienced by these tasks while judiciously utilizing the device buffering
capability. We use a dynamic programming framework to model the optimal
prefetching policy. We further propose a) a prefetching algorithm Fetch-or- Not
(FON), which uses quasi-static assumption on system state to make prefetching
decisions, and b) a prefetching policy RFON, which uses randomized
approximation to the optimal solution thus obviating the need for dynamic
online optimization and substantially reducing the computational complexity.
Through performance evaluation under slow and fast fading scenarios we show
that proposed algorithms come close to performance of the optimal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5276</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5276</id><created>2009-12-30</created><authors><author><keyname>Brody</keyname><forenames>Joshua</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Amit</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author><author><keyname>Vidick</keyname><forenames>Thomas</forenames></author><author><keyname>de Wolf</keyname><forenames>Ronald</forenames></author></authors><title>Better Gap-Hamming Lower Bounds via Better Round Elimination</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gap Hamming Distance is a well-studied problem in communication complexity,
in which Alice and Bob have to decide whether the Hamming distance between
their respective n-bit inputs is less than n/2-sqrt(n) or greater than
n/2+sqrt(n). We show that every k-round bounded-error communication protocol
for this problem sends a message of at least Omega(n/(k^2\log k)) bits. This
lower bound has an exponentially better dependence on the number of rounds than
the previous best bound, due to Brody and Chakrabarti. Our communication lower
bound implies strong space lower bounds on algorithms for a number of data
stream computations, such as approximating the number of distinct elements in a
stream.
  Subsequent to this result, the bound has been improved by some of us to the
optimal Omega(n), independent of k, by using different techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5287</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5287</id><created>2009-12-29</created><authors><author><keyname>Vagharshakyan</keyname><forenames>Ashot</forenames></author></authors><title>Uniqueness theorem for analytic functions and its application in
  denoising problem</title><categories>cs.IT math.IT</categories><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In various applications the problem of separation of the original signal and
the noise arises. For example, in the identification problem for discrete
linear and causal systems, the original signal consists of the values of
transfer function at some points in the unit disk. In this paper we discuss the
problem of choosing the points in the unite disk, for which it is possible to
remove the additive noise with probability one. Since the transfer function is
analytic in the unite disk, so this problem is related to the uniqueness
theorems for analytic functions. Here we give a new uniqueness result for
bounded analytic functions and show its applications in the denoising problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5292</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5292</id><created>2009-12-29</created><updated>2010-01-03</updated><authors><author><keyname>P</keyname><forenames>Arun Kumar S</forenames></author></authors><title>High-Speed Signature Matching in Network Interface Device using Bloom
  Filters</title><categories>cs.NI</categories><comments>Pre-print version. International Joint Journal Conference in
  Engineering, IJJCE 2009</comments><acm-class>C.2.0; C.2.5; D.4.6; K.4.4</acm-class><journal-ref>International Journal of Recent Trends in Engineering, Volume 1,
  Number 1, May 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network intrusion detection systems play a critical role in protecting the
information infrastructure of an organization. Due to the sophistication and
complexity of techniques used for the analysis they are commonly based on
general-purpose workstations. Although cost-efficient, these general-purpose
systems are found to be inadequate as they are unable to perform efficiently at
high packet rates. The resulting packet loss degrades the system's overall
effectiveness, as the analyzing capability of the system is reduced. It has
been found that the performance of these sensors can be improved significantly
by filtering out unwanted packets. This paper presents the design of a
Programmable Ethernet Interface Card that is used to offload signature matching
from software and thereby improve the detection ratio and performance of the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5324</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5324</id><created>2009-12-29</created><updated>2011-02-03</updated><authors><author><keyname>Alfredo</keyname><forenames>Ortega A.</forenames><affiliation>ITBA, CORE</affiliation></author><author><keyname>Bettachini</keyname><forenames>Victor A.</forenames><affiliation>ITBA</affiliation></author><author><keyname>Alvarez-Hamelin</keyname><forenames>Jos&#xe9; Ignacio</forenames><affiliation>ITBA, CONICET</affiliation></author><author><keyname>Grosz</keyname><forenames>Diego F.</forenames><affiliation>CONICET, LabOp</affiliation></author></authors><title>Point-to-point and Point-to-multipoint CDMA Access Network with Enhanced
  Security</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a network implementation with enhanced security at the physical
layer by means of time-hopping CDMA, supporting cryptographically secure
point-to-point and point-to-multipoint communication. In particular, we analyze
an active star topology optical network implementation capable of supporting
128 simultaneous users up to 20 km apart. The feasibility of the proposed
scheme is demonstrated through numerical simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5327</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5327</id><created>2009-12-29</created><updated>2010-03-18</updated><authors><author><keyname>Goldstein</keyname><forenames>Doron</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>The Dense k Subgraph problem</title><categories>cs.DM</categories><comments>Submitted as MSc thesis, The Open University of Israel</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G = (V,E) and a parameter k, we consider the problem of finding
a subset U in V of size k that maximizes the number of induced edges (DkS). We
improve upon the previously best known approximation ratio for DkS, a ratio
that has not seen any progress during the last decade. Specifically, we improve
the approximation ratio from n^{0.32258} to n^{0.3159}.
  The improved ratio is obtained by studying a variant to the DkS problem in
which one considers the problem of finding a subset U in V of size at most k
that maximizes the number of induced edges.
  Finally, we study the DkS variant in which one considers the problem of
finding a subset U in V of size at least k that maximizes the number of induced
edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5334</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5334</id><created>2009-12-29</created><authors><author><keyname>Shaikh</keyname><forenames>Riaz Ahmed</forenames></author><author><keyname>Jameel</keyname><forenames>Hassan</forenames></author><author><keyname>Auriol</keyname><forenames>Brian J. d</forenames></author><author><keyname>Lee</keyname><forenames>Heejo</forenames></author><author><keyname>Lee</keyname><forenames>Sungyoung</forenames></author><author><keyname>Song</keyname><forenames>Young-Jae</forenames></author></authors><title>Intrusion-aware Alert Validation Algorithm for Cooperative Distributed
  Intrusion Detection Schemes of Wireless Sensor Networks</title><categories>cs.CR</categories><comments>19 pages, 7 figures</comments><journal-ref>Sensors 2009, vol. 9(8), pp. 5989-6007</journal-ref><doi>10.3390/s90805989</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing anomaly and intrusion detection schemes of wireless sensor networks
have mainly focused on the detection of intrusions. Once the intrusion is
detected, an alerts or claims will be generated. However, any unidentified
malicious nodes in the network could send faulty anomaly and intrusion claims
about the legitimate nodes to the other nodes. Verifying the validity of such
claims is a critical and challenging issue that is not considered in the
existing cooperative-based distributed anomaly and intrusion detection schemes
of wireless sensor networks. In this paper, we propose a validation algorithm
that addresses this problem. This algorithm utilizes the concept of
intrusion-aware reliability that helps to provide adequate reliability at a
modest communication cost. In this paper, we also provide a security resiliency
analysis of the proposed intrusion-aware alert validation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5340</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5340</id><created>2009-12-29</created><authors><author><keyname>Meliou</keyname><forenames>Alexandra</forenames></author><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Moore</keyname><forenames>Katherine F.</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Why so? or Why no? Functional Causality for Explaining Query Answers</title><categories>cs.DB cs.AI</categories><comments>18 pages, 15 figures</comments><report-no>University of Washington CSE Technical Report 09-12-01</report-no><acm-class>H.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose causality as a unified framework to explain query
answers and non-answers, thus generalizing and extending several previously
proposed approaches of provenance and missing query result explanations.
  We develop our framework starting from the well-studied definition of actual
causes by Halpern and Pearl. After identifying some undesirable characteristics
of the original definition, we propose functional causes as a refined
definition of causality with several desirable properties. These properties
allow us to apply our notion of causality in a database context and apply it
uniformly to define the causes of query results and their individual
contributions in several ways: (i) we can model both provenance as well as
non-answers, (ii) we can define explanations as either data in the input
relations or relational operations in a query plan, and (iii) we can give
graded degrees of responsibility to individual causes, thus allowing us to rank
causes. In particular, our approach allows us to explain contributions to
relational aggregate functions and to rank causes according to their respective
responsibilities. We give complexity results and describe polynomial algorithms
for evaluating causality in tractable cases. Throughout the paper, we
illustrate the applicability of our framework with several examples.
  Overall, we develop in this paper the theoretical foundations of causality
theory in a database context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5342</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5342</id><created>2009-12-29</created><authors><author><keyname>Pedicini</keyname><forenames>Marco</forenames></author><author><keyname>Piazza</keyname><forenames>Mario</forenames></author></authors><title>Elementary Complexity and von Neumann Algebras</title><categories>cs.CC cs.LO</categories><comments>22 pages, 2 figures, journal submission</comments><acm-class>F.1.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show how a construction of an implicit complexity model can
be implemented using concepts coming from the core of von Neumann algebras.
Namely, our aim is to gain an understanding of classical computation in terms
of the hyperfinite $\mathrm{II}_1$ factor, starting from the class of Kalmar
recursive functions. More methodologically, we address the problem of finding
the right perspective from which to view the new relation between computation
and combinatorial aspects in operator algebras. The rich structure of discrete
invariants may provide a mathematical setting able to shed light on some basic
combinatorial phenomena that are at the basis of our understanding of
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5343</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5343</id><created>2009-12-29</created><updated>2010-02-22</updated><authors><author><keyname>Karapanos</keyname><forenames>Evangelos</forenames></author><author><keyname>Martens</keyname><forenames>Jean-Bernard</forenames></author><author><keyname>Hassenzahl</keyname><forenames>Marc</forenames></author></authors><title>Reconstructing Experiences through Sketching</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present iScale, a survey tool for the retrospective elicitation of
longitudinal user experience data. iScale employs sketching in imposing a
process in the reconstruction of one's experiences with the aim to minimize
retrospection bias. Two versions, the Constructive and the Value-Account
iScale, were motivated by two distinct theories on how people reconstruct
emotional experiences from memory. These two versions were tested in two
separate studies. Study 1 aimed at providing qualitative insight into the use
of iScale and compared its performance to that of free-hand sketching. Study 2
compared the two versions of iScale to free recall, a control condition that
does not influence the reconstruction process. Significant differences between
iScale and free recall were found. Overall, iScale resulted in an increase in
the amount, the richness, and the test-retest reliability of recalled
information. These results provide support for the viability of retrospective
techniques as a cost-effective alternative to longitudinal studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5353</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5353</id><created>2009-12-29</created><updated>2010-01-05</updated><authors><author><keyname>Xie</keyname><forenames>Yao</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Diversity-Multiplexing-Delay Tradeoffs in MIMO Multihop Networks with
  ARQ</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Tradeoff in diversity, multiplexing, and delay in multihop MIMO relay
networks with ARQ is studied, where the random delay is caused by queueing and
ARQ retransmission. This leads to an optimal ARQ allocation problem with
per-hop delay or end-to-end delay constraint. The optimal ARQ allocation has to
trade off between the ARQ error that the receiver fails to decode in the
allocated maximum ARQ rounds and the packet loss due to queueing delay. These
two probability of errors are characterized using the
diversity-multiplexing-delay tradeoff (DMDT) (without queueing) and the tail
probability of random delay derived using large deviation techniques,
respectively. Then the optimal ARQ allocation problem can be formulated as a
convex optimization problem. We show that the optimal ARQ allocation should
balance each link performance as well avoid significant queue delay, which is
also demonstrated by numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5380</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5380</id><created>2009-12-30</created><authors><author><keyname>Dimitrov</keyname><forenames>Darko</forenames></author><author><keyname>Holst</keyname><forenames>Mathias</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Kriegel</keyname><forenames>Klaus</forenames></author></authors><title>Computing Principal Components Dynamically</title><categories>cs.GR cs.CG</categories><comments>32 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present closed-form solutions for efficiently updating the
principal components of a set of $n$ points, when $m$ points are added or
deleted from the point set. For both operations performed on a discrete point
set in $\mathbb{R}^d$, we can compute the new principal components in $O(m)$
time for fixed $d$. This is a significant improvement over the commonly used
approach of recomputing the principal components from scratch, which takes
$O(n+m)$ time. An important application of the above result is the dynamical
computation of bounding boxes based on principal component analysis. PCA
bounding boxes are very often used in many fields, among others in computer
graphics for collision detection and fast rendering. We have implemented and
evaluated few algorithms for computing dynamically PCA bounding boxes in
$\mathbb{R}^3$. In addition, we present closed-form solutions for computing
dynamically principal components of continuous point sets in $\mathbb{R}^2$ and
$\mathbb{R}^3$. In both cases, discrete and continuous, to compute the new
principal components, no additional data structures or storage are needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5391</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5391</id><created>2009-12-30</created><authors><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Buttyan</keyname><forenames>L.</forenames></author><author><keyname>Holczer</keyname><forenames>T.</forenames></author><author><keyname>Schoch</keyname><forenames>E.</forenames></author><author><keyname>Freudiger</keyname><forenames>J.</forenames></author><author><keyname>Raya</keyname><forenames>M.</forenames></author><author><keyname>Ma</keyname><forenames>Z.</forenames></author><author><keyname>Kargl</keyname><forenames>F.</forenames></author><author><keyname>Kung</keyname><forenames>A.</forenames></author><author><keyname>Hubaux</keyname><forenames>J. -P.</forenames></author></authors><title>Secure Vehicular Communication Systems: Design and Architecture</title><categories>cs.CR cs.NI</categories><journal-ref>IEEE Communcations Magazine, vol. 46, no. 11, pp. 100--109,
  November 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Significant developments have taken place over the past few years in the area
of vehicular communication (VC) systems. Now, it is well understood in the
community that security and protection of private user information are a
prerequisite for the deployment of the technology. This is so, precisely
because the benefits of VC systems, with the mission to enhance transportation
safety and efficiency, are at stake. Without the integration of strong and
practical security and privacy enhancing mechanisms, VC systems could be
disrupted or disabled, even by relatively unsophisticated attackers. We address
this problem within the SeVeCom project, having developed a security
architecture that provides a comprehensive and practical solution. We present
our results in a set of two papers in this issue. In this first one, we analyze
threats and types of adversaries, we identify security and privacy
requirements, and we present a spectrum of mechanisms to secure VC systems. We
provide a solution that can be quickly adopted and deployed. In the second
paper, we present our progress towards the implementation of our architecture
and results on the performance of the secure VC system, along with a discussion
of upcoming research challenges and our related current results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5393</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5393</id><created>2009-12-30</created><authors><author><keyname>Kargl</keyname><forenames>F.</forenames></author><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Buttyan</keyname><forenames>L.</forenames></author><author><keyname>Muter</keyname><forenames>M.</forenames></author><author><keyname>Wiedersheim</keyname><forenames>B.</forenames></author><author><keyname>Schoch</keyname><forenames>E.</forenames></author><author><keyname>Thong</keyname><forenames>T. -V.</forenames></author><author><keyname>Calandriello</keyname><forenames>G.</forenames></author><author><keyname>Held</keyname><forenames>A.</forenames></author><author><keyname>Kung</keyname><forenames>A.</forenames></author><author><keyname>Hubaux</keyname><forenames>J. -P.</forenames></author></authors><title>Secure Vehicular Communication Systems: Implementation, Performance, and
  Research Challenges</title><categories>cs.CR cs.NI</categories><journal-ref>IEEE Communications Magazine, vol. 46, no. 11, pp. 110--118,
  November 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular Communication (VC) systems are on the verge of practical
deployment. Nonetheless, their security and privacy protection is one of the
problems that have been addressed only recently. In order to show the
feasibility of secure VC, certain implementations are required. In [1] we
discuss the design of a VC security system that has emerged as a result of the
European SeVeCom project. In this second paper, we discuss various issues
related to the implementation and deployment aspects of secure VC systems.
Moreover, we provide an outlook on open security research issues that will
arise as VC systems develop from today's simple prototypes to full-fledged
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5410</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5410</id><created>2009-12-29</created><authors><author><keyname>Goldenberg</keyname><forenames>Anna</forenames></author><author><keyname>Zheng</keyname><forenames>Alice X</forenames></author><author><keyname>Fienberg</keyname><forenames>Stephen E</forenames></author><author><keyname>Airoldi</keyname><forenames>Edoardo M</forenames></author></authors><title>A survey of statistical network models</title><categories>stat.ME cs.LG physics.soc-ph q-bio.MN stat.ML</categories><comments>96 pages, 14 figures, 333 references</comments><journal-ref>Foundations and Trends in Machine Learning, 2(2):1-117, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks are ubiquitous in science and have become a focal point for
discussion in everyday life. Formal statistical models for the analysis of
network data have emerged as a major topic of interest in diverse areas of
study, and most of these involve a form of graphical representation.
Probability models on graphs date back to 1959. Along with empirical studies in
social psychology and sociology from the 1960s, these early works generated an
active network community and a substantial literature in the 1970s. This effort
moved into the statistical literature in the late 1970s and 1980s, and the past
decade has seen a burgeoning network literature in statistical physics and
computer science. The growth of the World Wide Web and the emergence of online
networking communities such as Facebook, MySpace, and LinkedIn, and a host of
more specialized professional network communities has intensified interest in
the study of networks and network data. Our goal in this review is to provide
the reader with an entry point to this burgeoning literature. We begin with an
overview of the historical development of statistical network modeling and then
we introduce a number of examples that have been studied in the network
literature. Our subsequent discussion focuses on a number of prominent static
and dynamic network models and their interconnections. We emphasize formal
model descriptions, and pay special attention to the interpretation of
parameters and their estimation. We end with a description of some open
problems and challenges for machine learning and statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5424</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5424</id><created>2009-12-30</created><updated>2010-08-16</updated><authors><author><keyname>Arbitman</keyname><forenames>Yuriy</forenames></author><author><keyname>Naor</keyname><forenames>Moni</forenames></author><author><keyname>Segev</keyname><forenames>Gil</forenames></author></authors><title>Backyard Cuckoo Hashing: Constant Worst-Case Operations with a Succinct
  Representation</title><categories>cs.DS</categories><comments>FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of a dynamic dictionary is measured mainly by its update
time, lookup time, and space consumption. In terms of update time and lookup
time there are known constructions that guarantee constant-time operations in
the worst case with high probability, and in terms of space consumption there
are known constructions that use essentially optimal space. However, although
the first analysis of a dynamic dictionary dates back more than 45 years ago
(when Knuth analyzed linear probing in 1963), the trade-off between these
aspects of performance is still not completely understood. In this paper we
settle two fundamental open problems: - We construct the first dynamic
dictionary that enjoys the best of both worlds: it stores n elements using
(1+epsilon)n memory words, and guarantees constant-time operations in the worst
case with high probability. Specifically, for any epsilon = \Omega((\log\log n
/ \log n)^{1/2} ) and for any sequence of polynomially many operations, with
high probability over the randomness of the initialization phase, all
operations are performed in constant time which is independent of epsilon. The
construction is a two-level variant of cuckoo hashing, augmented with a
&quot;backyard&quot; that handles a large fraction of the elements, together with a
de-amortized perfect hashing scheme for eliminating the dependency on epsilon.
- We present a variant of the above construction that uses only (1+o(1))B bits,
where B is the information-theoretic lower bound for representing a set of size
n taken from a universe of size u, and guarantees constant-time operations in
the worst case with high probability, as before. This problem was open even in
the amortized setting. One of the main ingredients of our construction is a
permutation-based variant of cuckoo hashing, which significantly improves the
space consumption of cuckoo hashing when dealing with a rather small universe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5426</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5426</id><created>2009-12-30</created><authors><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author><author><keyname>Tao</keyname><forenames>Yufei</forenames></author></authors><title>The Hardness and Approximation Algorithms for L-Diversity</title><categories>cs.DB</categories><comments>EDBT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing solutions to privacy preserving publication can be classified
into the theoretical and heuristic categories. The former guarantees provably
low information loss, whereas the latter incurs gigantic loss in the worst
case, but is shown empirically to perform well on many real inputs. While
numerous heuristic algorithms have been developed to satisfy advanced privacy
principles such as l-diversity, t-closeness, etc., the theoretical category is
currently limited to k-anonymity which is the earliest principle known to have
severe vulnerability to privacy attacks. Motivated by this, we present the
first theoretical study on l-diversity, a popular principle that is widely
adopted in the literature. First, we show that optimal l-diverse generalization
is NP-hard even when there are only 3 distinct sensitive values in the
microdata. Then, an (l*d)-approximation algorithm is developed, where d is the
dimensionality of the underlying dataset. This is the first known algorithm
with a non-trivial bound on information loss. Extensive experiments with real
datasets validate the effectiveness and efficiency of proposed solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5434</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5434</id><created>2009-12-30</created><updated>2010-09-30</updated><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>A Complete Theory of Everything (will be subjective)</title><categories>cs.IT astro-ph.CO math.IT physics.pop-ph</categories><comments>26 LaTeX pages</comments><journal-ref>Algorithms 3:329-350,2010</journal-ref><doi>10.3390/a3040329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasingly encompassing models have been suggested for our world. Theories
range from generally accepted to increasingly speculative to apparently bogus.
The progression of theories from ego- to geo- to helio-centric models to
universe and multiverse theories and beyond was accompanied by a dramatic
increase in the sizes of the postulated worlds, with humans being expelled from
their center to ever more remote and random locations. Rather than leading to a
true theory of everything, this trend faces a turning point after which the
predictive power of such theories decreases (actually to zero). Incorporating
the location and other capacities of the observer into such theories avoids
this problem and allows to distinguish meaningful from predictively meaningless
theories. This also leads to a truly complete theory of everything consisting
of a (conventional objective) theory of everything plus a (novel subjective)
observer process. The observer localization is neither based on the
controversial anthropic principle, nor has it anything to do with the
quantum-mechanical observation process. The suggested principle is extended to
more practical (partial, approximate, probabilistic, parametric) world models
(rather than theories of everything). Finally, I provide a justification of
Ockham's razor, and criticize the anthropic principle, the doomsday argument,
the no free lunch theorem, and the falsifiability dogma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5449</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5449</id><created>2009-12-30</created><authors><author><keyname>Ferreira</keyname><forenames>Artur</forenames></author><author><keyname>Oliveira</keyname><forenames>Arlindo</forenames></author><author><keyname>Figueiredo</keyname><forenames>Mario</forenames></author></authors><title>Time and Memory Efficient Lempel-Ziv Compression Using Suffix Arrays</title><categories>cs.DS cs.IT math.IT</categories><comments>10 pages, submitted to DCC2010</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well-known dictionary-based algorithms of the Lempel-Ziv (LZ) 77 family
are the basis of several universal lossless compression techniques. These
algorithms are asymmetric regarding encoding/decoding time and memory
requirements, with the former being much more demanding. In the past years,
considerable attention has been devoted to the problem of finding efficient
data structures to support these searches, aiming at optimizing the encoders in
terms of speed and memory. Hash tables, binary search trees and suffix trees
have been widely used for this purpose, as they allow fast search at the
expense of memory. Some recent research has focused on suffix arrays (SA), due
to their low memory requirements and linear construction algorithms. Previous
work has shown how the LZ77 decomposition can be computed using a single SA or
an SA with an auxiliary array with the longest common prefix information. The
SA-based algorithms use less memory than the tree-based encoders, allocating
the strictly necessary amount of memory, regardless of the contents of the text
to search/encode. In this paper, we improve on previous work by proposing
faster SA-based algorithms for LZ77 encoding and sub-string search, keeping
their low memory requirements. For some compression settings, on a large set of
benchmark files, our low-memory SA-based encoders are also faster than
tree-based encoders. This provides time and memory efficient LZ77 encoding,
being a possible replacement for trees on well known encoders like LZMA. Our
algorithm is also suited for text classification, because it provides a compact
way to describe text in a bag-of-words representation, as well as a fast
indexing mechanism that allows to quickly find all the sets of words that start
with a given symbol, over a static dictionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5456</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5456</id><created>2009-12-30</created><authors><author><keyname>Schmidt</keyname><forenames>Thomas C.</forenames></author><author><keyname>Hildebrand</keyname><forenames>Arne</forenames></author><author><keyname>Engelhardt</keyname><forenames>Michael</forenames></author><author><keyname>Lange</keyname><forenames>Dagmar</forenames></author></authors><title>From a Link Semantic to Semantic Links - Building Context in Educational
  Hypermedia</title><categories>cs.IR cs.NI</categories><comments>Summary of several conference articles</comments><acm-class>H.4.2; H.5.4; H.3.3; C.2.4; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modularization and granulation are key concepts in educational content
management, whereas teaching, learning and understanding require a discourse
within thematic contexts. Even though hyperlinks and semantically typed
references provide the context building blocks of hypermedia systems, elaborate
concepts to derive, manage and propagate such relations between content objects
are not around at present. Based on Semantic Web standards, this paper makes
several contributions to content enrichment. Work starts from harvesting
multimedia annotations in class-room recordings, and proceeds to deriving a
dense educational semantic net between eLearning Objects decorated with
extended LOM relations. Special focus is drawn on the processing of recorded
speech and on an Ontological Evaluation Layer that autonomously derives
meaningful inter-object relations. Further on, a semantic representation of
hyperlinks is developed and elaborated to the concept of semantic link
contexts, an approach to manage a coherent rhetoric of linking. These solutions
have been implemented in the Hypermedia Learning Objects System (hylOs), our
eLearning content management system. hylOs is built upon the more general Media
Information Repository (MIR) and the MIR adaptive context linking environment
(MIRaCLE), its linking extension. MIR is an open system supporting the
standards XML and JNDI. hylOs benefits from configurable information
structures, sophisticated access logic and high-level authoring tools like the
WYSIWYG XML editor and its Instructional Designer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5468</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5468</id><created>2009-12-30</created><updated>2010-02-03</updated><authors><author><keyname>Fiala</keyname><forenames>Jiri</forenames></author><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Lidicky</keyname><forenames>Bernard</forenames></author><author><keyname>Paulusma</keyname><forenames>Daniel</forenames></author></authors><title>The k-in-a-path problem for claw-free graphs</title><categories>cs.DM cs.DS</categories><comments>12 pages, 1 figure, STACS 2010</comments><acm-class>G.2.2; F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Testing whether there is an induced path in a graph spanning k given vertices
is already NP-complete in general graphs when k=3. We show how to solve this
problem in polynomial time on claw-free graphs, when k is not part of the input
but an arbitrarily fixed integer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5473</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5473</id><created>2009-12-30</created><authors><author><keyname>Paul</keyname><forenames>Gerald</forenames></author></authors><title>A Variable Depth Sequential Search Heuristic for the Quadratic
  Assignment Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a variable depth search heuristic for the quadratic assignment
problem. The heuristic is based on sequential changes in assignments analogous
to the Lin-Kernighan sequential edge moves for the traveling salesman problem.
We treat unstructured problem instances of sizes 60 to 400. When the heuristic
is used in conjunction with robust tabu search, we measure performance
improvements of up to a factor of 15 compared to the use of robust tabu alone.
The performance improvement increases as the problem size increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5494</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5494</id><created>2009-12-30</created><authors><author><keyname>Song</keyname><forenames>Miao</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Grogono</keyname><forenames>Peter</forenames></author></authors><title>Teaching Physical Based Animation via OpenGL Slides</title><categories>cs.GR cs.HC</categories><comments>12 pages; 7 figures; the poster is presented at C32SE'09 and the
  paper at CISSE'09 at http://conference.cisse2009.org/proceedings.aspx ; there
  are an executable demo and its source code</comments><acm-class>I.3.7; I.3.6; I.4.9; H.5.2</acm-class><doi>10.1007/978-90-481-9112-3_82 10.1145/1557626.1557647</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work expands further our earlier poster presentation and integration of
the OpenGL Slides Framework (OGLSF) - to make presentations with real-time
animated graphics where each slide is a scene with tidgets - and physical based
animation of elastic two-, three-layer softbody objects. The whole project is
very interactive, and serves dual purpose - delivering the teaching material in
a classroom setting with real running animated examples as well as releasing
the source code to the students to show how the actual working things are made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5497</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5497</id><created>2009-12-30</created><authors><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Haas</keyname><forenames>Z. J.</forenames></author><author><keyname>Hubaux</keyname><forenames>J. -P.</forenames></author></authors><title>How to Specify and How to Prove Correctness of Secure Routing Protocols
  for MANET</title><categories>cs.CR cs.NI</categories><journal-ref>IEEE-CS BroadNets 2006, San Jose, CA, USA, October 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure routing protocols for mobile ad hoc networks have been developed
recently, yet, it has been unclear what are the properties they achieve, as a
formal analysis of these protocols is mostly lacking. In this paper, we are
concerned with this problem, how to specify and how to prove the correctness of
a secure routing protocol. We provide a definition of what a protocol is
expected to achieve independently of its functionality, as well as
communication and adversary models. This way, we enable formal reasoning on the
correctness of secure routing protocols. We demonstrate this by analyzing two
protocols from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5502</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5502</id><created>2009-12-30</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Song</keyname><forenames>Miao</forenames></author><author><keyname>Suen</keyname><forenames>Ching Y.</forenames></author></authors><title>Writer Identification Using Inexpensive Signal Processing Techniques</title><categories>cs.CV</categories><comments>9 pages; 1 figure; presented at CISSE'09 at
  http://conference.cisse2009.org/proceedings.aspx ; includes the the
  application source code; based on MARF described in arXiv:0905.1235</comments><acm-class>I.5</acm-class><doi>10.1007/978-90-481-9112-3_74</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to use novel and classical audio and text signal-processing and
otherwise techniques for &quot;inexpensive&quot; fast writer identification tasks of
scanned hand-written documents &quot;visually&quot;. The &quot;inexpensive&quot; refers to the
efficiency of the identification process in terms of CPU cycles while
preserving decent accuracy for preliminary identification. This is a
comparative study of multiple algorithm combinations in a pattern recognition
pipeline implemented in Java around an open-source Modular Audio Recognition
Framework (MARF) that can do a lot more beyond audio. We present our
preliminary experimental findings in such an identification task. We simulate
&quot;visual&quot; identification by &quot;looking&quot; at the hand-written document as a whole
rather than trying to extract fine-grained features out of it prior
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5506</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5506</id><created>2009-12-30</created><authors><author><keyname>Panchard</keyname><forenames>J.</forenames></author><author><keyname>Rao</keyname><forenames>P. R. S.</forenames></author><author><keyname>Sheshshayee</keyname><forenames>M. S.</forenames></author><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Kumar</keyname><forenames>S.</forenames></author><author><keyname>Hubaux</keyname><forenames>J-P.</forenames></author></authors><title>Wireless Sensor Networking for Rain-fed Farming Decision Support</title><categories>cs.NI</categories><acm-class>C.2.m</acm-class><journal-ref>ACM SIGCOMM Workshop on Networked Systems for Developing Regions
  (NSDR), Seattle, WA, USA, August 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) can be a valuable decision-support tool for
farmers. This motivated our deployment of a WSN system to support rain-fed
agriculture in India. We defined promising use cases and resolved technical
challenges throughout a two-year deployment of our COMMON-Sense Net system,
which provided farmers with environment data. However, the direct use of this
technology in the field did not foster the expected participation of the
population. This made it difficult to develop the intended decision-support
system. Based on this experience, we take the following position in this paper:
currently, the deployment of WSN technology in developing regions is more
likely to be effective if it targets scientists and technical personnel as
users, rather than the farmers themselves. We base this claim on the lessons
learned from the COMMON-Sense system deployment and the results of an extensive
user experiment with agriculture scientists, which we describe in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5511</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5511</id><created>2009-12-30</created><authors><author><keyname>Delgrande</keyname><forenames>James</forenames></author><author><keyname>Schaub</keyname><forenames>Torsten</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author><author><keyname>Woltran</keyname><forenames>Stefan</forenames></author></authors><title>A general approach to belief change in answer set programming</title><categories>cs.AI</categories><comments>44 pages</comments><acm-class>I.2.3; I.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of belief change in (nonmonotonic) logic programming
under answer set semantics. Unlike previous approaches to belief change in
logic programming, our formal techniques are analogous to those of
distance-based belief revision in propositional logic. In developing our
results, we build upon the model theory of logic programs furnished by SE
models. Since SE models provide a formal, monotonic characterisation of logic
programs, we can adapt techniques from the area of belief revision to belief
change in logic programs. We introduce methods for revising and merging logic
programs, respectively. For the former, we study both subset-based revision as
well as cardinality-based revision, and we show that they satisfy the majority
of the AGM postulates for revision. For merging, we consider operators
following arbitration merging and IC merging, respectively. We also present
encodings for computing the revision as well as the merging of logic programs
within the same logic programming framework, giving rise to a direct
implementation of our approach in terms of off-the-shelf answer set solvers.
These encodings reflect in turn the fact that our change operators do not
increase the complexity of the base formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5514</identifier>
 <datestamp>2012-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5514</id><created>2009-12-30</created><updated>2012-06-18</updated><authors><author><keyname>De</keyname><forenames>Anindya</forenames></author><author><keyname>Portmann</keyname><forenames>Christopher</forenames></author><author><keyname>Vidick</keyname><forenames>Thomas</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Trevisan's extractor in the presence of quantum side information</title><categories>quant-ph cs.CC cs.CR</categories><comments>20+10 pages; v2: extract more min-entropy, use weakly random seed;
  v3: extended introduction, matches published version with sections somewhat
  reordered</comments><journal-ref>SIAM Journal on Computing, 41(4):915-940, 2012</journal-ref><doi>10.1137/100813683</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomness extraction involves the processing of purely classical information
and is therefore usually studied in the framework of classical probability
theory. However, such a classical treatment is generally too restrictive for
applications, where side information about the values taken by classical random
variables may be represented by the state of a quantum system. This is
particularly relevant in the context of cryptography, where an adversary may
make use of quantum devices. Here, we show that the well known construction
paradigm for extractors proposed by Trevisan is sound in the presence of
quantum side information.
  We exploit the modularity of this paradigm to give several concrete extractor
constructions, which, e.g, extract all the conditional (smooth) min-entropy of
the source using a seed of length poly-logarithmic in the input, or only
require the seed to be weakly random.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5515</identifier>
 <datestamp>2010-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5515</id><created>2009-12-30</created><updated>2010-01-02</updated><authors><author><keyname>Polonowski</keyname><forenames>Emmanuel</forenames></author></authors><title>LoopW Technical Reference v0.3</title><categories>cs.LO</categories><report-no>TR-LACL-2009-8</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the implementation in SML of the LoopW language, an
imperative language with higher-order procedural variables and non-local jumps
equiped with a program logic. It includes the user manual along with some
implementation notes and many examples of certified imperative programs. As a
concluding example, we show the certification of an imperative program encoding
shift/reset using callcc/throw and a global meta-continuation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5518</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5518</id><created>2009-12-30</created><authors><author><keyname>Crocce</keyname><forenames>Fabian</forenames></author><author><keyname>Mordecki</keyname><forenames>Ernesto</forenames></author></authors><title>Optimal minimax strategy in a dice game</title><categories>math.PR cs.GT math.OC</categories><comments>14 pages</comments><msc-class>60J10; 91A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each of two players, by turns, rolls a dice several times accumulating the
successive scores until he decides to stop, or he rolls an ace. When stopping,
the accumulated turn score is added to the player account and the dice is given
to his opponent. If he rolls an ace, the dice is given to the opponent without
adding any point. In this paper we formulate this game in the framework of
competitive Markov decision processes (also known as stochastic games), show
that the game has a value, provide an algorithm to compute the optimal minimax
strategy, and present results of this algorithm in three different variants of
the game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5524</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5524</id><created>2009-12-30</created><updated>2010-01-11</updated><authors><author><keyname>Meyer</keyname><forenames>Thomas Kellam</forenames></author></authors><title>The Cardinality of Infinite Games</title><categories>math.CT cs.GT math.CO</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The focus of this essay is a rigorous treatment of infinite games. An
infinite game is defined as a play consisting of a fixed number of players
whose sequence of moves is repeated, or iterated ad infinitum. Each sequence
corresponds to a single iteration of the play, where there are an infinite
amount of iterations. There are two distinct concepts within this broad
definition which encompass all infinite games: the strong infinite game and the
weak infinite game. Both differ in terms of imputations. The strong infinite
game has a uniqueness qualification in that all moves must differ to the extent
that no imputation (these occur at the end of any given iteration) may ever be
the same. Conversely, there is no such qualification in a weak infinite game,
any payout may equal another.
  Another property shared by strong and weak infinite games (apart from their
fulfilling the criterion of an infinite game) is the fact that both consist of
a countably infinite amount of moves. Therefore all infinite games have a
countably infinite number of turns; the set of all infinite games is composed
of each strong and weak infinite game. This result has a very important
consequence: the ordinality of turns. That is, the moves of an infinite game
have an order or structure which they adhere to. It is this structure which
provides any future development or game theoretical analysis of these sorts of
games with the necessary foundation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5527</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5527</id><created>2009-12-30</created><authors><author><keyname>Kafsi</keyname><forenames>M.</forenames></author><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Dousse</keyname><forenames>O.</forenames></author><author><keyname>Alpcan</keyname><forenames>T.</forenames></author><author><keyname>Hubaux</keyname><forenames>J. -P.</forenames></author></authors><title>VANET Connectivity Analysis</title><categories>cs.NI</categories><journal-ref>IEEE AutoNet, New Orleans, LA, USA, December 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular Ad Hoc Networks (VANETs) are a peculiar subclass of mobile ad hoc
networks that raise a number of technical challenges, notably from the point of
view of their mobility models. In this paper, we provide a thorough analysis of
the connectivity of such networks by leveraging on well-known results of
percolation theory. By means of simulations, we study the influence of a number
of parameters, including vehicle density, proportion of equipped vehicles, and
radio communication range. We also study the influence of traffic lights and
roadside units. Our results provide insights on the behavior of connectivity.
We believe this paper to be a valuable framework to assess the feasibility and
performance of future applications relying on vehicular connectivity in urban
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5533</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5533</id><created>2009-12-30</created><authors><author><keyname>Moratz</keyname><forenames>Reinhard</forenames></author><author><keyname>L&#xfc;cke</keyname><forenames>Dominik</forenames></author><author><keyname>Mossakowski</keyname><forenames>Till</forenames></author></authors><title>Oriented Straight Line Segment Algebra: Qualitative Spatial Reasoning
  about Oriented Objects</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Nearly 15 years ago, a set of qualitative spatial relations between oriented
straight line segments (dipoles) was suggested by Schlieder. This work received
substantial interest amongst the qualitative spatial reasoning community.
However, it turned out to be difficult to establish a sound constraint calculus
based on these relations. In this paper, we present the results of a new
investigation into dipole constraint calculi which uses algebraic methods to
derive sound results on the composition of relations and other properties of
dipole calculi. Our results are based on a condensed semantics of the dipole
relations.
  In contrast to the points that are normally used, dipoles are extended and
have an intrinsic direction. Both features are important properties of natural
objects. This allows for a straightforward representation of prototypical
reasoning tasks for spatial agents. As an example, we show how to generate
survey knowledge from local observations in a street network. The example
illustrates the fast constraint-based reasoning capabilities of the dipole
calculus. We integrate our results into two reasoning tools which are publicly
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0912.5537</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0912.5537</id><created>2009-12-30</created><updated>2014-03-04</updated><authors><author><keyname>Bennett</keyname><forenames>Charles H.</forenames></author><author><keyname>Devetak</keyname><forenames>Igor</forenames></author><author><keyname>Harrow</keyname><forenames>Aram W.</forenames></author><author><keyname>Shor</keyname><forenames>Peter W.</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Quantum Reverse Shannon Theorem</title><categories>quant-ph cs.IT math.IT</categories><comments>35 pages, to appear in IEEE-IT. v2 has a fixed proof of the Clueless
  Eve result, a new single-letter formula for the &quot;spread deficit&quot;, better
  error scaling, and an improved strong converse. v3 and v4 each make small
  improvements to the presentation and add references. v5 fixes broken
  references</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 60, no. 5, pp. 2926-2959, May 2014</journal-ref><doi>10.1109/TIT.2014.2309968</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual to the usual noisy channel coding problem, where a noisy (classical or
quantum) channel is used to simulate a noiseless one, reverse Shannon theorems
concern the use of noiseless channels to simulate noisy ones, and more
generally the use of one noisy channel to simulate another. For channels of
nonzero capacity, this simulation is always possible, but for it to be
efficient, auxiliary resources of the proper kind and amount are generally
required. In the classical case, shared randomness between sender and receiver
is a sufficient auxiliary resource, regardless of the nature of the source, but
in the quantum case the requisite auxiliary resources for efficient simulation
depend on both the channel being simulated, and the source from which the
channel inputs are coming. For tensor power sources (the quantum generalization
of classical IID sources), entanglement in the form of standard ebits
(maximally entangled pairs of qubits) is sufficient, but for general sources,
which may be arbitrarily correlated or entangled across channel inputs,
additional resources, such as entanglement-embezzling states or backward
communication, are generally needed. Combining existing and new results, we
establish the amounts of communication and auxiliary resources needed in both
the classical and quantum cases, the tradeoffs among them, and the loss of
simulation efficiency when auxiliary resources are absent or insufficient. In
particular we find a new single-letter expression for the excess forward
communication cost of coherent feedback simulations of quantum channels (i.e.
simulations in which the sender retains what would escape into the environment
in an ordinary simulation), on non-tensor-power sources in the presence of
unlimited ebits but no other auxiliary resource. Our results on tensor power
sources establish a strong converse to the entanglement-assisted capacity
theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0001</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0001</id><created>2009-12-30</created><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author><author><keyname>Heden</keyname><forenames>Olof</forenames><affiliation>Department of Mathematics, KTH, Stockholm, Sweden</affiliation></author></authors><title>On the structure of non-full-rank perfect codes</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><journal-ref>Adv. Math. Commun. 5(2) 2011, 149-156</journal-ref><doi>10.3934/amc.2011.5.149</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Krotov combining construction of perfect 1-error-correcting binary codes
from 2000 and a theorem of Heden saying that every non-full-rank perfect
1-error-correcting binary code can be constructed by this combining
construction is generalized to the $q$-ary case. Simply, every non-full-rank
perfect code $C$ is the union of a well-defined family of $\mu$-components
$K_\mu$, where $\mu$ belongs to an &quot;outer&quot; perfect code $C^*$, and these
components are at distance three from each other. Components from distinct
codes can thus freely be combined to obtain new perfect codes. The Phelps
general product construction of perfect binary code from 1984 is generalized to
obtain $\mu$-components, and new lower bounds on the number of perfect
1-error-correcting $q$-ary codes are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0018</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0018</id><created>2009-12-30</created><updated>2010-01-28</updated><authors><author><keyname>Montanaro</keyname><forenames>Ashley</forenames></author></authors><title>Nonadaptive quantum query complexity</title><categories>quant-ph cs.CC</categories><comments>9 pages; v2: new title, updated with new results on learning</comments><journal-ref>Information Processing Letters 110 (2010), pp. 1110-1113</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power of nonadaptive quantum query algorithms, which are
algorithms whose queries to the input do not depend on the result of previous
queries. First, we show that any bounded-error nonadaptive quantum query
algorithm that computes some total boolean function depending on n variables
must make Omega(n) queries to the input in total. Second, we show that, if
there exists a quantum algorithm that uses k nonadaptive oracle queries to
learn which one of a set of m boolean functions it has been given, there exists
a nonadaptive classical algorithm using O(k log m) queries to solve the same
problem. Thus, in the nonadaptive setting, quantum algorithms can achieve at
most a very limited speed-up over classical query algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0025</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0025</id><created>2009-12-30</created><authors><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Jovanovic</keyname><forenames>A.</forenames></author></authors><title>GNSS-based positioning: Attacks and Countermeasures</title><categories>cs.CR</categories><journal-ref>IEEE MILCOM, San Diego, CA, USA, November 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing numbers of mobile computing devices, user-portable, or embedded in
vehicles, cargo containers, or the physical space, need to be aware of their
location in order to provide a wide range of commercial services. Most often,
mobile devices obtain their own location with the help of Global Navigation
Satellite Systems (GNSS), integrating, for example, a Global Positioning System
(GPS) receiver. Nonetheless, an adversary can compromise location-aware
applications by attacking the GNSS-based positioning: It can forge navigation
messages and mislead the receiver into calculating a fake location. In this
paper, we analyze this vulnerability and propose and evaluate the effectiveness
of countermeasures. First, we consider replay attacks, which can be effective
even in the presence of future cryptographic GNSS protection mechanisms. Then,
we propose and analyze methods that allow GNSS receivers to detect the
reception of signals generated by an adversary, and then reject fake locations
calculated because of the attack. We consider three diverse defense mechanisms,
all based on knowledge, in particular, own location, time, and Doppler shift,
receivers can obtain prior to the onset of an attack. We find that inertial
mechanisms that estimate location can be defeated relatively easy. This is
equally true for the mechanism that relies on clock readings from off-the-shelf
devices; as a result, highly stable clocks could be needed. On the other hand,
our Doppler Shift Test can be effective without any specialized hardware, and
it can be applied to existing devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0036</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0036</id><created>2009-12-30</created><authors><author><keyname>Haslinger</keyname><forenames>Robert</forenames></author><author><keyname>Klinkner</keyname><forenames>Kristina Lisa</forenames></author><author><keyname>Shalizi</keyname><forenames>Cosma Rohilla</forenames></author></authors><title>The Computational Structure of Spike Trains</title><categories>q-bio.NC cs.IT math.IT nlin.AO physics.data-an stat.ML</categories><comments>Somewhat different format from journal version but same content</comments><journal-ref>Neural Computation, vol. 22 (2010), pp. 121--157</journal-ref><doi>10.1162/neco.2009.12-07-678</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neurons perform computations, and convey the results of those computations
through the statistical structure of their output spike trains. Here we present
a practical method, grounded in the information-theoretic analysis of
prediction, for inferring a minimal representation of that structure and for
characterizing its complexity. Starting from spike trains, our approach finds
their causal state models (CSMs), the minimal hidden Markov models or
stochastic automata capable of generating statistically identical time series.
We then use these CSMs to objectively quantify both the generalizable structure
and the idiosyncratic randomness of the spike train. Specifically, we show that
the expected algorithmic information content (the information needed to
describe the spike train exactly) can be split into three parts describing (1)
the time-invariant structure (complexity) of the minimal spike-generating
process, which describes the spike train statistically; (2) the randomness
(internal entropy rate) of the minimal spike-generating process; and (3) a
residual pure noise term not described by the minimal spike-generating process.
We use CSMs to approximate each of these quantities. The CSMs are inferred
nonparametrically from the data, making only mild regularity assumptions, via
the causal state splitting reconstruction algorithm. The methods presented here
complement more traditional spike train analyses by describing not only spiking
probability and spike train entropy, but also the complexity of a spike train's
structure. We demonstrate our approach using both simulated spike trains and
experimental data recorded in rat barrel cortex during vibrissa stimulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0039</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0039</id><created>2009-12-30</created><authors><author><keyname>Mitschang</keyname><forenames>Arik W.</forenames><affiliation>Smithsonian Astrophysical Observatory</affiliation></author><author><keyname>Huenemoerder</keyname><forenames>David P.</forenames><affiliation>MIT Kavli Institute for Space Research</affiliation></author><author><keyname>Nichols</keyname><forenames>Joy S.</forenames><affiliation>Smithsonian Astrophysical Observatory</affiliation></author></authors><title>TGCat, The Chandra Transmission Grating Catalog and Archive: Systems,
  Design and Accessibility</title><categories>astro-ph.IM cs.DL</categories><comments>5 pages, proceedings of ADASS XIX, Oct 4-8 2009, Sapporo, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently released Chandra Transmission Grating Catalog and Archive,
TGCat, presents a fully dynamic on-line catalog allowing users to browse and
categorize Chandra gratings observations quickly and easily, generate custom
plots of resulting response corrected spectra on-line without the need for
special software and to download analysis ready products from multiple
observations in one convenient operation. TGCat has been registered as a VO
resource with the NVO providing direct access to the catalogs interface. The
catalog is supported by a back-end designed to automatically fetch newly public
data, process, archive and catalog them, At the same time utilizing an advanced
queue system integrated into the archive's MySQL database allowing large
processing projects to take advantage of an unlimited number of CPUs across a
network for rapid completion. A unique feature of the catalog is that all of
the high level functions used to retrieve inputs from the Chandra archive and
to generate the final data products are available to the user in an ISIS
written library with detailed documentation. Here we present a structural
overview of the Systems, Design, and Accessibility features of the catalog and
archive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0041</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0041</id><created>2009-12-30</created><updated>2010-07-02</updated><authors><author><keyname>Indyk</keyname><forenames>Piotr</forenames></author><author><keyname>Szarek</keyname><forenames>Stanislaw</forenames></author></authors><title>Almost-Euclidean subspaces of $\ell_1^N$ via tensor products: a simple
  approach to randomness reduction</title><categories>math.MG cs.CC math.FA</categories><comments>11 pages; title change, abstract and references added, other minor
  changes</comments><msc-class>46B25, 52A21, 68P30</msc-class><journal-ref>RANDOM 2010, LNCS 6302, Springer 2010, 632-641</journal-ref><doi>10.1007/978-3-642-15369-3_47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been known since 1970's that the N-dimensional $\ell_1$-space contains
nearly Euclidean subspaces whose dimension is $\Omega(N)$. However, proofs of
existence of such subspaces were probabilistic, hence non-constructive, which
made the results not-quite-suitable for subsequently discovered applications to
high-dimensional nearest neighbor search, error-correcting codes over the
reals, compressive sensing and other computational problems. In this paper we
present a &quot;low-tech&quot; scheme which, for any $a &gt; 0$, allows to exhibit nearly
Euclidean $\Omega(N)$-dimensional subspaces of $\ell_1^N$ while using only
$N^a$ random bits. Our results extend and complement (particularly) recent work
by Guruswami-Lee-Wigderson. Characteristic features of our approach include (1)
simplicity (we use only tensor products) and (2) yielding &quot;almost Euclidean&quot;
subspaces with arbitrarily small distortions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0054</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0054</id><created>2009-12-30</created><authors><author><keyname>Meyer</keyname><forenames>Thomas Kellam</forenames></author></authors><title>Cryptographic Implications for Artificially Mediated Games</title><categories>cs.CR cs.AI cs.GT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  There is currently an intersection in the research of game theory and
cryptography. Generally speaking, there are two aspects to this partnership.
First there is the application of game theory to cryptography. Yet, the purpose
of this paper is to focus on the second aspect, the converse of the first, the
application of cryptography to game theory. Chiefly, there exist a branch of
non-cooperative games which have a correlated equilibrium as their solution.
These equilibria tend to be superior to the conventional Nash equilibria. The
primary condition for a correlated equilibrium is the presence of a mediator
within the game. This is simply a neutral and mutually trusted entity. It is
the role of the mediator to make recommendations in terms of strategy profiles
to all players, who then act (supposedly) on this advice. Each party privately
provides the mediator with the necessary information, and the referee responds
privately with their optimized strategy set. However, there seem to be a
multitude of situations in which no mediator could exist. Thus, games modeling
these sorts of cases could not use these entities as tools for analysis. Yet,
if these equilibria are in the best interest of players, it would be rational
to construct a machine, or protocol, to calculate them. Of course, this machine
would need to satisfy some standard for secure transmission between a player
and itself. The requirement that no third party could detect either the input
or strategy profile would need to be satisfied by this scheme. Here is the
synthesis of cryptography into game theory; analyzing the ability of the
players to construct a protocol which can be used successfully in the place of
a mediator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0063</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0063</id><created>2009-12-30</created><authors><author><keyname>Epasto</keyname><forenames>Alessandro</forenames></author><author><keyname>Nardelli</keyname><forenames>Enrico</forenames></author></authors><title>On a Model for Integrated Information</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give a thorough presentation of a model proposed by Tononi
et al. for modeling \emph{integrated information}, i.e. how much information is
generated in a system transitioning from one state to the next one by the
causal interaction of its parts and \emph{above and beyond} the information
given by the sum of its parts. We also provides a more general formulation of
such a model, independent from the time chosen for the analysis and from the
uniformity of the probability distribution at the initial time instant.
Finally, we prove that integrated information is null for disconnected systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0069</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0069</id><created>2009-12-30</created><authors><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Liew</keyname><forenames>Soung-Chang</forenames></author><author><keyname>Wang</keyname><forenames>Hui</forenames></author></authors><title>Synchronization Analysis in Physical Layer Network Coding</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical-layer Network Coding (PNC) makes use of the additive nature of the
electromagnetic (EM) waves to apply network coding arithmetic at the physical
layer. With PNC,the destructive effect of interference in wireless networks is
eliminated and the capacity of networks can be boosted significantly. This
paper addresses a key outstanding issue in PNC: synchronization among
transmitting nodes. We first investigate the impact of imperfect
synchronization (i.e., finite synchronization errors) in a 3-node network. It
is shown that with QPSK modulation, PNC still yields significantly higher
capacity than straightforward network coding when there are synchronization
errors. Significantly, this remains to be so even in the extreme case when
synchronization is not performed at all. Moving beyond a 3-node network, we
propose and investigate a synchronization scheme for PNC in a general chain
network. At last, numerical simulation verifies that PNC is robust to
synchronization errors. In particular, for the mutual information performance,
there is about 0.5dB loss without time synchronization and there is at most 2dB
loss without phase synchronization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0080</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0080</id><created>2009-12-30</created><authors><author><keyname>Chen</keyname><forenames>Hongyang</forenames></author><author><keyname>Lui</keyname><forenames>Kenneth W. K.</forenames></author><author><keyname>Wang</keyname><forenames>Zizhuo</forenames></author><author><keyname>So</keyname><forenames>H. C.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Non-line-of-sight Node Localization based on Semi-Definite Programming
  in Wireless Sensor Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE ICC'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An unknown-position sensor can be localized if there are three or more
anchors making time-of-arrival (TOA) measurements of a signal from it. However,
the location errors can be very large due to the fact that some of the
measurements are from non-line-of-sight (NLOS) paths. In this paper, we propose
a semi-definite programming (SDP) based node localization algorithm in NLOS
environment for ultra-wideband (UWB) wireless sensor networks. The positions of
sensors can be estimated using the distance estimates from location-aware
anchors as well as other sensors. However, in the absence of LOS paths, e.g.,
in indoor networks, the NLOS range estimates can be significantly biased. As a
result, the NLOS error can remarkably decrease the location accuracy.
  And it is not easy to efficiently distinguish LOS from NLOS measurements. In
this paper, an algorithm is proposed that achieves high location accuracy
without the need of identifying NLOS and LOS measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0107</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0107</id><created>2009-12-31</created><updated>2010-04-15</updated><authors><author><keyname>Suh</keyname><forenames>Changho</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Exact Regeneration Codes for Distributed Storage Repair Using
  Interference Alignment</title><categories>cs.IT math.IT</categories><comments>to be submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high repair cost of (n,k) Maximum Distance Separable (MDS) erasure codes
has recently motivated a new class of codes, called Regenerating Codes, that
optimally trade off storage cost for repair bandwidth. On one end of this
spectrum of Regenerating Codes are Minimum Storage Regenerating (MSR) codes
that can match the minimum storage cost of MDS codes while also significantly
reducing repair bandwidth. In this paper, we describe Exact-MSR codes which
allow for any failed nodes (whether they are systematic or parity nodes) to be
regenerated exactly rather than only functionally or information-equivalently.
We show that Exact-MSR codes come with no loss of optimality with respect to
random-network-coding based MSR codes (matching the cutset-based lower bound on
repair bandwidth) for the cases of: (a) k/n &lt;= 1/2; and (b) k &lt;= 3. Our
constructive approach is based on interference alignment techniques, and,
unlike the previous class of random-network-coding based approaches, we provide
explicit and deterministic coding schemes that require a finite-field size of
at most 2(n-k).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0115</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0115</id><created>2009-12-31</created><authors><author><keyname>Boss</keyname><forenames>Niklas Skamriis</forenames></author><author><keyname>Jensen</keyname><forenames>Andreas Schmidt</forenames></author><author><keyname>Villadsen</keyname><forenames>J&#xf8;rgen</forenames></author></authors><title>Developing Artificial Herders Using Jason</title><categories>cs.MA</categories><comments>5 pages</comments><report-no>IfI-09-08, Clausthal University of Technology, Germany</report-no><journal-ref>Proceedings of the 10th International Workshop on Computational
  Logic in Multi-Agent Systems 2009 193-197</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives an overview of a proposed strategy for the &quot;Cows and
Herders&quot; scenario given in the Multi-Agent Programming Contest 2009. The
strategy is to be implemented using the Jason platform, based on the
agent-oriented programming language Agent-Speak. The paper describes the
agents, their goals and the strategies they should follow. The basis for the
paper and for participating in the contest is a new course given in spring 2009
and our main objective is to show that we are able to implement complex
multi-agent systems with the knowledge gained in an introductory course on
multi-agent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0117</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0117</id><created>2010-01-04</created><updated>2010-02-03</updated><authors><author><keyname>Gu</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Hitchcock</keyname><forenames>John M.</forenames></author><author><keyname>Pavan</keyname><forenames>A.</forenames></author></authors><title>Collapsing and Separating Completeness Notions under Average-Case and
  Worst-Case Hypotheses</title><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents the following results on sets that are complete for NP.
  1. If there is a problem in NP that requires exponential time at almost all
lengths, then every many-one NP-complete set is complete under
length-increasing reductions that are computed by polynomial-size circuits. 2.
If there is a problem in coNP that cannot be solved by polynomial-size
nondeterministic circuits, then every many-one complete set is complete under
length-increasing reductions that are computed by polynomial-size circuits. 3.
If there exist a one-way permutation that is secure against subexponential-size
circuits and there is a hard tally language in NP intersect coNP, then there is
a Turing complete language for NP that is not many-one complete. Our first two
results use worst-case hardness hypotheses whereas earlier work that showed
similar results relied on average-case or almost-everywhere hardness
assumptions. The use of average-case and worst-case hypotheses in the last
result is unique as previous results obtaining the same consequence relied on
almost-everywhere hardness results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0136</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0136</id><created>2009-12-31</created><authors><author><keyname>Ide</keyname><forenames>Yusuke</forenames></author><author><keyname>Konno</keyname><forenames>Norio</forenames></author><author><keyname>Obata</keyname><forenames>Nobuaki</forenames></author></authors><title>Spectral Properties of the Threshold Network Model</title><categories>math.CO cs.DM</categories><journal-ref>Internet Mathematics, Vol.6, No.2, pp.173-187 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the spectral distribution of the threshold network model.The results
contain an explicit description and its asymptotic behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0143</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0143</id><created>2009-12-31</created><authors><author><keyname>Sofronia</keyname><forenames>Alexandru</forenames></author><author><keyname>Popa</keyname><forenames>Alexandru</forenames></author><author><keyname>Stefanescu</keyname><forenames>Gheorghe</forenames></author></authors><title>Undecidability Results for Finite Interactive Systems</title><categories>cs.FL cs.PL</categories><acm-class>F.1.2; D.1.3</acm-class><journal-ref>Romanian Journal of Information Science and Technology, Volume 12
  (2009), pp. 265-279</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach to the design of massively parallel and interactive
programming languages has been recently proposed using rv-systems (interactive
systems with registers and voices) and Agapia programming. In this paper we
present a few theoretical results on FISs (finite interactive systems), the
underlying mechanism used for specifying control and interaction in these
systems. First, we give a proof for the undecidability of the emptiness problem
for FISs, by reduction to the Post Correspondence Problem. Next, we use the
construction in this proof to get other undecidability results, e.g., for the
accessibility of a transition in a FIS, or for the finiteness of the language
recognized by a FIS. Finally, we present a simple proof of the equivalence
between FISs and tile systems, making explicit that they precisely capture
recognizable two-dimensional languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0167</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0167</id><created>2009-12-31</created><authors><author><keyname>Wu</keyname><forenames>Yunnan</forenames></author><author><keyname>Jiang</keyname><forenames>Anxiao</forenames></author></authors><title>Position Modulation Code for Rewriting Write-Once Memories</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory on Sept. 23,
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A write-once memory (wom) is a storage medium formed by a number of
``write-once'' bit positions (wits), where each wit initially is in a `0' state
and can be changed to a `1' state irreversibly. Examples of write-once memories
include SLC flash memories and optical disks. This paper presents a low
complexity coding scheme for rewriting such write-once memories, which is
applicable to general problem configurations. The proposed scheme is called the
\emph{position modulation code}, as it uses the positions of the zero symbols
to encode some information. The proposed technique can achieve code rates
higher than state-of-the-art practical solutions for some configurations. For
instance, there is a position modulation code that can write 56 bits 10 times
on 278 wits, achieving rate 2.01. In addition, the position modulation code is
shown to achieve a rate at least half of the optimal rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0196</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0196</id><created>2009-12-31</created><authors><author><keyname>Walker</keyname><forenames>Edward</forenames></author></authors><title>A distributed file system for a wide-area high performance computing
  infrastructure</title><categories>cs.DC cs.OS</categories><comments>6 pages, Proceedings of Third USENIX Workshop on Real, Large
  Distributed Systems, Seattle, Nov 2006</comments><acm-class>C.2.4; D.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe our work in implementing a wide-area distributed file system for
the NSF TeraGrid. The system, called XUFS, allows private distributed name
spaces to be created for transparent access to personal files across over 9000
computer nodes. XUFS builds on many principles from prior distributed file
systems research, but extends key design goals to support the workflow of
computational science researchers. Specifically, XUFS supports file access from
the desktop to the wide-area network seamlessly, survives transient
disconnected operations robustly, and demonstrates comparable or better
throughput than some current high performance file systems on the wide-area
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0208</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0208</id><created>2010-01-01</created><updated>2010-02-03</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author><author><keyname>Woods</keyname><forenames>Damien</forenames></author></authors><title>Intrinsic Universality in Self-Assembly</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Tile Assembly Model exhibits a strong notion of universality
where the goal is to give a single tile assembly system that simulates the
behavior of any other tile assembly system. We give a tile assembly system that
is capable of simulating a very wide class of tile systems, including itself.
Specifically, we give a tile set that simulates the assembly of any tile
assembly system in a class of systems that we call \emph{locally consistent}:
each tile binds with exactly the strength needed to stay attached, and that
there are no glue mismatches between tiles in any produced assembly.
  Our construction is reminiscent of the studies of \emph{intrinsic
universality} of cellular automata by Ollinger and others, in the sense that
our simulation of a tile system $T$ by a tile system $U$ represents each tile
in an assembly produced by $T$ by a $c \times c$ block of tiles in $U$, where
$c$ is a constant depending on $T$ but not on the size of the assembly $T$
produces (which may in fact be infinite). Also, our construction improves on
earlier simulations of tile assembly systems by other tile assembly systems (in
particular, those of Soloveichik and Winfree, and of Demaine et al.) in that we
simulate the actual process of self-assembly, not just the end result, as in
Soloveichik and Winfree's construction, and we do not discriminate against
infinite structures. Both previous results simulate only temperature 1 systems,
whereas our construction simulates tile assembly systems operating at
temperature 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0210</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0210</id><created>2010-01-01</created><updated>2011-04-03</updated><authors><author><keyname>Mahdavifar</keyname><forenames>Hessam</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Achieving the Secrecy Capacity of Wiretap Channels Using Polar Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>15 pages, to appear in the IEEE Transactions on Information Theory</comments><msc-class>94B99, 94A60</msc-class><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose Alice wishes to send messages to Bob through a communication channel
C_1, but her transmissions also reach an eavesdropper Eve through another
channel C_2. The goal is to design a coding scheme that makes it possible for
Alice to communicate both reliably and securely. Reliability is measured in
terms of Bob's probability of error in recovering the message, while security
is measured in terms of Eve's equivocation ratio. Wyner showed that the
situation is characterized by a single constant C_s, called the secrecy
capacity, which has the following meaning: for all $\epsilon &gt; 0$, there exist
coding schemes of rate $R \ge C_s - \epsilon$ that asymptotically achieve both
the reliability and the security objectives. However, his proof of this result
is based upon a nonconstructive random-coding argument. To date, despite a
considerable research effort, the only case where we know how to construct
coding schemes that achieve secrecy capacity is when Eve's channel C_2 is an
erasure channel, or a combinatorial variation thereof.
  Polar codes were recently invented by Arikan; they approach the capacity of
symmetric binary-input discrete memoryless channels with low encoding and
decoding complexity. Herein, we use polar codes to construct a coding scheme
that achieves the secrecy capacity for a wide range of wiretap channels. Our
construction works for any instantiation of the wiretap channel model, as long
as both C_1 and C_2 are symmetric and binary-input, and C_2 is degraded with
respect to C_1. Moreover, we show how to modify our construction in order to
provide strong security, in the sense defined by Maurer, while still operating
at a rate that approaches the secrecy capacity. In this case, we cannot
guarantee that the reliability condition will be satisfied unless the main
channel C_1 is noiseless, although we believe it can be always satisfied in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0236</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0236</id><created>2010-01-01</created><updated>2010-02-03</updated><authors><author><keyname>de Berg</keyname><forenames>Mark</forenames></author><author><keyname>van Nijnatten</keyname><forenames>Fred</forenames></author><author><keyname>Sitters</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Woeginger</keyname><forenames>Gerhard J.</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>The Traveling Salesman Problem Under Squared Euclidean Distances</title><categories>cs.CG cs.CC</categories><comments>12 pages, 4 figures. (v2) Minor linguistic changes</comments><acm-class>I.1.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of points in $\mathbb{R}^d$, and let $\alpha \ge 1$ be a
real number. We define the distance between two points $p,q\in P$ as
$|pq|^{\alpha}$, where $|pq|$ denotes the standard Euclidean distance between
$p$ and $q$. We denote the traveling salesman problem under this distance
function by TSP($d,\alpha$). We design a 5-approximation algorithm for TSP(2,2)
and generalize this result to obtain an approximation factor of
$3^{\alpha-1}+\sqrt{6}^{\alpha}/3$ for $d=2$ and all $\alpha\ge2$.
  We also study the variant Rev-TSP of the problem where the traveling salesman
is allowed to revisit points. We present a polynomial-time approximation scheme
for Rev-TSP$(2,\alpha)$ with $\alpha\ge2$, and we show that Rev-TSP$(d,
\alpha)$ is APX-hard if $d\ge3$ and $\alpha&gt;1$. The APX-hardness proof carries
over to TSP$(d, \alpha)$ for the same parameter ranges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0251</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0251</id><created>2010-01-01</created><updated>2011-02-12</updated><authors><author><keyname>Cervelle</keyname><forenames>Julien</forenames></author><author><keyname>Formenti</keyname><forenames>Enrico</forenames></author><author><keyname>Guillon</keyname><forenames>Pierre</forenames></author></authors><title>Ultimate Traces of Cellular Automata</title><categories>cs.FL cs.DM nlin.CG</categories><comments>12 pages + 5 of appendix conference STACS'10</comments><acm-class>F.1.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cellular automaton (CA) is a parallel synchronous computing model, which
consists in a juxtaposition of finite automata (cells) whose state evolves
according to that of their neighbors. Its trace is the set of infinite words
representing the sequence of states taken by some particular cell. In this
paper we study the ultimate trace of CA and partial CA (a CA restricted to a
particular subshift). The ultimate trace is the trace observed after a long
time run of the CA. We give sufficient conditions for a set of infinite words
to be the trace of some CA and prove the undecidability of all properties over
traces that are stable by ultimate coincidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0253</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0253</id><created>2010-01-01</created><updated>2011-08-24</updated><authors><author><keyname>Guillon</keyname><forenames>Pierre</forenames></author><author><keyname>Richard</keyname><forenames>Ga&#xe9;tan</forenames></author></authors><title>Revisiting the Rice Theorem of Cellular Automata</title><categories>cs.DM cs.FL</categories><comments>12 pages conference STACS'10</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cellular automaton is a parallel synchronous computing model, which
consists in a juxtaposition of finite automata whose state evolves according to
that of their neighbors. It induces a dynamical system on the set of
configurations, i.e. the infinite sequences of cell states. The limit set of
the cellular automaton is the set of configurations which can be reached
arbitrarily late in the evolution.
  In this paper, we prove that all properties of limit sets of cellular
automata with binary-state cells are undecidable, except surjectivity. This is
a refinement of the classical &quot;Rice Theorem&quot; that Kari proved on cellular
automata with arbitrary state sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0278</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0278</id><created>2010-01-01</created><authors><author><keyname>Li</keyname><forenames>Xi</forenames></author></authors><title>How to retrieve priced data</title><categories>cs.CR</categories><comments>10 pages, 0 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Databases are an indispensable resource for retrieving up-to-date
information. However, curious database operators may be able to find out the
users' interests when the users buy something from the database. For these
cases, if the digital goods have the identical prices, then a $k$-out-of-$n$
oblivious transfer protocol could help the users to hide their choices, but
when the goods have different prices, this would not work. In this paper, we
propose a scheme to help users to keep their choices secret when buying priced
digital goods from databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0282</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0282</id><created>2010-01-04</created><authors><author><keyname>Dehghan</keyname><forenames>Hamed</forenames></author><author><keyname>Safavi</keyname><forenames>S. Ebrahim</forenames></author></authors><title>Robust Image Watermarking in the Wavelet Domain for Copyright Protection</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to ICEE 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new approach to image watermarking in wavelet domain is
presented. The idea is to hide the watermark data in blocks of the block
segmented image. Two schemes are presented based on this idea by embedding the
watermark data in the low pass wavelet coefficients of each block. Due to low
computational complexity of the proposed approach, this algorithm can be
implemented in real time. Experimental results demonstrate the
impercepti-bility of the proposed method and its high robustness against
various attacks such as filtering, JPEG compres-sion, cropping, noise addition
and geometric distortions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0304</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0304</id><created>2010-01-02</created><authors><author><keyname>Shao</keyname><forenames>Junwei</forenames></author><author><keyname>Hou</keyname><forenames>Xiaorong</forenames></author></authors><title>A Complete Method for Checking Hurwitz Stability of a Polytope of
  Matrices</title><categories>cs.SC</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method for checking the Hurwitz stability of a polytope of
matrices. First we prove that the polytope matrix is stable if and only if two
homogenous polynomials are positive on a simplex, then through a newly proposed
method, i.e., the weighted difference substitution method, the latter can be
checked in finite steps. Examples show the efficiency of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0317</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0317</id><created>2010-01-02</created><updated>2010-02-03</updated><authors><author><keyname>Formato</keyname><forenames>Richard A.</forenames></author></authors><title>Pseudorandomness in Central Force Optimization</title><categories>cs.OH</categories><comments>Includes Source Code and Corrections 02-03-2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Central Force Optimization is a deterministic metaheuristic for an
evolutionary algorithm that searches a decision space by flying probes whose
trajectories are computed using a gravitational metaphor. CFO benefits
substantially from the inclusion of a pseudorandom component (a numerical
sequence that is precisely known by specification or calculation but otherwise
arbitrary). The essential requirement is that the sequence is uncorrelated with
the decision space topology, so that its effect is to pseudorandomly distribute
probes throughout the landscape. While this process may appear to be similar to
the randomness in an inherently stochastic algorithm, it is in fact
fundamentally different because CFO remains deterministic at every step. Three
pseudorandom methods are discussed (initial probe distribution, repositioning
factor, and decision space adaptation). A sample problem is presented in detail
and summary data included for a 23-function benchmark suite. CFO's performance
is quite good compared to other highly developed, state-of-the-art algorithms.
Includes corrections 02-03-2010.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0338</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0338</id><created>2010-01-02</created><updated>2011-01-27</updated><authors><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Bala</forenames></author></authors><title>Optimal Homologous Cycles, Total Unimodularity, and Linear Programming</title><categories>math.AT cs.CG cs.DS math.OC</categories><comments>Earlier version of this paper appeared in the 42nd ACM Symposium on
  Theory of Computing (STOC 2010). In this version we complete the
  characterization in terms of Moebius complexes. Added more information to the
  experimental results section. Fixed typos</comments><msc-class>55U10, 55N99, 90C10, 90C05, 68U05</msc-class><acm-class>F.2.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a simplicial complex with weights on its simplices, and a nontrivial
cycle on it, we are interested in finding the cycle with minimal weight which
is homologous to the given one. Assuming that the homology is defined with
integer coefficients, we show the following : For a finite simplicial complex
$K$ of dimension greater than $p$, the boundary matrix $[\partial_{p+1}]$ is
totally unimodular if and only if $H_p(L, L_0)$ is torsion-free, for all pure
subcomplexes $L_0, L$ in $K$ of dimensions $p$ and $p+1$ respectively, where
$L_0$ is a subset of $L$. Because of the total unimodularity of the boundary
matrix, we can solve the optimization problem, which is inherently an integer
programming problem, as a linear program and obtain integer solution. Thus the
problem of finding optimal cycles in a given homology class can be solved in
polynomial time. This result is surprising in the backdrop of a recent result
which says that the problem is NP-hard under $\mathbb{Z}_2$ coefficients which,
being a field, is in general easier to deal with. One consequence of our
result, among others, is that one can compute in polynomial time an optimal
2-cycle in a given homology class for any finite simplicial complex embedded in
$\mathbb{R}^3$. Our optimization approach can also be used for various related
problems, such as finding an optimal chain homologous to a given one when these
are not cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0339</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0339</id><created>2010-01-02</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author></authors><title>Tight oracle bounds for low-rank matrix recovery from a minimal number
  of random measurements</title><categories>cs.IT math.IT</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents several novel theoretical results regarding the recovery
of a low-rank matrix from just a few measurements consisting of linear
combinations of the matrix entries. We show that properly constrained
nuclear-norm minimization stably recovers a low-rank matrix from a constant
number of noisy measurements per degree of freedom; this seems to be the first
result of this nature. Further, the recovery error from noisy data is within a
constant of three targets: 1) the minimax risk, 2) an oracle error that would
be available if the column space of the matrix were known, and 3) a more
adaptive oracle error which would be available with the knowledge of the column
space corresponding to the part of the matrix that stands above the noise.
Lastly, the error bounds regarding low-rank matrices are extended to provide an
error bound when the matrix has full rank with decaying singular values. The
analysis in this paper is based on the restricted isometry property (RIP)
introduced in [6] for vectors, and in [22] for matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0340</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0340</id><created>2010-01-04</created><updated>2010-03-16</updated><authors><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Luttenberger</keyname><forenames>Michael</forenames></author></authors><title>Computing the Least Fixed Point of Positive Polynomial Systems</title><categories>cs.NA cs.DS</categories><comments>This is a technical report that goes along with an article to appear
  in SIAM Journal on Computing.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider equation systems of the form X_1 = f_1(X_1, ..., X_n), ..., X_n =
f_n(X_1, ..., X_n) where f_1, ..., f_n are polynomials with positive real
coefficients. In vector form we denote such an equation system by X = f(X) and
call f a system of positive polynomials, short SPP. Equation systems of this
kind appear naturally in the analysis of stochastic models like stochastic
context-free grammars (with numerous applications to natural language
processing and computational biology), probabilistic programs with procedures,
web-surfing models with back buttons, and branching processes. The least
nonnegative solution mu f of an SPP equation X = f(X) is of central interest
for these models. Etessami and Yannakakis have suggested a particular version
of Newton's method to approximate mu f.
  We extend a result of Etessami and Yannakakis and show that Newton's method
starting at 0 always converges to mu f. We obtain lower bounds on the
convergence speed of the method. For so-called strongly connected SPPs we prove
the existence of a threshold k_f such that for every i &gt;= 0 the (k_f+i)-th
iteration of Newton's method has at least i valid bits of mu f. The proof
yields an explicit bound for k_f depending only on syntactic parameters of f.
We further show that for arbitrary SPP equations Newton's method still
converges linearly: there are k_f&gt;=0 and alpha_f&gt;0 such that for every i&gt;=0 the
(k_f+alpha_f i)-th iteration of Newton's method has at least i valid bits of mu
f. The proof yields an explicit bound for alpha_f; the bound is exponential in
the number of equations, but we also show that it is essentially optimal.
Constructing a bound for k_f is still an open problem. Finally, we also provide
a geometric interpretation of Newton's method for SPPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0346</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0346</id><created>2010-01-02</created><authors><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Lau</keyname><forenames>Vincent</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>Protocol design and stability/delay analysis of half-duplex buffered
  cognitive relay systems</title><categories>cs.IT math.IT</categories><comments>6 pages, double column, 6 figures, TWC letter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we quantify the benefits of employing relay station in
large-coverage cognitive radio systems which opportunistically access the
licensed spectrum of some small-coverage primary systems scattered inside.
Through analytical study, we show that even a simple decode-and-forward (SDF)
relay, which can hold only one packet, offers significant path-loss gain in
terms of the spatial transmission opportunities and link reliability. However,
such scheme fails to capture the spatial-temporal burstiness of the primary
activities, that is, when either the source-relay (SR) link or
relay-destination (RD) link is blocked by the primary activities, the cognitive
spectrum access has to stop. To overcome this obstacle, we further propose
buffered decode-and-forward (BDF) protocol. By exploiting the infinitely long
buffer at the relay, the blockage time on either SR or RD link is saved for
cognitive spectrum access. The buffer gain is shown analytically to improve the
stability region and average end-to-end delay performance of the cognitive
relay system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0357</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0357</id><created>2010-01-03</created><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Orthogonal vs Non-Orthogonal Multiple Access with Finite Input Alphabet
  and Finite Bandwidth</title><categories>cs.IT math.IT</categories><comments>7 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a two-user Gaussian multiple access channel (GMAC), frequency division
multiple access (FDMA), a well known orthogonal-multiple-access (O-MA) scheme
has been preferred to non-orthogonal-multiple-access (NO-MA) schemes since FDMA
can achieve the sum-capacity of the channel with only single-user decoding
complexity [\emph{Chapter 14, Elements of Information Theory by Cover and
Thomas}]. However, with finite alphabets, in this paper, we show that NO-MA is
better than O-MA for a two-user GMAC. We plot the constellation constrained
(CC) capacity regions of a two-user GMAC with FDMA and time division multiple
access (TDMA) and compare them with the CC capacity regions with trellis coded
multiple access (TCMA), a recently introduced NO-MA scheme. Unlike the Gaussian
alphabets case, it is shown that the CC capacity region with FDMA is strictly
contained inside the CC capacity region with TCMA. In particular, for a given
bandwidth, the gap between the CC capacity regions with TCMA and FDMA is shown
to increase with the increase in the average power constraint. Also, for a
given power constraint, the gap between the CC capacity regions with TCMA and
FDMA is shown to decrease with the increase in the bandwidth. Hence, for finite
alphabets, a NO-MA scheme such as TCMA is better than the well known O-MAC
schemes, FDMA and TDMA which makes NO-MA schemes worth pursuing in practice for
a two-user GMAC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0358</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0358</id><created>2010-01-03</created><authors><author><keyname>Cagliari</keyname><forenames>Francesca</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Finiteness of rank invariants of multidimensional persistent homology
  groups</title><categories>math.AT cs.IT math.IT</categories><msc-class>55N99; 68T10; 54C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rank invariants are a parametrized version of Betti numbers of a space
multi-filtered by a continuous vector-valued function. In this note we give a
sufficient condition for their finiteness. This condition is sharp for spaces
embeddable in R^n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0361</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0361</id><created>2010-01-03</created><updated>2010-01-09</updated><authors><author><keyname>Gargouri</keyname><forenames>Yassine</forenames></author><author><keyname>Hajjem</keyname><forenames>Chawki</forenames></author><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author><author><keyname>Carr</keyname><forenames>Les</forenames></author><author><keyname>Brody</keyname><forenames>Tim</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Self-Selected or Mandated, Open Access Increases Citation Impact for
  Higher Quality Research</title><categories>cs.CY cs.DL</categories><comments>30 pages, 15 figures, 8 tables</comments><doi>10.1371/journal.pone.0013636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Articles whose authors make them Open Access (OA) by self-archiving them
online are cited significantly more than articles accessible only to
subscribers. Some have suggested that this &quot;OA Advantage&quot; may not be causal but
just a self-selection bias, because authors preferentially make higher-quality
articles OA. To test this we compared self-selective self-archiving with
mandatory self-archiving for a sample of 27,197 articles published 2002-2006 in
1,984 journals. The OA Advantage proved just as high for both. Logistic
regression showed that the advantage is independent of other correlates of
citations (article age; journal impact factor; number of co-authors, references
or pages; field; article type; or country) and greatest for the most highly
cited articles. The OA Advantage is real, independent and causal, but skewed.
Its size is indeed correlated with quality, just as citations themselves are
(the top 20% of articles receive about 80% of all citations). The advantage is
greater for the more citeable articles, not because of a quality bias from
authors self-selecting what to make OA, but because of a quality advantage,
from users self-selecting what to use and cite, freed by OA from the
constraints of selective accessibility to subscribers only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0383</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0383</id><created>2010-01-03</created><updated>2010-02-03</updated><authors><author><keyname>Das</keyname><forenames>Bireswar</forenames></author><author><keyname>Toran</keyname><forenames>Jacobo</forenames></author><author><keyname>Wagner</keyname><forenames>Fabian</forenames></author></authors><title>Restricted Space Algorithms for Isomorphism on Bounded Treewidth Graphs</title><categories>cs.CC</categories><comments>STACS conference 2010, 12 pages</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Graph Isomorphism problem restricted to graphs of bounded treewidth or
bounded tree distance width are known to be solvable in polynomial time
[Bod90],[YBFT99]. We give restricted space algorithms for these problems
proving the following results: - Isomorphism for bounded tree distance width
graphs is in L and thus complete for the class. We also show that for this kind
of graphs a canon can be computed within logspace. - For bounded treewidth
graphs, when both input graphs are given together with a tree decomposition,
the problem of whether there is an isomorphism which respects the
decompositions (i.e. considering only isomorphisms mapping bags in one
decomposition blockwise onto bags in the other decomposition) is in L. - For
bounded treewidth graphs, when one of the input graphs is given with a tree
decomposition the isomorphism problem is in LogCFL. - As a corollary the
isomorphism problem for bounded treewidth graphs is in LogCFL. This improves
the known TC1 upper bound for the problem given by Grohe and Verbitsky
[GroVer06].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0393</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0393</id><created>2010-01-03</created><updated>2010-07-30</updated><authors><author><keyname>Chakraborty</keyname><forenames>Sourav</forenames></author><author><keyname>Devanur</keyname><forenames>Nikhil</forenames></author><author><keyname>Karande</keyname><forenames>Chinmay</forenames></author></authors><title>Market Equilibrium with Transaction Costs</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identical products being sold at different prices in different locations is a
common phenomenon. Price differences might occur due to various reasons such as
shipping costs, trade restrictions and price discrimination. To model such
scenarios, we supplement the classical Fisher model of a market by introducing
{\em transaction costs}. For every buyer $i$ and every good $j$, there is a
transaction cost of $\cij$; if the price of good $j$ is $p_j$, then the cost to
the buyer $i$ {\em per unit} of $j$ is $p_j + \cij$. This allows the same good
to be sold at different (effective) prices to different buyers.
  We provide a combinatorial algorithm that computes $\epsilon$-approximate
equilibrium prices and allocations in
$O\left(\frac{1}{\epsilon}(n+\log{m})mn\log(B/\epsilon)\right)$ operations -
where $m$ is the number goods, $n$ is the number of buyers and $B$ is the sum
of the budgets of all the buyers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0405</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0405</id><created>2010-01-03</created><authors><author><keyname>Bshouty</keyname><forenames>Nader H.</forenames></author><author><keyname>Mazzawi</keyname><forenames>Hanna</forenames></author></authors><title>Optimal Query Complexity for Reconstructing Hypergraphs</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of reconstructing a hidden weighted
hypergraph of constant rank using additive queries. We prove the following: Let
$G$ be a weighted hidden hypergraph of constant rank with n vertices and $m$
hyperedges. For any $m$ there exists a non-adaptive algorithm that finds the
edges of the graph and their weights using $$ O(\frac{m\log n}{\log m}) $$
additive queries. This solves the open problem in [S. Choi, J. H. Kim. Optimal
Query Complexity Bounds for Finding Graphs. {\em STOC}, 749--758,~2008].
  When the weights of the hypergraph are integers that are less than
$O(poly(n^d/m))$ where $d$ is the rank of the hypergraph (and therefore for
unweighted hypergraphs) there exists a non-adaptive algorithm that finds the
edges of the graph and their weights using $$ O(\frac{m\log \frac{n^d}{m}}{\log
m}). $$ additive queries.
  Using the information theoretic bound the above query complexities are tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0415</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0415</id><created>2010-01-03</created><updated>2010-01-08</updated><authors><author><keyname>Chermakani</keyname><forenames>Deepak Ponvel</forenames></author></authors><title>A new Rational Generating Function for the Frobenius Coin Problem</title><categories>cs.DM</categories><comments>2 pages, 1 Theorem, I have now enhanced the explanation for Theorem-1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important question arising from the Frobenius Coin Problem is to decide
whether or not a given monetary sum S can be obtained from N coin
denominations. We develop a new Generating Function G(x), where the coefficient
of x^i is equal to the number of ways in which coins from the given
denominations can be arranged as a stack whose total monetary worth is i. We
show that the Recurrence Relation for obtaining G(x), is linear, enabling G(x)
to be expressed as a rational function, that is, G(x) = P(x)/Q(x), where both
P(x) and Q(x) are Polynomials whose degrees are bounded by the largest coin
denomination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0418</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0418</id><created>2010-01-03</created><authors><author><keyname>Anacleto</keyname><forenames>Junia Coutinho</forenames></author><author><keyname>de Carvalho</keyname><forenames>Aparecido Fabiano Pinatti</forenames></author></authors><title>Improving Human-Computer Interaction by Developing Culture-sensitive
  Applications based on Common Sense Knowledge</title><categories>cs.HC</categories><comments>Book: Human-Computer Interaction, New Developments The whole book can
  be downloaded from http://www.sciyo.com</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The advent of Web 3.0, claiming for personalization in interactive systems
(Lassila &amp; Hendler, 2007), and the need for systems capable of interacting in a
more natural way in the future society flooded with computer systems and
devices (Harper et al., 2008) show that great advances in HCI should be done.
This chapter presents some contributions of LIA for the future of HCI,
defending that using common sense knowledge is a possibility for improving HCI,
especially because people assign meaning to their messages based on their
common sense and, therefore, the use of this knowledge in developing user
interfaces can make them more intuitive to the end-user. Moreover, as common
sense knowledge varies from group to group of people, it can be used for
developing applications capable of giving different feedback for different
target groups, as the applications presented along this chapter illustrate,
allowing, in this way, interface personalization taking into account cultural
issues. For the purpose of using common sense knowledge in the development and
design of computer systems, it is necessary to provide an architecture that
allows it. This chapter presents LIAs approaches for common sense knowledge
acquisition, representation and use, as well as for natural language
processing, contributing with those ones who intent to get into this
challenging world to get started.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0420</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0420</id><created>2010-01-03</created><authors><author><keyname>Asai</keyname><forenames>Kikuo</forenames></author></authors><title>The Role of Head-Up Display in Computer- Assisted Instruction</title><categories>cs.HC</categories><comments>www.sciyo.com</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We investigated the role of HUDs in CAI. HUDs have been used in various
situations in daily lives by recent downsizing and cost down of the display
devices. CAI is one of the promising applications for HUDs. We have developed
an HUD-based CAI system for effectively presenting instructions of the
equipment in the transportable earth station. This chapter described HUDs in
CAI from a viewpoint of human-computer interaction based on the development
experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0421</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0421</id><created>2010-01-03</created><authors><author><keyname>Tordable</keyname><forenames>Javier</forenames></author></authors><title>MapReduce for Integer Factorization</title><categories>cs.DC</categories><comments>6 pages, 3 tables</comments><acm-class>D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integer factorization is a very hard computational problem. Currently no
efficient algorithm for integer factorization is publicly known. However, this
is an important problem on which it relies the security of many real world
cryptographic systems.
  I present an implementation of a fast factorization algorithm on MapReduce.
MapReduce is a programming model for high performance applications developed
originally at Google. The quadratic sieve algorithm is split into the different
MapReduce phases and compared against a standard implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0436</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0436</id><created>2010-01-03</created><updated>2011-04-16</updated><authors><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author><author><keyname>Ghosh</keyname><forenames>Arpita</forenames></author></authors><title>Truthful Assignment without Money</title><categories>cs.GT</categories><comments>Extended abstract appears in the 11th ACM Conference on Electronic
  Commerce (EC), 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of truthful mechanisms that do not use payments for the
generalized assignment problem (GAP) and its variants. An instance of the GAP
consists of a bipartite graph with jobs on one side and machines on the other.
Machines have capacities and edges have values and sizes; the goal is to
construct a welfare maximizing feasible assignment. In our model of private
valuations, motivated by impossibility results, the value and sizes on all
job-machine pairs are public information; however, whether an edge exists or
not in the bipartite graph is a job's private information.
  We study several variants of the GAP starting with matching. For the
unweighted version, we give an optimal strategyproof mechanism; for maximum
weight bipartite matching, however, we show give a 2-approximate strategyproof
mechanism and show by a matching lowerbound that this is optimal. Next we study
knapsack-like problems, which are APX-hard. For these problems, we develop a
general LP-based technique that extends the ideas of Lavi and Swamy to reduce
designing a truthful mechanism without money to designing such a mechanism for
the fractional version of the problem, at a loss of a factor equal to the
integrality gap in the approximation ratio. We use this technique to obtain
strategyproof mechanisms with constant approximation ratios for these problems.
We then design an O(log n)-approximate strategyproof mechanism for the GAP by
reducing, with logarithmic loss in the approximation, to our solution for the
value-invariant GAP. Our technique may be of independent interest for designing
truthful mechanisms without money for other LP-based problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0440</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0440</id><created>2010-01-04</created><authors><author><keyname>Kannan</keyname><forenames>Rajkumar</forenames></author><author><keyname>Andres</keyname><forenames>Frederic</forenames></author><author><keyname>Ramadoss</keyname><forenames>Balakrishnan</forenames></author></authors><title>Tutoring System for Dance Learning</title><categories>cs.IR cs.MM</categories><comments>IEEE International Advance Computing Conference 2009, Patiala, India</comments><acm-class>H.3.1; H.5.4; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in hardware sophistication related to graphics display, audio
and video devices made available a large number of multimedia and hypermedia
applications. These multimedia applications need to store and retrieve the
different forms of media like text, hypertext, graphics, still images,
animations, audio and video. Dance is one of the important cultural forms of a
nation and dance video is one such multimedia types. Archiving and retrieving
the required semantics from these dance media collections is a crucial and
demanding multimedia application. This paper summarizes the difference dance
video archival techniques and systems. Keywords: Multimedia, Culture Media,
Metadata archival and retrieval systems, MPEG-7, XML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0441</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0441</id><created>2010-01-04</created><authors><author><keyname>Kannan</keyname><forenames>Rajkumar</forenames></author><author><keyname>Ramadoss</keyname><forenames>Balakrishnan</forenames></author></authors><title>Semantic Modeling and Retrieval of Dance Video Annotations</title><categories>cs.MM cs.LO</categories><comments>INFOCOMP Journal of Computer Science, Brazil</comments><acm-class>H.3.1; H.5.4; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dance video is one of the important types of narrative videos with semantic
rich content. This paper proposes a new meta model, Dance Video Content Model
(DVCM) to represent the expressive semantics of the dance videos at multiple
granularity levels. The DVCM is designed based on the concepts such as video,
shot, segment, event and object, which are the components of MPEG-7 MDS. This
paper introduces a new relationship type called Temporal Semantic Relationship
to infer the semantic relationships between the dance video objects. Inverted
file based index is created to reduce the search time of the dance queries. The
effectiveness of containment queries using precision and recall is depicted.
Keywords: Dance Video Annotations, Effectiveness Metrics, Metamodeling,
Temporal Semantic Relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0442</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0442</id><created>2010-01-04</created><authors><author><keyname>Kannan</keyname><forenames>Rajkumar</forenames></author><author><keyname>Ramadoss</keyname><forenames>Balakrishnan</forenames></author></authors><title>Modeling and Annotating the Expressive Semantics of Dance Videos</title><categories>cs.MM</categories><comments>International Journal of Information Technologies and Knowledge</comments><acm-class>J.5; H.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dance videos are interesting and semantics-intensive. At the same time, they
are the complex type of videos compared to all other types such as sports, news
and movie videos. In fact, dance video is the one which is less explored by the
researchers across the globe. Dance videos exhibit rich semantics such as macro
features and micro features and can be classified into several types. Hence,
the conceptual modeling of the expressive semantics of the dance videos is very
crucial and complex. This paper presents a generic Dance Video Semantics Model
(DVSM) in order to represent the semantics of the dance videos at different
granularity levels, identified by the components of the accompanying song. This
model incorporates both syntactic and semantic features of the videos and
introduces a new entity type called, Agent, to specify the micro features of
the dance videos. The instantiations of the model are expressed as graphs. The
model is implemented as a tool using J2SE and JMF to annotate the macro and
micro features of the dance videos. Finally examples and evaluation results are
provided to depict the effectiveness of the proposed dance video model.
Keywords: Agents, Dance videos, Macro features, Micro features, Video
annotation, Video semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0443</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0443</id><created>2010-01-04</created><authors><author><keyname>Kannan</keyname><forenames>Rajkumar</forenames></author><author><keyname>Guetl</keyname><forenames>Christian</forenames></author></authors><title>Discovering Knowledge from Multi-modal Lecture Recordings</title><categories>cs.MM</categories><comments>First International Conference on Data Engineering and Management
  2008, India</comments><acm-class>H.3.1; H.5.4; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Educational media mining is the process of converting raw media data from
educational systems to useful information that can be used to design learning
systems, answer research questions and allow personalized learning experiences.
Knowledge discovery encompasses a wide range of techniques ranging from
database queries to more recent developments in machine learning and language
technology. Educational media mining techniques are now being used in IT
Services research worldwide. Multi-modal Lecture Recordings is one of the
important types of educational media and this paper explores the research
challenges for mining lecture recordings for the efficient personalized
learning experiences. Keywords: Educational Media Mining; Lecture Recordings,
Multimodal Information System, Personalized Learning; Online Course Ware;
Skills and Competences;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0453</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0453</id><created>2010-01-04</created><authors><author><keyname>Thomas</keyname><forenames>Andr&#xe9;</forenames><affiliation>CRAN</affiliation></author></authors><title>RFID et nouvelles technologies de communication; enjeux \'economiques
  incontournables et probl\`emes d'\'ethique RFID and new communication
  technologies - economic challenges and ethic problems</title><categories>cs.CY</categories><comments>Keynote paper</comments><proxy>ccsd hal-00442873</proxy><journal-ref>CPI09, FES : Maroc (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Auto ID technologies such RFID are more and more commonly used in industry
and in distribution. Human are identify thanks to this technology, too. A lot
of people have highlighted ethic problems relative to their utilization. This
paper present first RFID technology, then it presents their opportunities in
business and industry. In a second part, the paper highlights some ethic
problems leading to a necessary standardization and regulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0464</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0464</id><created>2010-01-04</created><updated>2011-08-08</updated><authors><author><keyname>Kowalczyk</keyname><forenames>Michael</forenames></author><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author></authors><title>Holant Problems for Regular Graphs with Complex Edge Functions</title><categories>cs.CC</categories><comments>19 pages, 4 figures, added proofs for full version</comments><acm-class>F.2.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We prove a complexity dichotomy theorem for Holant Problems on 3-regular
graphs with an arbitrary complex-valued edge function. Three new techniques are
introduced: (1) higher dimensional iterations in interpolation; (2) Eigenvalue
Shifted Pairs, which allow us to prove that a pair of combinatorial gadgets in
combination succeed in proving #P-hardness; and (3) algebraic symmetrization,
which significantly lowers the symbolic complexity of the proof for
computational complexity. With holographic reductions the classification
theorem also applies to problems beyond the basic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0529</identifier>
 <datestamp>2015-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0529</id><created>2010-01-04</created><updated>2010-02-03</updated><authors><author><keyname>Brandt</keyname><forenames>Felix</forenames></author><author><keyname>Fischer</keyname><forenames>Felix</forenames></author><author><keyname>Holzer</keyname><forenames>Markus</forenames></author></authors><title>On Iterated Dominance, Matrix Elimination, and Matched Paths</title><categories>cs.GT cs.CC</categories><comments>12 pages, 3 figures, 27th International Symposium on Theoretical
  Aspects of Computer Science (STACS)</comments><acm-class>F.2.2; J.4</acm-class><doi>10.4230/LIPIcs.STACS.2010.2448</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study computational problems arising from the iterated removal of weakly
dominated actions in anonymous games. Our main result shows that it is
NP-complete to decide whether an anonymous game with three actions can be
solved via iterated weak dominance. The two-action case can be reformulated as
a natural elimination problem on a matrix, the complexity of which turns out to
be surprisingly difficult to characterize and ultimately remains open. We
however establish connections to a matching problem along paths in a directed
graph, which is computationally hard in general but can also be used to
identify tractable cases of matrix elimination. We finally identify different
classes of anonymous games where iterated dominance is in P and NP-complete,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0555</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0555</id><created>2010-01-04</created><authors><author><keyname>Angelini</keyname><forenames>Patrizio</forenames></author><author><keyname>Geyer</keyname><forenames>Markus</forenames></author><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>Neuwirth</keyname><forenames>Daniel</forenames></author></authors><title>On a Tree and a Path with no Geometric Simultaneous Embedding</title><categories>cs.CG</categories><comments>42 pages, 33 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two graphs $G_1=(V,E_1)$ and $G_2=(V,E_2)$ admit a geometric simultaneous
embedding if there exists a set of points P and a bijection M: P -&gt; V that
induce planar straight-line embeddings both for $G_1$ and for $G_2$. While it
is known that two caterpillars always admit a geometric simultaneous embedding
and that two trees not always admit one, the question about a tree and a path
is still open and is often regarded as the most prominent open problem in this
area. We answer this question in the negative by providing a counterexample.
Additionally, since the counterexample uses disjoint edge sets for the two
graphs, we also negatively answer another open question, that is, whether it is
possible to simultaneously embed two edge-disjoint trees. As a final result, we
study the same problem when some constraints on the tree are imposed. Namely,
we show that a tree of depth 2 and a path always admit a geometric simultaneous
embedding. In fact, such a strong constraint is not so far from closing the gap
with the instances not admitting any solution, as the tree used in our
counterexample has depth 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0591</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0591</id><created>2010-01-04</created><updated>2011-03-13</updated><authors><author><keyname>Joshi</keyname><forenames>Sarang</forenames></author><author><keyname>Kommaraju</keyname><forenames>Raj Varma</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Comparing Distributions and Shapes using the Kernel Distance</title><categories>cs.CG cs.CV cs.LG</categories><comments>20 pages. In Proceedings 27th Symposium on Computational Geometry,
  2011. See also (http://arxiv.org/abs/1103.1625) for more background on the
  kernel distance</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting with a similarity function between objects, it is possible to define
a distance metric on pairs of objects, and more generally on probability
distributions over them. These distance metrics have a deep basis in functional
analysis, measure theory and geometric measure theory, and have a rich
structure that includes an isometric embedding into a (possibly infinite
dimensional) Hilbert space. They have recently been applied to numerous
problems in machine learning and shape analysis.
  In this paper, we provide the first algorithmic analysis of these distance
metrics. Our main contributions are as follows: (i) We present fast
approximation algorithms for computing the kernel distance between two point
sets P and Q that runs in near-linear time in the size of (P cup Q) (note that
an explicit calculation would take quadratic time). (ii) We present
polynomial-time algorithms for approximately minimizing the kernel distance
under rigid transformation; they run in time O(n + poly(1/epsilon, log n)).
(iii) We provide several general techniques for reducing complex objects to
convenient sparse representations (specifically to point sets or sets of points
sets) which approximately preserve the kernel distance. In particular, this
allows us to reduce problems of computing the kernel distance between various
types of objects such as curves, surfaces, and distributions to computing the
kernel distance between point sets. These take advantage of the reproducing
kernel Hilbert space and a new relation linking binary range spaces to
continuous range spaces with bounded fat-shattering dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0592</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0592</id><created>2010-01-05</created><updated>2010-03-30</updated><authors><author><keyname>Byers</keyname><forenames>John W.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Zervas</keyname><forenames>Georgios</forenames></author></authors><title>Information Asymmetries in Pay-Per-Bid Auctions: How Swoopo Makes Bank</title><categories>cs.GT</categories><comments>48 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Innovative auction methods can be exploited to increase profits, with
Shubik's famous &quot;dollar auction&quot; perhaps being the most widely known example.
Recently, some mainstream e-commerce web sites have apparently achieved the
same end on a much broader scale, by using &quot;pay-per-bid&quot; auctions to sell
items, from video games to bars of gold. In these auctions, bidders incur a
cost for placing each bid in addition to (or sometimes in lieu of) the winner's
final purchase cost. Thus even when a winner's purchase cost is a small
fraction of the item's intrinsic value, the auctioneer can still profit
handsomely from the bid fees. Our work provides novel analyses for these
auctions, based on both modeling and datasets derived from auctions at
Swoopo.com, the leading pay-per-bid auction site. While previous modeling work
predicts profit-free equilibria, we analyze the impact of information asymmetry
broadly, as well as Swoopo features such as bidpacks and the Swoop It Now
option specifically, to quantify the effects of imperfect information in these
auctions. We find that even small asymmetries across players (cheaper bids,
better estimates of other players' intent, different valuations of items,
committed players willing to play &quot;chicken&quot;) can increase the auction duration
well beyond that predicted by previous work and thus skew the auctioneer's
profit disproportionately. Finally, we discuss our findings in the context of a
dataset of thousands of live auctions we observed on Swoopo, which enables us
also to examine behavioral factors, such as the power of aggressive bidding.
Ultimately, our findings show that even with fully rational players, if players
overlook or are unaware any of these factors, the result is outsized profits
for pay-per-bid auctioneers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0595</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0595</id><created>2010-01-04</created><updated>2011-09-27</updated><authors><author><keyname>Shapiro</keyname><forenames>Michael</forenames></author><author><keyname>Delgado-Eckert</keyname><forenames>Edgar</forenames></author></authors><title>Finding an individual's probability of infection in an SIR network is
  NP-hard</title><categories>q-bio.PE cs.CC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The celebrated Kermack-McKendric model of epidemics studies the transmission
of a disease in a population where each individual is initially susceptible
(S), may become infective (I) and then removed or recovered (R) and plays no
further epidemiological role. This ODE model arises as the limiting case of a
network model where each individual has an equal chance of infecting every
other. More recent work gives explicit consideration to the network of social
interaction and attendant probability of transmission for each interacting
pair. The state of such a network is an assignment of the values {S,I,R} to its
members. Given such a network, an initial state and a particular susceptible
individual, we would like to compute their probability of becoming infected in
the course of an epidemic. It turns out that this problem is NP-hard. In
particular, it belongs in a class of problems all of whose known solutions
require an exponential amount of computation and for which it is unlikely that
there will be more efficient solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0597</identifier>
 <datestamp>2012-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0597</id><created>2010-01-04</created><updated>2011-01-21</updated><authors><author><keyname>Nguyen</keyname><forenames>XuanLong</forenames></author></authors><title>Inference of global clusters from locally distributed data</title><categories>stat.ME cs.LG stat.ML</categories><comments>27 pages, 12 figures</comments><report-no>Technical report 504, Department of Statistics, University of
  Michigan</report-no><journal-ref>Published in Bayesian Analysis, 5(4), 817--846, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of analyzing the heterogeneity of clustering
distributions for multiple groups of observed data, each of which is indexed by
a covariate value, and inferring global clusters arising from observations
aggregated over the covariate domain. We propose a novel Bayesian nonparametric
method reposing on the formalism of spatial modeling and a nested hierarchy of
Dirichlet processes. We provide an analysis of the model properties, relating
and contrasting the notions of local and global clusters. We also provide an
efficient inference algorithm, and demonstrate the utility of our method in
several data examples, including the problem of object tracking and a global
clustering analysis of functional data where the functional identity
information is not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0608</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0608</id><created>2010-01-05</created><authors><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author></authors><title>An Efficient Quantum Algorithm for some Instances of the Group
  Isomorphism Problem</title><categories>quant-ph cs.DS math.GR</categories><comments>20 pages; this is the full version of a paper that will appear in the
  Proceedings of the 27th International Symposium on Theoretical Aspects of
  Computer Science (STACS 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of testing whether two finite groups
are isomorphic. Whereas the case where both groups are abelian is well
understood and can be solved efficiently, very little is known about the
complexity of isomorphism testing for nonabelian groups. Le Gall has
constructed an efficient classical algorithm for a class of groups
corresponding to one of the most natural ways of constructing nonabelian groups
from abelian groups: the groups that are extensions of an abelian group $A$ by
a cyclic group $Z_m$ with the order of $A$ coprime with $m$. More precisely,
the running time of that algorithm is almost linear in the order of the input
groups. In this paper we present a quantum algorithm solving the same problem
in time polynomial in the logarithm of the order of the input groups. This
algorithm works in the black-box setting and is the first quantum algorithm
solving instances of the nonabelian group isomorphism problem exponentially
faster than the best known classical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0627</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0627</id><created>2010-01-05</created><authors><author><keyname>Horton</keyname><forenames>John</forenames></author><author><keyname>Chilton</keyname><forenames>Lydia</forenames></author></authors><title>The Labor Economics of Paid Crowdsourcing</title><categories>cs.HC cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing is a form of &quot;peer production&quot; in which work traditionally
performed by an employee is outsourced to an &quot;undefined, generally large group
of people in the form of an open call.&quot; We present a model of workers supplying
labor to paid crowdsourcing projects. We also introduce a novel method for
estimating a worker's reservation wage--the smallest wage a worker is willing
to accept for a task and the key parameter in our labor supply model. It shows
that the reservation wages of a sample of workers from Amazon's Mechanical Turk
(AMT) are approximately log normally distributed, with a median wage of
$1.38/hour. At the median wage, the point elasticity of extensive labor supply
is 0.43. We discuss how to use our calibrated model to make predictions in
applied work. Two experimental tests of the model show that many workers
respond rationally to offered incentives. However, a non-trivial fraction of
subjects appear to set earnings targets. These &quot;target earners&quot; consider not
just the offered wage--which is what the rational model predicts--but also
their proximity to earnings goals. Interestingly, a number of workers clearly
prefer earning total amounts evenly divisible by 5, presumably because these
amounts make good targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0639</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0639</id><created>2010-01-05</created><authors><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Ilcinkas</keyname><forenames>David</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Labourel</keyname><forenames>Arnaud</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Pelc</keyname><forenames>Andrzej</forenames></author></authors><title>Optimal Exploration of Terrains with Obstacles</title><categories>cs.DS</categories><proxy>ccsd hal-00442209</proxy><doi>10.1007/978-3-642-13731-0_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile robot represented by a point moving in the plane has to explore an
unknown terrain with obstacles. Both the terrain and the obstacles are modeled
as arbitrary polygons. We consider two scenarios: the unlimited vision, when
the robot situated at a point p of the terrain explores (sees) all points q of
the terrain for which the segment pq belongs to the terrain, and the limited
vision, when we require additionally that the distance between p and q be at
most 1. All points of the terrain (except obstacles) have to be explored and
the performance of an exploration algorithm is measured by the length of the
trajectory of the robot. For unlimited vision we show an exploration algorithm
with complexity O(P + D?k), where P is the total perimeter of the terrain
(including perimeters of obstacles), D is the diameter of the convex hull of
the terrain, and k is the number of obstacles. We do not assume knowledge of
these parameters. We also prove a matching lower bound showing that the above
complexity is optimal, even if the terrain is known to the robot. For limited
vision we show exploration algorithms with complexity O(P + A + ?Ak), where A
is the area of the terrain (excluding obstacles). Our algorithms work either
for arbitrary terrains, if one of the parameters A or k is known, or for c-fat
terrains, where c is any constant (unknown to the robot) and no additional
knowledge is assumed. (A terrain T with obstacles is c-fat if R/r ? c, where R
is the radius of the smallest disc containing T and r is the radius of the
largest disc contained in T .) We also prove a matching lower bound ?(P + A +
?Ak) on the complexity of exploration for limited vision, even if the terrain
is known to the robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0641</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0641</id><created>2010-01-05</created><authors><author><keyname>Clairambault</keyname><forenames>Pierre</forenames><affiliation>PPS</affiliation></author></authors><title>Least and greatest fixpoints in game semantics</title><categories>cs.LO cs.GT cs.PL</categories><proxy>ccsd hal-00443537</proxy><journal-ref>Foundations of Software Science and Computational Structures, York
  : United Kingdom (2009)</journal-ref><doi>10.1007/978-3-642-00596-1_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how solutions to many recursive arena equations can be computed in a
natural way by allowing loops in arenas. We then equip arenas with winning
functions and total winning strategies. We present two natural winning
conditions compatible with the loop construction which respectively provide
initial algebras and terminal coalgebras for a large class of continuous
functors. Finally, we introduce an intuitionistic sequent calculus, extended
with syntactic constructions for least and greatest fixed points, and prove it
has a sound and (in a certain weak sense) complete interpretation in our game
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0642</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0642</id><created>2010-01-05</created><authors><author><keyname>David</keyname><forenames>Bertrand</forenames><affiliation>LIESP</affiliation></author><author><keyname>Yin</keyname><forenames>Chuantao</forenames><affiliation>LIESP</affiliation></author><author><keyname>Chalon</keyname><forenames>Ren&#xe9;</forenames><affiliation>LIESP</affiliation></author></authors><title>Contextual Mobile Learning Strongly Related to Industrial Activities:
  Principles and Case Study</title><categories>cs.HC</categories><proxy>ccsd hal-00443061</proxy><acm-class>H.5</acm-class><journal-ref>iJAC Journal, International Jouranl of Advanced Corporate Learning
  2, 3 (2009) 12-20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  M-learning (mobile learning) can take various forms. We are interested in
contextualized M-learning, i.e. the training related to the situation
physically or logically localized. Contextualization and pervasivity are
important aspects of our approach. We propose in particular MOCOCO principles
(Mobility - COntextualisation - COoperation) using IMERA platform (Mobile
Interaction in the Augmented Real Environment). We are studying various mobile
learning contexts related to professional activities, in order to master
appliances (Installation, Use, Breakdown diagnostic and Repairing).
Contextualization, traceability and checking of execution of prescribed
operations are based mainly on the use of RFID labels. Investigation of the
appropriate training methods for this kind of learning situation, applying
mainly a constructivist approach known as &quot;Just-in-time learning&quot;, &quot;learning by
doing&quot;, &quot;learning and doing&quot;, constitutes an important topic of this project.
  From an organizational point of view we are in perfect symbiosis with EPSS -
Electronic Performance Support System [12] and our objective is to integrate
learning in professional activities in three ways: 1/ before work i.e. to learn
about coming actions, 2/ after work i.e. to learn about past actions to
understand what happened and accumulate experience, 3/ during work i.e. to
master the problem just-in-time
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0649</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0649</id><created>2010-01-05</created><authors><author><keyname>Qin</keyname><forenames>Xiaolin</forenames></author><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Chen</keyname><forenames>Jingwei</forenames></author><author><keyname>Zhang</keyname><forenames>Jingzhong</forenames></author></authors><title>A complete algorithm to find exact minimal polynomial by approximations</title><categories>cs.SC</categories><comments>17</comments><acm-class>F.2.1; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a complete algorithm for finding an exact minimal polynomial from
its approximate value by using an improved parameterized integer relation
construction method. Our result is superior to the existence of error
controlling on obtaining an exact rational number from its approximation. The
algorithm is applicable for finding exact minimal polynomial of an algebraic
number by its approximate root. This also enables us to provide an efficient
method of converting the rational approximation representation to the minimal
polynomial representation, and devise a simple algorithm to factor multivariate
polynomials with rational coefficients.
  Compared with the subsistent methods, our method combines advantage of high
efficiency in numerical computation, and exact, stable results in symbolic
computation. we also discuss some applications to some transcendental numbers
by approximations. Moreover, the Digits of our algorithm is far less than the
LLL-lattice basis reduction technique in theory. In this paper, we completely
implement how to obtain exact results by numerical approximate computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0674</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0674</id><created>2010-01-05</created><updated>2010-10-20</updated><authors><author><keyname>Severini</keyname><forenames>Simone</forenames></author></authors><title>The 3-dimensional cube is the only periodic, connected cubic graph with
  perfect state transfer</title><categories>quant-ph cs.DM</categories><comments>15 pages, 5 EPS figures; the main result is now weaker because of an
  error in the previous version. I would like to thank Matthew Russell for
  pointing out the error to me</comments><journal-ref>2010 J. Phys.: Conf. Ser. 254 012012</journal-ref><doi>10.1088/1742-6596/254/1/012012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is perfect state transfer between two vertices of a graph, if a single
excitation can travel with fidelity one between the corresponding sites of a
spin system modeled by the graph. When the excitation is back at the initial
site, for all sites at the same time, the graph is said to be periodic. A graph
is cubic if each of its vertices has a neighbourhood of size exactly three. We
prove that the 3-dimensional cube is the only periodic, connected cubic graph
with perfect state transfer. We conjecture that this is also the only connected
cubic graph with perfect state transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0683</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0683</id><created>2010-01-05</created><authors><author><keyname>Oezbek</keyname><forenames>Christopher</forenames></author></authors><title>Introducing Automated Regression Testing in Open Source Projects</title><categories>cs.SE</categories><comments>21 pages, 8 figures, condensed version was submitted to OSS 2010</comments><report-no>Technical Report Series B / B-10-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To learn how to introduce automated regression testing to existing medium
scale Open Source projects, a long-term field experiment was performed with the
Open Source project FreeCol. Results indicate that (1) introducing testing is
both beneficial for the project and feasible for an outside innovator, (2)
testing can enhance communication between developers, (3) signaling is
important for engaging the project participants to fill a newly vacant position
left by a withdrawal of the innovator. Five prescriptive strategies are
extracted for the innovator and two conjectures offered about the ability of an
Open Source project to learn about innovations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0695</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0695</id><created>2010-01-05</created><updated>2012-01-06</updated><authors><author><keyname>Bae</keyname><forenames>Sang Won</forenames></author><author><keyname>Korman</keyname><forenames>Matias</forenames></author><author><keyname>Okamoto</keyname><forenames>Yoshio</forenames></author></authors><title>The Geodesic Diameter of Polygonal Domains</title><categories>cs.CG</categories><comments>21 pages, 7 figures, preliminary version presented at ESA2010 and
  submitted to DCG</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the geodesic diameter of polygonal domains having h holes
and n corners. For simple polygons (i.e., h = 0), the geodesic diameter is
determined by a pair of corners of a given polygon and can be computed in
linear time, as known by Hershberger and Suri. For general polygonal domains
with h &gt;= 1, however, no algorithm for computing the geodesic diameter was
known prior to this paper. In this paper, we present the first algorithms that
compute the geodesic diameter of a given polygonal domain in worst-case time
O(n^7.73) or O(n^7 (log n + h)). The main difficulty unlike the simple polygon
case relies on the following observation revealed in this paper: two interior
points can determine the geodesic diameter and in that case there exist at
least five distinct shortest paths between the two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0700</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0700</id><created>2010-01-05</created><authors><author><keyname>Belani</keyname><forenames>Amit</forenames></author></authors><title>Vandalism Detection in Wikipedia: a Bag-of-Words Classifier Approach</title><categories>cs.LG cs.CY cs.IR</categories><comments>15 pages, 5 figures</comments><acm-class>I.2.6; I.2.7; G.3; K.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A bag-of-words based probabilistic classifier is trained using regularized
logistic regression to detect vandalism in the English Wikipedia. Isotonic
regression is used to calibrate the class membership probabilities. Learning
curve, reliability, ROC, and cost analysis are performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0716</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0716</id><created>2010-01-05</created><updated>2010-06-15</updated><authors><author><keyname>Moshksar</keyname><forenames>Kamyar</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Totally Asynchronous Interference Channels</title><categories>cs.IT math.IT</categories><comments>This paper is withdrawn due to some technicality regarding
  ergodicity. The corrected version will be submitted under the title
  &quot;Randomized On-Off signaling in Asynchronous Wireless Networks&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses an interference channel consisting of $\mathbf{n}$
active users sharing $u$ frequency sub-bands. Users are asynchronous meaning
there exists a mutual delay between their transmitted codes. A stationary model
for interference is considered by assuming the starting point of an
interferer's data is uniformly distributed along the codeword of any user. The
spectrum is divided to private and common bands each containing
$v_{\mathrm{p}}$ and $v_{\mathrm{c}}$ frequency sub-bands respectively. We
consider a scenario where all transmitters are unaware of the number of active
users and the channel gains. The optimum $v_{\mathrm{p}}$ and $v_{\mathrm{c}}$
are obtained such that the so-called outage capacity per user is maximized. If
$\Pr\{\mathbf{n}\leq 2\}=1$, upper and lower bounds on the mutual information
between the input and output of the channel for each user are derived using a
genie-aided technique. The proposed bounds meet each other as the code length
grows to infinity yielding a closed expression for the achievable rates. If
$\Pr\{\mathbf{n}&gt;2\}&gt;0$, all users follow a locally Randomized On-Off signaling
scheme on the common band where each transmitter quits transmitting its
Gaussian signals independently from transmission to transmission. Using a
conditional version of Entropy Power Inequality (EPI) and an upper bound on the
differential entropy of a mixed Gaussian random variable, lower bounds on the
achievable rates of users are developed. Thereafter, the activation probability
on each transmission slot is designed resulting in the largest outage capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0723</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0723</id><created>2010-01-05</created><updated>2010-04-22</updated><authors><author><keyname>Forney</keyname><forenames>G. David</forenames><suffix>Jr</suffix></author></authors><title>MacWilliams Identities for Terminated Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>5 pages; accepted for 2010 IEEE International Symposium on
  Information Theory, Austin, TX, June 13-18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shearer and McEliece [1977] showed that there is no MacWilliams identity for
the free distance spectra of orthogonal linear convolutional codes. We show
that on the other hand there does exist a MacWilliams identity between the
generating functions of the weight distributions per unit time of a linear
convolutional code C and its orthogonal code C^\perp, and that this
distribution is as useful as the free distance spectrum for estimating code
performance. These observations are similar to those made recently by
Bocharova, Hug, Johannesson and Kudryashov; however, we focus on terminating by
tail-biting rather than by truncation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0735</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0735</id><created>2010-01-05</created><updated>2010-02-03</updated><authors><author><keyname>Schroeder</keyname><forenames>Lutz</forenames></author><author><keyname>Pattinson</keyname><forenames>Dirk</forenames></author></authors><title>Named Models in Coalgebraic Hybrid Logic</title><categories>cs.LO cs.AI</categories><acm-class>F.4.1; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid logic extends modal logic with support for reasoning about individual
states, designated by so-called nominals. We study hybrid logic in the broad
context of coalgebraic semantics, where Kripke frames are replaced with
coalgebras for a given functor, thus covering a wide range of reasoning
principles including, e.g., probabilistic, graded, default, or coalitional
operators. Specifically, we establish generic criteria for a given coalgebraic
hybrid logic to admit named canonical models, with ensuing completeness proofs
for pure extensions on the one hand, and for an extended hybrid language with
local binding on the other. We instantiate our framework with a number of
examples. Notably, we prove completeness of graded hybrid logic with local
binding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0746</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0746</id><created>2010-01-05</created><updated>2010-02-03</updated><authors><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Alternation-Trading Proofs, Linear Programming, and Lower Bounds</title><categories>cs.CC cs.AI</categories><comments>To appear in STACS 2010, 12 pages</comments><acm-class>F.2.3; I.2.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A fertile area of recent research has demonstrated concrete polynomial time
lower bounds for solving natural hard problems on restricted computational
models. Among these problems are Satisfiability, Vertex Cover, Hamilton Path,
Mod6-SAT, Majority-of-Majority-SAT, and Tautologies, to name a few. The proofs
of these lower bounds follow a certain proof-by-contradiction strategy that we
call alternation-trading. An important open problem is to determine how
powerful such proofs can possibly be.
  We propose a methodology for studying these proofs that makes them amenable
to both formal analysis and automated theorem proving. We prove that the search
for better lower bounds can often be turned into a problem of solving a large
series of linear programming instances. Implementing a small-scale theorem
prover based on this result, we extract new human-readable time lower bounds
for several problems. This framework can also be used to prove concrete
limitations on the current techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0773</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0773</id><created>2010-01-05</created><authors><author><keyname>Zwart</keyname><forenames>Simon Portegies</forenames><affiliation>Leiden</affiliation></author><author><keyname>Ishiyama</keyname><forenames>Tomoaki</forenames><affiliation>Tokyo</affiliation></author><author><keyname>Groen</keyname><forenames>Derek</forenames><affiliation>Leiden</affiliation></author><author><keyname>Nitadori</keyname><forenames>Keigo</forenames><affiliation>Tokyo</affiliation></author><author><keyname>Makino</keyname><forenames>Junichiro</forenames><affiliation>Tokyo</affiliation></author><author><keyname>de Laat</keyname><forenames>Cees</forenames><affiliation>Amsterdam</affiliation></author><author><keyname>McMillan</keyname><forenames>Stephen</forenames><affiliation>Drexel</affiliation></author><author><keyname>Hiraki</keyname><forenames>Kei</forenames><affiliation>Tokyo</affiliation></author><author><keyname>Harfst</keyname><forenames>Stefan</forenames><affiliation>Leiden</affiliation></author><author><keyname>Grosso</keyname><forenames>Paola</forenames><affiliation>Amsterdam</affiliation></author></authors><title>Simulating the universe on an intercontinental grid of supercomputers</title><categories>astro-ph.CO astro-ph.IM cs.DC physics.comp-ph</categories><comments>Accepted for publication in IEEE Computer</comments><doi>10.1109/MC.2009.419</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the universe is hampered by the elusiveness of its most common
constituent, cold dark matter. Almost impossible to observe, dark matter can be
studied effectively by means of simulation and there is probably no other
research field where simulation has led to so much progress in the last decade.
Cosmological N-body simulations are an essential tool for evolving density
perturbations in the nonlinear regime. Simulating the formation of large-scale
structures in the universe, however, is still a challenge due to the enormous
dynamic range in spatial and temporal coordinates, and due to the enormous
computer resources required. The dynamic range is generally dealt with by the
hybridization of numerical techniques. We deal with the computational
requirements by connecting two supercomputers via an optical network and make
them operate as a single machine. This is challenging, if only for the fact
that the supercomputers of our choice are separated by half the planet, as one
is located in Amsterdam and the other is in Tokyo. The co-scheduling of the two
computers and the 'gridification' of the code enables us to achieve a 90%
efficiency for this distributed intercontinental supercomputer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0793</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0793</id><created>2010-01-05</created><authors><author><keyname>Soundararajan</keyname><forenames>Rajiv</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On the Vacationing CEO Problem: Achievable Rates and Outer Bounds</title><categories>cs.IT math.IT</categories><comments>19 pages, 1 figure, ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a class of source coding problems that combines elements
of the CEO problem with the multiple description problem. In this setting,
noisy versions of one remote source are observed by two nodes with encoders
(which is similar to the CEO problem). However, it differs from the CEO problem
in that each node must generate multiple descriptions of the source. This
problem is of interest in multiple scenarios in efficient communication over
networks. In this paper, an achievable region and an outer bound are presented
for this problem, which is shown to be sum rate optimal for a class of
distortion constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0820</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0820</id><created>2010-01-06</created><authors><author><keyname>Lierler</keyname><forenames>Yuliya</forenames></author></authors><title>Abstract Answer Set Solvers with Learning</title><categories>cs.AI cs.LO</categories><comments>Long version of the paper that will appear in special issue of Theory
  and Practice of Logic Programming</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nieuwenhuis, Oliveras, and Tinelli (2006) showed how to describe enhancements
of the Davis-Putnam-Logemann-Loveland algorithm using transition systems,
instead of pseudocode. We design a similar framework for several algorithms
that generate answer sets for logic programs: Smodels, Smodels-cc, Asp-Sat with
Learning (Cmodels), and a newly designed and implemented algorithm Sup. This
approach to describing answer set solvers makes it easier to prove their
correctness, to compare them, and to design new systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0821</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0821</id><created>2010-01-06</created><authors><author><keyname>Dorn</keyname><forenames>Frederic</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Beyond Bidimensionality: Parameterized Subexponential Algorithms on
  Directed Graphs</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop two different methods to achieve subexponential time parameterized
algorithms for problems on sparse directed graphs. We exemplify our approaches
with two well studied problems.
  For the first problem, {\sc $k$-Leaf Out-Branching}, which is to find an
oriented spanning tree with at least $k$ leaves, we obtain an algorithm solving
the problem in time $2^{O(\sqrt{k} \log k)} n+ n^{O(1)}$ on directed graphs
whose underlying undirected graph excludes some fixed graph $H$ as a minor. For
the special case when the input directed graph is planar, the running time can
be improved to $2^{O(\sqrt{k})}n + n^{O(1)}$. The second example is a
generalization of the {\sc Directed Hamiltonian Path} problem, namely {\sc
$k$-Internal Out-Branching}, which is to find an oriented spanning tree with at
least $k$ internal vertices. We obtain an algorithm solving the problem in time
$2^{O(\sqrt{k} \log k)} + n^{O(1)}$ on directed graphs whose underlying
undirected graph excludes some fixed apex graph $H$ as a minor. Finally, we
observe that for any $\epsilon&gt;0$, the {\sc $k$-Directed Path} problem is
solvable in time $O((1+\epsilon)^k n^{f(\epsilon)})$, where $f$ is some
function of $\ve$.
  Our methods are based on non-trivial combinations of obstruction theorems for
undirected graphs, kernelization, problem specific combinatorial structures and
a layering technique similar to the one employed by Baker to obtain PTAS for
planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0824</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0824</id><created>2010-01-06</created><updated>2010-02-03</updated><authors><author><keyname>Baswana</keyname><forenames>Neelesh Khanna Surender</forenames></author></authors><title>Approximate Shortest Paths Avoiding a Failed Vertex: Optimal Size Data
  Structures for Unweighted Graph</title><categories>cs.DS</categories><comments>12 pages STACS 2010</comments><acm-class>E.1; G.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Let $G=(V,E)$ be any undirected graph on $V$ vertices and $E$ edges. A path
$\textbf{P}$ between any two vertices $u,v\in V$ is said to be $t$-approximate
shortest path if its length is at most $t$ times the length of the shortest
path between $u$ and $v$. We consider the problem of building a compact data
structure for a given graph $G$ which is capable of answering the following
query for any $u,v,z\in V$ and $t&gt;1$:
  Report $t$-approximate shortest path between $u$ and $v$ when vertex $z$
fails
  We present data structures for the single source as well all-pairs versions
of this problem. Our data structures guarantee optimal query time. Most
impressive feature of our data structures is that their size {\em nearly} match
the size of their best static counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0827</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0827</id><created>2010-01-06</created><authors><author><keyname>De Vries</keyname><forenames>Christopher M.</forenames></author><author><keyname>Geva</keyname><forenames>Shlomo</forenames></author></authors><title>Document Clustering with K-tree</title><categories>cs.IR cs.AI cs.DS</categories><comments>12 pages, INEX 2008</comments><doi>10.1007/978-3-642-03761-0_43</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the approach taken to the XML Mining track at INEX 2008
by a group at the Queensland University of Technology. We introduce the K-tree
clustering algorithm in an Information Retrieval context by adapting it for
document clustering. Many large scale problems exist in document clustering.
K-tree scales well with large inputs due to its low complexity. It offers
promising results both in terms of efficiency and quality. Document
classification was completed using Support Vector Machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0829</identifier>
 <datestamp>2013-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0829</id><created>2010-01-06</created><updated>2013-03-07</updated><authors><author><keyname>Fiori</keyname><forenames>Simone</forenames></author></authors><title>Least-Squares on the Real Symplectic Group</title><categories>cs.NA</categories><comments>The paper has been published in 2011, hence I think that it is time
  to withdraw it from the arXiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper discusses the problem of least-squares over the real
symplectic group of matrices Sp(2n,R)$. The least-squares problem may be
extended from flat spaces to curved spaces by the notion of geodesic distance.
The resulting non-linear minimization problem on manifold may be tackled by
means of a gradient-descent algorithm tailored to the geometry of the space at
hand. In turn, gradient steepest descent on manifold may be implemented through
a geodesic-based stepping method. As the space Sp(2n,R) is a non-compact Lie
group, it is convenient to endow it with a pseudo-Riemannian geometry. Indeed,
a pseudo-Riemannian metric allows the computation of geodesic arcs and geodesic
distances in closed form on Sp(2n,R).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0830</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0830</id><created>2010-01-06</created><authors><author><keyname>De Vries</keyname><forenames>Christopher M.</forenames></author><author><keyname>Geva</keyname><forenames>Shlomo</forenames></author></authors><title>K-tree: Large Scale Document Clustering</title><categories>cs.IR cs.AI cs.DS</categories><comments>2 pages, SIGIR 2009</comments><acm-class>H.3.3</acm-class><doi>10.1145/1571941.1572094</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce K-tree in an information retrieval context. It is an efficient
approximation of the k-means clustering algorithm. Unlike k-means it forms a
hierarchy of clusters. It has been extended to address issues with sparse
representations. We compare performance and quality to CLUTO using document
collections. The K-tree has a low time complexity that is suitable for large
document collections. This tree structure allows for efficient disk based
implementations where space requirements exceed that of main memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0831</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0831</id><created>2010-01-06</created><updated>2010-08-03</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Khan</keyname><forenames>Pervez</forenames></author><author><keyname>Ullah</keyname><forenames>Niamat</forenames></author><author><keyname>Saleem</keyname><forenames>Shahnaz</forenames></author><author><keyname>Higgins</keyname><forenames>Henry</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>A Review of Wireless Body Area Networks for Medical Applications</title><categories>cs.NI</categories><comments>7 pages, 7 figures, and 3 tables. In V3, the manuscript is converted
  to LaTeX</comments><journal-ref>International Journal of Communications, Network and System
  Sciences, Vol. 2, No. 8, pp 797-803, 2009</journal-ref><doi>10.4236/ijcns.2009.28093</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in Micro-Electro-Mechanical Systems (MEMS) technology,
integrated circuits, and wireless communication have allowed the realization of
Wireless Body Area Networks (WBANs). WBANs promise unobtrusive ambulatory
health monitoring for a long period of time and provide real-time updates of
the patient's status to the physician. They are widely used for ubiquitous
healthcare, entertainment, and military applications. This paper reviews the
key aspects of WBANs for numerous applications. We present a WBAN
infrastructure that provides solutions to on-demand, emergency, and normal
traffic. We further discuss in-body antenna design and low-power MAC protocol
for WBAN. In addition, we briefly outline some of the WBAN applications with
examples. Our discussion realizes a need for new power-efficient solutions
towards in-body and on-body sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0833</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0833</id><created>2010-01-06</created><updated>2010-02-01</updated><authors><author><keyname>De Vries</keyname><forenames>Christopher M.</forenames></author><author><keyname>De Vine</keyname><forenames>Lance</forenames></author><author><keyname>Geva</keyname><forenames>Shlomo</forenames></author></authors><title>Random Indexing K-tree</title><categories>cs.IR cs.AI cs.DS</categories><comments>8 pages, ADCS 2009; Hyperref and cleveref LaTeX packages conflicted.
  Removed cleveref</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random Indexing (RI) K-tree is the combination of two algorithms for
clustering. Many large scale problems exist in document clustering. RI K-tree
scales well with large inputs due to its low complexity. It also exhibits
features that are useful for managing a changing collection. Furthermore, it
solves previous issues with sparse document vectors when using K-tree. The
algorithms and data structures are defined, explained and motivated. Specific
modifications to K-tree are made for use with RI. Experiments have been
executed to measure quality. The results indicate that RI K-tree improves
document cluster quality over the original K-tree algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0879</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0879</id><created>2010-01-06</created><authors><author><keyname>Zhdanov</keyname><forenames>Fedor</forenames></author><author><keyname>Kalnishkan</keyname><forenames>Yuri</forenames></author></authors><title>Linear Probability Forecasting</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-class classification is one of the most important tasks in machine
learning. In this paper we consider two online multi-class classification
problems: classification by a linear model and by a kernelized model. The
quality of predictions is measured by the Brier loss function. We suggest two
computationally efficient algorithms to work with these problems and prove
theoretical guarantees on their losses. We kernelize one of the algorithms and
prove theoretical guarantees on its loss. We perform experiments and compare
our algorithms with logistic regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0887</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0887</id><created>2010-01-06</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Yu</keyname><forenames>Weichuan</forenames></author></authors><title>Stable Feature Selection for Biomarker Discovery</title><categories>cs.CE q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection techniques have been used as the workhorse in biomarker
discovery applications for a long time. Surprisingly, the stability of feature
selection with respect to sampling variations has long been under-considered.
It is only until recently that this issue has received more and more attention.
In this article, we review existing stable feature selection methods for
biomarker discovery using a generic hierarchal framework. We have two
objectives: (1) providing an overview on this new yet fast growing topic for a
convenient reference; (2) categorizing existing methods under an expandable
framework for future research and development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0889</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0889</id><created>2010-01-06</created><authors><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Ilcinkas</keyname><forenames>David</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Labourel</keyname><forenames>Arnaud</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Pelc</keyname><forenames>Andrzej</forenames></author></authors><title>Asynchronous deterministic rendezvous in bounded terrains</title><categories>cs.CG cs.DS</categories><proxy>ccsd hal-00442196</proxy><doi>10.1007/978-3-642-13284-1_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two mobile agents (robots) have to meet in an a priori unknown bounded
terrain modeled as a polygon, possibly with polygonal obstacles. Agents are
modeled as points, and each of them is equipped with a compass. Compasses of
agents may be incoherent. Agents construct their routes, but the actual walk of
each agent is decided by the adversary: the movement of the agent can be at
arbitrary speed, the agent may sometimes stop or go back and forth, as long as
the walk of the agent in each segment of its route is continuous, does not
leave it and covers all of it. We consider several scenarios, depending on
three factors: (1) obstacles in the terrain are present, or not, (2) compasses
of both agents agree, or not, (3) agents have or do not have a map of the
terrain with their positions marked. The cost of a rendezvous algorithm is the
worst-case sum of lengths of the agents' trajectories until their meeting. For
each scenario we design a deterministic rendezvous algorithm and analyze its
cost. We also prove lower bounds on the cost of any deterministic rendezvous
algorithm in each case. For all scenarios these bounds are tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0890</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0890</id><created>2010-01-06</created><authors><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Labourel</keyname><forenames>Arnaud</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Pelc</keyname><forenames>Andrzej</forenames></author></authors><title>How to meet asynchronously (almost) everywhere</title><categories>cs.DS cs.DC</categories><proxy>ccsd hal-00418775</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two mobile agents (robots) with distinct labels have to meet in an arbitrary,
possibly in?nite, unknown connected graph or in an unknown connected terrain in
the plane. Agents are modeled as points, and the route of each of them only
depends on its label and on the unknown environment. The actual walk of each
agent also depends on an asynchronous adversary that may arbitrarily vary the
speed of the agent, stop it, or even move it back and forth, as long as the
walk of the agent in each segment of its route is continuous, does not leave it
and covers all of it. Meeting in a graph means that both agents must be at the
same time in some node or in some point inside an edge of the graph, while
meeting in a terrain means that both agents must be at the same time in some
point of the terrain. Does there exist a deterministic algorithm that allows
any two agents to meet in any unknown environment in spite of this very
powerfull adversary? We give deterministic rendezvous algorithms for agents
starting at arbitrary nodes of any anonymous connected graph (?nite or in?nite)
and for agents starting at any interior points with rational coordinates in any
closed region of the plane with path-connected interior. While our algorithms
work in a very general setting ? agents can, indeed, meet almost everywhere ?
we show that none of the above few limitations imposed on the environment can
be removed. On the other hand, our algorithm also guarantees the following
approximate rendezvous for agents starting at arbitrary interior points of a
terrain as above: agents will eventually get at an arbitrarily small positive
distance from each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0920</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0920</id><created>2010-01-06</created><updated>2010-02-03</updated><authors><author><keyname>Mathieu</keyname><forenames>Claire</forenames></author><author><keyname>Sankur</keyname><forenames>Ocan</forenames></author><author><keyname>Schudy</keyname><forenames>Warren</forenames></author></authors><title>Online Correlation Clustering</title><categories>cs.DS</categories><comments>12 pages, 1 figure</comments><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study the online clustering problem where data items arrive in an online
fashion. The algorithm maintains a clustering of data items into similarity
classes. Upon arrival of v, the relation between v and previously arrived items
is revealed, so that for each u we are told whether v is similar to u. The
algorithm can create a new cluster for v and merge existing clusters.
  When the objective is to minimize disagreements between the clustering and
the input, we prove that a natural greedy algorithm is O(n)-competitive, and
this is optimal.
  When the objective is to maximize agreements between the clustering and the
input, we prove that the greedy algorithm is .5-competitive; that no online
algorithm can be better than .834-competitive; we prove that it is possible to
get better than 1/2, by exhibiting a randomized algorithm with competitive
ratio .5+c for a small positive fixed constant c.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0921</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0921</id><created>2010-01-06</created><authors><author><keyname>Jain</keyname><forenames>Brijnesh J.</forenames></author><author><keyname>Obermayer</keyname><forenames>Klaus</forenames></author></authors><title>Graph Quantization</title><categories>cs.AI</categories><comments>24 pages; submitted to CVIU</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector quantization(VQ) is a lossy data compression technique from signal
processing, which is restricted to feature vectors and therefore inapplicable
for combinatorial structures. This contribution presents a theoretical
foundation of graph quantization (GQ) that extends VQ to the domain of
attributed graphs. We present the necessary Lloyd-Max conditions for optimality
of a graph quantizer and consistency results for optimal GQ design based on
empirical distortion measures and stochastic optimization. These results
statistically justify existing clustering algorithms in the domain of graphs.
The proposed approach provides a template of how to link structural pattern
recognition methods other than GQ to statistical pattern recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0927</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0927</id><created>2010-01-06</created><authors><author><keyname>Jain</keyname><forenames>Brijnesh J.</forenames></author><author><keyname>Obermayer</keyname><forenames>Klaus</forenames></author></authors><title>Accelerating Competitive Learning Graph Quantization</title><categories>cs.CV</categories><comments>17 pages; submitted to CVIU</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector quantization(VQ) is a lossy data compression technique from signal
processing for which simple competitive learning is one standard method to
quantize patterns from the input space. Extending competitive learning VQ to
the domain of graphs results in competitive learning for quantizing input
graphs. In this contribution, we propose an accelerated version of competitive
learning graph quantization (GQ) without trading computational time against
solution quality. For this, we lift graphs locally to vectors in order to avoid
unnecessary calculations of intractable graph distances. In doing so, the
accelerated version of competitive learning GQ gradually turns locally into a
competitive learning VQ with increasing number of iterations. Empirical results
show a significant speedup by maintaining a comparable solution quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0958</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0958</id><created>2010-01-06</created><updated>2010-01-06</updated><authors><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Wang</keyname><forenames>James Z.</forenames></author><author><keyname>Feltus</keyname><forenames>F. Alex</forenames></author><author><keyname>Zhou</keyname><forenames>Jizhong</forenames></author><author><keyname>Luo</keyname><forenames>Feng</forenames></author></authors><title>Effectively integrating information content and structural relationship
  to improve the GO-based similarity measure between proteins</title><categories>cs.CE q-bio.GN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gene Ontology (GO) provides a knowledge base to effectively describe
proteins. However, measuring similarity between proteins based on GO remains a
challenge. In this paper, we propose a new similarity measure, information
coefficient similarity measure (SimIC), to effectively integrate both the
information content (IC) of GO terms and the structural information of GO
hierarchy to determine the similarity between proteins. Testing on yeast
proteins, our results show that SimIC efficiently addresses the shallow
annotation issue in GO, thus improves the correlations between GO similarities
of yeast proteins and their expression similarities as well as between GO
similarities of yeast proteins and their sequence similarities. Furthermore, we
demonstrate that the proposed SimIC is superior in predicting yeast protein
interactions. We predict 20484 yeast protein-protein interactions (PPIs)
between 2462 proteins based on the high SimIC values of biological process (BP)
and cellular component (CC). Examining the 214 MIPS complexes in our predicted
PPIs shows that all members of 159 MIPS complexes can be found in our PPI
predictions, which is more than those (120/214) found in PPIs predicted by
relative specificity similarity (RSS). Integrating IC and structural
information of GO hierarchy can improve the effectiveness of the semantic
similarity measure of GO terms. The new SimIC can effectively correct the
effect of shallow annotation, and then provide an effective way to measure
similarity between proteins based on Gene Ontology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.0961</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.0961</id><created>2010-01-06</created><updated>2010-01-08</updated><authors><author><keyname>Sauerbier</keyname><forenames>Charles</forenames></author></authors><title>Computing a Frobenius Coin Problem decision problem in O(n^2)</title><categories>cs.DS</categories><comments>7 pages, 0 figures; corrected misspelling of Chemakani's name,
  reformated, added larger images of algorithm listings</comments><acm-class>F.2.1; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expanding on recent results of another an algorithm is presented that
provides solution to the Frobenius Coin Problem in worst case O(n^2) in the
magnitude of the largest denomination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1009</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1009</id><created>2010-01-06</created><authors><author><keyname>Thouin</keyname><forenames>Frederic</forenames><affiliation>McGill University, Montreal, Canada</affiliation></author><author><keyname>Coates</keyname><forenames>Mark</forenames><affiliation>McGill University, Montreal, Canada</affiliation></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames><affiliation>McGill University, Montreal, Canada</affiliation></author></authors><title>Multi-path Probabilistic Available Bandwidth Estimation through Bayesian
  Active Learning</title><categories>cs.NI cs.LG</categories><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowing the largest rate at which data can be sent on an end-to-end path such
that the egress rate is equal to the ingress rate with high probability can be
very practical when choosing transmission rates in video streaming or selecting
peers in peer-to-peer applications. We introduce probabilistic available
bandwidth, which is defined in terms of ingress rates and egress rates of
traffic on a path, rather than in terms of capacity and utilization of the
constituent links of the path like the standard available bandwidth metric. In
this paper, we describe a distributed algorithm, based on a probabilistic
graphical model and Bayesian active learning, for simultaneously estimating the
probabilistic available bandwidth of multiple paths through a network. Our
procedure exploits the fact that each packet train provides information not
only about the path it traverses, but also about any path that shares a link
with the monitored path. Simulations and PlanetLab experiments indicate that
this process can dramatically reduce the number of probes required to generate
accurate estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1013</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1013</id><created>2010-01-06</created><authors><author><keyname>Zhu</keyname><forenames>Xiaoqing</forenames></author><author><keyname>Agrawal</keyname><forenames>Piyush</forenames></author><author><keyname>Singh</keyname><forenames>Jatinder Pal</forenames></author><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Girod</keyname><forenames>Bernd</forenames></author></authors><title>Distributed Rate Allocation Policies for Multi-Homed Video Streaming
  over Heterogeneous Access Networks</title><categories>cs.MM cs.NI</categories><comments>12 pages, 22 figures</comments><journal-ref>IEEE Transactions on Multimedia, Pages: 752-764, Volume: 11 Issue:
  4, Date: June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate allocation among multiple simultaneous video
streams sharing multiple heterogeneous access networks. We develop and evaluate
an analytical framework for optimal rate allocation based on observed available
bit rate (ABR) and round-trip time (RTT) over each access network and video
distortion-rate (DR) characteristics. The rate allocation is formulated as a
convex optimization problem that minimizes the total expected distortion of all
video streams. We present a distributed approximation of its solution and
compare its performance against H-infinity optimal control and two heuristic
schemes based on TCP-style additive-increase-multiplicative decrease (AIMD)
principles. The various rate allocation schemes are evaluated in simulations of
multiple high-definition (HD) video streams sharing multiple access networks.
Our results demonstrate that, in comparison with heuristic AIMD-based schemes,
both media-aware allocation and H-infinity optimal control benefit from
proactive congestion avoidance and reduce the average packet loss rate from 45%
to below 2%. Improvement in average received video quality ranges between 1.5
to 10.7 dB in PSNR for various background traffic loads and video playout
deadlines. Media-aware allocation further exploits its knowledge of the video
DR characteristics to achieve a more balanced video quality among all streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1017</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1017</id><created>2010-01-06</created><authors><author><keyname>Alexeev</keyname><forenames>Boris</forenames></author><author><keyname>Tsimerman</keyname><forenames>Jacob</forenames></author></authors><title>An analysis of a war-like card game</title><categories>math.CO cs.GT</categories><comments>5 pages, 1 figure</comments><msc-class>91A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In his book &quot;Mathematical Mind-Benders&quot;, Peter Winkler poses the following
open problem, originally due to the first author: &quot;[In the game Peer Pressure,]
two players are dealt some number of cards, initially face up, each card
carrying a different integer. In each round, the players simultaneously play a
card; the higher card is discarded and the lower card passed to the other
player. The player who runs out of cards loses. As the number of cards dealt
becomes larger, what is the limiting probability that one of the players will
have a winning strategy?&quot;
  We show that the answer to this question is zero, as Winkler suspected.
Moreover, assume the cards are dealt so that one player receives r &gt;= 1 cards
for every one card of the other. Then if r &lt; phi = (1+sqrt 5)/2, the limiting
probability that either player has a winning strategy is still zero, while if r
&gt; phi, it is one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1020</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1020</id><created>2010-01-07</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>An Empirical Evaluation of Four Algorithms for Multi-Class
  Classification: Mart, ABC-Mart, Robust LogitBoost, and ABC-LogitBoost</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This empirical study is mainly devoted to comparing four tree-based boosting
algorithms: mart, abc-mart, robust logitboost, and abc-logitboost, for
multi-class classification on a variety of publicly available datasets. Some of
those datasets have been thoroughly tested in prior studies using a broad range
of classification algorithms including SVM, neural nets, and deep learning.
  In terms of the empirical classification errors, our experiment results
demonstrate:
  1. Abc-mart considerably improves mart. 2. Abc-logitboost considerably
improves (robust) logitboost. 3. Robust) logitboost} considerably improves mart
on most datasets. 4. Abc-logitboost considerably improves abc-mart on most
datasets. 5. These four boosting algorithms (especially abc-logitboost)
outperform SVM on many datasets. 6. Compared to the best deep learning methods,
these four boosting algorithms (especially abc-logitboost) are competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1021</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1021</id><created>2010-01-06</created><updated>2010-01-12</updated><authors><author><keyname>Uchoa-Filho</keyname><forenames>Bartolomeu F.</forenames></author><author><keyname>Nobrega</keyname><forenames>Roberto W.</forenames></author></authors><title>The Capacity of Random Linear Coding Networks as Subspace Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2010; reference corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider noncoherent random linear coding networks (RLCNs)
as a discrete memoryless channel (DMC) whose input and output alphabets consist
of subspaces. This contrasts with previous channel models in the literature
which assume matrices as the channel input and output. No particular
assumptions are made on the network topology or the transfer matrix, except
that the latter may be rank-deficient according to some rank deficiency
probability distribution. We introduce a random vector basis selection
procedure which renders the DMC symmetric. The capacity we derive can be seen
as a lower bound on the capacity of noncoherent RLCNs, where subspace coding
suffices to achieve this bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1022</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1022</id><created>2010-01-06</created><authors><author><keyname>Vassev</keyname><forenames>Emil</forenames></author></authors><title>LXG Compiler - Design and Implementation</title><categories>cs.PL cs.SE</categories><comments>37 pages, 2 figures, grammar in BNF</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LXG is a simple Pascal-like language. It is a functional programming language
developed for studying compiler design and implementation. The language
supports procedure and variable declarations, but no classes. This paper
reports the design and implementation of an LXG compiler. Test results are
presented as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1026</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1026</id><created>2010-01-07</created><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>On Network-Error Correcting Convolutional Codes under the BSC Edge Error
  Model</title><categories>cs.IT math.IT</categories><comments>10 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional network-error correcting codes (CNECCs) are known to provide
error correcting capability in acyclic instantaneous networks within the
network coding paradigm under small field size conditions. In this work, we
investigate the performance of CNECCs under the error model of the network
where the edges are assumed to be statistically independent binary symmetric
channels, each with the same probability of error $p_e$($0\leq p_e&lt;0.5$). We
obtain bounds on the performance of such CNECCs based on a modified generating
function (the transfer function) of the CNECCs. For a given network, we derive
a mathematical condition on how small $p_e$ should be so that only single edge
network-errors need to be accounted for, thus reducing the complexity of
evaluating the probability of error of any CNECC. Simulations indicate that
convolutional codes are required to possess different properties to achieve
good performance in low $p_e$ and high $p_e$ regimes. For the low $p_e$ regime,
convolutional codes with good distance properties show good performance. For
the high $p_e$ regime, convolutional codes that have a good \textit{slope} (the
minimum normalized cycle weight) are seen to be good. We derive a lower bound
on the slope of any rate $b/c$ convolutional code with a certain degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1027</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1027</id><created>2010-01-07</created><updated>2014-07-24</updated><authors><author><keyname>Sohl-Dickstein</keyname><forenames>Jascha</forenames></author><author><keyname>Wang</keyname><forenames>Ching Ming</forenames></author><author><keyname>Olshausen</keyname><forenames>Bruno A.</forenames></author></authors><title>An Unsupervised Algorithm For Learning Lie Group Transformations</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several theoretical contributions which allow Lie groups to be fit
to high dimensional datasets. Transformation operators are represented in their
eigen-basis, reducing the computational complexity of parameter estimation to
that of training a linear transformation model. A transformation specific
&quot;blurring&quot; operator is introduced that allows inference to escape local minima
via a smoothing of the transformation space. A penalty on traversed manifold
distance is added which encourages the discovery of sparse, minimal distance,
transformations between states. Both learning and inference are demonstrated
using these methods for the full set of affine transformations on natural image
patches. Transformation operators are then trained on natural video sequences.
It is shown that the learned video transformations provide a better description
of inter-frame differences than the standard motion model based on rigid
translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1043</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1043</id><created>2010-01-07</created><authors><author><keyname>Lu</keyname><forenames>Ruqian</forenames></author><author><keyname>Li</keyname><forenames>Lixing</forenames></author><author><keyname>Shang</keyname><forenames>Yun</forenames></author><author><keyname>Li</keyname><forenames>Xiaoyu</forenames></author></authors><title>Process Algebra as Abstract Data Types</title><categories>cs.PL cs.LO</categories><comments>74pages</comments><acm-class>D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduced an algebraic semantics for process algebra in
form of abstract data types. For that purpose, we developed a particular type
of algebra, the seed algebra, which describes exactly the behavior of a process
within a labeled transition system. We have shown the possibility of
characterizing the bisimulation of two processes with the isomorphism of their
corresponding seed algebras. We pointed out that the traditional concept of
isomorphism of algebra does not apply here, because there is even no one-one
correspondence between the elements of two seed algebras. The lack of this
one-one correspondence comes from the non-deterministic choice of transitions
of a process. We introduce a technique of hidden operations to mask unwanted
details of elements of a seed algebra, which only reflect non-determinism or
other implicit control mechanism of process transition. Elements of a seed
algebra are considered as indistinguishable if they show the same behavior
after these unwanted details are masked. Each class of indistinguishable
elements is called a non-hidden closure. We proved that bisimulation of two
processes is equivalent to isomorphism of non-hidden closures of two seed
algebras representing these two processes. We call this kind of isomorphism a
deep isomorphism. We get different models of seed algebra by specifying
different axiom systems for the same signature. Each model corresponds to a
different kind of bisimulation. By proving the relations between these models
we also established relations between 10 different bisimulations, which form a
acyclic directed graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1065</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1065</id><created>2010-01-07</created><authors><author><keyname>Baek</keyname><forenames>Seung Ki</forenames></author><author><keyname>Bernhardsson</keyname><forenames>Sebastian</forenames></author></authors><title>Equilibrium solution to the lowest unique positive integer game</title><categories>math.CO cs.GT math.PR</categories><comments>8 pages, 3 figures</comments><journal-ref>Fluctuation and Noise Letters, 9:1, pp. 61-68 (2010)</journal-ref><doi>10.1142/S0219477510000071</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the equilibrium concept of a reverse auction game so that no one
can enhance the individual payoff by a unilateral change when all the others
follow a certain strategy. In this approach the combinatorial possibilities to
consider become very much involved even for a small number of players, which
has hindered a precise analysis in previous works. We here present a systematic
way to reach the solution for a general number of players, and show that this
game is an example of conflict between the group and the individual interests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1078</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1078</id><created>2010-01-07</created><updated>2010-05-10</updated><authors><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Stability of multidimensional persistent homology with respect to domain
  perturbations</title><categories>math.AT cs.CG cs.IT math.IT</categories><comments>16 pages Newly added Section 3 &quot;Stability with respect to other
  distances between sets&quot; New example in Section 4</comments><msc-class>Primary: 55N35, Secondary: 68T10, 68U05, 55N05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the problem of dealing with incomplete or imprecise acquisition
of data in computer vision and computer graphics, we extend results concerning
the stability of persistent homology with respect to function perturbations to
results concerning the stability with respect to domain perturbations. Domain
perturbations can be measured in a number of different ways. An important
method to compare domains is the Hausdorff distance. We show that by encoding
sets using the distance function, the multidimensional matching distance
between rank invariants of persistent homology groups is always upperly bounded
by the Hausdorff distance between sets. Moreover we prove that our construction
maintains information about the original set. Other well known methods to
compare sets are considered, such as the symmetric difference distance between
classical sets and the sup-distance between fuzzy sets. Also in these cases we
present results stating that the multidimensional matching distance between
rank invariants of persistent homology groups is upperly bounded by these
distances. An experiment showing the potential of our approach concludes the
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1079</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1079</id><created>2010-01-07</created><authors><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author></authors><title>Measuring Latent Causal Structure</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discovering latent representations of the observed world has become
increasingly more relevant in data analysis. Much of the effort concentrates on
building latent variables which can be used in prediction problems, such as
classification and regression. A related goal of learning latent structure from
data is that of identifying which hidden common causes generate the
observations, such as in applications that require predicting the effect of
policies. This will be the main problem tackled in our contribution: given a
dataset of indicators assumed to be generated by unknown and unmeasured common
causes, we wish to discover which hidden common causes are those, and how they
generate our data. This is possible under the assumption that observed
variables are linear functions of the latent causes with additive noise.
Previous results in the literature present solutions for the case where each
observed variable is a noisy function of a single latent variable. We show how
to extend the existing results for some cases where observed variables measure
more than one latent variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1093</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1093</id><created>2010-01-07</created><authors><author><keyname>Linhares</keyname><forenames>Andrea Carneiro</forenames></author><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author><author><keyname>Peinl</keyname><forenames>Peter</forenames></author><author><keyname>Michelon</keyname><forenames>Philippe</forenames></author></authors><title>Solving the Frequency Assignment Problem by Site Availability and
  Constraint Programming</title><categories>math.OC cs.NI math.CO</categories><comments>11 pages, 1 figure and 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient use of bandwidth for radio communications becomes more and more
crucial when developing new information technologies and their applications.
The core issues are addressed by the so-called Frequency Assignment Problems
(FAP). Our work investigates static FAP, where an attempt is first made to
configure a kernel of links. We study the problem based on the concepts and
techniques of Constraint Programming and integrate the site availability
concept. Numerical simulations conducted on scenarios provided by CELAR are
very promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1106</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1106</id><created>2010-01-07</created><updated>2010-04-20</updated><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor V.</forenames></author></authors><title>Optimal Thresholds for GMD Decoding with (L+1)/L-extended Bounded
  Distance Decoders</title><categories>cs.IT math.IT</categories><comments>Accepted for the 2010 IEEE International Symposium on Information
  Theory, Austin, TX, USA, June 13 - 18, 2010. 5 pages, 2 figures</comments><doi>10.1109/ISIT.2010.5513698</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate threshold-based multi-trial decoding of concatenated codes
with an inner Maximum-Likelihood decoder and an outer error/erasure
(L+1)/L-extended Bounded Distance decoder, i.e. a decoder which corrects e
errors and t erasures if e(L+1)/L + t &lt;= d - 1, where d is the minimum distance
of the outer code and L is a positive integer. This is a generalization of
Forney's GMD decoding, which was considered only for L = 1, i.e. outer Bounded
Minimum Distance decoding. One important example for (L+1)/L-extended Bounded
Distance decoders is decoding of L-Interleaved Reed-Solomon codes. Our main
contribution is a threshold location formula, which allows to optimally erase
unreliable inner decoding results, for a given number of decoding trials and
parameter L. Thereby, the term optimal means that the residual codeword error
probability of the concatenated code is minimized. We give an estimation of
this probability for any number of decoding trials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1110</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1110</id><created>2010-01-07</created><authors><author><keyname>Kelif</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Coupechoux</keyname><forenames>Marceau</forenames></author></authors><title>Joint Impact of Pathloss Shadowing and Fast Fading - An Outage Formula
  for Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyse the joint impact of pathloss, shadowing and fast
fading on wireless networks. Taking into account the pathloss and the
shadowing, we first express the SINR distribution of a mobile located at a
given distance from its serving base-station (BS). The moments of this
distribution are easily computed, using the Fenton-Wilkinson method, and a
fluid model that considers the cellular network as a continuum of BS. Then
considering the joint impact of pathloss, shadowing and fast fading, we derive
an easily computable outage probability formula, for a mobile located at any
distance from its serving BS. We validate our approach by comparing all results
to Monte Carlo simulations performed in a traditional hexagonal network.
Indeed, we establish that the results given by the formula are close to the
ones given by Monte Carlo simulations. The proposed framework is a powerful
tool to study performances of cellular networks e.g. OFDMA systems (WiMAX,
LTE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1117</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1117</id><created>2010-01-07</created><authors><author><keyname>Han</keyname><forenames>Bin</forenames></author><author><keyname>Zhuang</keyname><forenames>Xiaosheng</forenames></author></authors><title>Matrix Extension with Symmetry and Its Application to Filter Banks</title><categories>cs.IT cs.NA math.IT math.NA math.RA</categories><msc-class>15A83, 15A54, 42C40, 15A23</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we completely solve the matrix extension problem with symmetry
and provide a step-by-step algorithm to construct such a desired matrix
$\mathsf{P}_e$ from a given matrix $\mathsf{P}$. Furthermore, using a cascade
structure, we obtain a complete representation of any $r\times s$ paraunitary
matrix $\mathsf{P}$ having compatible symmetry, which in turn leads to an
algorithm for deriving a desired matrix $\mathsf{P}_e$ from a given matrix
$\mathsf{P}$. Matrix extension plays an important role in many areas such as
electronic engineering, system sciences, applied mathematics, and pure
mathematics. As an application of our general results on matrix extension with
symmetry, we obtain a satisfactory algorithm for constructing symmetric
paraunitary filter banks and symmetric orthonormal multiwavelets by deriving
high-pass filters with symmetry from any given low-pass filters with symmetry.
Several examples are provided to illustrate the proposed algorithms and results
in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1122</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1122</id><created>2010-01-07</created><updated>2010-07-25</updated><authors><author><keyname>Gorban</keyname><forenames>A. N.</forenames></author><author><keyname>Zinovyev</keyname><forenames>A.</forenames></author></authors><title>Principal manifolds and graphs in practice: from molecular biology to
  dynamical systems</title><categories>cs.NE cs.AI</categories><comments>12 pages, 9 figures</comments><journal-ref>International Journal of Neural Systems, Vol. 20, No. 3 (2010)
  219-232</journal-ref><doi>10.1142/S0129065710002383</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present several applications of non-linear data modeling, using principal
manifolds and principal graphs constructed using the metaphor of elasticity
(elastic principal graph approach). These approaches are generalizations of the
Kohonen's self-organizing maps, a class of artificial neural networks. On
several examples we show advantages of using non-linear objects for data
approximation in comparison to the linear ones. We propose four numerical
criteria for comparing linear and non-linear mappings of datasets into the
spaces of lower dimension. The examples are taken from comparative political
science, from analysis of high-throughput data in molecular biology, from
analysis of dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1133</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1133</id><created>2010-01-07</created><updated>2010-06-04</updated><authors><author><keyname>Huh</keyname><forenames>Hoon</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Moon</keyname><forenames>Sung-Hyun</forenames></author><author><keyname>Lee</keyname><forenames>Inkyu</forenames></author></authors><title>Multi-cell MIMO Downlink with Fairness Criteria: the Large System Limit</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, accepted for ISIT 2010, camera-ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the downlink of a cellular network with multiple cells and
multi-antenna base stations including arbitrary inter-cell cooperation,
realistic distance-dependent pathloss and general &quot;fairness&quot; requirements.
Beyond Monte Carlo simulation, no efficient computation method to evaluate the
ergodic throughput of such systems has been provided so far. We propose an
analytic method based on the combination of the large random matrix theory with
Lagrangian optimization. The proposed method is computationally much more
efficient than Monte Carlo simulation and provides a very accurate
approximation (almost indistinguishable) for the actual finite-dimensional
case, even for of a small number of users and base station antennas. Numerical
examples include linear 2-cell and planar three-sectored 7-cell layouts, with
no inter-cell cooperation, sector cooperation, and full cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1139</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1139</id><created>2010-01-07</created><updated>2010-05-28</updated><authors><author><keyname>Abal</keyname><forenames>G.</forenames></author><author><keyname>Donangelo</keyname><forenames>R.</forenames></author><author><keyname>Marquezino</keyname><forenames>F. L.</forenames></author><author><keyname>Portugal</keyname><forenames>R.</forenames></author></authors><title>Spatial search in a honeycomb network</title><categories>quant-ph cs.CC cs.DS</categories><comments>10 pages, 2 figures; Minor typos corrected, one Reference added.
  accepted in Math. Structures in Computer Science, special volume on Quantum
  Computing</comments><journal-ref>Mathematical Structures in Computer Science, v. 20, p. 999-1009,
  2010</journal-ref><doi>10.1017/S0960129510000332</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spatial search problem consists in minimizing the number of steps
required to find a given site in a network, under the restriction that only
oracle queries or translations to neighboring sites are allowed. In this paper,
a quantum algorithm for the spatial search problem on a honeycomb lattice with
$N$ sites and torus-like boundary conditions. The search algorithm is based on
a modified quantum walk on a hexagonal lattice and the general framework
proposed by Ambainis, Kempe and Rivosh is used to show that the time complexity
of this quantum search algorithm is $O(\sqrt{N \log N})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1143</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1143</id><created>2010-01-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Redundancy in Systems which Entertain a Model of Themselves: Interaction
  Information and the Self-organization of Anticipation</title><categories>cs.IR physics.soc-ph</categories><journal-ref>Entropy 12(1) (2010) 63-79</journal-ref><doi>10.3390/e12010063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mutual information among three or more dimensions (mu-star = - Q) has been
considered as interaction information. However, Krippendorff (2009a, 2009b) has
shown that this measure cannot be interpreted as a unique property of the
interactions and has proposed an alternative measure of interaction information
based on iterative approximation of maximum entropies. Q can then be considered
as a measure of the difference between interaction information and redundancy
generated in a model entertained by an observer. I argue that this provides us
with a measure of the imprint of a second-order observing system -- a model
entertained by the system itself -- on the underlying information processing.
The second-order system communicates meaning hyper-incursively; an observation
instantiates this meaning-processing within the information processing. The net
results may add to or reduce the prevailing uncertainty. The model is tested
empirically for the case where textual organization can be expected to contain
intellectual organization in terms of distributions of title words, author
names, and cited references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1172</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1172</id><created>2010-01-07</created><authors><author><keyname>Horton</keyname><forenames>John</forenames></author></authors><title>The Condition of the Turking Class: Are Online Employers Fair and
  Honest?</title><categories>cs.CY cs.HC</categories><acm-class>J.4; K.4.1; K.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online labor markets give people in poor countries direct access to buyers in
rich countries. Economic theory and empirical evidence strongly suggest that
this kind of access improves human welfare. However, critics claim that abuses
are endemic in these markets and that employers exploit unprotected, vulnerable
workers. I investigate part of this claim using a randomized, paired survey in
which I ask workers in an online labor market (Amazon Mechanical Turk) how they
perceive online employers and employers in their host country in terms of
honesty and fairness. I find that, on average, workers perceive the collection
of online employers as slightly fairer and more honest than offline employers,
though the effect is not significant. Views are more polarized in the online
employer case, with more respondents having very positive views of the online
collection of employers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1185</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1185</id><created>2010-01-07</created><authors><author><keyname>Tulabandhula</keyname><forenames>Theja</forenames></author></authors><title>Some Architectures for Chebyshev Interpolation</title><categories>cs.NA</categories><comments>4 pages, 3 figures, draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital architectures for Chebyshev interpolation are explored and a
variation which is word-serial in nature is proposed. These architectures are
contrasted with equispaced system structures. Further, Chebyshev interpolation
scheme is compared to the conventional equispaced interpolation vis-a-vis
reconstruction error and relative number of samples. It is also shown that the
use of a hybrid (or dual) Analog to Digital converter unit can reduce system
power consumption by as much as 1/3rd of the original.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1187</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1187</id><created>2010-01-07</created><updated>2010-01-12</updated><authors><author><keyname>Shirani-Mehr</keyname><forenames>Hooman</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Haralabos C.</forenames></author><author><keyname>Ramprashad</keyname><forenames>Sean A.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Joint Scheduling and ARQ for MU-MIMO Downlink in the Presence of
  Inter-Cell Interference</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications, v2: small
  corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User scheduling and multiuser multi-antenna (MU-MIMO) transmission are at the
core of high rate data-oriented downlink schemes of the next-generation of
cellular systems (e.g., LTE-Advanced). Scheduling selects groups of users
according to their channels vector directions and SINR levels. However, when
scheduling is applied independently in each cell, the inter-cell interference
(ICI) power at each user receiver is not known in advance since it changes at
each new scheduling slot depending on the scheduling decisions of all
interfering base stations. In order to cope with this uncertainty, we consider
the joint operation of scheduling, MU-MIMO beamforming and Automatic Repeat
reQuest (ARQ). We develop a game-theoretic framework for this problem and build
on stochastic optimization techniques in order to find optimal scheduling and
ARQ schemes. Particularizing our framework to the case of &quot;outage service
rates&quot;, we obtain a scheme based on adaptive variable-rate coding at the
physical layer, combined with ARQ at the Logical Link Control (ARQ-LLC). Then,
we present a novel scheme based on incremental redundancy Hybrid ARQ (HARQ)
that is able to achieve a throughput performance arbitrarily close to the
&quot;genie-aided service rates&quot;, with no need for a genie that provides
non-causally the ICI power levels. The novel HARQ scheme is both easier to
implement and superior in performance with respect to the conventional
combination of adaptive variable-rate coding and ARQ-LLC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1195</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1195</id><created>2010-01-07</created><updated>2010-07-18</updated><authors><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Chen</keyname><forenames>Zesheng</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author></authors><title>Characterizing Internet Worm Infection Structure</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet worm infection continues to be one of top security threats and has
been widely used by botnets to recruit new bots. In this work, we attempt to
quantify the infection ability of individual hosts and reveal the key
characteristics of the underlying topology formed by worm infection, i.e., the
number of children and the generation of the worm infection family tree.
Specifically, we first apply probabilistic modeling methods and a sequential
growth model to analyze the infection tree of a wide class of worms. We
analytically and empirically find that the number of children has
asymptotically a geometric distribution with parameter 0.5. As a result, on
average half of infected hosts never compromise any vulnerable host, over 98%
of infected hosts have no more than five children, and a small portion of
infected hosts have a large number of children. We also discover that the
generation follows closely a Poisson distribution and the average path length
of the worm infection family tree increases approximately logarithmically with
the total number of infected hosts. Next, we empirically study the infection
structure of localized-scanning worms and surprisingly find that most of the
above observations also apply to localized-scanning worms. Finally, we apply
our findings to develop bot detection methods and study potential
countermeasures for a botnet (e.g., Conficker C) that uses scan-based peer
discovery to form a P2P-based botnet. Specifically, we demonstrate that
targeted detection that focuses on the nodes with the largest number of
children is an efficient way to expose bots. For example, our simulation shows
that when 3.125% nodes are examined, targeted detection can reveal 22.36% bots.
However, we also point out that future botnets may limit the maximum number of
children to weaken targeted detection, without greatly slowing down the speed
of worm infection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1197</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1197</id><created>2010-01-08</created><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>Construction of wiretap codes from ordinary channel codes</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, no figure, IEEEtran.cls. Submitted to 2010 IEEE ISIT</comments><journal-ref>Proc. 2010 IEEE ISIT, pp. 2538-2542, Austin, Texas, USA, June
  13-18, 2010</journal-ref><doi>10.1109/ISIT.2010.5513794</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From an arbitrary given channel code over a discrete or Gaussian memoryless
channel, we construct a wiretap code with the strong security. Our construction
can achieve the wiretap capacity under mild assumptions. The key tool is the
new privacy amplification theorem bounding the eavesdropped information in
terms of the Gallager function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1199</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1199</id><created>2010-01-07</created><authors><author><keyname>Gebeshuber</keyname><forenames>I. C.</forenames></author><author><keyname>Majlis</keyname><forenames>B. Y</forenames></author></authors><title>New ways of scientific publishing and accessing human knowledge inspired
  by transdisciplinary approaches</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by interdisciplinary work touching biology and microtribology, the
authors propose a new, dynamic way of publishing research results, the
establishment of a tree of knowledge and the localisation of scientific
articles on this tree. 'Technomimetics' is proposed as a new method of
knowledge management in science and technology: it shall help find and organise
information in an era of over-information. Such ways of presenting and managing
research results would be accessible by people with different kinds of
backgrounds and levels of education, and allow for full use of the ever-
increasing number of scientific and technical publications. This approach would
dramatically change and revolutionize the way we are doing science, and
contribute to overcoming the three gaps between the world of ideas, inventors,
innovators and investors as introduced by Gebeshuber, Gruber and Drack in 2009
for accelerated scientific and technological breakthroughs to improve the human
condition. Inspiration for the development of above methods was the fact that -
generally - tribologists and biologists do not see many overlaps of their
professions. However, both deal with materials, structures and processes.
Tribology is omnipresent in biology and many biological systems have impressive
tribological properties. Tribologists can therefore get valuable input and
inspiration from living systems. The aim of biomimetics is knowledge transfer
from biology to technology and successful biomimetics in tribology needs
collaboration between biologists and tribologists. Literature search shows that
the number of papers regarding biotribology is steadily increasing. However, at
the moment, most scientific papers of the other respective field are hard to
access and hard to understand, in terms of concepts and specific wording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1210</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1210</id><created>2010-01-08</created><authors><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Dondi</keyname><forenames>Riccardo</forenames></author><author><keyname>Pirola</keyname><forenames>Yuri</forenames></author><author><keyname>Rizzi</keyname><forenames>Romeo</forenames></author></authors><title>Pure Parsimony Xor Haplotyping</title><categories>cs.CE cs.DS</categories><journal-ref>IEEE/ACM Trans. on Computational Biology and Bioinformatics 7.4
  (2010) 598-610</journal-ref><doi>10.1109/TCBB.2010.52</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The haplotype resolution from xor-genotype data has been recently formulated
as a new model for genetic studies. The xor-genotype data is a cheaply
obtainable type of data distinguishing heterozygous from homozygous sites
without identifying the homozygous alleles. In this paper we propose a
formulation based on a well-known model used in haplotype inference: pure
parsimony. We exhibit exact solutions of the problem by providing polynomial
time algorithms for some restricted cases and a fixed-parameter algorithm for
the general case. These results are based on some interesting combinatorial
properties of a graph representation of the solutions. Furthermore, we show
that the problem has a polynomial time k-approximation, where k is the maximum
number of xor-genotypes containing a given SNP. Finally, we propose a heuristic
and produce an experimental analysis showing that it scales to real-world large
instances taken from the HapMap project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1214</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1214</id><created>2010-01-08</created><authors><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>The Capacity of Finite-State Channels in the High-Noise Regime</title><categories>cs.IT math.IT</categories><comments>Extended version of research presented at: &quot;Entropy of Hidden Markov
  Processes and Connections to Dynamical Systems&quot;, Banff International Reseach
  Station (BIRS), October 5, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the derivative of the entropy rate of a hidden Markov
process with respect to the observation probabilities. The main result is a
compact formula for the derivative that can be evaluated easily using Monte
Carlo methods. It is applied to the problem of computing the capacity of a
finite-state channel (FSC) and, in the high-noise regime, the formula has a
simple closed-form expression that enables series expansion of the capacity of
a FSC. This expansion is evaluated for a binary-symmetric channel under a (0,1)
run-length limited constraint and an intersymbol-interference channel with
Gaussian noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1215</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1215</id><created>2010-01-08</created><authors><author><keyname>Manasa</keyname><forenames>Lakshmi</forenames></author><author><keyname>S</keyname><forenames>Krishna.</forenames></author></authors><title>Integer Reset Timed Automata: Clock Reduction and Determinizability</title><categories>cs.FL</categories><comments>submitted to LATA 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a procedure that given an integer reset timed
automaton (IRTA) ${\cal A}$, produces a language equivalent deterministic one
clock IRTA ${\cal B}$ whose size is at most doubly exponential in the size of
${\cal A}$. We prove that this bound on the number of locations is tight.
Further, if integer resets are used in stopwatch automata, a subclass of
stopwatch automata which is closed under all boolean operations and for which
reachability is decidable is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1221</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1221</id><created>2010-01-08</created><authors><author><keyname>Piro</keyname><forenames>Paolo</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Barlaud</keyname><forenames>Michel</forenames></author></authors><title>Boosting k-NN for categorization of natural scenes</title><categories>cs.CV</categories><comments>under revision for IJCV</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-nearest neighbors (k-NN) classification rule has proven extremely
successful in countless many computer vision applications. For example, image
categorization often relies on uniform voting among the nearest prototypes in
the space of descriptors. In spite of its good properties, the classic k-NN
rule suffers from high variance when dealing with sparse prototype datasets in
high dimensions. A few techniques have been proposed to improve k-NN
classification, which rely on either deforming the nearest neighborhood
relationship or modifying the input space. In this paper, we propose a novel
boosting algorithm, called UNN (Universal Nearest Neighbors), which induces
leveraged k-NN, thus generalizing the classic k-NN rule. We redefine the voting
rule as a strong classifier that linearly combines predictions from the k
closest prototypes. Weak classifiers are learned by UNN so as to minimize a
surrogate risk. A major feature of UNN is the ability to learn which prototypes
are the most relevant for a given class, thus allowing one for effective data
reduction. Experimental results on the synthetic two-class dataset of Ripley
show that such a filtering strategy is able to reject &quot;noisy&quot; prototypes. We
carried out image categorization experiments on a database containing eight
classes of natural scenes. We show that our method outperforms significantly
the classic k-NN classification, while enabling significant reduction of the
computational cost by means of data filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1231</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1231</id><created>2010-01-08</created><updated>2011-10-02</updated><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Saha</keyname><forenames>Barna</forenames></author><author><keyname>Srinivasan</keyname><forenames>Aravind</forenames></author></authors><title>New Constructive Aspects of the Lovasz Local Lemma</title><categories>cs.DS cs.DM</categories><comments>23 pages</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lov\'{a}sz Local Lemma (LLL) states that the probability that none of a
set of &quot;bad&quot; events happens is nonzero if the probability of each event is
small compared to the number of bad events it depends on. A series of results
have provided algorithms to efficiently construct structures whose existence is
(non-constructively) guaranteed by the full asymmetric LLL, culminating in the
recent breakthrough of Moser &amp; Tardos. We show that the output distribution of
the Moser-Tardos procedure has sufficient randomness, leading to two classes of
algorithmic applications. We first show that when an LLL application provides a
small amount of slack, the running time of the Moser-Tardos algorithm is
polynomial in the number of underlying independent variables (not events!), and
can thus be used to give efficient constructions in cases where the underlying
proof applies the LLL to super-polynomially many events (or where finding a bad
event that holds is computationally hard). We demonstrate our method on
applications including: the first constant-factor approximation algorithm for
the Santa Claus problem, as well as efficient algorithms for acyclic edge
coloring, non-repetitive graph colorings, and Ramsey-type graphs. Second, we
show applications to cases where a few of the bad events can hold, leading to
the first such algorithmic applications of the LLL: MAX $k$-SAT is an
illustrative example of this.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1232</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1232</id><created>2010-01-08</created><authors><author><keyname>Ripamonti</keyname><forenames>Laura A.</forenames></author></authors><title>Il rapporto tra ICT e PMI italiane e le problematiche
  economico-organizzative dell'OS</title><categories>cs.CY</categories><comments>59 pages, project technical report, in Italian</comments><report-no>RT 16-07</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This technical report summarizes the preliminary findings of a project that
has been developed in 2007 by an Italian company (Datanet, based in Siracusa,
Italy) togheter with two Italian research institutions: Universita' degli Studi
di Milano and Universita' Bocconi. The main aim of the OS4E (Open Source for
Enterprises) project, has been to investigate if and how open source solutions
could be profitabily and effectively exploited by an IT company based in the
South of Italy, whose core business is IT systems integration and which
operates in the market of Italian SMEs (Small and Medium Enterprises). Beside
this goal, the project also aimed at developing effective tools and
methodologies to support decision making processes while evaluating different
alternative software applications based on OSS (open source software).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1257</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1257</id><created>2010-01-08</created><authors><author><keyname>Barnabei</keyname><forenames>Graziano</forenames></author><author><keyname>Bagnoli</keyname><forenames>Franco</forenames></author><author><keyname>Conversano</keyname><forenames>Ciro</forenames></author><author><keyname>Lensi</keyname><forenames>Elena</forenames></author></authors><title>Decisional Processes with Boolean Neural Network: the Emergence of
  Mental Schemes</title><categories>cs.AI</categories><comments>11 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human decisional processes result from the employment of selected quantities
of relevant information, generally synthesized from environmental incoming data
and stored memories. Their main goal is the production of an appropriate and
adaptive response to a cognitive or behavioral task. Different strategies of
response production can be adopted, among which haphazard trials, formation of
mental schemes and heuristics. In this paper, we propose a model of Boolean
neural network that incorporates these strategies by recurring to global
optimization strategies during the learning session. The model characterizes as
well the passage from an unstructured/chaotic attractor neural network typical
of data-driven processes to a faster one, forward-only and representative of
schema-driven processes. Moreover, a simplified version of the Iowa Gambling
Task (IGT) is introduced in order to test the model. Our results match with
experimental data and point out some relevant knowledge coming from
psychological domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1269</identifier>
 <datestamp>2015-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1269</id><created>2010-01-08</created><updated>2010-07-26</updated><authors><author><keyname>Bauer</keyname><forenames>Ulrich</forenames></author><author><keyname>Lange</keyname><forenames>Carsten</forenames></author><author><keyname>Wardetzky</keyname><forenames>Max</forenames></author></authors><title>Optimal topological simplification of discrete functions on surfaces</title><categories>cs.CG math.CO math.GT</categories><comments>27 pages, 8 figures</comments><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Discrete and Computational Geometry 47:2 (2012), 347-377</journal-ref><doi>10.1007/s00454-011-9350-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the problem of minimizing the number of critical points among all
functions on a surface within a prescribed distance {\delta} from a given input
function. The result is achieved by establishing a connection between discrete
Morse theory and persistent homology. Our method completely removes homological
noise with persistence less than 2{\delta}, constructively proving the
tightness of a lower bound on the number of critical points given by the
stability theorem of persistent homology in dimension two for any input
function. We also show that an optimal solution can be computed in linear time
after persistence pairs have been computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1276</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1276</id><created>2010-01-08</created><authors><author><keyname>Idoudi</keyname><forenames>Nizar</forenames><affiliation>LITIS</affiliation></author><author><keyname>louati</keyname><forenames>Nada</forenames><affiliation>LITIS</affiliation></author><author><keyname>Duvallet</keyname><forenames>Claude</forenames><affiliation>LITIS</affiliation></author><author><keyname>Sadeg</keyname><forenames>Bruno</forenames><affiliation>LITIS</affiliation></author><author><keyname>Bouaziz</keyname><forenames>Rafik</forenames><affiliation>LITIS</affiliation></author><author><keyname>Gargouri</keyname><forenames>Faiez</forenames><affiliation>LITIS</affiliation></author></authors><title>A framework to model real-time databases</title><categories>cs.DB</categories><proxy>ccsd hal-00442320</proxy><journal-ref>International Journal of Computing and Information Sciences
  (IJCIS) 6, 1 (2008) On line</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time databases deal with time-constrained data and time-constrained
transactions. The design of this kind of databases requires the introduction of
new concepts to support both data structures and the dynamic behaviour of the
database. In this paper, we give an overview about different aspects of
real-time databases and we clarify requirements of their modelling. Then, we
present a framework for real-time database design and describe its fundamental
operations. A case study demonstrates the validity of the structural model and
illustrates SQL queries and Java code generated from the classes of the model
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1277</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1277</id><created>2010-01-08</created><authors><author><keyname>Quarez</keyname><forenames>Ronan</forenames><affiliation>IRMAR</affiliation></author></authors><title>Piecewise Certificates of Positivity for matrix polynomials</title><categories>math.RA cs.OH</categories><proxy>ccsd hal-00445256</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any symmetric positive definite homogeneous matrix polynomial
$M\in\R[x_1,...,x_n]^{m\times m}$ admits a piecewise semi-certificate, i.e. a
collection of identites $M(x)=\sum_jf_{i,j}(x)U_{i,j}(x)^TU_{i,j}(x)$ where
$U_{i,j}(x)$ is a matrix polynomial and $f_{i,j}(x)$ is a non negative
polynomial on a semi-algebraic subset $S_i$, where $\R^n=\cup_{i=1}^r S_i$.
This result generalizes to the setting of biforms. Some examples of
certificates are given and among others, we study a variation around the Choi
counterexample of a positive semi-definite biquadratic form which is not a sum
of squares. As a byproduct we give a representation of the famous non negative
sum of squares polynomial $x^4z^2+z^4y^2+y^4x^2-3 x^2y^2z^2$ as the determinant
of a positive semi-definite quadratic matrix polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1278</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1278</id><created>2010-01-08</created><authors><author><keyname>D'yachkov</keyname><forenames>A.</forenames></author><author><keyname>Voronina</keyname><forenames>A.</forenames></author><author><keyname>Macula</keyname><forenames>A.</forenames></author><author><keyname>Renz</keyname><forenames>T.</forenames></author><author><keyname>Rykov</keyname><forenames>V.</forenames></author></authors><title>On Critical Relative Distance of DNA Codes for Additive Stem Similarity</title><categories>cs.IT math.IT q-bio.BM q-bio.GN</categories><comments>5 or 6 pages (compiler-dependable), 0 figures, submitted to 2010 IEEE
  International Symposium on Information Theory (ISIT 2010), uses IEEEtran.cls</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider DNA codes based on the nearest-neighbor (stem) similarity model
which adequately reflects the &quot;hybridization potential&quot; of two DNA sequences.
Our aim is to present a survey of bounds on the rate of DNA codes with respect
to a thermodynamically motivated similarity measure called an additive stem
similarity. These results yield a method to analyze and compare known samples
of the nearest neighbor &quot;thermodynamic weights&quot; associated to stacked pairs
that occurred in DNA secondary structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1298</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1298</id><created>2010-01-08</created><authors><author><keyname>Huemer</keyname><forenames>Mario</forenames></author><author><keyname>Hofbauer</keyname><forenames>Christian</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>Coded OFDM by Unique Word Prefix</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, submitted to ISIT2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel transmit signal structure and an adjusted
and optimized receiver for OFDM (orthogonal frequency division multiplexing).
Instead of the conventional cyclic prefix we use a deterministic sequence,
which we call unique word (UW), as guard interval. We show how unique words,
which are already well investigated for single carrier systems with frequency
domain equalization (SC/FDE), can also be introduced in OFDM symbols. Since
unique words represent known sequences, they can advantageously be used for
synchronization and channel estimation purposes. Furthermore, the proposed
approach introduces a complex number Reed-Solomon (RS-) code structure within
the sequence of subcarriers. This allows for RS-decoding or to apply a highly
efficient Wiener smoother succeeding a zero forcing stage at the receiver. We
present simulation results in an indoor multipath environment to highlight the
advantageous properties of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1308</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1308</id><created>2010-01-08</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Knowledge-Based Innovation Systems and the Model of a Triple Helix of
  University-Industry-Government Relations</title><categories>cs.CY nlin.AO physics.soc-ph</categories><journal-ref>Paper presented at the Conference 'New Economic Windows: New
  Paradigms for the New Millennium', Salerno, Italy, September 2001</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The (neo-)evolutionary model of a Triple Helix of
University-Industry-Government Relations focuses on the overlay of
expectations, communications, and interactions that potentially feed back on
the institutional arrangements among the carrying agencies. From this
perspective, the evolutionary perspective in economics can be complemented with
the reflexive turn from sociology. The combination provides a richer
understanding of how knowledge-based systems of innovation are shaped and
reconstructed. The communicative capacities of the carrying agents become
crucial to the system's further development, whereas the institutional
arrangements (e.g., national systems) can be expected to remain under
reconstruction. The tension of the differentiation no longer needs to be
resolved, since the network configurations are reproduced by means of
translations among historically changing codes. Some methodological and
epistemological implications for studying innovation systems are explicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1315</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1315</id><created>2010-01-08</created><authors><author><keyname>Fujigaki</keyname><forenames>Yuko</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Quality Control and Validation Boundaries in a Triple Helix of
  University-Industry-Government: 'Mode 2' and the Future of University
  Research</title><categories>cs.CY cs.DL physics.soc-ph</categories><journal-ref>Social Science Information 39(4) (2000) 635-655</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How is quality control organized in the new &quot;Mode 2&quot; of the production of
scientific knowledge? When institutional boundaries are increasingly blurred in
a Triple Helix of University-Industry-Government relations, criteria for
quality control in the production of scientific knowledge can be expected to
change at the interfaces. The categorization in terms of two modes of knowledge
production was introduced by Gibbons et al. (1994) in order to describe changes
in the networks of scientific communications (funding patterns, research
configurations, styles of knowledge management, etc.). These changes were
mainly specified as institutional parameters in order to deal with the subjects
of R&amp;D management and S&amp;T policies, that is, ex ante (Spiegel-Ring 1973 Van den
Daele et al. 1979). We focus on the 'validation boundaries' emerging from the
differences between Mode 1 and Mode 2 that is, on the criteria for quality
control that can analytically and reflexively be brought to the fore ex post.
The shift from an institutional frame of reference to a focus on the dynamics
of communications enables us to clarify several problems in the discussion of
the future of university research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1320</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1320</id><created>2010-01-08</created><authors><author><keyname>Heimeriks</keyname><forenames>Gaston</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Besselaar</keyname><forenames>Peter Van den</forenames></author></authors><title>Distributed scientific communication in the European information
  society: Some cases of &quot;Mode 2&quot; fields of research</title><categories>cs.IR cs.DL physics.soc-ph</categories><journal-ref>Paper presented at Science &amp; Technology Indicators Conference,
  Leiden, May 2000</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can self-organization of scientific communication be specified by using
literature-based indicators? In this study, we explore this question by
applying entropy measures to typical &quot;Mode-2&quot; fields of knowledge production.
We hypothesized these scientific systems to be developing from a
self-organization of the interaction between cognitive and institutional
levels: European subsidized research programs aim at creating an institutional
network, while a cognitive reorganization is continuously ongoing at the
scientific field level. The results indicate that the European system develops
towards a stable level of distribution of cited references and title-words
among the European member states. We suggested that this distribution could be
a property of the emerging European system. In order to measure to degree of
specialization with respect to the respective distributions of countries, cited
references and title words, the mutual information among the three frequency
distributions was calculated. The so-called transmission values informed us
that the European system shows increasing levels of differentiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1373</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1373</id><created>2010-01-08</created><authors><author><keyname>Blasiak</keyname><forenames>Anna</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>The Serializability of Network Codes</title><categories>cs.IT cs.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding theory studies the transmission of information in networks
whose vertices may perform nontrivial encoding and decoding operations on data
as it passes through the network. The main approach to deciding the feasibility
of network coding problems aims to reduce the problem to optimization over a
polytope of entropic vectors subject to constraints imposed by the network
structure. In the case of directed acyclic graphs, these constraints are
completely understood, but for general graphs the problem of enumerating them
remains open: it is not known how to classify the constraints implied by a
property that we call serializability, which refers to the absence of
paradoxical circular dependencies in a network code.
  In this work we initiate the first systematic study of the constraints
imposed on a network code by serializability. We find that serializability
cannot be detected solely by evaluating the Shannon entropy of edge sets in the
graph, but nevertheless, we give a polynomial-time algorithm that decides the
serializability of a network code. We define a certificate of
non-serializability, called an information vortex, that plays a role in the
theory of serializability comparable to the role of fractional cuts in
multicommodity flow theory, including a type of min-max relation. Finally, we
study the serializability deficit of a network code, defined as the minimum
number of extra bits that must be sent in order to make it serializable. For
linear codes, we show that it is NP-hard to approximate this parameter within a
constant factor, and we demonstrate some surprising facts about the behavior of
this parameter under parallel composition of codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1374</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1374</id><created>2010-01-08</created><authors><author><keyname>Duursma</keyname><forenames>Iwan</forenames></author><author><keyname>Kirov</keyname><forenames>Radoslav</forenames></author><author><keyname>Park</keyname><forenames>Seungkook</forenames></author></authors><title>Distance bounds for algebraic geometric codes</title><categories>cs.IT math.AG math.IT</categories><comments>29 pages</comments><msc-class>11T71; 14G50; 94B</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various methods have been used to obtain improvements of the Goppa lower
bound for the minimum distance of an algebraic geometric code. The main methods
divide into two categories and all but a few of the known bounds are special
cases of either the Lundell-McCullough floor bound or the Beelen order bound.
The exceptions are recent improvements of the floor bound by
Guneri-Stichtenoth-Taskin, and Duursma-Park, and of the order bound by
Duursma-Park and Duursma-Kirov. In this paper we provide short proofs for all
floor bounds and most order bounds in the setting of the van Lint and Wilson AB
method. Moreover, we formulate unifying theorems for order bounds and formulate
the DP and DK order bounds as natural but different generalizations of the
Feng-Rao bound for one-point codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1386</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1386</id><created>2010-01-08</created><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Hastad</keyname><forenames>Johan</forenames></author><author><keyname>Kopparty</keyname><forenames>Swastik</forenames></author></authors><title>On the List-Decodability of Random Linear Codes</title><categories>cs.IT math.CO math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every fixed finite field $\F_q$, $p \in (0,1-1/q)$ and $\epsilon &gt; 0$, we
prove that with high probability a random subspace $C$ of $\F_q^n$ of dimension
$(1-H_q(p)-\epsilon)n$ has the property that every Hamming ball of radius $pn$
has at most $O(1/\epsilon)$ codewords.
  This answers a basic open question concerning the list-decodability of linear
codes, showing that a list size of $O(1/\epsilon)$ suffices to have rate within
$\epsilon$ of the &quot;capacity&quot; $1-H_q(p)$. Our result matches up to constant
factors the list-size achieved by general random codes, and gives an
exponential improvement over the best previously known list-size bound of
$q^{O(1/\epsilon)}$.
  The main technical ingredient in our proof is a strong upper bound on the
probability that $\ell$ random vectors chosen from a Hamming ball centered at
the origin have too many (more than $\Theta(\ell)$) vectors from their linear
span also belong to the ball.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1389</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1389</id><created>2010-01-08</created><authors><author><keyname>Li</keyname><forenames>Jiangyuan</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author></authors><title>Optimal Cooperative Relaying Schemes for Improving Wireless Physical
  Layer Security</title><categories>cs.IT math.IT</categories><comments>30 pages, 8 figures</comments><doi>10.1109/TSP.2011.2159598</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cooperative wireless network in the presence of one of more
eavesdroppers, and exploit node cooperation for achieving physical (PHY) layer
based security. Two different cooperation schemes are considered. In the first
scheme, cooperating nodes retransmit a weighted version of the source signal in
a decode-and-forward (DF) fashion. In the second scheme, while the source is
transmitting, cooperating nodes transmit weighted noise to confound the
eavesdropper (cooperative jamming (CJ)). We investigate two objectives, i.e.,
maximization of achievable secrecy rate subject to a total power constraint,
and minimization of total power transmit power under a secrecy rate constraint.
For the first design objective with a single eavesdropper we obtain expressions
for optimal weights under the DF protocol in closed form, and give an algorithm
that converges to the optimal solution for the CJ scheme; while for multiple
eavesdroppers we give an algorithm for the solution using the DF protocol that
is guaranteed to converge to the optimal solution for two eavesdroppers. For
the second design objective, existing works introduced additional constraints
in order to reduce the degree of difficulty, thus resulting in suboptimal
solutions. In this work, either a closed form solution is obtained, or
algorithms to search for the solution are proposed. Numerical results are
presented to illustrate the proposed schemes and demonstrate the advantages of
cooperation as compared to direct transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1393</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1393</id><created>2010-01-08</created><authors><author><keyname>Yang</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Xingang</forenames></author><author><keyname>Li</keyname><forenames>Yao</forenames></author><author><keyname>Sheng</keyname><forenames>Zhengmao</forenames></author></authors><title>On the pinning strategy of complex networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.NI</categories><doi>10.1209/0295-5075/92/48002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In pinning control of complex networks, a tacit believing is that the system
dynamics will be better controlled by pinning the large-degree nodes than the
small-degree ones. Here, by changing the number of pinned nodes, we find that,
when a significant fraction of the network nodes are pinned, pinning the
small-degree nodes could generally have a higher performance than pinning the
large-degree nodes. We demonstrate this interesting phenomenon on a variety of
complex networks, and analyze the underlying mechanisms by the model of star
networks. By changing the network properties, we also find that, comparing to
densely connected homogeneous networks, the advantage of the small-degree
pinning strategy is more distinct in sparsely connected heterogenous networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1401</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1401</id><created>2010-01-08</created><authors><author><keyname>DiPaola</keyname><forenames>Steve</forenames></author><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>Incorporating characteristics of human creativity into an evolutionary
  art algorithm</title><categories>cs.AI cs.NE q-bio.NC</categories><journal-ref>DiPaola, S. &amp; Gabora, L. (2009). Incorporating characteristics of
  human creativity into an evolutionary art algorithm. Genetic Programming and
  Evolvable Machines, 10(2), 97-110</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A perceived limitation of evolutionary art and design algorithms is that they
rely on human intervention; the artist selects the most aesthetically pleasing
variants of one generation to produce the next. This paper discusses how
computer generated art and design can become more creatively human-like with
respect to both process and outcome. As an example of a step in this direction,
we present an algorithm that overcomes the above limitation by employing an
automatic fitness function. The goal is to evolve abstract portraits of Darwin,
using our 2nd generation fitness function which rewards genomes that not just
produce a likeness of Darwin but exhibit certain strategies characteristic of
human artists. We note that in human creativity, change is less choosing
amongst randomly generated variants and more capitalizing on the associative
structure of a conceptual network to hone in on a vision. We discuss how to
achieve this fluidity algorithmically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1414</identifier>
 <datestamp>2010-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1414</id><created>2010-01-09</created><updated>2010-01-17</updated><authors><author><keyname>Sarma</keyname><forenames>Akash Das</forenames></author><author><keyname>Gujar</keyname><forenames>Sujit</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author></authors><title>Multi-Armed Bandit Mechanisms for Multi-Slot Sponsored Search Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In pay-per click sponsored search auctions which are currently extensively
used by search engines, the auction for a keyword involves a certain number of
advertisers (say k) competing for available slots (say m) to display their ads.
This auction is typically conducted for a number of rounds (say T). There are
click probabilities mu_ij associated with each agent-slot pairs. The goal of
the search engine is to maximize social welfare of the advertisers, that is,
the sum of values of the advertisers. The search engine does not know the true
values advertisers have for a click to their respective ads and also does not
know the click probabilities mu_ij s. A key problem for the search engine
therefore is to learn these click probabilities during the T rounds of the
auction and also to ensure that the auction mechanism is truthful. Mechanisms
for addressing such learning and incentives issues have recently been
introduced and are aptly referred to as multi-armed-bandit (MAB) mechanisms.
When m = 1, characterizations for truthful MAB mechanisms are available in the
literature and it has been shown that the regret for such mechanisms will be
O(T^{2/3}). In this paper, we seek to derive a characterization in the
realistic but non-trivial general case when m &gt; 1 and obtain several
interesting results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1435</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1435</id><created>2010-01-09</created><updated>2015-05-18</updated><authors><author><keyname>Casteigts</keyname><forenames>Arnaud</forenames></author></authors><title>JBotSim, a Tool for Fast Prototyping of Distributed Algorithms in
  Dynamic Networks</title><categories>cs.MS cs.DC cs.NI</categories><comments>A shorter version appeared in SIMUTOOLS 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  JBotSim is a java library that offers basic primitives for prototyping,
running, and visualizing distributed algorithms in dynamic networks. With
JBotSim, one can implement an idea in minutes and interact with it ({\it e.g.},
add, move, or delete nodes) while it is running. JBotSim is well suited to
prepare live demonstrations of your algorithms to colleagues or students; it
can also be used to evaluate performance at the algorithmic level (number of
messages, number of rounds, etc.). Unlike most tools, JBotSim is not an
integrated environment. It is a lightweight library to be used in your program.
In this paper, we present an overview of its distinctive features and
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1445</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1445</id><created>2010-01-09</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Graph-Constrained Group Testing</title><categories>cs.DM cs.IT math.IT</categories><comments>Full version to appear in IEEE Transactions on Information Theory. A
  preliminary summary of this work appeared (under the same title) in
  proceedings of the 2010 IEEE International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-adaptive group testing involves grouping arbitrary subsets of $n$ items
into different pools. Each pool is then tested and defective items are
identified. A fundamental question involves minimizing the number of pools
required to identify at most $d$ defective items. Motivated by applications in
network tomography, sensor networks and infection propagation, a variation of
group testing problems on graphs is formulated. Unlike conventional group
testing problems, each group here must conform to the constraints imposed by a
graph. For instance, items can be associated with vertices and each pool is any
set of nodes that must be path connected. In this paper, a test is associated
with a random walk. In this context, conventional group testing corresponds to
the special case of a complete graph on $n$ vertices.
  For interesting classes of graphs a rather surprising result is obtained,
namely, that the number of tests required to identify $d$ defective items is
substantially similar to what is required in conventional group testing
problems, where no such constraints on pooling is imposed. Specifically, if
T(n) corresponds to the mixing time of the graph $G$, it is shown that with
$m=O(d^2T^2(n)\log(n/d))$ non-adaptive tests, one can identify the defective
items. Consequently, for the Erdos-Renyi random graph $G(n,p)$, as well as
expander graphs with constant spectral gap, it follows that $m=O(d^2\log^3n)$
non-adaptive tests are sufficient to identify $d$ defective items. Next, a
specific scenario is considered that arises in network tomography, for which it
is shown that $m=O(d^3\log^3n)$ non-adaptive tests are sufficient to identify
$d$ defective items. Noisy counterparts of the graph constrained group testing
problem are considered, for which parallel results are developed. We also
briefly discuss extensions to compressive sensing on graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1446</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1446</id><created>2010-01-09</created><authors><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Marin</forenames></author></authors><title>Using Financial Ratios to Identify Romanian Distressed Companies</title><categories>q-fin.PM cs.CE q-bio.GN</categories><comments>ISSN: 1454-0320</comments><acm-class>J.1; J.4; K.6.0</acm-class><journal-ref>Economy Journal - Series Management, vol. 12, special issue no. 1,
  pp. 46-55, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of the current financial crisis, when more companies are
facing bankruptcy or insolvency, the paper aims to find methods to identify
distressed firms by using financial ratios. The study will focus on identifying
a group of Romanian listed companies, for which financial data for the year
2008 were available. For each company a set of 14 financial indicators was
calculated and then used in a principal component analysis, followed by a
cluster analysis, a logit model, and a CHAID classification tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1451</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1451</id><created>2010-01-09</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Efficient Upload Bandwidth Estimation and Communication Resource
  Allocation Techniques</title><categories>cs.NI cs.DC cs.DS</categories><comments>Proceedings of the 9th WSEAS International Conference on Multimedia,
  Internet &amp; Video Technologies (MIV), Budapest, Hungary, 3-5 September, 2009;
  ISBN: 978-960-474-114-4 / ISSN: 1790-5109</comments><acm-class>C.2.1; C.2.2; C.2.4; G.2.1; G.2.2</acm-class><journal-ref>Recent Advances in Signals &amp; Systems, pp. 186-191, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address two problems, for which we present novel, efficient,
algorithmic solutions. The first problem is motivated by practical situations
and is concerned with the efficient estimation of the upload bandwidth of a
machine, particularly in the context of a peer-to-peer content sharing and
distribution application. The second problem is more of a theoretical nature
and considers a constrained communication resource allocation situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1454</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1454</id><created>2010-01-09</created><authors><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Cataniciu</keyname><forenames>Nicolae</forenames></author></authors><title>Multidimensional Data Structures and Techniques for Efficient Decision
  Making</title><categories>cs.CG cs.DB cs.DS</categories><acm-class>E.1; H.3.3</acm-class><journal-ref>Proc. of the 10th WSEAS Intl. Conf. on Mathematics and Computers
  in Business and Economics (MCBE), pp. 249-254, Prague, Czech Republic, 23-25
  March, 2009. (ISBN: 978-960-474-063-5 / ISSN: 1790-5109)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present several novel efficient techniques and
multidimensional data structures which can improve the decision making process
in many domains. We consider online range aggregation, range selection and
range weighted median queries; for most of them, the presented data structures
and techniques can provide answers in polylogarithmic time. The presented
results have applications in many business and economic scenarios, some of
which are described in detail in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1468</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1468</id><created>2010-01-10</created><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Wang</keyname><forenames>Zizhou Vincent</forenames></author><author><keyname>Geng</keyname><forenames>Yanlin</forenames></author></authors><title>An information inequality and evaluation of Marton's inner bound for
  binary input broadcast channels</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish an information inequality that is intimately connected to the
evaluation of the sum rate given by Marton's inner bound for two receiver
broadcast channels with a binary input alphabet. This generalizes a recent
result where the inequality was established for a particular channel, the
binary skew-symmetric broadcast channel. The inequality implies that randomized
time-division strategy indeed achieves the sum rate of Marton's inner bound for
all binary input broadcast channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1470</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1470</id><created>2010-01-10</created><authors><author><keyname>Saha</keyname><forenames>Barna</forenames></author><author><keyname>Srinivasan</keyname><forenames>Aravind</forenames></author></authors><title>A New Approximation Technique for Resource-Allocation Problems</title><categories>cs.DS cs.DC</categories><comments>Proceedings of Innovations in Computer Science (ICS) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a rounding method based on random walks in polytopes, which leads
to improved approximation algorithms and integrality gaps for several
assignment problems that arise in resource allocation and scheduling. In
particular, it generalizes the work of Shmoys &amp; Tardos on the generalized
assignment problem in two different directions, where the machines have hard
capacities, and where some jobs can be dropped. We also outline possible
applications and connections of this methodology to discrepancy theory and
iterated rounding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1478</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1478</id><created>2010-01-10</created><authors><author><keyname>Niu</keyname><forenames>Bo</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Somekh</keyname><forenames>Oren</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author></authors><title>Ergodic and Outage Performance of Fading Broadcast Channels with 1-Bit
  Feedback</title><categories>cs.IT math.IT</categories><comments>11 pages, 5 figures, to appear in IEEE Transactions on Vehicular
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the ergodic sum-rate and outage probability of a downlink
single-antenna channel with K users are analyzed in the presence of Rayleigh
flat fading, where limited channel state information (CSI) feedback is assumed.
Specifically, only 1-bit feedback per fading block per user is available at the
base station. We first study the ergodic sum-rate of the 1-bit feedback scheme,
and consider the impact of feedback delay on the system. A closed-form
expression for the achievable ergodic sum-rate is presented as a function of
the fading temporal correlation coefficient. It is proved that the sum-rate
scales as loglogK, which is the same scaling law achieved by the optimal
non-delayed full CSI feedback scheme. The sum-rate degradation due to outdated
CSI is also evaluated in the asymptotic regimes of either large K or low SNR.
The outage performance of the 1-bit feedback scheme for both instantaneous and
outdated feedback is then investigated. Expressions for the outage
probabilities are derived, along with the corresponding diversity-multiplexing
tradeoffs (DMT). It is shown that with instantaneous feedback, a power
allocation based on the feedback bits enables to double the DMT compared to the
case with short-term power constraint in which a dynamic power allocation is
not allowed. But, with outdated feedback, the advantage of power allocation is
lost, and the DMT reverts to that achievable with no CSI feedback.
Nevertheless, for finite SNR, improvement in terms of outage probability can
still be obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1482</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1482</id><created>2010-01-10</created><updated>2010-01-20</updated><authors><author><keyname>Ali</keyname><forenames>Olfa Ben Sik</forenames></author><author><keyname>Cardinal</keyname><forenames>Christian</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>Performance of Optimum Combining in a Poisson Field of Interferers and
  Rayleigh Fading Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Wireless Communication (Jan. 2009)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper studies the performance of antenna array processing in distributed
multiple access networks without power control. The interference is represented
as a Poisson point process. Desired and interfering signals are subject to both
path-loss fading (with an exponent greater than 2) and to independent Rayleigh
fading. Using these assumptions, we derive the exact closed form expression for
the cumulative distribution function of the output
signal-to-interference-plus-noise ratio when optimum combining is applied. This
results in a pertinent measure of the network performance in terms of the
outage probability, which in turn provides insights into the network capacity
gain that could be achieved with antenna array processing. We present and
discuss examples of applications, as well as some numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1526</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1526</id><created>2010-01-10</created><authors><author><keyname>Basciftci</keyname><forenames>Fatih</forenames></author><author><keyname>Kahramanli</keyname><forenames>Sirzat</forenames></author></authors><title>A Reduced Offset Based Method for Fast Computation of the Prime
  Implicants Covering a Given Cube</title><categories>cs.DS cs.LO</categories><comments>35 pages, no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to generate prime implicants for a given cube (minterm), most of
minimization methods increase the dimension of this cube by removing one
literal from it at a time. But there are two problems of exponential
complexity. One of them is the selection of the order in which the literals are
to be removed from the implicant at hand. The latter is the mechanism that
checks whether a tentative literal removal is acceptable. The reduced Offset
concept has been developed to avoid of these problems. This concept is based on
positional-cube representation where each cube is represented by two n-bit
strings. We show that each reduced Off-cube may be represented by a single
n-bit string and propose a set of bitwise operations to be performed on such
strings. The experiments on single-output benchmarks show that this approach
can significantly speed up the minimization process, improve the quality of its
results and reduce the amount of memory required for this aim.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1565</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1565</id><created>2010-01-11</created><updated>2013-10-29</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Landau</keyname><forenames>Gad M.</forenames></author><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author><author><keyname>Sadakane</keyname><forenames>Kunihiko</forenames></author><author><keyname>Satti</keyname><forenames>Srinivasa Rao</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>Random Access to Grammar Compressed Strings</title><categories>cs.DS</categories><comments>Preliminary version in SODA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grammar based compression, where one replaces a long string by a small
context-free grammar that generates the string, is a simple and powerful
paradigm that captures many popular compression schemes. In this paper, we
present a novel grammar representation that allows efficient random access to
any character or substring without decompressing the string.
  Let $S$ be a string of length $N$ compressed into a context-free grammar
$\mathcal{S}$ of size $n$. We present two representations of $\mathcal{S}$
achieving $O(\log N)$ random access time, and either $O(n\cdot \alpha_k(n))$
construction time and space on the pointer machine model, or $O(n)$
construction time and space on the RAM. Here, $\alpha_k(n)$ is the inverse of
the $k^{th}$ row of Ackermann's function. Our representations also efficiently
support decompression of any substring in $S$: we can decompress any substring
of length $m$ in the same complexity as a single random access query and
additional $O(m)$ time. Combining these results with fast algorithms for
uncompressed approximate string matching leads to several efficient algorithms
for approximate string matching on grammar-compressed strings without
decompression. For instance, we can find all approximate occurrences of a
pattern $P$ with at most $k$ errors in time $O(n(\min\{|P|k, k^4 + |P|\} + \log
N) + occ)$, where $occ$ is the number of occurrences of $P$ in $S$. Finally, we
generalize our results to navigation and other operations on grammar-compressed
ordered trees.
  All of the above bounds significantly improve the currently best known
results. To achieve these bounds, we introduce several new techniques and data
structures of independent interest, including a predecessor data structure, two
&quot;biased&quot; weighted ancestor data structures, and a compact representation of
heavy paths in grammars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1593</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1593</id><created>2010-01-11</created><authors><author><keyname>Gopalan</keyname><forenames>P.</forenames></author><author><keyname>O'Donnell</keyname><forenames>R.</forenames></author><author><keyname>Wu</keyname><forenames>Y.</forenames></author><author><keyname>Zuckerman</keyname><forenames>D.</forenames></author></authors><title>Fooling functions of halfspaces under product distributions</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct pseudorandom generators that fool functions of halfspaces
(threshold functions) under a very broad class of product distributions. This
class includes not only familiar cases such as the uniform distribution on the
discrete cube, the uniform distribution on the solid cube, and the multivariate
Gaussian distribution, but also includes any product of discrete distributions
with probabilities bounded away from 0.
  Our first main result shows that a recent pseudorandom generator construction
of Meka and Zuckerman [MZ09], when suitably modifed, can fool arbitrary
functions of d halfspaces under product distributions where each coordinate has
bounded fourth moment. To eps-fool any size-s, depth-d decision tree of
halfspaces, our pseudorandom generator uses seed length O((d log(ds/eps)+log n)
log(ds/eps)). For monotone functions of d halfspaces, the seed length can be
improved to O((d log(d/eps)+log n) log(d/eps)). We get better bounds for larger
eps; for example, to 1/polylog(n)-fool all monotone functions of (log n)= log
log n halfspaces, our generator requires a seed of length just O(log n). Our
second main result generalizes the work of Diakonikolas et al. [DGJ+09] to show
that bounded independence suffices to fool functions of halfspaces under
product distributions. Assuming each coordinate satisfies a certain stronger
moment condition, we show that any function computable by a size-s, depth-d
decision tree of halfspaces is eps-fooled by O(d^4s^2/eps^2)-wise independence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1597</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1597</id><created>2010-01-11</created><updated>2010-08-19</updated><authors><author><keyname>Norton</keyname><forenames>Graham H.</forenames></author></authors><title>The Berlekamp-Massey Algorithm via Minimal Polynomials</title><categories>cs.IT cs.SC math.IT</categories><comments>Major revision of earlier versions: Introduction expanded, main
  theorem is now a recursive construction using a recursively defined index
  function and is relative to any element of $D$. Includes some simpler proofs,
  a recursive Berlekamp-Massey 'theorem' and additional references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a recursive minimal polynomial theorem for finite sequences over a
commutative integral domain $D$. This theorem is relative to any element of
$D$. The ingredients are: the arithmetic of Laurent polynomials over $D$, a
recursive 'index function' and simple mathematical induction. Taking
reciprocals gives a 'Berlekamp-Massey theorem' i.e. a recursive construction of
the polynomials arising in the Berlekamp-Massey algorithm, relative to any
element of $D$. The recursive theorem readily yields the iterative minimal
polynomial algorithm due to the author and a transparent derivation of the
iterative Berlekamp-Massey algorithm.
  We give an upper bound for the sum of the linear complexities of $s$ which is
tight if $s$ has a perfect linear complexity profile. This implies that over a
field, both iterative algorithms require at most $2\lfloor
\frac{n^2}{4}\rfloor$ multiplications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1603</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1603</id><created>2010-01-11</created><authors><author><keyname>Nordman</keyname><forenames>Risto</forenames></author></authors><title>Soft Decision Decoding of the Orthogonal Complex MIMO Codes for Three
  and Four Transmit Antennas</title><categories>cs.IT math.IT</categories><comments>12 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory 9 Dec. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonality is a much desired property for MIMO coding. It enables
symbol-wise decoding, where the errors in other symbol estimates do not affect
the result, thus providing an optimality that is worth pursuing. Another
beneficial property is a low complexity soft decision decoder, which for
orthogonal complex MIMO codes is known for two transmit (Tx) antennas i.e. for
the Alamouti code. We propose novel soft decision decoders for the orthogonal
complex MIMO codes on three and four Tx antennas and extend the old result of
maximal ratio combining (MRC) to cover all orthogonal codes up to four Tx
antennas.
  As a rule, a sophisticated transmission scheme encompasses forward error
correction (FEC) coding, and its performance is measured at the FEC decoder
instead of at the MIMO decoder. We introduce the receiver structure that
delivers the MIMO decoder's soft decisions to the demodulator, which in turn
cranks out the logarithm of likelihood ratio (LLR) of each bit and delivers
them to the FEC decoder. This makes a significant improvement on the receiver,
where a maximum likelihood (ML) MIMO decoder makes hard decisions at a too
early stage. Further, the additional gain is achieved with stunningly low
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1610</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1610</id><created>2010-01-11</created><updated>2011-04-10</updated><authors><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Steps towards a theory and calculus of aliasing</title><categories>cs.SE cs.PL</categories><comments>Revision of original JOT paper. To appear in IJSI (International
  Journal of Software and Informatics) in 2011. The original title was: The
  theory and calculus of aliasing</comments><report-no>ISSN 1673-7288</report-no><acm-class>D.1.5; D.2.4; F.3.1; F.3.2; F.3.3; F.3.1; F.4.1</acm-class><journal-ref>International Journal of Software and Informaticsspecial issue
  (Festschrift in honor of Manfred Broy), Chinese Academy of Sciences, 2011,
  pages 77-116</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theory, graphical notation, mathematical calculus and implementation for
finding whether two given expressions can, at execution time, denote references
attached to the same object. Intended as the basis for a comprehensive solution
to the &quot;frame problem&quot; and as a complement to, or even a replacement for,
separation logic, shape analysis, ownership types and dynamic frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1624</identifier>
 <datestamp>2013-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1624</id><created>2010-01-11</created><updated>2010-10-05</updated><authors><author><keyname>Binder</keyname><forenames>Thomas</forenames></author><author><keyname>Martinetz</keyname><forenames>Thomas</forenames></author></authors><title>On the boundedness of an iteration involving points on the hypersphere</title><categories>cs.CG</categories><journal-ref>Int. J. Comp. Geom. Appl. 22 (2012) 499-515</journal-ref><doi>10.1142/S0218195912500136</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a finite set of points $X$ on the unit hypersphere in $\mathbb{R}^d$ we
consider the iteration $u_{i+1}=u_i+\chi_i$, where $\chi_i$ is the point of $X$
farthest from $u_i$. Restricting to the case where the origin is contained in
the convex hull of $X$ we study the maximal length of $u_i$. We give sharp
upper bounds for the length of $u_i$ independently of $X$. Precisely, this
upper bound is infinity for $d\ge 3$ and $\sqrt2$ for $d=2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1625</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1625</id><created>2010-01-11</created><authors><author><keyname>Luzzi</keyname><forenames>Laura</forenames></author><author><keyname>Othman</keyname><forenames>Ghaya Rekaya-Ben</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Augmented Lattice Reduction for MIMO decoding</title><categories>cs.IT math.IT</categories><comments>6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice reduction algorithms, such as the LLL algorithm, have been proposed
as preprocessing tools in order to enhance the performance of suboptimal
receivers in MIMO communications. In this paper we introduce a new kind of
lattice reduction-aided decoding technique, called augmented lattice reduction,
which recovers the transmitted vector directly from the change of basis matrix,
and therefore doesn't entail the computation of the pseudo-inverse of the
channel matrix or its QR decomposition. We prove that augmented lattice
reduction attains the maximum receive diversity order of the channel;
simulation results evidence that it significantly outperforms LLL-SIC detection
without entailing any additional complexity. A theoretical bound on the
complexity is also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1653</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1653</id><created>2010-01-11</created><authors><author><keyname>Shafer</keyname><forenames>Glenn</forenames></author></authors><title>A betting interpretation for probabilities and Dempster-Shafer degrees
  of belief</title><categories>math.ST cs.AI stat.TH</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are at least two ways to interpret numerical degrees of belief in terms
of betting: (1) you can offer to bet at the odds defined by the degrees of
belief, or (2) you can judge that a strategy for taking advantage of such
betting offers will not multiply the capital it risks by a large factor. Both
interpretations can be applied to ordinary additive probabilities and used to
justify updating by conditioning. Only the second can be applied to
Dempster-Shafer degrees of belief and used to justify Dempster's rule of
combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1654</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1654</id><created>2010-01-11</created><updated>2010-02-19</updated><authors><author><keyname>Walter</keyname><forenames>S. F.</forenames></author><author><keyname>Lehmann</keyname><forenames>L.</forenames></author></authors><title>Algorithmic Differentiation of Linear Algebra Functions with Application
  in Optimum Experimental Design (Extended Version)</title><categories>cs.DS cs.MS math.NA</categories><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive algorithms for higher order derivative computation of the
rectangular $QR$ and eigenvalue decomposition of symmetric matrices with
distinct eigenvalues in the forward and reverse mode of algorithmic
differentiation (AD) using univariate Taylor propagation of matrices (UTPM).
Linear algebra functions are regarded as elementary functions and not as
algorithms. The presented algorithms are implemented in the BSD licensed AD
tool \texttt{ALGOPY}. Numerical tests show that the UTPM algorithms derived in
this paper produce results close to machine precision accuracy. The theory
developed in this paper is applied to compute the gradient of an objective
function motivated from optimum experimental design: $\nabla_x
\Phi(C(J(F(x,y))))$, where $\Phi = \{\lambda_1 : \lambda_1 C\}$, $C = (J^T
J)^{-1}$, $J = \frac{\dd F}{\dd y}$ and $F = F(x,y)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1658</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1658</id><created>2010-01-11</created><updated>2010-11-16</updated><authors><author><keyname>Siavoshani</keyname><forenames>Mahdi Jafari</forenames></author><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>On the Capacity of Non-Coherent Network Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of multicasting information from a source to a set of
receivers over a network where intermediate network nodes perform randomized
network coding operations on the source packets. We propose a channel model for
the non-coherent network coding introduced by Koetter and Kschischang in [6],
that captures the essence of such a network operation, and calculate the
capacity as a function of network parameters. We prove that use of subspace
coding is optimal, and show that, in some cases, the capacity-achieving
distribution uses subspaces of several dimensions, where the employed
dimensions depend on the packet length. This model and the results also allow
us to give guidelines on when subspace coding is beneficial for the proposed
model and by how much, in comparison to a coding vector approach, from a
capacity viewpoint. We extend our results to the case of multiple source
multicast that creates a virtual multiple access channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1662</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1662</id><created>2010-01-11</created><updated>2011-05-20</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Fousse</keyname><forenames>Laurent</forenames><affiliation>LJK</affiliation></author><author><keyname>Reynaud</keyname><forenames>Jean-Claude</forenames><affiliation>RC</affiliation></author></authors><title>States and exceptions considered as dual effects</title><categories>cs.LO math.CT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the two major computational effects of states and
exceptions, from the point of view of diagrammatic logics. We get a surprising
result: there exists a symmetry between these two effects, based on the
well-known categorical duality between products and coproducts. More precisely,
the lookup and update operations for states are respectively dual to the throw
and catch operations for exceptions. This symmetry is deeply hidden in the
programming languages; in order to unveil it, we start from the monoidal
equational logic and we add progressively the logical features which are
necessary for dealing with either effect. This approach gives rise to a new
point of view on states and exceptions, which bypasses the problems due to the
non-algebraicity of handling exceptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1679</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1679</id><created>2010-01-11</created><authors><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Cascade and Triangular Source Coding with Side Information at the First
  Two Nodes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the cascade and triangular rate-distortion problem where side
information is known to the source encoder and to the first user but not to the
second user. We characterize the rate-distortion region for these problems. For
the quadratic Gaussian case, we show that it is sufficient to consider jointly
Gaussian distributions, a fact that leads to an explicit solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1685</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1685</id><created>2010-01-11</created><authors><author><keyname>Gwizdka</keyname><forenames>Jacek</forenames></author></authors><title>Assessing Cognitive Load on Web Search Tasks</title><categories>cs.HC cs.IR</categories><comments>Published in the special issue Hot Topic: Cognition and the Web</comments><journal-ref>Ergonomics Open Journal 2, 2009, 114-123</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assessing cognitive load on web search is useful for characterizing search
system features and search tasks with respect to their demands on the
searcher's mental effort. It is also helpful for examining how individual
differences among searchers (e.g. cognitive abilities) affect the search
process. We examined cognitive load from the perspective of primary and
secondary task performance. A controlled web search study was conducted with 48
participants. The primary task performance components were found to be
significantly related to both the objective and the subjective task difficulty.
However, the relationship between objective and subjective task difficulty and
the secondary task performance measures was weaker than expected. The results
indicate that the dual-task approach needs to be used with caution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1686</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1686</id><created>2010-01-11</created><updated>2010-04-20</updated><authors><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Leonardi</keyname><forenames>Stefano</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author></authors><title>Combinatorial Auctions with Budgets</title><categories>cs.GT cs.DS</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider budget constrained combinatorial auctions where bidder $i$ has a
private value $v_i$, a budget $b_i$, and is interested in all the items in
$S_i$. The value to agent $i$ of a set of items $R$ is $|R \cap S_i| \cdot
v_i$. Such auctions capture adword auctions, where advertisers offer a bid for
ads in response to an advertiser-dependent set of adwords, and advertisers have
budgets. It is known that even of all items are identical and all budgets are
public it is not possible to be truthful and efficient. Our main result is a
novel auction that runs in polynomial time, is incentive compatible, and
ensures Pareto-optimality for such auctions when the valuations are private and
the budgets are public knowledge. This extends the result of Dobzinski et al.
(FOCS 2008) for auctions of multiple {\sl identical} items and public budgets
to single-valued {\sl combinatorial} auctions with public budgets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1705</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1705</id><created>2010-01-11</created><authors><author><keyname>Zumbragel</keyname><forenames>Jens</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author></authors><title>On the Pseudocodeword Redundancy</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the AWGNC, BSC, and max-fractional pseudocodeword redundancy of a
code as the smallest number of rows in a parity-check matrix such that the
corresponding minimum pseudoweight is equal to the minimum Hamming distance. We
show that most codes do not have a finite pseudocodeword redundancy. We also
provide bounds on the pseudocodeword redundancy for some families of codes,
including codes based on designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1711</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1711</id><created>2010-01-11</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Internet voting protocol based on implicit data security</title><categories>cs.CR</categories><comments>4 pages</comments><journal-ref>Proceedings of 17th International Conference on Computer
  Communications and Networks 2008. ICCCN 08, Pages 1-4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new protocol for Internet voting based on implicit data
security. This protocol allows recasting of votes, which permits a change of
mind by voters either during the time window over which polling is open or
during a shorter period over which recasting is permitted. The security of
votes depends on multiple servers such that each vote is divided into
partitions and these partitions are distributed among the servers, all of which
need to be brought together to reconstruct the votes. Such a protocol has
potential applications in bargaining and electronic commerce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1718</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1718</id><created>2010-01-11</created><authors><author><keyname>Xu</keyname><forenames>Chang</forenames><affiliation>Department of Information Engineering, Zhejiang Business Technology Institute, Ningbo, China</affiliation></author><author><keyname>Kirk</keyname><forenames>Steven R.</forenames><affiliation>Department of Computer Science and Informatics, University West, Trollhattan, Sweden</affiliation></author><author><keyname>Jenkins</keyname><forenames>Samantha</forenames><affiliation>Department of Computer Science and Informatics, University West, Trollhattan, Sweden</affiliation></author></authors><title>Tiling for Performance Tuning on Different Models of GPUs</title><categories>cs.DC cs.PF</categories><comments>Accepted to ISISE2009 (Second International Symposium on Information
  Science and Engineering, 26 - 28,Dec. 2009, Shanghai, China)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The strategy of using CUDA-compatible GPUs as a parallel computation solution
to improve the performance of programs has been more and more widely approved
during the last two years since the CUDA platform was released. Its benefit
extends from the graphic domain to many other computationally intensive
domains. Tiling, as the most general and important technique, is widely used
for optimization in CUDA programs. New models of GPUs with better compute
capabilities have, however, been released, new versions of CUDA SDKs were also
released. These updated compute capabilities must to be considered when
optimizing using the tiling technique. In this paper, we implement image
interpolation algorithms as a test case to discuss how different tiling
strategies affect the program's performance. We especially focus on how the
different models of GPUs affect the tiling's effectiveness by executing the
same program on two different models of GPUs equipped testing platforms. The
results demonstrate that an optimized tiling strategy on one GPU model is not
always a good solution when execute on other GPU models, especially when some
external conditions were changed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1730</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1730</id><created>2010-01-11</created><authors><author><keyname>Yedidia</keyname><forenames>Jonathan S.</forenames></author><author><keyname>Wang</keyname><forenames>Yige</forenames></author><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author></authors><title>Divide &amp; Concur and Difference-Map BP Decoders for LDPC Codes</title><categories>cs.IT cs.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The &quot;Divide and Concur'' (DC) algorithm, recently introduced by Gravel and
Elser, can be considered a competitor to the belief propagation (BP) algorithm,
in that both algorithms can be applied to a wide variety of constraint
satisfaction, optimization, and probabilistic inference problems. We show that
DC can be interpreted as a message-passing algorithm on a constraint graph,
which helps make the comparison with BP more clear. The &quot;difference-map''
dynamics of the DC algorithm enables it to avoid &quot;traps'' which may be related
to the &quot;trapping sets'' or &quot;pseudo-codewords'' that plague BP decoders of
low-density parity check (LDPC) codes in the error-floor regime.
  We investigate two decoders for low-density parity-check (LDPC) codes based
on these ideas. The first decoder is based directly on DC, while the second
decoder borrows the important &quot;difference-map'' concept from the DC algorithm
and translates it into a BP-like decoder. We show that this &quot;difference-map
belief propagation'' (DMBP) decoder has dramatically improved error-floor
performance compared to standard BP decoders, while maintaining a similar
computational complexity. We present simulation results for LDPC codes on the
additive white Gaussian noise and binary symmetric channels, comparing DC and
DMBP decoders with other decoders based on BP, linear programming, and
mixed-integer linear programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1732</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1732</id><created>2010-01-11</created><updated>2010-04-09</updated><authors><author><keyname>Bradler</keyname><forenames>Kamil</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Touchette</keyname><forenames>Dave</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Trade-off capacities of the quantum Hadamard channels</title><categories>quant-ph cs.IT math.IT</categories><comments>27 pages, 6 figures, some slight refinements and submitted to
  Physical Review A</comments><journal-ref>Physical Review A 81, 062312 (2010)</journal-ref><doi>10.1103/PhysRevA.81.062312</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coding theorems in quantum Shannon theory express the ultimate rates at which
a sender can transmit information over a noisy quantum channel. More often than
not, the known formulas expressing these transmission rates are intractable,
requiring an optimization over an infinite number of uses of the channel.
Researchers have rarely found quantum channels with a tractable classical or
quantum capacity, but when such a finding occurs, it demonstrates a complete
understanding of that channel's capabilities for transmitting classical or
quantum information. Here, we show that the three-dimensional capacity region
for entanglement-assisted transmission of classical and quantum information is
tractable for the Hadamard class of channels. Examples of Hadamard channels
include generalized dephasing channels, cloning channels, and the Unruh
channel. The generalized dephasing channels and the cloning channels are
natural processes that occur in quantum systems through the loss of quantum
coherence or stimulated emission, respectively. The Unruh channel is a noisy
process that occurs in relativistic quantum information theory as a result of
the Unruh effect and bears a strong relationship to the cloning channels. We
give exact formulas for the entanglement-assisted classical and quantum
communication capacity regions of these channels. The coding strategy for each
of these examples is superior to a naive time-sharing strategy, and we
introduce a measure to determine this improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1763</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1763</id><created>2010-01-11</created><updated>2010-06-01</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>Infinite-message Interactive Function Computation in Collocated Networks</title><categories>cs.IT math.IT</categories><comments>5 pages. 2 figures. This draft has been submitted to IEEE
  International Symposium on Information Theory (ISIT) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An interactive function computation problem in a collocated network is
studied in a distributed block source coding framework. With the goal of
computing a desired function at the sink, the source nodes exchange messages
through a sequence of error-free broadcasts. The infinite-message minimum
sum-rate is viewed as a functional of the joint source pmf and is characterized
as the least element in a partially ordered family of functionals having
certain convex-geometric properties. This characterization leads to a family of
lower bounds for the infinite-message minimum sum-rate and a simple optimality
test for any achievable infinite-message sum-rate. An iterative algorithm for
evaluating the infinite-message minimum sum-rate functional is proposed and is
demonstrated through an example of computing the minimum function of three
sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1768</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1768</id><created>2010-01-11</created><updated>2010-01-13</updated><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On the Secure DoF of the Single-Antenna MAC</title><categories>cs.IT math.IT</categories><comments>5 Pages, Submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new achievability rate region for the secure discrete memoryless
Multiple-Access-Channel (MAC) is presented. Thereafter, a novel secure coding
scheme is proposed to achieve a positive Secure Degrees-of-Freedom (S-DoF) in
the single-antenna MAC. This scheme converts the single-antenna system into a
multiple-dimension system with fractional dimensions. The achievability scheme
is based on the alignment of signals into a small sub-space at the
eavesdropper, and the simultaneous separation of the signals at the intended
receiver. Tools from the field of Diophantine Approximation in number theory
are used to analyze the probability of error in the coding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1781</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1781</id><created>2010-01-11</created><authors><author><keyname>Rudra</keyname><forenames>Atri</forenames></author><author><keyname>Uurtamo</keyname><forenames>Steve</forenames></author></authors><title>Two Theorems in List Decoding</title><categories>cs.IT math.IT</categories><comments>19 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following results concerning the list decoding of
error-correcting codes:
  (i) We show that for \textit{any} code with a relative distance of $\delta$
(over a large enough alphabet), the following result holds for \textit{random
errors}: With high probability, for a $\rho\le \delta -\eps$ fraction of random
errors (for any $\eps&gt;0$), the received word will have only the transmitted
codeword in a Hamming ball of radius $\rho$ around it. Thus, for random errors,
one can correct twice the number of errors uniquely correctable from worst-case
errors for any code. A variant of our result also gives a simple algorithm to
decode Reed-Solomon codes from random errors that, to the best of our
knowledge, runs faster than known algorithms for certain ranges of parameters.
  (ii) We show that concatenated codes can achieve the list decoding capacity
for erasures. A similar result for worst-case errors was proven by Guruswami
and Rudra (SODA 08), although their result does not directly imply our result.
Our results show that a subset of the random ensemble of codes considered by
Guruswami and Rudra also achieve the list decoding capacity for erasures.
  Our proofs employ simple counting and probabilistic arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1794</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1794</id><created>2010-01-12</created><authors><author><keyname>Botchkarev</keyname><forenames>Alexei</forenames></author><author><keyname>Zhao</keyname><forenames>Lian</forenames></author><author><keyname>Rasouli</keyname><forenames>Hamed</forenames></author></authors><title>Designing a Truly Integrated (Onsite and Online) Conference: Concept,
  Processes, Solutions</title><categories>cs.MM cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web conferencing tools have entered the mainstream of business applications.
Using web conferencing for IEEE conferences has a good potential of adding
value to both organizers and participants. Authors propose a concept of Truly
Integrated Conference (TIC) according to which a multi-point
worldwide-distributed network of conference online authors/participants will
enhance the standard (centralized) IEEE conference model, which requires
attendance of the participants in person at the main conference location. The
concept entails seamless integration of the onsite and online conference
systems, including data/presentation, video, audio channels. Benefits and
challenges of the TIC concept are analyzed. Requirements to the web
conferencing system capable of supporting the TIC conference are presented and
reviewed against commercial web conferencing tools. Case study of the IEEE
Toronto International Conference ? Science and Technology for Humanity, which
was the first realization of TIC, is presented which analyzes various aspects
(organizational, technological, and financial) of the integrated conference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1798</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1798</id><created>2010-01-12</created><updated>2010-04-07</updated><authors><author><keyname>Chong</keyname><forenames>Kai Fong Ernest</forenames></author><author><keyname>Kurniawan</keyname><forenames>Ernest</forenames></author><author><keyname>Sun</keyname><forenames>Sumei</forenames></author><author><keyname>Yen</keyname><forenames>Kai</forenames></author></authors><title>Fountain Codes with Varying Probability Distributions</title><categories>cs.IT math.CO math.IT</categories><comments>5 pages, 1 figure. Changes, including a different simulation example
  in Section IV, are made to improve clarity. Theory remains unchanged.
  Resubmitted to the 6th International Symposium on Turbo Codes &amp; Iterative
  Information Processing (ISTC 2010).</comments><msc-class>94B60; 06A06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fountain codes are rateless erasure-correcting codes, i.e., an essentially
infinite stream of encoded packets can be generated from a finite set of data
packets. Several fountain codes have been proposed recently to minimize
overhead, many of which involve modifications of the Luby transform (LT) code.
These fountain codes, like the LT code, have the implicit assumption that the
probability distribution is fixed throughout the encoding process. In this
paper, we will use the theory of posets to show that this assumption is
unnecessary, and by dropping it, we can achieve overhead reduction by as much
as 64% lower than LT codes. We also present the fundamental theory of
probability distribution designs for fountain codes with non-constant
probability distributions that minimize overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1799</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1799</id><created>2010-01-12</created><updated>2010-04-23</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Wang</keyname><forenames>Zizhou Vincent</forenames></author></authors><title>The capacity region of a class of broadcast channels with a sequence of
  less noisy receivers</title><categories>cs.IT math.IT</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of a broadcast channel consisting of k-receivers that lie
in a less noisy sequence is an open problem, when k &gt;= 3. We solve this problem
for the case k=3. We prove that superposition coding is optimal for a class of
broadcast channels with a sequence of less noisy receivers. T
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1802</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1802</id><created>2010-01-12</created><updated>2010-02-19</updated><authors><author><keyname>Schaffer</keyname><forenames>Martin</forenames></author><author><keyname>Rass</keyname><forenames>Stefan</forenames></author></authors><title>Fusion Discrete Logarithm Problems</title><categories>cs.CR</categories><comments>15 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Discrete Logarithm Problem is well-known among cryptographers, for its
computational hardness that grants security to some of the most commonly used
cryptosystems these days. Still, many of these are limited to a small number of
candidate algebraic structures which permit implementing the algorithms. In
order to extend the applicability of discrete-logarithm-based cryptosystems to
a much richer class of algebraic structures, we present a generalized form of
exponential function. Our extension relaxes some assumptions on the exponent,
which is no longer required to be an integer. Using an axiomatic
characterization of the exponential function, we show how to construct mappings
that obey the same rules as exponentials, but can raise vectors to the power of
other vectors in an algebraically sound manner. At the same time, computational
hardness is not affected (in fact, the problem could possibly be strengthened).
Setting up standard cryptosystems in terms of our generalized exponential
function is simple and requires no change to the existing security proofs. This
opens the field for building much more general schemes than the ones known so
far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1806</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1806</id><created>2010-01-12</created><authors><author><keyname>Hamada</keyname><forenames>Mitsuru</forenames></author></authors><title>An Exposition of a Result in &quot;Conjugate Codes for Secure and Reliable
  Information Transmission&quot;</title><categories>cs.IT math.IT</categories><comments>11 pages, 1 figure. An exposition of a result presented in an invited
  talk in ITW 2006, Chengdu, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An elementary proof of the attainability of random coding exponent with
linear codes for additive channels is presented. The result and proof are from
Hamada (Proc. ITW, Chendu, China, 2006), and the present material explains the
proof in detail for those unfamiliar with elementary calculations on
probabilities related to linear codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1808</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1808</id><created>2010-01-12</created><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>Performance Analysis for Data Compression Based Signal Classification
  Methods</title><categories>cs.IT math.IT</categories><comments>5 pages submitted to 2010 IEEE International Symposium on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an information theoretic analysis of the blind
signal classification algorithm. We show that the algorithm is equivalent to a
Maximum A Posteriori (MAP) estimator based on estimated parametric probability
models. We prove a lower bound on the error exponents of the parametric model
estimation. It is shown that the estimated model parameters converge in
probability to the true model parameters except some small bias terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1819</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1819</id><created>2010-01-12</created><updated>2010-02-12</updated><authors><author><keyname>Nuanmeesri</keyname><forenames>Sumitra</forenames></author><author><keyname>Baitiang</keyname><forenames>Chanasak</forenames></author><author><keyname>Meesad</keyname><forenames>Phayung</forenames></author></authors><title>Genealogical Information Search by Using Parent Bidirectional Breadth
  Algorithm and Rule Based Relationship</title><categories>cs.DS</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 001-006, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genealogical information is the best histories resources for culture study
and cultural heritage. The genealogical research generally presents family
information and depict tree diagram. This paper presents Parent Bidirectional
Breadth Algorithm (PBBA) to find consanguine relationship between two persons.
In addition, the paper utilizes rules based system in order to identify
consanguine relationship. The study reveals that PBBA is fast to solve the
genealogical information search problem and the Rule Based Relationship
provides more benefits in blood relationship identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1826</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1826</id><created>2010-01-12</created><updated>2010-10-26</updated><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Richardson</keyname><forenames>Tom</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Threshold Saturation via Spatial Coupling: Why Convolutional LDPC
  Ensembles Perform so well over the BEC</title><categories>cs.IT math.IT</categories><comments>29 pages, 11 figures, To appear in Special Issue of the IEEE
  Transactions on Information Theory, Facets of Coding Theory: from Algorithms
  to Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional LDPC ensembles, introduced by Felstrom and Zigangirov, have
excellent thresholds and these thresholds are rapidly increasing as a function
of the average degree. Several variations on the basic theme have been proposed
to date, all of which share the good performance characteristics of
convolutional LDPC ensembles. We describe the fundamental mechanism which
explains why &quot;convolutional-like&quot; or &quot;spatially coupled&quot; codes perform so well.
In essence, the spatial coupling of the individual code structure has the
effect of increasing the belief-propagation (BP) threshold of the new ensemble
to its maximum possible value, namely the maximum-a-posteriori (MAP) threshold
of the underlying ensemble. For this reason we call this phenomenon &quot;threshold
saturation.&quot; This gives an entirely new way of approaching capacity. One
significant advantage of such a construction is that one can create
capacity-approaching ensembles with an error correcting radius which is
increasing in the blocklength. Our proof makes use of the area theorem of the
BP-EXIT curve and the connection between the MAP and BP threshold recently
pointed out by Measson, Montanari, Richardson, and Urbanke. Although we prove
the connection between the MAP and the BP threshold only for a very specific
ensemble and only for the binary erasure channel, empirically a threshold
saturation phenomenon occurs for a wide class of ensembles and channels. More
generally, we conjecture that for a large range of graphical systems a similar
saturation of the &quot;dynamical&quot; threshold occurs once individual components are
coupled sufficiently strongly. This might give rise to improved algorithms as
well as to new techniques for analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1836</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1836</id><created>2010-01-12</created><authors><author><keyname>Hogo</keyname><forenames>Mofreh</forenames></author><author><keyname>Fouad</keyname><forenames>Khaled</forenames></author><author><keyname>Mousa</keyname><forenames>Fouad</forenames></author></authors><title>Web-Based Expert System for Civil Service Regulations: RCSES</title><categories>cs.AI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 007-016, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet and expert systems have offered new ways of sharing and distributing
knowledge, but there is a lack of researches in the area of web based expert
systems. This paper introduces a development of a web-based expert system for
the regulations of civil service in the Kingdom of Saudi Arabia named as RCSES.
It is the first time to develop such system (application of civil service
regulations) as well the development of it using web based approach. The
proposed system considers 17 regulations of the civil service system. The
different phases of developing the RCSES system are presented, as knowledge
acquiring and selection, ontology and knowledge representations using XML
format. XML Rule-based knowledge sources and the inference mechanisms were
implemented using ASP.net technique. An interactive tool for entering the
ontology and knowledge base, and the inferencing was built. It gives the
ability to use, modify, update, and extend the existing knowledge base in an
easy way. The knowledge was validated by experts in the domain of civil service
regulations, and the proposed RCSES was tested, verified, and validated by
different technical users and the developers staff. The RCSES system is
compared with other related web based expert systems, that comparison proved
the goodness, usability, and high performance of RCSES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1844</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1844</id><created>2010-01-12</created><authors><author><keyname>Kestila</keyname><forenames>Antti Alexander</forenames></author></authors><title>The Peacock Encryption Method</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here is described a preliminary method that enables secure
'anti-search-engine' encryption, where the middleman can participate in the
encrypted information exchange, without being able to understand the exchanged
information, encrypted using a one-way function, as well as being unaware of
one of two main exchange participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1860</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1860</id><created>2010-01-12</created><updated>2010-02-01</updated><authors><author><keyname>Weinberg</keyname><forenames>Volker</forenames></author><author><keyname>Brehm</keyname><forenames>Matthias</forenames></author><author><keyname>Christadler</keyname><forenames>Iris</forenames></author></authors><title>OMI4papps: Optimisation, Modelling and Implementation for Highly
  Parallel Applications</title><categories>cs.PF</categories><comments>12 pages, 8 figures, talk given at the HLRB, KONWIHR and
  Linux-Cluster Review and Results Workshop, Garching b. Muenchen, Germany, 8-9
  Dec 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article reports on first results of the KONWIHR-II project OMI4papps at
the Leibniz Supercomputing Centre (LRZ). The first part describes Apex-MAP, a
tunable synthetic benchmark designed to simulate the performance of typical
scientific applications. Apex-MAP mimics common memory access patterns and
different computational intensity of scientific codes. An approach for
modelling LRZ's application mix is given whichh makes use of performance
counter measurements of real applications running on &quot;HLRB II&quot;, an SGI Altix
system based on 9728 Intel Montecito dual-cores.
  The second part will show how the Apex-MAP benchmark could be used to
simulate the performance of two mathematical kernels frequently used in
scientific applications: a dense matrix-matrix multiplication and a sparse
matrix-vector multiplication. The performance of both kernels has been
intensively studied on x86 cores and hardware accelerators. We will compare the
predicted performance with measured data to validate our Apex-MAP approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1872</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1872</id><created>2010-01-12</created><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Reduced ML-Decoding Complexity, Full-Rate STBCs for 4 Transmit Antenna
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an $n_t$ transmit, $n_r$ receive antenna system ($n_t \times n_r$
system), a {\it{full-rate}} space time block code (STBC) transmits
$min(n_t,n_r)$ complex symbols per channel use. In this paper, a scheme to
obtain a full-rate STBC for 4 transmit antennas and any $n_r$, with reduced
ML-decoding complexity is presented. The weight matrices of the proposed STBC
are obtained from the unitary matrix representations of Clifford Algebra. By
puncturing the symbols of the STBC, full rate designs can be obtained for $n_r
&lt; 4$. For any value of $n_r$, the proposed design offers the least ML-decoding
complexity among known codes. The proposed design is comparable in error
performance to the well known perfect code for 4 transmit antennas while
offering lower ML-decoding complexity. Further, when $n_r &lt; 4$, the proposed
design has higher ergodic capacity than the punctured Perfect code. Simulation
results which corroborate these claims are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1873</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1873</id><created>2010-01-12</created><updated>2010-04-30</updated><authors><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Raymond</keyname><forenames>Jack</forenames></author></authors><title>Optimal incorporation of sparsity information by weighted $\ell_1$
  optimization</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear in Proceedings of ISIT2010</comments><journal-ref>Information Theory Proceedings (ISIT), 2010 IEEE International
  Symposium on , vol., no., pp.1598,1602, 13-18 June 2010</journal-ref><doi>10.1109/ISIT.2010.5513420</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing of sparse sources can be improved by incorporating prior
knowledge of the source. In this paper we demonstrate a method for optimal
selection of weights in weighted $L_1$ norm minimization for a noiseless
reconstruction model, and show the improvements in compression that can be
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1877</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1877</id><created>2010-01-12</created><updated>2010-03-09</updated><authors><author><keyname>Sahasranand</keyname><forenames>K. R.</forenames></author><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author><author><keyname>Rajan</keyname><forenames>S.</forenames></author></authors><title>How not to share a set of secrets</title><categories>cs.CR</categories><comments>Added a new section demonstrating two new kinds of attack; 10 pages</comments><journal-ref>International Journal of Computer Science and Information
  Security, Vol. 8, No.1, pp. 234-237, Apr. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note analyses one of the existing space efficient secret sharing schemes
and suggests vulnerabilities in its design. We observe that the said algorithm
fails for certain choices of the set of secrets and there is no reason for
preferring this particular scheme over alternative schemes. The paper also
elaborates the adoption of a scheme proposed by Hugo Krawczyk as an extension
of Shamir's scheme, for a set of secrets. Such an implementation is space
optimal and works for all choices of secrets. We also propose two new methods
of attack which are valid under certain assumptions and observe that it is the
elimination of random values that facilitates these kinds of attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1889</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1889</id><created>2010-01-12</created><authors><author><keyname>Lahoz-Beltra</keyname><forenames>Rafeal</forenames></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Cheating for Problem Solving: A Genetic Algorithm with Social
  Interactions</title><categories>cs.NE cs.AI cs.GT</categories><comments>7 pages, 5 Figures, 5 Tables, Proceedings of Genetic and Evolutionary
  Computation Conference (GECCO 2009), Montreal, Canada</comments><journal-ref>Proceedings of Genetic and Evolutionary Computation Conference
  (GECCO 2009), Montreal, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a variation of the standard genetic algorithm that incorporates
social interaction between the individuals in the population. Our goal is to
understand the evolutionary role of social systems and its possible application
as a non-genetic new step in evolutionary algorithms. In biological
populations, ie animals, even human beings and microorganisms, social
interactions often affect the fitness of individuals. It is conceivable that
the perturbation of the fitness via social interactions is an evolutionary
strategy to avoid trapping into local optimum, thus avoiding a fast convergence
of the population. We model the social interactions according to Game Theory.
The population is, therefore, composed by cooperator and defector individuals
whose interactions produce payoffs according to well known game models
(prisoner's dilemma, chicken game, and others). Our results on Knapsack
problems show, for some game models, a significant performance improvement as
compared to a standard genetic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1896</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1896</id><created>2010-01-12</created><updated>2010-01-13</updated><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Generalized Degrees of Freedom of the Interference Channel with a Signal
  Cognitive Relay</title><categories>cs.IT math.IT</categories><comments>Results submitted to ISIT 2010, 19 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the interference channel with a signal cognitive relay. A signal
cognitive relay knows the transmit signals (but not the messages) of the
sources non-causally, and tries to help them communicating with their
respective destinations. We derive upper bounds and provide achievable schemes
for this channel. These upper and lower bounds are shown to be tight from
generalized degrees of freedom point of view. As a result, a characterization
of the generalized degrees of freedom of the interference channel with a signal
cognitive relay is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1901</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1901</id><created>2010-01-12</created><authors><author><keyname>Pountourakis</keyname><forenames>Emmanouil</forenames></author><author><keyname>Vidali</keyname><forenames>Angelina</forenames></author></authors><title>A complete characterization of group-strategyproof mechanisms of
  cost-sharing</title><categories>cs.GT</categories><comments>29 pages</comments><acm-class>F.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of designing group-strategyproof cost-sharing
mechanisms. The players report their bids for getting serviced and the
mechanism decides which players are going to be serviced and how much each one
of them is going to pay. We determine three conditions: \emph{Fence
Monotonicity}, \emph{Stability} of the allocation and \emph{Validity} of the
tie-breaking rule that are necessary and sufficient for
group-strategyproofness, regardless of the cost function. Fence Monotonicity
puts restrictions only on the payments of the mechanism and stability only on
the allocation. Consequently Fence Monotonicity characterizes
group-strategyproof cost-sharing schemes. Finally, we use our results to prove
that there exist families of cost functions, where any group-strategyproof
mechanism has unbounded approximation ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1902</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1902</id><created>2010-01-12</created><updated>2010-02-19</updated><authors><author><keyname>Christadler</keyname><forenames>Iris</forenames></author><author><keyname>Weinberg</keyname><forenames>Volker</forenames></author></authors><title>RapidMind: Portability across Architectures and its Limitations</title><categories>cs.PF cs.PL</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, hybrid architectures using accelerators like GPGPUs or the Cell
processor have gained much interest in the HPC community. The RapidMind
Multi-Core Development Platform is a programming environment that allows
generating code which is able to seamlessly run on hardware accelerators like
GPUs or the Cell processor and multicore CPUs both from AMD and Intel. This
paper describes the ports of three mathematical kernels to RapidMind which are
chosen as synthetic benchmarks and representatives of scientific codes.
Performance of these kernels has been measured on various RapidMind backends
(cuda, cell and x86) and compared to other hardware-specific implementations
(using CUDA, Cell SDK and Intel MKL). The results give an insight in the degree
of portability of RapidMind code and code performance across different
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1912</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1912</id><created>2010-01-12</created><authors><author><keyname>Naja</keyname><forenames>Ziad</forenames></author><author><keyname>Alberge</keyname><forenames>Florence</forenames></author><author><keyname>Duhamel</keyname><forenames>P.</forenames></author></authors><title>M\'ethode du point proximal: principe et applications aux algorithmes
  it\'eratifs</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00445731</proxy><journal-ref>GRETSI, Dijon : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper recalls the proximal point method. We study two iterative
algorithms: the Blahut-Arimoto algorithm for computing the capacity of
arbitrary discrete memoryless channels, as an example of an iterative algorithm
working with probability density estimates and the iterative decoding of the
Bit Interleaved Coded Modulation (BICM-ID). For these iterative algorithms, we
apply the proximal point method which allows new interpretations with improved
convergence rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1915</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1915</id><created>2010-01-12</created><authors><author><keyname>Naja</keyname><forenames>Ziad</forenames></author><author><keyname>Alberge</keyname><forenames>Florence</forenames></author><author><keyname>Duhamel</keyname><forenames>P.</forenames></author></authors><title>Geometrical interpretation and improvements of the Blahut-Arimoto's
  algorithm</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00445714</proxy><journal-ref>ICASSP, Taipei : Taiwan (2009)</journal-ref><doi>10.1109/ICASSP.2009.4960131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper first recalls the Blahut Arimoto algorithm for computing the
capacity of arbitrary discrete memoryless channels, as an example of an
iterative algorithm working with probability density estimates. Then, a
geometrical interpretation of this algorithm based on projections onto linear
and exponential families of probabilities is provided. Finally, this
understanding allows also to propose to write the Blahut-Arimoto algorithm, as
a true proximal point algorithm. it is shown that the corresponding version has
an improved convergence rate, compared to the initial algorithm, as well as in
comparison with other improved versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1917</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1917</id><created>2010-01-12</created><authors><author><keyname>Alberge</keyname><forenames>Florence</forenames></author><author><keyname>Naja</keyname><forenames>Ziad</forenames></author><author><keyname>Duhamel</keyname><forenames>P.</forenames></author></authors><title>New Criteria for Iterative Decoding</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00445615</proxy><journal-ref>ICASSP, Taipei : Taiwan (2009)</journal-ref><doi>10.1109/ICASSP.2009.4960128</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative decoding was not originally introduced as the solution to an
optimization problem rendering the analysis of its convergence very difficult.
In this paper, we investigate the link between iterative decoding and classical
optimization techniques. We first show that iterative decoding can be rephrased
as two embedded minimization processes involving the Fermi-Dirac distance.
Based on this new formulation, an hybrid proximal point algorithm is first
derived with the additional advantage of decreasing a desired criterion. In a
second part, an hybrid minimum entropy algorithm is proposed with improved
performance compared to the classical iterative decoding. Even if this paper
focus on iterative decoding for BICM, the results can be applied to the large
class of turbo-like decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1933</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1933</id><created>2010-01-12</created><updated>2010-06-03</updated><authors><author><keyname>Kwiatkowska</keyname><forenames>Marta</forenames></author><author><keyname>Norman</keyname><forenames>Gethin</forenames></author><author><keyname>Trivedi</keyname><forenames>Ashutosh</forenames></author></authors><title>Quantitative Games on Probabilistic Timed Automata</title><categories>cs.GT cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-player zero-sum games are a well-established model for synthesising
controllers that optimise some performance criterion. In such games one player
represents the controller, while the other describes the (adversarial)
environment, and controller synthesis corresponds to computing the optimal
strategies of the controller for a given criterion. Asarin and Maler initiated
the study of quantitative games on (non-probabilistic) timed automata by
synthesising controllers which optimise the time to reach a final state. The
correctness and termination of their approach was dependent on exploiting the
properties of a special class of functions, called simple functions, that can
be finitely represented. In this paper we consider quantitative games over
probabilistic timed automata. Since the concept of simple functions is not
sufficient to solve games in this setting, we generalise simple functions to
so-called quasi-simple functions. Then, using this class of functions, we
demonstrate that the problem of solving games with either expected
reachability-time or expected discounted-time criteria on probabilistic timed
automata are in NEXPTIME $\cap$ co-NEXPTIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1936</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1936</id><created>2010-01-12</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>A Key Distribution Scheme for Sensor Networks Using Structured Graphs</title><categories>cs.CR</categories><comments>To appear in Proceedings of ELECTRO 2009, Dec 22-24, Banaras Hindu
  University, Banaras, India. (4 pages, Invited - Subhash Kak)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new key predistribution scheme for sensor networks
based on structured graphs. Structured graphs are advantageous in that they can
be optimized to minimize the parameter of interest. The proposed approach
achieves a balance between the number of keys per node, path lengths, network
diameter and the complexity of routing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1937</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1937</id><created>2010-01-12</created><updated>2010-02-04</updated><authors><author><keyname>Parandehgheibi</keyname><forenames>Ali</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asu</forenames></author></authors><title>Avoiding Interruptions - QoE Trade-offs in Block-coded Streaming Media
  Applications</title><categories>cs.MM cs.NI</categories><comments>Submitted to ISIT 2010 - Full version</comments><report-no>MIT - RLE report #730</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We take an analytical approach to study Quality of user Experience (QoE) for
video streaming applications. First, we show that random linear network coding
applied to blocks of video frames can significantly simplify the packet
requests at the network layer and save resources by avoiding duplicate packet
reception. Network coding allows us to model the receiver's buffer as a queue
with Poisson arrivals and deterministic departures. We consider the probability
of interruption in video playback as well as the number of initially buffered
packets (initial waiting time) as the QoE metrics. We characterize the optimal
trade-off between these metrics by providing upper and lower bounds on the
minimum initial buffer size, required to achieve certain level of interruption
probability for different regimes of the system parameters. Our bounds are
asymptotically tight as the file size goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1948</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1948</id><created>2010-01-12</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Collision Helps - Algebraic Collision Recovery for Wireless Erasure
  Networks</title><categories>cs.IT cs.NI math.IT</categories><report-no>RLE report # 728</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current medium access control mechanisms are based on collision avoidance and
collided packets are discarded. The recent work on ZigZag decoding departs from
this approach by recovering the original packets from multiple collisions. In
this paper, we present an algebraic representation of collisions which allows
us to view each collision as a linear combination of the original packets. The
transmitted, colliding packets may themselves be a coded version of the
original packets.
  We propose a new acknowledgment (ACK) mechanism for collisions based on the
idea that if a set of packets collide, the receiver can afford to ACK exactly
one of them and still decode all the packets eventually. We analytically
compare delay and throughput performance of such collision recovery schemes
with other collision avoidance approaches in the context of a single hop
wireless erasure network. In the multiple receiver case, the broadcast
constraint calls for combining collision recovery methods with network coding
across packets at the sender. From the delay perspective, our scheme, without
any coordination, outperforms not only a ALOHA-type random access mechanisms,
but also centralized scheduling. For the case of streaming arrivals, we propose
a priority-based ACK mechanism and show that its stability region coincides
with the cut-set bound of the packet erasure network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1960</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1960</id><created>2010-01-12</created><authors><author><keyname>Fontes</keyname><forenames>Lila</forenames></author></authors><title>Formal Theories for Logspace Counting</title><categories>cs.LO cs.CC</categories><comments>33 pages, uses newalg.sty (file included)</comments><acm-class>F.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two-sorted theories in the style of Cook and Nguyen for the
complexity classes ParityL and DET, whose complete problems include
determinants over GF(2) and Z, respectively. The definable functions in these
theories are the functions in the corresponding complexity classes; thus each
theory formalizes reasoning using concepts from its corresponding complexity
class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1962</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1962</id><created>2010-01-12</created><authors><author><keyname>Lashkari</keyname><forenames>Arash Habibi</forenames></author><author><keyname>Saleh</keyname><forenames>Dr. Rosli</forenames></author><author><keyname>Farmand</keyname><forenames>Samaneh</forenames></author><author><keyname>Zakaria</keyname><forenames>Dr. Omar Bin</forenames></author></authors><title>A Wide range Survey on Recall Based Graphical User Authentications
  Algorithms Based on ISO and Attack Patterns</title><categories>cs.CR</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 017-025, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, user authentication is one of the important topics in information
security. Text based strong password schemes could provide with certain degree
of security. However, the fact that strong passwords being difficult to
memorize often leads their owners to write them down on papers or even save
them in a computer file. Graphical user authentication (GUA) has been proposed
as a possible alternative solution to text based authentication, motivated
particularly by the fact that humans can remember images better than text. In
recent years, many networks, computer systems and Internet based environments
try used GUA technique for their users authentication. All of GUA algorithms
have two different aspects which are usability and security. Unfortunately,
none of graphical algorithms were being able to cover both of these aspects at
the same time. This paper presents a wide range survey on the pure and cued
recall based algorithms in GUA, based on ISO standards for usability and attack
patterns standards for security. After explain usability ISO standards and
attack patterns international standards, we try to collect the major attributes
of usability and security in GUA. Finally, try to make comparison tables among
all recall based algorithms based on usability attributes and attack patterns
those we found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1966</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1966</id><created>2010-01-12</created><authors><author><keyname>Khan</keyname><forenames>Maleika Heenaye Mamode</forenames></author><author><keyname>Khan</keyname><forenames>Naushad Ali Mamode</forenames></author></authors><title>A New Method to Extract Dorsal Hand Vein Pattern using Quadratic
  Inference Function</title><categories>cs.CV cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 026-030, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among all biometric, dorsal hand vein pattern is attracting the attention of
researchers, of late. Extensive research is being carried out on various
techniques in the hope of finding an efficient one which can be applied on
dorsal hand vein pattern to improve its accuracy and matching time. One of the
crucial step in biometric is the extraction of features. In this paper, we
propose a method based on quadratic inference function to the dorsal hand vein
features to extract its features. The biometric system developed was tested on
a database of 100 images. The false acceptance rate (FAR), false rejection rate
(FRR) and the matching time are being computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1967</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1967</id><created>2010-01-12</created><authors><author><keyname>Hassan</keyname><forenames>Rosilah</forenames></author><author><keyname>Razali</keyname><forenames>Rozilawati</forenames></author><author><keyname>Mohseni</keyname><forenames>Shima</forenames></author><author><keyname>Mohamad</keyname><forenames>Ola</forenames></author><author><keyname>Ismail</keyname><forenames>Zahian</forenames></author></authors><title>Architecture of Network Management Tools for Heterogeneous System</title><categories>cs.NI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 031-040, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Managing heterogeneous network systems is a difficult task because each of
these networks has its own curious management system. These networks usually
are constructed on independent management protocols which are not compatible
with each other. This results in the coexistence of many management systems
with different managing functions and services across enterprises.
Incompatibility of different management systems makes management of whole
system a very complex and often complicated job. Ideally, it is necessary to
implement centralized metalevel management across distributed heterogeneous
systems and their underlying supporting network systems where the information
flow and guidance is provided via a single console or single operating panels
which integrates all the management functions in spite of their individual
protocols and structures. This paper attempts to provide a novel network
management tool architecture which supports heterogeneous managements across
many different architectural platforms. Furthermore, an architectural approach
to integrate heterogeneous network is proposed. This architecture takes into
account both wireless fixed and mobile nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1968</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1968</id><created>2010-01-12</created><authors><author><keyname>Krishnaveni</keyname><forenames>M.</forenames></author><author><keyname>Radha</keyname><forenames>Dr. V.</forenames></author></authors><title>A Topological derivative based image segmentation for sign language
  recognition system using isotropic filter</title><categories>cs.CV</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 041-045, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need of sign language is increasing radically especially to hearing
impaired community. Only few research groups try to automatically recognize
sign language from video, colored gloves and etc. Their approach requires a
valid segmentation of the data that is used for training and of the data that
is used to be recognized. Recognition of a sign language image sequence is
challenging because of the variety of hand shapes and hand motions. Here, this
paper proposes to apply a combination of image segmentation with restoration
using topological derivatives for achieving high recognition accuracy. Image
quality measures are conceded here to differentiate the methods both
subjectively as well as objectively. Experiments show that the additional use
of the restoration before segmenting the postures significantly improves the
correct rate of hand detection, and that the discrete derivatives yields a high
rate of discrimination between different static hand postures as well as
between hand postures and the scene background. Eventually, the research is to
contribute to the implementation of automated sign language recognition system
mainly established for the welfare purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1970</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1970</id><created>2010-01-12</created><authors><author><keyname>Soni</keyname><forenames>Devpriya</forenames></author><author><keyname>Shrivastava</keyname><forenames>Ritu</forenames></author><author><keyname>Kumar</keyname><forenames>M.</forenames></author></authors><title>A Framework for Validation of Object Oriented Design Metrics</title><categories>cs.SE</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 046-052, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large number of metrics have been proposed for the quality of object
oriented software. Many of these metrics have not been properly validated due
to poor methods of validation and non acceptance of metrics on scientific
grounds. In the literature, two types of validations namely internal
(theoretical) and external (empirical) are recommended. In this study, the
authors have used both theoretical as well as empirical validation for
validating already proposed set of metrics for the five quality factors. These
metrics were proposed by Kumar and Soni.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1972</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1972</id><created>2010-01-12</created><authors><author><keyname>Kaur</keyname><forenames>Amanpreet</forenames></author><author><keyname>Dhir</keyname><forenames>Renu</forenames></author><author><keyname>Sikka</keyname><forenames>Geeta</forenames></author></authors><title>A New Image Steganography Based On First Component Alteration Technique</title><categories>cs.MM cs.CV</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 053-056, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, A new image steganography scheme is proposed which is a kind
of spatial domain technique. In order to hide secret data in cover-image, the
first component alteration technique is used. Techniques used so far focuses
only on the two or four bits of a pixel in a image (at the most five bits at
the edge of an image) which results in less peak to signal noise ratio and high
root mean square error. In this technique, 8 bits of blue components of pixels
are replaced with secret data bits. Proposed scheme can embed more data than
previous schemes and shows better image quality. To prove this scheme, several
experiments are performed, and are compared the experimental results with the
related previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1974</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1974</id><created>2010-01-12</created><authors><author><keyname>Khiyal</keyname><forenames>Malik Sikandar Hayat</forenames></author><author><keyname>Khan</keyname><forenames>Aihab</forenames></author><author><keyname>Amjad</keyname><forenames>Sehrish</forenames></author><author><keyname>Khalil</keyname><forenames>M. Shahid</forenames></author></authors><title>Evaluating Effectiveness of Tamper Proofing on Dynamic Graph Software
  Watermarks</title><categories>cs.MM cs.CR</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 057-063, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For enhancing the protection level of dynamic graph software watermarks and
for the purpose of conducting the analysis which evaluates the effect of
integrating two software protection techniques such as software watermarking
and tamper proofing, constant encoding technique along with the enhancement
through the idea of constant splitting is proposed. In this paper Thomborson
technique has been implemented with the scheme of breaking constants which
enables to encode all constants without having any consideration about their
values with respect to the value of watermark tree. Experimental analysis which
have been conducted and provided in this paper concludes that the constant
encoding process significantly increases the code size, heap space usage, and
execution time, while making the tamper proofed code resilient to variety of
semantic preserving program transformation attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1975</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1975</id><created>2010-01-12</created><authors><author><keyname>Ruckmani</keyname><forenames>V.</forenames></author><author><keyname>Sadasivam</keyname><forenames>Dr G Sudha</forenames></author></authors><title>A Novel Trigon based Dual Authentication Protocol for Enhancing Security
  in Grid Environment</title><categories>cs.CR</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 064-072, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent times, a necessity has been raised in order to distribute computing
applications often across grids. These applications are dependent on the
services like data transfer or data portal services as well as submission of
jobs. Security is of utmost importance in grid computing applications as grid
resources are heterogeneous, dynamic, and multidomain. Authentication remains
as the significant security challenge in grid environment. In traditional
authentication protocol a single server stores the sensitive user credentials,
like username and password. When such a server is compromised, a large number
of user passwords, will be exposed. Our proposed approach uses a dual
authentication protocol in order to improve the authentication service in grid
environment. The protocol utilizes the fundamental concepts of trigon and based
on the parameters of the trigon the user authentication will be performed. In
the proposed protocol, the password is interpreted and alienated into more than
one unit and these units are stored in two different servers, namely,
Authentication Server and Backend Server. Only when the combined authentication
scheme from both the servers authenticates the user, the privilege of accessing
the requested resources is obtained by the user. The main advantage of
utilizing the dual authentication protocol in grid computing is that an
adversary user cannot attain the access privilege by compromising a single
consolidated server because of the fact that the split password is stored in
different servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1976</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1976</id><created>2010-01-12</created><authors><author><keyname>Saravanan</keyname><forenames>S.</forenames></author><author><keyname>Madheswaran</keyname><forenames>M.</forenames></author></authors><title>Design and Analysis of a Spurious Switching Suppression Technique
  Equipped Low Power Multiplier with Hybrid Encoding Scheme</title><categories>cs.OH</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 073-078, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiplication is an arithmetic operation that is mostly used in Digital
Signal Processing (DSP) and communication applications. Efficient
implementation of the multipliers is required in many applications. The design
and analysis of Spurious Switching Suppression Technique (SSST) equipped low
power multiplier with hybrid encoding is presented in this paper. The proposed
encoding technique reduces the number of switching activity and dynamic power
consumption by analyzing the bit patterns in the input data. In this proposed
encoding scheme, the operation is executed depends upon the number of 1s and
its position in the multiplier data. The architecture of the proposed
multiplier is designed using a low power full adder which consumes less power
than the other adder architectures. The switching activity of the proposed
multiplier has been reduced by 86 percent and 46percent compared with
conventional and Booth multiplier respectively. It is observed from the device
level simulation using TANNER 12.6 EDA that the power consumption of the
proposed multiplier has been reduced by 87 percent and 26 percent compared with
conventional and Booth multiplier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1979</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1979</id><created>2010-01-12</created><authors><author><keyname>Chinniah</keyname><forenames>P.</forenames></author><author><keyname>Muttan</keyname><forenames>Dr. S.</forenames></author></authors><title>ICD 10 Based Medical Expert System Using Fuzzy Temporal Logic</title><categories>cs.AI cs.LO</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 084-089, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical diagnosis process involves many levels and considerable amount of
time and money are invariably spent for the first level of diagnosis usually
made by the physician for all the patients every time. Hence there is a need
for a computer based system which not only asks relevant questions to the
patients but also aids the physician by giving a set of possible diseases from
the symptoms obtained using logic at inference. In this work, an ICD10 based
Medical Expert System that provides advice, information and recommendation to
the physician using fuzzy temporal logic. The knowledge base used in this
system consists of facts of symptoms and rules on diseases. It also provides
fuzzy severity scale and weight factor for symptom and disease and can vary
with respect to time. The system generates the possible disease conditions
based on modified Euclidean metric using Elders algorithm for effective
clustering. The minimum similarity value is used as the decision parameter to
identify a disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1984</identifier>
 <datestamp>2010-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1984</id><created>2010-01-12</created><updated>2010-02-06</updated><authors><author><keyname>Singh</keyname><forenames>Chandra Prakash</forenames></author><author><keyname>Khan</keyname><forenames>Feroz</forenames></author><author><keyname>Singh</keyname><forenames>Sanjay Kumar</forenames></author><author><keyname>Chauhan</keyname><forenames>Durg Singh</forenames></author></authors><title>DNA-MATRIX a tool for DNA motif discovery and weight matrix construction</title><categories>q-bio.GN cs.CE</categories><comments>3 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 090-092, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In computational molecular biology, gene regulatory binding sites prediction
in whole genome remains a challenge for the researchers. Now a days, the genome
wide regulatory binding site prediction tools required either direct pattern
sequence or weight matrix. Although there are known transcription factor
binding sites databases available for genome wide prediction but no tool is
available which can construct different weight matrices as per need of user or
tools available for large data set scanning by first aligning the input
upstream or promoter sequences and than construct the matrices in different
level and file format. Considering this, we developed a DNA MATRIX tool for
searching putative regulatory binding sites in gene upstream sequences. This
tool uses the simple biological rule based heuristic algorithm for weight
matrix construction, which can be transformed into different formats after
motif alignment and therefore provides the possibility to identify the most
potential conserved binding sites in the regulated genes. The user may
construct and save specific weight or frequency matrices in different form and
file formats based on user based selection of conserved aligned block of short
sequences ranges from 6 to 20 base pairs and prior nucleotide frequency before
weight scoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1985</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1985</id><created>2010-01-12</created><authors><author><keyname>Padmavathi</keyname><forenames>Dr. G.</forenames></author><author><keyname>Vijayalakshmi</keyname><forenames>Mrs. S. R.</forenames></author></authors><title>Multiprocessor Scheduling For Tasks With Priority Using GA</title><categories>cs.NE cs.DC</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 093-100, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiprocessors have emerged as a powerful computing means for running
realtime applications, especially where a uniprocessor system would not be
sufficient enough to execute all the tasks. The high performance and
reliability of multiprocessors have made them a powerful computing resource.
Such computing environment requires an efficient algorithm to determine when
and on which processor a given task should execute. In multiprocessor systems,
an efficient scheduling of a parallel program onto the processors that
minimizes the entire execution time is vital for achieving a high performance.
This scheduling problem is known to be NPHard. In multiprocessor scheduling
problem, a given program is to be scheduled in a given multiprocessor system
such that the programs execution time is minimized. The last job must be
completed as early as possible. Genetic algorithm (GA) is one of the widely
used techniques for constrained optimization problems. Genetic algorithms are
basically search algorithms based on the mechanics of natural selection and
natural genesis. The main goal behind research on genetic algorithms is
robustness i.e. balance between efficiency and efficacy. This paper proposes
Genetic algorithm to solve scheduling problem of multiprocessors that minimizes
the make span.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1986</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1986</id><created>2010-01-12</created><authors><author><keyname>Nirmala</keyname><forenames>S.</forenames></author><author><keyname>Palanisamy</keyname><forenames>V.</forenames></author></authors><title>Measurement of Nuchal Translucency Thickness for Detection of
  Chromosomal Abnormalities using First Trimester Ultrasound Fetal Images</title><categories>cs.OH physics.med-ph</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 101-106, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nuchal Translucency thickness measurement is made to identify the Down
Syndrome in screening first trimester fetus and presented in this paper. The
mean shift analysis and canny operators are utilized for segmenting the nuchal
translucency region and the exact thickness has been estimated using Blob
analysis. It is observed from the results that the fetus in the 14th week of
Gestation is expected to have a nuchal translucency thickness of 1.87 plus or
minus 0.25mm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1988</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1988</id><created>2010-01-12</created><authors><author><keyname>Rajendran</keyname><forenames>P.</forenames></author><author><keyname>Madheswaran</keyname><forenames>M.</forenames></author></authors><title>An Improved Image Mining Technique For Brain Tumour Classification Using
  Efficient Classifier</title><categories>cs.CV cs.IR</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 107-116, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An improved image mining technique for brain tumor classification using
pruned association rule with MARI algorithm is presented in this paper. The
method proposed makes use of association rule mining technique to classify the
CT scan brain images into three categories namely normal, benign and malign. It
combines the low level features extracted from images and high level knowledge
from specialists. The developed algorithm can assist the physicians for
efficient classification with multiple keywords per image to improve the
accuracy. The experimental result on prediagnosed database of brain images
showed 96 percent and 93 percent sensitivity and accuracy respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1991</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1991</id><created>2010-01-12</created><authors><author><keyname>Anandhavalli</keyname><forenames>M.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author><author><keyname>Gauthaman</keyname><forenames>K.</forenames></author></authors><title>Mining Spatial Gene Expression Data Using Negative Association Rules</title><categories>cs.DB cs.CE q-bio.GN</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 117-120, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the years, data mining has attracted most of the attention from the
research community. The researchers attempt to develop faster, more scalable
algorithms to navigate over the ever increasing volumes of spatial gene
expression data in search of meaningful patterns. Association rules are a data
mining technique that tries to identify intrinsic patterns in spatial gene
expression data. It has been widely used in different applications, a lot of
algorithms introduced to discover these rules. However Priori like algorithms
has been used to find positive association rules. In contrast to positive
rules, negative rules encapsulate relationship between the occurrences of one
set of items with absence of the other set of items. In this paper, an
algorithm for mining negative association rules from spatial gene expression
data is introduced. The algorithm intends to discover the negative association
rules which are complementary to the association rules often generated by
Priori like algorithm. Our study shows that negative association rules can be
discovered efficiently from spatial gene expression data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1992</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1992</id><created>2010-01-12</created><authors><author><keyname>Gautam</keyname><forenames>K. K.</forenames></author><author><keyname>Chaudhary</keyname><forenames>Menu</forenames></author></authors><title>Hierarchical Route Optimization by Using Tree information option in a
  Mobile Networks</title><categories>cs.NI</categories><comments>3 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 121-123, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Networks Mobility (NEMO) Protocol is a way of managing the mobility of an
entire network, and mobile internet protocol is the basic solution for Networks
Mobility. A hierarchical route optimization system for mobile network is
proposed to solve management of hierarchical route optimization problems. In
present paper, we study Hierarchical Route Optimization Scheme using Tree
Information Option (HROSTIO). The concept of optimization finding the extreme
of a function that maps candidate solution to scalar values of quality, is an
extremely general and useful idea. For solving this problem, we use a few
salient adaptations and we also extend HROSTIO perform routing between the
mobile networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.1993</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.1993</id><created>2010-01-12</created><authors><author><keyname>Longe</keyname><forenames>O. B.</forenames></author><author><keyname>Mbarika</keyname><forenames>V.</forenames></author><author><keyname>Kourouma</keyname><forenames>M.</forenames></author><author><keyname>Wada</keyname><forenames>F.</forenames></author><author><keyname>Isabalija</keyname><forenames>R.</forenames></author></authors><title>Seeing Beyond the Surface, Understanding and Tracking Fraudulent Cyber
  Activities</title><categories>cs.CR</categories><comments>12 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 124-135, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The malaise of electronic spam mail that solicit illicit partnership using
bogus business proposals (popularly called 419 mails) remained unabated on the
internet despite concerted efforts. In addition to these are the emergence and
prevalence of phishing scams that use social engineering tactics to obtain
online access codes such as credit card number, ATM pin numbers, bank account
details, social security number and other personal information (22). In an age
where dependence on electronic transaction is on the increase, the web security
community will have to devise more pragmatic measures to make the cyberspace
safe from these demeaning ills. Understanding the perpetrators of internet
crimes and their mode of operation is a basis for any meaningful effort towards
stemming these crimes. This paper discusses the nature of the criminals engaged
in fraudulent cyberspace activities with special emphasis on the Nigeria 419
scam mails. Based on a qualitative analysis and experiments to trace the source
of electronic spam and phishing emails received over a six months period, we
provide information about the scammers personalities, motivation, methodologies
and victims. We posited that popular email clients are deficient in the
provision of effective mechanisms that can aid users in identifying fraud mails
and protect them against phishing attacks. We demonstrate, using state of the
art techniques, how users can detect and avoid fraudulent emails and conclude
by making appropriate recommendations based on our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2024</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2024</id><created>2010-01-12</created><updated>2010-06-15</updated><authors><author><keyname>Moshksar</keyname><forenames>Kamyar</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Wireless Networks with Asynchronous Users</title><categories>cs.IT math.IT</categories><comments>This paperi is withdrawn by the author due to a crucial technicality
  regarding ergodicity. It will be soon corrected and replaced by a draft
  called &quot;Randomized On-Off Signaling n Asynchronous Wireless Networks&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses an interference channel consisting of $\mathbf{n}$
active users sharing $u$ frequency sub-bands. Users are asynchronous meaning
there exists a mutual delay between their transmitted codes. A stationary model
for interference is considered by assuming the starting point of an
interferer's data is uniformly distributed along the codeword of any user. This
model is not ergodic, however, we show that the noise plus interference process
satisfies an Asymptotic Equipartition Property (AEP) under certain conditions.
This enables us to define achievable rates in the conventional Shannon sense.
The spectrum is divided to private and common bands. Each user occupies its
assigned private band and the common band upon activation. In a scenario where
all transmitters are unaware of the number of active users and the channel
gains, the optimum spectrum assignment is obtained such that the so-called
outage capacity per user is maximized. If $\Pr\{\mathbf{n}&gt;2\}&gt;0$, all users
follow a locally Randomized On-Off signaling scheme on the common band where
each transmitter quits transmitting its Gaussian signals independently from
transmission to transmission. Achievable rates are developed using a
conditional version of Entropy Power Inequality (EPI) and an upper bound on the
differential entropy of a mixed Gaussian random variable. Thereafter, the
activation probability on each transmission slot together with the spectrum
assignment are designed resulting in the largest outage capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2034</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2034</id><created>2010-01-12</created><authors><author><keyname>Pavan</keyname><forenames>Aduri</forenames></author><author><keyname>Tewari</keyname><forenames>Raghunath</forenames></author><author><keyname>Vinodchandran</keyname><forenames>N. V.</forenames></author></authors><title>On the Power of Unambiguity in Logspace</title><categories>cs.CC</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report progress on the \NL vs \UL problem. [-] We show unconditionally
that the complexity class $\ReachFewL\subseteq\UL$. This improves on the
earlier known upper bound $\ReachFewL \subseteq \FewL$. [-] We investigate the
complexity of min-uniqueness - a central notion in studying the \NL vs \UL
problem. We show that min-uniqueness is necessary and sufficient for showing
$\NL =\UL$. We revisit the class $\OptL[\log n]$ and show that {\sc
ShortestPathLength} - computing the length of the shortest path in a DAG, is
complete for $\OptL[\log n]$. We introduce $\UOptL[\log n]$, an unambiguous
version of $\OptL[\log n]$, and show that (a) $\NL =\UL$ if and only if
$\OptL[\log n] = \UOptL[\log n]$, (b) $\LogFew \leq \UOptL[\log n] \leq \SPL$.
[-] We show that the reachability problem over graphs embedded on 3 pages is
complete for \NL. This contrasts with the reachability problem over graphs
embedded on 2 pages which is logspace equivalent to the reachability problem in
planar graphs and hence is in \UL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2038</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2038</id><created>2010-01-12</created><updated>2010-01-27</updated><authors><author><keyname>Jia</keyname><affiliation>Jasmine</affiliation></author><author><keyname>Meng</keyname></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Houssain</keyname><forenames>Ekram</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Collaborative Spectrum Sensing from Sparse Observations Using Matrix
  Completion for Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><journal-ref>ICASSP 3114-3117, 2010</journal-ref><doi>10.1109/ICASSP.2010.5496089</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio, spectrum sensing is a key component to detect spectrum
holes (i.e., channels not used by any primary users). Collaborative spectrum
sensing among the cognitive radio nodes is expected to improve the ability of
checking complete spectrum usage states. Unfortunately, due to power limitation
and channel fading, available channel sensing information is far from being
sufficient to tell the unoccupied channels directly. Aiming at breaking this
bottleneck, we apply recent matrix completion techniques to greatly reduce the
sensing information needed. We formulate the collaborative sensing problem as a
matrix completion subproblem and a joint-sparsity reconstruction subproblem.
Results of numerical simulations that validated the effectiveness and
robustness of the proposed approach are presented. In particular, in noiseless
cases, when number of primary user is small, exact detection was obtained with
no more than 8% of the complete sensing information, whilst as number of
primary user increases, to achieve a detection rate of 95.55%, the required
information percentage was merely 16.8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2050</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2050</id><created>2010-01-12</created><updated>2010-06-12</updated><authors><author><keyname>Li</keyname><forenames>Qiao</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author></authors><title>Scheduling in Wireless Networks under Uncertainties: A Greedy
  Primal-Dual Approach</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>8 pages, 2 figures, submitted to Allerton 2010. The title and
  abstract are updated compared to version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a dynamic primal-dual type algorithm to solve the optimal
scheduling problem in wireless networks subject to uncertain parameters, which
are generated by stochastic network processes such as random packet arrivals,
channel fading, and node mobilities. The algorithm is a generalization of the
well-known max-weight scheduling algorithm proposed by Tassiulas et al., where
only queue length information is used for computing the schedules when the
arrival rates are uncertain. Using the technique of fluid limits, sample path
convergence of the algorithm to an arbitrarily close to optimal solution is
proved, under the assumption that the Strong Law of Large Numbers (SLLN)
applies to the random processes which generate the uncertain parameters. The
performance of the algorithm is further verified by simulation results. The
method may potentially be applied to other applications where dynamic
algorithms for convex problems with uncertain parameters are needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2052</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2052</id><created>2010-01-13</created><authors><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>Block Sensitivity of Minterm-Transitive Functions</title><categories>cs.CC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boolean functions with symmetry properties are interesting from a complexity
theory perspective; extensive research has shown that these functions, if
nonconstant, must have high `complexity' according to various measures.
  In recent work of this type, Sun gave bounds on the block sensitivity of
nonconstant Boolean functions invariant under a transitive permutation group.
Sun showed that all such functions satisfy bs(f) = Omega(N^{1/3}), and that
there exists such a function for which bs(f) = O(N^{3/7}ln N). His example
function belongs to a subclass of transitively invariant functions called the
minterm-transitive functions (defined in earlier work by Chakraborty).
  We extend these results in two ways. First, we show that nonconstant
minterm-transitive functions satisfy bs(f) = Omega(N^{3/7}). Thus Sun's example
function has nearly minimal block sensitivity for this subclass. Second, we
give an improved example: a minterm-transitive function for which bs(f) =
O(N^{3/7}ln^{1/7}N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2059</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2059</id><created>2010-01-12</created><updated>2010-04-12</updated><authors><author><keyname>Nobrega</keyname><forenames>Roberto W.</forenames></author><author><keyname>Uchoa-Filho</keyname><forenames>Bartolomeu F.</forenames></author></authors><title>Multishot Codes for Network Coding using Rank-Metric Codes</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures. Replaced the extended injection distance (and
  doubtful unproven statements about it) with the extended subspace distance;
  some other minor corrections and points clarified.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiplicative-additive finite-field matrix channel arises as an adequate
model for linear network coding systems when links are subject to errors and
erasures, and both the network topology and the network code are unknown. In a
previous work we proposed a general construction of multishot codes for this
channel based on the multilevel coding theory. Herein we apply this
construction to the rank-metric space, obtaining multishot rank-metric codes
which, by lifting, can be converted to codes for the aforementioned channel. We
also adapt well-known encoding and decoding algorithms to the considered
situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2060</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2060</id><created>2010-01-12</created><updated>2010-03-18</updated><authors><author><keyname>Zhao</keyname><forenames>Qingchun</forenames></author><author><keyname>Yin</keyname><forenames>Hongxi</forenames></author></authors><title>Message Detection and Extraction of Chaotic Optical Communication Using
  Time-Frequency Analysis</title><categories>cs.CR</categories><comments>5 pages, 4 figures</comments><journal-ref>6th International Conference on Natural Computation (ICNC 2010),
  (2010) 3067-3071</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The security of chaotic optical communication using time-frequency (TF)
representation is analyzed in this paper. The mean scalogram ratio (MSR) of TF
representation and peak sidelobe level of MSR are defined to detect message.
Algorithm for message detection and extraction is presented in detail. Two
typical message encryption schemes, chaos masking and chaos modulation, are
analyzed. The results reveal that it is not secure to transmit message when the
message frequency locates at low power on power spectrum portrait. The proposed
method is very useful for estimating the security level of message masking in
chaotic optical communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2062</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2062</id><created>2010-01-13</created><authors><author><keyname>Geng</keyname><forenames>Yanlin</forenames></author><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author><author><keyname>Wang</keyname><forenames>Zizhou Vincent</forenames></author></authors><title>On broadcast channels with binary inputs and symmetric outputs</title><categories>cs.IT math.IT</categories><comments>17 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the capacity regions of broadcast channels with binary inputs and
symmetric outputs. We study the partial order induced by the more capable
ordering of broadcast channels for channels belonging to this class. This study
leads to some surprising connections regarding various notions of dominance of
receivers. The results here also help us isolate some classes of symmetric
channels where the best known inner and outer bounds differ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2067</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2067</id><created>2010-01-13</created><authors><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author></authors><title>Refined rate of channel polarization</title><categories>cs.IT math.IT</categories><comments>5 or 6 pages, submitted to IEEE Int. Symp. Info. Theory 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rate-dependent upper bound of the best achievable block error probability
of polar codes with successive-cancellation decoding is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2076</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2076</id><created>2010-01-13</created><authors><author><keyname>Prasad</keyname><forenames>N. Lakshmi</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Fast-Group-Decodable STBCs via Codes over GF(4)</title><categories>cs.IT math.IT</categories><comments>15 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we construct low decoding complexity STBCs by using the Pauli
matrices as linear dispersion matrices. In this case the Hurwitz-Radon
orthogonality condition is shown to be easily checked by transferring the
problem to $\mathbb{F}_4$ domain. The problem of constructing low decoding
complexity STBCs is shown to be equivalent to finding certain codes over
$\mathbb{F}_4$. It is shown that almost all known low complexity STBCs can be
obtained by this approach. New codes are given that have the least known
decoding complexity in particular ranges of rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2077</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2077</id><created>2010-01-13</created><updated>2010-01-18</updated><authors><author><keyname>Guang</keyname><forenames>Xuan</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>On Random Linear Network Coding for Butterfly Network</title><categories>cs.IT math.IT</categories><comments>This paper was submitted to IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random linear network coding is a feasible encoding tool for network coding,
specially for the non-coherent network, and its performance is important in
theory and application. In this letter, we study the performance of random
linear network coding for the well-known butterfly network by analyzing the
failure probabilities. We determine the failure probabilities of random linear
network coding for the well-known butterfly network and the butterfly network
with channel failure probability p.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2086</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2086</id><created>2010-01-13</created><authors><author><keyname>Kuske</keyname><forenames>Dietrich</forenames></author><author><keyname>Liu</keyname><forenames>Jiamou</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>The Isomorphism Problem On Classes of Automatic Structures</title><categories>cs.LO cs.FL</categories><acm-class>F.4.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic structures are finitely presented structures where the universe and
all relations can be recognized by finite automata. It is known that the
isomorphism problem for automatic structures is complete for $\Sigma^1_1$; the
first existential level of the analytical hierarchy. Several new results on
isomorphism problems for automatic structures are shown in this paper: (i) The
isomorphism problem for automatic equivalence relations is complete for
$\Pi^0_1$ (first universal level of the arithmetical hierarchy). (ii) The
isomorphism problem for automatic trees of height $n \geq 2$ is
$\Pi^0_{2n-3}$-complete. (iii) The isomorphism problem for automatic linear
orders is not arithmetical. This solves some open questions of Khoussainov,
Rubin, and Stephan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2097</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2097</id><created>2010-01-13</created><authors><author><keyname>Voyant</keyname><forenames>Cyril</forenames><affiliation>SPE</affiliation></author><author><keyname>Muselli</keyname><forenames>Marc</forenames><affiliation>SPE</affiliation></author><author><keyname>Paoli</keyname><forenames>Christophe</forenames><affiliation>SPE</affiliation></author><author><keyname>Nivet</keyname><forenames>Marie Laure</forenames><affiliation>SPE</affiliation></author><author><keyname>Poggi</keyname><forenames>Philippe</forenames><affiliation>SPE</affiliation></author><author><keyname>Haurant</keyname><forenames>P.</forenames><affiliation>SPE</affiliation></author></authors><title>Predictability of PV power grid performance on insular sites without
  weather stations: use of artificial neural networks</title><categories>cs.NE</categories><proxy>ccsd hal-00442312</proxy><report-no>EU PVSEC 2009</report-no><journal-ref>24th European Photovoltaic Solar Energy Conference, Hamburg :
  Germany (2009)</journal-ref><doi>10.4229/24thEUPVSEC2009-5BV.2.35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The official meteorological network is poor on the island of Corsica: only
three sites being about 50 km apart are equipped with pyranometers which enable
measurements by hourly and daily step. These sites are Ajaccio (41\degree 55'N
and 8\degree 48'E, seaside), Bastia (42\degree 33'N, 9\degree 29'E, seaside)
and Corte (42\degree 30'N, 9\degree 15'E average altitude of 486 meters). This
lack of weather station makes difficult the predictability of PV power grid
performance. This work intends to study a methodology which can predict global
solar irradiation using data available from another location for daily and
hourly horizon. In order to achieve this prediction, we have used Artificial
Neural Network which is a popular artificial intelligence technique in the
forecasting domain. A simulator has been obtained using data available for the
station of Ajaccio that is the only station for which we have a lot of data: 16
years from 1972 to 1987. Then we have tested the efficiency of this simulator
in two places with different geographical features: Corte, a mountainous region
and Bastia, a coastal region. On daily horizon, the relocation has implied
fewer errors than a &quot;na\&quot;ive&quot; prediction method based on the persistence
(RMSE=1468 Vs 1383Wh/m^2 to Bastia and 1325 Vs 1213Wh/m^2 to Corte). On hourly
case, the results were still satisfactory, and widely better than persistence
(RMSE=138.8 Vs 109.3 Wh/m^2 to Bastia and 135.1 Vs 114.7 Wh/m^2 to Corte). The
last experiment was to evaluate the accuracy of our simulator on a PV power
grid localized at 10 km from the station of Ajaccio. We got errors very
suitable (nRMSE=27.9%, RMSE=99.0 W.h) compared to those obtained with the
persistence (nRMSE=42.2%, RMSE=149.7 W.h).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2100</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2100</id><created>2010-01-13</created><updated>2011-02-10</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author></authors><title>What's Decidable About Sequences?</title><categories>cs.LO</categories><comments>Fixed a few lapses in the Mergesort example</comments><journal-ref>Proceedings of the 8th International Symposium on Automated
  Technology for Verification and Analysis (ATVA'10). Lecture Notes in Computer
  Science, 6252:128--142, Springer-Verlag, September 2010</journal-ref><doi>10.1007/978-3-642-15643-4_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a first-order theory of sequences with integer elements,
Presburger arithmetic, and regular constraints, which can model significant
properties of data structures such as arrays and lists. We give a decision
procedure for the quantifier-free fragment, based on an encoding into the
first-order theory of concatenation; the procedure has PSPACE complexity. The
quantifier-free fragment of the theory of sequences can express properties such
as sortedness and injectivity, as well as Boolean combinations of periodic and
arithmetic facts relating the elements of the sequence and their positions
(e.g., &quot;for all even i's, the element at position i has value i+3 or 2i&quot;). The
resulting expressive power is orthogonal to that of the most expressive
decidable logics for arrays. Some examples demonstrate that the fragment is
also suitable to reason about sequence-manipulating programs within the
standard framework of axiomatic semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2101</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2101</id><created>2010-01-13</created><updated>2010-06-29</updated><authors><author><keyname>Sir&#xe9;n</keyname><forenames>Jouni</forenames></author></authors><title>Sampled Longest Common Prefix Array</title><categories>cs.DS</categories><comments>This is a slightly extended version of the paper that was presented
  at CPM 2010. The implementation is available at
  http://www.cs.helsinki.fi/group/suds/rlcsa/</comments><doi>10.1007/978-3-642-13509-5_21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When augmented with the longest common prefix (LCP) array and some other
structures, the suffix array can solve many string processing problems in
optimal time and space. A compressed representation of the LCP array is also
one of the main building blocks in many compressed suffix tree proposals. In
this paper, we describe a new compressed LCP representation: the sampled LCP
array. We show that when used with a compressed suffix array (CSA), the sampled
LCP array often offers better time/space trade-offs than the existing
alternatives. We also show how to construct the compressed representations of
the LCP array directly from a CSA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2112</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2112</id><created>2010-01-13</created><authors><author><keyname>Renk</keyname><forenames>Tobias</forenames></author><author><keyname>Jaekel</keyname><forenames>Holger</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Outage Capacity of Bursty Amplify-and-Forward with Incremental Relaying</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE International Symposium on
  Information Theory, Austin, TX, June 13-18, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the outage capacity of a bursty version of the amplify-and-forward
(BAF) protocol for small signal-to-noise ratios when incremental relaying is
used. We show that the ratio between the outage capacities of BAF and the
cut-set bound is independent of the relay position and that BAF is outage
optimal for certain conditions on the target rate R. This is in contrast to
decode-and-forward with incremental relaying, where the relay location strongly
determines the performance of the cooperative protocol. We further derive the
outage capacity for a network consisting of an arbitrary number of relay nodes.
In this case the relays transmit in subsequent partitions of the overall
transmission block and the destination accumulates signal-to-noise ratio until
it is able to decode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2117</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2117</id><created>2010-01-13</created><authors><author><keyname>Renk</keyname><forenames>Tobias</forenames></author><author><keyname>Jaekel</keyname><forenames>Holger</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich</forenames></author></authors><title>On Outage Capacity for Incremental Relaying with Imperfect Feedback</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, submitted to IEEE International Symposium on
  Information Theory, Austin, TX, June 13-18, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the effect of imperfect feedback on the \epsilon-outage
capacity of incremental relaying in the low signal-to-noise ratio (SNR) regime.
We show that imperfect feedback leads to a rescaling of the pre-log factor
(comparable to the multiplexing gain for networks operating in the high SNR
regime) and thus reduces the \epsilon-outage capacity considerably. Moreover,
we investigate the effect of different degrees of feedback reliability on the
system performance. We further derive a simple binary tree-based construction
rule to analyze networks with an arbitrary number of relay nodes with respect
to imperfect feedback. This rule can directly be mapped to a comprehensive
matrix notation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2140</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2140</id><created>2010-01-13</created><updated>2010-02-12</updated><authors><author><keyname>Madhavan</keyname><forenames>Mukundan</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author><author><keyname>Sankarasubramaniam</keyname><forenames>Yogesh</forenames></author><author><keyname>Viswanathan</keyname><forenames>Kapali</forenames></author></authors><title>NLHB : A Non-Linear Hopper Blum Protocol</title><categories>cs.CR</categories><comments>Revision 1 : Typos fixes, presentation changes made</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a light-weight provably-secure authentication
protocol called the NLHB protocol, which is a variant of the HB protocol. The
HB protocol uses the complexity of decoding linear codes for security against
passive attacks. In contrast, security for the NLHB protocol is proved by
reducing passive attacks to the problem of decoding a class of non-linear codes
that are provably hard. We demonstrate that the existing passive attacks on the
HB protocol family, which have contributed to considerable reduction in its
effective key-size, are ineffective against the NLHB protocol.
  From the evidence, we conclude that smaller-key sizes are sufficient for the
NLHB protocol to achieve the same level of passive attack security as the HB
Protocol. Further, for this choice of parameters, we provide an implementation
instance for the NLHB protocol for which the Prover/Verifier complexity is
lower than the HB protocol, enabling authentication on very low-cost devices
like RFID tags. Finally, in the spirit of the HB$^{+}$ protocol, we extend the
NLHB protocol to the NLHB$^{+}$ protocol and prove security against the class
of active attacks defined in the DET Model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2155</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2155</id><created>2010-01-13</created><authors><author><keyname>Kim</keyname><forenames>Jungwon</forenames></author><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>McLeod</keyname><forenames>Julie</forenames></author></authors><title>Cooperative Automated Worm Response and Detection Immune Algorithm</title><categories>cs.AI cs.CR cs.NE</categories><comments>14 pages, 2 figures, 2 tables, 4th International Conference on
  Artificial Immune Systems (ICARIS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The role of T-cells within the immune system is to confirm and assess
anomalous situations and then either respond to or tolerate the source of the
effect. To illustrate how these mechanisms can be harnessed to solve real-world
problems, we present the blueprint of a T-cell inspired algorithm for computer
security worm detection. We show how the three central T-cell processes, namely
T-cell maturation, differentiation and proliferation, naturally map into this
domain and further illustrate how such an algorithm fits into a complete immune
inspired computer security system and framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2160</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2160</id><created>2010-01-13</created><updated>2010-02-03</updated><authors><author><keyname>Grigorieff</keyname><forenames>Serge</forenames></author><author><keyname>Valarcher</keyname><forenames>Pierre</forenames></author></authors><title>Evolving MultiAlgebras unify all usual sequential computation models</title><categories>cs.FL cs.LO</categories><comments>12 pages, Symposium on Theoretical Aspects of Computer Science</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  It is well-known that Abstract State Machines (ASMs) can simulate
&quot;step-by-step&quot; any type of machines (Turing machines, RAMs, etc.). We aim to
overcome two facts: 1) simulation is not identification, 2) the ASMs simulating
machines of some type do not constitute a natural class among all ASMs. We
modify Gurevich's notion of ASM to that of EMA (&quot;Evolving MultiAlgebra&quot;) by
replacing the program (which is a syntactic object) by a semantic object: a
functional which has to be very simply definable over the static part of the
ASM. We prove that very natural classes of EMAs correspond via &quot;literal
identifications&quot; to slight extensions of the usual machine models and also to
grammar models. Though we modify these models, we keep their computation
approach: only some contingencies are modified. Thus, EMAs appear as the
mathematical model unifying all kinds of sequential computation paradigms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2164</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2164</id><created>2010-01-13</created><authors><author><keyname>Yazdi</keyname><forenames>S. M. Hossein Tabatabaei</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>The Capacity of a Class of Linear Deterministic Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate optimal coding strategies for a class of linear
deterministic relay networks. The network under study is a relay network, with
one source, one destination, and two relay nodes. Additionally, there is a
disturbing source of signals that causes interference with the information
signals received by the relay nodes. Our model captures the effect of the
interference of message signals and disturbing signals on a single relay
network, or the interference of signals from multiple relay networks with each
other in the linear deterministic framework. For several ranges of the network
parameters we find upper bounds on the maximum achievable source--destination
rate in the presense of the disturbing node and in each case we find an optimal
coding scheme that achieves the upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2170</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2170</id><created>2010-01-13</created><authors><author><keyname>Majid</keyname><forenames>Mazlina Abdul</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author></authors><title>Comparing Simulation Output Accuracy of Discrete Event and Agent Based
  Models: A Quantitive Approach</title><categories>cs.AI cs.MA</categories><comments>8 pages, 8 Figures, 5 Tables, Summer Computer Simulation Conference
  (SCSC 2009), Istambul, Turkey</comments><journal-ref>Proceedings of Summer Computer Simulation Conference (SCSC 2009),
  Istambul, Turkey</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our research we investigate the output accuracy of discrete event
simulation models and agent based simulation models when studying human centric
complex systems. In this paper we focus on human reactive behaviour as it is
possible in both modelling approaches to implement human reactive behaviour in
the model by using standard methods. As a case study we have chosen the retail
sector, and here in particular the operations of the fitting room in the women
wear department of a large UK department store. In our case study we looked at
ways of determining the efficiency of implementing new management policies for
the fitting room operation through modelling the reactive behaviour of staff
and customers of the department. First, we have carried out a validation
experiment in which we compared the results from our models to the performance
of the real system. This experiment also allowed us to establish differences in
output accuracy between the two modelling methids. In a second step a
multi-scenario experiment was carried out to study the behaviour of the models
when they are used for the purpose of operational improvement. Overall we have
found that for our case study example both discrete event simulation and agent
based simulation have the same potential to support the investigation into the
efficiency of implementing new management policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2175</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2175</id><created>2010-01-13</created><updated>2010-02-19</updated><authors><author><keyname>Mathissen</keyname><forenames>Christian</forenames></author></authors><title>Weighted Logics for Nested Words and Algebraic Formal Power Series</title><categories>cs.LO</categories><acm-class>F.1.1; F.1.2; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (February
  19, 2010) lmcs:854</journal-ref><doi>10.2168/LMCS-6(1:5)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nested words, a model for recursive programs proposed by Alur and Madhusudan,
have recently gained much interest. In this paper we introduce quantitative
extensions and study nested word series which assign to nested words elements
of a semiring. We show that regular nested word series coincide with series
definable in weighted logics as introduced by Droste and Gastin. For this we
establish a connection between nested words and the free bisemigroup. Applying
our result, we obtain characterizations of algebraic formal power series in
terms of weighted logics. This generalizes results of Lautemann, Schwentick and
Therien on context-free languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2186</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2186</id><created>2010-01-13</created><authors><author><keyname>Jiang</keyname><forenames>Luo-Luo</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Wakeling</keyname><forenames>Joseph R.</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Building reputation systems for better ranking</title><categories>cs.IR cs.DB</categories><comments>5 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How to rank web pages, scientists and online resources has recently attracted
increasing attention from both physicists and computer scientists. In this
paper, we study the ranking problem of rating systems where users vote objects
by discrete ratings. We propose an algorithm that can simultaneously evaluate
the user reputation and object quality in an iterative refinement way.
According to both the artificially generated data and the real data from
MovieLens and Amazon, our algorithm can considerably enhance the ranking
accuracy. This work highlights the significance of reputation systems in the
Internet era and points out a way to evaluate and compare the performances of
different reputation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2188</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2188</id><created>2010-01-13</created><authors><author><keyname>Deransart</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Oliveira</keyname><forenames>Rafael</forenames><affiliation>CIN</affiliation></author></authors><title>Towards a Generic Framework to Generate Explanatory Traces of Constraint
  Solving and Rule-Based Reasoning</title><categories>cs.PL</categories><proxy>ccsd inria-00443635</proxy><report-no>RR-7165</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we show how to use the Simple Fluent Calculus (SFC) to
specify generic tracers, i.e. tracers which produce a generic trace. A generic
trace is a trace which can be produced by different implementations of a
software component and used independently from the traced component. This
approach is used to define a method for extending a java based CHRor platform
called CHROME (Constraint Handling Rule Online Model-driven Engine) with an
extensible generic tracer. The method includes a tracer specification in SFC, a
methodology to extend it, and the way to integrate it with CHROME, resulting in
the platform CHROME-REF (for Reasoning Explanation Facilities), which is a
constraint solving and rule based reasoning engine with explanatory traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2190</identifier>
 <datestamp>2010-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2190</id><created>2010-01-13</created><updated>2010-05-19</updated><authors><author><keyname>Furuichi</keyname><forenames>Shigeru</forenames></author></authors><title>Characterizations of generalized entropy functions by functional
  equations</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We shall show that a two-parameter extended entropy function is characterized
by a functional equation. As a corollary of this result, we obtain that the
Tsallis entropy function is characterized by a functional equation, which is a
different form used in \cite{ST} i.e., in Proposition \ref{prop01} in the
present paper. We also give an interpretation of the functional equation giving
the Tsallis entropy function, in the relation with two non-additive properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2195</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2195</id><created>2010-01-13</created><authors><author><keyname>Al-Hammadi</keyname><forenames>Yousof</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author></authors><title>DCA for Bot Detection</title><categories>cs.AI cs.CR cs.NE</categories><comments>10pages, 5 tables, 6 figures, IEEE World Congress on Computational
  Intelligence (WCCI2008), Hong Kong</comments><journal-ref>Proceedings of the IEEE World Congress on Computational
  Intelligence (WCCI2008), Hong Kong</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring the security of computers is a non-trivial task, with many
techniques used by malicious users to compromise these systems. In recent years
a new threat has emerged in the form of networks of hijacked zombie machines
used to perform complex distributed attacks such as denial of service and to
obtain sensitive data such as password information. These zombie machines are
said to be infected with a 'bot' - a malicious piece of software which is
installed on a host machine and is controlled by a remote attacker, termed the
'botmaster of a botnet'. In this work, we use the biologically inspired
Dendritic Cell Algorithm (DCA) to detect the existence of a single bot on a
compromised host machine. The DCA is an immune-inspired algorithm based on an
abstract model of the behaviour of the dendritic cells of the human body. The
basis of anomaly detection performed by the DCA is facilitated using the
correlation of behavioural attributes such as keylogging and packet flooding
behaviour. The results of the application of the DCA to the detection of a
single bot show that the algorithm is a successful technique for the detection
of such malicious software without responding to normally running programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2198</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2198</id><created>2010-01-13</created><authors><author><keyname>Tresch</keyname><forenames>R.</forenames></author><author><keyname>Guillaud</keyname><forenames>M.</forenames></author></authors><title>Performance of Interference Alignment in Clustered Wireless Ad Hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial interference alignment among a finite number of users is proposed as
a technique to increase the probability of successful transmission in an
interference limited clustered wireless ad hoc network. Using techniques from
stochastic geometry, we build on the work of Ganti and Haenggi dealing with
Poisson cluster processes with a fixed number of cluster points and provide a
numerically integrable expression for the outage probability using an
intra-cluster interference alignment strategy with multiplexing gain one. For a
special network setting we derive a closed-form upper bound. We demonstrate
significant performance gains compared to single-antenna systems without local
cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2205</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2205</id><created>2010-01-13</created><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author><author><keyname>Junior</keyname><forenames>Valdemar Cardoso da Rocha</forenames></author><author><keyname>Pimentel</keyname><forenames>Cecilio</forenames></author></authors><title>Deriving the Probabilistic Capacity of General Run-Length Sets Using
  Generating Functions</title><categories>cs.IT cs.FL math.CO math.IT</categories><comments>5 pages, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In &quot;Reliable Communication in the Absence of a Common Clock&quot; (Yeung et al.,
2009), the authors introduce general run-length sets, which form a class of
constrained systems that permit run-lengths from a countably infinite set. For
a particular definition of probabilistic capacity, they show that probabilistic
capacity is equal to combinatorial capacity. In the present work, it is shown
that the same result also holds for Shannon's original definition of
probabilistic capacity. The derivation presented here is based on generating
functions of constrained systems as developed in &quot;On the Capacity of
Constrained Systems&quot; (Boecherer et al., 2010) and provides a unified
information-theoretic treatment of general run-length sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2208</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2208</id><created>2010-01-13</created><updated>2010-03-09</updated><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Biological Inspiration for Artificial Immune Systems</title><categories>cs.AI cs.NE</categories><comments>12 pages, 6th International Conference on Artificial Immune Systems
  (ICARIS2007), Lecture Notes in Computer Science 4628, Santos, Brazil</comments><journal-ref>Proceedings of the 6th International Conference on Artificial
  Immune Systems (ICARIS2007), Lecture Notes in Computer Science 4628, Santos,
  Brazil</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial immune systems (AISs) to date have generally been inspired by
naive biological metaphors. This has limited the effectiveness of these
systems. In this position paper two ways in which AISs could be made more
biologically realistic are discussed. We propose that AISs should draw their
inspiration from organisms which possess only innate immune systems, and that
AISs should employ systemic models of the immune system to structure their
overall design. An outline of plant and invertebrate immune systems is
presented, and a number of contemporary research that more
biologically-realistic AISs could have is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2218</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2218</id><created>2010-01-13</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Bounds on the Capacity of the Relay Channel with Noncausal State
  Information at Source</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to 2010 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a three-terminal state-dependent relay channel with the channel
state available non-causally at only the source. Such a model may be of
interest for node cooperation in the framework of cognition, i.e.,
collaborative signal transmission involving cognitive and non-cognitive radios.
We study the capacity of this communication model. One principal problem in
this setup is caused by the relay's not knowing the channel state. In the
discrete memoryless (DM) case, we establish lower bounds on channel capacity.
For the Gaussian case, we derive lower and upper bounds on the channel
capacity. The upper bound is strictly better than the cut-set upper bound. We
show that one of the developed lower bounds comes close to the upper bound,
asymptotically, for certain ranges of rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2228</identifier>
 <datestamp>2010-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2228</id><created>2010-01-13</created><updated>2010-05-17</updated><authors><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Estimation with Random Linear Mixing, Belief Propagation and Compressed
  Sensing</title><categories>cs.IT math.IT</categories><comments>24 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply Guo and Wang's relaxed belief propagation (BP) method to the
estimation of a random vector from linear measurements followed by a
componentwise probabilistic measurement channel. Relaxed BP uses a Gaussian
approximation in standard BP to obtain significant computational savings for
dense measurement matrices. The main contribution of this paper is to extend
the relaxed BP method and analysis to general (non-AWGN) output channels.
Specifically, we present detailed equations for implementing relaxed BP for
general channels and show that relaxed BP has an identical asymptotic large
sparse limit behavior as standard BP, as predicted by the Guo and Wang's state
evolution (SE) equations. Applications are presented to compressed sensing and
estimation with bounded noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2249</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2249</id><created>2010-01-13</created><authors><author><keyname>Hansen</keyname><forenames>Klaus</forenames></author><author><keyname>Larsen</keyname><forenames>Troels</forenames></author><author><keyname>Olsen</keyname><forenames>Kim</forenames></author></authors><title>On the Efficiency of Fast RSA Variants in Modern Mobile Phones</title><categories>cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 136-140, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern mobile phones are increasingly being used for more services that
require modern security mechanisms such as the public key cryptosystem RSA. It
is, however, well known that public key cryptography demands considerable
computing resources and that RSA encryption is much faster than RSA decryption.
It is consequently an interesting question if RSA as a whole can be executed
efficiently on modern mobile phones. In this paper, we explore the efficiency
on modern mobile phones of variants of the RSA cryptosystem, covering CRT,
MultiPrime RSA, MultiPower RSA, Rebalanced RSA and R Prime RSA by comparing the
encryption and decryption time using a simple Java implementation and a typical
RSA setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2250</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2250</id><created>2010-01-13</created><authors><author><keyname>Kumar</keyname><forenames>B. Sathish</forenames></author><author><keyname>Kumar</keyname><forenames>K. R. Shankar</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>R.</forenames></author></authors><title>An Efficient Inter Carrier Interference Cancellation Schemes for OFDM
  Systems</title><categories>cs.OH</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 141-148, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal Frequency Division Multiplexing (OFDM) has recently been used
widely in wireless communication systems. OFDM is very effective in combating
intersymbol interference and can achieve high data rate in frequency selective
channel. For OFDM communication systems, the frequency offsets in mobile radio
channels distort the orthogonality between subcarriers resulting in Inter
Carrier Interference (ICI). ICI causes power leakage among subcarriers thus
degrading the system performance. A wellknown problem of OFDM is its
sensitivity to frequency offset between the transmitted and received carrier
frequencies. There are two deleterious effects caused by frequency offset one
is the reduction of signal amplitude in the output of the filters matched to
each of the carriers and the second is introduction of ICI from the other
carriers. This research work investigates three effective methods for combating
the effects of ICI: ICI Self Cancellation (SC), Maximum Likelihood (ML)
estimation, and Extended Kalman Filter (EKF) method. These three methods are
compared in terms of bit error rate performance and bandwidth efficiency.
Through simulations, it is shown that the three techniques are effective in
mitigating the modulation schemes, the ML and EKF methods perform better than
the SC method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2253</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2253</id><created>2010-01-13</created><authors><author><keyname>Jamjaem</keyname><forenames>Theerayut</forenames></author><author><keyname>Burapattanasiri</keyname><forenames>Bancha</forenames></author></authors><title>High Precision HalfWave Rectifier Circuit In Dual Phase Output Mode</title><categories>cs.OH</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 149-152, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper present high precision halfwave rectifier circuit in dual phase
output mode by 0.5 micrometer CMOS technology, plus or minus 1.5 V low voltage,
it has received input signal and sent output current signal, respond in high
frequency. The main structure compound with CMOS inverter circuit, common
source circuit, and current mirror circuit. Simulation and confirmation quality
of working by PSpice program, then it able to operating at maximum frequency
about 100 MHz, maximum input current range about 400 \mu Ap p, high precision
output signal, low power dissipation, and uses a little transistor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2258</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2258</id><created>2010-01-13</created><updated>2011-09-07</updated><authors><author><keyname>Potgantwar</keyname><forenames>A. D.</forenames></author><author><keyname>Wadhai</keyname><forenames>Vijay M.</forenames></author></authors><title>Internal Location Based System For Mobile Devices Using Passive RFID And
  Wireless Technology</title><categories>cs.CY</categories><comments>This article has been withdrawn by arXiv administrators due to
  plagiarized content from arXiv:1009.3448</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 153-159, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article has been withdrawn by arXiv administrators due to plagiarized
content from arXiv:1009.3448.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2261</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2261</id><created>2010-01-13</created><authors><author><keyname>Burapattanasiri</keyname><forenames>Bancha</forenames></author></authors><title>High Precision MultiWave Rectifier Circuit Operating in Low Voltage 1.5
  Volt Current Mode</title><categories>cs.OH</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 160-164, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is present high precision multiwave rectifier circuit operating
in low voltage plus or minus 1.5 Volt current modes by CMOS technology 0.5
\mum, receive input and give output in current mode, respond at high frequency
period. The structure compound with high speed current comparator circuit,
current mirror circuit, and CMOS inverter circuit. PSpice program used for
confirmation the performance of testing. The PSpice program shows operating of
circuit is able to working at maximum input current 400 \muAp p, maximum
frequency responding 200 MHz, high precision and low power losses, and
non-precision zero crossing output signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2262</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2262</id><created>2010-01-13</created><authors><author><keyname>Jooya</keyname><forenames>A. Z.</forenames></author><author><keyname>Analoui</keyname><forenames>M.</forenames></author></authors><title>Classifying Application Phases in Asymmetric Chip Multiprocessors</title><categories>cs.DC cs.AR cs.PF</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 165-170, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In present study, in order to improve the performance and reduce the amount
of power which is dissipated in heterogeneous multicore processors, the ability
of detecting the program execution phases is investigated. The programs
execution intervals have been classified in different phases based on their
throughput and the utilization of the cores. The results of implementing the
phase detection technique are investigated on a single core processor and also
on a multicore processor. To minimize the profiling overhead, an algorithm for
the dynamic adjustment of the profiling intervals is presented. It is based on
the behavior of the program and reduces the profiling overhead more than three
fold. The results are obtained from executing multiprocessor benchmarks on a
given processor. In order to show the program phases clearly, throughput and
utilization of execution intervals are presented on a scatter plot. The results
are presented for both fixed and variable intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2263</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2263</id><created>2010-01-13</created><authors><author><keyname>Kalyani</keyname><forenames>N.</forenames></author><author><keyname>Sunitha</keyname><forenames>Dr K. V. N.</forenames></author></authors><title>Syllable Analysis to Build a Dictation System in Telugu language</title><categories>cs.CL cs.HC</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 171-176, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent decades, Speech interactive systems gained increasing importance.
To develop Dictation System like Dragon for Indian languages it is most
important to adapt the system to a speaker with minimum training. In this paper
we focus on the importance of creating speech database at syllable units and
identifying minimum text to be considered while training any speech recognition
system. There are systems developed for continuous speech recognition in
English and in few Indian languages like Hindi and Tamil. This paper gives the
statistical details of syllables in Telugu and its use in minimizing the search
space during recognition of speech. The minimum words that cover maximum
syllables are identified. This words list can be used for preparing a small
text which can be used for collecting speech sample while training the
dictation system. The results are plotted for frequency of syllables and the
number of syllables in each word. This approach is applied on the CIIL Mysore
text corpus which is of 3 million words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2264</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2264</id><created>2010-01-13</created><authors><author><keyname>Burapattanasiri</keyname><forenames>Bancha</forenames></author></authors><title>Sinusoidal Frequency Doublers Circuit With Low Voltage 1.5 Volt CMOS
  Inverter</title><categories>cs.OH</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 177-180, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is present sinusoidal frequency doublers circuit with low voltage
1.5 volt CMOS inverter. Main structure of circuit has three parts that is CMOS
inverter circuit, differential amplifier circuit, and square root circuit. This
circuit has designed to receive input voltage and give output voltage use few
MOS transistor, easy to understand, non complex of circuit, high precision, low
error and low power. The Simulation of circuit has MOS transistor functional in
active and saturation period. PSpice programmed has used to confirmation of
testing and simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2267</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2267</id><created>2010-01-13</created><authors><author><keyname>Anusuya</keyname><forenames>M. A.</forenames></author><author><keyname>Katti</keyname><forenames>S. K.</forenames></author></authors><title>Speech Recognition by Machine, A Review</title><categories>cs.CL</categories><comments>25 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 181-205, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a brief survey on Automatic Speech Recognition and
discusses the major themes and advances made in the past 60 years of research,
so as to provide a technological perspective and an appreciation of the
fundamental progress that has been accomplished in this important area of
speech communication. After years of research and development the accuracy of
automatic speech recognition remains one of the important research challenges
(e.g., variations of the context, speakers, and environment).The design of
Speech Recognition system requires careful attentions to the following issues:
Definition of various types of speech classes, speech representation, feature
extraction techniques, speech classifiers, database and performance evaluation.
The problems that are existing in ASR and the various techniques to solve these
problems constructed by various research workers have been presented in a
chronological order. Hence authors hope that this work shall be a contribution
in the area of speech recognition. The objective of this review paper is to
summarize and compare some of the well known methods used in various stages of
speech recognition system and identify research topic and applications which
are at the forefront of this exciting and challenging field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2268</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2268</id><created>2010-01-13</created><authors><author><keyname>Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Azgomi</keyname><forenames>Mohammad Abdollahi</forenames></author></authors><title>An Extension for Combination of Duty Constraints in Role-Based Access
  Control</title><categories>cs.CR</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 206-215, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among access control models, Role Based Access Control (RBAC) is very useful
and is used in many computer systems. Static Combination of Duty (SCD) and
Dynamic Combination of Duty (DCD) constraints have been introduced recently for
this model to handle dependent roles. These roles must be used together and can
be considered as a contrary point of conflicting roles. In this paper, we
propose several new types of SCD and DCD constraints. Also, we introduce strong
dependent roles and define new groups of SCD constraints for these types of
roles as SCD with common items and SCD with union items. In addition, we
present an extension for SCD constraints in the presence of hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2270</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2270</id><created>2010-01-13</created><authors><author><keyname>Boora</keyname><forenames>Rajesh Kumar</forenames></author><author><keyname>Shukla</keyname><forenames>Ruchi</forenames></author><author><keyname>Misra</keyname><forenames>A. K.</forenames></author></authors><title>An Improved Approach to High Level Privacy Preserving Itemset Mining</title><categories>cs.DB cs.IR</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 216-223, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy preserving association rule mining has triggered the development of
many privacy preserving data mining techniques. A large fraction of them use
randomized data distortion techniques to mask the data for preserving. This
paper proposes a new transaction randomization method which is a combination of
the fake transaction randomization method and a new per transaction
randomization method. This method distorts the items within each transaction
and ensures a higher level of data privacy in comparison to the previous
approaches. The pertransaction randomization method involves a randomization
function to replace the item by a random number guarantying privacy within the
transaction also. A tool has also been developed to implement the proposed
approach to mine frequent itemsets and association rules from the data
guaranteeing the antimonotonic property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2272</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2272</id><created>2010-01-13</created><authors><author><keyname>Babu</keyname><forenames>H. S. Ramesh</forenames></author><author><keyname>Shankar</keyname><forenames>Gowri</forenames></author><author><keyname>Satyanarayana</keyname><forenames>P. S.</forenames></author></authors><title>Call Admission Control performance model for Beyond 3G Wireless Networks</title><categories>cs.NI</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 224-229, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Next Generation Wireless Networks (NGWN) will be heterogeneous in nature
where the different Radio Access Technologies (RATs) operate together .The
mobile terminals operating in this heterogeneous environment will have
different QoS requirements to be handled by the system. These QoS requirements
are determined by a set of QoS parameters. The radio resource management is one
of the key challenges in NGWN. Call admission control is one of the radio
resource management technique plays instrumental role in ensure the desired QoS
to the users working on different applications which have diversified QoS
requirements from the wireless networks . The call blocking probability is one
such QoS parameter for the wireless network. For better QoS it is desirable to
reduce the call blocking probability. In this customary scenario it is highly
desirable to obtain analytic Performance model. In this paper we propose a
higher order Markov chain based performance model for call admission control in
a heterogeneous wireless network environment. In the proposed algorithm we have
considered three classes of traffic having different QoS requirements and we
have considered the heterogeneous network environment which includes the RATs
that can effectively handle applications like voice calls, Web browsing and
file transfer applications which are with varied QoS parameters. The paper
presents the call blocking probabilities for all the three types of traffic
both for fixed and varied traffic scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2274</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2274</id><created>2010-01-13</created><updated>2010-01-13</updated><authors><author><keyname>Halabian</keyname><forenames>Hassan</forenames></author><author><keyname>Lambadaris</keyname><forenames>Ioannis</forenames></author><author><keyname>Lung</keyname><forenames>Chung-Horng</forenames></author></authors><title>Network Capacity Region of Multi-Queue Multi-Server Queueing System with
  Time Varying Connectivities</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network capacity region of multi-queue multi-server queueing system with
random ON-OFF connectivities and stationary arrival processes is derived in
this paper. Specifically, the necessary and sufficient conditions for the
stability of the system are derived under general arrival processes with finite
first and second moments. In the case of stationary arrival processes, these
conditions establish the network capacity region of the system. It is also
shown that AS/LCQ (Any Server/Longest Connected Queue) policy stabilizes the
system when it is stabilizable. Furthermore, an upper bound for the average
queue occupancy is derived for this policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2275</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2275</id><created>2010-01-13</created><authors><author><keyname>Shahraki</keyname><forenames>Mohammad Nadimi</forenames></author><author><keyname>Mustapha</keyname><forenames>Norwati</forenames></author><author><keyname>Sulaiman</keyname><forenames>Md Nasir B</forenames></author><author><keyname>Mamat</keyname><forenames>Ali B</forenames></author></authors><title>Efficient Candidacy Reduction For Frequent Pattern Mining</title><categories>cs.DB</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 230-237, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Certainly, nowadays knowledge discovery or extracting knowledge from large
amount of data is a desirable task in competitive businesses. Data mining is a
main step in knowledge discovery process. Meanwhile frequent patterns play
central role in data mining tasks such as clustering, classification, and
association analysis. Identifying all frequent patterns is the most time
consuming process due to a massive number of candidate patterns. For the past
decade there have been an increasing number of efficient algorithms to mine the
frequent patterns. However reducing the number of candidate patterns and
comparisons for support counting are still two problems in this field which
have made the frequent pattern mining one of the active research themes in data
mining. A reasonable solution is identifying a small candidate pattern set from
which can generate all frequent patterns. In this paper, a method is proposed
based on a new candidate set called candidate head set or H which forms a small
set of candidate patterns. The experimental results verify the accuracy of the
proposed method and reduction of the number of candidate patterns and
comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2277</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2277</id><created>2010-01-13</created><authors><author><keyname>Elamvazuthi</keyname><forenames>I.</forenames></author><author><keyname>Ganesan</keyname><forenames>T.</forenames></author><author><keyname>Vasant</keyname><forenames>P.</forenames></author><author><keyname>Webb</keyname><forenames>J. F.</forenames></author></authors><title>Application of a Fuzzy Programming Technique to Production Planning in
  the Textile Industry</title><categories>cs.AI</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 238-243, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many engineering optimization problems can be considered as linear
programming problems where all or some of the parameters involved are
linguistic in nature. These can only be quantified using fuzzy sets. The aim of
this paper is to solve a fuzzy linear programming problem in which the
parameters involved are fuzzy quantities with logistic membership functions. To
explore the applicability of the method a numerical example is considered to
determine the monthly production planning quotas and profit of a home textile
group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2279</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2279</id><created>2010-01-13</created><authors><author><keyname>Elamvazuthi</keyname><forenames>I.</forenames></author><author><keyname>Vasant</keyname><forenames>P.</forenames></author><author><keyname>Webb</keyname><forenames>J. F.</forenames></author></authors><title>The Application of Mamdani Fuzzy Model for Auto Zoom Function of a
  Digital Camera</title><categories>cs.AI</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 244-249, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mamdani Fuzzy Model is an important technique in Computational Intelligence
(CI) study. This paper presents an implementation of a supervised learning
method based on membership function training in the context of Mamdani fuzzy
models. Specifically, auto zoom function of a digital camera is modelled using
Mamdani technique. The performance of control method is verified through a
series of simulation and numerical results are provided as illustrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2280</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2280</id><created>2010-01-13</created><authors><author><keyname>Kolhar</keyname><forenames>Manjur S</forenames></author><author><keyname>Abu-Alhaj</keyname><forenames>Mosleh M.</forenames></author><author><keyname>Abouabdalla</keyname><forenames>Omar</forenames></author><author><keyname>Wan</keyname><forenames>Tat Chee</forenames></author><author><keyname>Manasrah</keyname><forenames>Ahmad M.</forenames></author></authors><title>Comparative Evaluation and Analysis of IAX and RSW</title><categories>cs.NI cs.MM</categories><comments>3 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Volume 6, No. 3, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 250-252, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice over IP (VoIP) is a technology to transport media over IP networks such
as the Internet. VoIP has the capability of connecting people over packet
switched networks instead of traditional circuit switched networks. Recently,
the InterAsterisk Exchange Protocol (IAX) has emerged as a new VoIP which is
gaining popularity among VoIP products. IAX is known for its simplicity, NAT
friendliness, efficiency, and robustness. More recently, the Real time
Switching (RSW) control criterion has emerged as a multimedia conferencing
protocol. In this paper, we made a comparative evaluation and analysis of IAX
and RSW using Mean Opinion Score rating (MOS) and found that they both perform
well under different network packet delays in ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2283</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2283</id><created>2010-01-13</created><authors><author><keyname>Rusek</keyname><forenames>Fredrik</forenames></author><author><keyname>Lozano</keyname><forenames>Angel</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Mutual Information of IID Complex Gaussian Signals on Block
  Rayleigh-faded Channels</title><categories>cs.IT math.IT</categories><comments>8 pages. Shorter version submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to compute, quickly and efficiently, the mutual
information achieved by an IID (independent identically distributed) complex
Gaussian input on a block Rayleigh-faded channel without side information at
the receiver. The method accommodates both scalar and MIMO (multiple-input
multiple-output) settings. Operationally, the mutual information thus computed
represents the highest spectral efficiency that can be attained using standard
Gaussian codebooks. Examples are provided that illustrate the loss in spectral
efficiency caused by fast fading and how that loss is amplified by the use of
multiple transmit antennas. These examples are further enriched by comparisons
with the channel capacity under perfect channel-state information at the
receiver, and with the spectral efficiency attained by pilot-based
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2284</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2284</id><created>2010-01-13</created><authors><author><keyname>Eftekhari</keyname><forenames>Yaser</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author><author><keyname>Lambadaris</keyname><forenames>Ioannis</forenames></author></authors><title>An Efficient Approach Toward the Asymptotic Analysis of Node-Based
  Recovery Algorithms in Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a general framework for the asymptotic analysis of
node-based verification-based algorithms. In our analysis we tend the signal
length $n$ to infinity. We also let the number of non-zero elements of the
signal $k$ scale linearly with $n$. Using the proposed framework, we study the
asymptotic behavior of the recovery algorithms over random sparse matrices
(graphs) in the context of compressive sensing. Our analysis shows that there
exists a success threshold on the density ratio $k/n$, before which the
recovery algorithms are successful, and beyond which they fail. This threshold
is a function of both the graph and the recovery algorithm. We also demonstrate
that there is a good agreement between the asymptotic behavior of recovery
algorithms and finite length simulations for moderately large values of $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2298</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2298</id><created>2010-01-13</created><authors><author><keyname>Sridharan</keyname><forenames>Gokul</forenames></author><author><keyname>Lim</keyname><forenames>Teng Joon</forenames></author></authors><title>Turbo Receiver Design for Phase Noise Mitigation in OFDM Systems</title><categories>cs.IT math.IT</categories><comments>17 pages; 1 figure. Shorter version of this paper was submitted to
  ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the issue of phase noise in OFDM systems. Phase noise
(PHN) is a transceiver impairment resulting from the non-idealities of the
local oscillator. We present a case for designing a turbo receiver for systems
corrupted by phase noise by taking a closer look at the effects of the common
phase error (CPE). Using an approximate probabilistic framework called
variational inference (VI), we develop a soft-in soft-out (SISO) algorithm that
generates posterior bit-level soft estimates while taking into account the
effect of phase noise. The algorithm also provides an estimate of the phase
noise sequence. Using this SISO algorithm, a turbo receiver is designed by
passing soft information between the SISO detector and an outer forward error
correcting (FEC) decoder that uses a soft decoding algorithm. It is shown that
the turbo receiver achieves close to optimal performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2307</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2307</id><created>2010-01-14</created><authors><author><keyname>Islam</keyname><forenames>Muhammad Nazmul</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author></authors><title>Tranceiver Design using Linear Precoding in a Multiuser MIMO System with
  Limited Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IET Journals in Communications</comments><journal-ref>IET Journals in Communications, Vol: 5, Issue: 1, Page: 27-38, Jan
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate quantization and feedback of channel state information in a
multiuser (MU) multiple input multiple output (MIMO) system. Each user may
receive multiple data streams. Our design minimizes the sum mean squared error
(SMSE) while accounting for the imperfections in channel state information
(CSI) at the transmitter. This paper makes three contributions: first, we
provide an end-to-end SMSE transceiver design that incorporates receiver
combining, feedback policy and transmit precoder design with channel
uncertainty. This enables the proposed transceiver to outperform the previously
derived limited feedback MU linear transceivers. Second, we remove
dimensionality constraints on the MIMO system, for the scenario with multiple
data streams per user, using a combination of maximum expected signal combining
(MESC) and minimum MSE receiver. This makes the feedback of each user
independent of the others and the resulting feedback overhead scales linearly
with the number of data streams instead of the number of receiving antennas.
Finally, we analyze SMSE of the proposed algorithm at high signal-to-noise
ratio (SNR) and large number of transmit antennas. As an aside, we show
analytically why the bit error rate, in the high SNR regime, increases if
quantization error is ignored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2314</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2314</id><created>2010-01-13</created><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>Circuit partitions and #P-complete products of inner products</title><categories>cs.CC cs.DM math.CO quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple, natural #P-complete problem. Let G be a directed graph,
and let k be a positive integer. We define q(G;k) as follows. At each vertex v,
we place a k-dimensional complex vector x_v. We take the product, over all
edges (u,v), of the inner product &lt;x_u,x_v&gt;. Finally, q(G;k) is the expectation
of this product, where the x_v are chosen uniformly and independently from all
vectors of norm 1 (or, alternately, from the Gaussian distribution). We show
that q(G;k) is proportional to G's cycle partition polynomial, and therefore
that it is #P-complete for any k&gt;1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2320</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2320</id><created>2010-01-13</created><authors><author><keyname>Aperjis</keyname><forenames>Christina</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Wu</keyname><forenames>Fang</forenames></author></authors><title>Harvesting Collective Intelligence: Temporal Behavior in Yahoo Answers</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When harvesting collective intelligence, a user wishes to maximize the
accuracy and value of the acquired information without spending too much time
collecting it. We empirically study how people behave when facing these
conflicting objectives using data from Yahoo Answers, a community driven
question-and-answer site. We take two complementary approaches. We first study
how users behave when trying to maximize the amount of the acquired
information, while minimizing the waiting time. We identify and quantify how
question authors at Yahoo Answers trade off the number of answers they receive
and the cost of waiting. We find that users are willing to wait more to obtain
an additional answer when they have only received a small number of answers;
this implies decreasing marginal returns in the amount of collected
information. We also estimate the user's utility function from the data. Our
second approach focuses on how users assess the qualities of the individual
answers without explicitly considering the cost of waiting. We assume that
users make a sequence of decisions, deciding to wait for an additional answer
as long as the quality of the current answer exceeds some threshold. Under this
model, the probability distribution for the number of answers that a question
gets is an inverse Gaussian, which is a Zipf-like distribution. We use the data
to validate this conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2326</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2326</id><created>2010-01-13</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>A Distributed Data Storage Scheme for Sensor Networks</title><categories>cs.CR</categories><comments>9 pages</comments><journal-ref>Security and Privacy in Mobile Information and Communication
  Systems. Volume 17, pages 14-22, LNICST, Springer, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a data storage scheme for sensor networks that achieves the
targets of encryption and distributed storage simultaneously. We partition the
data to be stored into numerous pieces such that at least a specific number of
them have to be brought together to recreate the data. The procedure for
creation of partitions does not use any encryption key and the pieces are
implicitly secure. These pieces are then distributed over random sensors for
storage. Capture or malfunction of one or more (less than a threshold number of
sensors) does not compromise the data. The scheme provides protection against
compromise of data in specific sensors due to physical capture or malfunction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2327</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2327</id><created>2010-01-13</created><updated>2010-06-02</updated><authors><author><keyname>Chia</keyname><forenames>Yeow-Khiang</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>Wiretap Channel with Causal State Information</title><categories>cs.IT math.IT</categories><comments>V2: Minor edits. 19 pages, 3 figures V3: Minor edits. Typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lower bound on the secrecy capacity of the wiretap channel with state
information available causally at both the encoder and decoder is established.
The lower bound is shown to be strictly larger than that for the noncausal case
by Liu and Chen. Achievability is proved using block Markov coding, Shannon
strategy, and key generation from common state information. The state sequence
available at the end of each block is used to generate a key, which is used to
enhance the transmission rate of the confidential message in the following
block. An upper bound on the secrecy capacity when the state is available
noncausally at the encoder and decoder is established and is shown to coincide
with the lower bound for several classes of wiretap channels with state.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="10000" completeListSize="102538">1122234|11001</resumptionToken>
</ListRecords>
</OAI-PMH>
