<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:41:04Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|9001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1770</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1770</id><created>2009-09-09</created><authors><author><keyname>Sowell</keyname><forenames>Benjamin</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Demers</keyname><forenames>Alan</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Gupta</keyname><forenames>Nitin</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Li</keyname><forenames>Haoyuan</forenames><affiliation>Cornell University</affiliation></author><author><keyname>White</keyname><forenames>Walker</forenames><affiliation>Cornell University</affiliation></author></authors><title>From Declarative Languages to Declarative Processing in Computer Games</title><categories>cs.DB cs.MA</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent work has shown that we can dramatically improve the performance of
computer games and simulations through declarative processing: Character AI can
be written in an imperative scripting language which is then compiled to
relational algebra and executed by a special games engine with features similar
to a main memory database system. In this paper we lay out a challenging
research agenda built on these ideas.
  We discuss several research ideas for novel language features to support
atomic actions and reactive programming. We also explore challenges for
main-memory query processing in games and simulations including adaptive query
plan selection, support for parallel architectures, debugging simulation
scripts, and extensions for multi-player games and virtual worlds. We believe
that these research challenges will result in a dramatic change in the design
of game engines over the next decade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1771</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1771</id><created>2009-09-09</created><authors><author><keyname>Smith</keyname><forenames>Ken</forenames><affiliation>MITRE</affiliation></author><author><keyname>Morse</keyname><forenames>Michael</forenames><affiliation>MITRE</affiliation></author><author><keyname>Mork</keyname><forenames>Peter</forenames><affiliation>MITRE</affiliation></author><author><keyname>Li</keyname><forenames>Maya</forenames><affiliation>MITRE</affiliation></author><author><keyname>Rosenthal</keyname><forenames>Arnon</forenames><affiliation>MITRE</affiliation></author><author><keyname>Allen</keyname><forenames>David</forenames><affiliation>MITRE</affiliation></author><author><keyname>Seligman</keyname><forenames>Len</forenames><affiliation>MITRE</affiliation></author><author><keyname>Wolf</keyname><forenames>Chris</forenames><affiliation>MITRE</affiliation></author></authors><title>The Role of Schema Matching in Large Enterprises</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  To date, the principal use case for schema matching research has been as a
precursor for code generation, i.e., constructing mappings between schema
elements with the end goal of data transfer. In this paper, we argue that
schema matching plays valuable roles independent of mapping construction,
especially as schemata grow to industrial scales. Specifically, in large
enterprises human decision makers and planners are often the immediate consumer
of information derived from schema matchers, instead of schema mapping tools.
We list a set of real application areas illustrating this role for schema
matching, and then present our experiences tackling a customer problem in one
of these areas. We describe the matcher used, where the tool was effective,
where it fell short, and our lessons learned about how well current schema
matching technology is suited for use in large enterprises. Finally, we suggest
a new agenda for schema matching research based on these experiences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1772</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1772</id><created>2009-09-09</created><authors><author><keyname>Graefe</keyname><forenames>Goetz</forenames><affiliation>HP</affiliation></author><author><keyname>Kuno</keyname><forenames>Harumi</forenames><affiliation>Hewlett-Packard Co.</affiliation></author><author><keyname>Wiener</keyname><forenames>Janet</forenames><affiliation>Hewlett-Packard, Co.</affiliation></author></authors><title>Visualizing the robustness of query execution</title><categories>cs.DB cs.PF</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In database query processing, actual run-time conditions (e.g., actual
selectivities and actual available memory) very often differ from compile-time
expectations of run-time conditions (e.g., estimated predicate selectivities
and anticipated memory availability). Robustness of query processing can be
defined as the ability to handle unexpected conditions. Robustness of query
execution, specifically, can be defined as the ability to process a specific
plan efficiently in an unexpected condition. We focus on query execution
(run-time), ignoring query optimization (compile-time), in order to complement
existing research and to explore untapped potential for improved robustness in
database query processing.
  One of our initial steps has been to devise diagrams or maps that show how
well plans perform in the face of varying run-time conditions and how
gracefully a system's query architecture, operators, and their implementation
degrade in the face of adverse conditions. In this paper, we show several kinds
of diagrams with data from three real systems and report on what we have
learned both about these visualization techniques and about the three database
systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1773</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1773</id><created>2009-09-09</created><authors><author><keyname>Balmin</keyname><forenames>Andrey</forenames><affiliation>IBM Almaden Research Center</affiliation></author><author><keyname>Colby</keyname><forenames>Latha</forenames><affiliation>IBM Almaden Research Center</affiliation></author><author><keyname>Curtmola</keyname><forenames>Emiran</forenames><affiliation>UC, San Diego</affiliation></author><author><keyname>Li</keyname><forenames>Quanzhong</forenames><affiliation>IBM Almaden Research Center</affiliation></author><author><keyname>Ozcan</keyname><forenames>Fatma</forenames><affiliation>IBM Almaden Research Center</affiliation></author></authors><title>Search Driven Analysis of Heterogenous XML Data</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Analytical processing on XML repositories is usually enabled by designing
complex data transformations that shred the documents into a common data
warehousing schema. This can be very time-consuming and costly, especially if
the underlying XML data has a lot of variety in structure, and only a subset of
attributes constitutes meaningful dimensions and facts. Today, there is no tool
to explore an XML data set, discover interesting attributes, dimensions and
facts, and rapidly prototype an OLAP solution.
  In this paper, we propose a system, called SEDA that enables users to start
with simple keyword-style querying, and interactively refine the query based on
result summaries. SEDA then maps query results onto a set of known, or newly
created, facts and dimensions, and derives a star schema and its instantiation
to be fed into an off-the-shelf OLAP tool, for further analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1774</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1774</id><created>2009-09-09</created><authors><author><keyname>Koutrika</keyname><forenames>Georgia</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Bercovitz</keyname><forenames>Benjamin</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Ikeda</keyname><forenames>Robert</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Kaliszan</keyname><forenames>Filip</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Liou</keyname><forenames>Henry</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Zadeh</keyname><forenames>Zahra Mohammadi</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Garcia-Molina</keyname><forenames>Hector</forenames><affiliation>Stanford University</affiliation></author></authors><title>Social Systems: Can we Do More Than Just Poke Friends?</title><categories>cs.DB cs.CY</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Social sites have become extremely popular among users but have they
attracted equal attention from the research community? Are they good only for
simple tasks, such as tagging and poking friends? Do they present any new or
interesting research challenges? In this paper, we describe the insights we
have obtained implementing CourseRank, a course evaluation and planning social
system. We argue that more attention should be given to social sites like ours
and that there are many challenges (though not the traditional DBMS ones) that
should be addressed by our community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1775</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1775</id><created>2009-09-09</created><authors><author><keyname>Armbrust</keyname><forenames>Michael</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Fox</keyname><forenames>Armando</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Patterson</keyname><forenames>David</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Lanham</keyname><forenames>Nick</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Trushkowsky</keyname><forenames>Beth</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Trutna</keyname><forenames>Jesse</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Oh</keyname><forenames>Haruki</forenames><affiliation>UC Berkeley</affiliation></author></authors><title>SCADS: Scale-Independent Storage for Social Computing Applications</title><categories>cs.DB cs.DC</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Collaborative web applications such as Facebook, Flickr and Yelp present new
challenges for storing and querying large amounts of data. As users and
developers are focused more on performance than single copy consistency or the
ability to perform ad-hoc queries, there exists an opportunity for a
highly-scalable system tailored specifically for relaxed consistency and
pre-computed queries. The Web 2.0 development model demands the ability to both
rapidly deploy new features and automatically scale with the number of users.
There have been many successful distributed key-value stores, but so far none
provide as rich a query language as SQL. We propose a new architecture, SCADS,
that allows the developer to declaratively state application specific
consistency requirements, takes advantage of utility computing to provide cost
effective scale-up and scale-down, and will use machine learning models to
introspectively anticipate performance problems and predict the resource
requirements of new queries before execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1776</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1776</id><created>2009-09-09</created><authors><author><keyname>Berti-Equille</keyname><forenames>Laure</forenames><affiliation>Universite de Rennes 1</affiliation></author><author><keyname>Sarma</keyname><forenames>Anish Das</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Xin</keyname><affiliation>Luna</affiliation></author><author><keyname>Dong</keyname><affiliation>AT&amp;T Labs-Research</affiliation></author><author><keyname>Marian</keyname><forenames>Amelie</forenames><affiliation>Rutgus University</affiliation></author><author><keyname>Srivastava</keyname><forenames>Divesh</forenames><affiliation>ATT Labs-Research</affiliation></author></authors><title>Sailing the Information Ocean with Awareness of Currents: Discovery and
  Application of Source Dependence</title><categories>cs.DB cs.LG</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Web has enabled the availability of a huge amount of useful information,
but has also eased the ability to spread false information and rumors across
multiple sources, making it hard to distinguish between what is true and what
is not. Recent examples include the premature Steve Jobs obituary, the second
bankruptcy of United airlines, the creation of Black Holes by the operation of
the Large Hadron Collider, etc. Since it is important to permit the expression
of dissenting and conflicting opinions, it would be a fallacy to try to ensure
that the Web provides only consistent information. However, to help in
separating the wheat from the chaff, it is essential to be able to determine
dependence between sources. Given the huge number of data sources and the vast
volume of conflicting data available on the Web, doing so in a scalable manner
is extremely challenging and has not been addressed by existing work yet.
  In this paper, we present a set of research problems and propose some
preliminary solutions on the issues involved in discovering dependence between
sources. We also discuss how this knowledge can benefit a variety of
technologies, such as data integration and Web 2.0, that help users manage and
access the totality of the available information from various sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1777</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1777</id><created>2009-09-09</created><authors><author><keyname>Diao</keyname><forenames>Yanlei</forenames><affiliation>U. Massachusetts-Amherst</affiliation></author><author><keyname>Li</keyname><forenames>Boduo</forenames><affiliation>University of Massachusetts Amherst</affiliation></author><author><keyname>Liu</keyname><forenames>Anna</forenames><affiliation>UMass Amherst</affiliation></author><author><keyname>Peng</keyname><forenames>Liping</forenames><affiliation>UMass Amherst</affiliation></author><author><keyname>Sutton</keyname><forenames>Charles</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Tran</keyname><forenames>Thanh</forenames><affiliation>UMass Amherst</affiliation></author><author><keyname>Zink</keyname><forenames>Michael</forenames></author></authors><title>Capturing Data Uncertainty in High-Volume Stream Processing</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present the design and development of a data stream system that captures
data uncertainty from data collection to query processing to final result
generation. Our system focuses on data that is naturally modeled as continuous
random variables. For such data, our system employs an approach grounded in
probability and statistical theory to capture data uncertainty and integrates
this approach into high-volume stream processing. The first component of our
system captures uncertainty of raw data streams from sensing devices. Since
such raw streams can be highly noisy and may not carry sufficient information
for query processing, our system employs probabilistic models of the data
generation process and stream-speed inference to transform raw data into a
desired format with an uncertainty metric. The second component captures
uncertainty as data propagates through query operators. To efficiently quantify
result uncertainty of a query operator, we explore a variety of techniques
based on probability and statistical theory to compute the result distribution
at stream speed. We are currently working with a group of scientists to
evaluate our system using traces collected from the domains of (and eventually
in the real systems for) hazardous weather monitoring and object tracking and
monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1778</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1778</id><created>2009-09-09</created><authors><author><keyname>Khoussainova</keyname><forenames>Nodira</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Balazinska</keyname><forenames>Magda</forenames><affiliation>U. Washington</affiliation></author><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Kwon</keyname><forenames>YongChul</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Suciu</keyname><forenames>Dan</forenames><affiliation>University of Washington</affiliation></author></authors><title>A Case for A Collaborative Query Management System</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Over the past 40 years, database management systems (DBMSs) have evolved to
provide a sophisticated variety of data management capabilities. At the same
time, tools for managing queries over the data have remained relatively
primitive. One reason for this is that queries are typically issued through
applications. They are thus debugged once and re-used repeatedly. This mode of
interaction, however, is changing. As scientists (and others) store and share
increasingly large volumes of data in data centers, they need the ability to
analyze the data by issuing exploratory queries. In this paper, we argue that,
in these new settings, data management systems must provide powerful query
management capabilities, from query browsing to automatic query
recommendations. We first discuss the requirements for a collaborative query
management system. We outline an early system architecture and discuss the many
research challenges associated with building such an engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1779</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1779</id><created>2009-09-09</created><authors><author><keyname>Cudre-Mauroux</keyname><forenames>Philippe</forenames><affiliation>MIT</affiliation></author><author><keyname>Wu</keyname><forenames>Eugene</forenames><affiliation>MIT</affiliation></author><author><keyname>Madden</keyname><forenames>Sam</forenames><affiliation>MIT</affiliation></author></authors><title>The Case for RodentStore, an Adaptive, Declarative Storage System</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent excitement in the database community surrounding new
applications?analytic, scientific, graph, geospatial, etc.?has led to an
explosion in research on database storage systems. New storage systems are
vital to the database community, as they are at the heart of making database
systems perform well in new application domains. Unfortunately, each such
system also represents a substantial engineering effort including a great deal
of duplication of mechanisms for features such as transactions and caching. In
this paper, we make the case for RodentStore, an adaptive and declarative
storage system providing a high-level interface for describing the physical
representation of data. Specifically, RodentStore uses a declarative storage
algebra whereby administrators (or database design tools) specify how a logical
schema should be grouped into collections of rows, columns, and/or arrays, and
the order in which those groups should be laid out on disk. We describe the key
operators and types of our algebra, outline the general architecture of
RodentStore, which interprets algebraic expressions to generate a physical
representation of the data, and describe the interface between RodentStore and
other parts of a database system, such as the query optimizer and executor. We
provide a case study of the potential use of RodentStore in representing dense
geospatial data collected from a mobile sensor network, showing the ease with
which different storage layouts can be expressed using some of our algebraic
constructs and the potential performance gains that a RodentStore-built storage
system can offer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1780</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1780</id><created>2009-09-09</created><authors><author><keyname>Bouganim</keyname><forenames>Luc</forenames><affiliation>INRIA</affiliation></author><author><keyname>J&#xf3;nsson</keyname><forenames>Bj&#xf6;rn</forenames><affiliation>Reykjav&#xed;k University</affiliation></author><author><keyname>Bonnet</keyname><forenames>Philippe</forenames><affiliation>Department of Computer Science, University of Copenhagen</affiliation></author></authors><title>uFLIP: Understanding Flash IO Patterns</title><categories>cs.PF</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Does the advent of flash devices constitute a radical change for secondary
storage? How should database systems adapt to this new form of secondary
storage? Before we can answer these questions, we need to fully understand the
performance characteristics of flash devices. More specifically, we want to
establish what kind of IOs should be favored (or avoided) when designing
algorithms and architectures for flash-based systems. In this paper, we focus
on flash IO patterns, that capture relevant distribution of IOs in time and
space, and our goal is to quantify their performance. We define uFLIP, a
benchmark for measuring the response time of flash IO patterns. We also present
a benchmarking methodology which takes into account the particular
characteristics of flash devices. Finally, we present the results obtained by
measuring eleven flash devices, and derive a set of design hints that should
drive the development of flash-based systems on current devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1781</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1781</id><created>2009-09-09</created><authors><author><keyname>Mitra</keyname><forenames>Abhishek</forenames><affiliation>UC Riverside</affiliation></author><author><keyname>Vieira</keyname><forenames>Marcos</forenames><affiliation>UCR</affiliation></author><author><keyname>Bakalov</keyname><forenames>Petko</forenames><affiliation>ESRI</affiliation></author><author><keyname>Najjar</keyname><forenames>Walid</forenames><affiliation>UCR</affiliation></author><author><keyname>Tsotras</keyname><forenames>Vassilis</forenames><affiliation>UCR</affiliation></author></authors><title>Boosting XML Filtering with a Scalable FPGA-based Architecture</title><categories>cs.AR cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The growing amount of XML encoded data exchanged over the Internet increases
the importance of XML based publish-subscribe (pub-sub) and content based
routing systems. The input in such systems typically consists of a stream of
XML documents and a set of user subscriptions expressed as XML queries. The
pub-sub system then filters the published documents and passes them to the
subscribers. Pub-sub systems are characterized by very high input ratios,
therefore the processing time is critical. In this paper we propose a &quot;pure
hardware&quot; based solution, which utilizes XPath query blocks on FPGA to solve
the filtering problem. By utilizing the high throughput that an FPGA provides
for parallel processing, our approach achieves drastically better throughput
than the existing software or mixed (hardware/software) architectures. The
XPath queries (subscriptions) are translated to regular expressions which are
then mapped to FPGA devices. By introducing stacks within the FPGA we are able
to express and process a wide range of path queries very efficiently, on a
scalable environment. Moreover, the fact that the parser and the filter
processing are performed on the same FPGA chip, eliminates expensive
communication costs (that a multi-core system would need) thus enabling very
fast and efficient pipelining. Our experimental evaluation reveals more than
one order of magnitude improvement compared to traditional pub/sub systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1782</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1782</id><created>2009-09-09</created><authors><author><keyname>Finkelstein</keyname><forenames>Shel</forenames><affiliation>SAP</affiliation></author><author><keyname>Jacobs</keyname><forenames>Dean</forenames><affiliation>SAP</affiliation></author><author><keyname>Brendle</keyname><forenames>Rainer</forenames><affiliation>SAP</affiliation></author></authors><title>Principles for Inconsistency</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Data consistency is very desirable because strong semantic properties make it
easier to write correct programs that perform as users expect. However, there
are good reasons why consistency may have to be weakened to achieve other
business goals. In this CIDR 2009 Perspectives paper, we present real-world
reasons inconsistency may be necessary, offer principles for managing
inconsistency coherently, and describe implementation approaches we are
investigating for sustainably scalable systems that offer comprehensible user
experiences despite inconsistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1783</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1783</id><created>2009-09-09</created><authors><author><keyname>Doan</keyname><forenames>AnHai</forenames><affiliation>Univ of Wisconsin</affiliation></author><author><keyname>Naughton</keyname><forenames>Jeff</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Baid</keyname><forenames>Akanksha</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Chai</keyname><forenames>Xiaoyong</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Chen</keyname><forenames>Fei</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Chen</keyname><forenames>Ting</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Chu</keyname><forenames>Eric</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>DeRose</keyname><forenames>Pedro</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Gao</keyname><forenames>Byron</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Gokhale</keyname><forenames>Chaitanya</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Huang</keyname><forenames>Jiansheng</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Shen</keyname><forenames>Warren</forenames><affiliation>Wisconsin</affiliation></author><author><keyname>Vuong</keyname><forenames>Ba-Quy</forenames><affiliation>Wisconsin</affiliation></author></authors><title>The Case for a Structured Approach to Managing Unstructured Data</title><categories>cs.DB cs.IR</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The challenge of managing unstructured data represents perhaps the largest
data management opportunity for our community since managing relational data.
And yet we are risking letting this opportunity go by, ceding the playing field
to other players, ranging from communities such as AI, KDD, IR, Web, and
Semantic Web, to industrial players such as Google, Yahoo, and Microsoft. In
this essay we explore what we can do to improve upon this situation. Drawing on
the lessons learned while managing relational data, we outline a structured
approach to managing unstructured data. We conclude by discussing the potential
implications of this approach to managing other kinds of non-relational data,
and to the identify of our field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1784</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1784</id><created>2009-09-09</created><authors><author><keyname>Harizopoulos</keyname><forenames>Stavros</forenames><affiliation>HP Labs</affiliation></author><author><keyname>Shah</keyname><forenames>Mehul</forenames><affiliation>UCLA</affiliation></author><author><keyname>Meza</keyname><forenames>Justin</forenames><affiliation>UCLA</affiliation></author><author><keyname>Ranganathan</keyname><forenames>Parthasarathy</forenames><affiliation>HP Labs</affiliation></author></authors><title>Energy Efficiency: The New Holy Grail of Data Management Systems
  Research</title><categories>cs.DB cs.PF</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Energy costs are quickly rising in large-scale data centers and are soon
projected to overtake the cost of hardware. As a result, data center operators
have recently started turning into using more energy-friendly hardware. Despite
the growing body of research in power management techniques, there has been
little work to date on energy efficiency from a data management software
perspective.
  In this paper, we argue that hardware-only approaches are only part of the
solution, and that data management software will be key in optimizing for
energy efficiency. We discuss the problems arising from growing energy use in
data centers and the trends that point to an increasing set of opportunities
for software-level optimizations. Using two simple experiments, we illustrate
the potential of such optimizations, and, motivated by these examples, we
discuss general approaches for reducing energy waste. Lastly, we point out
existing places within database systems that are promising for
energy-efficiency optimizations and urge the data management systems community
to shift focus from performance-oriented research to energy-efficient
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1785</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1785</id><created>2009-09-09</created><authors><author><keyname>Madhavan</keyname><forenames>Jayant</forenames><affiliation>Google Inc.</affiliation></author><author><keyname>Afanasiev</keyname><forenames>Loredana</forenames><affiliation>Universiteit van Amsterdam</affiliation></author><author><keyname>Antova</keyname><forenames>Lyublena</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Halevy</keyname><forenames>Alon</forenames><affiliation>Google</affiliation></author></authors><title>Harnessing the Deep Web: Present and Future</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Over the past few years, we have built a system that has exposed large
volumes of Deep-Web content to Google.com users. The content that our system
exposes contributes to more than 1000 search queries per-second and spans over
50 languages and hundreds of domains. The Deep Web has long been acknowledged
to be a major source of structured data on the web, and hence accessing
Deep-Web content has long been a problem of interest in the data management
community. In this paper, we report on where we believe the Deep Web provides
value and where it does not. We contrast two very different approaches to
exposing Deep-Web content -- the surfacing approach that we used, and the
virtual integration approach that has often been pursued in the data management
literature. We emphasize where the values of each of the two approaches lie and
caution against potential pitfalls. We outline important areas of future
research and, in particular, emphasize the value that can be derived from
analyzing large collections of potentially disparate structured data on the
web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1786</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1786</id><created>2009-09-09</created><authors><author><keyname>Simitsis</keyname><forenames>Alkis</forenames><affiliation>HP Labs</affiliation></author><author><keyname>Ioannidis</keyname><forenames>Yannis</forenames></author></authors><title>DBMSs Should Talk Back Too</title><categories>cs.DB cs.HC</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Natural language user interfaces to database systems have been studied for
several decades now. They have mainly focused on parsing and interpreting
natural language queries to generate them in a formal database language. We
envision the reverse functionality, where the system would be able to take the
internal result of that translation, say in SQL form, translate it back into
natural language, and show it to the initiator of the query for verification.
Likewise, information extraction has received considerable attention in the
past ten years or so, identifying structured information in free text so that
it may then be stored appropriately and queried. Validation of the records
stored with a backward translation into text would again be very powerful.
Verification and validation of query and data input of a database system
correspond to just one example of the many important applications that would
benefit greatly from having mature techniques for translating such database
constructs into free-flowing text. The problem appears to be deceivingly
simple, as there are no ambiguities or other complications in interpreting
internal database elements, so initially a straightforward translation appears
adequate. Reality teaches us quite the opposite, however, as the resulting text
should be expressive, i.e., accurate in capturing the underlying queries or
data, and effective, i.e., allowing fast and unique interpretation of them.
Achieving both of these qualities is very difficult and raises several
technical challenges that need to be addressed. In this paper, we first expose
the reader to several situations and applications that need translation into
natural language, thereby, motivating the problem. We then outline, by example,
the research problems that need to be solved, separately for data translations
and query translations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1788</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1788</id><created>2009-09-09</created><authors><author><keyname>Helland</keyname><forenames>Pat</forenames><affiliation>Microsoft</affiliation></author><author><keyname>Campbell</keyname><forenames>David</forenames><affiliation>Microsoft</affiliation></author></authors><title>Building on Quicksand</title><categories>cs.DC</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Reliable systems have always been built out of unreliable components. Early
on, the reliable components were small such as mirrored disks or ECC (Error
Correcting Codes) in core memory. These systems were designed such that
failures of these small components were transparent to the application. Later,
the size of the unreliable components grew larger and semantic challenges crept
into the application when failures occurred.
  As the granularity of the unreliable component grows, the latency to
communicate with a backup becomes unpalatable. This leads to a more relaxed
model for fault tolerance. The primary system will acknowledge the work request
and its actions without waiting to ensure that the backup is notified of the
work. This improves the responsiveness of the system.
  There are two implications of asynchronous state capture: 1) Everything
promised by the primary is probabilistic. There is always a chance that an
untimely failure shortly after the promise results in a backup proceeding
without knowledge of the commitment. Hence, nothing is guaranteed! 2)
Applications must ensure eventual consistency. Since work may be stuck in the
primary after a failure and reappear later, the processing order for work
cannot be guaranteed.
  Platform designers are struggling to make this easier for their applications.
Emerging patterns of eventual consistency and probabilistic execution may soon
yield a way for applications to express requirements for a &quot;looser&quot; form of
consistency while providing availability in the face of ever larger failures.
  This paper recounts portions of the evolution of these trends, attempts to
show the patterns that span these changes, and talks about future directions as
we continue to &quot;build on quicksand&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1789</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1789</id><created>2009-09-09</created><authors><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Perino</keyname><forenames>Diego</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On Resource Aware Algorithms in Epidemic Live Streaming</title><categories>cs.NI</categories><proxy>ccsd inria-00414706</proxy><report-no>RR-7031</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epidemic-style diffusion schemes have been previously proposed for achieving
peer-to-peer live streaming. Their performance trade-offs have been deeply
analyzed for homogeneous systems, where all peers have the same upload
capacity. However, epidemic schemes designed for heterogeneous systems have not
been completely understood yet. In this report we focus on the peer selection
process and propose a generic model that encompasses a large class of
algorithms. The process is modeled as a combination of two functions, an aware
one and an agnostic one. By means of simulations, we analyze the
awareness-agnostism trade-offs on the peer selection process and the impact of
the source distribution policy in non-homogeneous networks. We highlight that
the early diffusion of a given chunk is crucial for its overall diffusion
performance, and a fairness trade-off arises between the performance of
heterogeneous peers, as a function of the level of awareness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1792</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1792</id><created>2009-09-09</created><authors><author><keyname>Mathieu</keyname><forenames>Fabien</forenames></author></authors><title>Heterogeneity in Distributed Live Streaming: Blessing or Curse?</title><categories>cs.NI</categories><proxy>ccsd inria-00414767</proxy><report-no>RR-OL-2009-09-001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed live streaming has brought a lot of interest in the past few
years. In the homogeneous case (all nodes having the same capacity), many
algorithms have been proposed, which have been proven almost optimal or
optimal. On the other hand, the performance of heterogeneous systems is not
completely understood yet. In this paper, we investigate the impact of
heterogeneity on the achievable delay of chunk-based live streaming systems. We
propose several models for taking the atomicity of a chunk into account. For
all these models, when considering the transmission of a single chunk,
heterogeneity is indeed a ``blessing'', in the sense that the achievable delay
is always faster than an equivalent homogeneous system. But for a stream of
chunks, we show that it can be a ``curse'': there is systems where the
achievable delay can be arbitrary greater compared to equivalent homogeneous
systems. However, if the system is slightly bandwidth-overprovisioned, optimal
single chunk diffusion schemes can be adapted to a stream of chunks, leading to
near-optimal, faster than homogeneous systems, heterogeneous live streaming
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1801</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1801</id><created>2009-09-09</created><authors><author><keyname>Srivastava</keyname><forenames>Vaibhav</forenames></author><author><keyname>Plarre</keyname><forenames>Kurt</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Randomized Sensor Selection in Sequential Hypothesis Testing</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure, Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of sensor selection for time-optimal detection of a
hypothesis. We consider a group of sensors transmitting their observations to a
fusion center. The fusion center considers the output of only one randomly
chosen sensor at the time, and performs a sequential hypothesis test. We
consider the class of sequential tests which are easy to implement,
asymptotically optimal, and computationally amenable. For three distinct
performance metrics, we show that, for a generic set of sensors and binary
hypothesis, the fusion center needs to consider at most two sensors. We also
show that for the case of multiple hypothesis, the optimal policy needs at most
as many sensors to be observed as the number of underlying hypotheses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1817</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1817</id><created>2009-09-10</created><authors><author><keyname>Kim</keyname><forenames>Muryong</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Cooperative Transmission for a Vector Gaussian Parallel Relay Network</title><categories>cs.IT math.IT</categories><comments>35 pages, 10 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a parallel relay network where two relays
cooperatively help a source transmit to a destination. We assume the source and
the destination nodes are equipped with multiple antennas. Three basic schemes
and their achievable rates are studied: Decode-and-Forward (DF),
Amplify-and-Forward (AF), and Compress-and-Forward (CF). For the DF scheme, the
source transmits two private signals, one for each relay, where dirty paper
coding (DPC) is used between the two private streams, and a common signal for
both relays. The relays make efficient use of the common information to
introduce a proper amount of correlation in the transmission to the
destination. We show that the DF scheme achieves the capacity under certain
conditions. We also show that the CF scheme is asymptotically optimal in the
high relay power limit, regardless of channel ranks. It turns out that the AF
scheme also achieves the asymptotic optimality but only when the
relays-to-destination channel is full rank. The relative advantages of the
three schemes are discussed with numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1830</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1830</id><created>2009-09-09</created><authors><author><keyname>Ustebay</keyname><forenames>Deniz</forenames></author><author><keyname>Oreshkin</keyname><forenames>Boris</forenames></author><author><keyname>Coates</keyname><forenames>Mark</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>Greedy Gossip with Eavesdropping</title><categories>cs.DC cs.AI</categories><comments>25 pages, 7 figures</comments><doi>10.1109/TSP.2010.2046593</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents greedy gossip with eavesdropping (GGE), a novel
randomized gossip algorithm for distributed computation of the average
consensus problem. In gossip algorithms, nodes in the network randomly
communicate with their neighbors and exchange information iteratively. The
algorithms are simple and decentralized, making them attractive for wireless
network applications. In general, gossip algorithms are robust to unreliable
wireless conditions and time varying network topologies. In this paper we
introduce GGE and demonstrate that greedy updates lead to rapid convergence. We
do not require nodes to have any location information. Instead, greedy updates
are made possible by exploiting the broadcast nature of wireless
communications. During the operation of GGE, when a node decides to gossip,
instead of choosing one of its neighbors at random, it makes a greedy
selection, choosing the node which has the value most different from its own.
In order to make this selection, nodes need to know their neighbors' values.
Therefore, we assume that all transmissions are wireless broadcasts and nodes
keep track of their neighbors' values by eavesdropping on their communications.
We show that the convergence of GGE is guaranteed for connected network
topologies. We also study the rates of convergence and illustrate, through
theoretical bounds and numerical simulations, that GGE consistently outperforms
randomized gossip and performs comparably to geographic gossip on
moderate-sized random geometric graph topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1858</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1858</id><created>2009-09-09</created><authors><author><keyname>Chan</keyname><forenames>Aldar C-F.</forenames></author></authors><title>A Graph Theoretic Approach for Optimizing Key Pre-distribution in
  Wireless SensorNetworks</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding an optimal key assignment (subject to given constraints) for a key
predistribution scheme in wireless sensor networks is a difficult task. Hence,
most of the practical schemes are based on probabilistic key assignment, which
leads to sub-optimal schemes requiring key storage linear in the total number
of nodes. A graph theoretic framework is introduced to study the fundamental
tradeoffs between key storage, average key path length (directly related to the
battery consumption) and resilience (to compromised nodes) of key
predistribution schemes for wireless sensor networks. Based on the proposed
framework, a lower bound on key storage is derived for a given average key path
length. An upper bound on the compromising probability is also given. This
framework also leads to the design of key assignment schemes with a storage
complexity of the same order as the lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1866</identifier>
 <datestamp>2011-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1866</id><created>2009-09-09</created><updated>2011-10-27</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Optimally fast incremental Manhattan plane embedding and planar tight
  span construction</title><categories>cs.CG cs.DS</categories><comments>39 pages, 15 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Journal of Computational Geometry 2(1):144-182, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a data structure, a rectangular complex, that can be used to
represent hyperconvex metric spaces that have the same topology (although not
necessarily the same distance function) as subsets of the plane. We show how to
use this data structure to construct the tight span of a metric space given as
an n x n distance matrix, when the tight span is homeomorphic to a subset of
the plane, in time O(n^2), and to add a single point to a planar tight span in
time O(n). As an application of this construction, we show how to test whether
a given finite metric space embeds isometrically into the Manhattan plane in
time O(n^2), and add a single point to the space and re-test whether it has
such an embedding in time O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1870</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1870</id><created>2009-09-10</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Paired approximation problems and incompatible inapproximabilities</title><categories>cs.DS</categories><comments>13 pages, 3 figures. To appear at 21st ACM-SIAM Symp. Discrete
  Algorithms (SODA 2010)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers pairs of optimization problems that are defined from a
single input and for which it is desired to find a good approximation to either
one of the problems. In many instances, it is possible to efficiently find an
approximation of this type that is better than known inapproximability lower
bounds for either of the two individual optimization problems forming the pair.
In particular, we find either a $(1+\epsilon)$-approximation to $(1,2)$-TSP or
a $1/\epsilon$-approximation to maximum independent set, from a given graph, in
linear time. We show a similar paired approximation result for finding either a
coloring or a long path. However, no such tradeoff exists in some other cases:
for set cover and hitting set problems defined from a single set family, and
for clique and independent set problems on the same graph, it is not possible
to find an approximation when both problems are combined that is better than
the best approximation for either problem on its own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1876</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1876</id><created>2009-09-10</created><authors><author><keyname>Martina</keyname><forenames>Maurizio</forenames></author><author><keyname>Masera</keyname><forenames>Guido</forenames></author></authors><title>Turbo NOC: a framework for the design of Network On Chip based turbo
  decoder architectures</title><categories>cs.AR</categories><comments>submitted to IEEE Trans. on Circuits and Systems I (submission date
  27 may 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a general framework for the design and simulation of
network on chip based turbo decoder architectures. Several parameters in the
design space are investigated, namely the network topology, the parallelism
degree, the rate at which messages are sent by processing nodes over the
network and the routing strategy. The main results of this analysis are: i) the
most suited topologies to achieve high throughput with a limited complexity
overhead are generalized de-Bruijn and generalized Kautz topologies; ii)
depending on the throughput requirements different parallelism degrees, message
injection rates and routing algorithms can be used to minimize the network area
overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1933</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1933</id><created>2009-09-10</created><updated>2010-06-04</updated><authors><author><keyname>Ralaivola</keyname><forenames>Liva</forenames><affiliation>LIF</affiliation></author><author><keyname>Szafranski</keyname><forenames>Marie</forenames><affiliation>IBISC</affiliation></author><author><keyname>Stempfel</keyname><forenames>Guillaume</forenames><affiliation>LIF</affiliation></author></authors><title>Chromatic PAC-Bayes Bounds for Non-IID Data: Applications to Ranking and
  Stationary $\beta$-Mixing Processes</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>Long version of the AISTATS 09 paper:
  http://jmlr.csail.mit.edu/proceedings/papers/v5/ralaivola09a/ralaivola09a.pdf</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pac-Bayes bounds are among the most accurate generalization bounds for
classifiers learned from independently and identically distributed (IID) data,
and it is particularly so for margin classifiers: there have been recent
contributions showing how practical these bounds can be either to perform model
selection (Ambroladze et al., 2007) or even to directly guide the learning of
linear classifiers (Germain et al., 2009). However, there are many practical
situations where the training data show some dependencies and where the
traditional IID assumption does not hold. Stating generalization bounds for
such frameworks is therefore of the utmost interest, both from theoretical and
practical standpoints. In this work, we propose the first - to the best of our
knowledge - Pac-Bayes generalization bounds for classifiers trained on data
exhibiting interdependencies. The approach undertaken to establish our results
is based on the decomposition of a so-called dependency graph that encodes the
dependencies within the data, in sets of independent data, thanks to graph
fractional covers. Our bounds are very general, since being able to find an
upper bound on the fractional chromatic number of the dependency graph is
sufficient to get new Pac-Bayes bounds for specific settings. We show how our
results can be used to derive bounds for ranking statistics (such as Auc) and
classifiers trained on data distributed according to a stationary {\ss}-mixing
process. In the way, we show how our approach seemlessly allows us to deal with
U-processes. As a side note, we also provide a Pac-Bayes generalization bound
for classifiers learned on data from stationary $\varphi$-mixing distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1965</identifier>
 <datestamp>2009-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1965</id><created>2009-09-10</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author></authors><title>The complete Generating Function for Gessel Walks is Algebraic</title><categories>math.CO cs.SC</categories><msc-class>05A15, 14N10, 33F10, 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gessel walks are lattice walks in the quarter plane $\set N^2$ which start at
the origin $(0,0)\in\set N^2$ and consist only of steps chosen from the set
$\{\leftarrow,\swarrow,\nearrow,\to\}$. We prove that if $g(n;i,j)$ denotes the
number of Gessel walks of length $n$ which end at the point $(i,j)\in\set N^2$,
then the trivariate generating series $G(t;x,y)=\sum_{n,i,j\geq 0} g(n;i,j)x^i
y^j t^n$ is an algebraic function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1977</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1977</id><created>2009-09-10</created><authors><author><keyname>Alegre</keyname><forenames>Fernando</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Pande</keyname><forenames>Santosh</forenames></author></authors><title>Using Ellipsoidal Domains to Analyze Control Systems Software</title><categories>cs.PL cs.SE</categories><comments>17 pages</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a methodology for the automatic verification of safety properties
of controllers based on dynamical systems, such as those typically used in
avionics. In particular, our focus is on proving stability properties of
software implementing linear and some non-linear controllers. We develop an
abstract interpretation framework that follows closely the Lyapunov methods
used in proofs at the model level and describe the corresponding abstract
domains, which for linear systems consist of ellipsoidal constraints. These
ellipsoidal domains provide abstractions for the values of state variables and
must be combined with other domains that model the remaining variables in a
program. Thus, the problem of automatically assigning the right type of
abstract domain to each variable arises. We provide an algorithm that solves
this classification problem in many practical cases and suggest how it could be
generalized to more complicated cases. We then find a fixpoint by solving a
matrix equation, which in the linear case is just the discrete Lyapunov
equation. Contrary to most cases in software analysis, this fixpoint cannot be
reached by the usual iterative method of propagating constraints until
saturation and so numerical methods become essential. Finally, we illustrate
our methodology with several examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2000</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2000</id><created>2009-09-10</created><authors><author><keyname>Krusche</keyname><forenames>Peter</forenames></author><author><keyname>Tiskin</keyname><forenames>Alexander</forenames></author></authors><title>Computing alignment plots efficiently</title><categories>cs.DS cs.DC cs.DM</categories><comments>Presented at ParCo 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dot plots are a standard method for local comparison of biological sequences.
In a dot plot, a substring to substring distance is computed for all pairs of
fixed-size windows in the input strings. Commonly, the Hamming distance is used
since it can be computed in linear time. However, the Hamming distance is a
rather crude measure of string similarity, and using an alignment-based edit
distance can greatly improve the sensitivity of the dot plot method. In this
paper, we show how to compute alignment plots of the latter type efficiently.
Given two strings of length m and n and a window size w, this problem consists
in computing the edit distance between all pairs of substrings of length w, one
from each input string. The problem can be solved by repeated application of
the standard dynamic programming algorithm in time O(mnw^2). This paper gives
an improved data-parallel algorithm, running in time $O(mnw/\gamma/p)$ using
vector operations that work on $\gamma$ values in parallel and $p$ processors.
We show experimental results from an implementation of this algorithm, which
uses Intel's MMX/SSE instructions for vector parallelism and MPI for
coarse-grained parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2005</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2005</id><created>2009-09-10</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Zeitouni</keyname><forenames>Ofer</forenames></author></authors><title>Deterministic approximation for the cover time of trees</title><categories>cs.DS math.PR</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deterministic algorithm that given a tree T with n vertices, a
starting vertex v and a slackness parameter epsilon &gt; 0, estimates within an
additive error of epsilon the cover and return time, namely, the expected time
it takes a simple random walk that starts at v to visit all vertices of T and
return to v. The running time of our algorithm is polynomial in n/epsilon, and
hence remains polynomial in n also for epsilon = 1/n^{O(1)}. We also show how
the algorithm can be extended to estimate the expected cover (without return)
time on trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2009</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2009</id><created>2009-09-10</created><updated>2011-12-06</updated><authors><author><keyname>Weidmann</keyname><forenames>Claudio</forenames></author><author><keyname>Lechner</keyname><forenames>Gottfried</forenames></author></authors><title>A Fresh Look at Coding for q-ary Symmetric Channels</title><categories>cs.IT math.IT</categories><comments>12 pages, 6 figures; revision submitted to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies coding schemes for the $q$-ary symmetric channel based on
binary low-density parity-check (LDPC) codes that work for any alphabet size
$q=2^m$, $m\in\mathbb{N}$, thus complementing some recently proposed
packet-based schemes requiring large $q$. First, theoretical optimality of a
simple layered scheme is shown, then a practical coding scheme based on a
simple modification of standard binary LDPC decoding is proposed. The decoder
is derived from first principles and using a factor-graph representation of a
front-end that maps $q$-ary symbols to groups of $m$ bits connected to a binary
code. The front-end can be processed with a complexity that is linear in
$m=\log_2 q$. An extrinsic information transfer chart analysis is carried out
and used for code optimization. Finally, it is shown how the same decoder
structure can also be applied to a larger class of $q$-ary channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2017</identifier>
 <datestamp>2012-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2017</id><created>2009-09-10</created><updated>2012-09-12</updated><authors><author><keyname>Bowley</keyname><forenames>James</forenames></author><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author></authors><title>Sparsity and `Something Else': An Approach to Encrypted Image Folding</title><categories>cs.CV cs.IT math.IT</categories><comments>Revised manuscript- Software for implementing the Encrypted Image
  Folding proposed in this paper is available on
  http://www.nonlinear-approx.info/</comments><journal-ref>IEEE Signal Processing Letters, Vol. 8 No 3, 189--192, 2011</journal-ref><doi>10.1109/LSP.2011.2106496</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A property of sparse representations in relation to their capacity for
information storage is discussed. It is shown that this feature can be used for
an application that we term Encrypted Image Folding. The proposed procedure is
realizable through any suitable transformation. In particular, in this paper we
illustrate the approach by recourse to the Discrete Cosine Transform and a
combination of redundant Cosine and Dirac dictionaries. The main advantage of
the proposed technique is that both storage and encryption can be achieved
simultaneously using simple processing steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2024</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2024</id><created>2009-09-10</created><authors><author><keyname>La</keyname><forenames>Chi-Anh</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author><author><keyname>Casetti</keyname><forenames>Claudio</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author><author><keyname>Fiore</keyname><forenames>Marco</forenames></author></authors><title>A Lightweight Distributed Solution to Content Replication in Mobile
  Networks</title><categories>cs.NI cs.PF</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance and reliability of content access in mobile networks is
conditioned by the number and location of content replicas deployed at the
network nodes. Facility location theory has been the traditional, centralized
approach to study content replication: computing the number and placement of
replicas in a network can be cast as an uncapacitated facility location
problem. The endeavour of this work is to design a distributed, lightweight
solution to the above joint optimization problem, while taking into account the
network dynamics. In particular, we devise a mechanism that lets nodes share
the burden of storing and providing content, so as to achieve load balancing,
and decide whether to replicate or drop the information so as to adapt to a
dynamic content demand and time-varying topology. We evaluate our mechanism
through simulation, by exploring a wide range of settings and studying
realistic content access mechanisms that go beyond the traditional
assumptionmatching demand points to their closest content replica. Results show
that our mechanism, which uses local measurements only, is: (i) extremely
precise in approximating an optimal solution to content placement and
replication; (ii) robust against network mobility; (iii) flexible in
accommodating various content access patterns, including variation in time and
space of the content demand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2030</identifier>
 <datestamp>2009-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2030</id><created>2009-09-10</created><updated>2009-12-12</updated><authors><author><keyname>Valiant</keyname><forenames>Gregory</forenames></author><author><keyname>Valiant</keyname><forenames>Paul</forenames></author></authors><title>Size Bounds for Conjunctive Queries with General Functional Dependencies</title><categories>cs.DB cs.DS</categories><comments>22 pages, 2 figures</comments><acm-class>H.2.4; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the work of Gottlob, Lee, and Valiant (PODS 2009)[GLV],
and considers worst-case bounds for the size of the result Q(D) of a
conjunctive query Q to a database D given an arbitrary set of functional
dependencies. The bounds in [GLV] are based on a &quot;coloring&quot; of the query
variables. In order to extend the previous bounds to the setting of arbitrary
functional dependencies, we leverage tools from information theory to formalize
the original intuition that each color used represents some possible entropy of
that variable, and bound the maximum possible size increase via a linear
program that seeks to maximize how much more entropy is in the result of the
query than the input. This new view allows us to precisely characterize the
entropy structure of worst-case instances for conjunctive queries with simple
functional dependencies (keys), providing new insights into the results of
[GLV]. We extend these results to the case of general functional dependencies,
providing upper and lower bounds on the worst-case size increase. We identify
the fundamental connection between the gap in these bounds and a central open
question in information theory.
  Finally, we show that, while both the upper and lower bounds are given by
exponentially large linear programs, one can distinguish in polynomial time
whether the result of a query with an arbitrary set of functional dependencies
can be any larger than the input database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2055</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2055</id><created>2009-09-10</created><authors><author><keyname>Schikuta</keyname><forenames>Erich</forenames></author><author><keyname>Weishaeupl</keyname><forenames>Thomas</forenames></author><author><keyname>Donno</keyname><forenames>Flavia</forenames></author><author><keyname>Stockinger</keyname><forenames>Heinz</forenames></author><author><keyname>Vinek</keyname><forenames>Elisabeth</forenames></author><author><keyname>Wanek</keyname><forenames>Helmut</forenames></author><author><keyname>Witzany</keyname><forenames>Christoph</forenames></author><author><keyname>Haq</keyname><forenames>Irfan Ul</forenames></author></authors><title>Business in the Grid</title><categories>cs.DC cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From 2004 to 2007 the Business In the Grid (BIG) project took place and was
driven by the following goals: Firstly, make business aware of Grid technology
and, secondly, try to explore new business models. We disseminated Grid
computing by mainly concentrating on the central European market and
interviewed several companies in order to gain insights into the Grid
acceptance in industrial environments. In this article we present the results
of the project, elaborate on a critical discussion on business adaptations, and
describe a novel dynamic authorization workflow for business processes in the
Grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2058</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2058</id><created>2009-09-10</created><authors><author><keyname>Amer-Yahia</keyname><forenames>Sihem</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Lakshmanan</keyname><forenames>Laks</forenames><affiliation>UBC</affiliation></author><author><keyname>Yu</keyname><forenames>Cong</forenames><affiliation>Yahoo! Research</affiliation></author></authors><title>SocialScope: Enabling Information Discovery on Social Content Sites</title><categories>cs.DB cs.HC cs.IR cs.PL</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, many content sites have started encouraging their users to engage
in social activities such as adding buddies on Yahoo! Travel and sharing
articles with their friends on New York Times. This has led to the emergence of
{\em social content sites}, which is being facilitated by initiatives like
OpenID (http://www.openid.net/) and OpenSocial (http://www.opensocial.org/).
These community standards enable the open access to users' social profiles and
connections by individual content sites and are bringing content-oriented sites
and social networking sites ever closer. The integration of content and social
information raises new challenges for {\em information management and
discovery} over such sites. We propose a logical architecture, named
\kw{SocialScope}, consisting of three layers, for tackling the challenges. The
{\em content management} layer is responsible for integrating, maintaining and
physically accessing the content and social data. The {\em information
discovery} layer takes care of analyzing content to derive interesting new
information, and interpreting and processing the user's information need to
identify relevant information. Finally, the {\em information presentation}
layer explores the discovered information and helps users better understand it
in a principled way. We describe the challenges in each layer and propose
solutions for some of those challenges. In particular, we propose a uniform
algebraic framework, which can be leveraged to uniformly and flexibly specify
many of the information discovery and analysis tasks and provide the foundation
for the optimization of those tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2062</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2062</id><created>2009-09-10</created><authors><author><keyname>Fern&#xe1;ndez-Moctezuma</keyname><forenames>Rafael</forenames><affiliation>Portland State University</affiliation></author><author><keyname>Tufte</keyname><forenames>Kristin</forenames><affiliation>Portland State University</affiliation></author><author><keyname>Li</keyname><forenames>Jin</forenames><affiliation>Portland State University</affiliation></author></authors><title>Inter-Operator Feedback in Data Stream Management Systems via
  Punctuation</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  High-volume, high-speed data streams may overwhelm the capabilities of stream
processing systems; techniques such as data prioritization, avoidance of
unnecessary processing and on-demand result production may be necessary to
reduce processing requirements. However, the dynamic nature of data streams, in
terms of both rate and content, makes the application of such techniques
challenging. Such techniques have been addressed in the context of static and
centralized query optimization; however, they have not been fully addressed for
data stream management systems. In this work, we present a comprehensive
framework that supports prioritization, avoidance of unnecessary work, and
on-demand result production over distributed, unreliable, bursty, disordered
data sources, typical of many data streams. We propose a form of inter-operator
feedback, which flows against the stream direction, to communicate the
information needed to enable execution of these techniques. This feedback
leverages punctuations to describe the subsets of interest. We identify
potential sources of feedback information, characterize new types of
punctuation to support feedback, and describe the roles of producers,
exploiters, and relayers of feedback that query operators may implement. We
present initial experimental observations using the NiagaraST data-stream
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2074</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2074</id><created>2009-09-10</created><updated>2010-10-22</updated><authors><author><keyname>Annapureddy</keyname><forenames>V. Sreekanth</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Sum Capacity of MIMO Interference Channels in the Low Interference
  Regime</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, Sept. 2009,
  revised Oct. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Gaussian inputs and treating interference as noise at the receivers has
recently been shown to be sum capacity achieving for the two-user single-input
single-output (SISO) Gaussian interference channel in a low interference
regime, where the interference levels are below certain thresholds. In this
paper, such a low interference regime is characterized for multiple-input
multiple-output (MIMO) Gaussian interference channels. Conditions are provided
on the direct and cross channel gain matrices under which using Gaussian inputs
and treating interference as noise at the receivers is sum capacity achieving.
For the special cases of the symmetric multiple-input single-output (MISO) and
single-input multiple-output (SIMO) Gaussian interference channels, more
explicit expressions for the low interference regime are derived. In
particular, the threshold on the interference levels that characterize low
interference regime is related to the input SNR and the angle between the
direct and cross channel gain vectors. It is shown that the low interference
regime can be quite significant for MIMO interference channels, with the low
interference threshold being at least as large as the sine of the angle between
the direct and cross channel gain vectors for the MISO and SIMO cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2088</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2088</id><created>2009-09-11</created><updated>2010-11-02</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Arithmetical meadows</title><categories>math.RA cs.LO</categories><comments>14 pages; sections 4 and 5 permuted</comments><report-no>PRG0909</report-no><msc-class>12E12, 12E30, 12L05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An inversive meadow is a commutative ring with identity equipped with a
multiplicative inverse operation made total by choosing 0 as its value at 0.
Previously, inversive meadows were shortly called meadows. A divisive meadow is
an inversive meadows with the multiplicative inverse operation replaced by a
division operation. In the spirit of Peacock's arithmetical algebra, we
introduce variants of inversive and divisive meadows without an additive
identity element and an additive inverse operation. We give equational
axiomatizations of several classes of such variants of inversive and divisive
meadows as well as of several instances of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2089</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2089</id><created>2009-09-11</created><updated>2012-08-17</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Indirect jumps improve instruction sequence performance</title><categories>cs.PL</categories><comments>10 pages, definition of maximal internal delay and theorem 1 are
  stated more precise; presentation improved</comments><report-no>PRG0910</report-no><acm-class>D.3.3; F.1.1; F.3.3</acm-class><journal-ref>Scientific Annals of Computer Science, 22(2):253--265, 2012</journal-ref><doi>10.7561/SACS.2012.2.253</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instruction sequences with direct and indirect jump instructions are as
expressive as instruction sequences with direct jump instructions only. We show
that, in the case where the number of instructions is not bounded, we are faced
with increases of the maximal internal delays of instruction sequences on
execution that are not bounded by a linear function if we strive for acceptable
increases of the lengths of instruction sequences on elimination of indirect
jump instructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2090</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2090</id><created>2009-09-11</created><authors><author><keyname>Dalmau</keyname><forenames>Marc</forenames></author><author><keyname>Roose</keyname><forenames>Philippe</forenames></author><author><keyname>Laplace</keyname><forenames>Sophie</forenames></author></authors><title>Context Aware Adaptable Applications - A global approach</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues, Volume 1, pp13-25,
  August 2009</comments><journal-ref>M. Dalmau, P. Roose and S. Laplace, &quot;Context Aware Adaptable
  Applications - A global approach&quot;, International Journal of Computer Science
  Issues, Volume 1, pp13-25, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Actual applications (mostly component based) requirements cannot be expressed
without a ubiquitous and mobile part for end-users as well as for M2M
applications (Machine to Machine). Such an evolution implies context management
in order to evaluate the consequences of the mobility and corresponding
mechanisms to adapt or to be adapted to the new environment. Applications are
then qualified as context aware applications. This first part of this paper
presents an overview of context and its management by application adaptation.
This part starts by a definition and proposes a model for the context. It also
presents various techniques to adapt applications to the context: from
self-adaptation to supervised approached. The second part is an overview of
architectures for adaptable applications. It focuses on platforms based
solutions and shows information flows between application, platform and
context. Finally it makes a synthesis proposition with a platform for adaptable
context-aware applications called Kalimucho. Then we present implementations
tools for software components and a dataflow models in order to implement the
Kalimucho platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2091</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2091</id><created>2009-09-11</created><authors><author><keyname>Takagi</keyname><forenames>Hideyuki</forenames><affiliation>I3S</affiliation></author><author><keyname>Pallez</keyname><forenames>Denis</forenames><affiliation>I3S</affiliation></author></authors><title>Paired Comparisons-based Interactive Differential Evolution</title><categories>cs.AI</categories><proxy>ccsd hal-00415778</proxy><journal-ref>World Congress on Nature and Biologically Inspired Computing,
  Coimbatore : Inde (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Interactive Differential Evolution (IDE) based on paired
comparisons for reducing user fatigue and evaluate its convergence speed in
comparison with Interactive Genetic Algorithms (IGA) and tournament IGA. User
interface and convergence performance are two big keys for reducing Interactive
Evolutionary Computation (IEC) user fatigue. Unlike IGA and conventional IDE,
users of the proposed IDE and tournament IGA do not need to compare whole
individuals each other but compare pairs of individuals, which largely
decreases user fatigue. In this paper, we design a pseudo-IEC user and evaluate
another factor, IEC convergence performance, using IEC simulators and show that
our proposed IDE converges significantly faster than IGA and tournament IGA,
i.e. our proposed one is superior to others from both user interface and
convergence performance points of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2103</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2103</id><created>2009-09-11</created><authors><author><keyname>Bouzefrane</keyname><forenames>Samia</forenames></author><author><keyname>Cordry</keyname><forenames>Julien</forenames></author><author><keyname>Paradinas</keyname><forenames>Pierre</forenames></author></authors><title>MESURE Tool to benchmark Java Card platforms</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues, Volume 1, pp49-57,
  August 2009</comments><journal-ref>S. Bouzefrane, J. Cordry and P. Paradinas,&quot;MESURE Tool to
  benchmark Java Card platforms&quot;, International Journal of Computer Science
  Issues, Volume 1, pp49-57, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of the Java Card standard has been a major turning point in smart
card technology. With the growing acceptance of this standard, understanding
the performance behavior of these platforms is becoming crucial. To meet this
need, we present in this paper a novel benchmarking framework to test and
evaluate the performance of Java Card platforms. MESURE tool is the first
framework which accuracy and effectiveness are independent from the particular
Java Card platform tested and CAD used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2119</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2119</id><created>2009-09-11</created><updated>2010-11-25</updated><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author></authors><title>Performance of Opportunistic Epidemic Routing on Edge-Markovian Dynamic
  Graphs</title><categories>cs.NI</categories><comments>5 pages, 4 figures. Accepted for publication in IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectivity patterns in intermittently-connected mobile networks (ICMN) can
be modeled as edge-Markovian dynamic graphs. We propose a new model for
epidemic propagation on such graphs and calculate a closed-form expression that
links the best achievable delivery ratio to common ICMN parameters such as
message size, maximum tolerated delay, and link lifetime. These theoretical
results are compared to those obtained by replaying a real-life contact trace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2145</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2145</id><created>2009-09-11</created><authors><author><keyname>Cruz-Lara</keyname><forenames>Samuel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Bonhomme</keyname><forenames>Patrice</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>De Saint-Rat</keyname><forenames>Christophe</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A general XML-based distributed software architecture for accessing and
  sharing ressources</title><categories>cs.SE</categories><comments>Colloque avec actes et comit\'e de lecture</comments><proxy>ccsd inria-00098880</proxy><report-no>99-R-368 || cruz-lara99a</report-no><journal-ref>XML Finland'99, Helsinki : Finland (1999)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a general xml-based distributed software architecture in
the aim of accessing and sharing resources in an opened client/server
environment. The paper is organized as follows : First, we introduce the idea
of a &quot;General Distributed Software Architecture&quot;. Second, we describe the
general framework in which this architecture is used. Third, we describe the
process of information exchange and we introduce some technical issues involved
in the implementation of the proposed architecture. Finally, we present some
projects which are currently using, or which should use, the proposed
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2157</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2157</id><created>2009-09-11</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>Navigation in tilings of the hyperbolic plane and possible applications</title><categories>cs.CG</categories><comments>7 pages, 10 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a method of navigation in a large family of tilings of
the hyperbolic plane and looks at the question of possible applications in the
light of the few ones which were already obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2183</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2183</id><created>2009-09-11</created><authors><author><keyname>Ibrahim</keyname><forenames>Noha</forenames></author><author><keyname>Mouel</keyname><forenames>Frederic Le</forenames></author></authors><title>A Survey on Service Composition Middleware in Pervasive Environments</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues, Volume 1, pp1-12,
  August 2009</comments><journal-ref>N. Ibrahim and F.L. Mouel, &quot; A Survey on Service Composition
  Middleware in Pervasive Environments&quot;,International Journal of Computer
  Science Issues, Volume 1, pp1-12, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of pervasive computing has put the light on a challenging
problem: how to dynamically compose services in heterogeneous and highly
changing environments? We propose a survey that defines the service composition
as a sequence of four steps: the translation, the generation, the evaluation,
and finally the execution. With this powerful and simple model we describe the
major service composition middleware. Then, a classification of these service
composition middleware according to pervasive requirements - interoperability,
discoverability, adaptability, context awareness, QoS management, security,
spontaneous management, and autonomous management - is given. The
classification highlights what has been done and what remains to do to develop
the service composition in pervasive environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2185</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2185</id><created>2009-09-11</created><authors><author><keyname>Carter</keyname><forenames>Scott</forenames></author><author><keyname>Denoue</keyname><forenames>Laurent</forenames></author></authors><title>SeeReader: An (Almost) Eyes-Free Mobile Rich Document Viewer</title><categories>cs.HC</categories><comments>International Journal of Computer Science Issues, Volume 1, pp36-41,
  August 2009</comments><journal-ref>S. Carter and L. Denoue, &quot;SeeReader: An (Almost) Eyes-Free Mobile
  Rich Document Viewer &quot;, International Journal of Computer Science Issues,
  Volume 1, pp36-41, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reading documents on mobile devices is challenging. Not only are screens
small and difficult to read, but also navigating an environment using limited
visual attention can be difficult and potentially dangerous. Reading content
aloud using text-tospeech (TTS) processing can mitigate these problems, but
only for content that does not include rich visual information. In this paper,
we introduce a new technique, SeeReader, that combines TTS with automatic
content recognition and document presentation control that allows users to
listen to documents while also being notified of important visual content.
Together, these services allow users to read rich documents on mobile devices
while maintaining awareness of their visual environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2187</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2187</id><created>2009-09-11</created><authors><author><keyname>Torres</keyname><forenames>Santiago J. Barro</forenames></author><author><keyname>Cascon</keyname><forenames>Carlos J. Escudero</forenames></author></authors><title>Embedded Sensor System for Early Pathology Detection in Building
  Construction</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, Volume 1, pp26-35,
  August 2009</comments><journal-ref>S.J. B. Torres and C. J. E. Cascon, &quot; Embedded Sensor System for
  Early Pathology Detection in Building Construction&quot;, International Journal of
  Computer Science Issues, Volume 1, pp26-35, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structure pathology detection is an important security task in building
construction, which is performed by an operator by looking manually for damages
on the materials. This activity could be dangerous if the structure is hidden
or difficult to reach. On the other hand, embedded devices and wireless sensor
networks (WSN) are becoming popular and cheap, enabling the design of an
alternative pathology detection system to monitor structures based on these
technologies. This article introduces a ZigBee WSN system, intending to be
autonomous, easy to use and with low power consumption. Its functional parts
are fully discussed with diagrams, as well as the protocol used to collect
samples from sensor nodes. Finally, several tests focused on range and power
consumption of our prototype are shown, analysing whether the results obtained
were as expected or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2194</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2194</id><created>2009-09-11</created><authors><author><keyname>Tschopp</keyname><forenames>Dominique</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Approximate Nearest Neighbor Search through Comparisons</title><categories>cs.DS cs.DB cs.LG</categories><comments>19 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of finding the nearest neighbor (or one of
the R-nearest neighbors) of a query object q in a database of n objects. In
contrast with most existing approaches, we can only access the ``hidden'' space
in which the objects live through a similarity oracle. The oracle, given two
reference objects and a query object, returns the reference object closest to
the query object. The oracle attempts to model the behavior of human users,
capable of making statements about similarity, but not of assigning meaningful
numerical values to distances between objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2234</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2234</id><created>2009-09-11</created><updated>2010-09-09</updated><authors><author><keyname>Unnikrishnan</keyname><forenames>Jayakrishnan</forenames></author><author><keyname>Huang</keyname><forenames>Dayu</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author><author><keyname>Surana</keyname><forenames>Amit</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal</forenames></author></authors><title>Universal and Composite Hypothesis Testing via Mismatched Divergence</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>Accepted to IEEE Transactions on Information Theory, July 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the universal hypothesis testing problem, where the goal is to decide
between the known null hypothesis distribution and some other unknown
distribution, Hoeffding proposed a universal test in the nineteen sixties.
Hoeffding's universal test statistic can be written in terms of
Kullback-Leibler (K-L) divergence between the empirical distribution of the
observations and the null hypothesis distribution. In this paper a modification
of Hoeffding's test is considered based on a relaxation of the K-L divergence
test statistic, referred to as the mismatched divergence. The resulting
mismatched test is shown to be a generalized likelihood-ratio test (GLRT) for
the case where the alternate distribution lies in a parametric family of the
distributions characterized by a finite dimensional parameter, i.e., it is a
solution to the corresponding composite hypothesis testing problem. For certain
choices of the alternate distribution, it is shown that both the Hoeffding test
and the mismatched test have the same asymptotic performance in terms of error
exponents. A consequence of this result is that the GLRT is optimal in
differentiating a particular distribution from others in an exponential family.
It is also shown that the mismatched test has a significant advantage over the
Hoeffding test in terms of finite sample size performance. This advantage is
due to the difference in the asymptotic variances of the two test statistics
under the null hypothesis. In particular, the variance of the K-L divergence
grows linearly with the alphabet size, making the test impractical for
applications involving large alphabet distributions. The variance of the
mismatched divergence on the other hand grows linearly with the dimension of
the parameter space, and can hence be controlled through a prudent choice of
the function class defining the mismatched divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2290</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2290</id><created>2009-09-11</created><authors><author><keyname>Li</keyname><forenames>Tiancheng</forenames></author><author><keyname>Li</keyname><forenames>Ninghui</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author><author><keyname>Molloy</keyname><forenames>Ian</forenames></author></authors><title>Slicing: A New Approach to Privacy Preserving Data Publishing</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several anonymization techniques, such as generalization and bucketization,
have been designed for privacy preserving microdata publishing. Recent work has
shown that generalization loses considerable amount of information, especially
for high-dimensional data. Bucketization, on the other hand, does not prevent
membership disclosure and does not apply for data that do not have a clear
separation between quasi-identifying attributes and sensitive attributes.
  In this paper, we present a novel technique called slicing, which partitions
the data both horizontally and vertically. We show that slicing preserves
better data utility than generalization and can be used for membership
disclosure protection. Another important advantage of slicing is that it can
handle high-dimensional data. We show how slicing can be used for attribute
disclosure protection and develop an efficient algorithm for computing the
sliced data that obey the l-diversity requirement. Our workload experiments
confirm that slicing preserves better utility than generalization and is more
effective than bucketization in workloads involving the sensitive attribute.
Our experiments also demonstrate that slicing can be used to prevent membership
disclosure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2292</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2292</id><created>2009-09-13</created><updated>2009-10-01</updated><authors><author><keyname>Wang</keyname><forenames>Xiao Z.</forenames></author><author><keyname>Sha</keyname><forenames>Wei E. I.</forenames></author></authors><title>Random Sampling Using Shannon Interpolation and Poisson Summation
  Formulae</title><categories>cs.IT cs.CE math.IT math.NA</categories><comments>This is a preprint version of research report, which may submit to
  some conference or journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report mainly focused on the basic concepts and the recovery methods for
the random sampling. The recovery methods involve the orthogonal matching
pursuit algorithm and the gradient-based total variation strategy. In
particular, a fast and efficient observation matrix filling technique was
implemented by the classic Shannon interpolation and Poisson summation
formulae. The numerical results for the trigonometric signal, the
Gaussian-modulated sinusoidal pulse, and the square wave were demonstrated and
discussed. The work may give some help for future work in theoretical study and
practical implementation of the random sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2297</identifier>
 <datestamp>2009-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2297</id><created>2009-09-13</created><authors><author><keyname>Wira-Alam</keyname><forenames>Andias</forenames></author></authors><title>Simulation of Resource Usage in Parallel Evolutionary Peptide
  Optimization using JavaSpaces Technology</title><categories>cs.DC cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peptide Optimization is a highly complex problem and it takes very long time
of computation. This optimization process uses many software applications in a
cluster running GNU/Linux Operating System that perform special tasks. The
application to organize the whole optimization process had been already
developed, namely SEPP (System for Evolutionary Pareto Optimization of
Peptides/Polymers). A single peptide optimization takes a lot of computation
time to produce a certain number of individuals. However, it can be accelerated
by increasing the degree of parallelism as well as the number of nodes
(processors) in the cluster. In this master thesis, I build a model simulating
the interplay of the programs so that the usage of each resource (processor)
can be determined and also the approximated time needed for the overall
optimization process. There are two Evolutionary Algorithms that could be used
in the optimization, namely Generation-based and Steady-state Evolutionary
Algorithm. The results of each Evolutionary Algorithm are shown based on the
simulations. Moreover, the results are also compared by using different
parameters (the degree of parallelism and the number of processors) in the
simulation to give an overview of the advantages and the disadvantages of the
algorithms in terms of computation time and resource usage. The model is built
up using JavaSpaces Technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2309</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2309</id><created>2009-09-12</created><updated>2009-12-14</updated><authors><author><keyname>Tanaka</keyname><forenames>Jun</forenames></author></authors><title>Logic with Verbs</title><categories>cs.AI cs.LO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The aim of this paper is to introduce a logic in which nouns and verbs are
handled together as a deductive reasoning, and also to observe the relationship
between nouns and verbs as well as between logics and conversations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2318</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2318</id><created>2009-09-12</created><authors><author><keyname>Chevreau</keyname><forenames>Gr&#xe9;goire</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Conort</keyname><forenames>Pierre</forenames><affiliation>CRISTAL</affiliation></author><author><keyname>Renard-Penna</keyname><forenames>Rapha&#xeb;lle</forenames><affiliation>CRISTAL</affiliation></author><author><keyname>Mallet</keyname><forenames>Alain</forenames><affiliation>CRISTAL</affiliation></author><author><keyname>Daudon</keyname><forenames>Michel</forenames><affiliation>CRISTAL</affiliation></author><author><keyname>Mozer</keyname><forenames>Pierre</forenames></author></authors><title>Estimation of urinary stone composition by automated processing of CT
  images</title><categories>physics.med-ph cs.OH</categories><proxy>ccsd hal-00416159</proxy><journal-ref>Urological Research (2009) epub ahead of print</journal-ref><doi>10.1007/s00240-009-0195-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this article was developing an automated tool for routine
clinical practice to estimate urinary stone composition from CT images based on
the density of all constituent voxels. A total of 118 stones for which the
composition had been determined by infrared spectroscopy were placed in a
helical CT scanner. A standard acquisition, low-dose and high-dose acquisitions
were performed. All voxels constituting each stone were automatically selected.
A dissimilarity index evaluating variations of density around each voxel was
created in order to minimize partial volume effects: stone composition was
established on the basis of voxel density of homogeneous zones. Stone
composition was determined in 52% of cases. Sensitivities for each compound
were: uric acid: 65%, struvite: 19%, cystine: 78%, carbapatite: 33.5%, calcium
oxalate dihydrate: 57%, calcium oxalate monohydrate: 66.5%, brushite: 75%.
Low-dose acquisition did not lower the performances (P &lt; 0.05). This entirely
automated approach eliminates manual intervention on the images by the
radiologist while providing identical performances including for low-dose
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2331</identifier>
 <datestamp>2014-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2331</id><created>2009-09-12</created><updated>2014-05-02</updated><authors><author><keyname>Kelleher</keyname><forenames>Jerome</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Barry</forenames></author></authors><title>Generating All Partitions: A Comparison Of Two Encodings</title><categories>cs.DS cs.DM math.CO</categories><comments>40 pages, 2 figures. Derived from J. Kelleher's Ph.D thesis, Encoding
  Partitions as Ascending Compositions, University College Cork, 2006. V2:
  corrected typos in RuleDesc algorithm</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integer partitions may be encoded as either ascending or descending
compositions for the purposes of systematic generation. Many algorithms exist
to generate all descending compositions, yet none have previously been
published to generate all ascending compositions. We develop three new
algorithms to generate all ascending compositions and compare these with
descending composition generators from the literature. We analyse the new
algorithms and provide new and more precise analyses for the descending
composition generators. In each case, the ascending composition generation
algorithm is substantially more efficient than its descending composition
counterpart. We develop a new formula for the partition function p(n) as part
of our analysis of the lexicographic succession rule for ascending
compositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2336</identifier>
 <datestamp>2010-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2336</id><created>2009-09-12</created><updated>2010-05-19</updated><authors><author><keyname>Ghaffari</keyname><forenames>Hamed . O.</forenames></author></authors><title>Two-Phase Flow in Heterogeneous Media</title><categories>cs.CE</categories><comments>This paper has been withdrawn by the author due to repetition of some
  parts in other publications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we investigate the appeared complexity of two-phase flow
(air-water) in a heterogeneous soil where the supposed porous media is
non-deformable media which is under the time-dependent gas pressure. After
obtaining of governing equations and considering the capillary
pressure-saturation and permeability functions, the evolution of the models
unknown parameters were obtained. In this way, using COMSOL (FEMLAB) and fluid
flow-script Module, the role of heterogeneity in intrinsic permeability was
analysed. Also, the evolution of relative permeability of wetting and
non-wetting fluid, capillary pressure and other parameters were elicited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2339</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2339</id><created>2009-09-12</created><authors><author><keyname>Owladeghaffari</keyname><forenames>H.</forenames></author><author><keyname>Aghababaei</keyname><forenames>H.</forenames></author></authors><title>Back analysis based on SOM-RST system</title><categories>cs.AI</categories><comments>10th. International Symposium on Landslides and Engineering and.
  Engineered Slopes, Xi'an, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes application of information granulation theory, on the
back analysis of Jeffrey mine southeast wall Quebec. In this manner, using a
combining of Self Organizing Map (SOM) and rough set theory (RST), crisp and
rough granules are obtained. Balancing of crisp granules and sub rough granules
is rendered in close-open iteration. Combining of hard and soft computing,
namely finite difference method (FDM) and computational intelligence and taking
in to account missing information are two main benefits of the proposed method.
As a practical example, reverse analysis on the failure of the southeast wall
Jeffrey mine is accomplished.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2345</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2345</id><created>2009-09-12</created><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author></authors><title>Weblog Clustering in Multilinear Algebra Perspective</title><categories>cs.IR</categories><comments>16 pages, 7 figures</comments><journal-ref>International Journal of Information Technology, Vol. 15 No. 1,
  2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper describes a clustering method to group the most similar and
important weblogs with their descriptive shared words by using a technique from
multilinear algebra known as PARAFAC tensor decomposition. The proposed method
first creates labeled-link network representation of the weblog datasets, where
the nodes are the blogs and the labels are the shared words. Then, 3-way
adjacency tensor is extracted from the network and the PARAFAC decomposition is
applied to the tensor to get pairs of node lists and label lists with scores
attached to each list as the indication of the degree of importance. The
clustering is done by sorting the lists in decreasing order and taking the
pairs of top ranked blogs and words. Thus, unlike standard co-clustering
methods, this method not only groups the similar blogs with their descriptive
words but also tends to produce clusters of important blogs and descriptive
words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2358</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2358</id><created>2009-09-12</created><authors><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author><author><keyname>Backhaus</keyname><forenames>Scott</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Message Passing for Integrating and Assessing Renewable Generation in a
  Redundant Power Grid</title><categories>physics.soc-ph cond-mat.stat-mech cs.CE physics.data-an</categories><comments>10 pages, accepted for HICSS-43</comments><journal-ref>43rd Hawaii International Conference on System Sciences (HICSS),
  1-10 (2010)</journal-ref><doi>10.1109/HICSS.2010.272</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simplified model of a redundant power grid is used to study integration of
fluctuating renewable generation. The grid consists of large number of
generator and consumer nodes. The net power consumption is determined by the
difference between the gross consumption and the level of renewable generation.
The gross consumption is drawn from a narrow distribution representing the
predictability of aggregated loads, and we consider two different distributions
representing wind and solar resources. Each generator is connected to D
consumers, and redundancy is built in by connecting R of these consumers to
other generators. The lines are switchable so that at any instance each
consumer is connected to a single generator. We explore the capacity of the
renewable generation by determining the level of &quot;firm&quot; generation capacity
that can be displaced for different levels of redundancy R. We also develop
message-passing control algorithm for finding switch settings where no
generator is overloaded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2363</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2363</id><created>2009-09-12</created><authors><author><keyname>Islam</keyname><forenames>Md. Rabiul</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Fayzur</forenames></author></authors><title>Improvement of Text Dependent Speaker Identification System Using
  Neuro-Genetic Hybrid Algorithm in Office Environmental Conditions</title><categories>cs.SD</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp42-48, August 2009</comments><journal-ref>R. Islam and F. Rahman,&quot; International Journal of Computer Science
  Issues (IJCSI), Volume 1, pp42-48,August 2009&quot;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an improved strategy for automated text dependent speaker
identification system has been proposed in noisy environment. The
identification process incorporates the Neuro- Genetic hybrid algorithm with
cepstral based features. To remove the background noise from the source
utterance, wiener filter has been used. Different speech pre-processing
techniques such as start-end point detection algorithm, pre-emphasis filtering,
frame blocking and windowing have been used to process the speech utterances.
RCC, MFCC, MFCC, MFCC, LPC and LPCC have been used to extract the features.
After feature extraction of the speech, Neuro-Genetic hybrid algorithm has been
used in the learning and identification purposes. Features are extracted by
using different techniques to optimize the performance of the identification.
According to the VALID speech database, the highest speaker identification rate
of 100.000 percent for studio environment and 82.33 percent for office
environmental conditions have been achieved in the close set text dependent
speaker identification system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2365</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2365</id><created>2009-09-12</created><authors><author><keyname>Schatten</keyname><forenames>Markus</forenames></author><author><keyname>Baca</keyname><forenames>Miroslav</forenames></author><author><keyname>Cubrilo</keyname><forenames>Mirko</forenames></author></authors><title>Towards a General Definition of Biometric Systems</title><categories>cs.OH q-bio.QM</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp1-7, August 2009</comments><journal-ref>M. Schatten, M. Baca and M. Cubrilo, &quot; Towards a General
  Definition of Biometric Systems&quot;, International Journal of Computer Science
  Issues (IJCSI), Volume 1, pp1-7, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A foundation for closing the gap between biometrics in the narrower and the
broader perspective is presented trough a conceptualization of biometric
systems in both perspectives. A clear distinction between verification,
identification and classification systems is made as well as shown that there
are additional classes of biometric systems. In the end a Unified Modeling
Language model is developed showing the connections between the two
perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2366</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2366</id><created>2009-09-12</created><authors><author><keyname>Halloush</keyname><forenames>Maisa</forenames></author><author><keyname>Sharif</keyname><forenames>Mai</forenames></author></authors><title>Global Heuristic Search on Encrypted Data (GHSED)</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp13-17, August 2009</comments><journal-ref>M. Halloush and M. Sharif,&quot;Global Heuristic Search on Encrypted
  Data (GHSED) &quot;, International Journal of Computer Science Issues (IJCSI),
  Volume 1, pp13-17, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Important document are being kept encrypted in remote servers. In order to
retrieve these encrypted data, efficient search methods needed to enable the
retrieval of the document without knowing the content of the documents In this
paper a technique called a global heuristic search on encrypted data (GHSED)
technique will be described for search in an encrypted files using public key
encryption stored on an untrusted server and retrieve the files that satisfy a
certain search pattern without revealing any information about the original
files. GHSED technique would satisfy the following: (1) Provably secure, the
untrusted server cannot learn anything about the plaintext given only the
cipher text. (2) Provide controlled searching, so that the untrusted server
cannot search for a word without the user's authorization. (3) Support hidden
queries, so that the user may ask the untrusted server to search for a secret
word without revealing the word to the server. (4) Support query isolation, so
the untrusted server learns nothing more than the search result about the
plaintext.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2367</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2367</id><created>2009-09-12</created><authors><author><keyname>Qureshi</keyname><forenames>M Atif</forenames></author><author><keyname>Younus</keyname><forenames>Arjumand</forenames></author><author><keyname>Khan</keyname><forenames>Arslan Ahmed</forenames></author></authors><title>Philosophical Survey of Passwords</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp8-12, August 2009</comments><journal-ref>M . Qureshi, A.Younus and A. A. Khan,&quot;Philosophical Survey of
  Passwords&quot;, International Journal of Computer Science Issues (IJCSI), Volume
  1, pp8-12, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the years security experts in the field of Information Technology have
had a tough time in making passwords secure. This paper studies and takes a
careful look at this issue from the angle of philosophy and cognitive science.
We have studied the process of passwords to rank its strengths and weaknesses
in order to establish a quality metric for passwords. Finally we related the
process to human senses which enables us to propose a constitutional scheme for
the process of password. The basic proposition is to exploit relationship
between human senses and password to ensure improvement in authentication while
keeping it an enjoyable activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2368</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2368</id><created>2009-09-12</created><authors><author><keyname>Lewis</keyname><forenames>Kelly D. Lewis andjames E.</forenames></author></authors><title>Web Single Sign-On Authentication using SAML</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp41-48, August 2009</comments><journal-ref>K. D. LEWIS andJ. E. LEWIS, &quot; Web Single Sign-On Authentication
  using SAML&quot;, International Journal of Computer Science Issues (IJCSI), Volume
  1, pp41-48, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Companies have increasingly turned to application service providers (ASPs) or
Software as a Service (SaaS) vendors to offer specialized web-based services
that will cut costs and provide specific and focused applications to users. The
complexity of designing, installing, configuring, deploying, and supporting the
system with internal resources can be eliminated with this type of methodology,
providing great benefit to organizations. However, these models can present an
authentication problem for corporations with a large number of external service
providers. This paper describes the implementation of Security Assertion Markup
Language (SAML) and its capabilities to provide secure single sign-on (SSO)
solutions for externally hosted applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2369</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2369</id><created>2009-09-12</created><authors><author><keyname>Ismaili</keyname><forenames>Zine El Abidine Alaoui</forenames></author><author><keyname>Moussa</keyname><forenames>Ahmed</forenames></author></authors><title>Self-Partial and Dynamic Reconfiguration Implementation for AES using
  FPGA</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp33-40, August 2009</comments><journal-ref>Z. El. ALAOUI ISMAILI and A. MOUSSA, &quot; Self-Partial and Dynamic
  Reconfiguration Implementation for AES using FPGA&quot;, International Journal of
  Computer Science Issues (IJCSI), Volume 1, pp33-40, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses efficient hardware/software implementation approaches
for the AES (Advanced Encryption Standard) algorithm and describes the design
and performance testing algorithm for embedded system. Also, with the spread of
reconfigurable hardware such as FPGAs (Field Programmable Gate Array) embedded
cryptographic hardware became cost-effective. Nevertheless, it is worthy to
note that nowadays, even hardwired cryptographic algorithms are not so safe.
  From another side, the self-reconfiguring platform is reported that enables
an FPGA to dynamically reconfigure itself under the control of an embedded
microprocessor. Hardware acceleration significantly increases the performance
of embedded systems built on programmable logic. Allowing a FPGA-based
MicroBlaze processor to self-select the coprocessors uses can help reduce area
requirements and increase a system's versatility. The architecture proposed in
this paper is an optimal hardware implementation algorithm and takes dynamic
partially reconfigurable of FPGA. This implementation is good solution to
preserve confidentiality and accessibility to the information in the numeric
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2370</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2370</id><created>2009-09-12</created><authors><author><keyname>Saraydaryan</keyname><forenames>Jacques</forenames></author><author><keyname>Benali</keyname><forenames>Fatiha</forenames></author><author><keyname>Ubeda</keyname><forenames>Stephane</forenames></author></authors><title>Comprehensive Security Framework for Global Threads Analysis</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp18-32, August 2009</comments><journal-ref>J. SARAYDARYAN, F.BENALI and S. UBEDA, &quot;Comprehensive Security
  Framework for Global Threads Analysis &quot;, International Journal of Computer
  Science Issues (IJCSI), Volume 1, pp18-32, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber criminality activities are changing and becoming more and more
professional. With the growth of financial flows through the Internet and the
Information System (IS), new kinds of thread arise involving complex scenarios
spread within multiple IS components. The IS information modeling and
Behavioral Analysis are becoming new solutions to normalize the IS information
and counter these new threads. This paper presents a framework which details
the principal and necessary steps for monitoring an IS. We present the
architecture of the framework, i.e. an ontology of activities carried out
within an IS to model security information and User Behavioral analysis. The
results of the performed experiments on real data show that the modeling is
effective to reduce the amount of events by 91%. The User Behavioral Analysis
on uniform modeled data is also effective, detecting more than 80% of
legitimate actions of attack scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2371</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2371</id><created>2009-09-12</created><authors><author><keyname>Raj</keyname><forenames>Payal N.</forenames></author><author><keyname>Swadas</keyname><forenames>Prashant B.</forenames></author></authors><title>Dpraodv: A Dyanamic Learning System Against Blackhole Attack in Aodv
  Based Manet</title><categories>cs.CR cs.NI</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp54-59, August 2009</comments><journal-ref>P. N. Raj and P. B. Swadas, &quot;DPRAODV: A DYANAMIC LEARNING SYSTEM
  AGAINST BLACKHOLE ATTACK IN AODV BASED MANET&quot;, International Journal of
  Computer Science Issues (IJCSI), Volume 1, pp54-59, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security is an essential requirement in mobile ad hoc networks to provide
protected communication between mobile nodes. Due to unique characteristics of
MANETS, it creates a number of consequential challenges to its security design.
To overcome the challenges, there is a need to build a multifence security
solution that achieves both broad protection and desirable network performance.
MANETs are vulnerable to various attacks, blackhole, is one of the possible
attacks. Black hole is a type of routing attack where a malicious node
advertise itself as having the shortest path to all nodes in the environment by
sending fake route reply. By doing this, the malicious node can deprive the
traffic from the source node. It can be used as a denial-of-service attack
where it can drop the packets later. In this paper, we proposed a DPRAODV
(Detection, Prevention and Reactive AODV) to prevent security threats of
blackhole by notifying other nodes in the network of the incident. The
simulation results in ns2 (ver- 2.33) demonstrate that our protocol not only
prevents blackhole attack but consequently improves the overall performance of
(normal) AODV in presence of black hole attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2373</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2373</id><created>2009-09-12</created><authors><author><keyname>Nageshkumar</keyname><forenames>M.</forenames></author><author><keyname>Mahesh</keyname><forenames>P. K.</forenames></author><author><keyname>Swamy</keyname><forenames>M. N. S.</forenames></author></authors><title>An Efficient Secure Multimodal Biometric Fusion Using Palmprint and Face
  Image</title><categories>cs.CV cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 1,
  pp49-53, August 2009</comments><journal-ref>M.Nageshkumar,P.K.Mahesh and M.N.S.Swamy, &quot;An Efficient Secure
  Multimodal Biometric Fusion Using Palmprint and Face Image&quot;, International
  Journal of Computer Science Issues (IJCSI), Volume 1, pp49-53, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometrics based personal identification is regarded as an effective method
for automatically recognizing, with a high confidence a person's identity. A
multimodal biometric systems consolidate the evidence presented by multiple
biometric sources and typically better recognition performance compare to
system based on a single biometric modality. This paper proposes an
authentication method for a multimodal biometric system identification using
two traits i.e. face and palmprint. The proposed system is designed for
application where the training data contains a face and palmprint. Integrating
the palmprint and face features increases robustness of the person
authentication. The final decision is made by fusion at matching score level
architecture in which features vectors are created independently for query
measures and are then compared to the enrolment template, which are stored
during database preparation. Multimodal biometric system is developed through
fusion of face and palmprint recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2375</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2375</id><created>2009-09-12</created><authors><author><keyname>Kabir</keyname><forenames>Mashud</forenames></author></authors><title>Similarity Matching Techniques for Fault Diagnosis in Automotive
  Infotainment Electronics</title><categories>cs.AI</categories><comments>International Journal of Computer Science Issues(IJCSI), Volume 3,
  pp14-19, August 2009</comments><journal-ref>M. Kabir, &quot; SIMILARITY MATCHING TECHNIQUES FOR FAULT DIAGNOSIS IN
  AUTOMOTIVE INFOTAINMENT ELECTRONICS&quot;, International Journal of Computer
  Science Issues(IJCSI), Volume 3, pp14-19, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fault diagnosis has become a very important area of research during the last
decade due to the advancement of mechanical and electrical systems in
industries. The automobile is a crucial field where fault diagnosis is given a
special attention. Due to the increasing complexity and newly added features in
vehicles, a comprehensive study has to be performed in order to achieve an
appropriate diagnosis model. A diagnosis system is capable of identifying the
faults of a system by investigating the observable effects (or symptoms). The
system categorizes the fault into a diagnosis class and identifies a probable
cause based on the supplied fault symptoms. Fault categorization and
identification are done using similarity matching techniques. The development
of diagnosis classes is done by making use of previous experience, knowledge or
information within an application area. The necessary information used may come
from several sources of knowledge, such as from system analysis. In this paper
similarity matching techniques for fault diagnosis in automotive infotainment
applications are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2376</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2376</id><created>2009-09-12</created><authors><author><keyname>Lazanas</keyname><forenames>Alexis</forenames></author></authors><title>Performing Hybrid Recommendation in Intermodal Transportation-the
  FTMarket System's Recommendation Module</title><categories>cs.AI</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 3,
  pp24-34, August 2009</comments><journal-ref>A. Lazanas&quot;Performing Hybrid Recommendation in Intermodal
  Transportation-the FTMarket System's Recommendation Module &quot;,International
  Journal of Computer Science Issues (IJCSI), Volume 3, pp24-34, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diverse recommendation techniques have been already proposed and encapsulated
into several e-business applications, aiming to perform a more accurate
evaluation of the existing information and accordingly augment the assistance
provided to the users involved. This paper reports on the development and
integration of a recommendation module in an agent-based transportation
transactions management system. The module is built according to a novel hybrid
recommendation technique, which combines the advantages of collaborative
filtering and knowledge-based approaches. The proposed technique and supporting
module assist customers in considering in detail alternative transportation
transactions that satisfy their requests, as well as in evaluating completed
transactions. The related services are invoked through a software agent that
constructs the appropriate knowledge rules and performs a synthesis of the
recommendation policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2377</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2377</id><created>2009-09-12</created><authors><author><keyname>Zirari</keyname><forenames>Soumaya</forenames></author><author><keyname>Canalda</keyname><forenames>Philippe</forenames></author><author><keyname>Spies</keyname><forenames>Francois</forenames></author></authors><title>Geometric and Signal Strength Dilution of Precision (DoP)Wi-Fi</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 3,
  pp35-44, August 2009</comments><journal-ref>S.Zirari,P. Canalda and F.Spies, &quot; Geometric and Signal Strength
  Dilution of Precision (DoP)Wi-Fi&quot;, International Journal of Computer Science
  Issues (IJCSI), Volume 3, pp35-44, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The democratization of wireless networks combined to the emergence of mobile
devices increasingly autonomous and efficient lead to new services. Positioning
services become overcrowded. Accuracy is the main quality criteria in
positioning. But to better appreciate this one a coefficient is needed. In this
paper we present Geometric and Signal Strength Dilution of Precision (DOP) for
positioning systems based on Wi-Fi and Signal Strength measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2379</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2379</id><created>2009-09-12</created><authors><author><keyname>Gupta</keyname><forenames>Priyanka</forenames></author><author><keyname>Goyal</keyname><forenames>Vishal</forenames></author></authors><title>Implementation of Rule Based Algorithm for Sandhi-Vicheda Of Compound
  Hindi Words</title><categories>cs.CL</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 3,
  pp45-49, August 2009</comments><journal-ref>P.Gupta and V.Goyal, &quot; Implementation of Rule Based Algorithm for
  Sandhi-Vicheda Of Compound Hindi Words&quot;, International Journal of Computer
  Science Issues (IJCSI), Volume 3, pp45-49, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sandhi means to join two or more words to coin new word. Sandhi literally
means `putting together' or combining (of sounds), It denotes all combinatory
sound-changes effected (spontaneously) for ease of pronunciation.
Sandhi-vicheda describes [5] the process by which one letter (whether single or
cojoined) is broken to form two words. Part of the broken letter remains as the
last letter of the first word and part of the letter forms the first letter of
the next letter. Sandhi- Vicheda is an easy and interesting way that can give
entirely new dimension that add new way to traditional approach to Hindi
Teaching. In this paper using the Rule based algorithm we have reported an
accuracy of 60-80% depending upon the number of rules to be implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2408</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2408</id><created>2009-09-13</created><updated>2010-05-26</updated><authors><author><keyname>Cuff</keyname><forenames>Paul</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Permuter</keyname><forenames>Haim</forenames><affiliation>Ben-Gurion University</affiliation></author><author><keyname>Cover</keyname><forenames>Thomas</forenames><affiliation>Stanford University</affiliation></author></authors><title>Coordination Capacity</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Trans. on Info. Theory, 25 pages, 23 eps figure,
  uses IEEEtran.cls</comments><acm-class>H.1.1</acm-class><journal-ref>IEEE Trans. on Info. Theory, vol.56, no.9, pp.4181-4206, Sept.
  2010</journal-ref><doi>10.1109/TIT.2010.2054651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop elements of a theory of cooperation and coordination in networks.
Rather than considering a communication network as a means of distributing
information, or of reconstructing random processes at remote nodes, we ask what
dependence can be established among the nodes given the communication
constraints. Specifically, in a network with communication rates {R_{i,j}}
between the nodes, we ask what is the set of all achievable joint distributions
p(x1, ..., xm) of actions at the nodes of the network. Several networks are
solved, including arbitrarily large cascade networks.
  Distributed cooperation can be the solution to many problems such as
distributed games, distributed control, and establishing mutual information
bounds on the influence of one part of a physical system on another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2450</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2450</id><created>2009-09-13</created><updated>2010-01-20</updated><authors><author><keyname>Broderick</keyname><forenames>Tamara</forenames></author><author><keyname>MacKay</keyname><forenames>David John Cameron</forenames></author></authors><title>Fast and flexible selection with a single switch</title><categories>cs.HC</categories><comments>14 pages, 5 figures, 1 table, presented at NIPS 2009 Mini-symposia</comments><journal-ref>PLoS ONE 4(10): e7481, 2009</journal-ref><doi>10.1371/journal.pone.0007481</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Selection methods that require only a single-switch input, such as a button
click or blink, are potentially useful for individuals with motor impairments,
mobile technology users, and individuals wishing to transmit information
securely. We present a single-switch selection method, &quot;Nomon,&quot; that is general
and efficient. Existing single-switch selection methods require selectable
options to be arranged in ways that limit potential applications. By contrast,
traditional operating systems, web browsers, and free-form applications (such
as drawing) place options at arbitrary points on the screen. Nomon, however,
has the flexibility to select any point on a screen. Nomon adapts automatically
to an individual's clicking ability; it allows a person who clicks precisely to
make a selection quickly and allows a person who clicks imprecisely more time
to make a selection without error. Nomon reaps gains in information rate by
allowing the specification of beliefs (priors) about option selection
probabilities and by avoiding tree-based selection schemes in favor of direct
(posterior) inference. We have developed both a Nomon-based writing application
and a drawing application. To evaluate Nomon's performance, we compared the
writing application with a popular existing method for single-switch writing
(row-column scanning). Novice users wrote 35% faster with the Nomon interface
than with the scanning interface. An experienced user (author TB, with &gt; 10
hours practice) wrote at speeds of 9.3 words per minute with Nomon, using 1.2
clicks per character and making no errors in the final text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2452</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2452</id><created>2009-09-13</created><authors><author><keyname>Allan</keyname><forenames>Susan</forenames></author></authors><title>Excel Modelling - Transparency, Auditing and Business Use</title><categories>cs.SE cs.HC</categories><comments>7 Pages, 6 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 9-16
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within Lloyds Banking Group the heritage HBOS Corporate division deals with
Corporate loans, and is required to assess these loans for risk in accordance
with the Basle Accord regulations. Statistical Risk Rating models are developed
by the risk analysts to assess the obligors credit worthiness. It is necessary
then to provide the bankers who originated the loan ('Relationship Managers' or
RMs) with an assessment tool to generate the loan rating upon which they base
their lending decisions. Heritage HBoS Corporate required a new model build
system for holding its Risk Rating models in 2006 as a result of more complex
models being created to comply with the Basle Accord. The use of Excel was
promoted by the IT department for a number of reasons; the Excel solution now
in use is reviewed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2455</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2455</id><created>2009-09-13</created><authors><author><keyname>McGeady</keyname><forenames>Andrew</forenames></author><author><keyname>McGouran</keyname><forenames>Joseph</forenames></author></authors><title>End User Computing in AIB Capital Markets: A Management Summary</title><categories>cs.HC cs.CY</categories><comments>7 Pages. Referenced &amp; submitted by GJC in Sept 2009</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 25-31
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a management summary of how the area of End User Computing
(EUC) has been addressed by AIB Capital Markets. The development of an
effective policy is described, as well as the process by which a register of
critical EUC applications was assembled and how those applications were brought
into a controlled environment. A number of findings are included as well as
recommendations for others who would seek to run a similar project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2476</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2476</id><created>2009-09-14</created><authors><author><keyname>Hungr</keyname><forenames>Nikolai</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Zemiti</keyname><forenames>Nabil</forenames><affiliation>TIMC</affiliation></author><author><keyname>Tripodi</keyname><forenames>Nathanael</forenames><affiliation>TIMC</affiliation></author></authors><title>Design of an ultrasound-guided robotic brachytherapy needle insertion
  system</title><categories>cs.RO</categories><proxy>ccsd hal-00416163</proxy><journal-ref>31th International Conference of the Engineering in Medicine and
  Biology Society, Minneapolis : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a new robotic brachytherapy needle-insertion system
that is designed to replace the template used in the manual technique. After a
brief review of existing robotic systems, we describe the requirements that we
based our design upon. A detailed description of the proposed system follows.
Our design is capable of positioning and inclining a needle within the same
workspace as the manual template. To help improve accuracy, the needle can be
rotated about its axis during insertion into the prostate. The system can be
mounted on existing steppers and also easily accommodates existing seed
dispensers, such as the Mick Applicator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2489</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2489</id><created>2009-09-14</created><authors><author><keyname>Yang</keyname><forenames>Pu</forenames></author><author><keyname>Guo</keyname><forenames>Jun</forenames></author><author><keyname>Xu</keyname><forenames>Weiran</forenames></author></authors><title>PrisCrawler: A Relevance Based Crawler for Automated Data Classification
  from Bulletin Board</title><categories>cs.IR</categories><comments>published in GCIS of IEEE WRI '09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays people realize that it is difficult to find information simply and
quickly on the bulletin boards. In order to solve this problem, people propose
the concept of bulletin board search engine. This paper describes the
priscrawler system, a subsystem of the bulletin board search engine, which can
automatically crawl and add the relevance to the classified attachments of the
bulletin board. Priscrawler utilizes Attachrank algorithm to generate the
relevance between webpages and attachments and then turns bulletin board into
clear classified and associated databases, making the search for attachments
greatly simplified. Moreover, it can effectively reduce the complexity of
pretreatment subsystem and retrieval subsystem and improve the search
precision. We provide experimental results to demonstrate the efficacy of the
priscrawler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2496</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2496</id><created>2009-09-14</created><updated>2009-10-02</updated><authors><author><keyname>Yang</keyname><forenames>Pu</forenames></author><author><keyname>Guo</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Guang</forenames></author></authors><title>Pavideoge: A Metadata Markup Video Structure in Video Search Engine</title><categories>cs.IR</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problems of video processing in video search
engine. Video has now become a very important kind of data in Internet; while
searching for video is still a challenging task due to the inner properties of
video: requiring enormous storage space, being independent, expressing
information hiddenly. To handle the properties of video more effectively, in
this paper, we propose a new video processing method in video search engine. In
detail, the core of the new video processing method is creating pavideoge--a
new data type, which contains the video advantages and webpage advantages. The
pavideoge has four attributes: real link, videorank, text information and
playnum. Each of them combines video's properties with webpage's. Video search
engine based on the pavideoge can retrieve video more effectively. The
experiment results show the encouraging performance of our approach. Based on
the pavideoge, our video search engine can retrieve more precise videos in
comparsion with previous related work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2504</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2504</id><created>2009-09-14</created><updated>2009-09-16</updated><authors><author><keyname>Tschopp</keyname><forenames>Dominique</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author><author><keyname>Grossglauser</keyname><forenames>Matthias</forenames></author></authors><title>Hierarchical Routing over Dynamic Wireless Networks</title><categories>cs.NI cs.DS</categories><comments>29 pages, 19 figures, a shorter version was published in the
  proceedings of the 2008 ACM Sigmetrics conference</comments><report-no>LICOS-REPORT-2007-005</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless network topologies change over time and maintaining routes requires
frequent updates. Updates are costly in terms of consuming throughput available
for data transmission, which is precious in wireless networks. In this paper,
we ask whether there exist low-overhead schemes that produce low-stretch
routes. This is studied by using the underlying geometric properties of the
connectivity graph in wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2517</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2517</id><created>2009-09-14</created><updated>2009-10-06</updated><authors><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Hassan</keyname><forenames>Sk. Sarif</forenames></author><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author></authors><title>On the Interesting World of Fractals and Their Applications to Music</title><categories>cs.OH</categories><comments>This paper tell about music fractals. It is delivered at FRMS-2009</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we have defined one function that has been used to construct
different fractals having fractal dimensions between 1.58 and 2. Also, we tried
to calculate the amount of increment of fractal dimension in accordance with
the base of the number systems. Further, interestingly enough, these very
fractals could be a frame of lyrics for the musicians, as we know that the
fractal dimension of music is around 1.65 and varies between a high of 1.68 and
a low of 1.60. Further, at the end we conjecture that the switching from one
music fractal to another is nothing but enhancing a constant amount fractal
dimension which might be equivalent to a kind of different sets of musical
notes in various orientations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2526</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2526</id><created>2009-09-14</created><updated>2011-02-28</updated><authors><author><keyname>&#xd6;sterg&#xe5;rd</keyname><forenames>Patric R. J.</forenames></author><author><keyname>Pottonen</keyname><forenames>Olli</forenames></author></authors><title>Two Optimal One-Error-Correcting Codes of Length 13 That Are Not Doubly
  Shortened Perfect Codes</title><categories>cs.IT math.IT</categories><comments>v2: a correction concerning shortened codes of length 12</comments><doi>10.1007/s10623-010-9450-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The doubly shortened perfect codes of length 13 are classified utilizing the
classification of perfect codes in [P.R.J. \&quot;Osterg{\aa}rd and O. Pottonen, The
perfect binary one-error-correcting codes of length 15: Part I -
Classification, IEEE Trans. Inform. Theory, to appear]; there are 117821 such
(13,512,3) codes. By applying a switching operation to those codes, two more
(13,512,3) codes are obtained, which are then not doubly shortened perfect
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2542</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2542</id><created>2009-09-14</created><authors><author><keyname>Yatsenko</keyname><forenames>Vadim</forenames><affiliation>State Design Office Yuzhnoye, Ukraine</affiliation></author></authors><title>Stochastic Optimization of Linear Dynamic Systems with Parametric
  Uncertainties</title><categories>cs.AI cs.IT math.IT</categories><comments>Submitted to Journal of Automation and Information Science</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper describes a new approach to solving some stochastic optimization
problems for linear dynamic system with various parametric uncertainties.
Proposed approach is based on application of tensor formalism for creation the
mathematical model of parametric uncertainties. Within proposed approach
following problems are considered: prediction, data processing and optimal
control. Outcomes of carried out simulation are used as illustration of
properties and effectiveness of proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2547</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2547</id><created>2009-09-14</created><authors><author><keyname>Kolosovskiy</keyname><forenames>Maxim</forenames><affiliation>Altai State Technical University, Russia</affiliation></author></authors><title>Simple implementation of deletion from open-address hash table</title><categories>cs.DS</categories><comments>6 pages</comments><acm-class>E.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deletion from open-address hash table is not so easy as deletion from chained
hash table, because in open-address table we can't simply mark a slot
containing deleted key as empty. Search for keys may become incorrect. The
classical method to implement deletion is to mark slots in hash table by three
values: &quot;free&quot;, &quot;busy&quot;, &quot;deleted&quot;. That method is easy to implement, but there
are some disadvantages. In this article we consider alternative method of
deletion keys, where we avoid using the mark &quot;deleted&quot;. The article contains
the implementation of the method in Java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2622</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2622</id><created>2009-09-14</created><authors><author><keyname>Li</keyname><forenames>Jiangyuan</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author></authors><title>Transmitter Optimization for Achieving Secrecy Capacity in Gaussian MIMO
  Wiretap Channels</title><categories>cs.IT math.IT</categories><comments>29 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Gaussian multiple-input multiple-output (MIMO) wiretap channel
model, where there exists a transmitter, a legitimate receiver and an
eavesdropper, each node equipped with multiple antennas. We study the problem
of finding the optimal input covariance matrix that achieves secrecy capacity
subject to a power constraint, which leads to a non-convex optimization problem
that is in general difficult to solve. Existing results for this problem
address the case in which the transmitter and the legitimate receiver have two
antennas each and the eavesdropper has one antenna. For the general cases, it
has been shown that the optimal input covariance matrix has low rank when the
difference between the Grams of the eavesdropper and the legitimate receiver
channel matrices is indefinite or semi-definite, while it may have low rank or
full rank when the difference is positive definite. In this paper, the
aforementioned non-convex optimization problem is investigated. In particular,
for the multiple-input single-output (MISO) wiretap channel, the optimal input
covariance matrix is obtained in closed form. For general cases, we derive the
necessary conditions for the optimal input covariance matrix consisting of a
set of equations. For the case in which the transmitter has two antennas, the
derived necessary conditions can result in a closed form solution; For the case
in which the difference between the Grams is indefinite and has all negative
eigenvalues except one positive eigenvalue, the optimal input covariance matrix
has rank one and can be obtained in closed form; For other cases, the solution
is proved to be a fixed point of a mapping from a convex set to itself and an
iterative procedure is provided to search for it. Numerical results are
presented to illustrate the proposed theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2623</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2623</id><created>2009-09-14</created><authors><author><keyname>Akbarinia</keyname><forenames>Reza</forenames><affiliation>INRIA - Lina</affiliation></author><author><keyname>Pacitti</keyname><forenames>Esther</forenames><affiliation>INRIA - Lina</affiliation></author><author><keyname>Valduriez</keyname><forenames>Patrick</forenames><affiliation>INRIA - Lina</affiliation></author></authors><title>Reducing Network Traffic in Unstructured P2P Systems Using Top-k Queries</title><categories>cs.DB</categories><proxy>ccsd hal-00416447</proxy><journal-ref>Distributed and Parallel Databases 19, 2-3 (2006) 67-86</journal-ref><doi>10.1007/s10619-006-8313-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major problem of unstructured P2P systems is their heavy network traffic.
This is caused mainly by high numbers of query answers, many of which are
irrelevant for users. One solution to this problem is to use Top-k queries
whereby the user can specify a limited number (k) of the most relevant answers.
In this paper, we present FD, a (Fully Distributed) framework for executing
Top-k queries in unstructured P2P systems, with the objective of reducing
network traffic. FD consists of a family of algorithms that are simple but
effec-tive. FD is completely distributed, does not depend on the existence of
certain peers, and addresses the volatility of peers during query execution. We
vali-dated FD through implementation over a 64-node cluster and simulation
using the BRITE topology generator and SimJava. Our performance evaluation
shows that FD can achieve major performance gains in terms of communication and
response time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2626</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2626</id><created>2009-09-14</created><authors><author><keyname>Salmon-Alt</keyname><forenames>Susanne</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Reference Resolution within the Framework of Cognitive Grammar</title><categories>cs.CL</categories><comments>Colloque avec actes et comit\'e de lecture. internationale</comments><proxy>ccsd inria-00100430</proxy><report-no>A01-R-057 || salmon-alt01a</report-no><journal-ref>International Colloqium on Cognitive Science, San Sebastian :
  Spain (2001)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following the principles of Cognitive Grammar, we concentrate on a model for
reference resolution that attempts to overcome the difficulties previous
approaches, based on the fundamental assumption that all reference (independent
on the type of the referring expression) is accomplished via access to and
restructuring of domains of reference rather than by direct linkage to the
entities themselves. The model accounts for entities not explicitly mentioned
but understood in a discourse, and enables exploitation of discursive and
perceptual context to limit the set of potential referents for a given
referring expression. As the most important feature, we note that a single
mechanism is required to handle what are typically treated as diverse
phenomena. Our approach, then, provides a fresh perspective on the relations
between Cognitive Grammar and the problem of reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2694</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2694</id><created>2009-09-14</created><authors><author><keyname>Toli</keyname><forenames>Ilia</forenames></author></authors><title>Singularity of Sparse Circulant Matrices is NP-complete</title><categories>cs.CC cs.DM</categories><comments>References are somewhere in the middle, before the appendices. 8
  pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown by Karp reduction that deciding the singularity of $(2^n - 1)
\times (2^n - 1)$ sparse circulant matrices (SC problem) is NP-complete. We can
write them only implicitly, by indicating values of the $2 + n(n + 1)/2$
eventually nonzero entries of the first row and can make all matrix operations
with them. The positions are $0, 1, 2^{i} + 2^{j}$. The complexity parameter is
$n$. Mulmuley's work on the rank of matrices \cite{Mulmuley87} makes SC stand
alone in a list of 3,000 and growing NP-complete problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2704</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2704</id><created>2009-09-15</created><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Memory Consistency Conditions for Self-Assembly Programming</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perhaps the two most significant theoretical questions about the programming
of self-assembling agents are: (1) necessary and sufficient conditions to
produce a unique terminal assembly, and (2) error correction. We address both
questions, by reducing two well-studied models of tile assembly to models of
distributed shared memory (DSM), in order to obtain results from the memory
consistency systems induced by tile assembly systems when simulated in the DSM
setting. The Abstract Tile Assembly Model (aTAM) can be simulated by a DSM
system that obeys causal consistency, and the locally deterministic tile
assembly systems in the aTAM correspond exactly to the concurrent-write free
programs that simulate tile assembly in such a model. Thus, the detection of
the failure of local determinism (which had formerly been an open problem)
reduces to the detection of data races in simulating programs. Further, the
Kinetic Tile Assembly Model can be simulated by a DSM system that obeys GWO, a
memory consistency condition defined by Steinke and Nutt. (To our knowledge,
this is the first natural example of a DSM system that obeys GWO, but no
stronger consistency condition.) We combine these results with the observation
that self-assembly algorithms are local algorithms, and there exists a fast
conversion of deterministic local algorithms into deterministic
self-stabilizing algorithms. This provides an &quot;immediate&quot; generalization of a
theorem by Soloveichik et al. about the existence of tile assembly systems that
simultaneously perform two forms of self-stabilization: proofreading and
self-healing. Our reductions and proof techniques can be extended to the
programming of self-assembling agents in a variety of media, not just DNA
tiles, and not just two-dimensional surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2705</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2705</id><created>2009-09-14</created><updated>2010-02-03</updated><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>SET: an algorithm for consistent matrix completion</title><categories>cs.IT math.IT</categories><comments>4+ pages, submitted to ICASSP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm, termed subspace evolution and transfer (SET), is proposed
for solving the consistent matrix completion problem. In this setting, one is
given a subset of the entries of a low-rank matrix, and asked to find one
low-rank matrix consistent with the given observations. We show that this
problem can be solved by searching for a column space that matches the
observations. The corresponding algorithm consists of two parts -- subspace
evolution and subspace transfer. In the evolution part, we use a line search
procedure to refine the column space. However, line search is not guaranteed to
converge, as there may exist barriers along the search path that prevent the
algorithm from reaching a global optimum. To address this problem, in the
transfer part, we design mechanisms to detect barriers and transfer the
estimated column space from one side of the barrier to the another. The SET
algorithm exhibits excellent empirical performance for very low-rank matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2706</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2706</id><created>2009-09-14</created><authors><author><keyname>Zhu</keyname><forenames>Yingwu</forenames></author></authors><title>Measurement and Analysis of an Online Content Voting Network: A Case
  Study of Digg</title><categories>cs.NI</categories><comments>12 pages, first draft in April 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emergence of online content voting networks allows users to share and rate
content including social news, photos and videos. The basic idea behind online
content voting networks is that aggregate user activities (e.g., submitting and
rating content) makes high-quality content thrive through the unprecedented
scale, high dynamics and divergent quality of user generated content (UGC). To
better understand the nature and impact of online content voting networks, we
have analyzed Digg, a popular online social news aggregator and rating website.
Based on a large amount of data collected, we provide an in-depth study of
Digg. In particular, we study structural properties of Digg social network,
impact of social network properties on user digging activities and vice versa,
distribution of user diggs, content promotion, and information filtering. We
also provide insight into design of content promotion algorithms and
recommendation-assisted content discovery. Overall, we believe that the results
presented in this paper are crucial in understanding online content rating
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2715</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2715</id><created>2009-09-15</created><authors><author><keyname>Cristea</keyname><forenames>Dan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Ide</keyname><forenames>Nancy</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Marking-up multiple views of a Text: Discourse and Reference</title><categories>cs.CL</categories><proxy>ccsd hal-00416510</proxy><journal-ref>First International Language Resources and Evaluation Conference,
  Grenada, Espagne : France (1998)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an encoding scheme for discourse structure and reference, based
on the TEI Guidelines and the recommendations of the Corpus Encoding
Specification (CES). A central feature of the scheme is a CES-based data
architecture enabling the encoding of and access to multiple views of a
marked-up document. We describe a tool architecture that supports the encoding
scheme, and then show how we have used the encoding scheme and the tools to
perform a discourse analytic task in support of a model of global discourse
cohesion called Veins Theory (Cristea &amp; Ide, 1998).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2718</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2718</id><created>2009-09-15</created><authors><author><keyname>Ide</keyname><forenames>Nancy</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Erjavec</keyname><forenames>Tomaz</forenames></author></authors><title>A Common XML-based Framework for Syntactic Annotations</title><categories>cs.CL</categories><comments>Colloque avec actes et comit\'e de lecture. internationale</comments><proxy>ccsd inria-00100592</proxy><report-no>A01-R-289 || ide01d</report-no><journal-ref>1st NLP and XML Workshop, Tokyo, Japan : Japan (2001)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is widely recognized that the proliferation of annotation schemes runs
counter to the need to re-use language resources, and that standards for
linguistic annotation are becoming increasingly mandatory. To answer this need,
we have developed a framework comprised of an abstract model for a variety of
different annotation types (e.g., morpho-syntactic tagging, syntactic
annotation, co-reference annotation, etc.), which can be instantiated in
different ways depending on the annotator's approach and goals. In this paper
we provide an overview of the framework, demonstrate its applicability to
syntactic annotation, and show how it can contribute to comparative evaluation
of parser output and diverse syntactic annotation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2719</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2719</id><created>2009-09-15</created><authors><author><keyname>Ide</keyname><forenames>Nancy</forenames><affiliation>COMPUTER Science Department</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - Loria</affiliation></author></authors><title>Standards for Language Resources</title><categories>cs.CL</categories><comments>Colloque avec actes et comit\'e de lecture. internationale</comments><proxy>ccsd inria-00100771</proxy><report-no>A02-R-096 || ide02a</report-no><journal-ref>Third International Conference on Language Resources and
  Evaluation - LREC 2002, Las Palmas, Spain : France (2002)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an abstract data model for linguistic annotations and its
implementation using XML, RDF and related standards; and to outline the work of
a newly formed committee of the International Standards Organization (ISO),
ISO/TC 37/SC 4 Language Resource Management, which will use this work as its
starting point. The primary motive for presenting the latter is to solicit the
participation of members of the research community to contribute to the work of
the committee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2721</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2721</id><created>2009-09-15</created><authors><author><keyname>Gupta</keyname><forenames>Minit</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Dynamically Generated Interfaces in XML Based Architecture</title><categories>cs.OH</categories><comments>Colloque avec actes et comit\'e de lecture. internationale</comments><proxy>ccsd inria-00100591</proxy><report-no>A01-R-293 || gupta01a</report-no><journal-ref>User Interface Markup Language - UIMl'2001, Paris : France (2001)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing on-line services on the Internet will require the definition of
flexible interfaces that are capable of adapting to the user's characteristics.
This is all the more important in the context of medical applications like home
monitoring, where no two patients have the same medical profile. Still, the
problem is not limited to the capacity of defining generic interfaces, as has
been made possible by UIML, but also to define the underlying information
structures from which these may be generated. The DIATELIC project deals with
the tele-monitoring of patients under peritoneal dialysis. By means of XML
abstractions, termed as &quot;medical components&quot;, to represent the patient's
profile, the application configures the customizable properties of the
patient's interface and generates a UIML document dynamically. The interface
allows the patient to feed the data manually or use a device which allows
&quot;automatic data acquisition&quot;. The acquired medical data is transferred to an
expert system, which analyses the data and sends alerts to the medical staff.
In this paper we show how UIML can be seen as one component within a global XML
based architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2733</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2733</id><created>2009-09-15</created><authors><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author></authors><title>An Optimal Labeling Scheme for Ancestry Queries</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An ancestry labeling scheme assigns labels (bit strings) to the nodes of
rooted trees such that ancestry queries between any two nodes in a tree can be
answered merely by looking at their corresponding labels. The quality of an
ancestry labeling scheme is measured by its label size, that is the maximal
number of bits in a label of a tree node.
  In addition to its theoretical appeal, the design of efficient ancestry
labeling schemes is motivated by applications in web search engines. For this
purpose, even small improvements in the label size are important. In fact, the
literature about this topic is interested in the exact label size rather than
just its order of magnitude. As a result, following the proposal of a simple
interval-based ancestry scheme with label size $2\log_2 n$ bits (Kannan et al.,
STOC '88), a considerable amount of work was devoted to improve the bound on
the size of a label. The current state of the art upper bound is $\log_2 n +
O(\sqrt{\log n})$ bits (Abiteboul et al., SODA '02) which is still far from the
known $\log_2 n + \Omega(\log\log n)$ bits lower bound (Alstrup et al., SODA
'03).
  In this paper we close the gap between the known lower and upper bounds, by
constructing an ancestry labeling scheme with label size $\log_2 n + O(\log\log
n)$ bits. In addition to the optimal label size, our scheme assigns the labels
in linear time and can support any ancestry query in constant time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2737</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2737</id><created>2009-09-15</created><updated>2009-09-30</updated><authors><author><keyname>Xiang</keyname><forenames>Yin</forenames></author><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>Compressive sensing by white random convolution</title><categories>math.OC cs.IT math.IT</categories><comments>10 pages with 4 figures</comments><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A different compressive sensing framework, convolution with white noise
waveform followed by subsampling at fixed (not randomly selected) locations, is
studied in this paper. We show that its recoverability for sparse signals
depends on the coherence (denoted by mu) between the signal representation and
the Fourier basis. In particular, an n-dimensional signal which is S-sparse in
such a basis can be recovered with a probability exceeding 1-delta from any
fixed m~O(mu^2*S*log(n/delta)^(3/2)) output samples of the random convolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2767</identifier>
 <datestamp>2014-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2767</id><created>2009-09-15</created><updated>2012-10-10</updated><authors><author><keyname>Aslanyan</keyname><forenames>Davit</forenames></author><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Samvel S.</forenames></author><author><keyname>Vardanyan</keyname><forenames>Gagik N.</forenames></author></authors><title>On disjoint matchings in cubic graphs: maximum 2- and 3-edge-colorable
  subgraphs</title><categories>cs.DM</categories><comments>31 pages, 14 figures, majorly revised</comments><journal-ref>Discrete Applied Mathematics 172 (2014) pp. 12--27</journal-ref><doi>10.1016/j.dam.2014.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any $2-$factor of a cubic graph can be extended to a maximum
$3-$edge-colorable subgraph. We also show that the sum of sizes of maximum $2-$
and $3-$edge-colorable subgraphs of a cubic graph is at least twice of its
number of vertices. Finally, for a cubic graph $G$, consider the pairs of
edge-disjoint matchings whose union consists of as many edges as possible. Let
$H$ be the largest matching among such pairs. Let $M$ be a maximum matching of
$G$. We show that 9/8 is a tight upper bound for $|M|/|H|$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2777</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2777</id><created>2009-09-15</created><authors><author><keyname>Bagheri</keyname><forenames>Hossein</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On the Symmetric Gaussian Interference Channel with Partial
  Unidirectional Cooperation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-user symmetric Gaussian Interference Channel (IC) is considered in
which a noiseless unidirectional link connects one encoder to the other. Having
a constant capacity, the additional link provides partial cooperation between
the encoders. It is shown that the available cooperation can dramatically
increase the sum-capacity of the channel. This fact is proved based on
comparison of proposed lower and upper bounds on the sum-capacity. Partitioning
the data into three independent messages, namely private, common, and
cooperative ones, the transmission strategy used to obtain the lower bound
enjoys a simple type of Han-Kobayashi scheme together with a cooperative
communication scheme. A Genie-aided upper bound is developed which incorporates
the capacity of the cooperative link. Other upper bounds are based on the
sum-capacity of the Cognitive Radio Channel and cut-set bounds. For the strong
interference regime, the achievablity scheme is simplified to employ common
and/or cooperative messages but not the private one. Through a careful analysis
it is shown that the gap between these bounds is at most one and two bits per
real dimension for strong and weak interference regimes, respectively.
Moreover, the Generalized Degrees-of-Freedom of the channel is characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2787</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2787</id><created>2009-09-15</created><authors><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Crossing-Free Acyclic Hamiltonian Path Completion for Planar st-Digraphs</title><categories>cs.DS cs.DM</categories><comments>Accepted to ISAAC2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of existence of a crossing-free acyclic
hamiltonian path completion (for short, HP-completion) set for embedded upward
planar digraphs. In the context of book embeddings, this question becomes:
given an embedded upward planar digraph $G$, determine whether there exists an
upward 2-page book embedding of $G$ preserving the given planar embedding.
  Given an embedded $st$-digraph $G$ which has a crossing-free HP-completion
set, we show that there always exists a crossing-free HP-completion set with at
most two edges per face of $G$. For an embedded $N$-free upward planar digraph
$G$, we show that there always exists a crossing-free acyclic HP-completion set
for $G$ which, moreover, can be computed in linear time. For a width-$k$
embedded planar $st$-digraph $G$, we show that we can be efficiently test
whether $G$ admits a crossing-free acyclic HP-completion set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2793</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2793</id><created>2009-09-15</created><updated>2009-09-18</updated><authors><author><keyname>Ge</keyname><forenames>D.</forenames></author><author><keyname>Idier</keyname><forenames>J.</forenames></author><author><keyname>Carpentier</keyname><forenames>E. Le</forenames></author></authors><title>Enhanced sampling schemes for MCMC based blind Bernoulli-Gaussian
  deconvolution</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes and compares two new sampling schemes for sparse
deconvolution using a Bernoulli-Gaussian model. To tackle such a deconvolution
problem in a blind and unsupervised context, the Markov Chain Monte Carlo
(MCMC) framework is usually adopted, and the chosen sampling scheme is most
often the Gibbs sampler. However, such a sampling scheme fails to explore the
state space efficiently. Our first alternative, the $K$-tuple Gibbs sampler, is
simply a grouped Gibbs sampler. The second one, called partially marginalized
sampler, is obtained by integrating the Gaussian amplitudes out of the target
distribution. While the mathematical validity of the first scheme is obvious as
a particular instance of the Gibbs sampler, a more detailed analysis is
provided to prove the validity of the second scheme.
  For both methods, optimized implementations are proposed in terms of
computation and storage cost. Finally, simulation results validate both schemes
as more efficient in terms of convergence time compared with the plain Gibbs
sampler. Benchmark sequence simulations show that the partially marginalized
sampler takes fewer iterations to converge than the $K$-tuple Gibbs sampler.
However, its computation load per iteration grows almost quadratically with
respect to the data length, while it only grows linearly for the $K$-tuple
Gibbs sampler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2814</identifier>
 <datestamp>2011-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2814</id><created>2009-09-15</created><authors><author><keyname>van Bevern</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Graph-based data clustering: a quadratic-vertex problem kernel for
  s-Plex Cluster Vertex Deletion</title><categories>cs.DM cs.DS</categories><comments>41 pages, 17 figures</comments><acm-class>G.2.2; I.5.3</acm-class><doi>10.1007/s00453-011-9492-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the s-Plex Cluster Vertex Deletion problem. Like the Cluster
Vertex Deletion problem, it is NP-hard and motivated by graph-based data
clustering. While the task in Cluster Vertex Deletion is to delete vertices
from a graph so that its connected components become cliques, the task in
s-Plex Cluster Vertex Deletion is to delete vertices from a graph so that its
connected components become s-plexes. An s-plex is a graph in which every
vertex is nonadjacent to at most s-1 other vertices; a clique is an 1-plex. In
contrast to Cluster Vertex Deletion, s-Plex Cluster Vertex Deletion allows to
balance the number of vertex deletions against the sizes and the density of the
resulting clusters, which are s-plexes instead of cliques. The focus of this
work is the development of provably efficient and effective data reduction
rules for s-Plex Cluster Vertex Deletion. In terms of fixed-parameter
algorithmics, these yield a so-called problem kernel. A similar problem, s-Plex
Editing, where the task is the insertion or the deletion of edges so that the
connected components of a graph become s-plexes, has also been studied in terms
of fixed-parameter algorithmics. Using the number of allowed graph
modifications as parameter, we expect typical parameter values for s-Plex
Cluster Vertex Deletion to be significantly lower than for s-Plex Editing,
because one vertex deletion can lead to a high number of edge deletions. This
holds out the prospect for faster fixed-parameter algorithms for s-Plex Cluster
Vertex Deletion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2816</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2816</id><created>2009-09-15</created><authors><author><keyname>Sakir</keyname><forenames>Emine Zerrin</forenames></author><author><keyname>Feldbauer</keyname><forenames>Christian</forenames></author></authors><title>Efficient Quality-Based Playout Buffer Algorithm</title><categories>cs.MM</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Playout buffers are used in VoIP systems to compensate for network delay
jitter by making a trade-off between delay and loss. In this work we propose a
playout buffer algorithm that makes the trade-off based on maximization of
conversational speech quality, aiming to keep the computational complexity
lowest possible. We model the network delay using a Pareto distribution and
show that it is a good compromise between providing an appropriate fit to the
network delay characteristics and yielding a low arithmetical complexity. We
use the ITU-T E-Model as the quality model and simplify its delay impairment
function. The proposed playout buffer algorithm finds the optimum playout delay
using a closed-form solution that minimizes the sum of the simplified delay
impairment factor and the loss-dependent equipment impairment factor of the
E-model. The simulation results show that our proposed algorithm outperforms
existing state-of-the-art algorithms with a reduced complexity for a
quality-based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2817</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2817</id><created>2009-09-15</created><authors><author><keyname>Huang</keyname><forenames>ShinnYih</forenames></author><author><keyname>Bidkhori</keyname><forenames>Hoda</forenames></author></authors><title>Strongly Cancellative and Recovering Sets On Lattices</title><categories>math.CO cs.IT math.IT</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use information theory to study recovering sets $\R_L$ and strongly
cancellative sets $\C_L$ on different lattices. These sets are special classes
of recovering pairs and cancellative sets previously discussed in [1], [3] and
[5]. We mainly focus on the lattices $B_n$ and $D_{l}^{k}$. Specifically, we
find upper bounds and constructions for the sets $\R_{B_n}$, $\C_{B_n}$, and
$\C_{D_{l}^{k}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2839</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2839</id><created>2009-09-15</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Ponse</keyname><forenames>Alban</forenames></author></authors><title>A progression ring for interfaces of instruction sequences, threads, and
  services</title><categories>cs.PL</categories><comments>12 pages</comments><acm-class>D.2.2; D.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define focus-method interfaces and some connections between such
interfaces and instruction sequences, giving rise to instruction sequence
components. We provide a flexible and practical notation for interfaces using
an abstract datatype specification comparable to that of basic process algebra
with deadlock. The structures thus defined are called progression rings. We
also define thread and service components. Two types of composition of
instruction sequences or threads and services (called `use' and `apply') are
lifted to the level of components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2849</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2849</id><created>2009-09-15</created><updated>2011-01-14</updated><authors><author><keyname>Gharan</keyname><forenames>Shayan Oveis</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author></authors><title>The Asymmetric Traveling Salesman Problem on Graphs with Bounded Genus</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a constant factor approximation algorithm for the asymmetric
traveling salesman problem when the support graph of the solution of the
Held-Karp linear programming relaxation has bounded orientable genus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2852</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2852</id><created>2009-09-15</created><authors><author><keyname>Jain</keyname><forenames>Ashwin</forenames></author><author><keyname>Hari</keyname><forenames>C</forenames></author></authors><title>A new efficient k-out-of-n Oblivious Transfer protocol</title><categories>cs.CR</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new efficient protocol for k-out-of-n oblivious
transfer which is a generalization of Parakh's 1-out-of-2 oblivious transfer
protocol based on Diffie-Hellman key exchange. In the proposed protocol, the
parties involved generate Diffie-Hellman keys obliviously and then use them for
oblivious transfer of secrets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2859</identifier>
 <datestamp>2009-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2859</id><created>2009-09-15</created><authors><author><keyname>Kelner</keyname><forenames>Jonathan</forenames></author><author><keyname>Maymounkov</keyname><forenames>Petar</forenames></author></authors><title>Electric routing and concurrent flow cutting</title><categories>cs.DM cs.DC</categories><comments>21 pages, 0 figures. To be published in Springer LNCS Book No. 5878,
  Proceedings of The 20th International Symposium on Algorithms and Computation
  (ISAAC'09)</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate an oblivious routing scheme, amenable to distributed
computation and resilient to graph changes, based on electrical flow. Our main
technical contribution is a new rounding method which we use to obtain a bound
on the L1-&gt;L1 operator norm of the inverse graph Laplacian. We show how this
norm reflects both latency and congestion of electric routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2891</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2891</id><created>2009-09-15</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Trott</keyname><forenames>Lowell</forenames></author></authors><title>Going Off-road: Transversal Complexity in Road Networks</title><categories>cs.CG</categories><comments>Fuller version of paper appearing in ACM GIS '09</comments><acm-class>F.2.2; G.2.2; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A geometric graph is a graph embedded in the plane with vertices at points
and edges drawn as curves (which are usually straight line segments) between
those points. The average transversal complexity of a geometric graph is the
number of edges of that graph that are crossed by random line or line segment.
In this paper, we study the average transversal complexity of road networks. By
viewing road networks as multiscale-dispersed graphs, we show that a random
line will cross the edges of such a graph O(sqrt(n)) times on average. In
addition, we provide by empirical evidence from experiments on the road
networks of the fifty states of United States and the District of Columbia that
this bound holds in practice and has a small constant factor. Combining this
result with data structuring techniques from computational geometry, allows us
to show that we can then do point location and ray-shooting navigational
queries with respect to road networks in O(sqrt(n) log n) expected time.
Finally, we provide empirical justification for this claim as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2894</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2894</id><created>2009-09-15</created><updated>2009-09-22</updated><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Adaptive Spatial Intercell Interference Cancellation in Multicell
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>26 pages, submitted to IEEE J. Select. Areas Commun. special issue on
  Cooperative Communications in MIMO Cellular Networks, Sept. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Downlink spatial intercell interference cancellation (ICIC) is considered for
mitigating other-cell interference using multiple transmit antennas. A
principle question we explore is whether it is better to do ICIC or simply
standard single-cell beamforming. We explore this question analytically and
show that beamforming is preferred for all users when the edge SNR
(signal-to-noise ratio) is low ($&lt;0$ dB), and ICIC is preferred when the edge
SNR is high ($&gt;10$ dB), for example in an urban setting. At medium SNR, a
proposed adaptive strategy, where multiple base stations jointly select
transmission strategies based on the user location, outperforms both while
requiring a lower feedback rate than the pure ICIC approach. The employed
metric is sum rate, which is normally a dubious metric for cellular systems,
but surprisingly we show that even with this reward function the adaptive
strategy also improves fairness. When the channel information is provided by
limited feedback, the impact of the induced quantization error is also
investigated. It is shown that ICIC with well-designed feedback strategies
still provides significant throughput gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2927</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2927</id><created>2009-09-16</created><authors><author><keyname>Feldman</keyname><forenames>Vitaly</forenames></author></authors><title>Distribution-Specific Agnostic Boosting</title><categories>cs.LG cs.CC</categories><journal-ref>Proceedings of Innovations in Computer Science (ICS), 2010, pp
  241-250</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of boosting the accuracy of weak learning algorithms
in the agnostic learning framework of Haussler (1992) and Kearns et al. (1992).
Known algorithms for this problem (Ben-David et al., 2001; Gavinsky, 2002;
Kalai et al., 2008) follow the same strategy as boosting algorithms in the PAC
model: the weak learner is executed on the same target function but over
different distributions on the domain. We demonstrate boosting algorithms for
the agnostic learning framework that only modify the distribution on the labels
of the points (or, equivalently, modify the target function). This allows
boosting a distribution-specific weak agnostic learner to a strong agnostic
learner with respect to the same distribution.
  When applied to the weak agnostic parity learning algorithm of Goldreich and
Levin (1989) our algorithm yields a simple PAC learning algorithm for DNF and
an agnostic learning algorithm for decision trees over the uniform distribution
using membership queries. These results substantially simplify Jackson's famous
DNF learning algorithm (1994) and the recent result of Gopalan et al. (2008).
  We also strengthen the connection to hard-core set constructions discovered
by Klivans and Servedio (1999) by demonstrating that hard-core set
constructions that achieve the optimal hard-core set size (given by Holenstein
(2005) and Barak et al. (2009)) imply distribution-specific agnostic boosting
algorithms. Conversely, our boosting algorithm gives a simple hard-core set
construction with an (almost) optimal hard-core set size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.2934</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.2934</id><created>2009-09-16</created><authors><author><keyname>Di Castro</keyname><forenames>D.</forenames></author><author><keyname>Meir</keyname><forenames>R.</forenames></author></authors><title>A Convergent Online Single Time Scale Actor Critic Algorithm</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Actor-Critic based approaches were among the first to address reinforcement
learning in a general setting. Recently, these algorithms have gained renewed
interest due to their generality, good convergence properties, and possible
biological relevance. In this paper, we introduce an online temporal difference
based actor-critic algorithm which is proved to converge to a neighborhood of a
local maximum of the average reward. Linear function approximation is used by
the critic in order estimate the value function, and the temporal difference
signal, which is passed from the critic to the actor. The main distinguishing
feature of the present convergence proof is that both the actor and the critic
operate on a similar time scale, while in most current convergence proofs they
are required to have very different time scales in order to converge. Moreover,
the same temporal difference signal is used to update the parameters of both
the actor and the critic. A limitation of the proposed approach, compared to
results available for two time scale convergence, is that convergence is
guaranteed only to a neighborhood of an optimal value, rather to an optimal
value itself. The single time scale and identical temporal difference signal
used by the actor and the critic, may provide a step towards constructing more
biologically realistic models of reinforcement learning in the brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3005</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3005</id><created>2009-09-16</created><authors><author><keyname>Rudolph</keyname><forenames>Terry</forenames></author></authors><title>A simple encoding of a quantum circuit amplitude as a matrix permanent</title><categories>quant-ph cs.CC</categories><comments>6 figures</comments><doi>10.1103/PhysRevA.80.054302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple construction is presented which allows computing the transition
amplitude of a quantum circuit to be encoded as computing the permanent of a
matrix which is of size proportional to the number of quantum gates in the
circuit. This opens up some interesting classical monte-carlo algorithms for
approximating quantum circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3027</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3027</id><created>2009-09-16</created><authors><author><keyname>Prochasson</keyname><forenames>Emmanuel Ep</forenames><affiliation>LINA</affiliation></author><author><keyname>Viard-Gaudin</keyname><forenames>Christian</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Morin</keyname><forenames>Emmanuel</forenames><affiliation>LINA</affiliation></author></authors><title>Language Models for Handwritten Short Message Services</title><categories>cs.CL</categories><proxy>ccsd hal-00417716</proxy><journal-ref>International Conference on Document Analysis and Recognition,
  Brazil (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handwriting is an alternative method for entering texts composing Short
Message Services. However, a whole new language features the texts which are
produced. They include for instance abbreviations and other consonantal writing
which sprung up for time saving and fashion. We have collected and processed a
significant number of such handwriting SMS, and used various strategies to
tackle this challenging area of handwriting recognition. We proposed to study
more specifically three different phenomena: consonant skeleton, rebus, and
phonetic writing. For each of them, we compare the rough results produced by a
standard recognition system with those obtained when using a specific language
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3028</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3028</id><created>2009-09-16</created><authors><author><keyname>Prochasson</keyname><forenames>Emmanuel</forenames><affiliation>LINA</affiliation></author><author><keyname>Morin</keyname><forenames>Emmanuel</forenames><affiliation>LINA</affiliation></author><author><keyname>Viard-Gaudin</keyname><forenames>Christian</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Vers la reconnaissance de mini-messages manuscrits</title><categories>cs.CL</categories><proxy>ccsd hal-00417719</proxy><journal-ref>Colloque International sur le Lexique et la Grammaire, Bonifacio :
  France (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handwriting is an alternative method for entering texts which composed Short
Message Services. However, a whole new language features the texts which are
produced. They include for instance abbreviations and other consonantal writing
which sprung up for time saving and fashion. We have collected and processed a
significant number of such handwritten SMS, and used various strategies to
tackle this challenging area of handwriting recognition. We proposed to study
more specifically three different phenomena: consonant skeleton, rebus, and
phonetic writing. For each of them, we compare the rough results produced by a
standard recognition system with those obtained when using a specific language
model to take care of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3055</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3055</id><created>2009-09-16</created><authors><author><keyname>Qaseem</keyname><forenames>Syed T.</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Compressive Sensing Based Opportunistic Protocol for Throughput
  Improvement in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications, August 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key feature in the design of any MAC protocol is the throughput it can
provide. In wireless networks, the channel of a user is not fixed but varies
randomly. Thus, in order to maximize the throughput of the MAC protocol at any
given time, only users with large channel gains should be allowed to transmit.
In this paper, compressive sensing based opportunistic protocol for throughput
improvement in wireless networks is proposed. The protocol is based on the
traditional protocol of R-ALOHA which allows users to compete for channel
access before reserving the channel to the best user. We use compressive
sensing to find the best user, and show that the proposed protocol requires
less time for reservation and so it outperforms other schemes proposed in
literature. This makes the protocol particularly suitable for enhancing R-ALOHA
in fast fading environments. We consider both analog and digital versions of
the protocol where the channel gains sent by the user are analog and digital,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3080</identifier>
 <datestamp>2009-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3080</id><created>2009-09-16</created><authors><author><keyname>Cointet</keyname><forenames>Jean-Philippe</forenames><affiliation>CREA, Inra - Sens</affiliation></author><author><keyname>Roth</keyname><forenames>Camille</forenames><affiliation>CREA, Cams</affiliation></author></authors><title>Socio-semantic dynamics in a blog network</title><categories>cs.CY physics.soc-ph</categories><proxy>ccsd hal-00416705</proxy><journal-ref>IEEE International Conference on Social Computing (SocialCom-09),
  Vancouver : Canada (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The blogosphere can be construed as a knowledge network made of bloggers who
are interacting through a social network to share, exchange or produce
information. We claim that the social and semantic dimensions are essentially
co-determined and propose to investigate the co-evolutionary dynamics of the
blogosphere by examining two intertwined issues: First, how does knowledge
distribution drive new interactions and thus influence the social network
topology? Second, which role structural network properties play in the
information circulation in the system? We adopt an empirical standpoint by
analyzing the semantic and social activity of a portion of the US political
blogosphere, monitored on a period of four months.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3091</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3091</id><created>2009-09-16</created><authors><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Kountouriotis</keyname><forenames>John</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Dandekar</keyname><forenames>Kapil R.</forenames></author></authors><title>ALOHA With Collision Resolution(ALOHA-CR): Theory and Software Defined
  Radio Implementation</title><categories>cs.NI</categories><doi>10.1109/TSP.2010.2048315</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cross-layer scheme, namely ALOHA With Collision Resolution (ALOHA-CR), is
proposed for high throughput wireless communications in a cellular scenario.
Transmissions occur in a time-slotted ALOHA-type fashion but with an important
difference: simultaneous transmissions of two users can be successful. If more
than two users transmit in the same slot the collision cannot be resolved and
retransmission is required. If only one user transmits, the transmitted packet
is recovered with some probability, depending on the state of the channel. If
two users transmit the collision is resolved and the packets are recovered by
first over-sampling the collision signal and then exploiting independent
information about the two users that is contained in the signal polyphase
components. The ALOHA-CR throughput is derived under the infinite backlog
assumption and also under the assumption of finite backlog. The contention
probability is determined under these two assumptions in order to maximize the
network throughput and maintain stability. Queuing delay analysis for network
users is also conducted. The performance of ALOHA-CR is demonstrated on the
Wireless Open Access Research Platform (WARP) test-bed containing five software
defined radio nodes. Analysis and test-bed results indicate that ALOHA-CR leads
to significant increase in throughput and reduction of service delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3122</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3122</id><created>2009-09-16</created><authors><author><keyname>Chakareski</keyname><forenames>Jacob</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author><author><keyname>Kerivin</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Leblet</keyname><forenames>Jimmy</forenames></author><author><keyname>Simon</keyname><forenames>Gwendal</forenames></author></authors><title>A note on the data-driven capacity of P2P networks</title><categories>cs.DS cs.NI</categories><comments>10 pages, technical report assisting a submission</comments><report-no>EPFL-LTS-2009-008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two capacity problems in P2P networks. In the first one, the
nodes have an infinite amount of data to send and the goal is to optimally
allocate their uplink bandwidths such that the demands of every peer in terms
of receiving data rate are met. We solve this problem through a mapping from a
node-weighted graph featuring two labels per node to a max flow problem on an
edge-weighted bipartite graph. In the second problem under consideration, the
resource allocation is driven by the availability of the data resource that the
peers are interested in sharing. That is a node cannot allocate its uplink
resources unless it has data to transmit first. The problem of uplink bandwidth
allocation is then equivalent to constructing a set of directed trees in the
overlay such that the number of nodes receiving the data is maximized while the
uplink capacities of the peers are not exceeded. We show that the problem is
NP-complete, and provide a linear programming decomposition decoupling it into
a master problem and multiple slave subproblems that can be resolved in
polynomial time. We also design a heuristic algorithm in order to compute a
suboptimal solution in a reasonable time. This algorithm requires only a local
knowledge from nodes, so it should support distributed implementations.
  We analyze both problems through a series of simulation experiments featuring
different network sizes and network densities. On large networks, we compare
our heuristic and its variants with a genetic algorithm and show that our
heuristic computes the better resource allocation. On smaller networks, we
contrast these performances to that of the exact algorithm and show that
resource allocation fulfilling a large part of the peer can be found, even for
hard configuration where no resources are in excess.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3123</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3123</id><created>2009-09-16</created><authors><author><keyname>Zhang</keyname><forenames>Teng</forenames></author><author><keyname>Szlam</keyname><forenames>Arthur</forenames></author><author><keyname>Lerman</keyname><forenames>Gilad</forenames></author></authors><title>Median K-flats for hybrid linear modeling with many outliers</title><categories>cs.CV cs.LG</categories><journal-ref>Proc. of 2nd IEEE International Workshop on Subspace Methods
  (Subspace 2009), pp. 234-241 (2009)</journal-ref><doi>10.1109/ICCVW.2009.5457695</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the Median K-Flats (MKF) algorithm, a simple online method for
hybrid linear modeling, i.e., for approximating data by a mixture of flats.
This algorithm simultaneously partitions the data into clusters while finding
their corresponding best approximating l1 d-flats, so that the cumulative l1
error is minimized. The current implementation restricts d-flats to be
d-dimensional linear subspaces. It requires a negligible amount of storage, and
its complexity, when modeling data consisting of N points in D-dimensional
Euclidean space with K d-dimensional linear subspaces, is of order O(n K d D+n
d^2 D), where n is the number of iterations required for convergence
(empirically on the order of 10^4). Since it is an online algorithm, data can
be supplied to it incrementally and it can incrementally produce the
corresponding output. The performance of the algorithm is carefully evaluated
using synthetic and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3127</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3127</id><created>2009-09-16</created><updated>2009-11-23</updated><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>On the largest empty axis-parallel box amidst $n$ points</title><categories>cs.CG</categories><comments>19 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first nontrivial upper and lower bounds on the maximum volume of
an empty axis-parallel box inside an axis-parallel unit hypercube in $\RR^d$
containing $n$ points. For a fixed $d$, we show that the maximum volume is of
the order $\Theta(\frac{1}{n})$. We then use the fact that the maximum volume
is $\Omega(\frac{1}{n})$ in our design of the first efficient
$(1-\eps)$-approximation algorithm for the following problem: Given an
axis-parallel $d$-dimensional box $R$ in $\RR^d$ containing $n$ points, compute
a maximum-volume empty axis-parallel $d$-dimensional box contained in $R$. The
running time of our algorithm is nearly linear in $n$, for small $d$, and
increases only by an $O(\log{n})$ factor when one goes up one dimension. No
previous efficient exact or approximation algorithms were known for this
problem for $d \geq 4$. As the problem has been recently shown to be NP-hard in
arbitrary high dimensions (i.e., when $d$ is part of the input), the existence
of efficient exact algorithms is unlikely.
  We also obtain tight estimates on the maximum volume of an empty
axis-parallel hypercube inside an axis-parallel unit hypercube in $\RR^d$
containing $n$ points. For a fixed $d$, this maximum volume is of the same
order order $\Theta(\frac{1}{n})$. A faster $(1-\eps)$-approximation algorithm,
with a milder dependence on $d$ in the running time, is obtained in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3131</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3131</id><created>2009-09-16</created><updated>2014-08-27</updated><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Honold</keyname><forenames>Thomas</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>Constructing Linear Encoders with Good Spectra</title><categories>cs.IT math.IT</categories><comments>v5.5.5, no. 201408271350, 40 pages, 3 figures, extended version of
  the paper to be published in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. Inf. Theory 60 (2014) 5950-5965</journal-ref><doi>10.1109/TIT.2014.2341560</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear encoders with good joint spectra are suitable candidates for optimal
lossless joint source-channel coding (JSCC), where the joint spectrum is a
variant of the input-output complete weight distribution and is considered good
if it is close to the average joint spectrum of all linear encoders (of the
same coding rate). In spite of their existence, little is known on how to
construct such encoders in practice. This paper is devoted to their
construction. In particular, two families of linear encoders are presented and
proved to have good joint spectra. The first family is derived from Gabidulin
codes, a class of maximum-rank-distance codes. The second family is constructed
using a serial concatenation of an encoder of a low-density parity-check code
(as outer encoder) with a low-density generator matrix encoder (as inner
encoder). In addition, criteria for good linear encoders are defined for three
coding applications: lossless source coding, channel coding, and lossless JSCC.
In the framework of the code-spectrum approach, these three scenarios
correspond to the problems of constructing linear encoders with good kernel
spectra, good image spectra, and good joint spectra, respectively. Good joint
spectra imply both good kernel spectra and good image spectra, and for every
linear encoder having a good kernel (resp., image) spectrum, it is proved that
there exists a linear encoder not only with the same kernel (resp., image) but
also with a good joint spectrum. Thus a good joint spectrum is the most
important feature of a linear encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3135</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3135</id><created>2009-09-16</created><authors><author><keyname>Wang</keyname><forenames>Jia</forenames></author><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Zhao</keyname><forenames>Lei</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author></authors><title>A Random Variable Substitution Lemma With Applications to Multiple
  Description Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a random variable substitution lemma and use it to investigate
the role of refinement layer in multiple description coding, which clarifies
the relationship among several existing achievable multiple description
rate-distortion regions. Specifically, it is shown that the El Gamal-Cover
(EGC) region is equivalent to the EGC* region (an antecedent version of the EGC
region) while the Venkataramani-Kramer-Goyal (VKG) region (when specialized to
the 2-description case) is equivalent to the Zhang-Berger (ZB) region.
Moreover, we prove that for multiple description coding with individual and
hierarchical distortion constraints, the number of layers in the VKG scheme can
be significantly reduced when only certain weighted sum rates are concerned.
The role of refinement layer in scalable coding (a special case of multiple
description coding) is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3137</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3137</id><created>2009-09-16</created><authors><author><keyname>Hudson</keyname><forenames>Beno&#xee;t</forenames></author></authors><title>Succinct Representation of Well-Spaced Point Clouds</title><categories>cs.CG cs.DS cs.GR</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set of n points in low dimensions takes Theta(n w) bits to store on a w-bit
machine. Surface reconstruction and mesh refinement impose a requirement on the
distribution of the points they process. I show how to use this assumption to
lossily compress a set of n input points into a representation that takes only
O(n) bits, independent of the word size. The loss can keep inter-point
distances to within 10% relative error while still achieving a factor of three
space savings. The representation allows standard quadtree operations, along
with computing the restricted Voronoi cell of a point, in time O(w^2 + log n),
which can be improved to time O(log n) if w is in Theta(log n). Thus one can
use this compressed representation to perform mesh refinement or surface
reconstruction in O(n) bits with only a logarithmic slowdown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3146</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3146</id><created>2009-09-17</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Fathi</keyname><forenames>Hanane</forenames></author></authors><title>An Authentication Code against Pollution Attacks in Network Coding</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Systems exploiting network coding to increase their throughput suffer greatly
from pollution attacks which consist of injecting malicious packets in the
network. The pollution attacks are amplified by the network coding process,
resulting in a greater damage than under traditional routing. In this paper, we
address this issue by designing an unconditionally secure authentication code
suitable for multicast network coding. The proposed scheme is robust against
pollution attacks from outsiders, as well as coalitions of malicious insiders.
Intermediate nodes can verify the integrity and origin of the packets received
without having to decode, and thus detect and discard the malicious messages
in-transit that fail the verification. This way, the pollution is canceled out
before reaching the destinations. We analyze the performance of the scheme in
terms of both multicast throughput and goodput, and show the goodput gains. We
also discuss applications to file distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3158</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3158</id><created>2009-09-17</created><authors><author><keyname>Karapanos</keyname><forenames>Evangelos</forenames></author><author><keyname>Martens</keyname><forenames>Jean-Bernard</forenames></author></authors><title>The quantitative side of the Repertory Grid Technique: some concerns</title><categories>cs.HC</categories><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User experience (UX) evaluation is gaining increased interest lately, both
from academia and industry. In this paper we argue that UX evaluation needs to
fulfill two important requirements: scalability, i.e. the ability to provide
useful feedback in different stages of the design, and diversity, i.e. the
ability to reflect the di-versity of opinions that may exist in different
users. We promote the use of the Repertory Grid Technique as a promising UX
evaluation technique and discuss some of our concerns regarding the
quantitative side of its use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3165</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3165</id><created>2009-09-17</created><authors><author><keyname>Shang</keyname><forenames>Yilun</forenames></author></authors><title>Finite-time Consensus for Nonlinear Multi-agent Systems with Fixed
  Topologies</title><categories>cs.IT cs.MA math.IT math.OC</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study finite-time state consensus problems for continuous
nonlinear multi-agent systems. Building on the theory of finite-time Lyapunov
stability, we propose sufficient criteria which guarantee the system to reach a
consensus in finite time, provided that the underlying directed network
contains a spanning tree. Novel finite-time consensus protocols are introduced
as examples for applying the criteria. Simulations are also presented to
illustrate our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3169</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3169</id><created>2009-09-17</created><authors><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author><author><keyname>Kar</keyname><forenames>Purushottam</forenames></author><author><keyname>Pal</keyname><forenames>Manjish</forenames></author></authors><title>On Low Distortion Embeddings of Statistical Distance Measures into Low
  Dimensional Spaces</title><categories>cs.CG cs.DB</categories><comments>18 pages, The short version of this paper was accepted for
  presentation at the 20th International Conference on Database and Expert
  Systems Applications, DEXA 2009</comments><acm-class>F.2.2; H.3.m</acm-class><journal-ref>Database and Expert Systems Applications (DEXA) 2009</journal-ref><doi>10.1007/978-3-642-03573-9_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical distance measures have found wide applicability in information
retrieval tasks that typically involve high dimensional datasets. In order to
reduce the storage space and ensure efficient performance of queries,
dimensionality reduction while preserving the inter-point similarity is highly
desirable. In this paper, we investigate various statistical distance measures
from the point of view of discovering low distortion embeddings into
low-dimensional spaces. More specifically, we consider the Mahalanobis distance
measure, the Bhattacharyya class of divergences and the Kullback-Leibler
divergence. We present a dimensionality reduction method based on the
Johnson-Lindenstrauss Lemma for the Mahalanobis measure that achieves
arbitrarily low distortion. By using the Johnson-Lindenstrauss Lemma again, we
further demonstrate that the Bhattacharyya distance admits dimensionality
reduction with arbitrarily low additive error. We also examine the question of
embeddability into metric spaces for these distance measures due to the
availability of efficient indexing schemes on metric spaces. We provide
explicit constructions of point sets under the Bhattacharyya and the
Kullback-Leibler divergences whose embeddings into any metric space incur
arbitrarily large distortions. We show that the lower bound presented for
Bhattacharyya distance is nearly tight by providing an embedding that
approaches the lower bound for relatively small dimensional datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3180</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3180</id><created>2009-09-17</created><authors><author><keyname>Misra</keyname><forenames>Neeldhara</forenames></author><author><keyname>Philip</keyname><forenames>Geevarghese</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Sikdar</keyname><forenames>Somnath</forenames></author></authors><title>FPT Algorithms for Connected Feedback Vertex Set</title><categories>cs.DS</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the recently introduced Connected Feedback Vertex Set (CFVS) problem
from the view-point of parameterized algorithms. CFVS is the connected variant
of the classical Feedback Vertex Set problem and is defined as follows: given a
graph G=(V,E) and an integer k, decide whether there exists a subset F of V, of
size at most k, such that G[V F] is a forest and G[F] is connected. We show
that Connected Feedback Vertex Set can be solved in time $O(2^{O(k)}n^{O(1)})$
on general graphs and in time $O(2^{O(\sqrt{k}\log k)}n^{O(1)})$ on graphs
excluding a fixed graph H as a minor. Our result on general undirected graphs
uses as subroutine, a parameterized algorithm for Group Steiner Tree, a well
studied variant of Steiner Tree. We find the algorithm for Group Steiner Tree
of independent interest and believe that it will be useful for obtaining
parameterized algorithms for other connectivity problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3185</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3185</id><created>2009-09-17</created><updated>2011-12-28</updated><authors><author><keyname>Pujol</keyname><forenames>J.</forenames></author><author><keyname>Rif&#xe0;</keyname><forenames>J.</forenames></author><author><keyname>Ronquillo</keyname><forenames>L.</forenames></author></authors><title>Construction of Additive Reed-Muller Codes</title><categories>cs.IT math.IT</categories><comments>7 pages, Part of the material in this paper was presented without
  proofs at the 18-th Symposium on Applied algebra, Algebraic algorithms, and
  Error Correcting Codes (AAECC 2009), Tarragona, Spain, June 8-12, 2009</comments><acm-class>H.1.1</acm-class><journal-ref>J. Pujol, J. Rifa and L. Ronquillo. Construction of Additive
  Reed-Muller Codes. Applied Algebra, Algebraic Algorithms and Error-Correcting
  Codes, LNCS 5527 (June 2009), pages 223-226</journal-ref><doi>10.1007/978-3-642-02181-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well known Plotkin construction is, in the current paper, generalized and
used to yield new families of Z2Z4-additive codes, whose length, dimension as
well as minimum distance are studied. These new constructions enable us to
obtain families of Z2Z4-additive codes such that, under the Gray map, the
corresponding binary codes have the same parameters and properties as the usual
binary linear Reed-Muller codes. Moreover, the first family is the usual binary
linear Reed-Muller family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3221</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3221</id><created>2009-09-17</created><updated>2011-09-13</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Newman</keyname><forenames>Ilan</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>The Stackelberg Minimum Spanning Tree Game on Planar and
  Bounded-Treewidth Graphs</title><categories>cs.GT cs.DS</categories><comments>v2: Referees' comments incorporated, section on bounded-treewidth
  graphs expanded</comments><journal-ref>Journal of Combinatorial Optimization, 25/1:19--46, 2013</journal-ref><doi>10.1007/s10878-011-9414-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Stackelberg Minimum Spanning Tree Game is a two-level combinatorial
pricing problem played on a graph representing a network. Its edges are colored
either red or blue, and the red edges have a given fixed cost, representing the
competitor's prices. The first player chooses an assignment of prices to the
blue edges, and the second player then buys the cheapest spanning tree, using
any combination of red and blue edges. The goal of the first player is to
maximize the total price of purchased blue edges.
  We study this problem in the cases of planar and bounded-treewidth graphs. We
show that the problem is NP-hard on planar graphs but can be solved in
polynomial time on graphs of bounded treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3226</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3226</id><created>2009-09-17</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Venturino</keyname><forenames>Luca</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>De Maio</keyname><forenames>Antonio</forenames></author></authors><title>Blind user detection in doubly-dispersive DS/CDMA channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication on IEEE Transactions on Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 58, No. 3, pp. 1446 -
  1451, March 2010</journal-ref><doi>10.1109/TSP.2009.2033001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the problem of detecting the presence of a new user
in a direct-sequence/code-division-multiple-access (DS/CDMA) system with a
doubly-dispersive fading channel, and we propose a novel blind detection
strategy which only requires knowledge of the spreading code of the user to be
detected, but no prior information as to the time-varying channel impulse
response and the structure of the multiaccess interference. The proposed
detector has a bounded constant false alarm rate (CFAR) under the design
assumptions, while providing satisfactory detection performance even in the
presence of strong cochannel interference and high user mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3248</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3248</id><created>2009-09-17</created><authors><author><keyname>Alcazar</keyname><forenames>Juan Gerardo</forenames></author><author><keyname>Diaz-Toca</keyname><forenames>Gema Maria</forenames></author></authors><title>Topology of 2D and 3D Rational Curves</title><categories>cs.SC cs.MS</categories><comments>26 pages, 19 figures</comments><acm-class>G.4</acm-class><doi>10.1016/j.cagd.2010.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present algorithms for computing the topology of planar and
space rational curves defined by a parametrization. The algorithms given here
work directly with the parametrization of the curve, and do not require to
compute or use the implicit equation of the curve (in the case of planar
curves) or of any projection (in the case of space curves). Moreover, these
algorithms have been implemented in Maple; the examples considered and the
timings obtained show good performance skills.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3257</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3257</id><created>2009-09-17</created><updated>2010-06-19</updated><authors><author><keyname>Faliszewski</keyname><forenames>P.</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>E.</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>L. A.</forenames></author><author><keyname>Rothe</keyname><forenames>J.</forenames></author></authors><title>The Shield that Never Was: Societies with Single-Peaked Preferences are
  More Open to Manipulation and Control</title><categories>cs.GT cs.CC cs.MA physics.soc-ph</categories><comments>38 pages, 2 figures</comments><report-no>URCS TR-2009-950</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much work has been devoted, during the past twenty years, to using complexity
to protect elections from manipulation and control. Many results have been
obtained showing NP-hardness shields, and recently there has been much focus on
whether such worst-case hardness protections can be bypassed by frequently
correct heuristics or by approximations. This paper takes a very different
approach: We argue that when electorates follow the canonical political science
model of societal preferences the complexity shield never existed in the first
place. In particular, we show that for electorates having single-peaked
preferences, many existing NP-hardness results on manipulation and control
evaporate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3273</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3273</id><created>2009-09-17</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Decomposition of the NVALUE constraint</title><categories>cs.AI</categories><comments>To appear in Proceedings of the Eighth International Workshop on
  Constraint Modelling and Reformulation, held alongside the 15th International
  Conference on Principles and Practice of Constraint Programming (CP 2009),
  Lisbon, Portugal</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study decompositions of NVALUE, a global constraint that can be used to
model a wide range of problems where values need to be counted. Whilst
decomposition typically hinders propagation, we identify one decomposition that
maintains a global view as enforcing bound consistency on the decomposition
achieves bound consistency on the original global NVALUE constraint. Such
decompositions offer the prospect for advanced solving techniques like nogood
learning and impact based branching heuristics. They may also help SAT and IP
solvers take advantage of the propagation of global constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3276</identifier>
 <datestamp>2009-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3276</id><created>2009-09-17</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Symmetries of Symmetry Breaking Constraints</title><categories>cs.AI</categories><comments>To appear in the Proceedings of the Ninth International Workshop on
  Symmetry and Constraint Satisfaction Problems, held alongside the 15th
  International Conference on Principles and Practice of Constraint Programming
  (CP 2009), Lisbon, Portugal</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry is an important feature of many constraint programs. We show that
any symmetry acting on a set of symmetry breaking constraints can be used to
break symmetry. Different symmetries pick out different solutions in each
symmetry class. We use these observations in two methods for eliminating
symmetry from a problem. These methods are designed to have many of the
advantages of symmetry breaking methods that post static symmetry breaking
constraint without some of the disadvantages. In particular, the two methods
prune the search space using fast and efficient propagation of posted
constraints, whilst reducing the conflict between symmetry breaking and
branching heuristics. Experimental results show that the two methods perform
well on some standard benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3342</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3342</id><created>2009-09-17</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Wang</keyname><forenames>YuPeng</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Multiple antenna technologies</title><categories>cs.OH</categories><comments>20 pages, 15 figures, Information and Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple antenna technologies have received high attention in the last few
decades for their capabilities to improve the overall system performance.
Multiple-input multiple-output systems include a variety of techniques capable
of not only increase the reliability of the communication but also impressively
boost the channel capacity. In addition, smart antenna systems can increase the
link quality and lead to appreciable interference reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3346</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3346</id><created>2009-09-17</created><updated>2010-11-12</updated><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Kapralov</keyname><forenames>Michael</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Perfect Matchings in O(n \log n) Time in Regular Bipartite Graphs</title><categories>cs.DS cs.DM</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the well-studied problem of finding a perfect
matching in a d-regular bipartite graph on 2n nodes with m=nd edges. The
best-known algorithm for general bipartite graphs (due to Hopcroft and Karp)
takes time O(m\sqrt{n}). In regular bipartite graphs, however, a matching is
known to be computable in O(m) time (due to Cole, Ost and Schirra). In a recent
line of work by Goel, Kapralov and Khanna the O(m) time algorithm was improved
first to \tilde O(min{m, n^{2.5}/d}) and then to \tilde O(min{m, n^2/d}). It
was also shown that the latter algorithm is optimal up to polylogarithmic
factors among all algorithms that use non-adaptive uniform sampling to reduce
the size of the graph as a first step.
  In this paper, we give a randomized algorithm that finds a perfect matching
in a d-regular graph and runs in O(n\log n) time (both in expectation and with
high probability). The algorithm performs an appropriately truncated random
walk on a modified graph to successively find augmenting paths. Our algorithm
may be viewed as using adaptive uniform sampling, and is thus able to bypass
the limitations of (non-adaptive) uniform sampling established in earlier work.
We also show that randomization is crucial for obtaining o(nd) time algorithms
by establishing an \Omega(nd) lower bound for any deterministic algorithm. Our
techniques also give an algorithm that successively finds a matching in the
support of a doubly stochastic matrix in expected time O(n\log^2 n) time, with
O(m) pre-processing time; this gives a simple O(m+mn\log^2 n) time algorithm
for finding the Birkhoff-von Neumann decomposition of a doubly stochastic
matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3356</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3356</id><created>2009-09-18</created><updated>2010-05-17</updated><authors><author><keyname>Chau</keyname><forenames>Chi-Kin</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Capacity of Large-scale CSMA Wireless Networks</title><categories>cs.NI cs.PF</categories><comments>Extended version of the paper presented at ACM MobiCom 09'. Improved
  Model for Aggregate Carrier-Sensing</comments><acm-class>C.2.1; G.3</acm-class><journal-ref>IEEE/ACM Transactions on Networking (ToN), Vol. 19, No. 3,
  pp893-906, Jun 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the literature, asymptotic studies of multi-hop wireless network capacity
often consider only centralized and deterministic TDMA (time-division
multi-access) coordination schemes. There have been fewer studies of the
asymptotic capacity of large-scale wireless networks based on CSMA
(carrier-sensing multi-access), which schedules transmissions in a distributed
and random manner. With the rapid and widespread adoption of CSMA technology, a
critical question is that whether CSMA networks can be as scalable as TDMA
networks. To answer this question and explore the capacity of CSMA networks, we
first formulate the models of CSMA protocols to take into account the unique
CSMA characteristics not captured by existing interference models in the
literature. These CSMA models determine the feasible states, and consequently
the capacity of CSMA networks. We then study the throughput efficiency of CSMA
scheduling as compared to TDMA. Finally, we tune the CSMA parameters so as to
maximize the throughput to the optimal order. As a result, we show that CSMA
can achieve throughput as $\Omega(\frac{1}{\sqrt{n}})$, the same order as
optimal centralized TDMA, on uniform random networks. Our CSMA scheme makes use
of an efficient backbone-peripheral routing scheme and a careful design of dual
carrier-sensing and dual channel scheme. We also address the implementation
issues of our CSMA scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3382</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3382</id><created>2009-09-18</created><authors><author><keyname>Hatabu</keyname><forenames>Atsushi</forenames></author><author><keyname>Takeda</keyname><forenames>Koujin</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Statistical mechanical analysis of the Kronecker channel model for MIMO
  wireless communication</title><categories>cs.IT cond-mat.dis-nn cond-mat.stat-mech math.IT</categories><journal-ref>Phys. Rev. E 80, 061124 (2009)</journal-ref><doi>10.1103/PhysRevE.80.061124</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kronecker channel model of wireless communication is analyzed using
statistical mechanics methods. In the model, spatial proximities among
transmission/reception antennas are taken into account as certain correlation
matrices, which generally yield non-trivial dependence among symbols to be
estimated. This prevents accurate assessment of the communication performance
by naively using a previously developed analytical scheme based on a matrix
integration formula. In order to resolve this difficulty, we develop a
formalism that can formally handle the correlations in Kronecker models based
on the known scheme. Unfortunately, direct application of the developed scheme
is, in general, practically difficult. However, the formalism is still useful,
indicating that the effect of the correlations generally increase after the
fourth order with respect to correlation strength. Therefore, the known
analytical scheme offers a good approximation in performance evaluation when
the correlation strength is sufficiently small. For a class of specific
correlation, we show that the performance analysis can be mapped to the problem
of one-dimensional spin systems in random fields, which can be investigated
without approximation by the belief propagation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3384</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3384</id><created>2009-09-18</created><authors><author><keyname>Esparcia-Alc&#xe1;zar</keyname><forenames>Anna I</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Mart&#xed;nez-Garc&#xed;a</keyname><forenames>Ana&#xed;s</forenames></author><author><keyname>Garc&#xed;a-S&#xe1;nchez</keyname><forenames>Pablo</forenames></author><author><keyname>Alfaro-Cid</keyname><forenames>Eva</forenames></author><author><keyname>Sharman</keyname><forenames>Ken</forenames></author></authors><title>Comparing Single and Multiobjective Evolutionary Approaches to the
  Inventory and Transportation Problem</title><categories>cs.NE</categories><comments>34 pages. Submitted to Evolutionary Computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EVITA, standing for Evolutionary Inventory and Transportation Algorithm, is a
two-level methodology designed to address the Inventory and Transportation
Problem (ITP) in retail chains. The top level uses an evolutionary algorithm to
obtain delivery patterns for each shop on a weekly basis so as to minimise the
inventory costs, while the bottom level solves the Vehicle Routing Problem
(VRP) for every day in order to obtain the minimum transport costs associated
to a particular set of patterns. The aim of this paper is to investigate
whether a multiobjective approach to this problem can yield any advantage over
the previously used single objective approach. The analysis performed allows us
to conclude that this is not the case and that the single objective approach is
in gene- ral preferable for the ITP in the case studied. A further conclusion
is that it is useful to employ a classical algorithm such as Clarke &amp; Wright's
as the seed for other metaheuristics like local search or tabu search in order
to provide good results for the Vehicle Routing Problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3388</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3388</id><created>2009-09-18</created><authors><author><keyname>Nuida</keyname><forenames>Koji</forenames></author></authors><title>Pattern occurrence in the dyadic expansion of square root of two and an
  analysis of pseudorandom number generators</title><categories>math.CO cs.IT math.IT</categories><comments>21 pages, extended abstract presented in FPSAC 2009</comments><msc-class>05A16, 68R15</msc-class><journal-ref>A part of this paper was published in: Electronic Journal of
  Combinatorial Number Theory, vol.10 (2010) 111-127</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, designs of pseudorandom number generators (PRNGs) using
integer-valued variants of logistic maps and their applications to some
cryptographic schemes have been studied, due mostly to their ease of
implementation and performance. However, it has been noted that this ease is
reduced for some choices of the PRNGs accuracy parameters. In this article, we
show that the distribution of such undesirable accuracy parameters is closely
related to the occurrence of some patterns in the dyadic expansion of the
square root of 2. We prove that for an arbitrary infinite binary word, the
asymptotic occurrence rate of these patterns is bounded in terms of the
asymptotic occurrence rate of zeroes. We also present examples of infinite
binary words that tightly achieve the bounds. As a consequence, a classical
conjecture on asymptotic evenness of occurrence of zeroes and ones in the
dyadic expansion of the square root of 2 implies that the asymptotic rate of
the undesirable accuracy parameters for the PRNGs is at least 1/6.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3392</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3392</id><created>2009-09-18</created><updated>2010-02-10</updated><authors><author><keyname>Montanaro</keyname><forenames>Ashley</forenames></author><author><keyname>Osborne</keyname><forenames>Tobias</forenames></author></authors><title>On the communication complexity of XOR functions</title><categories>cs.CC quant-ph</categories><comments>18 pages; v2: minor corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An XOR function is a function of the form g(x,y) = f(x + y), for some boolean
function f on n bits. We study the quantum and classical communication
complexity of XOR functions. In the case of exact protocols, we completely
characterise one-way communication complexity for all f. We also show that,
when f is monotone, g's quantum and classical complexities are quadratically
related, and that when f is a linear threshold function, g's quantum complexity
is Theta(n). More generally, we make a structural conjecture about the Fourier
spectra of boolean functions which, if true, would imply that the quantum and
classical exact communication complexities of all XOR functions are
asymptotically equivalent. We give two randomised classical protocols for
general XOR functions which are efficient for certain functions, and a third
protocol for linear threshold functions with high margin. These protocols
operate in the symmetric message passing model with shared randomness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3395</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3395</id><created>2009-09-18</created><authors><author><keyname>Karmakar</keyname><forenames>Subhajit</forenames></author><author><keyname>Sarkar</keyname><forenames>Sandip</forenames></author></authors><title>A possible low-level explanation of &quot;temporal dynamics of brightness
  induction and White's illusion&quot;</title><categories>cs.CV physics.bio-ph q-bio.NC</categories><comments>11 pages and 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based upon physiological observation on time dependent orientation
selectivity in the cells of macaque's primary visual cortex together with the
psychophysical studies on the tuning of orientation detectors in human vision
we suggest that time dependence in brightness perception can be accommodated
through the time evolution of cortical contribution to the orientation tuning
of the ODoG filter responses. A set of Difference of Gaussians functions has
been used to mimic the time dependence of orientation tuning. The tuning of
orientation preference and its inversion at a later time have been considered
in explaining qualitatively the temporal dynamics of brightness perception
observed in &quot;Brief presentations reveal the temporal dynamics of brightness
induction and White's illusion&quot; for 58 and 82 ms of stimulus exposure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3414</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3414</id><created>2009-09-18</created><authors><author><keyname>Wang</keyname><forenames>Wenguang</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Wang</keyname><forenames>Weiping</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Zander</keyname><forenames>Justyna</forenames><affiliation>Fraunhofer Institute FOKUS, Kaiserin-Augusta-Allee 31, Berlin, Germany</affiliation></author><author><keyname>Zhu</keyname><forenames>Yifan</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author></authors><title>Three-dimensional conceptual model for service-oriented simulation</title><categories>cs.SE</categories><comments>7 pages, 1 figures, 3 table, Journal of Zhejiang University SCIENCE
  A, 2009, 10(8): 1075-1081</comments><journal-ref>Journal of Zhejiang University SCIENCE A, 2009, 10(8): 1075-1081</journal-ref><doi>10.1631/jzus.A0920258</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose a novel three-dimensional conceptual model for an
emerging service-oriented simulation paradigm. The model can be used as a
guideline or an analytic means to find the potential and possible future
directions of the current simulation frameworks. In particular, the model
inspects the crossover between the disciplines of modeling and simulation,
service-orientation, and software/systems engineering. Finally, two specific
simulation frameworks are studied as examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3423</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3423</id><created>2009-09-18</created><updated>2009-10-06</updated><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author></authors><title>Digital Ecosystems</title><categories>cs.MA cs.NE</categories><comments>206 Pages, 73 figures, PhD</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We view Digital Ecosystems to be the digital counterparts of biological
ecosystems, which are considered to be robust, self-organising and scalable
architectures that can automatically solve complex, dynamic problems. So, this
work is concerned with the creation, investigation, and optimisation of Digital
Ecosystems, exploiting the self-organising properties of biological ecosystems.
First, we created the Digital Ecosystem, a novel optimisation technique
inspired by biological ecosystems, where the optimisation works at two levels:
a first optimisation, migration of agents which are distributed in a
decentralised peer-to-peer network, operating continuously in time; this
process feeds a second optimisation based on evolutionary computing that
operates locally on single peers and is aimed at finding solutions to satisfy
locally relevant constraints. We then investigated its self-organising aspects,
starting with an extension to the definition of Physical Complexity to include
evolving agent populations. Next, we established stability of evolving agent
populations over time, by extending the Chli-DeWilde definition of agent
stability to include evolutionary dynamics. Further, we evaluated the diversity
of the software agents within evolving agent populations. To conclude, we
considered alternative augmentations to optimise and accelerate our Digital
Ecosystem, by studying the accelerating effect of a clustering catalyst on the
evolutionary dynamics. We also studied the optimising effect of targeted
migration on the ecological dynamics, through the indirect and emergent
optimisation of the agent migration patterns. Overall, we have advanced the
understanding of creating Digital Ecosystems, the self-organisation that occurs
within them, and the optimisation of their Ecosystem-Oriented Architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3444</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3444</id><created>2009-09-18</created><authors><author><keyname>Marchand</keyname><forenames>Jonathan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Guillaume</keyname><forenames>Bruno</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Perrier</keyname><forenames>Guy</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Analyse en d\'ependances \`a l'aide des grammaires d'interaction</title><categories>cs.CL</categories><proxy>ccsd inria-00418366</proxy><journal-ref>Traitement Automatique des Langues Naturelles, Senlis : France
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article proposes a method to extract dependency structures from
phrase-structure level parsing with Interaction Grammars. Interaction Grammars
are a formalism which expresses interactions among words using a polarity
system. Syntactical composition is led by the saturation of polarities.
Interactions take place between constituents, but as grammars are lexicalized,
these interactions can be translated at the level of words. Dependency
relations are extracted from the parsing process: every dependency is the
consequence of a polarity saturation. The dependency relations we obtain can be
seen as a refinement of the usual dependency tree. Generally speaking, this
work sheds new light on links between phrase structure and dependency parsing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3445</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3445</id><created>2009-09-18</created><authors><author><keyname>Falk</keyname><forenames>Ingrid</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Gardent</keyname><forenames>Claire</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Jacquey</keyname><forenames>Evelyne</forenames><affiliation>ATILF</affiliation></author><author><keyname>Venant</keyname><forenames>Fabienne</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Grouping Synonyms by Definitions</title><categories>cs.CL</categories><proxy>ccsd inria-00418458</proxy><journal-ref>Recent Advances in Natural Language Processing (RANLP), Borovets :
  Bulgaria (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for grouping the synonyms of a lemma according to its
dictionary senses. The senses are defined by a large machine readable
dictionary for French, the TLFi (Tr\'esor de la langue fran\c{c}aise
informatis\'e) and the synonyms are given by 5 synonym dictionaries (also for
French). To evaluate the proposed method, we manually constructed a gold
standard where for each (word, definition) pair and given the set of synonyms
defined for that word by the 5 synonym dictionaries, 4 lexicographers specified
the set of synonyms they judge adequate. While inter-annotator agreement ranges
on that task from 67% to at best 88% depending on the annotator pair and on the
synonym dictionary being considered, the automatic procedure we propose scores
a precision of 67% and a recall of 71%. The proposed method is compared with
related work namely, word sense disambiguation, synonym lexicon acquisition and
WordNet construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3466</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3466</id><created>2009-09-18</created><updated>2010-12-03</updated><authors><author><keyname>Dujardin</keyname><forenames>Yann</forenames></author></authors><title>R\'esolution du &quot;partition problem&quot; par une approche arithm\'etique</title><categories>cs.CC</categories><comments>This paper has been withdrawn by the author due to a crucial error
  (in one of the quadratic forms introduced)</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3472</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3472</id><created>2009-09-18</created><updated>2010-03-09</updated><authors><author><keyname>Kunegis</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Said</keyname><forenames>Alan</forenames></author><author><keyname>Umbrath</keyname><forenames>Winfried</forenames></author></authors><title>The Universal Recommender</title><categories>cs.IR</categories><comments>17 pages; typo and references fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the Universal Recommender, a recommender system for semantic
datasets that generalizes domain-specific recommenders such as content-based,
collaborative, social, bibliographic, lexicographic, hybrid and other
recommenders. In contrast to existing recommender systems, the Universal
Recommender applies to any dataset that allows a semantic representation. We
describe the scalable three-stage architecture of the Universal Recommender and
its application to Internet Protocol Television (IPTV). To achieve good
recommendation accuracy, several novel machine learning and optimization
problems are identified. We finally give a brief argument supporting the need
for machine learning recommenders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3475</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3475</id><created>2009-09-18</created><authors><author><keyname>Shang</keyname><forenames>Yilun</forenames></author></authors><title>Multi-agent Coordination in Directed Moving Neighborhood Random Networks</title><categories>cs.MA cs.IT math.IT</categories><comments>9 pages</comments><journal-ref>Chinese physics b, 2010</journal-ref><doi>10.1088/1674-1056/19/7/070201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the consensus problem of dynamical multiple agents
that communicate via a directed moving neighborhood random network. Each agent
performs random walk on a weighted directed network. Agents interact with each
other through random unidirectional information flow when they coincide in the
underlying network at a given instant. For such a framework, we present
sufficient conditions for almost sure asymptotic consensus. Some existed
consensus schemes are shown to be reduced versions of the current model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3481</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3481</id><created>2009-09-18</created><authors><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Mortier</keyname><forenames>Richard</forenames></author><author><keyname>Henderson</keyname><forenames>Tristan</forenames></author><author><keyname>Crowcroft</keyname><forenames>Jon</forenames></author></authors><title>Planet-scale Human Mobility Measurement</title><categories>cs.NI cs.CY cs.GL</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research into, and design and construction of mobile systems and algorithms
requires access to large-scale mobility data. Unfortunately, the wireless and
mobile research community lacks such data. For instance, the largest available
human contact traces contain only 100 nodes with very sparse connectivity,
limited by experimental logistics. In this paper we pose a challenge to the
community: how can we collect mobility data from billions of human
participants? We re-assert the importance of large-scale datasets in
communication network design, and claim that this could impact fundamental
studies in other academic disciplines. In effect, we argue that planet-scale
mobility measurements can help to save the world. For example, through
understanding large-scale human mobility, we can track and model and contain
the spread of epidemics of various kinds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3508</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3508</id><created>2009-09-18</created><updated>2009-09-28</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Hormati</keyname><forenames>Ali</forenames></author><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Compressed Sensing with Probabilistic Measurements: A Group Testing
  Solution</title><categories>cs.IT cs.DM math.IT</categories><comments>In Proceedings of the Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of defective members of large populations has been widely studied
in the statistics community under the name &quot;group testing&quot;, a problem which
dates back to World War II when it was suggested for syphilis screening. There
the main interest is to identify a small number of infected people among a
large population using collective samples. In viral epidemics, one way to
acquire collective samples is by sending agents inside the population. While in
classical group testing, it is assumed that the sampling procedure is fully
known to the reconstruction algorithm, in this work we assume that the decoder
possesses only partial knowledge about the sampling process. This assumption is
justified by observing the fact that in a viral sickness, there is a chance
that an agent remains healthy despite having contact with an infected person.
Therefore, the reconstruction method has to cope with two different types of
uncertainty; namely, identification of the infected population and the
partially unknown sampling procedure.
  In this work, by using a natural probabilistic model for &quot;viral infections&quot;,
we design non-adaptive sampling procedures that allow successful identification
of the infected population with overwhelming probability 1-o(1). We propose
both probabilistic and explicit design procedures that require a &quot;small&quot; number
of agents to single out the infected individuals. More precisely, for a
contamination probability p, the number of agents required by the probabilistic
and explicit designs for identification of up to k infected members is bounded
by m = O(k^2 (log n)/p^2) and m = O(k^2 (log n)^2 /p^2), respectively. In both
cases, a simple decoder is able to successfully identify the infected
population in time O(mn).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3530</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3530</id><created>2009-09-18</created><authors><author><keyname>Kale</keyname><forenames>Ajinkya</forenames></author><author><keyname>Gilda</keyname><forenames>Ashish</forenames></author><author><keyname>Pradhan</keyname><forenames>Sudeep</forenames></author></authors><title>Securing Remote Procedure Calls over HTTPS</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote Procedure Calls (RPC) are widely used over the Internet as they
provide a simple and elegant way of interaction between the client and the
server. This paper proposes a solution for securing the remote procedure calls
(RPC) by tunneling it through HTTPS (Hypertext Transfer Protocol over Secure
Socket Layer). RPC over HTTP actually uses the Secure Socket Layer (SSL)
protocol as a transport for the traffic. SSL mandates that the server
authenticates itself to the client using a digital certificate (and associated
private key). SSL is normally configured to encrypt traffic before transmitting
it between the server and client and vice versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3533</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3533</id><created>2009-09-18</created><authors><author><keyname>Oruc</keyname><forenames>A. Yavuz</forenames></author><author><keyname>Atmaca</keyname><forenames>Abdullah</forenames></author></authors><title>On Ordinal Covering of Proposals Using Balanced Incomplete Block Designs</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A frequently encountered problem in peer review systems is to facilitate
pairwise comparisons of a given set of proposals by as few as referees as
possible. In [8], it was shown that, if each referee is assigned to review k
proposals then ceil{n(n-1)/k(k-1)} referees are necessary and ceil{n(2n-k)/k^2}
referees are sufficient to cover all n(n-1)/2 pairs of n proposals. While the
upper bound remains within a factor of 2 of the lower bound, it becomes
relatively large for small values of k and the ratio of the upper bound to the
lower bound is not less than 3/2 when 2 &lt;= k &lt;= n/2. In this paper, we show
that, if sqrt(n) &lt;= k &lt;= n/2 then the upper and lower bounds can be made closer
in that their ratio never exceeds 3/2. This is accomplished by a new method
that assigns proposals to referees using a particular family of balanced
incomplete block designs. Specifically, the new method uses ceil{n(n+k)/k^2}
referees when n/k is a prime power, n divides k^2, and sqrt(n) &lt;= k &lt;= n/2.
Comparing this new upper bound to the one given in [8] shows that the new upper
bound approaches the lower bound as k tends to sqrt(n) whereas the upper bound
in [8] approaches the lower bound as k tends to n. Therefore, the new method
given here when combined together with the one in [8] provides an assignment
whose upper bound referee complexity always remains within a factor of 3/2 of
the lower bound when sqrt(n) &lt;= k &lt;= n, thereby improving upon the assignment
described in [8]. Furthermore, the new method provides a minimal covering,
i.e., it uses the minimum number of referees possible when k = sqrt(n) and k is
a prime power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3554</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3554</id><created>2009-09-18</created><authors><author><keyname>Verma</keyname><forenames>Harsh K</forenames></author><author><keyname>Singh</keyname><forenames>Abhishek Narain</forenames></author><author><keyname>Kumar</keyname><forenames>Raman</forenames></author></authors><title>Robustness of the Digital Image Watermarking Techniques against
  Brightness and Rotation Attack</title><categories>cs.MM cs.CR</categories><comments>5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Harsh K Verma, Abhishek Narain Singh, Raman Kumar, International
  Journal of Computer Science and Information Security, IJCSIS, Vol. 5, No. 1,
  September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent advent in the field of multimedia proposed a many facilities in
transport, transmission and manipulation of data. Along with this advancement
of facilities there are larger threats in authentication of data, its licensed
use and protection against illegal use of data. A lot of digital image
watermarking techniques have been designed and implemented to stop the illegal
use of the digital multimedia images. This paper compares the robustness of
three different watermarking schemes against brightness and rotation attacks.
The robustness of the watermarked images has been verified on the parameters of
PSNR (Peak Signal to Noise Ratio), RMSE (Root Mean Square Error) and MAE (Mean
Absolute Error).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3558</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3558</id><created>2009-09-19</created><authors><author><keyname>Khoury</keyname><forenames>Joud</forenames></author><author><keyname>Abdallah</keyname><forenames>Chaouki T.</forenames></author><author><keyname>Krause</keyname><forenames>Kate</forenames></author><author><keyname>Crichigno</keyname><forenames>Jorge</forenames></author></authors><title>Route Distribution Incentives</title><categories>cs.GT cs.NI</categories><comments>15 page, lncs format, 2 figures, workshop</comments><acm-class>C.2.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an incentive model for route distribution in the context of path
vector routing protocols and we focus on the Border Gateway Protocol (BGP). BGP
is the de-facto protocol for interdomain routing on the Internet. We model BGP
route distribution and computation using a game in which a BGP speaker
advertises its prefix to its direct neighbors promising them a reward for
further distributing the route deeper into the network, the neighbors do the
same thing with their neighbors, and so on. The result of this cascaded route
distribution is an advertised prefix and hence reachability of the BGP speaker.
We first study the convergence of BGP protocol dynamics to a unique outcome
tree in the defined game. We then proceed to study the existence of equilibria
in the full information game considering competition dynamics. We focus our
work on the simplest two classes of graphs: 1) the line (and the tree) graphs
which involve no competition, and 2) the ring graph which involves competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3561</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3561</id><created>2009-09-19</created><authors><author><keyname>Kabudvand</keyname><forenames>Farzane</forenames></author></authors><title>ODMRP with Quality of Service and local recovery with security Support</title><categories>cs.NI cs.CR</categories><comments>5 Pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Farzane Kabudvand, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 5, No. 1, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we focus on one critical issue in mobile ad hoc networks that
is multicast routing and propose a mesh based on demand multicast routing
protocol for Ad-Hoc networks with QoS (quality of service) support. Then a
model was presented which is used for create a local recovering mechanism in
order to joining the nodes to multi sectional groups at the minimized time and
method for security in this protocol we present .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3591</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3591</id><created>2009-09-19</created><authors><author><keyname>Gilkey</keyname><forenames>P.</forenames></author><author><keyname>Ornat</keyname><forenames>S. Lopez</forenames></author><author><keyname>Karousou</keyname><forenames>A.</forenames></author></authors><title>Mathematics, Recursion, and Universals in Human Languages</title><categories>cs.CL</categories><msc-class>91F20, 03B65, 68T50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many scientific problems generated by the multiple and conflicting
alternative definitions of linguistic recursion and human recursive processing
that exist in the literature. The purpose of this article is to make available
to the linguistic community the standard mathematical definition of recursion
and to apply it to discuss linguistic recursion. As a byproduct, we obtain an
insight into certain &quot;soft universals&quot; of human languages, which are related to
cognitive constructs necessary to implement mathematical reasoning, i.e.
mathematical model theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3593</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3593</id><created>2009-09-19</created><updated>2010-09-24</updated><authors><author><keyname>Zhang</keyname><forenames>Min-Ling</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>Exploiting Unlabeled Data to Enhance Ensemble Diversity</title><categories>cs.LG cs.AI</categories><comments>10 pages, to appear in ICDM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensemble learning aims to improve generalization ability by using multiple
base learners. It is well-known that to construct a good ensemble, the base
learners should be accurate as well as diverse. In this paper, unlabeled data
is exploited to facilitate ensemble learning by helping augment the diversity
among the base learners. Specifically, a semi-supervised ensemble method named
UDEED is proposed. Unlike existing semi-supervised ensemble methods where
error-prone pseudo-labels are estimated for unlabeled data to enlarge the
labeled data to improve accuracy, UDEED works by maximizing accuracies of base
learners on labeled data while maximizing diversity among them on unlabeled
data. Experiments show that UDEED can effectively utilize unlabeled data for
ensemble learning and is highly competitive to well-established semi-supervised
ensemble methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3596</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3596</id><created>2009-09-19</created><authors><author><keyname>Preston</keyname><forenames>Chris</forenames></author></authors><title>Specifying Data Objects with Initial Algebras</title><categories>cs.LO math.LO</categories><comments>120 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a systematic approach to specifying data objects with the
help of initial algebras. The primary aim is to describe the set-up to be found
in modern functional programming languages such as Haskell and ML, although it
can also be applied to more general situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3606</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3606</id><created>2009-09-19</created><authors><author><keyname>Jethava</keyname><forenames>Vinay</forenames></author></authors><title>Extension of Path Probability Method to Approximate Inference over Time</title><categories>cs.LG cs.CV</categories><comments>M.Sc.(Research) Thesis, 64 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  There has been a tremendous growth in publicly available digital video
footage over the past decade. This has necessitated the development of new
techniques in computer vision geared towards efficient analysis, storage and
retrieval of such data. Many mid-level computer vision tasks such as
segmentation, object detection, tracking, etc. involve an inference problem
based on the video data available. Video data has a high degree of spatial and
temporal coherence. The property must be intelligently leveraged in order to
obtain better results.
  Graphical models, such as Markov Random Fields, have emerged as a powerful
tool for such inference problems. They are naturally suited for expressing the
spatial dependencies present in video data, It is however, not clear, how to
extend the existing techniques for the problem of inference over time. This
thesis explores the Path Probability Method, a variational technique in
statistical mechanics, in the context of graphical models and approximate
inference problems. It extends the method to a general framework for problems
involving inference in time, resulting in an algorithm, \emph{DynBP}. We
explore the relation of the algorithm with existing techniques, and find the
algorithm competitive with existing approaches.
  The main contribution of this thesis are the extended GBP algorithm, the
extension of Path Probability Methods to the DynBP algorithm and the
relationship between them. We have also explored some applications in computer
vision involving temporal evolution with promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3609</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3609</id><created>2009-09-19</created><authors><author><keyname>Jethava</keyname><forenames>Vinay</forenames></author><author><keyname>Suresh</keyname><forenames>Krishnan</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Chiranjib</forenames></author><author><keyname>Hariharan</keyname><forenames>Ramesh</forenames></author></authors><title>Randomized Algorithms for Large scale SVMs</title><categories>cs.LG</categories><comments>17 pages, Submitted to Machine Learning journal (October 2008) -
  under revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a randomized algorithm for training Support vector machines(SVMs)
on large datasets. By using ideas from Random projections we show that the
combinatorial dimension of SVMs is $O({log} n)$ with high probability. This
estimate of combinatorial dimension is used to derive an iterative algorithm,
called RandSVM, which at each step calls an existing solver to train SVMs on a
randomly chosen subset of size $O({log} n)$. The algorithm has probabilistic
guarantees and is capable of training SVMs with Kernels for both classification
and regression problems. Experiments done on synthetic and real life data sets
demonstrate that the algorithm scales up existing SVM learners, without loss of
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3637</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3637</id><created>2009-09-20</created><updated>2010-01-31</updated><authors><author><keyname>Li</keyname><forenames>Fei</forenames></author></authors><title>Packet Scheduling in a Size-Bounded Buffer</title><categories>cs.DS</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider algorithms to schedule packets with values and deadlines in a
size-bounded buffer. At any time, the buffer can store at most B packets.
Packets arrive over time. Each packet has a non-negative value and an integer
deadline. In each time step, at most one packet can be sent. Packets can be
dropped at any time before they are sent. The objective is to maximize the
total value gained by delivering packets no later than their respective
deadlines. This model generalizes the well-studied bounded-delay model (Hajek.
CISS 2001. Kesselman et al. STOC 2001). We first provide an optimal offline
algorithm for this model. Then we present an alternative proof of the
2-competitive deterministic online algorithm (Fung. arXiv July 2009). We also
prove that the lower bound of competitive ratio of a family of (deterministic
and randomized) algorithms is 2 - 1 / B.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3647</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3647</id><created>2009-09-20</created><authors><author><keyname>Petz</keyname><forenames>Denes</forenames></author></authors><title>From f-divergence to quantum quasi-entropies and their use</title><categories>cs.IT math.IT math.ST quant-ph stat.TH</categories><comments>Written version of the lecture in the conference &quot;Information and
  Communication&quot; held in Budapest</comments><doi>10.3390/e12030304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Csiszar's f-divergence of two probability distributions was extended to the
quantum case by the author in 1985. In the quantum setting positive
semidefinite matrices are in the place of probability distributions and the
quantum generalization is called quasi-entropy which is related to some other
important concepts as covariance, quadratic costs, Fisher information,
Cramer-Rao inequality and uncertainty relation. A conjecture about the scalar
curvature of a Fisher information geometry is explained. The described subjects
are overviewed in details in the matrix setting, but at the very end the von
Neumann algebra approach is sketched shortly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3648</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3648</id><created>2009-09-20</created><updated>2010-10-13</updated><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Random scattering of bits by prediction</title><categories>cs.AI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a population of binary mistake sequences that result from
learning with parametric models of different order. We obtain estimates of
their error, algorithmic complexity and divergence from a purely random
Bernoulli sequence. We study the relationship of these variables to the
learner's information density parameter which is defined as the ratio between
the lengths of the compressed to uncompressed files that contain the learner's
decision rule. The results indicate that good learners have a low information
density$\rho$ while bad learners have a high $\rho$. Bad learners generate
mistake sequences that are atypically complex or diverge stochastically from a
purely random Bernoulli sequence. Good learners generate typically complex
sequences with low divergence from Bernoulli sequences and they include mistake
sequences generated by the Bayes optimal predictor. Based on the static
algorithmic interference model of \cite{Ratsaby_entropy} the learner here acts
as a static structure which &quot;scatters&quot; the bits of an input sequence (to be
predicted) in proportion to its information density $\rho$ thereby deforming
its randomness characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3658</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3658</id><created>2009-09-20</created><authors><author><keyname>Kiayias</keyname><forenames>Aggelos</forenames></author><author><keyname>Raekow</keyname><forenames>Yona</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author><author><keyname>Shashidhar</keyname><forenames>Narasimha</forenames></author></authors><title>Efficient Steganography with Provable Security Guarantees</title><categories>cs.CR cs.IT math.IT</categories><comments>12 pages</comments><acm-class>F.2.2; G.3; E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a new provably-secure steganographic encryption protocol that is
proven secure in the complexity-theoretic framework of Hopper et al. The
fundamental building block of our steganographic encryption protocol is a
&quot;one-time stegosystem&quot; that allows two parties to transmit messages of length
shorter than the shared key with information-theoretic security guarantees. The
employment of a pseudorandom generator (PRG) permits secure transmission of
longer messages in the same way that such a generator allows the use of
one-time pad encryption for messages longer than the key in symmetric
encryption. The advantage of our construction, compared to that of Hopper et
al., is that it avoids the use of a pseudorandom function family and instead
relies (directly) on a pseudorandom generator in a way that provides linear
improvement in the number of applications of the underlying one-way permutation
per transmitted bit. This advantageous trade-off is achieved by substituting
the pseudorandom function family employed in the previous construction with an
appropriate combinatorial construction that has been used extensively in
derandomization, namely almost t-wise independent function families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3688</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3688</id><created>2009-09-21</created><updated>2012-01-12</updated><authors><author><keyname>Mishari</keyname><forenames>Mishari Al</forenames></author><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Defrawy</keyname><forenames>Karim El</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>Harvesting SSL Certificate Data to Identify Web-Fraud</title><categories>cs.CR cs.NI</categories><comments>To appear in the International Journal of Network Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web-fraud is one of the most unpleasant features of today's Internet. Two
well-known examples of fraudulent activities on the web are phishing and
typosquatting. Their effects range from relatively benign (such as unwanted
ads) to downright sinister (especially, when typosquatting is combined with
phishing). This paper presents a novel technique to detect web-fraud domains
that utilize HTTPS. To this end, we conduct the first comprehensive study of
SSL certificates. We analyze certificates of legitimate and popular domains and
those used by fraudulent ones. Drawing from extensive measurements, we build a
classifier that detects such malicious domains with high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3696</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3696</id><created>2009-09-21</created><updated>2010-01-27</updated><authors><author><keyname>Chen</keyname><forenames>Victor</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>de Wolf</keyname><forenames>Ronald</forenames></author></authors><title>Efficient and Error-Correcting Data Structures for Membership and
  Polynomial Evaluation</title><categories>cs.DS</categories><comments>An abridged version of this paper appears in STACS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct efficient data structures that are resilient against a constant
fraction of adversarial noise. Our model requires that the decoder answers most
queries correctly with high probability and for the remaining queries, the
decoder with high probability either answers correctly or declares &quot;don't
know.&quot; Furthermore, if there is no noise on the data structure, it answers all
queries correctly with high probability. Our model is the common generalization
of a model proposed recently by de Wolf and the notion of &quot;relaxed locally
decodable codes&quot; developed in the PCP literature.
  We measure the efficiency of a data structure in terms of its length,
measured by the number of bits in its representation, and query-answering time,
measured by the number of bit-probes to the (possibly corrupted)
representation. In this work, we study two data structure problems: membership
and polynomial evaluation. We show that these two problems have constructions
that are simultaneously efficient and error-correcting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3717</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3717</id><created>2009-09-21</created><updated>2009-10-06</updated><authors><author><keyname>Agrawal</keyname><forenames>Pranav</forenames><affiliation>CEDT Indian Institute of Science Bangalore</affiliation></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames><affiliation>ECE Indian Institute of Science Bangalore</affiliation></author><author><keyname>Kuri</keyname><forenames>Joy</forenames><affiliation>CEDT Indian Institute of Science Bangalore</affiliation></author><author><keyname>Panda</keyname><forenames>Manoj</forenames><affiliation>ECE Indian Institute of Science Bangalore</affiliation></author><author><keyname>Navda</keyname><forenames>Vishnu</forenames><affiliation>Microsoft Research Bangalore India</affiliation></author><author><keyname>Ramjee</keyname><forenames>Ramachandran</forenames><affiliation>Microsoft Research Bangalore India</affiliation></author><author><keyname>Padmanabhan</keyname><forenames>Venkata N.</forenames><affiliation>Microsoft Research Bangalore India</affiliation></author></authors><title>Analytical Models for Energy Consumption in Infrastructure WLAN STAs
  Carrying TCP Traffic</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop analytical models for estimating the energy spent by stations
(STAs) in infrastructure WLANs when performing TCP controlled file downloads.
We focus on the energy spent in radio communication when the STAs are in the
Continuously Active Mode (CAM), or in the static Power Save Mode (PSM). Our
approach is to develop accurate models for obtaining the fraction of times the
STA radios spend in idling, receiving and transmitting. We discuss two traffic
models for each mode of operation: (i) each STA performs one large file
download, and (ii) the STAs perform short file transfers. We evaluate the rate
of STA energy expenditure with long file downloads, and show that static PSM is
worse than just using CAM. For short file downloads we compute the number of
file downloads that can be completed with given battery capacity, and show that
PSM performs better than CAM for this case. We provide a validation of our
analytical models using the NS-2 simulator. In contrast to earlier work on
analytical modeling of PSM, our models that capture the details of the
interactions between the 802.11 MAC in PSM and certain aspects of TCP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3786</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3786</id><created>2009-09-21</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Kinematic calibration of Orthoglide-type mechanisms from observation of
  parallel leg motions</title><categories>cs.RO</categories><proxy>ccsd hal-00418777</proxy><journal-ref>Mechatronics 19, 4 (2009) 478-488</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a new calibration method for parallel manipulators that
allows efficient identification of the joint offsets using observations of the
manipulator leg parallelism with respect to the base surface. The method
employs a simple and low-cost measuring system, which evaluates deviation of
the leg location during motions that are assumed to preserve the leg
parallelism for the nominal values of the manipulator parameters. Using the
measured deviations, the developed algorithm estimates the joint offsets that
are treated as the most essential parameters to be identified. The validity of
the proposed calibration method and efficiency of the developed numerical
algorithms are confirmed by experimental results. The sensitivity of the
measurement methods and the calibration accuracy are also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3787</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3787</id><created>2009-09-21</created><updated>2009-12-19</updated><authors><author><keyname>Berlinkov</keyname><forenames>M. V.</forenames></author></authors><title>Approximating the minimum length of synchronizing words is hard</title><categories>cs.FL cs.CC</categories><comments>12 pages, 1 figure</comments><acm-class>F.1.1; F.4.3</acm-class><doi>10.1007/978-3-642-13182-0_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that, unless $\mathrm{P}=\mathrm{NP}$, no polynomial algorithm can
approximate the minimum length of \sws for a given \san within a constant
factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3789</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3789</id><created>2009-09-21</created><updated>2010-10-14</updated><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>Maximal Pivots on Graphs with an Application to Gene Assembly</title><categories>math.CO cs.DM</categories><comments>modest revision (including different latex style) w.r.t. v2, 16
  pages, 5 figures</comments><msc-class>68R05, 68R10, 92D20</msc-class><journal-ref>Discrete Applied Mathematics, Volume 158, Issue 18, Pages
  1977-1985</journal-ref><doi>10.1016/j.dam.2010.08.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider principal pivot transform (pivot) on graphs. We define a natural
variant of this operation, called dual pivot, and show that both the kernel and
the set of maximally applicable pivots of a graph are invariant under this
operation. The result is motivated by and applicable to the theory of gene
assembly in ciliates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3790</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3790</id><created>2009-09-21</created><updated>2010-02-14</updated><authors><author><keyname>Berlinkov</keyname><forenames>M. V.</forenames></author></authors><title>On Carpi and Alessandro conjecture</title><categories>cs.FL</categories><comments>11 pages, 1 figure</comments><acm-class>F.4.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well known open \v{C}ern\'y conjecture states that each \san with $n$
states has a \sw of length at most $(n-1)^2$. On the other hand, the best known
upper bound is cubic of $n$. Recently, in the paper \cite{CARPI1} of Alessandro
and Carpi, the authors introduced the new notion of strongly transitivity for
automata and conjectured that this property with a help of \emph{Extension}
method allows to get a quadratic upper bound for the length of the shortest
\sws. They also confirmed this conjecture for circular automata. We disprove
this conjecture and the long-standing \emph{Extension} conjecture too. We also
consider the widely used Extension method and its perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3868</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3868</id><created>2009-09-21</created><updated>2010-09-13</updated><authors><author><keyname>Salemi</keyname><forenames>Luigi</forenames></author></authors><title>Method of resolution of 3SAT in polynomial time</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Presentation of a Method for determining whether a problem 3Sat has solution,
and if yes to find one, in time max O(n^15). Is thus proved that the problem
3Sat is fully resolved in polynomial time and therefore that it is in P, by the
work of Cook and Levin, and can transform a SAT problem in a 3Sat in polynomial
time (ref. Karp), it follows that P = NP. Open Source program is available at
http://www.visainformatica.it/3sat
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3877</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3877</id><created>2009-09-21</created><authors><author><keyname>Nastos</keyname><forenames>James</forenames></author><author><keyname>Gao</keyname><forenames>Yong</forenames></author></authors><title>A note on the hardness of graph diameter augmentation problems</title><categories>cs.DM cs.DS</categories><comments>No figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph has \emph{diameter} D if every pair of vertices are connected by a
path of at most D edges. The Diameter-D Augmentation problem asks how to add
the a number of edges to a graph in order to make the resulting graph have
diameter D. It was previously known that this problem is NP-hard \cite{GJ},
even in the D=2 case. In this note, we give a simpler reduction to arrive at
this fact and show that this problem is W[2]-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3892</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3892</id><created>2009-09-21</created><authors><author><keyname>Borne</keyname><forenames>Kirk D.</forenames><affiliation>George Mason University</affiliation></author></authors><title>Astroinformatics: A 21st Century Approach to Astronomy</title><categories>astro-ph.IM cs.DB cs.DL cs.IR physics.data-an</categories><comments>14 pages total: 1 cover page, 3 pages of co-signers, plus 10 pages,
  Astro2010 Decadal Survey State of the Profession Position Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data volumes from multiple sky surveys have grown from gigabytes into
terabytes during the past decade, and will grow from terabytes into tens (or
hundreds) of petabytes in the next decade. This exponential growth of new data
both enables and challenges effective astronomical research, requiring new
approaches. Thus far, astronomy has tended to address these challenges in an
informal and ad hoc manner, with the necessary special expertise being assigned
to e-Science or survey science. However, we see an even wider scope and
therefore promote a broader vision of this data-driven revolution in
astronomical research. For astronomy to effectively cope with and reap the
maximum scientific return from existing and future large sky surveys,
facilities, and data-producing projects, we need our own information science
specialists. We therefore recommend the formal creation, recognition, and
support of a major new discipline, which we call Astroinformatics.
Astroinformatics includes a set of naturally-related specialties including data
organization, data description, astronomical classification taxonomies,
astronomical concept ontologies, data mining, machine learning, visualization,
and astrostatistics. By virtue of its new stature, we propose that astronomy
now needs to integrate Astroinformatics as a formal sub-discipline within
agency funding plans, university departments, research programs, graduate
training, and undergraduate education. Now is the time for the recognition of
Astroinformatics as an essential methodology of astronomical research. The
future of astronomy depends on it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3895</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3895</id><created>2009-09-21</created><authors><author><keyname>Borne</keyname><forenames>Kirk D.</forenames><affiliation>George Mason University</affiliation></author><author><keyname>Jacoby</keyname><forenames>Suzanne</forenames><affiliation>LSST Corporation</affiliation></author><author><keyname>Carney</keyname><forenames>K.</forenames><affiliation>Adler Planetarium</affiliation></author><author><keyname>Connolly</keyname><forenames>A.</forenames><affiliation>U. Washington</affiliation></author><author><keyname>Eastman</keyname><forenames>T.</forenames><affiliation>Wyle Information Systems</affiliation></author><author><keyname>Raddick</keyname><forenames>M. J.</forenames><affiliation>JHU/SDSS</affiliation></author><author><keyname>Tyson</keyname><forenames>J. A.</forenames><affiliation>UC Davis</affiliation></author><author><keyname>Wallin</keyname><forenames>J.</forenames><affiliation>George Mason University</affiliation></author></authors><title>The Revolution in Astronomy Education: Data Science for the Masses</title><categories>astro-ph.IM cs.DB cs.DL cs.IR physics.ed-ph</categories><comments>12 pages total: 1 cover page, 1 page of co-signers, plus 10 pages,
  State of the Profession Position Paper submitted to the Astro2010 Decadal
  Survey (March 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As our capacity to study ever-expanding domains of our science has increased
(including the time domain, non-electromagnetic phenomena, magnetized plasmas,
and numerous sky surveys in multiple wavebands with broad spatial coverage and
unprecedented depths), so have the horizons of our understanding of the
Universe been similarly expanding. This expansion is coupled to the exponential
data deluge from multiple sky surveys, which have grown from gigabytes into
terabytes during the past decade, and will grow from terabytes into Petabytes
(even hundreds of Petabytes) in the next decade. With this increased vastness
of information, there is a growing gap between our awareness of that
information and our understanding of it. Training the next generation in the
fine art of deriving intelligent understanding from data is needed for the
success of sciences, communities, projects, agencies, businesses, and
economies. This is true for both specialists (scientists) and non-specialists
(everyone else: the public, educators and students, workforce). Specialists
must learn and apply new data science research techniques in order to advance
our understanding of the Universe. Non-specialists require information literacy
skills as productive members of the 21st century workforce, integrating
foundational skills for lifelong learning in a world increasingly dominated by
data. We address the impact of the emerging discipline of data science on
astronomy education within two contexts: formal education and lifelong
learners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3911</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3911</id><created>2009-09-22</created><authors><author><keyname>Chen</keyname><forenames>Yon Ping</forenames></author><author><keyname>Der Yeh</keyname><forenames>Tien</forenames></author></authors><title>A Method for Extraction and Recognition of Isolated License Plate
  Characters</title><categories>cs.CV</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 1-10, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method to extract and recognize isolated characters in license plates is
proposed. In extraction stage, the proposed method detects isolated characters
by using Difference-of-Gaussian (DOG) function, The DOG function, similar to
Laplacian of Gaussian function, was proven to produce the most stable image
features compared to a range of other possible image functions. The candidate
characters are extracted by doing connected component analysis on different
scale DOG images. In recognition stage, a novel feature vector named
accumulated gradient projection vector (AGPV) is used to compare the candidate
character with the standard ones. The AGPV is calculated by first projecting
pixels of similar gradient orientations onto specific axes, and then
accumulates the projected gradient magnitudes by each axis. In the experiments,
the AGPVs are proven to be invariant from image scaling and rotation, and
robust to noise and illumination change.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3917</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3917</id><created>2009-09-22</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness Analysis Of Multi-Chain Parallel Robotic Systems</title><categories>cs.RO</categories><proxy>ccsd hal-00418768</proxy><report-no>JA2009</report-no><journal-ref>Journal of Automation, Mobile Robotics and Intelligent Systems 3,
  3 (2009) 75-82</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new stiffness modelling method for multi-chain parallel
robotic manipulators with flexible links and compliant actuating joints. In
contrast to other works, the method involves a FEA-based link stiffness
evaluation and employs a new solution strategy of the kinetostatic equations,
which allows computing the stiffness matrix for singular postures and to take
into account influence of the external forces. The advantages of the developed
technique are confirmed by application examples, which deal with stiffness
analysis of a parallel manipulator of the Orthoglide family
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3930</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3930</id><created>2009-09-22</created><authors><author><keyname>Rosgen</keyname><forenames>Bill</forenames></author></authors><title>Computational Distinguishability of Quantum Channels</title><categories>quant-ph cs.CC</categories><comments>Ph.D. Thesis, 178 pages, 35 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational problem of distinguishing two quantum channels is central
to quantum computing. It is a generalization of the well-known satisfiability
problem from classical to quantum computation. This problem is shown to be
surprisingly hard: it is complete for the class QIP of problems that have
quantum interactive proof systems, which implies that it is hard for the class
PSPACE of problems solvable by a classical computation in polynomial space.
  Several restrictions of distinguishability are also shown to be hard. It is
no easier when restricted to quantum computations of logarithmic depth, to
mixed-unitary channels, to degradable channels, or to antidegradable channels.
These hardness results are demonstrated by finding reductions between these
classes of quantum channels. These techniques have applications outside the
distinguishability problem, as the construction for mixed-unitary channels is
used to prove that the additivity problem for the classical capacity of quantum
channels can be equivalently restricted to the mixed unitary channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3931</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3931</id><created>2009-09-22</created><authors><author><keyname>Pandey</keyname><forenames>Sunil</forenames></author><author><keyname>Kaushik</keyname><forenames>Praveen</forenames></author><author><keyname>Shrivastava</keyname><forenames>Dr. S. C.</forenames></author></authors><title>Rossler Nonlinear Dynamical Machine for Cryptography Applications</title><categories>cs.CR</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many of the cryptography applications like password or IP address
encryption schemes, symmetric cryptography is useful. In these relatively
simpler applications of cryptography, asymmetric cryptography is difficult to
justify on account of the computational and implementation complexities
associated with asymmetric cryptography. Symmetric schemes make use of a single
shared key known only between the two communicating hosts. This shared key is
used both for the encryption as well as the decryption of data. This key has to
be small in size besides being a subset of a potentially large keyspace making
it convenient for the communicating hosts while at the same time making
cryptanalysis difficult for the potential attackers. In the present work, an
abstract Rossler nonlinear dynamical machine has been described first. The
Rossler system exhibits chaotic dynamics for certain values of system
parameters and initial conditions. The chaotic dynamics of the Rossler system
with its apparently erratic and irregular characteristics and extreme
sensitivity to the initial conditions has been used for the design of the
cryptographic key in an attempt to increase the confusion and the challenge for
the potential attackers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3966</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3966</id><created>2009-09-22</created><authors><author><keyname>Ubaidulla</keyname><forenames>P.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author></authors><title>Robust THP Transceiver Designs for Multiuser MIMO Downlink with
  Imperfect CSIT</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in EURASIP Journal on Advances in Signal
  Processing: Special Issue on Multiuser MIMO Transmission with Limited
  Feedback, Cooperation, and Coordination</comments><doi>10.1155/2009/473930</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present robust joint non-linear transceiver designs for
multiuser multiple-input multiple-output (MIMO) downlink in the presence of
imperfections in the channel state information at the transmitter (CSIT). The
base station (BS) is equipped with multiple transmit antennas, and each user
terminal is equipped with one or more receive antennas. The BS employs
Tomlinson-Harashima precoding (THP) for inter-user interference
pre-cancellation at the transmitter. We consider robust transceiver designs
that jointly optimize the transmit THP filters and receive filter for two
models of CSIT errors. The first model is a stochastic error (SE) model, where
the CSIT error is Gaussian-distributed. This model is applicable when the CSIT
error is dominated by channel estimation error. In this case, the proposed
robust transceiver design seeks to minimize a stochastic function of the sum
mean square error (SMSE) under a constraint on the total BS transmit power. We
propose an iterative algorithm to solve this problem. The other model we
consider is a norm-bounded error (NBE) model, where the CSIT error can be
specified by an uncertainty set. This model is applicable when the CSIT error
is dominated by quantization errors. In this case, we consider a worst-case
design. For this model, we consider robust i) minimum SMSE, ii)
MSE-constrained, and iii) MSE-balancing transceiver designs. We propose
iterative algorithms to solve these problems, wherein each iteration involves a
pair of semi-definite programs (SDP). Further, we consider an extension of the
proposed algorithm to the case with per-antenna power constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3976</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3976</id><created>2009-09-22</created><updated>2011-09-10</updated><authors><author><keyname>Madgazin</keyname><forenames>Vadim R.</forenames></author></authors><title>The Information Theory of Emotions of Musical Chords</title><categories>cs.SD q-bio.NC</categories><comments>18 pages, 2 figures, in English, and copy in Russian</comments><acm-class>H.5.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper offers a solution to the centuries-old puzzle - why the major
chords are perceived as happy and the minor chords as sad - based on the
information theory of emotions. A theory and a formula of musical emotions were
created. They define the sign and the amplitude of the utilitarian emotional
coloration of separate major and minor chords through relative pitches of
constituent sounds. Keywords: chord, major, minor, the formula of musical
emotions, the information theory of emotions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.3997</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.3997</id><created>2009-09-22</created><authors><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames></author><author><keyname>Vanier</keyname><forenames>Pascal</forenames></author></authors><title>Periodicity in tilings</title><categories>cs.DM</categories><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tilings and tiling systems are an abstract concept that arise both as a
computational model and as a dynamical system. In this paper, we characterize
the sets of periods that a tiling system can produce. We prove that up to a
slight recoding, they correspond exactly to languages in the complexity classes
$\nspace{n}$ and $\cne$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4004</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4004</id><created>2009-09-22</created><updated>2011-04-18</updated><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>The Group Structure of Pivot and Loop Complementation on Graphs and Set
  Systems</title><categories>cs.DM math.CO</categories><comments>21 pages, 7 figures, significant additions w.r.t. v3 are Thm 7 and
  Remark 25</comments><acm-class>G.2.1; G.2.2; F.4.2</acm-class><journal-ref>European Journal of Combinatorics, v. 32, 1353-1367, 2011</journal-ref><doi>10.1016/j.ejc.2011.03.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the interplay between principal pivot transform (pivot) and loop
complementation for graphs. This is done by generalizing loop complementation
(in addition to pivot) to set systems. We show that the operations together,
when restricted to single vertices, form the permutation group S_3. This leads,
e.g., to a normal form for sequences of pivots and loop complementation on
graphs. The results have consequences for the operations of local
complementation and edge complementation on simple graphs: an alternative proof
of a classic result involving local and edge complementation is obtained, and
the effect of sequences of local complementations on simple graphs is
characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4011</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4011</id><created>2009-09-22</created><authors><author><keyname>Adamaszek</keyname><forenames>Anna</forenames></author><author><keyname>Adamaszek</keyname><forenames>Michal</forenames></author></authors><title>Large-girth roots of graphs</title><categories>cs.DS cs.DM</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of recognizing graph powers and computing roots of
graphs. We provide a polynomial time recognition algorithm for r-th powers of
graphs of girth at least 2r+3, thus improving a bound conjectured by Farzad et
al. (STACS 2009). Our algorithm also finds all r-th roots of a given graph that
have girth at least 2r+3 and no degree one vertices, which is a step towards a
recent conjecture of Levenshtein that such root should be unique. On the
negative side, we prove that recognition becomes an NP-complete problem when
the bound on girth is about twice smaller. Similar results have so far only
been attempted for r=2,3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4013</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4013</id><created>2009-09-22</created><updated>2010-05-31</updated><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - IMAG</affiliation></author></authors><title>Automatic modular abstractions for template numerical constraints</title><categories>cs.PL cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for automatically generating abstract transformers for
static analysis by abstract interpretation. The method focuses on linear
constraints on programs operating on rational, real or floating-point variables
and containing linear assignments and tests. In addition to loop-free code, the
same method also applies for obtaining least fixed points as functions of the
precondition, which permits the analysis of loops and recursive functions. Our
algorithms are based on new quantifier elimination and symbolic manipulation
techniques. Given the specification of an abstract domain, and a program block,
our method automatically outputs an implementation of the corresponding
abstract transformer. It is thus a form of program transformation. The
motivation of our work is data-flow synchronous programming languages, used for
building control-command embedded systems, but it also applies to imperative
and functional programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4017</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4017</id><created>2009-09-22</created><authors><author><keyname>Huang</keyname><forenames>Chiachi</forenames><affiliation>Shitz</affiliation></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On Degrees of Freedom Region of MIMO Networks without CSIT</title><categories>cs.IT math.IT</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the effect of the absence of channel knowledge for
multiple-input-multiple-output (MIMO) networks. Specifically, we assume perfect
channel state information at the receivers, no channel state information at the
transmitter(s), and independent identically distributed (i.i.d.) Rayleigh
fading across antennas, users and time slots. We provide the characterization
of the degrees of freedom (DoF) region for a 2-user MIMO broadcast channel. We
then provide a DoF region outer bound for a 2-user MIMO interference channel.
This bound is shown to be tight for all possible combinations of the number of
antennas at each node except for one case. As a byproduct of this analysis we
point out the potential of interference alignment in the 2-user MIMO
interference channel with no CSIT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4021</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4021</id><created>2009-09-22</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Wojtaszczyk</keyname><forenames>Jakub Onufry</forenames></author></authors><title>Beyond O*(2^n) in domination-type problems</title><categories>cs.DS cs.DM</categories><comments>Submitted to STACS 2010</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide algorithms faster than O*(2^n) for several
NP-complete domination-type problems. More precisely, we provide: an algorithm
for CAPACITATED DOMINATING SET that solves it in O(1.89^n), a branch-and-reduce
algorithm solving LARGEST IRREDUNDANT SET in O(1.9657^n) time and a simple
iterative-DFS algorithm for SMALLEST INCLUSION-MAXIMAL IRREDUNDANT SET that
solves it in O(1.999956^n) time.
  We also provide an exponential approximation scheme for CAPACITATED
DOMINATING SET. All algorithms require polynomial space. Despite the fact that
the discussed problems are quite similar to the DOMINATING SET problem, we are
not aware of any published algorithms solving these problems faster than the
obvious O*(2^n) solution prior to this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4094</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4094</id><created>2009-09-22</created><updated>2010-02-03</updated><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>Csaba D.</forenames></author></authors><title>Long non-crossing configurations in the plane</title><categories>cs.CG</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit several maximization problems for geometric networks design under
the non-crossing constraint, first studied by Alon, Rajagopalan and Suri (ACM
Symposium on Computational Geometry, 1993). Given a set of $n$ points in the
plane in general position (no three points collinear), compute a longest
non-crossing configuration composed of straight line segments that is: (a) a
matching (b) a Hamiltonian path (c) a spanning tree. Here we obtain new results
for (b) and (c), as well as for the Hamiltonian cycle problem:
  (i) For the longest non-crossing Hamiltonian path problem, we give an
approximation algorithm with ratio $\frac{2}{\pi+1} \approx 0.4829$. The
previous best ratio, due to Alon et al., was $1/\pi \approx 0.3183$. Moreover,
the ratio of our algorithm is close to $2/\pi$ on a relatively broad class of
instances: for point sets whose perimeter (or diameter) is much shorter than
the maximum length matching. The algorithm runs in $O(n^{7/3}\log{n})$ time.
  (ii) For the longest non-crossing spanning tree problem, we give an
approximation algorithm with ratio 0.502 which runs in $O(n \log{n})$ time. The
previous ratio, 1/2, due to Alon et al., was achieved by a quadratic time
algorithm. Along the way, we first re-derive the result of Alon et al. with a
faster $O(n \log{n})$-time algorithm and a very simple analysis.
  (iii) For the longest non-crossing Hamiltonian cycle problem, we give an
approximation algorithm whose ratio is close to $2/\pi$ on a relatively broad
class of instances: for point sets with the product $\bf{&lt;}$diameter$\times$
convex hull size $\bf{&gt;}$ much smaller than the maximum length matching. The
algorithm runs in $O(n^{7/3}\log{n})$ time. No previous approximation results
were known for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4101</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4101</id><created>2009-09-22</created><authors><author><keyname>Cucker</keyname><forenames>Felipe</forenames></author><author><keyname>Krick</keyname><forenames>Teresa</forenames></author><author><keyname>Malajovich</keyname><forenames>Gregorio</forenames></author><author><keyname>Wschebor</keyname><forenames>Mario</forenames></author></authors><title>A Numerical Algorithm for Zero Counting. II: Distance to Ill-posedness
  and Smoothed Analysis</title><categories>cs.NA</categories><acm-class>F.2.1; G.1</acm-class><journal-ref>Journal of Fixed Point Theory and Applications 6 No 2, pp 285-294
  (Dec. 2009)</journal-ref><doi>10.1007/s11784-009-0127-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a Condition Number Theorem for the condition number of zero counting
for real polynomial systems. That is, we show that this condition number equals
the inverse of the normalized distance to the set of ill-posed systems (i.e.,
those having multiple real zeros). As a consequence, a smoothed analysis of
this condition number follows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4119</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4119</id><created>2009-09-22</created><updated>2013-04-30</updated><authors><author><keyname>Yamashita</keyname><forenames>Shigeru</forenames></author><author><keyname>Markov</keyname><forenames>Igor L.</forenames></author></authors><title>Fast Equivalence-checking for Quantum Circuits</title><categories>quant-ph cs.ET</categories><comments>Minor change of some wording</comments><journal-ref>Quant. Inf. and Comp., vol. 9, no. 9,10 (2010), pp. 721-734</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform formal verification of quantum circuits by integrating several
techniques specialized to particular classes of circuits. Our verification
methodology is based on the new notion of a reversible miter that allows one to
leverage existing techniques for circuit simplification of quantum circuits.
For reversible circuits which arise as runtime bottlenecks of key quantum
algorithms, we develop several verification techniques and empirically compare
them.
  We also combine existing quantum verification tools with the use of
SAT-solvers. Experiments with circuits for Shor's number-factoring algorithm,
containing thousands of gates, show improvements in efficiency by 3-4 orders of
magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4126</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4126</id><created>2009-09-22</created><authors><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>On an Inequality of Karlin and Rinott Concerning Weighted Sums of i.i.d.
  Random Variables</title><categories>cs.IT math.IT math.PR</categories><comments>&lt;= 4 pages</comments><journal-ref>Adv. in Appl. Probab. 40 (2008) 1223-1226</journal-ref><doi>10.1239/aap/1231340171</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an entropy comparison result concerning weighted sums of
independent and identically distributed random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4177</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4177</id><created>2009-09-23</created><authors><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Wang</keyname><forenames>Chenwei</forenames></author></authors><title>On the Degrees of Freedom of Finite State Compound Wireless Networks -
  Settling a Conjecture by Weingarten et. al</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the degrees of freedom (DoF) of three classes of finite state
compound wireless networks in this paper. First, we study the multiple-input
single-output (MISO) finite state compound broadcast channel (BC) with
arbitrary number of users and antennas at the transmitter. In prior work,
Weingarten et. al. have found inner and outer bounds on the DoF with 2 users.
The bounds have a different character. While the inner bound collapses to unity
as the number of states increases, the outer bound does not diminish with the
increasing number of states beyond a threshold value. It has been conjectured
that the outer bound is loose and the inner bound represents the actual DoF. In
the complex setting (all signals, noise, and channel coefficients are complex
variables) we solve a few cases to find that the outer bound -and not the inner
bound- of Weingarten et. al. is tight. For the real setting (all signals, noise
and channel coefficients are real variables) we completely characterize the
DoF, once again proving that the outer bound of Weingarten et. al. is tight. We
also extend the results to arbitrary number of users. Second, we characterize
the DoF of finite state scalar (single antenna nodes) compound X networks with
arbitrary number of users in the real setting. Third, we characterize the DoF
of finite state scalar compound interference networks with arbitrary number of
users in both the real and complex setting. The key finding is that scalar
interference networks and (real) X networks do not lose any DoF due to channel
uncertainty at the transmitter in the finite state compound setting. The finite
state compound MISO BC does lose DoF relative to the perfect CSIT scenario.
However, what is lost is only the DoF benefit of joint processing at transmit
antennas, without which the MISO BC reduces to an X network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4196</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4196</id><created>2009-09-23</created><authors><author><keyname>Al-Fedaghi</keyname><forenames>Sabah S.</forenames></author><author><keyname>Thalheim</keyname><forenames>Bernhard</forenames></author></authors><title>Personal Information Databases</title><categories>cs.DB</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Sabah S. Al-Fedaghi, Bernhard Thalheim, International Journal of
  Computer Science and Information Security, IJCSIS, Vol. 5, No. 1, pp. 11-20,
  August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important aspects of security organization is to establish a
framework to identify security significant points where policies and procedures
are declared. The (information) security infrastructure comprises entities,
processes, and technology. All are participants in handling information, which
is the item that needs to be protected. Privacy and security information
technology is a critical and unmet need in the management of personal
information. This paper proposes concepts and technologies for management of
personal information. Two different types of information can be distinguished:
personal information and nonpersonal information. Personal information can be
either personal identifiable information (PII), or nonidentifiable information
(NII). Security, policy, and technical requirements can be based on this
distinction. At the conceptual level, PII is defined and formalized by
propositions over infons (discrete pieces of information) that specify
transformations in PII and NII. PII is categorized into simple infons that
reflect the proprietor s aspects, relationships with objects, and relationships
with other proprietors. The proprietor is the identified person about whom the
information is communicated. The paper proposes a database organization that
focuses on the PII spheres of proprietors. At the design level, the paper
describes databases of personal identifiable information built exclusively for
this type of information, with their own conceptual scheme, system management,
and physical structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4202</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4202</id><created>2009-09-23</created><authors><author><keyname>Baboo</keyname><forenames>S Santhosh</forenames></author><author><keyname>Lobo</keyname><forenames>Nikhil</forenames></author></authors><title>Improving Effectiveness Of ELearning In Maintenance Using Interactive 3D</title><categories>cs.CY cs.HC</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Lt.Dr.S Santhosh Baboo, Nikhil Lobo, International Journal of
  Computer Science and Information Security, IJCSIS, Vol. 5, No. 1, pp. 21-24,
  August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In aerospace and defense, training is being carried out on the web by viewing
PowerPoint presentations, manuals and videos that are limited in their ability
to convey information to the technician. Interactive training in the form of 3D
is a more cost effective approach compared to creation of physical simulations
and mockups. This paper demonstrates how training using interactive 3D
simulations in elearning achieves a reduction in the time spent in training and
improves the efficiency of a trainee performing the installation or removal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4203</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4203</id><created>2009-09-23</created><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Error Exponents for the Gaussian Channel with Active Noisy Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the best exponential decay in the blocklength of the probability of
error that can be achieved in the transmission of a single bit over the
Gaussian channel with an active noisy Gaussian feedback link. We impose an
\emph{expected} block power constraint on the forward link and study both
\emph{almost-sure} and \emph{expected} block power constraints on the feedback
link. In both cases the best achievable error exponents are finite and grow
approximately proportionally to the larger between the signal-to-noise ratios
on the forward and feedback links. The error exponents under almost-sure block
power constraints are typically strictly smaller than under expected
constraints. Some of the results extend to communication at arbitrary rates
below capacity and to general discrete memoryless channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4224</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4224</id><created>2009-09-23</created><authors><author><keyname>Brankovic</keyname><forenames>Ljiljana</forenames></author><author><keyname>Fernau</keyname><forenames>Henning</forenames></author><author><keyname>Kneis</keyname><forenames>Joachim</forenames></author><author><keyname>Rossmanith</keyname><forenames>Dieter Kratsch Alexander Langer Mathieu Liedloff Daniel Raible Peter</forenames></author></authors><title>Breaking the 2^n-Barrier for Irredundance: A Parameterized Route to
  Solving Exact Puzzles</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lower and the upper irredundance numbers of a graph $G$, denoted $ir(G)$
and $IR(G)$ respectively, are conceptually linked to domination and
independence numbers and have numerous relations to other graph parameters. It
is a long-standing open question whether determining these numbers for a graph
$G$ on $n$ vertices admits exact algorithms running in time less than the
trivial $\Omega(2^n)$ enumeration barrier. We solve these open problems by
devising parameterized algorithms for the dual of the natural parameterizations
of the problems with running times faster than $O^*(4^{k})$. For example, we
present an algorithm running in time $O^*(3.069^{k})$ for determining whether
$IR(G)$ is at least $n-k$. Although the corresponding problem has been known to
be in FPT by kernelization techniques, this paper offers the first
parameterized algorithms with an exponential dependency on the parameter in the
running time. Additionally, our work also appears to be the first example of a
parameterized approach leading to a solution to a problem in exponential time
algorithmics where the natural interpretation as an exact exponential-time
algorithm fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4233</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4233</id><created>2009-09-23</created><updated>2011-11-06</updated><authors><author><keyname>Ziv</keyname><forenames>Jacob</forenames></author></authors><title>On the optimality of universal classifiers for finite-length individual
  test sequences</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider pairs of finite-length individual sequences that are realizations
of unknown, finite alphabet, stationary sources in a clas M of sources with
vanishing memory (e.g. stationary Markov sources).
  The task of a universal classifier is to decide whether the two sequences are
emerging from the same source or are emerging from two distinct sources in M,
and it has to carry this task without any prior knowledge of the two underlying
probability measures.
  Given a fidelity function and a fidelity criterion, the probability of
classification error for a given universal classifier is defined.
  Two universal classifiers are defined for pairs of $N$ -sequence: A
&quot;classical&quot; fixed-length (FL) universal classifier and an alternative
variable-length (VL) universal classifier.
  Following Wyner and Ziv (1996) it is demonstrated that if the length of the
individual sequences N is smaller than a cut-off value that is determined by
the properties of the class M, any universal classifier will fail with high
probability .
  It is demonstrated that for values of N larger than the cut-off rate, the
classification error relative to either one of the two classifiers tends to
zero as the length of the sequences tends to infinity.
  However, the probability of classification error that is associated with the
variable-length universal classifier is uniformly smaller (or equal) to the one
that is associated with the &quot;classical&quot; fixed-length universal classifier, for
any finite length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4260</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4260</id><created>2009-09-23</created><updated>2009-10-01</updated><authors><author><keyname>Akinola</keyname><forenames>Olalekan S.</forenames></author><author><keyname>Osofisan</keyname><forenames>Adenike O.</forenames></author></authors><title>An Empirical Comparative Study of Checklist based and Ad Hoc Code
  Reading Techniques in a Distributed Groupware Environment</title><categories>cs.OH</categories><comments>11 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Olalekan S. Akinola, and Adenike O. Osofisan, International
  Journal of Computer Science and Information Security, IJCSIS, Vol. 5, No. 1,
  pp. 25-35, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software inspection is a necessary and important tool for software quality
assurance. Since it was introduced by Fagan at IBM in 1976, arguments exist as
to which method should be adopted to carry out the exercise, whether it should
be paper based or tool based, and what reading technique should be used on the
inspection document. Extensive works have been done to determine the
effectiveness of reviewers in paper based environment when using ad hoc and
checklist reading techniques. In this work, we take the software inspection
research further by examining whether there is going to be any significant
difference in defect detection effectiveness of reviewers when they use either
ad hoc or checklist reading techniques in a distributed groupware environment.
Twenty final year undergraduate students of computer science, divided into ad
hoc and checklist reviewers groups of ten members each were employed to inspect
a medium sized java code synchronously on groupware deployed on the Internet.
The data obtained were subjected to tests of hypotheses using independent T
test and correlation coefficients. Results from the study indicate that there
are no significant differences in the defect detection effectiveness, effort in
terms of time taken in minutes and false positives reported by the reviewers
using either ad hoc or checklist based reading techniques in the distributed
groupware environment studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4275</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4275</id><created>2009-09-23</created><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Safro</keyname><forenames>Ilya</forenames></author></authors><title>A Measure of the Connection Strengths between Graph Vertices with
  Applications</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple iterative strategy for measuring the connection strength
between a pair of vertices in a graph. The method is attractive in that it has
a linear complexity and can be easily parallelized. Based on an analysis of the
convergence property, we propose a mutually reinforcing model to explain the
intuition behind the strategy. The practical effectiveness of this measure is
demonstrated through several combinatorial optimization problems on graphs and
hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4280</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4280</id><created>2009-09-23</created><authors><author><keyname>Bunt</keyname><forenames>Harry</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Towards Multimodal Content Representation</title><categories>cs.CL</categories><comments>Colloque avec actes et comit\'e de lecture. internationale</comments><proxy>ccsd inria-00100772</proxy><report-no>A02-R-095 || bunt02a</report-no><journal-ref>LREC Workshop on International Standards of Terminology and
  Language Resources Management, Las Palams : Spain (2002)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal interfaces, combining the use of speech, graphics, gestures, and
facial expressions in input and output, promise to provide new possibilities to
deal with information in more effective and efficient ways, supporting for
instance: - the understanding of possibly imprecise, partial or ambiguous
multimodal input; - the generation of coordinated, cohesive, and coherent
multimodal presentations; - the management of multimodal interaction (e.g.,
task completion, adapting the interface, error prevention) by representing and
exploiting models of the user, the domain, the task, the interactive context,
and the media (e.g. text, audio, video). The present document is intended to
support the discussion on multimodal content representation, its possible
objectives and basic constraints, and how the definition of a generic
representation framework for multimodal content representation may be
approached. It takes into account the results of the Dagstuhl workshop, in
particular those of the informal working group on multimodal meaning
representation that was active during the workshop (see
http://www.dfki.de/~wahlster/Dagstuhl_Multi_Modality, Working Group 4).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4314</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4314</id><created>2009-09-23</created><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author></authors><title>Higher-dimensional models of networks</title><categories>cs.NI cs.DM</categories><acm-class>C.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks are often studied as graphs, where the vertices stand for entities
in the world and the edges stand for connections between them. While relatively
easy to study, graphs are often inadequate for modeling real-world situations,
especially those that include contexts of more than two entities. For these
situations, one typically uses hypergraphs or simplicial complexes.
  In this paper, we provide a precise framework in which graphs, hypergraphs,
simplicial complexes, and many other categories, all of which model higher
graphs, can be studied side-by-side. We show how to transform a hypergraph into
its nearest simplicial analogue, for example. Our framework includes many new
categories as well, such as one that models broadcasting networks. We give
several examples and applications of these ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4341</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4341</id><created>2009-09-24</created><authors><author><keyname>Ferragina</keyname><forenames>Paolo</forenames></author><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Manzini</keyname><forenames>Giovanni</forenames></author></authors><title>Lightweight Data Indexing and Compression in External Memory</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe algorithms for computing the BWT and for building
(compressed) indexes in external memory. The innovative feature of our
algorithms is that they are lightweight in the sense that, for an input of size
$n$, they use only ${n}$ bits of disk working space while all previous
approaches use $\Th{n \log n}$ bits of disk working space. Moreover, our
algorithms access disk data only via sequential scans, thus they take full
advantage of modern disk features that make sequential disk accesses much
faster than random accesses.
  We also present a scan-based algorithm for inverting the BWT that uses
$\Th{n}$ bits of working space, and a lightweight {\em internal-memory}
algorithm for computing the BWT which is the fastest in the literature when the
available working space is $\os{n}$ bits.
  Finally, we prove {\em lower} bounds on the complexity of computing and
inverting the BWT via sequential scans in terms of the classic product:
internal-memory space $\times$ number of passes over the disk data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4348</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4348</id><created>2009-09-24</created><updated>2009-11-06</updated><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Vondrak</keyname><forenames>Jan</forenames></author><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Dependent Randomized Rounding for Matroid Polytopes and Applications</title><categories>cs.DS cs.DM</categories><comments>Rico Zenklusen joined as an author; paper substantially expanded
  compared to previous version; note a slight change in the title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by several applications, we consider the problem of randomly
rounding a fractional solution in a matroid (base) polytope to an integral one.
We consider the pipage rounding technique and also present a new technique,
randomized swap rounding. Our main technical results are concentration bounds
for functions of random variables arising from these rounding techniques. We
prove Chernoff-type concentration bounds for linear functions of random
variables arising from both techniques, and also a lower-tail exponential bound
for monotone submodular functions of variables arising from randomized swap
rounding.
  The following are examples of our applications: (1) We give a
(1-1/e-epsilon)-approximation algorithm for the problem of maximizing a
monotone submodular function subject to 1 matroid and k linear constraints, for
any constant k and epsilon&gt;0. (2) We present a result on minimax packing
problems that involve a matroid base constraint. We give an O(log m / log log
m)-approximation for the general problem Min {lambda: x \in {0,1}^N, x \in
B(M), Ax &lt;= lambda b}, where m is the number of packing constraints. (3) We
generalize the continuous greedy algorithm to problems involving multiple
submodular functions, and use it to find a (1-1/e-epsilon)-approximate pareto
set for the problem of maximizing a constant number of monotone submodular
functions subject to a matroid constraint. An example is the Submodular Welfare
Problem where we are looking for an approximate pareto set with respect to
individual players' utilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4349</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4349</id><created>2009-09-23</created><authors><author><keyname>Shang</keyname><forenames>Yilun</forenames></author></authors><title>Leader-following Consensus Problems with a Time-varying Leader under
  Measurement Noises</title><categories>cs.MA cs.IT math.IT</categories><comments>12 pages 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a leader-following consensus problem for networks
of continuous-time integrator agents with a time-varying leader under
measurement noises. We propose a neighbor-based state-estimation protocol for
every agent to track the leader, and time-varying consensus gains are
introduced to attenuate the noises. By combining the tools of stochastic
analysis and algebraic graph theory, we study mean square convergence of this
multi-agent system under directed fixed as well as switching interconnection
topologies. Sufficient conditions are given for mean square consensus in both
cases. Finally, a numerical example is given to illustrate our theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4359</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4359</id><created>2009-09-24</created><updated>2010-07-05</updated><authors><author><keyname>Wang</keyname><forenames>Yilun</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>Sparse Signal Reconstruction via Iterative Support Detection</title><categories>cs.IT math.IT math.NA math.OC</categories><msc-class>68U10, 65K10, 90C25, 90C51</msc-class><journal-ref>SIAM Journal on Imaging Sciences, 3(3), 462-491, 2010</journal-ref><doi>10.1137/090772447</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel sparse signal reconstruction method &quot;ISD&quot;, aiming to
achieve fast reconstruction and a reduced requirement on the number of
measurements compared to the classical l_1 minimization approach. ISD addresses
failed reconstructions of l_1 minimization due to insufficient measurements. It
estimates a support set I from a current reconstruction and obtains a new
reconstruction by solving the minimization problem \min{\sum_{i\not\in
I}|x_i|:Ax=b}, and it iterates these two steps for a small number of times. ISD
differs from the orthogonal matching pursuit (OMP) method, as well as its
variants, because (i) the index set I in ISD is not necessarily nested or
increasing and (ii) the minimization problem above updates all the components
of x at the same time. We generalize the Null Space Property to Truncated Null
Space Property and present our analysis of ISD based on the latter.
  We introduce an efficient implementation of ISD, called threshold--ISD, for
recovering signals with fast decaying distributions of nonzeros from
compressive sensing measurements. Numerical experiments show that
threshold--ISD has significant advantages over the classical l_1 minimization
approach, as well as two state--of--the--art algorithms: the iterative
reweighted l_1 minimization algorithm (IRL1) and the iterative reweighted
least--squares algorithm (IRLS).
  MATLAB code is available for download from
http://www.caam.rice.edu/~optimization/L1/ISD/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4362</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4362</id><created>2009-09-24</created><updated>2009-09-24</updated><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author></authors><title>A Strategy for Maker in the Clique Game which Helps to Tackle some Open
  Problems by Beck</title><categories>cs.GT cs.DM</categories><comments>12 pages, no figure</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Maker/Breaker games on the edges of the complete graph, as
introduced by Chvatal and Erdos. We show that in the (m:b) clique game played
on K_{N}, the complete graph on N vertices, Maker can achieve a K_{q} for q =
(m/(log_{2}(b + 1)) - o(1)) * log N, which partially solves an open problem by
Beck. Moreover, we show that in the (1:1) clique game played on K_{N} for a
sufficiently large N, Maker can achieve a K_{q} in only 2^(2q/3) moves, which
improves the previous best bound and answers a question of Beck. Finally we
consider the so called tournament game. A tournament is a directed graph where
every pair of vertices is connected by a single directed edge. The tournament
game is played on K_{N}. At the beginning Breaker fixes an arbitrary tournament
T_{q} on q vertices. Maker and Breaker then alternately take turns at claiming
one unclaimed edge e and selecting one of the two possible orientations. Maker
wins if his graph contains a copy of the goal tournament T_{q}; otherwise
Breaker wins. We show that Maker wins the tournament game on K_{N} with q = (1
- o(1))*log_{2}(N) which supports the random graph intuition: the threshold for
q is asymptotically the same for the game played by two &quot;clever'' players and
the game played by two ``random'' players.
  This last result solves an open problem of Beck which he included in his list
of the seven most humiliating open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4369</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4369</id><created>2009-09-24</created><authors><author><keyname>Flocchini</keyname><forenames>Paola</forenames></author><author><keyname>Mans</keyname><forenames>Bernard</forenames></author><author><keyname>Santoro</keyname><forenames>Nicola</forenames></author></authors><title>Exploration of Periodically Varying Graphs</title><categories>cs.DS</categories><comments>22 pages. Shorter paper (10 pages) accepted at ISAAC 2009. ISAAC'09,
  The 20th International Symposium on Algorithms and Computation, December
  16-18, 2008, Hawaii, USA. Exploration of Periodically Varying Graphs, P.
  Flocchini, B. Mans and N. Santoro, Springer-LNCS vol. 5878, accepted Aug.
  2009, Y. Dong, D.-Z. Du, and O. Ibarra (Eds), to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computability and complexity of the exploration problem in a
class of highly dynamic graphs: periodically varying (PV) graphs, where the
edges exist only at some (unknown) times defined by the periodic movements of
carriers. These graphs naturally model highly dynamic infrastructure-less
networks such as public transports with fixed timetables, low earth orbiting
(LEO) satellite systems, security guards' tours, etc. We establish necessary
conditions for the problem to be solved. We also derive lower bounds on the
amount of time required in general, as well as for the PV graphs defined by
restricted classes of carriers movements: simple routes, and circular routes.
We then prove that the limitations on computability and complexity we have
established are indeed tight. In fact we prove that all necessary conditions
are also sufficient and all lower bounds on costs are tight. We do so
constructively presenting two worst case optimal solution algorithms, one for
anonymous systems, and one for those with distinct nodes ids. An added benefit
is that the algorithms are rather simple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4385</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4385</id><created>2009-09-24</created><authors><author><keyname>Bernhardsson</keyname><forenames>Sebastian</forenames></author><author><keyname>da Rocha</keyname><forenames>Luis Enrique Correa</forenames></author><author><keyname>Minnhagen</keyname><forenames>Petter</forenames></author></authors><title>The meta book and size-dependent properties of written language</title><categories>physics.soc-ph cs.CL physics.data-an</categories><comments>7 pages, 6 figures, 1 table</comments><journal-ref>New J. Phys. 11 (2009) 123015</journal-ref><doi>10.1088/1367-2630/11/12/123015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evidence is given for a systematic text-length dependence of the power-law
index gamma of a single book. The estimated gamma values are consistent with a
monotonic decrease from 2 to 1 with increasing length of a text. A direct
connection to an extended Heap's law is explored. The infinite book limit is,
as a consequence, proposed to be given by gamma = 1 instead of the value
gamma=2 expected if the Zipf's law was ubiquitously applicable. In addition we
explore the idea that the systematic text-length dependence can be described by
a meta book concept, which is an abstract representation reflecting the
word-frequency structure of a text. According to this concept the
word-frequency distribution of a text, with a certain length written by a
single author, has the same characteristics as a text of the same length pulled
out from an imaginary complete infinite corpus written by the same author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4409</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4409</id><created>2009-09-24</created><authors><author><keyname>El-Zawawy</keyname><forenames>Mohamed A.</forenames></author><author><keyname>El-Sharkawi</keyname><forenames>Mohamed E.</forenames></author></authors><title>Clustering with Obstacles in Spatial Databases</title><categories>cs.DB</categories><comments>In Proc. 2001 IEEE Int. Symposium of Signal Processing and
  Information Technology (ISSPIT01), pages 420-425, Cairo, Egypt, Dec. 2001</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering large spatial databases is an important problem, which tries to
find the densely populated regions in a spatial area to be used in data mining,
knowledge discovery, or efficient information retrieval. However most
algorithms have ignored the fact that physical obstacles such as rivers, lakes,
and highways exist in the real world and could thus affect the result of the
clustering. In this paper, we propose CPO, an efficient clustering technique to
solve the problem of clustering in the presence of obstacles. The proposed
algorithm divides the spatial area into rectangular cells. Each cell is
associated with statistical information used to label the cell as dense or
non-dense. It also labels each cell as obstructed (i.e. intersects any
obstacle) or nonobstructed. For each obstructed cell, the algorithm finds a
number of non-obstructed sub-cells. Then it finds the dense regions of
non-obstructed cells or sub-cells by a breadthfirst search as the required
clusters with a center to each region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4412</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4412</id><created>2009-09-24</created><authors><author><keyname>El-Sharkawi</keyname><forenames>Mohamed E.</forenames></author><author><keyname>El-Zawawy</keyname><forenames>Mohamed A.</forenames></author></authors><title>Algorithm for Spatial Clustering with Obstacles</title><categories>cs.DB</categories><comments>In Proc. 2002 ICICIS Int. Conference on Intelligent Computing and
  Information Systems (ICICIS02), Cairo, Egypt, June 2002</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient clustering technique to solve the
problem of clustering in the presence of obstacles. The proposed algorithm
divides the spatial area into rectangular cells. Each cell is associated with
statistical information that enables us to label the cell as dense or
non-dense. We also label each cell as obstructed (i.e. intersects any obstacle)
or non-obstructed. Then the algorithm finds the regions (clusters) of
connected, dense, non-obstructed cells. Finally, the algorithm finds a center
for each such region and returns those centers as centers of the relatively
dense regions (clusters) in the spatial area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4416</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4416</id><created>2009-09-24</created><updated>2009-09-25</updated><authors><author><keyname>Gornerup</keyname><forenames>Olof</forenames></author><author><keyname>Boman</keyname><forenames>Magnus</forenames></author></authors><title>A baseline for content-based blog classification</title><categories>cs.IR</categories><comments>6 pages, 4 figures New version has higher resolution for figures 2
  and 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A content-based network representation of web logs (blogs) using a basic
word-overlap similarity measure is presented. Due to a strong signal in blog
data the approach is sufficient for accurately classifying blogs. Using Swedish
blog data we demonstrate that blogs that treat similar subjects are organized
in clusters that, in turn, are hierarchically organized in higher-order
clusters. The simplicity of the representation renders it both computationally
tractable and transparent. We therefore argue that the approach is suitable as
a baseline when developing and analyzing more advanced content-based
representations of the blogosphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4437</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4437</id><created>2009-09-24</created><authors><author><keyname>Pini</keyname><forenames>Maria</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>Brent</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Manipulation and gender neutrality in stable marriage procedures</title><categories>cs.AI cs.GT</categories><comments>8th International Joint Conference on Autonomous Agents and
  Multiagent Systems (AAMAS 2009), Budapest, Hungary, May 10-15, 2009, Volume 1</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stable marriage problem is a well-known problem of matching men to women
so that no man and woman who are not married to each other both prefer each
other. Such a problem has a wide variety of practical applications ranging from
matching resident doctors to hospitals to matching students to schools. A
well-known algorithm to solve this problem is the Gale-Shapley algorithm, which
runs in polynomial time.
  It has been proven that stable marriage procedures can always be manipulated.
Whilst the Gale-Shapley algorithm is computationally easy to manipulate, we
prove that there exist stable marriage procedures which are NP-hard to
manipulate. We also consider the relationship between voting theory and stable
marriage procedures, showing that voting rules which are NP-hard to manipulate
can be used to define stable marriage procedures which are themselves NP-hard
to manipulate. Finally, we consider the issue that stable marriage procedures
like Gale-Shapley favour one gender over the other, and we show how to use
voting rules to make any stable marriage procedure gender neutral.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4441</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4441</id><created>2009-09-24</created><authors><author><keyname>Pini</keyname><forenames>Maria</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>Brent</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Dealing with incomplete agents' preferences and an uncertain agenda in
  group decision making via sequential majority voting</title><categories>cs.AI cs.GT cs.MA</categories><comments>Principles of Knowledge Representation and Reasoning: Proceedings of
  the Eleventh International Conference, KR 2008, Sydney, Australia, September
  16-19, 2008</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multi-agent systems where agents' preferences are aggregated via
sequential majority voting: each decision is taken by performing a sequence of
pairwise comparisons where each comparison is a weighted majority vote among
the agents. Incompleteness in the agents' preferences is common in many
real-life settings due to privacy issues or an ongoing elicitation process. In
addition, there may be uncertainty about how the preferences are aggregated.
For example, the agenda (a tree whose leaves are labelled with the decisions
being compared) may not yet be known or fixed. We therefore study how to
determine collectively optimal decisions (also called winners) when preferences
may be incomplete, and when the agenda may be uncertain. We show that it is
computationally easy to determine if a candidate decision always wins, or may
win, whatever the agenda. On the other hand, it is computationally hard to know
wheth er a candidate decision wins in at least one agenda for at least one
completion of the agents' preferences. These results hold even if the agenda
must be balanced so that each candidate decision faces the same number of
majority votes. Such results are useful for reasoning about preference
elicitation. They help understand the complexity of tasks such as determining
if a decision can be taken collectively, as well as knowing if the winner can
be manipulated by appropriately ordering the agenda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4446</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4446</id><created>2009-09-24</created><authors><author><keyname>Gelain</keyname><forenames>Mirco</forenames></author><author><keyname>Pini</keyname><forenames>Maria</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>Brent</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Elicitation strategies for fuzzy constraint problems with missing
  preferences: algorithms and experimental studies</title><categories>cs.AI</categories><comments>Principles and Practice of Constraint Programming, 14th International
  Conference, CP 2008, Sydney, Australia, September 14-18, 2008. Proceedings</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy constraints are a popular approach to handle preferences and
over-constrained problems in scenarios where one needs to be cautious, such as
in medical or space applications. We consider here fuzzy constraint problems
where some of the preferences may be missing. This models, for example,
settings where agents are distributed and have privacy issues, or where there
is an ongoing preference elicitation process. In this setting, we study how to
find a solution which is optimal irrespective of the missing preferences. In
the process of finding such a solution, we may elicit preferences from the user
if necessary. However, our goal is to ask the user as little as possible. We
define a combined solving and preference elicitation scheme with a large number
of different instantiations, each corresponding to a concrete algorithm which
we compare experimentally. We compute both the number of elicited preferences
and the &quot;user effort&quot;, which may be larger, as it contains all the preference
values the user has to compute to be able to respond to the elicitation
requests. While the number of elicited preferences is important when the
concern is to communicate as little information as possible, the user effort
measures also the hidden work the user has to do to be able to communicate the
elicited preferences. Our experimental results show that some of our algorithms
are very good at finding a necessarily optimal solution while asking the user
for only a very small fraction of the missing preferences. The user effort is
also very small for the best algorithms. Finally, we test these algorithms on
hard constraint problems with possibly missing constraints, where the aim is to
find feasible solutions irrespective of the missing constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4452</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4452</id><created>2009-09-24</created><authors><author><keyname>Maher</keyname><forenames>Michael J.</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Flow-Based Propagators for the SEQUENCE and Related Global Constraints</title><categories>cs.AI</categories><comments>Principles and Practice of Constraint Programming, 14th International
  Conference, CP 2008, Sydney, Australia, September 14-18, 2008. Proceedings</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose new filtering algorithms for the SEQUENCE constraint and some
extensions of the SEQUENCE constraint based on network flows. We enforce domain
consistency on the SEQUENCE constraint in $O(n^2)$ time down a branch of the
search tree. This improves upon the best existing domain consistency algorithm
by a factor of $O(\log n)$. The flows used in these algorithms are derived from
a linear program. Some of them differ from the flows used to propagate global
constraints like GCC since the domains of the variables are encoded as costs on
the edges rather than capacities. Such flows are efficient for maintaining
bounds consistency over large domains and may be useful for other global
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4456</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4456</id><created>2009-09-24</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>The Weighted CFG Constraint</title><categories>cs.AI</categories><comments>Integration of AI and OR Techniques in Constraint Programming for
  Combinatorial Optimization Problems, 5th International Conference, CPAIOR
  2008, Paris, France, May 20-23, 2008, Proceedings</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the weighted CFG constraint and propose a propagation algorithm
that enforces domain consistency in $O(n^3|G|)$ time. We show that this
algorithm can be decomposed into a set of primitive arithmetic constraints
without hindering propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4457</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4457</id><created>2009-09-24</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>How are new citation-based journal indicators adding to the bibliometric
  toolbox?</title><categories>physics.soc-ph cs.DL physics.data-an</categories><journal-ref>Journal of the American Society for Information Science and
  Technology 60(7) (2009) 1327-1336</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The launching of Scopus and Google Scholar, and methodological developments
in Social Network Analysis have made many more indicators for evaluating
journals available than the traditional Impact Factor, Cited Half-life, and
Immediacy Index of the ISI. In this study, these new indicators are compared
with one another and with the older ones. Do the various indicators measure new
dimensions of the citation networks, or are they highly correlated among them?
Are they robust and relatively stable over time? Two main dimensions are
distinguished -- size and impact -- which together shape influence. The H-index
combines the two dimensions and can also be considered as an indicator of reach
(like Indegree). PageRank is mainly an indicator of size, but has important
interactions with centrality measures. The Scimago Journal Ranking (SJR)
indicator provides an alternative to the Journal Impact Factor, but the
computation is less easy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4474</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4474</id><created>2009-09-24</created><updated>2011-03-17</updated><authors><author><keyname>Blum</keyname><forenames>Jacques</forenames><affiliation>JAD</affiliation></author><author><keyname>Boulbe</keyname><forenames>Cedric</forenames><affiliation>JAD</affiliation></author><author><keyname>Faugeras</keyname><forenames>Blaise</forenames><affiliation>JAD</affiliation></author></authors><title>Reconstruction of the equilibrium of the plasma in a Tokamak and
  identification of the current density profile in real time</title><categories>math.NA cs.SY math.AP math.OC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reconstruction of the equilibrium of a plasma in a Tokamak is a free
boundary problem described by the Grad-Shafranov equation in axisymmetric
configuration. The right-hand side of this equation is a nonlinear source,
which represents the toroidal component of the plasma current density. This
paper deals with the identification of this nonlinearity source from
experimental measurements in real time. The proposed method is based on a fixed
point algorithm, a finite element resolution, a reduced basis method and a
least-square optimization formulation. This is implemented in a software called
Equinox with which several numerical experiments are conducted to explore the
identification problem. It is shown that the identification of the profile of
the averaged current density and of the safety factor as a function of the
poloidal flux is very robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4479</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4479</id><created>2009-09-24</created><updated>2009-11-12</updated><authors><author><keyname>Kashefi</keyname><forenames>Elham</forenames></author><author><keyname>Markham</keyname><forenames>Damian</forenames></author><author><keyname>Mhalla</keyname><forenames>Mehdi</forenames></author><author><keyname>Perdrix</keyname><forenames>Simon</forenames></author></authors><title>Information Flow in Secret Sharing Protocols</title><categories>quant-ph cs.CR</categories><journal-ref>EPTCS 9, 2009, pp. 87-97</journal-ref><doi>10.4204/EPTCS.9.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The entangled graph states have emerged as an elegant and powerful quantum
resource, indeed almost all multiparty protocols can be written in terms of
graph states including measurement based quantum computation (MBQC), error
correction and secret sharing amongst others. In addition they are at the
forefront in terms of implementations. As such they represent an excellent
opportunity to move towards integrated protocols involving many of these
elements. In this paper we look at expressing and extending graph state secret
sharing and MBQC in a common framework and graphical language related to flow.
We do so with two main contributions.
  First we express in entirely graphical terms which set of players can access
which information in graph state secret sharing protocols. These succinct
graphical descriptions of access allow us to take known results from graph
theory to make statements on the generalisation of the previous schemes to
present new secret sharing protocols.
  Second, we give a set of necessary conditions as to when a graph with flow,
i.e. capable of performing a class of unitary operations, can be extended to
include vertices which can be ignored, pointless measurements, and hence
considered as unauthorised players in terms of secret sharing, or error qubits
in terms of fault tolerance. This offers a way to extend existing MBQC patterns
to secret sharing protocols. Our characterisation of pointless measurements is
believed also to be a useful tool for further integrated measurement based
schemes, for example in constructing fault tolerant MBQC schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4484</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4484</id><created>2009-09-24</created><authors><author><keyname>Hachem</keyname><forenames>Walid</forenames></author><author><keyname>Moulines</keyname><forenames>Eric</forenames></author><author><keyname>Roueff</keyname><forenames>Francois</forenames></author></authors><title>Error exponents for Neyman-Pearson detection of a continuous-time
  Gaussian Markov process from noisy irregular samples</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the detection of a stochastic process in noise from
irregular samples. We consider two hypotheses. The \emph{noise only} hypothesis
amounts to model the observations as a sample of a i.i.d. Gaussian random
variables (noise only). The \emph{signal plus noise} hypothesis models the
observations as the samples of a continuous time stationary Gaussian process
(the signal) taken at known but random time-instants corrupted with an additive
noise. Two binary tests are considered, depending on which assumptions is
retained as the null hypothesis. Assuming that the signal is a linear
combination of the solution of a multidimensional stochastic differential
equation (SDE), it is shown that the minimum Type II error probability
decreases exponentially in the number of samples when the False Alarm
probability is fixed. This behavior is described by \emph{error exponents} that
are completely characterized. It turns out that they are related with the
asymptotic behavior of the Kalman Filter in random stationary environment,
which is studied in this paper. Finally, numerical illustrations of our claims
are provided in the context of sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4516</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4516</id><created>2009-09-24</created><authors><author><keyname>Orlicki</keyname><forenames>Jos&#xe9; I.</forenames></author></authors><title>SQL/JavaScript Hybrid Worms As Two-stage Quines</title><categories>cs.CR cs.NI</categories><comments>15 pages, 11 figures, Workshop de Seguridad Informatica, 38 JAIIO,
  Mar Del Plata, Argentina</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delving into present trends and anticipating future malware trends, a hybrid,
SQL on the server-side, JavaScript on the client-side, self-replicating worm
based on two-stage quines was designed and implemented on an ad-hoc scenario
instantiating a very common software pattern. The proof of concept code
combines techniques seen in the wild, in the form of SQL injections leading to
cross-site scripting JavaScript inclusion, and seen in the laboratory, in the
form of SQL quines propa- gated via RFIDs, resulting in a hybrid code
injection. General features of hybrid worms are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4569</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4569</id><created>2009-09-24</created><authors><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Wingarten</keyname><forenames>Amiram</forenames></author></authors><title>Envy, Multi Envy, and Revenue Maximization</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the envy free pricing problem faced by a seller who wishes to
maximize revenue by setting prices for bundles of items. If there is an
unlimited supply of items and agents are single minded then we show that
finding the revenue maximizing envy free allocation/pricing can be solved in
polynomial time by reducing it to an instance of weighted independent set on a
perfect graph.
  We define an allocation/pricing as \textit{multi envy free} if no agent
wishes to replace her allocation with the union of the allocations of some set
of other agents and her price with the sum of their prices. We show that it is
\textit{coNP}-hard to decide if a given allocation/pricing is multi envy free.
We also show that revenue maximization multi envy free allocation/pricing is
\textit{APX} hard.
  Furthermore, we give efficient algorithms and hardness results for various
variants of the highway problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4573</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4573</id><created>2009-09-24</created><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Huang</keyname><forenames>Howard</forenames></author></authors><title>Efficient Linear Precoding in Downlink Cooperative Cellular Networks
  with Soft Interference Nulling</title><categories>cs.IT math.IT</categories><comments>To appear at the Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing, September 30 - October 2, 2009,
  Monticello, Illinois</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple line network model is proposed to study the downlink cellular
network. Without base station cooperation, the system is interference-limited.
The interference limitation is overcome when the base stations are allowed to
jointly encode the user signals, but the capacity-achieving dirty paper coding
scheme can be too complex for practical implementation. A new linear precoding
technique called soft interference nulling (SIN) is proposed, which performs at
least as well as zero-forcing (ZF) beamforming under full network coordination.
Unlike ZF, SIN allows the possibility of but over-penalizes interference. The
SIN precoder is computed by solving a convex optimization problem, and the
formulation is extended to multiple-antenna channels. SIN can be applied when
only a limited number of base stations cooperate; it is shown that SIN under
partial network coordination can outperform full network coordination ZF at
moderate SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4575</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4575</id><created>2009-09-24</created><updated>2012-02-03</updated><authors><author><keyname>Kiayias</keyname><forenames>Aggelos</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author><author><keyname>Shashidhar</keyname><forenames>Narasimha</forenames></author></authors><title>Randomness Efficient Steganography</title><categories>cs.CR cs.IT math.IT</categories><comments>19 pages</comments><acm-class>F.2.2; G.3; E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganographic protocols enable one to embed covert messages into
inconspicuous data over a public communication channel in such a way that no
one, aside from the sender and the intended receiver, can even detect the
presence of the secret message. In this paper, we provide a new
provably-secure, private-key steganographic encryption protocol secure in the
framework of Hopper et al. We first present a &quot;one-time stegosystem&quot; that
allows two parties to transmit messages of length at most that of the shared
key with information-theoretic security guarantees. The employment of a
pseudorandom generator (PRG) permits secure transmission of longer messages in
the same way that such a generator allows the use of one-time pad encryption
for messages longer than the key in symmetric encryption. The advantage of our
construction, compared to all previous work is randomness efficiency: in the
information theoretic setting our protocol embeds a message of length n bits
using a shared secret key of length (1+o(1))n bits while achieving security
2^{-n/log^{O(1)}n}; simply put this gives a rate of key over message that is 1
as n tends to infinity (the previous best result achieved a constant rate
greater than 1 regardless of the security offered). In this sense, our protocol
is the first truly randomness efficient steganographic system. Furthermore, in
our protocol, we can permit a portion of the shared secret key to be public
while retaining precisely n private key bits. In this setting, by separating
the public and the private randomness of the shared key, we achieve security of
2^{-n}. Our result comes as an effect of the application of randomness
extractors to stegosystem design. To the best of our knowledge this is the
first time extractors have been applied in steganography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4588</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4588</id><created>2009-09-24</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Discrete MDL Predicts in Total Variation</title><categories>math.PR cs.IT cs.LG math.IT math.ST stat.ML stat.TH</categories><comments>15 LaTeX pages</comments><journal-ref>Advances in Neural Information Processing Systems 22 (NIPS 2009)
  pages 817-825</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Minimum Description Length (MDL) principle selects the model that has the
shortest code for data plus model. We show that for a countable class of
models, MDL predictions are close to the true distribution in a strong sense.
The result is completely general. No independence, ergodicity, stationarity,
identifiability, or other assumption on the model class need to be made. More
formally, we show that for any countable class of models, the distributions
selected by MDL (or MAP) asymptotically predict (merge with) the true measure
in the class in total variation distance. Implications for non-i.i.d. domains
like time-series forecasting, discriminative learning, and reinforcement
learning are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4589</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4589</id><created>2009-09-24</created><authors><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Feng</keyname><forenames>Rongquan</forenames></author><author><keyname>Zheng</keyname><forenames>Zhiming</forenames></author></authors><title>Cross-correlation properties of cyclotomic sequences</title><categories>cs.IT cs.DM math.CO math.IT</categories><journal-ref>This paper have been published in IEICE Trans. Fund., 2007</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Sequences with good correlation properties are widely used in engineering
applications, especially in the area of communications. Among the known
sequences, cyclotomic families have the optimal autocorrelation property. In
this paper, we decide the cross-correlation function of the known cyclotomic
sequences completely. Moreover, to get our results, the relations between the
multiplier group and the decimations of the characteristic sequence are also
established for an arbitrary difference set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4592</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4592</id><created>2009-09-24</created><updated>2010-08-22</updated><authors><author><keyname>Cai</keyname><forenames>Kai</forenames></author></authors><title>Autocorrelation-Run Formula for Binary Sequences</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The autocorrelation function and the run structure are two basic notions for
binary sequences, and have been used as two independent postulates to test
randomness of binary sequences ever since Golomb 1955. In this paper, we prove
for binary sequence that the autocorrelation function is in fact completely
determined by its run structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4601</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4601</id><created>2009-09-25</created><updated>2011-01-22</updated><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Suter</keyname><forenames>Bruce W.</forenames></author></authors><title>Rank Metric Decoder Architectures for Random Linear Network Coding with
  Error Control</title><categories>cs.IT math.IT</categories><comments>14 pages, 12 figures, accepted by IEEE Trans. VLSI Syst</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While random linear network coding is a powerful tool for disseminating
information in communication networks, it is highly susceptible to errors
caused by various sources. Due to error propagation, errors greatly deteriorate
the throughput of network coding and seriously undermine both reliability and
security of data. Hence error control for network coding is vital. Recently,
constant-dimension codes (CDCs), especially K\&quot;otter-Kschischang (KK) codes,
have been proposed for error control in random linear network coding. KK codes
can also be constructed from Gabidulin codes, an important class of rank metric
codes. Rank metric decoders have been recently proposed for both Gabidulin and
KK codes, but they have high computational complexities. Furthermore, it is not
clear whether such decoders are feasible and suitable for hardware
implementations. In this paper, we reduce the complexities of rank metric
decoders and propose novel decoder architectures for both codes. The synthesis
results of our decoder architectures for Gabidulin and KK codes with limited
error-correcting capabilities over small fields show that our architectures not
only are affordable, but also achieve high throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4603</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4603</id><created>2009-09-25</created><authors><author><keyname>Petterson</keyname><forenames>James</forenames></author><author><keyname>Caetano</keyname><forenames>Tiberio</forenames></author></authors><title>Scalable Inference for Latent Dirichlet Allocation</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of learning a topic model - the well-known Latent
Dirichlet Allocation - in a distributed manner, using a cluster of C processors
and dividing the corpus to be learned equally among them. We propose a simple
approximated method that can be tuned, trading speed for accuracy according to
the task at hand. Our approach is asynchronous, and therefore suitable for
clusters of heterogenous machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4604</identifier>
 <datestamp>2011-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4604</id><created>2009-09-25</created><updated>2011-09-21</updated><authors><author><keyname>Ghasemi</keyname><forenames>Akbar</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl Seyed</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Keyvan</forenames></author></authors><title>Interference Alignment for the $K$ User MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>25 pages, 4 figures, Presented in part at ISIT 2010, submitted to
  IEEE Transactions on Information Theory, June 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the $K$-user Multiple Input Multiple Output (MIMO) Gaussian
interference channel with $M$ antennas at each transmitter and $N$ antennas at
each receiver. It is assumed that channel coefficients are constant and are
available at all transmitters and at all receivers. The main objective of this
paper is to characterize the Degrees of Freedom (DoF) for this channel. Using a
new interference alignment technique which has been recently introduced in
\cite{abolfazl-final}, we show that $\frac{MN}{M+N} K$ degrees of freedom can
be achieved for almost all channel realizations. Also, a new upper-bound on the
DoF of this channel is provided. This upper-bound coincides with our achievable
DoF for $K\geq K_u\define\frac{M+N}{\gcd(M,N)}$, where $\gcd(M,N)$ denotes the
greatest common divisor of $M$ and $N$. This gives an exact characterization of
DoF for $M\times N$ MIMO Gaussian interference channel in the case of $K\geq
K_u$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4607</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4607</id><created>2009-09-25</created><authors><author><keyname>Lee</keyname><forenames>Troy</forenames></author></authors><title>A note on the sign degree of formulas</title><categories>cs.CC</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent breakthroughs in quantum query complexity have shown that any formula
of size n can be evaluated with O(sqrt(n)log(n)/log log(n)) many quantum
queries in the bounded-error setting [FGG08, ACRSZ07, RS08b, Rei09]. In
particular, this gives an upper bound on the approximate polynomial degree of
formulas of the same magnitude, as approximate polynomial degree is a lower
bound on quantum query complexity [BBCMW01].
  These results essentially answer in the affirmative a conjecture of O'Donnell
and Servedio [O'DS03] that the sign degree--the minimal degree of a polynomial
that agrees in sign with a function on the Boolean cube--of every formula of
size n is O(sqrt(n)).
  In this note, we show that sign degree is super-multiplicative under function
composition. Combining this result with the above mentioned upper bounds on the
quantum query complexity of formulas allows the removal of logarithmic factors
to show that the sign degree of every size n formula is at most sqrt(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4637</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4637</id><created>2009-09-25</created><authors><author><keyname>Cohen</keyname><forenames>Ernie</forenames></author><author><keyname>Schirmer</keyname><forenames>Norbert</forenames></author></authors><title>A Better Reduction Theorem for Store Buffers</title><categories>cs.LO</categories><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When verifying a concurrent program, it is usual to assume that memory is
sequentially consistent. However, most modern multiprocessors depend on store
buffering for efficiency, and provide native sequential consistency only at a
substantial performance penalty. To regain sequential consistency, a programmer
has to follow an appropriate programming discipline. However, na\&quot;ive
disciplines, such as protecting all shared accesses with locks, are not
flexible enough for building high-performance multiprocessor software.
  We present a new discipline for concurrent programming under TSO (total store
order, with store buffer forwarding). It does not depend on concurrency
primitives, such as locks. Instead, threads use ghost operations to acquire and
release ownership of memory addresses. A thread can write to an address only if
no other thread owns it, and can read from an address only if it owns it or it
is shared and the thread has flushed its store buffer since it last wrote to an
address it did not own. This discipline covers both coarse-grained concurrency
(where data is protected by locks) as well as fine-grained concurrency (where
atomic operations race to memory).
  We formalize this discipline in Isabelle/HOL, and prove that if every
execution of a program in a system without store buffers follows the
discipline, then every execution of the program with store buffers is
sequentially consistent. Thus, we can show sequential consistency under TSO by
ordinary assertional reasoning about the program, without having to consider
store buffers at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4642</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4642</id><created>2009-09-25</created><authors><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>Scherfenberg</keyname><forenames>Marc</forenames></author><author><keyname>Wolle</keyname><forenames>Thomas</forenames></author></authors><title>The directed Hausdorff distance between imprecise point sets</title><categories>cs.CG</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the directed Hausdorff distance between point sets in the plane,
where one or both point sets consist of imprecise points. An imprecise point is
modelled by a disc given by its centre and a radius. The actual position of an
imprecise point may be anywhere within its disc. Due to the direction of the
Hausdorff Distance and whether its tight upper or lower bound is computed there
are several cases to consider. For every case we either show that the
computation is NP-hard or we present an algorithm with a polynomial running
time. Further we give several approximation algorithms for the hard cases and
show that one of them cannot be approximated better than with factor 3, unless
P=NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4686</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4686</id><created>2009-09-25</created><authors><author><keyname>Tsaknakis</keyname><forenames>Haralampos</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>A Graph Spectral Approach for Computing Approximate Nash Equilibria</title><categories>cs.GT cs.DS</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new methodology for computing approximate Nash equilibria for
two-person non-cooperative games based upon certain extensions and
specializations of an existing optimization approach previously used for the
derivation of fixed approximations for this problem. In particular, the general
two-person problem is reduced to an indefinite quadratic programming problem of
special structure involving the $n \times n$ adjacency matrix of an induced
simple graph specified by the input data of the game, where $n$ is the number
of players' strategies. Using this methodology and exploiting certain
properties of the positive part of the spectrum of the induced graph, we show
that for any $\varepsilon &gt; 0$ there is an algorithm to compute an
$\varepsilon$-approximate Nash equilibrium in time $n^{\xi(m)/\varepsilon}$,
where, $\xi (m) = \sum_{i=1}^m \lambda_i / n$ and $\lambda_1, \lambda_2, &gt;...,
\lambda_m$ are the positive eigenvalues of the adjacency matrix of the graph.
For classes of games for which $\xi (m)$ is a constant, there is a PTAS. Based
on the best upper bound derived for $\xi(m)$ so far, the worst case complexity
of the method is bounded by the subexponential $n^{\sqrt{m}/\varepsilon}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4692</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4692</id><created>2009-09-25</created><authors><author><keyname>Dorn</keyname><forenames>Frederic</forenames></author></authors><title>Planar Subgraph Isomorphism Revisited</title><categories>cs.DS cs.DM</categories><comments>13 pages, 4 figures</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of Subgraph Isomorphism is defined as follows: Given a pattern H
and a host graph G on n vertices, does G contain a subgraph that is isomorphic
to H? Eppstein [SODA 95, J'GAA 99] gives the first linear time algorithm for
subgraph isomorphism for a fixed-size pattern, say of order k, and arbitrary
planar host graph, improving upon the O(n^\sqrt{k})-time algorithm when using
the ``Color-coding'' technique of Alon et al [J'ACM 95]. Eppstein's algorithm
runs in time k^O(k) n, that is, the dependency on k is superexponential. We
solve an open problem posed in Eppstein's paper and improve the running time to
2^O(k) n, that is, single exponential in k while keeping the term in n linear.
Next to deciding subgraph isomorphism, we can construct a solution and
enumerate all solutions in the same asymptotic running time. We may list w
subgraphs with an additive term O(w k) in the running time of our algorithm. We
introduce the technique of &quot;embedded dynamic programming&quot; on a suitably
structured graph decomposition, which exploits the topology of the underlying
embeddings of the subgraph pattern (rather than of the host graph). To achieve
our results, we give an upper bound on the number of partial solutions in each
dynamic programming step as a function of pattern size--as it turns out, for
the planar subgraph isomorphism problem, that function is single exponential in
the number of vertices in the pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4719</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4719</id><created>2009-09-25</created><authors><author><keyname>Eschen</keyname><forenames>Elaine M.</forenames></author><author><keyname>Hoang</keyname><forenames>Chinh T.</forenames></author><author><keyname>Spinrad</keyname><forenames>Jeremy P.</forenames></author><author><keyname>Sritharan</keyname><forenames>R.</forenames></author></authors><title>On graphs without a C4 or a diamond</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of (C4, diamond)-free graphs; graphs in this class do
not contain a C4 or a diamond as an induced subgraph. We provide an efficient
recognition algorithm for this class. We count the number of maximal cliques in
a (C4, diamond)-free graph and the number of n-vertex, labeled (C4,
diamond)-free graphs. We also give an efficient algorithm for finding a largest
clique in the more general class of (house, diamond)-free graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4727</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4727</id><created>2009-09-25</created><updated>2010-05-05</updated><authors><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author><author><keyname>Tan</keyname><forenames>Li-Yang</forenames></author><author><keyname>Wan</keyname><forenames>Andrew</forenames></author></authors><title>A regularity lemma, and low-weight approximators, for low-degree
  polynomial threshold functions</title><categories>cs.CC cs.DM</categories><comments>23 pages, 0 figures</comments><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a &quot;regularity lemma&quot; for degree-d polynomial threshold functions
(PTFs) over the Boolean cube {-1,1}^n. This result shows that every degree-d
PTF can be decomposed into a constant number of subfunctions such that almost
all of the subfunctions are close to being regular PTFs. Here a &quot;regular PTF is
a PTF sign(p(x)) where the influence of each variable on the polynomial p(x) is
a small fraction of the total influence of p.
  As an application of this regularity lemma, we prove that for any constants d
\geq 1, \eps \geq 0, every degree-d PTF over n variables has can be
approximated to accuracy eps by a constant-degree PTF that has integer weights
of total magnitude O(n^d). This weight bound is shown to be optimal up to
constant factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4756</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4756</id><created>2009-09-25</created><updated>2011-02-23</updated><authors><author><keyname>Hartline</keyname><forenames>Jason D.</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author></authors><title>Bayesian Algorithmic Mechanism Design</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The principal problem in algorithmic mechanism design is in merging the
incentive constraints imposed by selfish behavior with the algorithmic
constraints imposed by computational intractability. This field is motivated by
the observation that the preeminent approach for designing incentive compatible
mechanisms, namely that of Vickrey, Clarke, and Groves; and the central
approach for circumventing computational obstacles, that of approximation
algorithms, are fundamentally incompatible: natural applications of the VCG
approach to an approximation algorithm fails to yield an incentive compatible
mechanism. We consider relaxing the desideratum of (ex post) incentive
compatibility (IC) to Bayesian incentive compatibility (BIC), where
truthtelling is a Bayes-Nash equilibrium (the standard notion of incentive
compatibility in economics). For welfare maximization in single-parameter agent
settings, we give a general black-box reduction that turns any approximation
algorithm into a Bayesian incentive compatible mechanism with essentially the
same approximation factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4766</identifier>
 <datestamp>2012-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4766</id><created>2009-09-25</created><updated>2010-06-04</updated><authors><author><keyname>Farhi</keyname><forenames>Edward</forenames></author><author><keyname>Goldstone</keyname><forenames>Jeffrey</forenames></author><author><keyname>Gosset</keyname><forenames>David</forenames></author><author><keyname>Gutmann</keyname><forenames>Sam</forenames></author><author><keyname>Meyer</keyname><forenames>Harvey B.</forenames></author><author><keyname>Shor</keyname><forenames>Peter</forenames></author></authors><title>Quantum Adiabatic Algorithms, Small Gaps, and Different Paths</title><categories>quant-ph cs.CC</categories><comments>The original version considered a unique satisfying assignment and
  one problematic low lying state. The revision argues that the algorithm with
  path change will succeed when there are polynomially many low lying states</comments><report-no>MIT-CTP 4076, CERN-PH-TH-2009/175</report-no><journal-ref>Quantum Information &amp; Computation, Volume 11 number 3&amp;4, 2011,
  pages 181-214</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a set of instances of 3SAT which are not solved efficiently
using the simplest quantum adiabatic algorithm. These instances are obtained by
picking random clauses all consistent with two disparate planted solutions and
then penalizing one of them with a single additional clause. We argue that by
randomly modifying the beginning Hamiltonian, one obtains (with substantial
probability) an adiabatic path that removes this difficulty. This suggests that
the quantum adiabatic algorithm should in general be run on each instance with
many different random paths leading to the problem Hamiltonian. We do not know
whether this trick will help for a random instance of 3SAT (as opposed to an
instance from the particular set we consider), especially if the instance has
an exponential number of disparate assignments that violate few clauses. We use
a continuous imaginary time Quantum Monte Carlo algorithm in a novel way to
numerically investigate the ground state as well as the first excited state of
our system. Our arguments are supplemented by Quantum Monte Carlo data from
simulations with up to 150 spins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4767</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4767</id><created>2009-09-25</created><updated>2010-09-08</updated><authors><author><keyname>Bachoc</keyname><forenames>Christine</forenames><affiliation>IMB</affiliation></author></authors><title>Semidefinite programming, harmonic analysis and coding theory</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These lecture notes where presented as a course of the CIMPA summer school in
Manila, July 20-30, 2009, Semidefinite programming in algebraic combinatorics.
This version is an update June 2010.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4786</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4786</id><created>2009-09-25</created><authors><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn</forenames></author><author><keyname>Demleitner</keyname><forenames>Markus</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Worldwide Use and Impact of the NASA Astrophysics Data System Digital
  Library</title><categories>cs.DL physics.soc-ph</categories><comments>ADS bibcode: 2005JASIS..56...36K This is a portion (The bibliometric
  properties of article readership information is the other part) of the
  article: The NASA Astrophysics Data System: Sociology, bibliometrics and
  impact, which went on-line in the summer of 2003</comments><journal-ref>The Journal of the American Society for Information Science and
  Technology, Vol. 56, p. 36. (2005)</journal-ref><doi>10.1002/asi.20095</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By combining data from the text, citation, and reference databases with data
from the ADS readership logs we have been able to create Second Order
Bibliometric Operators, a customizable class of collaborative filters which
permits substantially improved accuracy in literature queries.
  Using the ADS usage logs along with membership statistics from the
International Astronomical Union and data on the population and gross domestic
product (GDP) we develop an accurate model for world-wide basic research where
the number of scientists in a country is proportional to the GDP of that
country, and the amount of basic research done by a country is proportional to
the number of scientists in that country times that country's per capita GDP.
  We introduce the concept of utility time to measure the impact of the
ADS/URANIA and the electronic astronomical library on astronomical research. We
find that in 2002 it amounted to the equivalent of 736 FTE researchers, or $250
Million, or the astronomical research done in France.
  Subject headings: digital libraries; bibliometrics; sociology of science;
information retrieval
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4789</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4789</id><created>2009-09-25</created><authors><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Demleitner</keyname><forenames>Markus</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author><author><keyname>Martimbeau</keyname><forenames>Nathalie</forenames></author><author><keyname>Elwell</keyname><forenames>Barbara</forenames></author></authors><title>The Bibliometric Properties of Article Readership Information</title><categories>cs.DL physics.soc-ph</categories><comments>ADS bibcode: 2005JASIS..56..111K This is the second paper (the first
  is Worldwide Use and Impact of the NASA Astrophysics Data System Digital
  Library) from the original article The NASA Astrophysics Data System:
  Sociology, Bibliometrics, and Impact, which went on-line in the summer of
  2003</comments><journal-ref>The Journal of the American Society for Information Science and
  Technology, Vol. 56, p. 111 (2005)</journal-ref><doi>10.1002/asi.20096</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The NASA Astrophysics Data System (ADS), along with astronomy's journals and
data centers (a collaboration dubbed URANIA), has developed a distributed
on-line digital library which has become the dominant means by which
astronomers search, access and read their technical literature. Digital
libraries such as the NASA Astrophysics Data System permit the easy
accumulation of a new type of bibliometric measure, the number of electronic
accesses (``reads'') of individual articles. We explore various aspects of this
new measure. We examine the obsolescence function as measured by actual reads,
and show that it can be well fit by the sum of four exponentials with very
different time constants. We compare the obsolescence function as measured by
readership with the obsolescence function as measured by citations. We find
that the citation function is proportional to the sum of two of the components
of the readership function. This proves that the normative theory of citation
is true in the mean. We further examine in detail the similarities and
differences between the citation rate, the readership rate and the total
citations for individual articles, and discuss some of the causes. Using the
number of reads as a bibliometric measure for individuals, we introduce the
read-cite diagram to provide a two-dimensional view of an individual's
scientific productivity. We develop a simple model to account for an
individual's reads and cites and use it to show that the position of a person
in the read-cite diagram is a function of age, innate productivity, and work
history. We show the age biases of both reads and cites, and develop two new
bibliometric measures which have substantially less age bias than citations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4807</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4807</id><created>2009-09-25</created><authors><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Moura</keyname><forenames>Jose' M. F.</forenames></author></authors><title>Consensus in Correlated Random Topologies: Weights for Finite Time
  Horizon</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the weight design problem for the consensus algorithm under a
finite time horizon. We assume that the underlying network is random where the
links fail at each iteration with certain probability and the link failures can
be spatially correlated. We formulate a family of weight design criteria
(objective functions) that minimize n, n = 1,...,N (out of N possible) largest
(slowest) eigenvalues of the matrix that describes the mean squared consensus
error dynamics. We show that the objective functions are convex; hence,
globally optimal weights (with respect to the design criteria) can be
efficiently obtained. Numerical examples on large scale, sparse random networks
with spatially correlated link failures show that: 1) weights obtained
according to our criteria lead to significantly faster convergence than the
choices available in the literature; 2) different design criteria that
corresponds to different n, exhibits very interesting tradeoffs: faster
transient performance leads to slower long time run performance and vice versa.
Thus, n is a valuable degree of freedom and can be appropriately selected for
the given time horizon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4808</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4808</id><created>2009-09-25</created><authors><author><keyname>Ebrahimi</keyname><forenames>Javad</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author></authors><title>Combinatiorial Algorithms for Wireless Information Flow</title><categories>cs.DS cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A long-standing open question in information theory is to characterize the
unicast capacity of a wireless relay network. The difficulty arises due to the
complex signal interactions induced in the network, since the wireless channel
inherently broadcasts the signals and there is interference among
transmissions. Recently, Avestimehr, Diggavi and Tse proposed a linear
deterministic model that takes into account the shared nature of wireless
channels, focusing on the signal interactions rather than the background noise.
They generalized the min-cut max-flow theorem for graphs to networks of
deterministic channels and proved that the capacity can be achieved using
information theoretical tools. They showed that the value of the minimum cut is
in this case the minimum rank of all the adjacency matrices describing
source-destination cuts.
  In this paper, we develop a polynomial time algorithm that discovers the
relay encoding strategy to achieve the min-cut value in linear deterministic
(wireless) networks, for the case of a unicast connection. Our algorithm
crucially uses a notion of linear independence between channels to calculate
the capacity in polynomial time. Moreover, we can achieve the capacity by using
very simple one-symbol processing at the intermediate nodes, thereby
constructively yielding finite length strategies that achieve the unicast
capacity of the linear deterministic (wireless) relay network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4828</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4828</id><created>2009-09-28</created><updated>2010-08-10</updated><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Optimal Feedback Communication via Posterior Matching</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a fundamental principle for optimal communication
over general memoryless channels in the presence of noiseless feedback, termed
posterior matching. Using this principle, we devise a (simple, sequential)
generic feedback transmission scheme suitable for a large class of memoryless
channels and input distributions, achieving any rate below the corresponding
mutual information. This provides a unified framework for optimal feedback
communication in which the Horstein scheme (BSC) and the Schalkwijk-Kailath
scheme (AWGN channel) are special cases. Thus, as a corollary, we prove that
the Horstein scheme indeed attains the BSC capacity, settling a longstanding
conjecture. We further provide closed form expressions for the error
probability of the scheme over a range of rates, and derive the achievable
rates in a mismatch setting where the scheme is designed according to the wrong
channel model. Several illustrative examples of the posterior matching scheme
for specific channels are given, and the corresponding error probability
expressions are evaluated. The proof techniques employed utilize novel
relations between information rates and contraction properties of iterated
function systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4830</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4830</id><created>2009-09-25</created><authors><author><keyname>Abreu</keyname><forenames>Luis Daniel</forenames></author></authors><title>Super-wavelets versus poly-Bergman spaces</title><categories>math.FA cs.IT math.IT</categories><comments>Preliminar version; 19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by potential applications in multiplexing and by recent results on
Gabor analysis with Hermite windows due to Gr\&quot;{o}chenig and Lyubarskii, we
investigate vector-valued wavelet transforms and vector-valued wavelet frames,
which constitute special cases of super-wavelets, with a particular attention
to the case when the analyzing wavelet vector is related to Fourier transforms
of Laguerre functions. We construct an isometric isomorphism between
$L^{2}(\mathbb{R}^{+},\mathbf{C}^{n})$ and poly-Bergman spaces, with a view to
relate the sampling sequences in the poly-Bergman spaces to the wavelet frames
and super-frames with the windows $\Phi_{n}$. One of the applications of the
theory is a proof that $b\ln a&lt;2\pi (n+1)$ is a necessary condition for the
(scalar) wavelet frame associated to the $\Phi_{n}$ to exist. This seems to be
the first known result of this type outside the setting of analytic functions
(the case $n=0$, which has been completely studied by Seip in 1993).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4858</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4858</id><created>2009-09-26</created><authors><author><keyname>Rathi</keyname><forenames>S.</forenames></author><author><keyname>Thanuskodi</keyname><forenames>K.</forenames></author></authors><title>A Secure and Fault tolerant framework for Mobile IPv6 based networks</title><categories>cs.NI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information Security
  Vol. 5, No. 1, pp. 46-55, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile IPv6 will be an integral part of the next generation Internet
protocol. The importance of mobility in the Internet gets keep on increasing.
Current specification of Mobile IPv6 does not provide proper support for
reliability in the mobile network and there are other problems associated with
it. In this paper, we propose Virtual Private Network (VPN) based Home Agent
Reliability Protocol (VHAHA) as a complete system architecture and extension to
Mobile IPv6 that supports reliability and offers solutions to the security
problems that are found in Mobile IP registration part. The key features of
this protocol over other protocols are: better survivability, transparent
failure detection and recovery, reduced complexity of the system and workload,
secure data transfer and improved overall performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4860</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4860</id><created>2009-09-26</created><authors><author><keyname>Robiah</keyname><forenames>Y.</forenames></author><author><keyname>Rahayu</keyname><forenames>S. Siti</forenames></author><author><keyname>Zaki</keyname><forenames>M. Mohd</forenames></author><author><keyname>Shahrin</keyname><forenames>S.</forenames></author><author><keyname>Faizal</keyname><forenames>M. A.</forenames></author><author><keyname>Marliza</keyname><forenames>R.</forenames></author></authors><title>A New Generic Taxonomy on Hybrid Malware Detection Technique</title><categories>cs.CR</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Robiah Y, Siti Rahayu S., Mohd Zaki M, Shahrin S., Faizal M. A.,
  Marliza R., International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 56-61, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malware is a type of malicious program that replicate from host machine and
propagate through network. It has been considered as one type of computer
attack and intrusion that can do a variety of malicious activity on a computer.
This paper addresses the current trend of malware detection techniques and
identifies the significant criteria in each technique to improve malware
detection in Intrusion Detection System (IDS). Several existing techniques are
analyzing from 48 various researches and the capability criteria of malware
detection technique have been reviewed. From the analysis, a new generic
taxonomy of malware detection technique have been proposed named Hybrid Malware
Detection Technique (Hybrid MDT) which consists of Hybrid Signature and Anomaly
detection technique and Hybrid Specification based and Anomaly detection
technique to complement the weaknesses of the existing malware detection
technique in detecting known and unknown attack as well as reducing false alert
before and during the intrusion occur.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4876</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4876</id><created>2009-09-26</created><authors><author><keyname>Mani</keyname><forenames>A.</forenames></author></authors><title>A Program in Dialectical Rough Set Theory</title><categories>math.LO cs.IT math.IT</categories><comments>8 Pages, Brief Version of forthcoming paper. My conference
  presentation at &quot;Internat. Conf. on Rough Sets, Fuzzy Sets and Soft
  Computing, Agartala, Tripura University, India, 2009&quot; includes many parts of
  this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dialectical rough set theory focussed on the relation between roughly
equivalent objects and classical objects was introduced in \cite{AM699} by the
present author. The focus of our investigation is on elucidating the minimal
conditions on the nature of granularity, underlying semantic domain and nature
of the general rough set theories (RST) involved for possible extension of the
semantics to more general RST on a paradigm. On this basis we also formulate a
program in dialectical rough set theory. The dialectical approach provides
better semantics in many difficult cases and helps in formalising a wide
variety of concepts and notions that remain untamed at meta levels in the usual
approaches. This is a brief version of a more detailed forthcoming paper by the
present author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4888</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4888</id><created>2009-09-26</created><authors><author><keyname>Mogos</keyname><forenames>Andrei-Horia</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Approximating Mathematical Semantic Web Services Using Approximation
  Formulas and Numerical Methods</title><categories>cs.MS cs.NA</categories><comments>The International Workshop on Multi-Agent Systems Technology and
  Semantics - MASTS 2009</comments><acm-class>F.1.3; H.3.5; I.2.4</acm-class><journal-ref>Proc. of the 17th Intl. Conf. on Control Systems and Computer
  Science (CSCS), vol. 2, pp. 533-538, Bucharest, Romania, 26-29 May, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical semantic web services are very useful in practice, but only a
small number of research results are reported in this area. In this paper we
present a method of obtaining an approximation of a mathematical semantic web
service, from its semantic description, using existing mathematical semantic
web services, approximation formulas, and numerical methods techniques. We also
give a method for automatic comparison of two complexity functions. In
addition, we present a method for classifying the numerical methods
mathematical semantic web services from a library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4889</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4889</id><created>2009-09-26</created><authors><author><keyname>Jemili</keyname><forenames>Farah</forenames></author><author><keyname>Zaghdoud</keyname><forenames>Montaceur</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed Ben</forenames></author></authors><title>Hybrid Intrusion Detection and Prediction multiAgent System HIDPAS</title><categories>cs.CR cs.AI cs.DS</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Farah Jemili, Montaceur Zaghdoud, Mohamed Ben Ahmed, International
  Journal of Computer Science and Information Security, IJCSIS, Vol. 5, No. 1,
  pp. 62-71, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an intrusion detection and prediction system based on
uncertain and imprecise inference networks and its implementation. Giving a
historic of sessions, it is about proposing a method of supervised learning
doubled of a classifier permitting to extract the necessary knowledge in order
to identify the presence or not of an intrusion in a session and in the
positive case to recognize its type and to predict the possible intrusions that
will follow it. The proposed system takes into account the uncertainty and
imprecision that can affect the statistical data of the historic. The
systematic utilization of an unique probability distribution to represent this
type of knowledge supposes a too rich subjective information and risk to be in
part arbitrary. One of the first objectives of this work was therefore to
permit the consistency between the manner of which we represent information and
information which we really dispose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4893</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4893</id><created>2009-09-26</created><updated>2010-01-12</updated><authors><author><keyname>Cohen</keyname><forenames>Hagai</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author></authors><title>Range Non-Overlapping Indexing</title><categories>cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the non-overlapping indexing problem: Given a text T, preprocess it
so that you can answer queries of the form: given a pattern P, report the
maximal set of non-overlapping occurrences of P in T. A generalization of this
problem is the range non-overlapping indexing where in addition we are given
two indexes i,j to report the maximal set of non-overlapping occurrences
between these two indexes. We suggest new solutions for these problems. For the
non-overlapping problem our solution uses O(n) space with query time of O(m +
occ_{NO}). For the range non-overlapping problem we propose a solution with
O(n\log^\epsilon n) space for some 0&lt;\epsilon&lt;1 and O(m + \log\log n +
occ_{ij,NO}) query time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4896</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4896</id><created>2009-09-26</created><authors><author><keyname>Attiogbe</keyname><forenames>Christian</forenames></author></authors><title>Modelling and Analysing Dynamic Decentralised Systems</title><categories>cs.SE cs.NI</categories><comments>6 pages - two columns (IEEE) - Conference PRDC'2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a method to specify and analyse decentralised dynamic systems;
the method is based on the combination of an event-based multi-process system
specification approach with a multi-facet analysis approach that considers a
reference abstract model and several specific ones derived from the abstract
model in order to support facet-wise analysis. The method is illustrated with
the modelling and the analysis of a mobile ad-hoc network. The Event-B
framework and its related tools B4free and ProB are used to conduct the
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4934</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4934</id><created>2009-09-27</created><authors><author><keyname>Voras</keyname><forenames>Ivan</forenames></author><author><keyname>Zagar</keyname><forenames>Mario</forenames></author></authors><title>Characteristics of multithreading models for high-performance IO driven
  network applications</title><categories>cs.NI cs.PF</categories><acm-class>D.1.3; D.2.11; D.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a technological landscape that is quickly moving toward dense multi-CPU
and multi-core computer systems, where using multithreading is an increasingly
popular application design decision, it is important to choose a proper model
for distributing tasks across multiple threads that will result in the best
efficiency for the application and the system as a whole. The work described in
this paper creates, implements and evaluates various models of distributing
tasks to CPU threads and investigates their characteristics for use in modern
high-performance network servers. The results presented here comprise a roadmap
of models for building multithreaded server applications for modern server
hardware and Unix-like operating systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4938</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4938</id><created>2009-09-27</created><updated>2011-12-23</updated><authors><author><keyname>Shang</keyname><forenames>Mingsheng</forenames></author><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Empirical analysis of web-based user-object bipartite networks</title><categories>physics.data-an cs.IR physics.soc-ph</categories><comments>6 pages, 7 figures and 1 table</comments><journal-ref>EPL 90 (2010) 48006</journal-ref><doi>10.1209/0295-5075/90/48006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the structure and evolution of web-based user-object networks
is a significant task since they play a crucial role in e-commerce nowadays.
This Letter reports the empirical analysis on two large-scale web sites,
audioscrobbler.com and del.icio.us, where users are connected with music groups
and bookmarks, respectively. The degree distributions and degree-degree
correlations for both users and objects are reported. We propose a new index,
named collaborative clustering coefficient, to quantify the clustering behavior
based on the collaborative selection. Accordingly, the clustering properties
and clustering-degree correlations are investigated. We report some novel
phenomena well characterizing the selection mechanism of web users and outline
the relevance of these phenomena to the information recommendation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4950</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4950</id><created>2009-09-27</created><updated>2010-08-26</updated><authors><author><keyname>Dotsenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Vejdemo-Johansson</keyname><forenames>Mikael</forenames></author></authors><title>Implementing Gr\&quot;obner bases for operads</title><categories>cs.SC cs.MS math.QA</categories><comments>18 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an implementation of the algorithm for computing Groebner bases
for operads due to the first author and A. Khoroshkin. We discuss the actual
algorithms, the choices made for the implementation platform and the data
representation, and strengths and weaknesses of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4955</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4955</id><created>2009-09-27</created><updated>2009-11-13</updated><authors><author><keyname>Alcazar</keyname><forenames>Juan Gerardo</forenames></author></authors><title>On the Different Shapes Arising in a Family of Rational Curves Depending
  on a Parameter</title><categories>cs.SC cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a family of rational curves depending on a real parameter, defined by
its parametric equations, we provide an algorithm to compute a finite partition
of the parameter space (${\Bbb R}$, in general) so that the shape of the family
stays invariant along each element of the partition. So, from this partition
the topology types in the family can be determined. The algorithm is based on a
geometric interpretation of previous work (\cite{JGRS}) for the implicit case.
However, in our case the algorithm works directly with the parametrization of
the family, and the implicit equation does not need to be computed. Timings
comparing the algorithm in the implicit and the parametric cases are given;
these timings show that the parametric algorithm developed here provides in
general better results than the known algorithm for the implicit case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4956</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4956</id><created>2009-09-27</created><authors><author><keyname>Alcazar</keyname><forenames>Juan Gerardo</forenames></author></authors><title>Local Shape of Generalized Offsets to Algebraic Curves</title><categories>cs.SC cs.MS</categories><comments>19 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the local behavior of an algebraic curve under a
geometric construction which is a variation of the usual offsetting
construction, namely the {\it generalized} offsetting process (\cite {SS99}).
More precisely, here we discuss when and how this geometric construction may
cause local changes in the shape of an algebraic curve, and we compare our
results with those obtained for the case of classical offsets (\cite{JGS07}).
For these purposes, we use well-known notions of Differential Geometry, and
also the notion of {\it local shape} introduced in \cite{JGS07}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4969</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4969</id><created>2009-09-27</created><authors><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>MACH: Fast Randomized Tensor Decompositions</title><categories>cs.DS</categories><comments>15 pages, 4 Tables, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensors naturally model many real world processes which generate multi-aspect
data. Such processes appear in many different research disciplines, e.g,
chemometrics, computer vision, psychometrics and neuroimaging analysis. Tensor
decompositions such as the Tucker decomposition are used to analyze
multi-aspect data and extract latent factors, which capture the multilinear
data structure. Such decompositions are powerful mining tools, for extracting
patterns from large data volumes. However, most frequently used algorithms for
such decompositions involve the computationally expensive Singular Value
Decomposition.
  In this paper we propose MACH, a new sampling algorithm to compute such
decompositions. Our method is of significant practical value for tensor
streams, such as environmental monitoring systems, IP traffic matrices over
time, where large amounts of data are accumulated and the analysis is
computationally intensive but also in &quot;post-mortem&quot; data analysis cases where
the tensor does not fit in the available memory. We provide the theoretical
analysis of our proposed method, and verify its efficacy in monitoring system
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4983</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4983</id><created>2009-09-27</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Kim</keyname><forenames>Dongku</forenames></author></authors><title>Event-Driven Optimal Feedback Control for Multi-Antenna Beamforming</title><categories>cs.IT math.IT</categories><comments>29 pages; submitted for publication</comments><doi>10.1109/TSP.2010.2045426</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmit beamforming is a simple multi-antenna technique for increasing
throughput and the transmission range of a wireless communication system. The
required feedback of channel state information (CSI) can potentially result in
excessive overhead especially for high mobility or many antennas. This work
concerns efficient feedback for transmit beamforming and establishes a new
approach of controlling feedback for maximizing net throughput, defined as
throughput minus average feedback cost. The feedback controller using a
stationary policy turns CSI feedback on/off according to the system state that
comprises the channel state and transmit beamformer. Assuming channel isotropy
and Markovity, the controller's state reduces to two scalars. This allows the
optimal control policy to be efficiently computed using dynamic programming.
Consider the perfect feedback channel free of error, where each feedback
instant pays a fixed price. The corresponding optimal feedback control policy
is proved to be of the threshold type. This result holds regardless of whether
the controller's state space is discretized or continuous. Under the
threshold-type policy, feedback is performed whenever a state variable
indicating the accuracy of transmit CSI is below a threshold, which varies with
channel power. The practical finite-rate feedback channel is also considered.
The optimal policy for quantized feedback is proved to be also of the threshold
type. The effect of CSI quantization is shown to be equivalent to an increment
on the feedback price. Moreover, the increment is upper bounded by the expected
logarithm of one minus the quantization error. Finally, simulation shows that
feedback control increases net throughput of the conventional periodic feedback
by up to 0.5 bit/s/Hz without requiring additional bandwidth or antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.4995</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.4995</id><created>2009-09-27</created><authors><author><keyname>Jankovic</keyname><forenames>Marko V.</forenames></author></authors><title>Geometrical Interpretation of Shannon's Entropy Based on the Born Rule</title><categories>cs.IT cs.NE math.IT math.PR physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will analyze discrete probability distributions in which
probabilities of particular outcomes of some experiment (microstates) can be
represented by the ratio of natural numbers (in other words, probabilities are
represented by digital numbers of finite representation length). We will
introduce several results that are based on recently proposed JoyStick
Probability Selector, which represents a geometrical interpretation of the
probability based on the Born rule. The terms of generic space and generic
dimension of the discrete distribution, as well as, effective dimension are
going to be introduced. It will be shown how this simple geometric
representation can lead to an optimal code length coding of the sequence of
signals. Then, we will give a new, geometrical, interpretation of the Shannon
entropy of the discrete distribution. We will suggest that the Shannon entropy
represents the logarithm of the effective dimension of the distribution.
Proposed geometrical interpretation of the Shannon entropy can be used to prove
some information inequalities in an elementary way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5000</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5000</id><created>2009-09-28</created><authors><author><keyname>Mhaskar</keyname><forenames>H. N.</forenames></author></authors><title>Eignets for function approximation on manifolds</title><categories>cs.LG cs.NA cs.NE</categories><comments>28 pages. Articles in press; Applied and Computational Harmonic
  Analysis, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\XX$ be a compact, smooth, connected, Riemannian manifold without
boundary, $G:\XX\times\XX\to \RR$ be a kernel. Analogous to a radial basis
function network, an eignet is an expression of the form $\sum_{j=1}^M
a_jG(\circ,y_j)$, where $a_j\in\RR$, $y_j\in\XX$, $1\le j\le M$. We describe a
deterministic, universal algorithm for constructing an eignet for approximating
functions in $L^p(\mu;\XX)$ for a general class of measures $\mu$ and kernels
$G$. Our algorithm yields linear operators. Using the minimal separation
amongst the centers $y_j$ as the cost of approximation, we give modulus of
smoothness estimates for the degree of approximation by our eignets, and show
by means of a converse theorem that these are the best possible for every
\emph{individual function}. We also give estimates on the coefficients $a_j$ in
terms of the norm of the eignet. Finally, we demonstrate that if any sequence
of eignets satisfies the optimal estimates for the degree of approximation of a
smooth function, measured in terms of the minimal separation, then the
derivatives of the eignets also approximate the corresponding derivatives of
the target function in an optimal manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5006</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5006</id><created>2009-09-28</created><updated>2009-10-03</updated><authors><author><keyname>Maddah-Ali</keyname><forenames>Mohammad Ali</forenames></author></authors><title>On the Degrees of Freedom of the Compound MIMO Broadcast Channels with
  Finite States</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-antenna broadcast channels with $M$ transmit antennas and $K$
single-antenna receivers is considered, where the channel of receiver $r$ takes
one of the $J_r$ finite values. It is assumed that the channel states of each
receiver are randomly selected from $\mathds{R}^{M\times 1}$ (or from
$\mathds{C}^{M\times 1}$). It is shown that no matter what $J_r$ is, the
degrees of freedom (DoF) of $\frac{MK}{M+K-1}$ is achievable. The achievable
scheme relies on the idea of interference alignment at receivers, without
exploiting the possibility of cooperation among transmit antennas. It is proven
that if $J_r \geq M$, $r=1,...,K$, this scheme achieves the optimal DoF. This
results implies that when the uncertainty of the base station about the channel
realization is considerable, the system loses the gain of cooperation. However,
it still benefits from the gain of interference alignment. In fact, in this
case, the compound broadcast channel is treated as a compound X channel.
  Moreover, it is shown that when the base station knows the channel states of
some of the receivers, a combination of transmit cooperation and interference
alignment would achieve the optimal DoF.
  Like time-invariant $K$-user interference channels, the naive vector-space
approaches of interference management seem insufficient to achieve the optimal
DoF of this channel. In this paper, we use the Number-Theory approach of
alignment, recently developed by Motahari et al.[1]. We extend the approach of
[1] to complex channels as well, therefore all the results that we present are
valid for both real and complex channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5007</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5007</id><created>2009-09-28</created><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Sung</keyname><forenames>Chi Wan</forenames></author></authors><title>Achieving Capacity of Bi-Directional Tandem Collision Network by Joint
  Medium-Access Control and Channel-Network Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ALOHA-type packetized network, the transmission times of packets follow a
stochastic process. In this paper, we advocate a deterministic approach for
channel multiple-access. Each user is statically assigned a periodic protocol
signal, which takes value either zero or one, and transmit packets whenever the
value of the protocol signal is equal to one. On top of this multiple-access
protocol, efficient channel coding and network coding schemes are devised. We
illustrate the idea by constructing a transmission scheme for the tandem
collision network, for both slot-synchronous and slot-asynchronous systems.
This cross-layer approach is able to achieve the capacity region when the
network is bi-directional.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5011</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5011</id><created>2009-09-28</created><updated>2009-10-19</updated><authors><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author><author><keyname>Tan</keyname><forenames>Li-Yang</forenames></author></authors><title>Average sensitivity and noise sensitivity of polynomial threshold
  functions</title><categories>cs.CC cs.DM</categories><comments>added proofs for non-multilinear PTFs over Gaussian random variables,
  added discussion section</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first non-trivial upper bounds on the average sensitivity and
noise sensitivity of degree-$d$ polynomial threshold functions (PTFs). These
bounds hold both for PTFs over the Boolean hypercube and for PTFs over $\R^n$
under the standard $n$-dimensional Gaussian distribution. Our bound on the
Boolean average sensitivity of PTFs represents progress towards the resolution
of a conjecture of Gotsman and Linial \cite{GL:94}, which states that the
symmetric function slicing the middle $d$ layers of the Boolean hypercube has
the highest average sensitivity of all degree-$d$ PTFs. Via the $L_1$
polynomial regression algorithm of Kalai et al. \cite{KKMS:08}, our bounds on
Gaussian and Boolean noise sensitivity yield polynomial-time agnostic learning
algorithms for the broad class of constant-degree PTFs under these input
distributions.
  The main ingredients used to obtain our bounds on both average and noise
sensitivity of PTFs in the Gaussian setting are tail bounds and
anti-concentration bounds on low-degree polynomials in Gaussian random
variables \cite{Janson:97,CW:01}. To obtain our bound on the Boolean average
sensitivity of PTFs, we generalize the ``critical-index'' machinery of
\cite{Servedio:07cc} (which in that work applies to halfspaces, i.e. degree-1
PTFs) to general PTFs. Together with the &quot;invariance principle&quot; of
\cite{MOO:05}, this lets us extend our techniques from the Gaussian setting to
the Boolean setting. Our bound on Boolean noise sensitivity is achieved via a
simple reduction from upper bounds on average sensitivity of Boolean PTFs to
corresponding bounds on noise sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5012</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5012</id><created>2009-09-28</created><authors><author><keyname>Scemama</keyname><forenames>Anthony</forenames></author></authors><title>IRPF90: a programming environment for high performance computing</title><categories>cs.SE cs.CE</categories><comments>18 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IRPF90 is a Fortran programming environment which helps the development of
large Fortran codes. In Fortran programs, the programmer has to focus on the
order of the instructions: before using a variable, the programmer has to be
sure that it has already been computed in all possible situations. For large
codes, it is common source of error. In IRPF90 most of the order of
instructions is handled by the pre-processor, and an automatic mechanism
guarantees that every entity is built before being used. This mechanism relies
on the {needs/needed by} relations between the entities, which are built
automatically. Codes written with IRPF90 execute often faster than Fortran
programs, are faster to write and easier to maintain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5029</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5029</id><created>2009-09-28</created><authors><author><keyname>Thielen</keyname><forenames>Clemens</forenames></author><author><keyname>Krumke</keyname><forenames>Sven O.</forenames></author></authors><title>Complexity of Strong Implementability</title><categories>cs.CC cs.GT</categories><journal-ref>EPTCS 4, 2009, pp. 1-12</journal-ref><doi>10.4204/EPTCS.4.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the question of implementability of a social choice function in a
classical setting where the preferences of finitely many selfish individuals
with private information have to be aggregated towards a social choice. This is
one of the central questions in mechanism design. If the concept of weak
implementation is considered, the Revelation Principle states that one can
restrict attention to truthful implementations and direct revelation
mechanisms, which implies that implementability of a social choice function is
easy to check. For the concept of strong implementation, however, the
Revelation Principle becomes invalid, and the complexity of deciding whether a
given social choice function is strongly implementable has been open so far. In
this paper, we show by using methods from polyhedral theory that strong
implementability of a social choice function can be decided in polynomial space
and that each of the payments needed for strong implementation can always be
chosen to be of polynomial encoding length. Moreover, we show that strong
implementability of a social choice function involving only a single selfish
individual can be decided in polynomial time via linear programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5032</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5032</id><created>2009-09-28</created><authors><author><keyname>Bretto</keyname><forenames>Alain</forenames><affiliation>University of Caen</affiliation></author><author><keyname>Silvestre</keyname><forenames>Yannick</forenames><affiliation>University of Caen</affiliation></author><author><keyname>Vall&#xe9;e</keyname><forenames>Thierry</forenames><affiliation>University of Caen</affiliation></author></authors><title>Cartesian product of hypergraphs: properties and algorithms</title><categories>cs.DM cs.DS</categories><journal-ref>EPTCS 4, 2009, pp. 22-28</journal-ref><doi>10.4204/EPTCS.4.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cartesian products of graphs have been studied extensively since the 1960s.
They make it possible to decrease the algorithmic complexity of problems by
using the factorization of the product. Hypergraphs were introduced as a
generalization of graphs and the definition of Cartesian products extends
naturally to them. In this paper, we give new properties and algorithms
concerning coloring aspects of Cartesian products of hypergraphs. We also
extend a classical prime factorization algorithm initially designed for graphs
to connected conformal hypergraphs using 2-sections of hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5033</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5033</id><created>2009-09-28</created><authors><author><keyname>Papalamprou</keyname><forenames>Konstantinos</forenames><affiliation>London School of Economics</affiliation></author><author><keyname>Pitsoulis</keyname><forenames>Leonidas</forenames><affiliation>Aristotle University of Thessaloniki</affiliation></author></authors><title>Regular Matroids with Graphic Cocircuits</title><categories>cs.DM</categories><journal-ref>EPTCS 4, 2009, pp. 29-41</journal-ref><doi>10.4204/EPTCS.4.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of graphic cocircuits and show that a large class of
regular matroids with graphic cocircuits belongs to the class of signed-graphic
matroids. Moreover, we provide an algorithm which determines whether a
cographic matroid with graphic cocircuits is signed-graphic or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5038</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5038</id><created>2009-09-28</created><authors><author><keyname>Tveretina</keyname><forenames>Olga</forenames><affiliation>Karlsruhe University</affiliation></author><author><keyname>Sinz</keyname><forenames>Carsten</forenames><affiliation>Karlsruhe University</affiliation></author><author><keyname>Zantema</keyname><forenames>Hans</forenames><affiliation>Technical University of Eindhoven, Radboud University of Nijmegen</affiliation></author></authors><title>An Exponential Lower Bound on OBDD Refutations for Pigeonhole Formulas</title><categories>cs.CC cs.LO</categories><journal-ref>EPTCS 4, 2009, pp. 13-21</journal-ref><doi>10.4204/EPTCS.4.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Haken proved that every resolution refutation of the pigeonhole formula has
at least exponential size. Groote and Zantema proved that a particular OBDD
computation of the pigeonhole formula has an exponential size. Here we show
that any arbitrary OBDD refutation of the pigeonhole formula has an exponential
size, too: we prove that the size of one of the intermediate OBDDs is at least
$\Omega(1.025^n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5045</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5045</id><created>2009-09-28</created><authors><author><keyname>Polonowski</keyname><forenames>Emmanuel</forenames></author></authors><title>Deriving SN from PSN: a general proof technique</title><categories>cs.LO</categories><report-no>TR-LACL-2006-5</report-no><journal-ref>TR-LACL (2006) 1-50</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the framework of explicit substitutions there is two termination
properties: preservation of strong normalization (PSN), and strong
normalization (SN). Since there are not easily proved, only one of them is
usually established (and sometimes none). We propose here a connection between
them which helps to get SN when one already has PSN. For this purpose, we
formalize a general proof technique of SN which consists in expanding
substitutions into &quot;pure&quot; lambda-terms and to inherit SN of the whole calculus
by SN of the &quot;pure&quot; calculus and by PSN. We apply it successfully to a large
set of calculi with explicit substitutions, allowing us to establish SN, or, at
least, to trace back the failure of SN to that of PSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5064</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5064</id><created>2009-09-28</created><authors><author><keyname>B&#xe1;tfai</keyname><forenames>Norbert</forenames></author></authors><title>A Conceivable Origin of Machine Consciousness in the IDLE process</title><categories>cs.OS cs.DC</categories><comments>4 pages</comments><acm-class>D.4.7; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short paper, we would like to call professional community's attention
to a daring idea that is surely unhelpful, but is exciting for programmers and
anyway conflicts with the trend of energy consumption in computer systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5087</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5087</id><created>2009-09-28</created><authors><author><keyname>Di Ruscio</keyname><forenames>Davide</forenames><affiliation>UNIVAQ</affiliation></author><author><keyname>Pelliccione</keyname><forenames>Patrizio</forenames><affiliation>UNIVAQ</affiliation></author><author><keyname>Pierantonio</keyname><forenames>Alfonso</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author></authors><title>Towards maintainer script modernization in FOSS distributions</title><categories>cs.SE</categories><proxy>ccsd hal-00420061</proxy><acm-class>D.2.10; I.6.5; D.2.13</acm-class><journal-ref>IWOCE 2009: 1st international workshop on Open component
  ecosystems, Amsterdam : Netherlands (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free and Open Source Software (FOSS) distributions are complex software
systems, made of thousands packages that evolve rapidly, independently, and
without centralized coordination. During packages upgrades, corner case
failures can be encountered and are hard to deal with, especially when they are
due to misbehaving maintainer scripts: executable code snippets used to
finalize package configuration. In this paper we report a software
modernization experience, the process of representing existing legacy systems
in terms of models, applied to FOSS distributions. We present a process to
define meta-models that enable dealing with upgrade failures and help rolling
back from them, taking into account maintainer scripts. The process has been
applied to widely used FOSS distributions and we report about such experiences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5091</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5091</id><created>2009-09-28</created><authors><author><keyname>Treinen</keyname><forenames>Ralf</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author></authors><title>Expressing advanced user preferences in component installation</title><categories>cs.SE</categories><proxy>ccsd hal-00420065</proxy><acm-class>K.6.3; D.2.9</acm-class><journal-ref>IWOCE 2009: 1st international workshop on Open component
  ecosystems, Amsterdam : Netherlands (2009)</journal-ref><doi>10.1145/1595800.1595806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State of the art component-based software collections - such as FOSS
distributions - are made of up to dozens of thousands components, with complex
inter-dependencies and conflicts. Given a particular installation of such a
system, each request to alter the set of installed components has potentially
(too) many satisfying answers. We present an architecture that allows to
express advanced user preferences about package selection in FOSS
distributions. The architecture is composed by a distribution-independent
format for describing available and installed packages called CUDF (Common
Upgradeability Description Format), and a foundational language called MooML to
specify optimization criteria. We present the syntax and semantics of CUDF and
MooML, and discuss the partial evaluation mechanism of MooML which allows to
gain efficiency in package dependency solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5097</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5097</id><created>2009-09-28</created><updated>2013-03-18</updated><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames><affiliation>Durham University, UK.</affiliation></author><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames><affiliation>CNRS/LIX, Ecole Polytechnique, France</affiliation></author><author><keyname>Hils</keyname><forenames>Martin</forenames><affiliation>Equipe de Logique Mathematique, Universite Paris Diderot - Paris 7, France</affiliation></author></authors><title>On the Scope of the Universal-Algebraic Approach to Constraint
  Satisfaction</title><categories>cs.LO cs.AI cs.CC</categories><comments>Extended abstract appeared at 25th Symposium on Logic in Computer
  Science (LICS 2010). This version will appear in the LMCS special issue
  associated with LICS 2010</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  12, 2012) lmcs:674</journal-ref><doi>10.2168/LMCS-8(3:13)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The universal-algebraic approach has proved a powerful tool in the study of
the complexity of CSPs. This approach has previously been applied to the study
of CSPs with finite or (infinite) omega-categorical templates, and relies on
two facts. The first is that in finite or omega-categorical structures A, a
relation is primitive positive definable if and only if it is preserved by the
polymorphisms of A. The second is that every finite or omega-categorical
structure is homomorphically equivalent to a core structure. In this paper, we
present generalizations of these facts to infinite structures that are not
necessarily omega-categorical. (This abstract has been severely curtailed by
the space constraints of arXiv -- please read the full abstract in the
article.) Finally, we present applications of our general results to the
description and analysis of the complexity of CSPs. In particular, we give
general hardness criteria based on the absence of polymorphisms that depend on
more than one argument, and we present a polymorphism-based description of
those CSPs that are first-order definable (and therefore can be solved in
polynomial time).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5099</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5099</id><created>2009-09-28</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Breaking Generator Symmetry</title><categories>cs.AI cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dealing with large numbers of symmetries is often problematic. One solution
is to focus on just symmetries that generate the symmetry group. Whilst there
are special cases where breaking just the symmetries in a generating set is
complete, there are also cases where no irredundant generating set eliminates
all symmetry. However, focusing on just generators improves tractability. We
prove that it is polynomial in the size of the generating set to eliminate all
symmetric solutions, but NP-hard to prune all symmetric values. Our proof
considers row and column symmetry, a common type of symmetry in matrix models
where breaking just generator symmetries is very effective. We show that
propagating a conjunction of lexicographical ordering constraints on the rows
and columns of a matrix of decision variables is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5119</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5119</id><created>2009-09-28</created><authors><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Random Access Transport Capacity</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Wireless Communications, Sept. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new metric for quantifying end-to-end throughput in multihop
wireless networks, which we term random access transport capacity, since the
interference model presumes uncoordinated transmissions. The metric quantifies
the average maximum rate of successful end-to-end transmissions, multiplied by
the communication distance, and normalized by the network area. We show that a
simple upper bound on this quantity is computable in closed-form in terms of
key network parameters when the number of retransmissions is not restricted and
the hops are assumed to be equally spaced on a line between the source and
destination. We also derive the optimum number of hops and optimal per hop
success probability and show that our result follows the well-known square root
scaling law while providing exact expressions for the preconstants as well.
Numerical results demonstrate that the upper bound is accurate for the purpose
of determining the optimal hop count and success (or outage) probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5120</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5120</id><created>2009-09-28</created><authors><author><keyname>Amariucai</keyname><forenames>George</forenames></author><author><keyname>Wei</keyname><forenames>Shuangqing</forenames></author></authors><title>Feedback-Based Collaborative Secrecy Encoding over Binary Symmetric
  Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a feedback scheme for transmitting secret messages
between two legitimate parties, over an eavesdropped communication link.
Relative to Wyner's traditional encoding scheme \cite{wyner1}, our
feedback-based encoding often yields larger rate-equivocation regions and
achievable secrecy rates. More importantly, by exploiting the channel
randomness inherent in the feedback channels, our scheme achieves a strictly
positive secrecy rate even when the eavesdropper's channel is less noisy than
the legitimate receiver's channel. All channels are modeled as binary and
symmetric (BSC). We demonstrate the versatility of our feedback-based encoding
method by using it in three different configurations: the stand-alone
configuration, the mixed configuration (when it combines with Wyner's scheme
\cite{wyner1}), and the reversed configuration. Depending on the channel
conditions, significant improvements over Wyner's secrecy capacity can be
observed in all configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5146</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5146</id><created>2009-09-28</created><updated>2010-03-11</updated><authors><author><keyname>Cohen</keyname><forenames>Hagai</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author></authors><title>Fast Set Intersection and Two Patterns Matching</title><categories>cs.DS</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new problem, the fast set intersection problem,
which is to preprocess a collection of sets in order to efficiently report the
intersection of any two sets in the collection. In addition we suggest new
solutions for the two-dimensional substring indexing problem and the document
listing problem for two patterns by reduction to the fast set intersection
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5166</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5166</id><created>2009-09-28</created><authors><author><keyname>Khare</keyname><forenames>Neelu</forenames></author><author><keyname>Adlakha</keyname><forenames>Neeru</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author></authors><title>An Algorithm for Mining Multidimensional Fuzzy Association Rules</title><categories>cs.IR cs.DB</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 72-76, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional association rule mining searches for interesting
relationship among the values from different dimensions or attributes in a
relational database. In this method the correlation is among set of dimensions
i.e., the items forming a rule come from different dimensions. Therefore each
dimension should be partitioned at the fuzzy set level. This paper proposes a
new algorithm for generating multidimensional association rules by utilizing
fuzzy sets. A database consisting of fuzzy transactions, the Apriory property
is employed to prune the useless candidates, itemsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5175</identifier>
 <datestamp>2014-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5175</id><created>2009-09-28</created><updated>2009-11-09</updated><authors><author><keyname>Harsha</keyname><forenames>Prahladh</forenames></author><author><keyname>Klivans</keyname><forenames>Adam</forenames></author><author><keyname>Meka</keyname><forenames>Raghu</forenames></author></authors><title>Bounding the Sensitivity of Polynomial Threshold Functions</title><categories>cs.CC cs.LG</categories><comments>Fixed an important flaw. Some proofs are simplified from last version</comments><journal-ref>Theory of Computing, 10(1):1-26, 2013</journal-ref><doi>10.4086/toc.2014.v010a001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first non-trivial upper bounds on the average sensitivity and
noise sensitivity of polynomial threshold functions. More specifically, for a
Boolean function f on n variables equal to the sign of a real, multivariate
polynomial of total degree d we prove
  1) The average sensitivity of f is at most O(n^{1-1/(4d+6)}) (we also give a
combinatorial proof of the bound O(n^{1-1/2^d}).
  2) The noise sensitivity of f with noise rate \delta is at most
O(\delta^{1/(4d+6)}).
  Previously, only bounds for the linear case were known. Along the way we show
new structural theorems about random restrictions of polynomial threshold
functions obtained via hypercontractivity. These structural results may be of
independent interest as they provide a generic template for transforming
problems related to polynomial threshold functions defined on the Boolean
hypercube to polynomial threshold functions defined in Gaussian space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5177</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5177</id><created>2009-09-28</created><updated>2010-01-27</updated><authors><author><keyname>Shen</keyname><forenames>Godwin</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Transform-based Distributed Data Gathering</title><categories>cs.DC</categories><doi>10.1109/TSP.2010.2047640</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general class of unidirectional transforms is presented that can be
computed in a distributed manner along an arbitrary routing tree. Additionally,
we provide a set of conditions under which these transforms are invertible.
These transforms can be computed as data is routed towards the collection (or
sink) node in the tree and exploit data correlation between nodes in the tree.
Moreover, when used in wireless sensor networks, these transforms can also
leverage data received at nodes via broadcast wireless communications. Various
constructions of unidirectional transforms are also provided for use in data
gathering in wireless sensor networks. New wavelet transforms are also proposed
which provide significant improvements over existing unidirectional transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5179</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5179</id><created>2009-09-28</created><authors><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Expected RIP: Conditioning of The Modulated Wideband Converter</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear ITW'09</comments><report-no>CCIT Report #736 July-09, EE Pub No. 1693, EE Dept., Technion -
  Israel Institute of Technology</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sensing matrix of a compressive system impacts the stability of the
associated sparse recovery problem. In this paper, we study the sensing matrix
of the modulated wideband converter, a recently proposed system for sub-Nyquist
sampling of analog sparse signals. Attempting to quantify the conditioning of
the converter sensing matrix with existing approaches leads to unreasonable
rate requirements, due to the relatively small size of this matrix. We propose
a new conditioning criterion, named the expected restricted isometry property,
and derive theoretical guarantees for the converter to satisfy this property.
We then show that applying these conditions to popular binary sequences, such
as maximal codes or Gold codes, leads to practical rate requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5216</identifier>
 <datestamp>2010-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5216</id><created>2009-09-28</created><updated>2010-01-04</updated><authors><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Willsky</keyname><forenames>Alan S.</forenames></author></authors><title>Learning Gaussian Tree Models: Analysis of Error Exponents and Extremal
  Structures</title><categories>stat.ML cs.IT math.IT math.ST stat.TH</categories><comments>Submitted to Transactions on Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, May 2010, Volume: 58
  Issue:5, pages 2701 - 2714</journal-ref><doi>10.1109/TSP.2010.2042478</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of learning tree-structured Gaussian graphical models from
independent and identically distributed (i.i.d.) samples is considered. The
influence of the tree structure and the parameters of the Gaussian distribution
on the learning rate as the number of samples increases is discussed.
Specifically, the error exponent corresponding to the event that the estimated
tree structure differs from the actual unknown tree structure of the
distribution is analyzed. Finding the error exponent reduces to a least-squares
problem in the very noisy learning regime. In this regime, it is shown that the
extremal tree structure that minimizes the error exponent is the star for any
fixed set of correlation coefficients on the edges of the tree. If the
magnitudes of all the correlation coefficients are less than 0.63, it is also
shown that the tree structure that maximizes the error exponent is the Markov
chain. In other words, the star and the chain graphs represent the hardest and
the easiest structures to learn in the class of tree-structured Gaussian
graphical models. This result can also be intuitively explained by correlation
decay: pairs of nodes which are far apart, in terms of graph distance, are
unlikely to be mistaken as edges by the maximum-likelihood estimator in the
asymptotic regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5224</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5224</id><created>2009-09-28</created><updated>2013-06-11</updated><authors><author><keyname>Efthymiou</keyname><forenames>Charilaos</forenames></author></authors><title>Deterministic counting of graph colourings using sequences of subgraphs</title><categories>cs.DM</categories><acm-class>G.2.1; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a deterministic algorithm for approximately counting
the $k$-colourings of sparse random graphs $G(n,d/n)$. In particular, our
algorithm computes in polynomial time a $(1\pm n^{-\Omega(1)})$approximation of
the logarithm of the number of $k$-colourings of $G(n,d/n)$ for $k\geq
(2+\epsilon) d$ with high probability over the graph instances.
  Our algorithm is related to the algorithms of A. Bandyopadhyay et al. in SODA
'06, and A. Montanari et al. in SODA '06, i.e. it uses {\em spatial correlation
decay} to compute {\em deterministically} marginals of {\em Gibbs
distribution}. We develop a scheme whose accuracy depends on {\em
non-reconstruction} of the colourings of $G(n,d/n)$, rather than {\em
uniqueness} that are required in previous works. This leaves open the
possibility for our schema to be sufficiently accurate even for $k&lt;d$.
  The set up for establishing correlation decay is as follows: Given
$G(n,d/n)$, we alter the graph structure in some specific region $\Lambda$ of
the graph by deleting edges between vertices of $\Lambda$. Then we show that
the effect of this change on the marginals of Gibbs distribution, diminishes as
we move away from $\Lambda$. Our approach is novel and suggests a new context
for the study of deterministic counting algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5263</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5263</id><created>2009-09-29</created><updated>2010-02-18</updated><authors><author><keyname>Zhou</keyname><forenames>Jinglong</forenames></author><author><keyname>Rao</keyname><forenames>Vijay S.</forenames></author><author><keyname>Pawe&#x142;czak</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Wu</keyname><forenames>Daniel</forenames></author><author><keyname>Mohapatra</keyname><forenames>Prasant</forenames></author></authors><title>Practical Rate and Route Adaptation with Efficient Link Quality
  Estimation for IEEE 802.11b/g Multi-Hop Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and fast packet delivery rate (PDR) estimation, used in evaluating
wireless link quality, is a prerequisite to increase the performance of mobile,
multi-hop and multi-rate wireless ad hoc networks. Unfortunately, contemporary
PDR estimation methods, i.e. beacon-based packet counting in Estimated
Transmission Time and Expected Transmission Count metrics, have unsatisfactory
performance. Therefore, in this paper we propose a novel PDR estimation method
based on SNR profiles. We classify all possible link quality estimation methods
and compare them analytically against our design. Results show that it leads to
a more efficient link quality estimation. Further investigations with the
prototype implementation of our method in IEEE 802.11b/g testbeds reveal that
the accuracy of PDR estimation in mobile scenarios can be improved up to 50% in
comparison to generic packet-based PDR. Experiments with the same prototype on
link and routing layers for different measurement scenarios show that it leads
to a better rate adaptation and route selection in the form of end-to-end
throughput increase compared to traditional packet counting methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5268</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5268</id><created>2009-09-29</created><updated>2010-02-04</updated><authors><author><keyname>Shenvi</keyname><forenames>Sagar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>A Simple Necessary and Sufficient Condition for the Double Unicast
  Problem</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures. Revised Version. Final manuscript for ICC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a directed acyclic network where there are two source-terminal
pairs and the terminals need to receive the symbols generated at the respective
sources. Each source independently generates an i.i.d. random process over the
same alphabet. Each edge in the network is error-free, delay-free, and can
carry one symbol from the alphabet per use. We give a simple necessary and
sufficient condition for being able to simultaneously satisfy the unicast
requirements of the two source-terminal pairs at rate-pair $(1,1)$ using vector
network coding. The condition is also sufficient for doing this using only
&quot;XOR&quot; network coding and is much simpler compared to the necessary and
sufficient conditions known from previous work. Our condition also yields a
simple characterization of the capacity region of a double-unicast network
which does not support the rate-pair $(1,1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5271</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5271</id><created>2009-09-29</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Partial Komori fields and imperative Komori fields</title><categories>math.RA cs.LO</categories><comments>10 pages</comments><report-no>PRG0911</report-no><msc-class>12E99; 12L99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the status of 1/0 and ways to deal with it.
These matters are treated in the setting of Komori fields, also known as
non-trivial cancellation meadows. Different viewpoints on the status of 1/0
exist in mathematics and theoretical computer science. We give a simple account
of how mathematicians deal with 1/0 in which a customary convention among
mathematicians plays a prominent part, and we make plausible that a convincing
account, starting from the popular computer science viewpoint that 1/0 is
undefined, by means of some logic of partial functions is not attainable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5278</identifier>
 <datestamp>2009-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5278</id><created>2009-09-29</created><updated>2009-12-22</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Finding Induced Subgraphs via Minimal Triangulations</title><categories>cs.DS</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Potential maximal cliques and minimal separators are combinatorial objects
which were introduced and studied in the realm of minimal triangulations
problems including Minimum Fill-in and Treewidth. We discover unexpected
applications of these notions to the field of moderate exponential algorithms.
In particular, we show that given an n-vertex graph G together with its set of
potential maximal cliques Pi_G, and an integer t, it is possible in time |Pi_G|
* n^(O(t)) to find a maximum induced subgraph of treewidth t in G; and for a
given graph F of treewidth t, to decide if G contains an induced subgraph
isomorphic to F. Combined with an improved algorithm enumerating all potential
maximal cliques in time O(1.734601^n), this yields that both problems are
solvable in time 1.734601^n * n^(O(t)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5293</identifier>
 <datestamp>2009-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5293</id><created>2009-09-29</created><updated>2009-10-04</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Lachish</keyname><forenames>Oded</forenames></author><author><keyname>Paterson</keyname><forenames>Mike</forenames></author><author><keyname>Savani</keyname><forenames>Rahul</forenames></author></authors><title>Wiretapping a hidden network</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing the probability of hitting a
strategically chosen hidden virtual network by placing a wiretap on a single
link of a communication network. This can be seen as a two-player win-lose
(zero-sum) game that we call the wiretap game. The value of this game is the
greatest probability that the wiretapper can secure for hitting the virtual
network. The value is shown to equal the reciprocal of the strength of the
underlying graph.
  We efficiently compute a unique partition of the edges of the graph, called
the prime-partition, and find the set of pure strategies of the hider that are
best responses against every maxmin strategy of the wiretapper. Using these
special pure strategies of the hider, which we call
omni-connected-spanning-subgraphs, we define a partial order on the elements of
the prime-partition. From the partial order, we obtain a linear number of
simple two-variable inequalities that define the maxmin-polytope, and a
characterization of its extreme points.
  Our definition of the partial order allows us to find all equilibrium
strategies of the wiretapper that minimize the number of pure best responses of
the hider. Among these strategies, we efficiently compute the unique strategy
that maximizes the least punishment that the hider incurs for playing a pure
strategy that is not a best response. Finally, we show that this unique
strategy is the nucleolus of the recently studied simple cooperative spanning
connectivity game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5310</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5310</id><created>2009-09-29</created><authors><author><keyname>Hamza</keyname><forenames>Doha</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>Cognitive Power Control Under Correlated Fading and Primary-Link CSI</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, submitted to ICC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the cognitive power control problem of maximizing the secondary
throughput under an outage probability constraint on a constant-power
constant-rate primary link. We assume a temporally correlated primary channel
with two types of feedback: perfect delayed channel state information (CSI) and
one-bit automatic repeat request (ARQ). We use channel correlation to enhance
the primary and secondary throughput via exploiting the CSI feedback to predict
the future primary channel gain. We provide a numerical solution for the power
control optimization problem under delayed CSI. In order to make the solution
tractable under ARQ-CSI, we re-formulate the cognitive power control problem as
the maximization of the instantaneous weighted sum of primary and secondary
throughput. We propose a greedy ARQ-CSI algorithm that is shown to achieve an
average throughput comparable to that attained under the delayed-CSI algorithm,
which we solve optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5313</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5313</id><created>2009-09-29</created><updated>2010-02-03</updated><authors><author><keyname>Arvind</keyname><forenames>Vikraman</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>The Remote Point Problem, Small Bias Space, and Expanding Generator Sets</title><categories>cs.CC cs.DS</categories><comments>accepted to STACS 2010, conference version, 16 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Using $\epsilon$-bias spaces over $F_2$, we show that the Remote Point
Problem (RPP), introduced by Alon et al [APY09], has an $NC^2$ algorithm
(achieving the same parameters as [APY09]). We study a generalization of the
Remote Point Problem to groups: we replace $F^n$ by $G^n$ for an arbitrary
fixed group $G$. When $G$ is Abelian, we give an $NC^2$ algorithm for RPP,
again using $\epsilon$-bias spaces. For nonabelian $G$, we give a deterministic
polynomial-time algorithm for RPP. We also show the connection to construction
of expanding generator sets for the group $G^n$. All our algorithms for the RPP
achieve essentially the same parameters as [APY09].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5365</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5365</id><created>2009-09-29</created><authors><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Nadav</keyname><forenames>Uri</forenames></author></authors><title>Quasi-Proportional Mechanisms: Prior-free Revenue Maximization</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by Internet ad auction applications, we study the problem of
allocating a single item via an auction when bidders place very different
values on the item. We formulate this as the problem of prior-free auction and
focus on designing a simple mechanism that always allocates the item. Rather
than designing sophisticated pricing methods like prior literature, we design
better allocation methods. In particular, we propose quasi-proportional
allocation methods in which the probability that an item is allocated to a
bidder depends (quasi-proportionally) on the bids.
  We prove that corresponding games for both all-pay and winners-pay
quasi-proportional mechanisms admit pure Nash equilibria and this equilibrium
is unique. We also give an algorithm to compute this equilibrium in polynomial
time. Further, we show that the revenue of the auctioneer is promisingly high
compared to the ultimate, i.e., the highest value of any of the bidders, and
show bounds on the revenue of equilibria both analytically, as well as using
experiments for specific quasi-proportional functions. This is the first known
revenue analysis for these natural mechanisms (including the special case of
proportional mechanism which is common in network resource allocation
problems).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5388</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5388</id><created>2009-09-29</created><authors><author><keyname>Benbernou</keyname><forenames>Nadia</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Ovadya</keyname><forenames>Aviv</forenames></author></authors><title>A Universal Crease Pattern for Folding Orthogonal Shapes</title><categories>cs.CG</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a universal crease pattern--known in geometry as the tetrakis
tiling and in origami as box pleating--that can fold into any object made up of
unit cubes joined face-to-face (polycubes). More precisely, there is one
universal finite crease pattern for each number n of unit cubes that need to be
folded. This result contrasts previous universality results for origami, which
require a different crease pattern for each target object, and confirms
intuition in the origami community that box pleating is a powerful design
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5393</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5393</id><created>2009-09-29</created><authors><author><keyname>Lata</keyname><forenames>Kusum</forenames></author><author><keyname>Jamadagni</keyname><forenames>H S</forenames></author></authors><title>Formal Verification of Full-Wave Rectifier: A Case Study</title><categories>cs.LO</categories><comments>The IEEE 8th International Conference on ASIC (IEEE ASICON 2009),
  October 20-23 2009, Changsha, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a case study of formal verification of full-wave rectifier for
analog and mixed signal designs. We have used the Checkmate tool from CMU [1],
which is a public domain formal verification tool for hybrid systems. Due to
the restriction imposed by Checkmate it necessitates to make the changes in the
Checkmate implementation to implement the complex and non-linear system.
Full-wave rectifier has been implemented by using the Checkmate custom blocks
and the Simulink blocks from MATLAB from Math works. After establishing the
required changes in the Checkmate implementation we are able to efficiently
verify the safety properties of the full-wave rectifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5413</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5413</id><created>2009-09-29</created><authors><author><keyname>Yokota</keyname><forenames>Rio</forenames></author><author><keyname>Barba</keyname><forenames>L. A.</forenames></author><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author></authors><title>PetRBF--A parallel O(N) algorithm for radial basis function
  interpolation</title><categories>cs.MS cs.DC cs.NA</categories><comments>Submitted to Computer Methods in Applied Mechanics and Engineering</comments><journal-ref>Computer Methods in Applied Mechanics and Engineering, 199(25-28),
  pp. 1793-1804, 2010</journal-ref><doi>10.1016/j.cma.2010.02.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed a parallel algorithm for radial basis function (RBF)
interpolation that exhibits O(N) complexity,requires O(N) storage, and scales
excellently up to a thousand processes. The algorithm uses a GMRES iterative
solver with a restricted additive Schwarz method (RASM) as a preconditioner and
a fast matrix-vector algorithm. Previous fast RBF methods, --,achieving at most
O(NlogN) complexity,--, were developed using multiquadric and polyharmonic
basis functions. In contrast, the present method uses Gaussians with a small
variance (a common choice in particle methods for fluid simulation, our main
target application). The fast decay of the Gaussian basis function allows rapid
convergence of the iterative solver even when the subdomains in the RASM are
very small. The present method was implemented in parallel using the PETSc
library (developer version). Numerical experiments demonstrate its capability
in problems of RBF interpolation with more than 50 million data points, timing
at 106 seconds (19 iterations for an error tolerance of 10^-15 on 1024
processors of a Blue Gene/L (700 MHz PowerPC processors). The parallel code is
freely available in the open-source model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5417</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5417</id><created>2009-09-29</created><updated>2009-10-01</updated><authors><author><keyname>Wilson</keyname><forenames>Joey</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author></authors><title>Through-Wall Tracking Using Variance-Based Radio Tomography Networks</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for imaging, localizing, and tracking motion
behind walls in real-time. The method takes advantage of the motion-induced
variance of received signal strength measurements made in a wireless
peer-to-peer network. Using a multipath channel model, we show that the signal
strength on a wireless link is largely dependent on the power contained in
multipath components that travel through space containing moving objects. A
statistical model relating variance to spatial locations of movement is
presented and used as a framework for the estimation of a motion image. From
the motion image, the Kalman filter is applied to recursively track the
coordinates of a moving target. Experimental results for a 34-node through-wall
imaging and tracking system over a 780 square foot area are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5424</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5424</id><created>2009-09-29</created><updated>2011-01-23</updated><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Degrees of Freedom Regions of MIMO Broadcast, Interference, and
  Cognitive Radio Channels with No CSIT</title><categories>cs.IT math.IT</categories><comments>49 pages, 11 figures, under review, IEEE Trans. Inform. Th. Submitted
  Sept. 2009, Revised Jan. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees of freedom (DoF) regions are characterized for the multiple-input
multiple-output (MIMO) broadcast channel (BC), interference channels (IC)
(including X and multi-hop interference channels) and the cognitive radio
channel (CRC), when there is perfect and no channel state information at the
receivers and the transmitter(s) (CSIR and CSIT), respectively. For the K-user
MIMO BC, the exact characterization of the DoF region is obtained, which shows
that a simple time-division-based transmission scheme is DoF-region optimal.
Using the techniques developed for the MIMO BC, the corresponding problems for
the two-user MIMO IC and the CRC are addressed. For both of these channels,
inner and outer bounds to the DoF region are obtained and are seen to coincide
for a vast majority of the relative numbers of antennas at the four terminals,
thereby characterizing DoF regions for all but a few cases. Finally, the DoF
regions of the $K$-user MIMO IC, the CRC, and X networks are derived for
certain classes of these networks, including the one where all transmitters
have an equal number of antennas and so do all receivers. The results of this
paper are derived for distributions of fading channel matrices and additive
noises that are more general than those considered in other simultaneous
related works. The DoF regions with and without CSIT are compared and
conditions on the relative numbers of antennas at the terminals under which a
lack of CSIT does, or does not, result in the loss of DoF are identified,
thereby providing, on the one hand, simple and robust communication schemes
that don't require CSIT but have the same DoF performance as their previously
found CSIT counterparts, and on the other hand, identifying situations where
CSI feedback to transmitters would provide gains that are significant enough
that even the DoF performance could be improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5450</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5450</id><created>2009-09-29</created><authors><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Narasimhamurthy</keyname><forenames>Adarsh B.</forenames></author></authors><title>Robust Distributed Estimation over Multiple Access Channels with
  Constant Modulus Signaling</title><categories>cs.IT math.IT</categories><comments>28 pages, 10 figures, submitted to IEEE Transactions on Signal
  Processing for consideration</comments><doi>10.1109/TSP.2010.2051432</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed estimation scheme where the sensors transmit with constant
modulus signals over a multiple access channel is considered. The proposed
estimator is shown to be strongly consistent for any sensing noise distribution
in the i.i.d. case both for a per-sensor power constraint, and a total power
constraint. When the distributions of the sensing noise are not identical, a
bound on the variances is shown to establish strong consistency. The estimator
is shown to be asymptotically normal with a variance (AsV) that depends on the
characteristic function of the sensing noise. Optimization of the AsV is
considered with respect to a transmission phase parameter for a variety of
noise distributions exhibiting differing levels of impulsive behavior. The
robustness of the estimator to impulsive sensing noise distributions such as
those with positive excess kurtosis, or those that do not have finite moments
is shown. The proposed estimator is favorably compared with the amplify and
forward scheme under an impulsive noise scenario. The effect of fading is shown
to not affect the consistency of the estimator, but to scale the asymptotic
variance by a constant fading penalty depending on the fading statistics.
Simulations corroborate our analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5457</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5457</id><created>2009-09-30</created><updated>2009-10-19</updated><authors><author><keyname>Meka</keyname><forenames>Raghu</forenames></author><author><keyname>Jain</keyname><forenames>Prateek</forenames></author><author><keyname>Dhillon</keyname><forenames>Inderjit S.</forenames></author></authors><title>Guaranteed Rank Minimization via Singular Value Projection</title><categories>cs.LG cs.IT math.IT</categories><comments>An earlier version of this paper was submitted to NIPS-2009 on June
  5, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimizing the rank of a matrix subject to affine constraints is a
fundamental problem with many important applications in machine learning and
statistics. In this paper we propose a simple and fast algorithm SVP (Singular
Value Projection) for rank minimization with affine constraints (ARMP) and show
that SVP recovers the minimum rank solution for affine constraints that satisfy
the &quot;restricted isometry property&quot; and show robustness of our method to noise.
Our results improve upon a recent breakthrough by Recht, Fazel and Parillo
(RFP07) and Lee and Bresler (LB09) in three significant ways:
  1) our method (SVP) is significantly simpler to analyze and easier to
implement,
  2) we give recovery guarantees under strictly weaker isometry assumptions
  3) we give geometric convergence guarantees for SVP even in presense of noise
and, as demonstrated empirically, SVP is significantly faster on real-world and
synthetic problems.
  In addition, we address the practically important problem of low-rank matrix
completion (MCP), which can be seen as a special case of ARMP. We empirically
demonstrate that our algorithm recovers low-rank incoherent matrices from an
almost optimal number of uniformly sampled entries. We make partial progress
towards proving exact recovery and provide some intuition for the strong
performance of SVP applied to matrix completion by showing a more restricted
isometry property. Our algorithm outperforms existing methods, such as those of
\cite{RFP07,CR08,CT09,CCS08,KOM09,LB09}, for ARMP and the matrix-completion
problem by an order of magnitude and is also significantly more robust to
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5458</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5458</id><created>2009-09-29</created><authors><author><keyname>Xu</keyname><forenames>Robert Sheng</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Salama</keyname><forenames>Magdy</forenames></author></authors><title>Information tracking approach to segmentation of ultrasound imagery of
  prostate</title><categories>cs.CV</categories><comments>27 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The size and geometry of the prostate are known to be pivotal quantities used
by clinicians to assess the condition of the gland during prostate cancer
screening. As an alternative to palpation, an increasing number of methods for
estimation of the above-mentioned quantities are based on using imagery data of
prostate. The necessity to process large volumes of such data creates a need
for automatic segmentation tools which would allow the estimation to be carried
out with maximum accuracy and efficiency. In particular, the use of transrectal
ultrasound (TRUS) imaging in prostate cancer screening seems to be becoming a
standard clinical practice due to the high benefit-to-cost ratio of this
imaging modality. Unfortunately, the segmentation of TRUS images is still
hampered by relatively low contrast and reduced SNR of the images, thereby
requiring the segmentation algorithms to incorporate prior knowledge about the
geometry of the gland. In this paper, a novel approach to the problem of
segmenting the TRUS images is described. The proposed approach is based on the
concept of distribution tracking, which provides a unified framework for
modeling and fusing image-related and morphological features of the prostate.
Moreover, the same framework allows the segmentation to be regularized via
using a new type of &quot;weak&quot; shape priors, which minimally bias the estimation
procedure, while rendering the latter stable and robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5460</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5460</id><created>2009-09-29</created><updated>2010-01-06</updated><authors><author><keyname>Shaked</keyname><forenames>E.</forenames></author><author><keyname>Michailovich</keyname><forenames>O.</forenames></author></authors><title>Iterative Shrinkage Approach to Restoration of Optical Imagery</title><categories>cs.CV</categories><comments>19 pages, 7 figures</comments><acm-class>I.4.0; I.4.3; I.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of reconstruction of digital images from their degraded
measurements is regarded as a problem of central importance in various fields
of engineering and imaging sciences. In such cases, the degradation is
typically caused by the resolution limitations of an imaging device in use
and/or by the destructive influence of measurement noise. Specifically, when
the noise obeys a Poisson probability law, standard approaches to the problem
of image reconstruction are based on using fixed-point algorithms which follow
the methodology first proposed by Richardson and Lucy. The practice of using
these methods, however, shows that their convergence properties tend to
deteriorate at relatively high noise levels. Accordingly, in the present paper,
a novel method for de-noising and/or de-blurring of digital images corrupted by
Poisson noise is introduced. The proposed method is derived under the
assumption that the image of interest can be sparsely represented in the domain
of a linear transform. Consequently, a shrinkage-based iterative procedure is
proposed, which guarantees the solution to converge to the global maximizer of
an associated maximum-a-posteriori criterion. It is shown in a series of both
computer-simulated and real-life experiments that the proposed method
outperforms a number of existing alternatives in terms of stability, precision,
and computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5479</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5479</id><created>2009-09-29</created><authors><author><keyname>Markakis</keyname><forenames>Evangelos</forenames><affiliation>Athens University of Economics and Business</affiliation></author><author><keyname>Milis</keyname><forenames>Ioannis</forenames><affiliation>Athens University of Economics and Business</affiliation></author></authors><title>Proceedings Fourth Athens Colloquium on Algorithms and Complexity</title><categories>cs.CC</categories><acm-class>F.2.0</acm-class><journal-ref>EPTCS 4, 2009</journal-ref><doi>10.4204/EPTCS.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ACAC 2009 is organized by the Athens University of Economics and Business
(AUEB) and it is the fourth in a series of meetings that aim to bring together
researchers working on all areas of the theory of algorithms and computational
complexity. These meetings are expected to serve as a lively forum for
presenting results that are in a preliminary stage or have been recently
presented in some major conference. For the first time this year all submitted
papers were reviewed and ACAC also offered to the authors the choice of
publishing their contribution (provided it has not been published anywhere else
before) with the post-proceedings of EPTCS (Electronic Proceedings in
Theoretical Computer Science).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5507</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5507</id><created>2009-09-30</created><authors><author><keyname>Shi</keyname><forenames>Cuizhu</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>Fast Algorithm for Finding Unicast Capacity of Linear Deterministic
  Wireless Relay Networks</title><categories>cs.IT math.IT</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deterministic channel model for wireless relay networks proposed by
Avestimehr, Diggavi and Tse `07 has captured the broadcast and inference nature
of wireless communications and has been widely used in approximating the
capacity of wireless relay networks. The authors generalized the max-flow
min-cut theorem to the linear deterministic wireless relay networks and
characterized the unicast capacity of such deterministic network as the minimum
rank of all the binary adjacency matrices describing source-destination cuts
whose number grows exponentially with the size of the network. In this paper,
we developed a fast algorithm for finding the unicast capacity of a linear
deterministic wireless relay network by finding the maximum number of linearly
independent paths using the idea of path augmentation. We developed a modified
depth-first search algorithm tailored for the linear deterministic relay
networks for finding linearly independent paths whose total number proved to
equal the unicast capacity of the underlying network. The result of our
algorithm suggests a capacity-achieving transmission strategy with one-bit
length linear encoding at the relay nodes in the concerned linear deterministic
wireless relay network. The correctness of our algorithm for universal cases is
given by our proof in the paper. Moreover, our algorithm has a computational
complexity bounded by $O(|{\cal{V}}_x|\cdot C^4+d\cdot |{\cal{V}}_x|\cdot C^3)$
which shows a significant improvement over the previous results for solving the
same problem by Amaudruz and Fragouli (whose complexity is bounded by $O(M\cdot
|{\cal{E}}|\cdot C^5)$ with $M\geq d$ and $|{\cal{E}}|\geq|{\cal{V}}_x|$) and
by Yazdi and Savari (whose complexity is bounded by $O(L^8\cdot M^{12}\cdot
h_0^3+L\cdot M^6\cdot C\cdot h_0^4)$ with $h_0\geq C$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5521</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5521</id><created>2009-09-30</created><updated>2010-10-02</updated><authors><author><keyname>Manyem</keyname><forenames>Prabhu</forenames></author></authors><title>Clique and Vertex Cover are solvable in polynomial time if the input
  structure is ordered and contains a successor predicate</title><categories>cs.CC cs.LO</categories><comments>Manuscript withdrawn, because results are incorrect. If phi = phi_1
  AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and
  phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be
  expressed as a universal Horn sentence in ESO (NOT even when the structure is
  ordered)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript, assuming that Graedel's 1991 results are correct (which
implies that bounds on the solution values for optimization problems can be
expressed in existential second order logic where the first order part is
universal Horn), I will show that Clique and Vertex Cover can be solved in
polynomial time if the input structure is ordered and contains a successor
predicate. In the last section, we will argue about the validity of Graedel's
1991 results. Update: Manuscript withdrawn, because results are incorrect. If
phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both
phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint
CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the
structure is ordered).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5524</identifier>
 <datestamp>2011-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5524</id><created>2009-09-30</created><updated>2011-09-20</updated><authors><author><keyname>Lung-Yut-Fong</keyname><forenames>Alexandre</forenames><affiliation>LTCI</affiliation></author><author><keyname>L&#xe9;vy-Leduc</keyname><forenames>C&#xe9;line</forenames><affiliation>LTCI</affiliation></author><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames><affiliation>LTCI</affiliation></author></authors><title>Distributed detection/localization of change-points in high-dimensional
  network traffic data</title><categories>stat.AP cs.NI math.ST stat.TH</categories><comments>Statistics and Computing (2011) 1-12</comments><proxy>ccsd</proxy><doi>10.1007/s11222-011-9240-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach for distributed statistical detection of
change-points in high-volume network traffic. We consider more specifically the
task of detecting and identifying the targets of Distributed Denial of Service
(DDoS) attacks. The proposed algorithm, called DTopRank, performs distributed
network anomaly detection by aggregating the partial information gathered in a
set of network monitors. In order to address massive data while limiting the
communication overhead within the network, the approach combines record
filtering at the monitor level and a nonparametric rank test for doubly
censored time series at the central decision site. The performance of the
DTopRank algorithm is illustrated both on synthetic data as well as from a
traffic trace provided by a major Internet service provider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5530</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5530</id><created>2009-09-30</created><authors><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Wang</keyname><forenames>Guozhang</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author></authors><title>Differential Privacy via Wavelet Transforms</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy preserving data publishing has attracted considerable research
interest in recent years. Among the existing solutions, {\em
$\epsilon$-differential privacy} provides one of the strongest privacy
guarantees. Existing data publishing methods that achieve
$\epsilon$-differential privacy, however, offer little data utility. In
particular, if the output dataset is used to answer count queries, the noise in
the query answers can be proportional to the number of tuples in the data,
which renders the results useless.
  In this paper, we develop a data publishing technique that ensures
$\epsilon$-differential privacy while providing accurate answers for {\em
range-count queries}, i.e., count queries where the predicate on each attribute
is a range. The core of our solution is a framework that applies {\em wavelet
transforms} on the data before adding noise to it. We present instantiations of
the proposed framework for both ordinal and nominal data, and we provide a
theoretical analysis on their privacy and utility guarantees. In an extensive
experimental study on both real and synthetic data, we show the effectiveness
and efficiency of our solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5554</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5554</id><created>2009-09-30</created><authors><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Prostate Biopsy Assistance System with Gland Deformation Estimation for
  Enhanced Precision</title><categories>cs.OH</categories><comments>This version of the paper integrates a correction concerning the
  local similarity measure w.r.t. the proceedings (this typing error could not
  be corrected before editing the proceedings)</comments><proxy>ccsd hal-00420370</proxy><journal-ref>12th International Conference on Medical Imaging and Computer
  Assisted Intervention, Londres : United Kingdom (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-assisted prostate biopsies became a very active research area during
the last years. Prostate tracking makes it possi- ble to overcome several
drawbacks of the current standard transrectal ultrasound (TRUS) biopsy
procedure, namely the insufficient targeting accuracy which may lead to a
biopsy distribution of poor quality, the very approximate knowledge about the
actual location of the sampled tissues which makes it difficult to implement
focal therapy strategies based on biopsy results, and finally the difficulty to
precisely reach non-ultrasound (US) targets stemming from different modalities,
statistical atlases or previous biopsy series. The prostate tracking systems
presented so far are limited to rigid transformation tracking. However, the
gland can get considerably deformed during the intervention because of US probe
pres- sure and patient movements. We propose to use 3D US combined with
image-based elastic registration to estimate these deformations. A fast elastic
registration algorithm that copes with the frequently occurring US shadows is
presented. A patient cohort study was performed, which yielded a statistically
significant in-vivo accuracy of 0.83+-0.54mm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5583</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5583</id><created>2009-09-30</created><updated>2010-08-31</updated><authors><author><keyname>Ghaffari</keyname><forenames>Hamed O.</forenames></author></authors><title>Two-Phase Flow Complexity in Heterogeneous Media</title><categories>cs.CE physics.flu-dyn</categories><comments>This paper has been withdrawn by the author. A report /version 2- Due
  to copy right the manuscript is not available</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we investigate the appeared complexity of two-phase flow
(air/water) in a heterogeneous soil where the supposed porous media is
non-deformable media which is under the timedependent gas pressure. After
obtaining of governing equations and considering the capillary
pressuresaturation and permeability functions, the evolution of the model
unknown parameters were obtained. In this way, using COMSOL (FEMLAB) and fluid
flow/script Module, the role of heterogeneity in intrinsic permeability was
analysed. Also, the evolution of relative permeability of wetting and
non-wetting fluid, capillary pressure and other parameters were elicited. In
the last part, a complex network approach to analysis of emerged patterns will
be employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5649</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5649</id><created>2009-09-30</created><authors><author><keyname>Leischner</keyname><forenames>Nikolaj</forenames></author><author><keyname>Osipov</keyname><forenames>Vitaly</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>GPU sample sort</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the design of a sample sort algorithm for manycore
GPUs. Despite being one of the most efficient comparison-based sorting
algorithms for distributed memory architectures its performance on GPUs was
previously unknown. For uniformly distributed keys our sample sort is at least
25% and on average 68% faster than the best comparison-based sorting algorithm,
GPU Thrust merge sort, and on average more than 2 times faster than GPU
quicksort. Moreover, for 64-bit integer keys it is at least 63% and on average
2 times faster than the highly optimized GPU Thrust radix sort that directly
manipulates the binary representation of keys. Our implementation is robust to
different distributions and entropy levels of keys and scales almost linearly
with the input size. These results indicate that multi-way techniques in
general and sample sort in particular achieve substantially better performance
than two-way merge sort and quicksort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5653</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5653</id><created>2009-09-30</created><authors><author><keyname>Fearnley</keyname><forenames>John</forenames></author><author><keyname>Jurdzi&#x144;ski</keyname><forenames>Marcin</forenames></author><author><keyname>Savani</keyname><forenames>Rahul</forenames></author></authors><title>Linear Complementarity Algorithms for Infinite Games</title><categories>cs.GT cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of two pivoting algorithms, due to Lemke and Cottle and
Dantzig, is studied on linear complementarity problems (LCPs) that arise from
infinite games, such as parity, average-reward, and discounted games. The
algorithms have not been previously studied in the context of infinite games,
and they offer alternatives to the classical strategy-improvement algorithms.
The two algorithms are described purely in terms of discounted games, thus
bypassing the reduction from the games to LCPs, and hence facilitating a better
understanding of the algorithms when applied to games. A family of parity games
is given, on which both algorithms run in exponential time, indicating that in
the worst case they perform no better for parity, average-reward, or discounted
games than they do for general P-matrix LCPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5654</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5654</id><created>2009-09-30</created><updated>2009-12-02</updated><authors><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author><author><keyname>Sun</keyname><forenames>Jian</forenames></author><author><keyname>Wang</keyname><forenames>Yusu</forenames></author></authors><title>Approximating Loops in a Shortest Homology Basis from Point Data</title><categories>cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference of topological and geometric attributes of a hidden manifold from
its point data is a fundamental problem arising in many scientific studies and
engineering applications. In this paper we present an algorithm to compute a
set of loops from a point data that presumably sample a smooth manifold
$M\subset \mathbb{R}^d$. These loops approximate a {\em shortest} basis of the
one dimensional homology group $H_1(M)$ over coefficients in finite field
$\mathbb{Z}_2$. Previous results addressed the issue of computing the rank of
the homology groups from point data, but there is no result on approximating
the shortest basis of a manifold from its point sample. In arriving our result,
we also present a polynomial time algorithm for computing a shortest basis of
$H_1(K)$ for any finite {\em simplicial complex} $K$ whose edges have
non-negative weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5656</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5656</id><created>2009-09-30</created><authors><author><keyname>Falie</keyname><forenames>D.</forenames></author></authors><title>Improvements of the 3D images captured with Time-of-Flight cameras</title><categories>cs.CV cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D Time-of-Flight camera's images are affected by errors due to the diffuse
(indirect) light and to the flare light. The presented method improves the 3D
image reducing the distance's errors to dark surface objects. This is achieved
by placing one or two contrast tags in the scene at different distances from
the ToF camera. The white and black parts of the tags are situated at the same
distance to the camera but the distances measured by the camera are different.
This difference is used to compute a correction vector. The distance to black
surfaces is corrected by subtracting this vector from the captured vector
image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5669</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5669</id><created>2009-09-30</created><authors><author><keyname>Davydov</keyname><forenames>Alexander A.</forenames></author><author><keyname>Giulietti</keyname><forenames>Massimo</forenames></author><author><keyname>Marcugini</keyname><forenames>Stefano</forenames></author><author><keyname>Pambianco</keyname><forenames>Fernanda</forenames></author></authors><title>Some combinatorial aspects of constructing bipartite-graph codes</title><categories>math.CO cs.IT math.IT</categories><comments>27 pages</comments><msc-class>94B05 (Primary) 94B27, 51E15, 05B25 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose geometrical methods for constructing square 01-matrices with the
same number n of units in every row and column, and such that any two rows of
the matrix contain at most one unit in common. These matrices are equivalent to
n-regular bipartite graphs without 4-cycles, and therefore can be used for the
construction of efficient bipartite-graph codes such that both the classes of
its vertices are associated with local constraints. We significantly extend the
region of parameters m,n for which there exist an n-regular bipartite graph
with 2m vertices and without 4-cycles. In that way we essentially increase the
region of lengths and rates of the corresponding bipartite-graph codes. Many
new matrices are either circulant or consist of circulant submatrices: this
provides code parity-check matrices consisting of circulant submatrices, and
hence quasi-cyclic bipartite-graph codes with simple implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5677</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5677</id><created>2009-09-30</created><authors><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author></authors><title>Beyond Equilibria: Mechanisms for Repeated Combinatorial Auctions</title><categories>cs.GT</categories><comments>16 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of mechanisms in combinatorial auction domains. We focus
on settings where the auction is repeated, motivated by auctions for licenses
or advertising space. We consider models of agent behaviour in which they
either apply common learning techniques to minimize the regret of their bidding
strategies, or apply short-sighted best-response strategies. We ask: when can a
black-box approximation algorithm for the base auction problem be converted
into a mechanism that approximately preserves the original algorithm's
approximation factor on average over many iterations? We present a general
reduction for a broad class of algorithms when agents minimize external regret.
We also present a new mechanism for the combinatorial auction problem that
attains an $O(\sqrt{m})$ approximation on average when agents apply
best-response dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5683</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5683</id><created>2009-09-30</created><updated>2010-03-18</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Kutin</keyname><forenames>Samuel A.</forenames></author></authors><title>Quantum interpolation of polynomials</title><categories>quant-ph cs.CC</categories><comments>8 pages; version 2 updates references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider quantum interpolation of polynomials. We imagine a quantum
computer with black-box access to input/output pairs (x_i, f(x_i)), where f is
a degree-d polynomial, and we wish to compute f(0). We give asymptotically
tight quantum lower bounds for this problem, even in the case where 0 is among
the possible values of x_i.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.5684</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.5684</id><created>2009-09-30</created><authors><author><keyname>Draisma</keyname><forenames>Jan</forenames></author><author><keyname>Kushilevitz</keyname><forenames>Eyal</forenames></author><author><keyname>Weinreb</keyname><forenames>Enav</forenames></author></authors><title>Partition Arguments in Multiparty Communication Complexity</title><categories>cs.CC</categories><comments>extended journal version of paper accepted for ICALP 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the &quot;Number in Hand&quot; multiparty communication complexity model,
where k players holding inputs x_1,...,x_k in {0,1}^n communicate to compute
the value f(x_1,...,x_k) of a function f known to all of them. The main lower
bound technique for the communication complexity of such problems is that of
partition arguments: partition the k players into two disjoint sets of players
and find a lower bound for the induced two-party communication complexity
problem.
  In this paper, we study the power of partition arguments. Our two main
results are very different in nature: (i) For randomized communication
complexity, we show that partition arguments may yield bounds that are
exponentially far from the true communication complexity. Specifically, we
prove that there exists a 3-argument function f whose communication complexity
is Omega(n), while partition arguments can only yield an Omega(log n) lower
bound. The same holds for nondeterministic communication complexity. (ii) For
deterministic communication complexity, we prove that finding significant gaps
between the true communication complexity and the best lower bound that can be
obtained via partition arguments, would imply progress on a generalized version
of the &quot;log-rank conjecture&quot; in communication complexity.
  We conclude with two results on the multiparty &quot;fooling set technique&quot;,
another method for obtaining communication complexity lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0013</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0013</id><created>2009-09-30</created><authors><author><keyname>Janota</keyname><forenames>Mikolas</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author><author><keyname>Grigore</keyname><forenames>Radu</forenames></author></authors><title>Algorithms for finding dispensable variables</title><categories>cs.DS cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note reviews briefly three algorithms for finding the set of
dispensable variables of a boolean formula. The presentation is light on proofs
and heavy on intuitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0045</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0045</id><created>2009-09-30</created><authors><author><keyname>Grenet</keyname><forenames>Bruno</forenames></author></authors><title>Acceptable Complexity Measures of Theorems</title><categories>cs.LO cs.IT math.IT</categories><comments>16 pages, presented at NKS Midwest Conference '08</comments><journal-ref>Complex Systems 18:4 (2010) 403-425</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1931, G\&quot;odel presented in K\&quot;onigsberg his famous Incompleteness Theorem,
stating that some true mathematical statements are unprovable. Yet, this result
gives us no idea about those independent (that is, true and unprovable)
statements, about their frequency, the reason they are unprovable, and so on.
Calude and J\&quot;urgensen proved in 2005 Chaitin's &quot;heuristic principle&quot; for an
appropriate measure: the theorems of a finitely-specified theory cannot be
significantly more complex than the theory itself. In this work, we investigate
the existence of other measures, different from the original one, which satisfy
this &quot;heuristic principle&quot;. At this end, we introduce the definition of
acceptable complexity measure of theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0097</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0097</id><created>2009-10-01</created><updated>2009-10-02</updated><authors><author><keyname>Vaniachine</keyname><forenames>A.</forenames></author><author><keyname>Collaboration</keyname><forenames>for the ATLAS</forenames></author></authors><title>Scalable Database Access Technologies for ATLAS Distributed Computing</title><categories>physics.ins-det cs.DB cs.DC hep-ex</categories><comments>6 pages, 7 figures. To be published in the proceedings of DPF-2009,
  Detroit, MI, July 2009, eConf C090726</comments><report-no>ANL-HEP-CP-09-085</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  ATLAS event data processing requires access to non-event data (detector
conditions, calibrations, etc.) stored in relational databases. The
database-resident data are crucial for the event data reconstruction processing
steps and often required for user analysis. A main focus of ATLAS database
operations is on the worldwide distribution of the Conditions DB data, which
are necessary for every ATLAS data processing job. Since Conditions DB access
is critical for operations with real data, we have developed the system where a
different technology can be used as a redundant backup. Redundant database
operations infrastructure fully satisfies the requirements of ATLAS
reprocessing, which has been proven on a scale of one billion database queries
during two reprocessing campaigns of 0.5 PB of single-beam and cosmics data on
the Grid. To collect experience and provide input for a best choice of
technologies, several promising options for efficient database access in user
analysis were evaluated successfully. We present ATLAS experience with scalable
database access technologies and describe our approach for prevention of
database access bottlenecks in a Grid computing environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0110</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0110</id><created>2009-10-01</created><authors><author><keyname>Briest</keyname><forenames>Patrick</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Improved Hardness of Approximation for Stackelberg Shortest-Path Pricing</title><categories>cs.DS cs.CC</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Stackelberg shortest-path pricing problem, which is defined
as follows. Given a graph G with fixed-cost and pricable edges and two distinct
vertices s and t, we may assign prices to the pricable edges. Based on the
predefined fixed costs and our prices, a customer purchases a cheapest s-t-path
in G and we receive payment equal to the sum of prices of pricable edges
belonging to the path. Our goal is to find prices maximizing the payment
received from the customer. While Stackelberg shortest-path pricing was known
to be APX-hard before, we provide the first explicit approximation threshold
and prove hardness of approximation within 2-o(1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0112</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0112</id><created>2009-10-01</created><updated>2010-02-17</updated><authors><author><keyname>Campagna</keyname><forenames>Andrea</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>Finding Associations and Computing Similarity via Biased Pair Sampling</title><categories>cs.DS cs.DB cs.LG</categories><comments>This is an extended version of a paper that appeared at the IEEE
  International Conference on Data Mining, 2009. The conference version is (c)
  2009 IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This version is ***superseded*** by a full version that can be found at
http://www.itu.dk/people/pagh/papers/mining-jour.pdf, which contains stronger
theoretical results and fixes a mistake in the reporting of experiments.
  Abstract: Sampling-based methods have previously been proposed for the
problem of finding interesting associations in data, even for low-support
items. While these methods do not guarantee precise results, they can be vastly
more efficient than approaches that rely on exact counting. However, for many
similarity measures no such methods have been known. In this paper we show how
a wide variety of measures can be supported by a simple biased sampling method.
The method also extends to find high-confidence association rules. We
demonstrate theoretically that our method is superior to exact methods when the
threshold for &quot;interesting similarity/confidence&quot; is above the average pairwise
similarity/confidence, and the average support is not too low. Our method is
particularly good when transactions contain many items. We confirm in
experiments on standard association mining benchmarks that this gives a
significant speedup on real data sets (sometimes much larger than the
theoretical guarantees). Reductions in computation time of over an order of
magnitude, and significant savings in space, are observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0144</identifier>
 <datestamp>2013-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0144</id><created>2009-10-01</created><authors><author><keyname>Clegg</keyname><forenames>Richard G.</forenames></author><author><keyname>Landa</keyname><forenames>Raul</forenames></author><author><keyname>Rio</keyname><forenames>Miguel</forenames></author></authors><title>Criticisms of modelling packet traffic using long-range dependence</title><categories>cs.NI cs.PF</categories><comments>Presented at the PMECT 2009 workshop (part of ICCCN 2009) in San
  Francisco</comments><doi>10.1109/ICCCN.2009.5235309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper criticises the notion that long-range dependence is an important
contributor to the queuing behaviour of real Internet traffic. The idea is
questioned in two different ways. Firstly, a class of models used to simulate
Internet traffic is shown to have important theoretical flaws. It is shown that
this behaviour is inconsistent with the behaviour of real traffic traces.
Secondly, the notion that long-range correlations significantly affects the
queuing performance of traffic is investigated by destroying those correlations
in real traffic traces (by reordering). It is shown that the longer ranges of
correlations are not important except in one case with an extremely high load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0179</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0179</id><created>2009-10-01</created><authors><author><keyname>Said</keyname><forenames>O.</forenames></author><author><keyname>Bahgat</keyname><forenames>S.</forenames></author><author><keyname>Ghoniemy</keyname><forenames>M.</forenames></author><author><keyname>Elawdy</keyname><forenames>Y.</forenames></author></authors><title>Analysis, Design and Simulation of a New System for Internet Multimedia
  Transmission Guarantee</title><categories>cs.MM cs.NI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 77-86, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  QoS is a very important issue for multimedia communication systems. In this
paper, a new system that reinstalls the relation between the QoS elements
(RSVP, routing protocol, sender, and receiver) during the multimedia
transmission is proposed, then an alternative path is created in case of
original multimedia path failure. The suggested system considers the resulting
problems that may be faced within and after the creation of rerouting path.
Finally, the proposed system is simulated using OPNET 11.5 simulation package.
Simulation results show that our proposed system outperforms the old one in
terms of QoS parameters like packet loss and delay jitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0187</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0187</id><created>2009-10-01</created><authors><author><keyname>Voras</keyname><forenames>Ivan</forenames></author><author><keyname>Zagar</keyname><forenames>Mario</forenames></author></authors><title>Web-enabling Cache Daemon for Complex Data</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most common basic techniques for improving the performance of web
applications is caching frequently accessed data in fast data stores,
colloquially known as cache daemons. In this paper we present a cache daemon
suitable for storing complex data while maintaining fine-grained control over
data storage, retrieval and expiry. Data manipulation in this cache daemon is
performed via standard SQL statements so we call it SQLcached. It is a
practical, usable solution already implemented in several large web sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0211</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0211</id><created>2009-10-01</created><authors><author><keyname>Argentini</keyname><forenames>Gianluca</forenames></author></authors><title>Searching the (really) real general solution of 2D Laplace differential
  equation</title><categories>math.AP cs.CE physics.flu-dyn</categories><comments>None new, but re-view</comments><msc-class>35J05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is not a new result. Purpose of this work is to describe a method to
search the analytical expression of the general real solution of the
two-dimensional Laplace differential equation. This thing is not easy to find
in scientific literature and, if present, often it is justified with the
assertion that an arbitrary analytic complex function is a solution of Laplace
equation, so introducing the condition of complex-differentiability which is
not really necessary for the existence of a real solution. The question of the
knowledge of real exact solutions to Laplace equation is of great importance in
science and engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0227</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0227</id><created>2009-10-01</created><authors><author><keyname>A.</keyname><forenames>Renuka</forenames></author><author><keyname>Shet</keyname><forenames>K. C.</forenames></author></authors><title>Hierarchical Approach for Key Management in Mobile Ad hoc Networks</title><categories>cs.CR</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 87-95, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad-hoc Network (MANET) is a collection of autonomous nodes or
terminals which communicate with each other by forming a multi-hop radio
network and maintaining connectivity in a decentralized manner. The
conventional security solutions to provide key management through accessing
trusted authorities or centralized servers are infeasible for this new
environment since mobile ad hoc networks are characterized by the absence of
any infrastructure, frequent mobility, and wireless links. We propose a
hierarchical group key management scheme that is hierarchical and fully
distributed with no central authority and uses a simple rekeying procedure
which is suitable for large and high mobility mobile ad hoc networks. The
rekeying procedure requires only one round in our scheme and Chinese Remainder
Theorem Diffie Hellman Group Diffie Hellmann and Burmester and Desmedt it is a
constant 3 whereas in other schemes such as Distributed Logical Key Hierarchy
and Distributed One Way Function Trees, it depends on the number of members. We
reduce the energy consumption during communication of the keying materials by
reducing the number of bits in the rekeying message. We show through analysis
and simulations that our scheme has less computation, communication and energy
consumption compared to the existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0239</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0239</id><created>2009-10-01</created><updated>2010-01-25</updated><authors><author><keyname>Saligrama</keyname><forenames>V.</forenames></author><author><keyname>Zhao</keyname><forenames>M.</forenames></author></authors><title>Compressed Blind De-convolution</title><categories>cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose the signal x is realized by driving a k-sparse signal u through an
arbitrary unknown stable discrete-linear time invariant system H. These types
of processes arise naturally in Reflection Seismology. In this paper we are
interested in several problems: (a) Blind-Deconvolution: Can we recover both
the filter $H$ and the sparse signal $u$ from noisy measurements? (b)
Compressive Sensing: Is x compressible in the conventional sense of compressed
sensing? Namely, can x, u and H be reconstructed from a sparse set of
measurements. We develop novel L1 minimization methods to solve both cases and
establish sufficient conditions for exact recovery for the case when the
unknown system H is auto-regressive (i.e. all pole) of a known order. In the
compressed sensing/sampling setting it turns out that both H and x can be
reconstructed from O(k log(n)) measurements under certain technical conditions
on the support structure of u. Our main idea is to pass x through a linear time
invariant system G and collect O(k log(n)) sequential measurements. The filter
G is chosen suitably, namely, its associated Toeplitz matrix satisfies the RIP
property. We develop a novel LP optimization algorithm and show that both the
unknown filter H and the sparse input u can be reliably estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0281</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0281</id><created>2009-10-01</created><updated>2010-03-06</updated><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Koenemann</keyname><forenames>Jochen</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>Hypergraphic LP Relaxations for Steiner Trees</title><categories>cs.DM</categories><comments>Revised full version; a shorter version will appear at IPCO 2010.</comments><doi>10.1007/978-3-642-13036-6_29</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We investigate hypergraphic LP relaxations for the Steiner tree problem,
primarily the partition LP relaxation introduced by Koenemann et al. [Math.
Programming, 2009]. Specifically, we are interested in proving upper bounds on
the integrality gap of this LP, and studying its relation to other linear
relaxations. Our results are the following. Structural results: We extend the
technique of uncrossing, usually applied to families of sets, to families of
partitions. As a consequence we show that any basic feasible solution to the
partition LP formulation has sparse support. Although the number of variables
could be exponential, the number of positive variables is at most the number of
terminals. Relations with other relaxations: We show the equivalence of the
partition LP relaxation with other known hypergraphic relaxations. We also show
that these hypergraphic relaxations are equivalent to the well studied
bidirected cut relaxation, if the instance is quasibipartite. Integrality gap
upper bounds: We show an upper bound of sqrt(3) ~ 1.729 on the integrality gap
of these hypergraph relaxations in general graphs. In the special case of
uniformly quasibipartite instances, we show an improved upper bound of 73/60 ~
1.216. By our equivalence theorem, the latter result implies an improved upper
bound for the bidirected cut relaxation as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0284</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0284</id><created>2009-10-02</created><updated>2010-07-19</updated><authors><author><keyname>Dougherty</keyname><forenames>Randall</forenames></author><author><keyname>Freiling</keyname><forenames>Chris</forenames></author><author><keyname>Zeger</keyname><forenames>Kenneth</forenames></author></authors><title>Linear rank inequalities on five or more variables</title><categories>cs.IT math.IT</categories><comments>Substantial improvements, including a stronger form of the second
  general construction of inequalities, many more six-variable inequalities,
  and further description of the computing methodology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranks of subspaces of vector spaces satisfy all linear inequalities satisfied
by entropies (including the standard Shannon inequalities) and an additional
inequality due to Ingleton. It is known that the Shannon and Ingleton
inequalities generate all such linear rank inequalities on up to four
variables, but it has been an open question whether additional inequalities
hold for the case of five or more variables. Here we give a list of 24
inequalities which, together with the Shannon and Ingleton inequalities,
generate all linear rank inequalities on five variables. We also give a partial
list of linear rank inequalities on six variables and general results which
produce such inequalities on an arbitrary number of variables; we prove that
there are essentially new inequalities at each number of variables beyond four
(a result also proved recently by Kinser).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0286</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0286</id><created>2009-10-01</created><authors><author><keyname>Purdy</keyname><forenames>George B.</forenames></author><author><keyname>Smith</keyname><forenames>Justin W.</forenames></author></authors><title>On Finding Ordinary or Monochromatic Intersection Points</title><categories>cs.CG cs.DM</categories><comments>21 pages, 4 figures</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm is demonstrated that finds an ordinary intersection in an
arrangement of $n$ lines in $\mathbb{R}^2$, not all parallel and not all
passing through a common point, in time $O(n \log{n})$. The algorithm is then
extended to find an ordinary intersection among an arrangement of hyperplanes
in $\mathbb{R}^d$, no $d$ passing through a line and not all passing through
the same point, again, in time $O(n \log{n})$.
  Two additional algorithms are provided that find an ordinary or monochromatic
intersection, respectively, in an arrangement of pseudolines in time $O(n^2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0287</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0287</id><created>2009-10-01</created><updated>2011-04-03</updated><authors><author><keyname>Cimmino</keyname><forenames>Luigi</forenames></author></authors><title>Shor's Algorithm from the Mindset of Quantum Oracles</title><categories>quant-ph cs.CC</categories><comments>8 pages, report on deterministic quantum measuremet theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this work is to show a brand-new way of making deterministic
Quantum Computing (short QC), in the sense of Theory of Calculability, by
meaning of unitary evolution. We start from the original Shor's Algorithm to
explain how the newest one works, at least compared to theory. We will give a
new conceptual foundation of QC, resulting from a set of conventional and well
known results of Calculability and Quantum Mechanics. In the practice, if that
can be used in its general sense, we will show an inaccessible relativized
process which let us able to obtain same results with the same outlay in the
time resource as the Shor's one for factorizing a given number n. Then the
QO-system will be a prototype way giving to the relativized calculus the
possibility to put in to practice an oracle, kind of object having till now
abstract nature. The basic physical tool of our theorization, we call Quantum
State Selection, consists in the twin-combined measurement process through
positive valued measure operator (POVM), needed to provide the quantum oracle's
answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0316</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0316</id><created>2009-10-01</created><authors><author><keyname>Ganeshkumar</keyname><forenames>P.</forenames></author><author><keyname>Thyagarajah</keyname><forenames>K.</forenames></author></authors><title>An Analysis of Energy Consumption on ACK plus Rate Packet in Rate Based
  Transport Protocol</title><categories>cs.NI cs.PF</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 96-102, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rate based transport protocol determines the rate of data transmission
between the sender and receiver and then sends the data according to that rate.
To notify the rate to the sender, the receiver sends ACKplusRate packet based
on epoch timer expiry. In this paper, through detailed arguments and simulation
it is shown that the transmission of ACKplusRate packet based on epoch timer
expiry consumes more energy in network with low mobility. To overcome this
problem, a new technique called Dynamic Rate Feedback (DRF) is proposed. DRF
sends ACKplusRate whenever there is a change in rate of (plus or minus) 25
percent than the previous rate. Based on ns2 simulation DRF is compared with a
reliable transport protocol for ad hoc network (ATP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0317</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0317</id><created>2009-10-01</created><authors><author><keyname>Karimi</keyname><forenames>Abbas</forenames></author><author><keyname>Zarafshan</keyname><forenames>Faraneh</forenames></author><author><keyname>Jantan</keyname><forenames>Adznan. b.</forenames></author><author><keyname>Ramli</keyname><forenames>A. R</forenames></author><author><keyname>Saripan</keyname><forenames>M. Iqbal b.</forenames></author></authors><title>A New Fuzzy Approach for Dynamic Load Balancing Algorithm</title><categories>cs.DC</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 01-05, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Load balancing is the process of improving the Performance of a parallel and
distributed system through is distribution of load among the processors [1-2].
Most of the previous work in load balancing and distributed decision making in
general, do not effectively take into account the uncertainty and inconsistency
in state information but in fuzzy logic, we have advantage of using crisps
inputs. In this paper, we present a new approach for implementing dynamic load
balancing algorithm with fuzzy logic, which can face to uncertainty and
inconsistency of previous algorithms, further more our algorithm shows better
response time than round robin and randomize algorithm respectively 30.84
percent and 45.45 percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0320</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0320</id><created>2009-10-01</created><authors><author><keyname>Liu</keyname><forenames>Jialing</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>Convergence of Fundamental Limitations in Feedback Communication,
  Estimation, and Feedback Control over Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we establish the connections of the fundamental limitations in
feedback communication, estimation, and feedback control over Gaussian
channels, from a unifying perspective for information, estimation, and control.
The optimal feedback communication system over a Gaussian necessarily employs
the Kalman filter (KF) algorithm, and hence can be transformed into an
estimation system and a feedback control system over the same channel. This
follows that the information rate of the communication system is alternatively
given by the decay rate of the Cramer-Rao bound (CRB) of the estimation system
and by the Bode integral (BI) of the control system. Furthermore, the optimal
tradeoff between the channel input power and information rate in feedback
communication is alternatively characterized by the optimal tradeoff between
the (causal) one-step prediction mean-square error (MSE) and (anti-causal)
smoothing MSE (of an appropriate form) in estimation, and by the optimal
tradeoff between the regulated output variance with causal feedback and the
disturbance rejection measure (BI or degree of anti-causality) in feedback
control. All these optimal tradeoffs have an interpretation as the tradeoff
between causality and anti-causality. Utilizing and motivated by these
relations, we provide several new results regarding the feedback codes and
information theoretic characterization of KF. Finally, the extension of the
finite-horizon results to infinite horizon is briefly discussed under specific
dimension assumptions (the asymptotic feedback capacity problem is left open in
this paper).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0349</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0349</id><created>2009-10-02</created><authors><author><keyname>Marinica</keyname><forenames>Claudia</forenames><affiliation>LINA</affiliation></author><author><keyname>Guillet</keyname><forenames>Fabrice</forenames><affiliation>LINA</affiliation></author><author><keyname>Briand</keyname><forenames>Henri</forenames><affiliation>LINA</affiliation></author></authors><title>Post-Processing of Discovered Association Rules Using Ontologies</title><categories>cs.LG</categories><proxy>ccsd hal-00421501</proxy><journal-ref>The Second International Workshop on Domain Driven Data Mining
  (DDDM 2008) in IEEE International Conference of Data Mining, Pisa : Italie
  (2008)</journal-ref><doi>10.1109/ICDMW.2008.87</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Data Mining, the usefulness of association rules is strongly limited by
the huge amount of delivered rules. In this paper we propose a new approach to
prune and filter discovered rules. Using Domain Ontologies, we strengthen the
integration of user knowledge in the post-processing task. Furthermore, an
interactive and iterative framework is designed to assist the user along the
analyzing task. On the one hand, we represent user domain knowledge using a
Domain Ontology over database. On the other hand, a novel technique is
suggested to prune and to filter discovered rules. The proposed framework was
applied successfully over the client database provided by Nantes Habitat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0366</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0366</id><created>2009-10-02</created><authors><author><keyname>Cederman</keyname><forenames>Daniel</forenames></author><author><keyname>Tsigas</keyname><forenames>Philippas</forenames></author></authors><title>Supporting Lock-Free Composition of Concurrent Data Objects</title><categories>cs.DC cs.DS</categories><report-no>2009-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lock-free data objects offer several advantages over their blocking
counterparts, such as being immune to deadlocks and convoying and, more
importantly, being highly concurrent. But they share a common disadvantage in
that the operations they provide are difficult to compose into larger atomic
operations while still guaranteeing lock-freedom. We present a lock-free
methodology for composing highly concurrent linearizable objects together by
unifying their linearization points. This makes it possible to relatively
easily introduce atomic lock-free move operations to a wide range of concurrent
objects. Experimental evaluation has shown that the operations originally
supported by the data objects keep their performance behavior under our
methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0410</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0410</id><created>2009-10-02</created><updated>2010-05-08</updated><authors><author><keyname>Steinberg</keyname><forenames>Benjamin</forenames></author></authors><title>The averaging trick and the Cerny conjecture</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The results of several papers concerning the \v{C}ern\'y conjecture are
deduced as consequences of a simple idea that I call the averaging trick. This
idea is implicitly used in the literature, but no attempt was made to formalize
the proof scheme axiomatically. Instead, authors axiomatized classes of
automata to which it applies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0413</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0413</id><created>2009-10-02</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author></authors><title>Accurate low-rank matrix recovery from a small number of linear
  measurements</title><categories>cs.IT math.IT</categories><comments>8 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering a lowrank matrix M from a small number
of random linear measurements. A popular and useful example of this problem is
matrix completion, in which the measurements reveal the values of a subset of
the entries, and we wish to fill in the missing entries (this is the famous
Netflix problem). When M is believed to have low rank, one would ideally try to
recover M by finding the minimum-rank matrix that is consistent with the data;
this is, however, problematic since this is a nonconvex problem that is,
generally, intractable.
  Nuclear-norm minimization has been proposed as a tractable approach, and past
papers have delved into the theoretical properties of nuclear-norm minimization
algorithms, establishing conditions under which minimizing the nuclear norm
yields the minimum rank solution. We review this spring of emerging literature
and extend and refine previous theoretical results. Our focus is on providing
error bounds when M is well approximated by a low-rank matrix, and when the
measurements are corrupted with noise. We show that for a certain class of
random linear measurements, nuclear-norm minimization provides stable recovery
from a number of samples nearly at the theoretical lower limit, and enjoys
order-optimal error bounds (with high probability).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0443</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0443</id><created>2009-10-02</created><authors><author><keyname>Chalermsook</keyname><forenames>Parinya</forenames></author><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author></authors><title>Stackelberg Pricing is Hard to Approximate within $2-\epsilon$</title><categories>cs.GT cs.CC cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stackelberg Pricing Games is a two-level combinatorial pricing problem
studied in the Economics, Operation Research, and Computer Science communities.
In this paper, we consider the decade-old shortest path version of this problem
which is the first and most studied problem in this family.
  The game is played on a graph (representing a network) consisting of {\em
fixed cost} edges and {\em pricable} or {\em variable cost} edges. The fixed
cost edges already have some fixed price (representing the competitor's
prices). Our task is to choose prices for the variable cost edges. After that,
a client will buy the cheapest path from a node $s$ to a node $t$, using any
combination of fixed cost and variable cost edges. The goal is to maximize the
revenue on variable cost edges.
  In this paper, we show that the problem is hard to approximate within
$2-\epsilon$, improving the previous \APX-hardness result by Joret [to appear
in {\em Networks}]. Our technique combines the existing ideas with a new
insight into the price structure and its relation to the hardness of the
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0456</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0456</id><created>2009-10-02</created><updated>2009-10-13</updated><authors><author><keyname>Rad</keyname><forenames>Kamiar Rahnama</forenames></author></authors><title>Sharp Sufficient Conditions on Exact Sparsity Pattern Recovery</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the $n$-dimensional vector $y=X\be+\e$, where $\be \in \R^p$ has
only $k$ nonzero entries and $\e \in \R^n$ is a Gaussian noise. This can be
viewed as a linear system with sparsity constraints, corrupted by noise. We
find a non-asymptotic upper bound on the probability that the optimal decoder
for $\beta$ declares a wrong sparsity pattern, given any generic perturbation
matrix $X$. In the case when $X$ is randomly drawn from a Gaussian ensemble, we
obtain asymptotically sharp sufficient conditions for exact recovery, which
agree with the known necessary conditions previously established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0460</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0460</id><created>2009-10-02</created><updated>2010-02-03</updated><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author></authors><title>Exact Covers via Determinants</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a k-uniform hypergraph on n vertices, partitioned in k equal parts such
that every hyperedge includes one vertex from each part, the k-dimensional
matching problem asks whether there is a disjoint collection of the hyperedges
which covers all vertices. We show it can be solved by a randomized polynomial
space algorithm in time O*(2^(n(k-2)/k)). The O*() notation hides factors
polynomial in n and k.
  When we drop the partition constraint and permit arbitrary hyperedges of
cardinality k, we obtain the exact cover by k-sets problem. We show it can be
solved by a randomized polynomial space algorithm in time O*(c_k^n), where
c_3=1.496, c_4=1.642, c_5=1.721, and provide a general bound for larger k.
  Both results substantially improve on the previous best algorithms for these
problems, especially for small k, and follow from the new observation that
Lovasz' perfect matching detection via determinants (1979) admits an embedding
in the recently proposed inclusion-exclusion counting scheme for set covers,
despite its inability to count the perfect matchings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0483</identifier>
 <datestamp>2009-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0483</id><created>2009-10-05</created><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author></authors><title>Statistical Decision Making for Authentication and Intrusion Detection</title><categories>stat.ML cs.LG stat.AP</categories><comments>13 pages, 2 figures, to be presented at ICMLA 2009</comments><report-no>IAS-UVA-09-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User authentication and intrusion detection differ from standard
classification problems in that while we have data generated from legitimate
users, impostor or intrusion data is scarce or non-existent. We review existing
techniques for dealing with this problem and propose a novel alternative based
on a principled statistical decision-making view point. We examine the
technique on a toy problem and validate it on complex real-world data from an
RFID based access control system. The results indicate that it can
significantly outperform the classical world model approach. The method could
be more generally useful in other decision-making scenarios where there is a
lack of adversary data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0493</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0493</id><created>2009-10-02</created><authors><author><keyname>Bucchiarone</keyname><forenames>Antonio</forenames></author><author><keyname>Di Ruscio</keyname><forenames>Davide</forenames></author><author><keyname>Muccini</keyname><forenames>Henry</forenames></author><author><keyname>Pelliccione</keyname><forenames>Patrizio</forenames></author></authors><title>From Requirements to code: an Architecture-centric Approach for
  producing Quality Systems</title><categories>cs.SE</categories><comments>Chapter of the book &quot;Model-Driven Software Development: Integrating
  Quality Assurance&quot;. Idea Group Inc., Information Science Publishing, IRM
  Press. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When engineering complex and distributed software and hardware systems
(increasingly used in many sectors, such as manufacturing, aerospace,
transportation, communication, energy, and health-care), quality has become a
big issue, since failures can have economics consequences and can also endanger
human life. Model-based specifications of a component-based system permit to
explicitly model the structure and behaviour of components and their
integration. In particular Software Architectures (SA) has been advocated as an
effective means to produce quality systems. In this chapter by combining
different technologies and tools for analysis and development, we propose an
architecture-centric model-driven approach to validate required properties and
to generate the system code. Functional requirements are elicited and used for
identifying expected properties the architecture shall express. The
architectural compliance to the properties is formally demonstrated, and the
produced architectural model is used to automatically generate the Java code.
Suitable transformations assure that the code is conforming to both structural
and behavioural SA constraints. This chapter describes the process and
discusses how some existing tools and languages can be exploited to support the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0504</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0504</id><created>2009-10-05</created><updated>2014-12-02</updated><authors><author><keyname>Soto</keyname><forenames>Jos&#xe9;</forenames></author></authors><title>Improved Analysis of a Max Cut Algorithm Based on Spectral Partitioning</title><categories>cs.DS</categories><comments>9 pages, 2 figures. Final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trevisan [SICOMP 2012] presented an algorithm for Max-Cut based on spectral
partitioning techniques. This is the first algorithm for Max-Cut with an
approximation guarantee strictly larger than 1/2 that is not based on
semidefinite programming. Trevisan showed that its approximation ratio is of at
least 0.531. In this paper we improve this bound up to 0.614247. We also define
and extend this result for the more general Maximum Colored Cut problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0505</identifier>
 <datestamp>2009-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0505</id><created>2009-10-02</created><updated>2009-11-13</updated><authors><author><keyname>Haque</keyname><forenames>Imran S.</forenames></author><author><keyname>Pande</keyname><forenames>Vijay S.</forenames></author></authors><title>Hard Data on Soft Errors: A Large-Scale Assessment of Real-World Error
  Rates in GPGPU</title><categories>cs.AR cs.GR</categories><comments>10 pages, 5 figures. For associated code and binaries, see
  https://simtk.org/home/memtest . Poster version to be presented at
  Supercomputing 2009. Version 1 of submission contained erroneous analysis of
  transaction coalescing on GT200</comments><acm-class>B.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphics processing units (GPUs) are gaining widespread use in computational
chemistry and other scientific simulation contexts because of their huge
performance advantages relative to conventional CPUs. However, the reliability
of GPUs in error-intolerant applications is largely unproven. In particular, a
lack of error checking and correcting (ECC) capability in the memory subsystems
of graphics cards has been cited as a hindrance to the acceptance of GPUs as
high-performance coprocessors, but the impact of this design has not been
previously quantified.
  In this article we present MemtestG80, our software for assessing memory
error rates on NVIDIA G80 and GT200-architecture-based graphics cards.
Furthermore, we present the results of a large-scale assessment of GPU error
rate, conducted by running MemtestG80 on over 20,000 hosts on the Folding@home
distributed computing network. Our control experiments on consumer-grade and
dedicated-GPGPU hardware in a controlled environment found no errors. However,
our survey over cards on Folding@home finds that, in their installed
environments, two-thirds of tested GPUs exhibit a detectable, pattern-sensitive
rate of memory soft errors. We demonstrate that these errors persist after
controlling for overclocking and environmental proxies for temperature, but
depend strongly on board architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0513</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0513</id><created>2009-10-03</created><authors><author><keyname>Du</keyname><forenames>Ye</forenames></author></authors><title>Ranking via Arrow-Debreu Equilibrium</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we establish a connection between ranking theory and general
equilibrium theory. First of all, we show that the ranking vector of PageRank
or Invariant method is precisely the equilibrium of a special Cobb-Douglas
market. This gives a natural economic interpretation for the PageRank or
Invariant method. Furthermore, we propose a new ranking method, the CES
ranking, which is minimally fair, strictly monotone and invariant to reference
intensity, but not uniform or weakly additive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0537</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0537</id><created>2009-10-03</created><authors><author><keyname>Gluzberg</keyname><forenames>Victor</forenames></author></authors><title>A Note On Higher Order Grammar</title><categories>cs.CL</categories><comments>7 pages in single-spaced pdf format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both syntax-phonology and syntax-semantics interfaces in Higher Order Grammar
(HOG) are expressed as axiomatic theories in higher-order logic (HOL), i.e. a
language is defined entirely in terms of provability in the single logical
system. An important implication of this elegant architecture is that the
meaning of a valid expression turns out to be represented not by a single, nor
even by a few &quot;discrete&quot; terms (in case of ambiguity), but by a &quot;continuous&quot;
set of logically equivalent terms. The note is devoted to precise formulation
and proof of this observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0542</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0542</id><created>2009-10-03</created><authors><author><keyname>Patri</keyname><forenames>Om Prasad</forenames></author><author><keyname>Mishra</keyname><forenames>Amit Kumar</forenames></author></authors><title>Pre-processing in AI based Prediction of QSARs</title><categories>cs.AI cs.NE q-bio.QM</categories><comments>6 pages, 12 figures, In the Proceedings of the 12th International
  Conference on Information Technology, ICIT 2009, December 21-24 2009,
  Bhubaneswar, India</comments><acm-class>I.5.2; I.5.3; J.2; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning, data mining and artificial intelligence (AI) based methods
have been used to determine the relations between chemical structure and
biological activity, called quantitative structure activity relationships
(QSARs) for the compounds. Pre-processing of the dataset, which includes the
mapping from a large number of molecular descriptors in the original high
dimensional space to a small number of components in the lower dimensional
space while retaining the features of the original data, is the first step in
this process. A common practice is to use a mapping method for a dataset
without prior analysis. This pre-analysis has been stressed in our work by
applying it to two important classes of QSAR prediction problems: drug design
(predicting anti-HIV-1 activity) and predictive toxicology (estimating
hepatocarcinogenicity of chemicals). We apply one linear and two nonlinear
mapping methods on each of the datasets. Based on this analysis, we conclude
the nature of the inherent relationships between the elements of each dataset,
and hence, the mapping method best suited for it. We also show that proper
preprocessing can help us in choosing the right feature extraction tool as well
as give an insight about the type of classifier pertinent for the given
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0548</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0548</id><created>2009-10-04</created><authors><author><keyname>Positselskaya</keyname><forenames>Lyubov N.</forenames></author></authors><title>Noisy fighter-bomber duel</title><categories>math.OC cs.GT math.PR</categories><comments>Equally detailed English and Russian versions, each 23 pages long.
  LaTeX 2e, with Babel for the Russian version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a duel-type game in which Player I uses his resource continuously
and Player II distributes it by discrete portions. Each player knows how much
resources he and his opponent have at every moment of time. The solution of the
game is given in an explicit form.
  Keywords: noisy duel, payoff, strategy, the value of a game, consumption of
resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0553</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0553</id><created>2009-10-03</created><authors><author><keyname>Goemans</keyname><forenames>Michel X.</forenames></author></authors><title>Combining Approximation Algorithms for the Prize-Collecting TSP</title><categories>cs.DS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a 1.91457-approximation algorithm for the prize-collecting
travelling salesman problem. This is obtained by combining a randomized variant
of a rounding algorithm of Bienstock et al. and a primal-dual algorithm of
Goemans and Williamson.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0555</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0555</id><created>2009-10-04</created><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Exploiting Channel Correlations - Simple Interference Alignment Schemes
  with no CSIT</title><categories>cs.IT math.IT</categories><comments>18 pages, 6 figures</comments><journal-ref>IEEE Journal of Selected Topics in Signal Processing, Vol. 6, No.
  3, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore 5 network communication problems where the possibility of
interference alignment, and consequently the total number of degrees of freedom
(DoF) with channel uncertainty at the transmitters are unknown. These problems
share the common property that in each case the best known outer bounds are
essentially robust to channel uncertainty and represent the outcome with
interference alignment, but the best inner bounds -- in some cases conjectured
to be optimal -- predict a total collapse of DoF, thus indicating the
infeasibility of interference alignment under channel uncertainty at
transmitters. Our main contribution is to show that even with no knowledge of
channel coefficient values at the transmitters, the knowledge of the channels'
correlation structure can be exploited to achieve interference alignment. In
each case, we show that under a staggered block fading model, the transmitters
are able to align interference without the knowledge of channel coefficient
values. The alignment schemes are based on linear beamforming -- which can be
seen as a repetition code over a small number of symbols -- and involve delays
of only a few coherence intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0575</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0575</id><created>2009-10-03</created><updated>2013-07-12</updated><authors><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author><author><keyname>Vega</keyname><forenames>Maria V.</forenames></author></authors><title>A Note on Functional Averages over Gaussian Ensembles</title><categories>math.PR cs.IT math.IT math.OA</categories><comments>Published in Journal of Probability and Statistics, Vol. 2013,
  Article ID 941058</comments><msc-class>60B20, 15B52</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we find a new formula for matrix averages over the Gaussian
ensemble. Let ${\bf H}$ be an $n\times n$ Gaussian random matrix with complex,
independent, and identically distributed entries of zero mean and unit
variance. Given an $n\times n$ positive definite matrix ${\bf A}$, and a
continuous function $f:\R^{+}\to\R$ such that $\int_{0}^{\infty}{e^{-\alpha
t}|f(t)|^2\,dt}&lt;\infty$ for every $\alpha&gt;0$, we find a new formula for the
expectation $\E[\mathrm{Tr}(f({\bf HAH^{*}}))]$. Taking $f(x)=\log(1+x)$ gives
another formula for the capacity of the MIMO communication channel, and taking
$f(x)=(1+x)^{-1}$ gives the MMSE achieved by a linear receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0582</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0582</id><created>2009-10-03</created><updated>2009-11-04</updated><authors><author><keyname>Lampis</keyname><forenames>Michael</forenames></author></authors><title>Algorithmic Meta-Theorems for Graphs of Bounded Vertex Cover</title><categories>cs.DS cs.CC</categories><comments>In this version, the algorithmic results have been extended to a new
  graph width, called neighborhood diversity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Possibly the most famous algorithmic meta-theorem is Courcelle's theorem,
which states that all MSO-expressible graph properties are decidable in linear
time for graphs of bounded treewidth. Unfortunately, the running time's
dependence on the MSO formula describing the problem is in general a tower of
exponentials of unbounded height, and there exist lower bounds proving that
this cannot be improved even if we restrict ourselves to deciding FO logic on
trees.
  In this paper we attempt to circumvent these lower bounds by focusing on a
subclass of bounded treewidth graphs, the graphs of bounded vertex cover. By
using a technique different from the standard decomposition and dynamic
programming technique of treewidth we prove that in this case the running time
implied by Courcelle's theorem can be improved dramatically, from
non-elementary to doubly and singly exponential for MSO and FO logic
respectively. Our technique relies on a new graph width measure we introduce,
for which we show some additional results that may indicate that it is of
independent interest. We also prove lower bound results which show that our
upper bounds cannot be improved significantly, under widely believed complexity
assumptions. Our work answers an open problem posed by Michael Fellows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0610</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0610</id><created>2009-10-04</created><updated>2010-10-17</updated><authors><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Shalev-Shwartz</keyname><forenames>Shai</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>Regularization Techniques for Learning with Matrices</title><categories>cs.LG stat.ML</categories><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is growing body of learning problems for which it is natural to
organize the parameters into matrix, so as to appropriately regularize the
parameters under some matrix norm (in order to impose some more sophisticated
prior knowledge). This work describes and analyzes a systematic method for
constructing such matrix-based, regularization methods. In particular, we focus
on how the underlying statistical properties of a given problem can help us
decide which regularization function is appropriate.
  Our methodology is based on the known duality fact: that a function is
strongly convex with respect to some norm if and only if its conjugate function
is strongly smooth with respect to the dual norm. This result has already been
found to be a key component in deriving and analyzing several learning
algorithms. We demonstrate the potential of this framework by deriving novel
generalization and regret bounds for multi-task learning, multi-class learning,
and kernel learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0626</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0626</id><created>2009-10-04</created><authors><author><keyname>Costan</keyname><forenames>Alexandru</forenames></author><author><keyname>Stratan</keyname><forenames>Corina</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Cristea</keyname><forenames>Valentin</forenames></author></authors><title>Towards a Grid Platform for Scientific Workflows Management</title><categories>cs.DC cs.NI</categories><acm-class>H.3.4; H.4.1</acm-class><journal-ref>Proc. of the 17th Intl. Conf. on Control Systems and Computer
  Science (CSCS), vol. 1, pp. 37-44, Bucharest, Romania, 26-29 May, 2009.
  (ISSN: 2066-4451)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Workflow management systems allow the users to develop complex applications
at a higher level, by orchestrating functional components without handling the
implementation details. Although a wide range of workflow engines are developed
in enterprise environments, the open source engines available for scientific
applications lack some functionalities or are too difficult to use for
non-specialists. Our purpose is to develop a workflow management platform for
distributed systems, that will provide features like an intuitive way to
describe workflows, efficient data handling mechanisms and flexible fault
tolerance support. We introduce here an architectural model for the workflow
platform, based on the ActiveBPEL workflow engine, which we propose to augment
with an additional set of components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0641</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0641</id><created>2009-10-04</created><updated>2010-04-09</updated><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Kopparty</keyname><forenames>Swastik</forenames></author><author><keyname>Schoenebeck</keyname><forenames>Grant</forenames></author><author><keyname>Sudan</keyname><forenames>Madhu</forenames></author><author><keyname>Zuckerman</keyname><forenames>David</forenames></author></authors><title>Optimal Testing of Reed-Muller Codes</title><categories>math.CO cs.CC cs.IT math.IT</categories><comments>22 pages; introduction reformulated and some minor changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of testing if a given function f : F_2^n -&gt; F_2 is
close to any degree d polynomial in n variables, also known as the Reed-Muller
testing problem. The Gowers norm is based on a natural 2^{d+1}-query test for
this property. Alon et al. [AKKLR05] rediscovered this test and showed that it
accepts every degree d polynomial with probability 1, while it rejects
functions that are Omega(1)-far with probability Omega(1/(d 2^{d})). We give an
asymptotically optimal analysis of this test, and show that it rejects
functions that are (even only) Omega(2^{-d})-far with Omega(1)-probability (so
the rejection probability is a universal constant independent of d and n). This
implies a tight relationship between the (d+1)st Gowers norm of a function and
its maximal correlation with degree d polynomials, when the correlation is
close to 1. Our proof works by induction on n and yields a new analysis of even
the classical Blum-Luby-Rubinfeld [BLR93] linearity test, for the setting of
functions mapping F_2^n to F_2. The optimality follows from a tighter analysis
of counterexamples to the &quot;inverse conjecture for the Gowers norm&quot; constructed
by [GT09,LMS08]. Our result has several implications. First, it shows that the
Gowers norm test is tolerant, in that it also accepts close codewords. Second,
it improves the parameters of an XOR lemma for polynomials given by Viola and
Wigderson [VW07]. Third, it implies a &quot;query hierarchy&quot; result for property
testing of affine-invariant properties. That is, for every function q(n), it
gives an affine-invariant property that is testable with O(q(n))-queries, but
not with o(q(n))-queries, complementing an analogous result of [GKNR09] for
graph properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0646</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0646</id><created>2009-10-04</created><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>Sadedin</keyname><forenames>Suzanne</forenames></author></authors><title>Digital Business Ecosystems: Natural Science Paradigms</title><categories>cs.NE</categories><comments>8 pages, 5 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A primary motivation for research in Digital Ecosystems is the desire to
exploit the self-organising properties of natural ecosystems. Ecosystems arc
thought to be robust, scalable architectures that can automatically solve
complex, dynamic problems. However, the biological processes that contribute to
these properties have not been made explicit in Digital Ecosystem research.
Here, we introduce how biological properties contribute to the self-organising
features of natural ecosystems. These properties include populations of
evolving agents, a complex dynamic environment, and spatial distributions which
generate local interactions. The potential for exploiting these properties in
artificial systems is then considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0650</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0650</id><created>2009-10-04</created><updated>2009-12-07</updated><authors><author><keyname>Tyagi</keyname><forenames>Himanshu</forenames></author></authors><title>Capacity Region of a State Dependent Degraded Broadcast Channel with
  Noncausal Transmitter CSI</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn due to a mistake in the previous
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn due to a mistake in the previous version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0651</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0651</id><created>2009-10-05</created><updated>2009-10-21</updated><authors><author><keyname>Recht</keyname><forenames>Benjamin</forenames></author></authors><title>A Simpler Approach to Matrix Completion</title><categories>cs.IT cs.NA math.IT math.OC</categories><comments>13 pages. Fixed typos. Added references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides the best bounds to date on the number of randomly sampled
entries required to reconstruct an unknown low rank matrix. These results
improve on prior work by Candes and Recht, Candes and Tao, and Keshavan,
Montanari, and Oh. The reconstruction is accomplished by minimizing the nuclear
norm, or sum of the singular values, of the hidden matrix subject to agreement
with the provided entries. If the underlying matrix satisfies a certain
incoherence condition, then the number of entries required is equal to a
quadratic logarithmic factor times the number of parameters in the singular
value decomposition. The proof of this assertion is short, self contained, and
uses very elementary analysis. The novel techniques herein are based on recent
work in quantum information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0653</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0653</id><created>2009-10-04</created><authors><author><keyname>Tyagi</keyname><forenames>Himanshu</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>The Gelfand-Pinsker Channel: Strong Converse and Upper Bound for the
  Reliability Function</title><categories>cs.IT math.IT</categories><comments>4 pages, Presented at the ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Gelfand-Pinsker discrete memoryless channel (DMC) model and
provide a strong converse for its capacity. The strong converse is then used to
obtain an upper bound on the reliability function. Instrumental in our proofs
is a new technical lemma which provides an upper bound for the rate of codes
with codewords that are conditionally typical over large message dependent
subsets of a typical set of state sequences. This technical result is a
nonstraightforward analog of a known result for a DMC without states that
provides an upper bound on the rate of a good code with codewords of a fixed
type (to be found in, for instance, the Csiszar-Korner book).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0663</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0663</id><created>2009-10-04</created><updated>2010-12-09</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Transmission line inspires a new distributed algorithm to solve linear
  system of circuit</title><categories>cs.CE cs.DC cs.MS cs.NA</categories><comments>This work was finished in Nov 2007. Recently we are preparing it for
  IEEE Trans. CAD. More info, see my web page at
  http://weifei00.googlepages.com</comments><msc-class>65F10, 65F50, 68M14</msc-class><acm-class>G.1.0; B.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmission line, or wire, is always troublesome to integrated circuits
designers, but it could be helpful to parallel computing researchers. This
paper proposes the Virtual Transmission Method (VTM), which is a new
distributed and stationary iterative algorithm to solve the linear system
extracted from circuit. It tears the circuit by virtual transmission lines to
achieve distributed computing. For the symmetric positive definite (SPD) linear
system, VTM is proved to be convergent. For the unsymmetrical linear system,
numerical experiments show that VTM is possible to achieve better convergence
property than the traditional stationary algorithms. VTM could be accelerated
by some preconditioning techniques, and the convergence speed of VTM is fast
when its preconditioner is properly chosen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0665</identifier>
 <datestamp>2010-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0665</id><created>2009-10-04</created><updated>2009-11-18</updated><authors><author><keyname>Kish</keyname><forenames>Lazar L.</forenames></author><author><keyname>Zhang</keyname><forenames>Bruce</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author></authors><title>Cracking the Liu key exchange protocol in its most secure state with
  Lorentzian spectra</title><categories>physics.data-an cs.CR quant-ph</categories><comments>Accepted for publication at November 18, 2009</comments><journal-ref>Fluctuation and Noise Letters Vol. 9, No. 1 (2010) 37-45</journal-ref><doi>10.1142/S0219477510000058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have found a security risk in the Liu's cypher based on random signals and
feedback, when it utilizes a large class of noises for communication in its
most secure state, the steady state. For the vulnerability to exist, the noise
must have a spectrum which can be transformed to white-like noise by linear
filtering. For the cracking, we utilize the natural properties of power density
spectra and autocorrelation functions. We introduce and demonstrate the method
for Lorentzian spectra. Some of the implications of the results concern the
transient operation during changing bits, where the modulation products of
noise cannot be band-limited therefore the cypher is vulnerable. We propose the
application of line filters to provide a proper spectral shape and to improve
the security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0668</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0668</id><created>2009-10-04</created><updated>2009-10-07</updated><authors><author><keyname>Qi</keyname><forenames>Yuan</forenames></author><author><keyname>Abdel-Gawad</keyname><forenames>Ahmed H.</forenames></author><author><keyname>Minka</keyname><forenames>Thomas P.</forenames></author></authors><title>Variable sigma Gaussian processes: An expectation propagation
  perspective</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian processes (GPs) provide a probabilistic nonparametric representation
of functions in regression, classification, and other problems. Unfortunately,
exact learning with GPs is intractable for large datasets. A variety of
approximate GP methods have been proposed that essentially map the large
dataset into a small set of basis points. The most advanced of these, the
variable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have
its own length scale. However, VSGP was only derived for regression. We
describe how VSGP can be applied to classification and other problems, by
deriving it as an expectation propagation algorithm. In this view, sparse GP
approximations correspond to a KL-projection of the true posterior onto a
compact exponential family of GPs. VSGP constitutes one such family, and we
show how to enlarge this family to get additional accuracy. In particular, we
show that endowing each basis point with its own full covariance matrix
provides a significant increase in approximation power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0674</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0674</id><created>2009-10-05</created><authors><author><keyname>Briscoe</keyname><forenames>G.</forenames></author><author><keyname>De Wilde</keyname><forenames>P.</forenames></author></authors><title>Computing of Applied Digital Ecosystems</title><categories>cs.NE cs.MA</categories><comments>8 pages, 10 figures, ACM Management of Emergent Digital EcoSystems
  (MEDES) 2009</comments><acm-class>C.2.4; D.2.11; H.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A primary motivation for our research in digital ecosystems is the desire to
exploit the self-organising properties of biological ecosystems. Ecosystems are
thought to be robust, scalable architectures that can automatically solve
complex, dynamic problems. However, the computing technologies that contribute
to these properties have not been made explicit in digital ecosystems research.
Here, we discuss how different computing technologies can contribute to
providing the necessary self-organising features, including Multi-Agent
Systems, Service-Oriented Architectures, and distributed evolutionary
computing. The potential for exploiting these properties in digital ecosystems
is considered, suggesting how several key features of biological ecosystems can
be exploited in Digital Ecosystems, and discussing how mimicking these features
may assist in developing robust, scalable self-organising architectures. An
example architecture, the Digital Ecosystem, is considered in detail. The
Digital Ecosystem is then measured experimentally through simulations,
considering the self-organised diversity of its evolving agent populations
relative to the user request behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0695</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0695</id><created>2009-10-05</created><updated>2010-02-11</updated><authors><author><keyname>Poinsot</keyname><forenames>L.</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G. H. E.</forenames><affiliation>LIPN</affiliation></author><author><keyname>Goodenough</keyname><forenames>S.</forenames><affiliation>LIPN</affiliation></author><author><keyname>Penson</keyname><forenames>K. A.</forenames><affiliation>LPTL</affiliation></author></authors><title>Statistics on Graphs, Exponential Formula and Combinatorial Physics</title><categories>cs.DM cs.CE math.CO quant-ph</categories><proxy>ccsd hal-00421897</proxy><journal-ref>Journal of Nonlinear Systems and Applications 1, 1 (2010) 58-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concern of this paper is a famous combinatorial formula known under the
name &quot;exponential formula&quot;. It occurs quite naturally in many contexts
(physics, mathematics, computer science). Roughly speaking, it expresses that
the exponential generating function of a whole structure is equal to the
exponential of those of connected substructures. Keeping this descriptive
statement as a guideline, we develop a general framework to handle many
different situations in which the exponential formula can be applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0703</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0703</id><created>2009-10-05</created><authors><author><keyname>Snarskii</keyname><forenames>D. V. Lande A. A.</forenames></author></authors><title>Self-similarity properties in a queuing network model</title><categories>cs.NI cs.DM</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a model of subscriber telephone network based on the concept of
cellular automata is elaborated. Some fractal properties inherent in the model
are revealed that vary depending on parameters assigning its operation rules.
The main advantage of the model in question is its compatibility with
algorithmic methods - a finite set of formal rules, assigned on a finite set of
elements (cells), allows precise realization in the form of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0708</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0708</id><created>2009-10-05</created><authors><author><keyname>Dobre</keyname><forenames>Ciprian Mihai</forenames></author><author><keyname>Pop</keyname><forenames>Florin</forenames></author><author><keyname>Costan</keyname><forenames>Alexandru</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Cristea</keyname><forenames>Valentin</forenames></author></authors><title>Robust Failure Detection Architecture for Large Scale Distributed
  Systems</title><categories>cs.DC cs.NI</categories><acm-class>C.2.4; C.4; D.4.5</acm-class><journal-ref>Proc. of the 17th Intl. Conf. on Control Systems and Computer
  Science (CSCS), vol. 1, pp. 433-440, Bucharest, Romania, 26-29 May, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Failure detection is a fundamental building block for ensuring fault
tolerance in large scale distributed systems. There are lots of approaches and
implementations in failure detectors. Providing flexible failure detection in
off-the-shelf distributed systems is difficult. In this paper we present an
innovative solution to this problem. Our approach is based on adaptive,
decentralized failure detectors, capable of working asynchronous and
independent on the application flow. The proposed solution considers an
architecture for the failure detectors, based on clustering, the use of a
gossip-based algorithm for detection at local level and the use of a
hierarchical structure among clusters of detectors along which traffic is
channeled. The solution can scale to a large number of nodes, considers the QoS
requirements of both applications and resources, and includes fault tolerance
and system orchestration mechanisms, added in order to asses the reliability
and availability of distributed systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0733</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0733</id><created>2009-10-05</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Co-Channel Interference Cancellation in OFDM Networks using Coordinated
  Symbol Repetition and Soft Decision MLE CCI Canceler</title><categories>cs.OH</categories><comments>4 pages, 8 figures, IEEE International Conference on Signal
  Processing and Communications, 2007. ICSPC 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new scheme of downlink co-channel interference (CCI)
cancellation in OFDM cellular networks is introduced for users at the
cell-edge. Coordinated symbol transmission between base stations (BS) is
operated where the same symbol is transmitted from different BS on different
sub-carriers. At the mobile station (MS) receiver, we introduce a soft decision
maximum likelihood CCI canceler and a modified maximum ratio combining (M-MRC)
to obtain an estimate of the transmitted symbols. Weights used in the combining
method are derived from the channels coefficients between the cooperated BS and
the MS. Simulations show that the proposed scheme works well under
frequency-selective channels and frequency non-selective channels. A gain of 9
dB and 6 dB in SIR is obtained under multipath fading and flat-fading channels,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0735</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0735</id><created>2009-10-05</created><authors><author><keyname>De Francesco</keyname><forenames>Erika</forenames></author><author><keyname>Iiritano</keyname><forenames>Salvatore</forenames></author><author><keyname>Spagnolo</keyname><forenames>Antonino</forenames></author><author><keyname>Iannelli</keyname><forenames>Marco</forenames></author></authors><title>A methodology for semi-automatic classification schema building</title><categories>cs.OH</categories><comments>36 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describe a methodology for semi-automatic classification schema
definition (a classification schema is a taxonomy of categories useful for
automatic document classification). The methodology is based on: (i) an
extensional approach useful to create a typology starting from a document base,
and (ii) an intensional approach to build the classification schema starting
from the typology. The extensional approach uses clustering techniques to group
together documents on the basis of a similarity measure, whereas the
intensional approach uses different operations (aggregation, reduction,
generalization specialization) to define classes. keywords: ontology,
classification schema, fundamentum divisionis, cluster analysis classification
task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0747</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0747</id><created>2009-10-05</created><updated>2009-10-05</updated><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author></authors><title>A Framework for Specifying, Prototyping, and Reasoning about
  Computational Systems</title><categories>cs.LO cs.PL</categories><comments>PhD Thesis submitted September, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis concerns the development of a framework that facilitates the
design and analysis of formal systems. Specifically, this framework provides a
specification language which supports the concise and direct description of
formal systems, a mechanism for animating the specification language thereby
producing prototypes of encoded systems, and a logic for proving properties of
specifications and therefore of the systems they encode. A defining
characteristic of the proposed framework is that it is based on two separate
but closely intertwined logics: a specification logic that facilitates the
description of computational structure and another logic that exploits the
special characteristics of the specification logic to support reasoning about
the computational behavior of systems that are described using it. Both logics
embody a natural treatment of binding structure by using the lambda-calculus as
a means for representing objects and by incorporating special mechanisms for
working with such structure. By using this technique, they lift the treatment
of binding from the object language into the domain of the relevant meta logic,
thereby allowing the specification or analysis components to focus on the more
essential logical aspects of the systems that are encoded. The primary
contributions of these thesis are the development of a rich meta-logic called G
with capabilities for sophisticated reasoning that includes induction and
co-induction over high-level specifications of computations and with an
associated cut-elimination result; an interactive reasoning system called
Abella based on G; and several reasoning examples which demonstrate the
expressiveness and naturalness of both G and Abella.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0750</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0750</id><created>2009-10-05</created><authors><author><keyname>Richard</keyname><forenames>Adrien</forenames></author></authors><title>Local negative circuits and fixed points in Boolean networks</title><categories>cs.DM</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To each Boolean function F from {0,1}^n to itself and each point x in
{0,1}^n, we associate the signed directed graph G_F(x) of order n that contains
a positive (resp. negative) arc from j to i if the partial derivative of f_i
with respect of x_j is positive (resp. negative) at point x. We then focus on
the following open problem: Is the absence of a negative circuit in G_F(x) for
all x in {0,1}^n a sufficient condition for F to have at least one fixed point?
As main result, we settle this problem under the additional condition that, for
all x in {0,1}^n, the out-degree of each vertex of G_F(x) is at most one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0767</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0767</id><created>2009-10-05</created><updated>2009-11-23</updated><authors><author><keyname>Bailly-Bechet</keyname><forenames>M.</forenames></author><author><keyname>Bradde</keyname><forenames>S.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Flaxman</keyname><forenames>A.</forenames></author><author><keyname>Foini</keyname><forenames>L.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Clustering with shallow trees</title><categories>cond-mat.dis-nn cs.DS q-bio.QM</categories><comments>11 pages, 7 figures</comments><journal-ref>J. Stat. Mech. (2009) P12010</journal-ref><doi>10.1088/1742-5468/2009/12/P12010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for hierarchical clustering based on the optimisation
of a cost function over trees of limited depth, and we derive a
message--passing method that allows to solve it efficiently. The method and
algorithm can be interpreted as a natural interpolation between two well-known
approaches, namely single linkage and the recently presented Affinity
Propagation. We analyze with this general scheme three biological/medical
structured datasets (human population based on genetic information, proteins
based on sequences and verbal autopsies) and show that the interpolation
technique provides new insight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0777</identifier>
 <datestamp>2011-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0777</id><created>2009-10-05</created><updated>2011-09-26</updated><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames></author><author><keyname>Heeringa</keyname><forenames>Brent</forenames></author><author><keyname>Wilfong</keyname><forenames>Gordon</forenames></author></authors><title>The Knapsack Problem with Neighbour Constraints</title><categories>cs.DS cs.DM</categories><comments>Full version of IWOCA 2011 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a constrained version of the knapsack problem in which dependencies
between items are given by the adjacencies of a graph. In the 1-neighbour
knapsack problem, an item can be selected only if at least one of its
neighbours is also selected. In the all-neighbours knapsack problem, an item
can be selected only if all its neighbours are also selected. We give
approximation algorithms and hardness results when the nodes have both uniform
and arbitrary weight and profit functions, and when the dependency graph is
directed and undirected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0817</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0817</id><created>2009-10-05</created><authors><author><keyname>Shanmugapriya</keyname><forenames>D.</forenames></author><author><keyname>Padmavathi</keyname><forenames>G.</forenames></author></authors><title>A Survey of Biometric keystroke Dynamics: Approaches, Security and
  Challenges</title><categories>cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSn 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 115-119, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometrics technologies are gaining popularity today since they provide more
reliable and efficient means of authentication and verification. Keystroke
Dynamics is one of the famous biometric technologies, which will try to
identify the authenticity of a user when the user is working via a keyboard.
The authentication process is done by observing the change in the typing
pattern of the user. A comprehensive survey of the existing keystroke dynamics
methods, metrics, different approaches are given in this study. This paper also
discusses about the various security issues and challenges faced by keystroke
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0819</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0819</id><created>2009-10-05</created><authors><author><keyname>Islam</keyname><forenames>Md. Ashraful</forenames></author><author><keyname>Mondal</keyname><forenames>Riaz Uddin</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Zahid</forenames></author></authors><title>Performance Evaluation of Wimax Physical Layer under Adaptive Modulation
  Techniques and Communication Channels</title><categories>cs.PF</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSn 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 111-114, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wimax (Worldwide Interoperability for Microwave Access) is a promising
technology which can offer high speed voice, video and data service up to the
customer end. The aim of this paper is the performance evaluation of an Wimax
system under different combinations of digital modulation (BPSK, QPSK, 4 QAM
and 16 QAM) and different communication channels AWGN and fading channels
(Rayleigh and Rician). And the Wimax system incorporates Reed Solomon (RS)
encoder with Convolutional encoder with half and two third rated codes in FEC
channel coding. The simulation results of estimated Bit Error Rate (BER)
displays that the implementation of interleaved RS code (255, 239, 8) with two
third rated Convolutional code under BPSK modulation technique is highly
effective to combat in the Wimax communication system. To complete this
performance analysis in Wimax based systems, a segment of audio signal is used
for analysis. The transmitted audio message is found to have retrieved
effectively under noisy situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0820</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0820</id><created>2009-10-05</created><updated>2009-10-08</updated><authors><author><keyname>Permanasari</keyname><forenames>Adhistya Erna</forenames></author><author><keyname>Rambli</keyname><forenames>Dayang Rohaya Awang</forenames></author><author><keyname>Dominic</keyname><forenames>Dhanapal Durai</forenames></author></authors><title>Prediction of Zoonosis Incidence in Human using Seasonal Auto Regressive
  Integrated Moving Average (SARIMA)</title><categories>cs.LG q-bio.QM</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSn 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 103-110, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zoonosis refers to the transmission of infectious diseases from animal to
human. The increasing number of zoonosis incidence makes the great losses to
lives, including humans and animals, and also the impact in social economic. It
motivates development of a system that can predict the future number of
zoonosis occurrences in human. This paper analyses and presents the use of
Seasonal Autoregressive Integrated Moving Average (SARIMA) method for
developing a forecasting model that able to support and provide prediction
number of zoonosis human incidence. The dataset for model development was
collected on a time series data of human tuberculosis occurrences in United
States which comprises of fourteen years of monthly data obtained from a study
published by Centers for Disease Control and Prevention (CDC). Several trial
models of SARIMA were compared to obtain the most appropriate model. Then,
diagnostic tests were used to determine model validity. The result showed that
the SARIMA(9,0,14)(12,1,24)12 is the fittest model. While in the measure of
accuracy, the selected model achieved 0.062 of Theils U value. It implied that
the model was highly accurate and a close fit. It was also indicated the
capability of final model to closely represent and made prediction based on the
tuberculosis historical dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0827</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0827</id><created>2009-10-05</created><updated>2010-05-31</updated><authors><author><keyname>Bianchi</keyname><forenames>Pascal</forenames><affiliation>LTCI</affiliation></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames><affiliation>Chaire Radio Flexible</affiliation></author><author><keyname>Ma&#xef;da</keyname><forenames>Myl&#xe8;ne</forenames><affiliation>LM-Orsay</affiliation></author><author><keyname>Najim</keyname><forenames>Jamal</forenames><affiliation>LTCI</affiliation></author></authors><title>Performance of Statistical Tests for Single Source Detection using
  Random Matrix Theory</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>45 p. improved presentation; more proofs provided</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a unified framework for the detection of a source with
a sensor array in the context where the noise variance and the channel between
the source and the sensors are unknown at the receiver. The Generalized Maximum
Likelihood Test is studied and yields the analysis of the ratio between the
maximum eigenvalue of the sampled covariance matrix and its normalized trace.
Using recent results of random matrix theory, a practical way to evaluate the
threshold and the $p$-value of the test is provided in the asymptotic regime
where the number $K$ of sensors and the number $N$ of observations per sensor
are large but have the same order of magnitude. The theoretical performance of
the test is then analyzed in terms of Receiver Operating Characteristic (ROC)
curve. It is in particular proved that both Type I and Type II error
probabilities converge to zero exponentially as the dimensions increase at the
same rate, and closed-form expressions are provided for the error exponents.
These theoretical results rely on a precise description of the large deviations
of the largest eigenvalue of spiked random matrix models, and establish that
the presented test asymptotically outperforms the popular test based on the
condition number of the sampled covariance matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0832</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0832</id><created>2009-10-05</created><authors><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>LIP6</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Optimal deterministic ring exploration with oblivious asynchronous
  robots</title><categories>cs.DS</categories><proxy>ccsd inria-00422100</proxy><doi>10.1007/978-3-642-13284-1_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of exploring an anonymous unoriented ring of size $n$
by $k$ identical, oblivious, asynchronous mobile robots, that are unable to
communicate, yet have the ability to sense their environment and take decisions
based on their local view. Previous works in this weak scenario prove that $k$
must not divide $n$ for a deterministic solution to exist. Also, it is known
that the minimum number of robots (either deterministic or probabilistic) to
explore a ring of size $n$ is 4. An upper bound of 17 robots holds in the
deterministic case while 4 probabilistic robots are sufficient. In this paper,
we close the complexity gap in the deterministic setting, by proving that no
deterministic exploration is feasible with less than five robots whenever the
size of the ring is even, and that five robots are sufficient for any $n$ that
is coprime with five. Our protocol completes exploration in O(n) robot moves,
which is also optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0868</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0868</id><created>2009-10-05</created><authors><author><keyname>Beohar</keyname><forenames>Harsh</forenames></author><author><keyname>Cuijpers</keyname><forenames>Pieter</forenames></author><author><keyname>Baeten</keyname><forenames>Jos</forenames></author></authors><title>Design of asynchronous supervisors</title><categories>cs.LO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  One of the main drawbacks while implementing the interaction between a plant
and a supervisor, synthesised by the supervisory control theory of
\citeauthor{RW:1987}, is the inexact synchronisation. \citeauthor{balemiphdt}
was the first to consider this problem, and the solutions given in his PhD
thesis were in the domain of automata theory. Our goal is to address the issue
of inexact synchronisation in a process algebra setting, because we get
concepts like modularity and abstraction for free, which are useful to further
analyze the synthesised system. In this paper, we propose four methods to check
a closed loop system in an asynchronous setting such that it is branching
bisimilar to the modified (asynchronous) closed loop system. We modify a given
closed loop system by introducing buffers either in the plant models, the
supervisor models, or the output channels of both supervisor and plant models,
or in the input channels of both supervisor and plant models. A notion of
desynchronisable closed loop system is introduced, which is a class of
synchronous closed loop systems such that they are branching bisimilar to their
corresponding asynchronous versions. Finally we study different case studies in
an asynchronous setting and then try to summarise the observations (or
conditions) which will be helpful in order to formulate a theory of
desynchronisable closed loop systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0880</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0880</id><created>2009-10-05</created><authors><author><keyname>Ghosh</keyname><forenames>Arpita</forenames></author><author><keyname>McAfee</keyname><forenames>Preston</forenames></author><author><keyname>Papineni</keyname><forenames>Kishore</forenames></author><author><keyname>Vassilvitskii</keyname><forenames>Sergei</forenames></author></authors><title>Bidding for Representative Allocations for Display Advertising</title><categories>cs.MA cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Display advertising has traditionally been sold via guaranteed contracts -- a
guaranteed contract is a deal between a publisher and an advertiser to allocate
a certain number of impressions over a certain period, for a pre-specified
price per impression. However, as spot markets for display ads, such as the
RightMedia Exchange, have grown in prominence, the selection of advertisements
to show on a given page is increasingly being chosen based on price, using an
auction. As the number of participants in the exchange grows, the price of an
impressions becomes a signal of its value. This correlation between price and
value means that a seller implementing the contract through bidding should
offer the contract buyer a range of prices, and not just the cheapest
impressions necessary to fulfill its demand.
  Implementing a contract using a range of prices, is akin to creating a mutual
fund of advertising impressions, and requires {\em randomized bidding}. We
characterize what allocations can be implemented with randomized bidding,
namely those where the desired share obtained at each price is a non-increasing
function of price. In addition, we provide a full characterization of when a
set of campaigns are compatible and how to implement them with randomized
bidding strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0881</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0881</id><created>2009-10-05</created><updated>2009-10-06</updated><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>When Watchdog Meets Coding</title><categories>cs.CR cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the problem of misbehavior detection in wireless
networks. A commonly adopted approach is to utilize the broadcasting nature of
the wireless medium and have nodes monitor their neighborhood. We call such
nodes the Watchdogs. In this paper, we first show that even if a watchdog can
overhear all packet transmissions of a flow, any linear operation of the
overheard packets can not eliminate miss-detection and is inefficient in terms
of bandwidth. We propose a light-weigh misbehavior detection scheme which
integrates the idea of watchdogs and error detection coding. We show that even
if the watchdog can only observe a fraction of packets, by choosing the encoder
properly, an attacker will be detected with high probability while achieving
throughput arbitrarily close to optimal. Such properties reduce the incentive
for the attacker to attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0886</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0886</id><created>2009-10-05</created><updated>2010-03-27</updated><authors><author><keyname>Shah</keyname><forenames>Sagar</forenames></author><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author></authors><title>Step-Frequency Radar with Compressive Sampling (SFR-CS)</title><categories>cs.IT math.IT</categories><comments>4 pages, 5 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Step-frequency radar (SFR) is a high resolution radar approach, where
multiple pulses are transmitted at different frequencies, covering a wide
spectrum. The obtained resolution directly depends on the total bandwidth used,
or equivalently, the number of transmitted pulses. This paper proposes a novel
SFR system, namely SFR with compressive sampling (SFRCS), that achieves the
same resolution as a conventional SFR, while using significantly reduced
bandwidth, or equivalently, transmitting significantly fewer pulses. This
bandwidth reduction is accomplished by employing compressive sampling ideas and
exploiting the sparseness of targets in the range velocity space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0887</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0887</id><created>2009-10-05</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author><author><keyname>Pasupathy</keyname><forenames>Subbarayan</forenames></author></authors><title>Green Modulation in Proactive Wireless Sensor Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Wireless Communications (25 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to unique characteristics of sensor nodes, choosing energy-efficient
modulation scheme with low-complexity implementation (refereed to as green
modulation) is a critical factor in the physical layer of Wireless Sensor
Networks (WSNs). This paper presents (to the best of our knowledge) the first
in-depth analysis of energy efficiency of various modulation schemes using
realistic models in IEEE 802.15.4 standard and present state-of-the art
technology, to find the best scheme in a proactive WSN over Rayleigh and Rician
flat-fading channel models with path-loss. For this purpose, we describe the
system model according to a pre-determined time-based process in practical
sensor nodes. The present analysis also includes the effect of bandwidth and
active mode duration on energy efficiency of popular modulation designs in the
pass-band and Ultra-WideBand (UWB) categories. Experimental results show that
among various pass-band and UWB modulation schemes, Non-Coherent M-ary
Frequency Shift Keying (NC-MFSK) with small order of $M$ and On-Off Keying
(OOK) have significant energy saving compared to other schemes for short range
scenarios, and could be considered as realistic candidates in WSNs. In
addition, NC-MFSK and OOK have the advantage of less complexity and cost in
implementation than the other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0899</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0899</id><created>2009-10-05</created><authors><author><keyname>Cao</keyname><forenames>Yi</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>Interference Channels with One Cognitive Transmitter</title><categories>cs.IT math.IT</categories><comments>33 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of interference channels with one cognitive
transmitter (ICOCT) where &quot;cognitive&quot; is defined from both the noncausal and
causal perspectives. For the noncausal ICOCT, referred to as interference
channels with degraded message sets (IC-DMS), we propose a new achievable rate
region that generalizes existing achievable rate regions for IC-DMS. In the
absence of the noncognitive transmitter, the proposed region coincides with
Marton's region for the broadcast channel. Based on this result, the capacity
region of a class of semi-deterministic IC-DMS is established. For the causal
ICOCT, due to the complexity of the channel model, we focus primarily on the
cognitive Z interference channel (ZIC), where the interference link from the
cognitive transmitter to the primary receiver is assumed to be absent due to
practical design considerations. Capacity bounds for such channels in different
parameter regimes are obtained and the impact of such causal cognitive ability
is carefully studied. In particular, depending on the channel parameters, the
cognitive link may not be useful in terms of enlarging the capacity region. An
optimal corner point of the capacity region is also established for the
cognitive ZIC for a certain parameter regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0902</identifier>
 <datestamp>2009-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0902</id><created>2009-10-06</created><updated>2009-12-22</updated><authors><author><keyname>Siddiqi</keyname><forenames>Sajid M.</forenames></author><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey J.</forenames></author></authors><title>Reduced-Rank Hidden Markov Models</title><categories>cs.LG cs.AI</categories><comments>Updated robot experiment figure, added details on KDE, fixed a couple
  of errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization
of HMMs that can model smooth state evolution as in Linear Dynamical Systems
(LDSs) as well as non-log-concave predictive distributions as in
continuous-observation HMMs. RR-HMMs assume an m-dimensional latent state and n
discrete observations, with a transition matrix of rank k &lt;= m. This implies
the dynamics evolve in a k-dimensional subspace, while the shape of the set of
predictive distributions is determined by m. Latent state belief is represented
with a k-dimensional state vector and inference is carried out entirely in R^k,
making RR-HMMs as computationally efficient as k-state HMMs yet more
expressive. To learn RR-HMMs, we relax the assumptions of a recently proposed
spectral learning algorithm for HMMs (Hsu, Kakade and Zhang 2009) and apply it
to learn k-dimensional observable representations of rank-k RR-HMMs. The
algorithm is consistent and free of local optima, and we extend its performance
guarantees to cover the RR-HMM case. We show how this algorithm can be used in
conjunction with a kernel density estimator to efficiently model
high-dimensional multivariate continuous data. We also relax the assumption
that single observations are sufficient to disambiguate state, and extend the
algorithm accordingly. Experiments on synthetic data and a toy video, as well
as on a difficult robot vision modeling problem, yield accurate models that
compare favorably with standard alternatives in simulation quality and
prediction capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0906</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0906</id><created>2009-10-05</created><updated>2011-01-13</updated><authors><author><keyname>Leinster</keyname><forenames>Tom</forenames></author></authors><title>A maximum entropy theorem with applications to the measurement of
  biodiversity</title><categories>cs.IT math.IT q-bio.PE q-bio.QM</categories><comments>26 pages. v4: references added, and other minor edits</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a preliminary article stating and proving a new maximum entropy
theorem. The entropies that we consider can be used as measures of
biodiversity. In that context, the question is: for a given collection of
species, which frequency distribution(s) maximize the diversity? The theorem
provides the answer. The chief surprise is that although we are dealing with
not just a single entropy, but a one-parameter family of entropies, there is a
single distribution maximizing all of them simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0916</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0916</id><created>2009-10-05</created><authors><author><keyname>Arcaute</keyname><forenames>Esteban</forenames></author><author><keyname>Vassilvitskii</keyname><forenames>Sergei</forenames></author></authors><title>Social Networks and Stable Matchings in the Job Market</title><categories>cs.GT</categories><comments>19 pages. A preliminary version will appear at the 5th International
  Workshop on Internet and Network Economics, WINE 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For most people, social contacts play an integral part in finding a new job.
As observed by Granovetter's seminal study, the proportion of jobs obtained
through social contacts is usually large compared to those obtained through
postings or agencies. At the same time, job markets are a natural example of
two-sided matching markets. An important solution concept in such markets is
that of stable matchings, and the use of the celebrated Gale-Shapley algorithm
to compute them. So far, the literature has evolved separately, either focusing
on the implications of information flowing through a social network, or on
developing a mathematical theory of job markets through the use of two-sided
matching techniques.
  In this paper we provide a model of the job market that brings both aspects
of job markets together. To model the social scientists' observations, we
assume that workers learn only about positions in firms through social
contacts. Given that information structure, we study both static properties of
what we call locally stable matchings (i.e., stable matchings subject to
informational constraints given by a social network) and dynamic properties
through a reinterpretation of Gale-Shapley's algorithm as myopic best response
dynamics.
  We prove that, in general, the set of locally stable matching strictly
contains that of stable matchings and it is in fact NP-complete to determine if
they are identical. We also show that the lattice structure of stable matchings
is in general absent. Finally, we focus on myopic best response dynamics
inspired by the Gale-Shapley algorithm. We study the efficiency loss due to the
informational constraints, providing both lower and upper bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0918</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0918</id><created>2009-10-05</created><authors><author><keyname>Kar</keyname><forenames>S.</forenames></author><author><keyname>Sinopoli</keyname><forenames>B.</forenames></author><author><keyname>Moura</keyname><forenames>J. M. F.</forenames></author></authors><title>A Random Dynamical Systems Approach to Filtering in Large-scale Networks</title><categories>cs.IT cs.MA math.IT math.OC math.PR</categories><comments>8 pages. Submitted to the American Control Conference, ACC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the problem of filtering a discrete-time linear system
observed by a network of sensors. The sensors share a common communication
medium to the estimator and transmission is bit and power budgeted. Under the
assumption of conditional Gaussianity of the signal process at the estimator
(which may be ensured by observation packet acknowledgements), the conditional
prediction error covariance of the optimum mean-squared error filter is shown
to evolve according to a random dynamical system (RDS) on the space of
non-negative definite matrices. Our RDS formalism does not depend on the
particular medium access protocol (randomized) and, under a minimal distributed
observability assumption, we show that the sequence of random conditional
prediction error covariance matrices converges in distribution to a unique
invariant distribution (independent of the initial filter state), i.e., the
conditional error process is shown to be ergodic. Under broad assumptions on
the medium access protocol, we show that the conditional error covariance
sequence satisfies a Markov-Feller property, leading to an explicit
characterization of the support of its invariant measure. The methodology
adopted in this work is sufficiently general to envision this application to
sample path analysis of more general hybrid or switched systems, where existing
analysis is mostly moment-based.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0921</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0921</id><created>2009-10-06</created><updated>2009-11-03</updated><authors><author><keyname>Keshavan</keyname><forenames>Raghunandan H.</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author></authors><title>Low-rank Matrix Completion with Noisy Observations: a Quantitative
  Comparison</title><categories>cs.LG cs.NA</categories><comments>7 pages, 7 figures, 47th Allerton Conference on Communication Control
  and Computing, 2009, invited paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a problem of significant practical importance, namely, the
reconstruction of a low-rank data matrix from a small subset of its entries.
This problem appears in many areas such as collaborative filtering, computer
vision and wireless sensor networks. In this paper, we focus on the matrix
completion problem in the case when the observed samples are corrupted by
noise. We compare the performance of three state-of-the-art matrix completion
algorithms (OptSpace, ADMiRA and FPCA) on a single simulation platform and
present numerical results. We show that in practice these efficient algorithms
can be used to reconstruct real data matrices, as well as randomly generated
matrices, accurately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0928</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0928</id><created>2009-10-06</created><authors><author><keyname>Barnat</keyname><forenames>Ji&#x159;&#xed;</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Brim</keyname><forenames>Lubo&#x161;</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>&#x10c;ern&#xe1;</keyname><forenames>Ivana</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Dra&#x17e;an</keyname><forenames>Sven</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Fabrikov&#xe1;</keyname><forenames>Jana</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>L&#xe1;n&#xed;k</keyname><forenames>Jan</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>&#x160;afr&#xe1;nek</keyname><forenames>David</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Ma</keyname><forenames>Hongwu</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>BioDiVinE: A Framework for Parallel Analysis of Biological Models</title><categories>cs.CE cs.DC q-bio.QM</categories><journal-ref>EPTCS 6, 2009, pp. 31-45</journal-ref><doi>10.4204/EPTCS.6.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel tool BioDiVinEfor parallel analysis of biological
models is presented. The tool allows analysis of biological models specified in
terms of a set of chemical reactions. Chemical reactions are transformed into a
system of multi-affine differential equations. BioDiVinE employs techniques for
finite discrete abstraction of the continuous state space. At that level,
parallel analysis algorithms based on model checking are provided. In the
paper, the key tool features are described and their application is
demonstrated by means of a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0983</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0983</id><created>2009-10-06</created><authors><author><keyname>Skopal</keyname><forenames>Tomas</forenames></author><author><keyname>Lokoc</keyname><forenames>Jakub</forenames></author></authors><title>On Metric Skyline Processing by PM-tree</title><categories>cs.DB cs.DL cs.MM cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of similarity search in multimedia databases is usually accomplished
by range or k nearest neighbor queries. However, the expressing power of these
&quot;single-example&quot; queries fails when the user's delicate query intent is not
available as a single example. Recently, the well-known skyline operator was
reused in metric similarity search as a &quot;multi-example&quot; query type. When
applied on a multi-dimensional database (i.e., on a multi-attribute table), the
traditional skyline operator selects all database objects that are not
dominated by other objects. The metric skyline query adopts the skyline
operator such that the multiple attributes are represented by distances
(similarities) to multiple query examples. Hence, we can view the metric
skyline as a set of representative database objects which are as similar to all
the examples as possible and, simultaneously, are semantically distinct. In
this paper we propose a technique of processing the metric skyline query by use
of PM-tree, while we show that our technique significantly outperforms the
original M-tree based implementation in both time and space costs. In
experiments we also evaluate the partial metric skyline processing, where only
a controlled number of skyline objects is retrieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.0996</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.0996</id><created>2009-10-06</created><authors><author><keyname>Cohen</keyname><forenames>Ernie</forenames></author></authors><title>Pessimistic Testing</title><categories>cs.SE cs.GT</categories><comments>2 pages, 3 refrences</comments><acm-class>D.2.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach to testing conformance to a nondeterministic
specification, in which testing proceeds only as long as increased test
coverage is guaranteed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1014</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1014</id><created>2009-10-06</created><updated>2009-10-08</updated><authors><author><keyname>Tranouez</keyname><forenames>Pierrick</forenames><affiliation>LITIS</affiliation></author><author><keyname>Dutot</keyname><forenames>Antoine</forenames><affiliation>LITIS</affiliation></author></authors><title>Building upon Fast Multipole Methods to Detect and Model Organizations</title><categories>cs.AI</categories><proxy>ccsd hal-00422358</proxy><journal-ref>DCDIS Series B: Applications &amp; Algorithms 16, 4 (2009) 489 - 500</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many models in natural and social sciences are comprised of sets of
inter-acting entities whose intensity of interaction decreases with distance.
This often leads to structures of interest in these models composed of dense
packs of entities. Fast Multipole Methods are a family of methods developed to
help with the calculation of a number of computable models such as described
above. We propose a method that builds upon FMM to detect and model the dense
structures of these systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1020</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1020</id><created>2009-10-06</created><authors><author><keyname>Crolard</keyname><forenames>Tristan</forenames></author><author><keyname>Polonowski</keyname><forenames>Emmanuel</forenames></author></authors><title>A Formally Specified Type System and Operational Semantics for
  Higher-Order Procedural Variables</title><categories>cs.LO</categories><report-no>TR-LACL-2009-3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formally specified the type system and operational semantics of LOOPw with
Ott and Isabelle/HOL proof assistant. Moreover, both the type system and the
semantics of LOOPw have been tested using Isabelle/HOL program extraction
facility for inductively defined relations. In particular, the program that
computes the Ackermann function type checks and behaves as expected. The main
difference (apart from the choice of an Ada-like concrete syntax) with LOOPw
comes from the treatment of parameter passing. Indeed, since Ott does not
currently fully support alpha-conversion, we rephrased the operational
semantics with explicit aliasing in order to implement the out parameter
passing mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1026</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1026</id><created>2009-10-06</created><authors><author><keyname>Daud&#xe9;</keyname><forenames>Eric</forenames><affiliation>IDEES</affiliation></author><author><keyname>Tranouez</keyname><forenames>Pierrick</forenames><affiliation>LITIS</affiliation></author><author><keyname>Langlois</keyname><forenames>Patrice</forenames><affiliation>IDEES</affiliation></author></authors><title>A multiagent urban traffic simulation. Part II: dealing with the
  extraordinary</title><categories>cs.AI</categories><proxy>ccsd hal-00422372</proxy><journal-ref>ICCSA 2009, France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Probabilistic Risk Management, risk is characterized by two quantities:
the magnitude (or severity) of the adverse consequences that can potentially
result from the given activity or action, and by the likelihood of occurrence
of the given adverse consequences. But a risk seldom exists in isolation: chain
of consequences must be examined, as the outcome of one risk can increase the
likelihood of other risks. Systemic theory must complement classic PRM. Indeed
these chains are composed of many different elements, all of which may have a
critical importance at many different levels. Furthermore, when urban
catastrophes are envisioned, space and time constraints are key determinants of
the workings and dynamics of these chains of catastrophes: models must include
a correct spatial topology of the studied risk. Finally, literature insists on
the importance small events can have on the risk on a greater scale: urban
risks management models belong to self-organized criticality theory. We chose
multiagent systems to incorporate this property in our model: the behavior of
an agent can transform the dynamics of important groups of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1028</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1028</id><created>2009-10-06</created><authors><author><keyname>Cohen</keyname><forenames>Ernie</forenames></author></authors><title>Weak Kleene Algebra is Sound and (Possibly) Complete for Simulation</title><categories>cs.LO cs.PL</categories><comments>12 pages, 9 references</comments><acm-class>F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the axioms of Weak Kleene Algebra (WKA) are sound and complete
for the theory of regular expressions modulo simulation equivalence, assuming
their completeness for monodic trees (as conjectured by Takai and Furusawa).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1059</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1059</id><created>2009-10-06</created><authors><author><keyname>Catusse</keyname><forenames>Nicolas</forenames></author><author><keyname>Chepoi</keyname><forenames>Victor</forenames></author><author><keyname>Vax&#xe8;s</keyname><forenames>Yann</forenames></author></authors><title>Embedding into the rectilinear plane in optimal O*(n^2)</title><categories>cs.CG cs.DS</categories><comments>12 pages, 13 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Theoretical Computer Science Volume 412, Issue 22 (2011), Pages
  2425-2433</journal-ref><doi>10.1016/j.tcs.2011.01.038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an optimal O*(n^2) time algorithm for deciding if a metric space
(X,d) on n points can be isometrically embedded into the plane endowed with the
l_1-metric. It improves the O*(n^2 log^2 n) time algorithm of J. Edmonds
(2008). Together with some ingredients introduced by J. Edmonds, our algorithm
uses the concept of tight span and the injectivity of the l_1-plane. A
different O*(n^2) time algorithm was recently proposed by D. Eppstein (2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1121</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1121</id><created>2009-10-06</created><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>LP Decoding meets LP Decoding: A Connection between Channel Coding and
  Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>Appeared in the Proceedings of the 47th Allerton Conference on
  Communications, Control, and Computing, Allerton House, Monticello, Illinois,
  USA, Sep. 30 - Oct. 2, 2009. This version of the paper contains all the
  proofs that were omitted in the official version due to space limitations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a tale of two linear programming decoders, namely channel coding
linear programming decoding (CC-LPD) and compressed sensing linear programming
decoding (CS-LPD). So far, they have evolved quite independently. The aim of
the present paper is to show that there is a tight connection between, on the
one hand, CS-LPD based on a zero-one measurement matrix over the reals and, on
the other hand, CC-LPD of the binary linear code that is obtained by viewing
this measurement matrix as a binary parity-check matrix. This connection allows
one to translate performance guarantees from one setup to the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1123</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1123</id><created>2009-10-06</created><authors><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Can Iterative Decoding for Erasure Correlated Sources be Universal?</title><categories>cs.IT math.IT</categories><comments>8 pages, to appear in Allerton '09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a few iterative decoding schemes for the joint
source-channel coding of correlated sources. Specifically, we consider the
joint source-channel coding of two erasure correlated sources with transmission
over different erasure channels. Our main interest is in determining whether or
not various code ensembles can achieve the capacity region universally over
varying channel conditions. We consider two ensembles in the class of
low-density generator-matrix (LDGM) codes known as Luby-Transform (LT) codes
and one ensemble of low-density parity-check (LDPC) codes. We analyze them
using density evolution and show that optimized LT codes can achieve the
extremal symmetric point of the capacity region. We also show that LT codes are
not universal under iterative decoding for this problem because they cannot
simultaneously achieve the extremal symmetric point and a corner point of the
capacity region. The sub-universality of iterative decoding is characterized by
studying the density evolution for LT codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1145</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1145</id><created>2009-10-06</created><authors><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Azmi</keyname><forenames>Marwan H.</forenames></author><author><keyname>Malaney</keyname><forenames>Robert.</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Design of network-coding based multi-edge type LDPC codes for
  multi-source relaying systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 8figure. conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate a multi-source LDPC scheme for a Gaussian relay
system, where M sources communicate with the destination under the help of a
single relay (M-1-1 system). Since various distributed LDPC schemes in the
cooperative single-source system, e.g. bilayer LDPC and bilayer multi-edge type
LDPC (BMET-LDPC), have been designed to approach the Shannon limit, these
schemes can be applied to the $M-1-1$ system by the relay serving each source
in a round-robin fashion. However, such a direct application is not optimal due
to the lack of potential joint processing gain. In this paper, we propose a
network coded multi-edge type LDPC (NCMET-LDPC) scheme for the multi-source
scenario. Through an EXIT analysis, we conclude that the NCMET-LDPC scheme
achieves higher extrinsic mutual information, relative to a separate
application of BMET-LDPC to each source. Our new NCMET-LDPC scheme thus
achieves a higher threshold relative to existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1151</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1151</id><created>2009-10-06</created><authors><author><keyname>Urgaonkar</keyname><forenames>Rahul</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Delay-Limited Cooperative Communication with Reliability Constraints in
  Wireless Networks</title><categories>cs.IT math.IT math.OC</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate optimal resource allocation for delay-limited cooperative
communication in time varying wireless networks. Motivated by real-time
applications that have stringent delay constraints, we develop a dynamic
cooperation strategy that makes optimal use of network resources to achieve a
target outage probability (reliability) for each user subject to average power
constraints. Using the technique of Lyapunov optimization, we first present a
general framework to solve this problem and then derive quasi-closed form
solutions for several cooperative protocols proposed in the literature. Unlike
earlier works, our scheme does not require prior knowledge of the statistical
description of the packet arrival, channel state and node mobility processes
and can be implemented in an online fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1191</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1191</id><created>2009-10-07</created><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>Sorting from Noisy Information</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies problems of inferring order given noisy information. In
these problems there is an unknown order (permutation) $\pi$ on $n$ elements
denoted by $1,...,n$. We assume that information is generated in a way
correlated with $\pi$. The goal is to find a maximum likelihood $\pi^*$ given
the information observed. We will consider two different types of observations:
noisy comparisons and noisy orders. The data in Noisy orders are permutations
given from an exponential distribution correlated with \pi (this is also called
the Mallow's model). The data in Noisy Comparisons is a signal given for each
pair of elements which is correlated with their true ordering.
  In this paper we present polynomial time algorithms for solving both problems
with high probability. As part of our proof we show that for both models the
maximum likelihood solution $\pi^{\ast}$ is close to the original permutation
$\pi$.
  Our results are of interest in applications to ranking, such as ranking in
sports, or ranking of search items based on comparisons by experts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1217</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1217</id><created>2009-10-07</created><authors><author><keyname>Aman</keyname><forenames>Bogdan</forenames></author><author><keyname>Ciobanu</keyname><forenames>Gabriel</forenames></author></authors><title>Mutual Mobile Membranes with Timers</title><categories>cs.FL q-bio.QM</categories><journal-ref>EPTCS 6, 2009, pp. 1-15</journal-ref><doi>10.4204/EPTCS.6.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A feature of current membrane systems is the fact that objects and membranes
are persistent. However, this is not true in the real world. In fact, cells and
intracellular proteins have a well-defined lifetime. Inspired from these
biological facts, we define a model of systems of mobile membranes in which
each membrane and each object has a timer representing their lifetime. We show
that systems of mutual mobile membranes with and without timers have the same
computational power. An encoding of timed safe mobile ambients into systems of
mutual mobile membranes with timers offers a relationship between two
formalisms used in describing biological systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1219</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1219</id><created>2009-10-07</created><authors><author><keyname>Barbuti</keyname><forenames>Roberto</forenames><affiliation>University of Pisa</affiliation></author><author><keyname>Caravagna</keyname><forenames>Giulio</forenames><affiliation>University of Pisa</affiliation></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames><affiliation>University of Pisa</affiliation></author><author><keyname>Maggiolo-Schettini</keyname><forenames>Andrea</forenames><affiliation>University of Pisa</affiliation></author></authors><title>On the Interpretation of Delays in Delay Stochastic Simulation of
  Biological Systems</title><categories>q-bio.QM cs.CE</categories><journal-ref>EPTCS 6, 2009, pp. 17-29</journal-ref><doi>10.4204/EPTCS.6.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delays in biological systems may be used to model events for which the
underlying dynamics cannot be precisely observed. Mathematical modeling of
biological systems with delays is usually based on Delay Differential Equations
(DDEs), a kind of differential equations in which the derivative of the unknown
function at a certain time is given in terms of the values of the function at
previous times. In the literature, delay stochastic simulation algorithms have
been proposed. These algorithms follow a &quot;delay as duration&quot; approach, namely
they are based on an interpretation of a delay as the elapsing time between the
start and the termination of a chemical reaction. This interpretation is not
suitable for some classes of biological systems in which species involved in a
delayed interaction can be involved at the same time in other interactions. We
show on a DDE model of tumor growth that the delay as duration approach for
stochastic simulation is not precise, and we propose a simulation algorithm
based on a ``purely delayed'' interpretation of delays which provides better
results on the considered model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1238</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1238</id><created>2009-10-07</created><authors><author><keyname>Pham</keyname><forenames>Quang Dung</forenames></author><author><keyname>Deville</keyname><forenames>Yves</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames></author></authors><title>A Local Search Modeling for Constrained Optimum Paths Problems (Extended
  Abstract)</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 5-11</journal-ref><doi>10.4204/EPTCS.5.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constrained Optimum Path (COP) problems appear in many real-life
applications, especially on communication networks. Some of these problems have
been considered and solved by specific techniques which are usually difficult
to extend. In this paper, we introduce a novel local search modeling for
solving some COPs by local search. The modeling features the compositionality,
modularity, reuse and strengthens the benefits of Constrained-Based Local
Search. We also apply the modeling to the edge-disjoint paths problem (EDP). We
show that side constraints can easily be added in the model. Computational
results show the significance of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1239</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1239</id><created>2009-10-07</created><authors><author><keyname>Bijarbooneh</keyname><forenames>Farshid Hassani</forenames></author><author><keyname>Flener</keyname><forenames>Pierre</forenames></author><author><keyname>Pearson</keyname><forenames>Justin</forenames></author></authors><title>Dynamic Demand-Capacity Balancing for Air Traffic Management Using
  Constraint-Based Local Search: First Results</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 27-40</journal-ref><doi>10.4204/EPTCS.5.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using constraint-based local search, we effectively model and efficiently
solve the problem of balancing the traffic demands on portions of the European
airspace while ensuring that their capacity constraints are satisfied. The
traffic demand of a portion of airspace is the hourly number of flights planned
to enter it, and its capacity is the upper bound on this number under which
air-traffic controllers can work. Currently, the only form of demand-capacity
balancing we allow is ground holding, that is the changing of the take-off
times of not yet airborne flights. Experiments with projected European flight
plans of the year 2030 show that already this first form of demand-capacity
balancing is feasible without incurring too much total delay and that it can
lead to a significantly better demand-capacity balance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1244</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1244</id><created>2009-10-07</created><authors><author><keyname>Pereira</keyname><forenames>David</forenames></author><author><keyname>Lynce</keyname><forenames>In&#xea;s</forenames></author><author><keyname>Prestwich</keyname><forenames>Steven</forenames></author></authors><title>On Improving Local Search for Unsatisfiability</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 41-53</journal-ref><doi>10.4204/EPTCS.5.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic local search (SLS) has been an active field of research in the
last few years, with new techniques and procedures being developed at an
astonishing rate. SLS has been traditionally associated with satisfiability
solving, that is, finding a solution for a given problem instance, as its
intrinsic nature does not address unsatisfiable problems. Unsatisfiable
instances were therefore commonly solved using backtrack search solvers. For
this reason, in the late 90s Selman, Kautz and McAllester proposed a challenge
to use local search instead to prove unsatisfiability. More recently, two SLS
solvers - Ranger and Gunsat - have been developed, which are able to prove
unsatisfiability albeit being SLS solvers. In this paper, we first compare
Ranger with Gunsat and then propose to improve Ranger performance using some of
Gunsat's techniques, namely unit propagation look-ahead and extended
resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1247</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1247</id><created>2009-10-07</created><authors><author><keyname>Audenard</keyname><forenames>Gilles</forenames></author><author><keyname>Lagniez</keyname><forenames>Jean-Marie</forenames></author><author><keyname>Mazure</keyname><forenames>Bertrand</forenames></author><author><keyname>Sa&#xef;s</keyname><forenames>Lakhdar</forenames></author></authors><title>Integrating Conflict Driven Clause Learning to Local Search</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 55-68</journal-ref><doi>10.4204/EPTCS.5.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces SatHyS (SAT HYbrid Solver), a novel hybrid approach
for propositional satisfiability. It combines local search and conflict driven
clause learning (CDCL) scheme. Each time the local search part reaches a local
minimum, the CDCL is launched. For SAT problems it behaves like a tabu list,
whereas for UNSAT ones, the CDCL part tries to focus on minimum unsatisfiable
sub-formula (MUS). Experimental results show good performances on many classes
of SAT instances from the last SAT competitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1253</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1253</id><created>2009-10-07</created><authors><author><keyname>He</keyname><forenames>Fang</forenames></author><author><keyname>Qu</keyname><forenames>Rong</forenames></author></authors><title>A Constraint-directed Local Search Approach to Nurse Rostering Problems</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 69-80</journal-ref><doi>10.4204/EPTCS.5.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the hybridization of constraint programming and
local search techniques within a large neighbourhood search scheme for solving
highly constrained nurse rostering problems. As identified by the research, a
crucial part of the large neighbourhood search is the selection of the fragment
(neighbourhood, i.e. the set of variables), to be relaxed and re-optimized
iteratively. The success of the large neighbourhood search depends on the
adequacy of this identified neighbourhood with regard to the problematic part
of the solution assignment and the choice of the neighbourhood size. We
investigate three strategies to choose the fragment of different sizes within
the large neighbourhood search scheme. The first two strategies are tailored
concerning the problem properties. The third strategy is more general, using
the information of the cost from the soft constraint violations and their
propagation as the indicator to choose the variables added into the fragment.
The three strategies are analyzed and compared upon a benchmark nurse rostering
problem. Promising results demonstrate the possibility of future work in the
hybrid approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1255</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1255</id><created>2009-10-07</created><authors><author><keyname>Pelleau</keyname><forenames>Marie</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames></author><author><keyname>Truchet</keyname><forenames>Charlotte</forenames></author></authors><title>Sonet Network Design Problems</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 81-95</journal-ref><doi>10.4204/EPTCS.5.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method and a constraint-based objective function to
solve two problems related to the design of optical telecommunication networks,
namely the Synchronous Optical Network Ring Assignment Problem (SRAP) and the
Intra-ring Synchronous Optical Network Design Problem (IDP). These network
topology problems can be represented as a graph partitioning with capacity
constraints as shown in previous works. We present here a new objective
function and a new local search algorithm to solve these problems. Experiments
conducted in Comet allow us to compare our method to previous ones and show
that we obtain better results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1264</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1264</id><created>2009-10-07</created><authors><author><keyname>Abreu</keyname><forenames>Salvator</forenames></author><author><keyname>Diaz</keyname><forenames>Daniel</forenames></author><author><keyname>Codognet</keyname><forenames>Philippe</forenames></author></authors><title>Parallel local search for solving Constraint Problems on the Cell
  Broadband Engine (Preliminary Results)</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 97-111</journal-ref><doi>10.4204/EPTCS.5.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the use of the Cell Broadband Engine (Cell/BE for short) for
combinatorial optimization applications: we present a parallel version of a
constraint-based local search algorithm that has been implemented on a
multiprocessor BladeCenter machine with twin Cell/BE processors (total of 16
SPUs per blade). This algorithm was chosen because it fits very well the
Cell/BE architecture and requires neither shared memory nor communication
between processors, while retaining a compact memory footprint. We study the
performance on several large optimization benchmarks and show that this
achieves mostly linear time speedups, even sometimes super-linear. This is
possible because the parallel implementation might explore simultaneously
different parts of the search space and therefore converge faster towards the
best sub-space and thus towards a solution. Besides getting speedups, the
resulting times exhibit a much smaller variance, which benefits applications
where a timely reply is critical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1266</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1266</id><created>2009-10-07</created><authors><author><keyname>He</keyname><forenames>Jun</forenames></author><author><keyname>Flener</keyname><forenames>Pierre</forenames></author><author><keyname>Pearson</keyname><forenames>Justin</forenames></author></authors><title>Toward an automaton Constraint for Local Search</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009, pp. 13-25</journal-ref><doi>10.4204/EPTCS.5.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the idea of using finite automata to implement new constraints for
local search (this is already a successful technique in constraint-based global
search). We show how it is possible to maintain incrementally the violations of
a constraint and its decision variables from an automaton that describes a
ground checker for that constraint. We establish the practicality of our
approach idea on real-life personnel rostering problems, and show that it is
competitive with the approach of [Pralong, 2007].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1268</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1268</id><created>2009-10-07</created><updated>2009-12-23</updated><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>The Complexity of Infinite Computations In Models of Set Theory</title><categories>cs.LO cs.CC math.LO</categories><proxy>ccsd hal-00422538</proxy><acm-class>F.1.1; F.1.3; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 4 (December
  21, 2009) lmcs:1205</journal-ref><doi>10.2168/LMCS-5(4:4)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following surprising result: there exist a 1-counter B\&quot;uchi
automaton and a 2-tape B\&quot;uchi automaton such that the \omega-language of the
first and the infinitary rational relation of the second in one model of ZFC
are \pi_2^0-sets, while in a different model of ZFC both are analytic but non
Borel sets.
  This shows that the topological complexity of an \omega-language accepted by
a 1-counter B\&quot;uchi automaton or of an infinitary rational relation accepted by
a 2-tape B\&quot;uchi automaton is not determined by the axiomatic system ZFC.
  We show that a similar result holds for the class of languages of infinite
pictures which are recognized by B\&quot;uchi tiling systems.
  We infer from the proof of the above results an improvement of the lower
bound of some decision problems recently studied by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1273</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1273</id><created>2009-10-07</created><authors><author><keyname>Bdiri</keyname><forenames>Taoufik</forenames><affiliation>CAOR</affiliation></author><author><keyname>Moutarde</keyname><forenames>Fabien</forenames><affiliation>CAOR</affiliation></author><author><keyname>Bourdis</keyname><forenames>Nicolas</forenames><affiliation>CAOR</affiliation></author><author><keyname>Steux</keyname><forenames>Bruno</forenames><affiliation>CAOR</affiliation></author></authors><title>Adaboost with &quot;Keypoint Presence Features&quot; for Real-Time Vehicle Visual
  Detection</title><categories>cs.CV cs.LG</categories><proxy>ccsd hal-00422581</proxy><journal-ref>16th World Congress on Intelligent Transport Systems (ITSwc'2009),
  Su\`ede (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present promising results for real-time vehicle visual detection, obtained
with adaBoost using new original ?keypoints presence features?. These
weak-classifiers produce a boolean response based on presence or absence in the
tested image of a ?keypoint? (~ a SURF interest point) with a descriptor
sufficiently similar (i.e. within a given distance) to a reference descriptor
characterizing the feature. A first experiment was conducted on a public image
dataset containing lateral-viewed cars, yielding 95% recall with 95% precision
on test set. Moreover, analysis of the positions of adaBoost-selected keypoints
show that they correspond to a specific part of the object category (such as
?wheel? or ?side skirt?) and thus have a ?semantic? meaning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1293</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1293</id><created>2009-10-07</created><authors><author><keyname>Stanciulescu</keyname><forenames>Bogdan</forenames><affiliation>CAOR</affiliation></author><author><keyname>Breheret</keyname><forenames>Amaury</forenames><affiliation>CAOR</affiliation></author><author><keyname>Moutarde</keyname><forenames>Fabien</forenames><affiliation>CAOR</affiliation></author></authors><title>Introducing New AdaBoost Features for Real-Time Vehicle Detection</title><categories>cs.CV cs.LG</categories><proxy>ccsd hal-00422587</proxy><journal-ref>COGIS'07 conference on COGnitive systems with Interactive Sensors,
  Stanford, Palo Alto : United States (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how to improve the real-time object detection in complex
robotics applications, by exploring new visual features as AdaBoost weak
classifiers. These new features are symmetric Haar filters (enforcing global
horizontal and vertical symmetry) and N-connexity control points. Experimental
evaluation on a car database show that the latter appear to provide the best
results for the vehicle-detection problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1294</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1294</id><created>2009-10-07</created><authors><author><keyname>Bdiri</keyname><forenames>Taoufik</forenames><affiliation>CAOR</affiliation></author><author><keyname>Moutarde</keyname><forenames>Fabien</forenames><affiliation>CAOR</affiliation></author><author><keyname>Steux</keyname><forenames>Bruno</forenames><affiliation>CAOR</affiliation></author></authors><title>Visual object categorization with new keypoint-based adaBoost features</title><categories>cs.CV cs.LG</categories><proxy>ccsd hal-00422580</proxy><journal-ref>IEEE Symposium on Intelligent Vehicles (IV'2009), XiAn : China
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present promising results for visual object categorization, obtained with
adaBoost using new original ?keypoints-based features?. These weak-classifiers
produce a boolean response based on presence or absence in the tested image of
a ?keypoint? (a kind of SURF interest point) with a descriptor sufficiently
similar (i.e. within a given distance) to a reference descriptor characterizing
the feature. A first experiment was conducted on a public image dataset
containing lateral-viewed cars, yielding 95% recall with 95% precision on test
set. Preliminary tests on a small subset of a pedestrians database also gives
promising 97% recall with 92 % precision, which shows the generality of our new
family of features. Moreover, analysis of the positions of adaBoost-selected
keypoints show that they correspond to a specific part of the object category
(such as ?wheel? or ?side skirt? in the case of lateral-cars) and thus have a
?semantic? meaning. We also made a first test on video for detecting vehicles
from adaBoostselected keypoints filtered in real-time from all detected
keypoints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1295</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1295</id><created>2009-10-07</created><authors><author><keyname>Moutarde</keyname><forenames>Fabien</forenames><affiliation>CAOR</affiliation></author><author><keyname>Bargeton</keyname><forenames>Alexandre</forenames><affiliation>CAOR</affiliation></author><author><keyname>Herbin</keyname><forenames>Anne</forenames></author><author><keyname>Chanussot</keyname><forenames>Lowik</forenames></author></authors><title>Modular Traffic Sign Recognition applied to on-vehicle real-time visual
  detection of American and European speed limit signs</title><categories>cs.CV</categories><proxy>ccsd hal-00422585</proxy><journal-ref>14th World congress on Intelligent Transportation Systems
  (ITS'2007), Beijing : China (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new modular traffic signs recognition system, successfully
applied to both American and European speed limit signs. Our sign detection
step is based only on shape-detection (rectangles or circles). This enables it
to work on grayscale images, contrary to most European competitors, which eases
robustness to illumination conditions (notably night operation). Speed sign
candidates are classified (or rejected) by segmenting potential digits inside
them (which is rather original and has several advantages), and then applying a
neural digit recognition. The global detection rate is ~90% for both (standard)
U.S. and E.U. speed signs, with a misclassification rate &lt;1%, and no validated
false alarm in &gt;150 minutes of video. The system processes in real-time ~20
frames/s on a standard high-end laptop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1300</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1300</id><created>2009-10-07</created><updated>2011-02-18</updated><authors><author><keyname>Torbatian</keyname><forenames>Mehdi</forenames></author><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames></author></authors><title>D-MG Tradeoff of DF and AF Relaying Protocols over Asynchronous PAM
  Cooperative Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diversity multiplexing tradeoff of a general two-hop asynchronous
cooperative network is examined for various relaying protocols such as
non-orthogonal selection decode-and-forward (NSDF), orthogonal selection
decode-and-forward (OSDF), non-orthogonal amplify-and-forward (NAF), and
orthogonal amplify-and-forward (OAF). The transmitter nodes are assumed to send
pulse amplitude modulation (PAM) signals asynchronously, in which information
symbols are linearly modulated by a shaping waveform to be sent to the
destination. We consider two different cases with respect to the length of the
shaping waveforms in the time domain. In the theoretical case where the shaping
waveforms with infinite time support are used, it is shown that asynchronism
does not affect the DMT performance of the system and the same DMT as that of
the corresponding synchronous network is obtained for all the aforementioned
protocols. In the practical case where finite length shaping waveforms are
used, it is shown that better diversity gains can be achieved at the expense of
bandwidth expansion. In the decode-and-forward (DF) type protocols, the
asynchronous network provides better diversity gains than those of the
corresponding synchronous network throughout the range of the multiplexing
gain. In the amplify-and-forward (AF) type protocols, the asynchronous network
provides the same DMT as that of the corresponding synchronous counterpart
under the OAF protocol; however, a better diversity gain is achieved under the
NAF protocol throughout the range of the multiplexing gain. In particular, in
the single relay asynchronous network, the NAF protocol provides the same DMT
as that of the 2 {\times} 1 multiple-input single-output (MISO) channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1335</identifier>
 <datestamp>2009-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1335</id><created>2009-10-07</created><authors><author><keyname>Mao</keyname><forenames>Wei</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Violating the Ingleton Inequality with Finite Groups</title><categories>cs.IT math.IT</categories><comments>17 pages, 1 figure. Presented at Allerton 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that there is a one-to-one correspondence between the
entropy vector of a collection of n random variables and a certain
group-characterizable vector obtained from a finite group and n of its
subgroups. However, if one restricts attention to abelian groups then not all
entropy vectors can be obtained. This is an explanation for the fact shown by
Dougherty et al that linear network codes cannot achieve capacity in general
network coding problems (since linear network codes form an abelian group). All
abelian group-characterizable vectors, and by fiat all entropy vectors
generated by linear network codes, satisfy a linear inequality called the
Ingleton inequality. In this paper, we study the problem of finding nonabelian
finite groups that yield characterizable vectors which violate the Ingleton
inequality. Using a refined computer search, we find the symmetric group S_5 to
be the smallest group that violates the Ingleton inequality. Careful study of
the structure of this group, and its subgroups, reveals that it belongs to the
Ingleton-violating family PGL(2,p) with primes p &gt; 3, i.e., the projective
group of 2 by 2 nonsingular matrices with entries in F_p. This family of groups
is therefore a good candidate for constructing network codes more powerful than
linear network codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1387</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1387</id><created>2009-10-07</created><updated>2009-11-04</updated><authors><author><keyname>Jacobs</keyname><forenames>Tobias</forenames></author></authors><title>Simpler Proofs by Symbolic Perturbation</title><categories>cs.DS cs.DM</categories><comments>This work introduces a fairly novel model for combinatorial problems
  and algorithms. The author believes that the result is successfully
  applicable to the analyes of a very broad class of algorithms. He would be
  happy to receive feedback from the readers</comments><acm-class>G.2.0; F.2.0; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In analyses of algorithms, a substantial amount of effort has often to be
spent on the discussion of special cases. For example, when the analysis
considers the cases X&lt;Y and X&gt;Y separately, one might have to be especially
careful about what happens when X=Y. On the other hand, experience tells us
that when a yet unregarded special case of this kind is discovered, one nearly
always finds a way to handle it. This is typically done by modifying the
analysis and/or the algorithm very slightly.
  In this article we substantiate this observation theoretically. We
concentrate on deterministic algorithms for weighted combinatorial optimization
problems. A problem instance of this kind is defined by its structure and a
vector of weights. The concept of a null case is introduced as set of problem
instances whose weight vectors constitute a nowhere open set (or null set) in
the space of all possible weight configurations. An algorithm is called robust
if any null case can be disregarded in the analysis of both its solution
quality and resource requirements.
  We show that achieving robustness is only a matter of breaking ties the right
way. More specifically, we show that the concept of symbolic perturbation known
from the area of geometric algorithms guarantees that no surprises will happen
in null cases. We argue that for a huge class of combinatorial optimization
algorithms it is easy to verify that they implicitly use symbolic perturbation
for breaking ties and thus can be analyzed under the assumption that some
arbitrary null case never occurs. Finally, we prove that there exists a
symbolic perturbation tie breaking policy for any algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1392</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1392</id><created>2009-10-07</created><authors><author><keyname>Chen</keyname><forenames>Wei-Mei</forenames></author><author><keyname>Hwang</keyname><forenames>Hsien-Kuei</forenames></author><author><keyname>Tsai</keyname><forenames>Tsung-Hsi</forenames></author></authors><title>Simple, efficient maxima-finding algorithms for multidimensional samples</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New algorithms are devised for finding the maxima of multidimensional point
samples, one of the very first problems studied in computational geometry. The
algorithms are very simple and easily coded and modified for practical needs.
The expected complexity of some measures related to the performance of the
algorithms is analyzed. We also compare the efficiency of the algorithms with a
few major ones used in practice, and apply our algorithms to find the maximal
layers and the longest common subsequences of multiple sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1403</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1403</id><created>2009-10-08</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>On the Sample Complexity of Compressed Counting</title><categories>cs.DS cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Counting (CC), based on maximally skewed stable random
projections, was recently proposed for estimating the p-th frequency moments of
data streams. The case p-&gt;1 is extremely useful for estimating Shannon entropy
of data streams. In this study, we provide a very simple algorithm based on the
sample minimum estimator and prove a much improved sample complexity bound,
compared to prior results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1404</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1404</id><created>2009-10-08</created><authors><author><keyname>Deville</keyname><forenames>Yves</forenames></author><author><keyname>Solnon</keyname><forenames>Christine</forenames></author></authors><title>Proceedings 6th International Workshop on Local Search Techniques in
  Constraint Satisfaction</title><categories>cs.AI</categories><journal-ref>EPTCS 5, 2009</journal-ref><doi>10.4204/EPTCS.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LSCS is a satellite workshop of the international conference on principles
and practice of Constraint Programming (CP), since 2004. It is devoted to local
search techniques in constraint satisfaction, and focuses on all aspects of
local search techniques, including: design and implementation of new
algorithms, hybrid stochastic-systematic search, reactive search optimization,
adaptive search, modeling for local-search, global constraints, flexibility and
robustness, learning methods, and specific applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1406</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1406</id><created>2009-10-08</created><authors><author><keyname>Bortolussi</keyname><forenames>Luca</forenames><affiliation>University of Trieste</affiliation></author><author><keyname>Policriti</keyname><forenames>Alberto</forenames><affiliation>University of Udine</affiliation></author></authors><title>Hybrid Semantics of Stochastic Programs with Dynamic Reconfiguration</title><categories>cs.PL cs.LO</categories><acm-class>J.3</acm-class><journal-ref>EPTCS 6, 2009, pp. 63-76</journal-ref><doi>10.4204/EPTCS.6.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We begin by reviewing a technique to approximate the dynamics of stochastic
programs --written in a stochastic process algebra-- by a hybrid system,
suitable to capture a mixed discrete/continuous evolution. In a nutshell, the
discrete dynamics is kept stochastic while the continuous evolution is given in
terms of ODEs, and the overall technique, therefore, naturally associates a
Piecewise Deterministic Markov Process with a stochastic program. The specific
contribution in this work consists in an increase of the flexibility of the
translation scheme, obtained by allowing a dynamic reconfiguration of the
degree of discreteness/continuity of the semantics. We also discuss the
relationships of this approach with other hybrid simulation strategies for
biochemical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1407</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1407</id><created>2009-10-08</created><updated>2011-06-18</updated><authors><author><keyname>Chia</keyname><forenames>Yeow-Khiang</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>3-Receiver Broadcast Channels with Common and Confidential Messages</title><categories>cs.IT math.IT</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper establishes inner bounds on the secrecy capacity regions for the
general 3-receiver broadcast channel with one common and one confidential
message sets. We consider two setups. The first is when the confidential
message is to be sent to two receivers and kept secret from the third receiver.
Achievability is established using indirect decoding, Wyner wiretap channel
coding, and the new idea of generating secrecy from a publicly available
superposition codebook. The inner bound is shown to be tight for a class of
reversely degraded broadcast channels and when both legitimate receivers are
less noisy than the third receiver. The second setup investigated in this paper
is when the confidential message is to be sent to one receiver and kept secret
from the other two receivers. Achievability in this case follows from Wyner
wiretap channel coding and indirect decoding. This inner bound is also shown to
be tight for several special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1409</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1409</id><created>2009-10-08</created><updated>2012-10-05</updated><authors><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Pathwidth, trees, and random embeddings</title><categories>math.MG cs.DS</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that, for every $k=1,2,...,$ every shortest-path metric on a graph
of pathwidth $k$ embeds into a distribution over random trees with distortion
at most $c$ for some $c=c(k)$. A well-known conjecture of Gupta, Newman,
Rabinovich, and Sinclair states that for every minor-closed family of graphs
$F$, there is a constant $c(F)$ such that the multi-commodity max-flow/min-cut
gap for every flow instance on a graph from $F$ is at most $c(F)$. The
preceding embedding theorem is used to prove this conjecture whenever the
family $F$ does not contain all trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1410</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1410</id><created>2009-10-08</created><authors><author><keyname>Loewe</keyname><forenames>Laurence</forenames></author><author><keyname>Moodie</keyname><forenames>Stuart</forenames></author><author><keyname>Hillston</keyname><forenames>Jane</forenames></author></authors><title>Quantifying the implicit process flow abstraction in SBGN-PD diagrams
  with Bio-PEPA</title><categories>cs.PL cs.CE q-bio.QM</categories><journal-ref>EPTCS 6, 2009, pp. 93-107</journal-ref><doi>10.4204/EPTCS.6.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a long time biologists have used visual representations of biochemical
networks to gain a quick overview of important structural properties. Recently
SBGN, the Systems Biology Graphical Notation, has been developed to standardise
the way in which such graphical maps are drawn in order to facilitate the
exchange of information. Its qualitative Process Diagrams (SBGN-PD) are based
on an implicit Process Flow Abstraction (PFA) that can also be used to
construct quantitative representations, which can be used for automated
analyses of the system. Here we explicitly describe the PFA that underpins
SBGN-PD and define attributes for SBGN-PD glyphs that make it possible to
capture the quantitative details of a biochemical reaction network. We
implemented SBGNtext2BioPEPA, a tool that demonstrates how such quantitative
details can be used to automatically generate working Bio-PEPA code from a
textual representation of SBGN-PD that we developed. Bio-PEPA is a process
algebra that was designed for implementing quantitative models of concurrent
biochemical reaction systems. We use this approach to compute the expected
delay between input and output using deterministic and stochastic simulations
of the MAPK signal transduction cascade. The scheme developed here is general
and can be easily adapted to other output formalisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1412</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1412</id><created>2009-10-08</created><authors><author><keyname>Siebert</keyname><forenames>Heike</forenames></author></authors><title>Dynamical and Structural Modularity of Discrete Regulatory Networks</title><categories>cs.DM cs.CE q-bio.MN</categories><journal-ref>EPTCS 6, 2009, pp. 109-124</journal-ref><doi>10.4204/EPTCS.6.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A biological regulatory network can be modeled as a discrete function that
contains all available information on network component interactions. From this
function we can derive a graph representation of the network structure as well
as of the dynamics of the system. In this paper we introduce a method to
identify modules of the network that allow us to construct the behavior of the
given function from the dynamics of the modules. Here, it proves useful to
distinguish between dynamical and structural modules, and to define network
modules combining aspects of both. As a key concept we establish the notion of
symbolic steady state, which basically represents a set of states where the
behavior of the given function is in some sense predictable, and which gives
rise to suitable network modules. We apply the method to a regulatory network
involved in T helper cell differentiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1415</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1415</id><created>2009-10-08</created><authors><author><keyname>Besozzi</keyname><forenames>Daniela</forenames></author><author><keyname>Cazzaniga</keyname><forenames>Paolo</forenames></author><author><keyname>Dugo</keyname><forenames>Matteo</forenames></author><author><keyname>Pescini</keyname><forenames>Dario</forenames></author><author><keyname>Mauri</keyname><forenames>Giancarlo</forenames></author></authors><title>A study on the combined interplay between stochastic fluctuations and
  the number of flagella in bacterial chemotaxis</title><categories>q-bio.MN cs.CE</categories><journal-ref>EPTCS 6, 2009, pp. 47-62</journal-ref><doi>10.4204/EPTCS.6.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chemotactic pathway allows bacteria to respond and adapt to environmental
changes, by tuning the tumbling and running motions that are due to clockwise
and counterclockwise rotations of their flagella. The pathway is tightly
regulated by feedback mechanisms governed by the phosphorylation and
methylation of several proteins. In this paper, we present a detailed
mechanistic model for chemotaxis, that considers all of its transmembrane and
cytoplasmic components, and their mutual interactions. Stochastic simulations
of the dynamics of a pivotal protein, CheYp, are performed by means of tau
leaping algorithm. This approach is then used to investigate the interplay
between the stochastic fluctuations of CheYp amount and the number of cellular
flagella. Our results suggest that the combination of these factors might
represent a relevant component for chemotaxis. Moreover, we study the pathway
under various conditions, such as different methylation levels and ligand
amounts, in order to test its adaptation response. Some issues for future work
are finally discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1416</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1416</id><created>2009-10-08</created><updated>2010-02-25</updated><authors><author><keyname>Hassan</keyname><forenames>Sk. Sarif</forenames></author><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Pal</keyname><forenames>Amita</forenames></author><author><keyname>Brahmachary</keyname><forenames>R. L.</forenames></author><author><keyname>Goswami</keyname><forenames>Arunava</forenames></author></authors><title>Use of L-system mathematics for making new subfamily members of
  olfactory receptor full length genes, OR1D2, OR1D4 and OR1D5</title><categories>cs.OH cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ligands for only two human olfactory receptors are known. One of them, OR1D2,
binds to Bourgeonal [Malnic B, Godfrey P-A, Buck L-B (2004) The human olfactory
receptor gene family. Proc. Natl. Acad. Sci U. S. A. 101: 2584-2589 and Erratum
in: Proc Natl Acad Sci U. S. A. (2004) 101: 7205]. OR1D2, OR1D4 and OR1D5 are
three full length olfactory receptors present in an olfactory locus in human
genome. These receptors are more than 80% identical in DNA sequences and have
108 base pair mismatches among them. We have used L-system mathematics and have
been able to show a closely related subfamily of OR1D2, OR1D4 and OR1D5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1418</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1418</id><created>2009-10-08</created><updated>2010-05-14</updated><authors><author><keyname>Coppo</keyname><forenames>Mario</forenames><affiliation>Dipartimento di Informatica, Universit&#xe1; di Torino</affiliation></author><author><keyname>Damiani</keyname><forenames>Ferruccio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe1; di Torino</affiliation></author><author><keyname>Grassi</keyname><forenames>Elena</forenames><affiliation>Molecular Biotechnology Center, Dipartimento di Genetica, Biologia e Biochimica and Dipartimento di Informatica, Universit&#xe1; di Torino</affiliation></author><author><keyname>Guether</keyname><forenames>Mike</forenames><affiliation>Dipartimento di Biologia Vegetale, Universit&#xe0; di Torino</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe1; di Torino</affiliation></author></authors><title>Modelling an Ammonium Transporter with SCLS</title><categories>q-bio.QM cs.CE q-bio.CB</categories><acm-class>F.3.3; J.3; F.1.2</acm-class><journal-ref>EPTCS 6, 2009, pp. 77-92</journal-ref><doi>10.4204/EPTCS.6.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Stochastic Calculus of Looping Sequences (SCLS) is a recently proposed
modelling language for the representation and simulation of biological systems
behaviour. It has been designed with the aim of combining the simplicity of
notation of rewrite systems with the advantage of compositionality. It also
allows a rather simple and accurate description of biological membranes and
their interactions with the environment.
  In this work we apply SCLS to model a newly discovered ammonium transporter.
This transporter is believed to play a fundamental role for plant mineral
acquisition, which takes place in the arbuscular mycorrhiza, the most
wide-spread plant-fungus symbiosis on earth. Due to its potential application
in agriculture this kind of symbiosis is one of the main focuses of the BioBITs
project.
  In our experiments the passage of NH3 / NH4+ from the fungus to the plant has
been dissected in known and hypothetical mechanisms; with the model so far we
have been able to simulate the behaviour of the system under different
conditions. Our simulations confirmed some of the latest experimental results
about the LjAMT2;2 transporter. The initial simulation results of the modelling
of the symbiosis process are promising and indicate new directions for
biological investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1427</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1427</id><created>2009-10-08</created><authors><author><keyname>Jansen</keyname><forenames>Maurice</forenames></author><author><keyname>N</keyname><forenames>Jayalal Sarma M.</forenames></author></authors><title>Balancing Bounded Treewidth Circuits</title><categories>cs.CC</categories><acm-class>F.2.3</acm-class><doi>10.1007/978-3-642-13182-0_21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic tools for graphs of small treewidth are used to address questions
in complexity theory. For both arithmetic and Boolean circuits, it is shown
that any circuit of size $n^{O(1)}$ and treewidth $O(\log^i n)$ can be
simulated by a circuit of width $O(\log^{i+1} n)$ and size $n^c$, where $c =
O(1)$, if $i=0$, and $c=O(\log \log n)$ otherwise. For our main construction,
we prove that multiplicatively disjoint arithmetic circuits of size $n^{O(1)}$
and treewidth $k$ can be simulated by bounded fan-in arithmetic formulas of
depth $O(k^2\log n)$. From this we derive the analogous statement for
syntactically multilinear arithmetic circuits, which strengthens a theorem of
Mahajan and Rao. As another application, we derive that constant width
arithmetic circuits of size $n^{O(1)}$ can be balanced to depth $O(\log n)$,
provided certain restrictions are made on the use of iterated multiplication.
Also from our main construction, we derive that Boolean bounded fan-in circuits
of size $n^{O(1)}$ and treewidth $k$ can be simulated by bounded fan-in
formulas of depth $O(k^2\log n)$. This strengthens in the non-uniform setting
the known inclusion that $SC^0 \subseteq NC^1$. Finally, we apply our
construction to show that {\sc reachability} for directed graphs of bounded
treewidth is in $LogDCFL$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1433</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1433</id><created>2009-10-08</created><authors><author><keyname>Tchamova</keyname><forenames>Albena</forenames><affiliation>IPP BAS</affiliation></author><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames><affiliation>UNM</affiliation></author></authors><title>Tracking object's type changes with fuzzy based fusion rule</title><categories>cs.AI</categories><proxy>ccsd hal-00422632</proxy><journal-ref>First International Conference on Modelling and Development of
  Intelligent Systems, Sibiu : Romania (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the behavior of three combinational rules for
temporal/sequential attribute data fusion for target type estimation are
analyzed. The comparative analysis is based on: Dempster's fusion rule proposed
in Dempster-Shafer Theory; Proportional Conflict Redistribution rule no. 5
(PCR5), proposed in Dezert-Smarandache Theory and one alternative class fusion
rule, connecting the combination rules for information fusion with particular
fuzzy operators, focusing on the t-norm based Conjunctive rule as an analog of
the ordinary conjunctive rule and t-conorm based Disjunctive rule as an analog
of the ordinary disjunctive rule. The way how different t-conorms and t-norms
functions within TCN fusion rule influence over target type estimation
performance is studied and estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1443</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1443</id><created>2009-10-08</created><authors><author><keyname>Jansen</keyname><forenames>Maurice</forenames></author></authors><title>Weakening Assumptions for Deterministic Subexponential Time Non-Singular
  Matrix Completion</title><categories>cs.CC</categories><acm-class>F.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In (Kabanets, Impagliazzo, 2004) it is shown how to decide the circuit
polynomial identity testing problem (CPIT) in deterministic subexponential
time, assuming hardness of some explicit multilinear polynomial family for
arithmetical circuits. In this paper, a special case of CPIT is considered,
namely low-degree non-singular matrix completion (NSMC). For this subclass of
problems it is shown how to obtain the same deterministic time bound, using a
weaker assumption in terms of determinantal complexity.
  Hardness-randomness tradeoffs will also be shown in the converse direction,
in an effort to make progress on Valiant's VP versus VNP problem. To separate
VP and VNP, it is known to be sufficient to prove that the determinantal
complexity of the m-by-m permanent is $m^{\omega(\log m)}$. In this paper it is
shown, for an appropriate notion of explicitness, that the existence of an
explicit multilinear polynomial family with determinantal complexity
m^{\omega(\log m)}$ is equivalent to the existence of an efficiently computable
generator $G_n$ for multilinear NSMC with seed length $O(n^{1/\sqrt{\log n}})$.
The latter is a combinatorial object that provides an efficient deterministic
black-box algorithm for NSMC. ``Multilinear NSMC'' indicates that $G_n$ only
has to work for matrices $M(x)$ of $poly(n)$ size in $n$ variables, for which
$det(M(x))$ is a multilinear polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1463</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1463</id><created>2009-10-08</created><authors><author><keyname>Hansen</keyname><forenames>Morten</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author></authors><title>Near-Optimal Detection in MIMO Systems using Gibbs Sampling</title><categories>cs.IT math.IT</categories><comments>To appear in Globecom 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a Markov Chain Monte Carlo (MCMC) Gibbs sampler for
solving the integer least-squares problem. In digital communication the problem
is equivalent to performing Maximum Likelihood (ML) detection in Multiple-Input
Multiple-Output (MIMO) systems. While the use of MCMC methods for such problems
has already been proposed, our method is novel in that we optimize the
&quot;temperature&quot; parameter so that in steady state, i.e. after the Markov chain
has mixed, there is only polynomially (rather than exponentially) small
probability of encountering the optimal solution. More precisely, we obtain the
largest value of the temperature parameter for this to occur, since the higher
the temperature, the faster the mixing. This is in contrast to simulated
annealing techniques where, rather than being held fixed, the temperature
parameter is tended to zero. Simulations suggest that the resulting Gibbs
sampler provides a computationally efficient way of achieving approximative ML
detection in MIMO systems having a huge number of transmit and receive
dimensions. In fact, they further suggest that the Markov chain is rapidly
mixing. Thus, it has been observed that even in cases were ML detection using,
e.g. sphere decoding becomes infeasible, the Gibbs sampler can still offer a
near-optimal solution using much less computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1468</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1468</id><created>2009-10-08</created><authors><author><keyname>Jayarekha</keyname><forenames>P.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. GopalaKrishnan</forenames></author></authors><title>Prefetching of VoD Programs Based On ART1 Requesting Clustering</title><categories>cs.MM</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 128-134, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel approach to group users according to the
VoD user request pattern. We cluster the user requests based on ART1 neural
network algorithm. The knowledge extracted from the cluster is used to prefetch
the multimedia object from each cluster before the users request. We have
developed an algorithm to cluster users according to the users request patterns
based on ART1 neural network algorithm that offers an unsupervised clustering.
This approach adapts to changes in user request patterns over period without
losing previous information. Each cluster is represented as prototype vector by
generalizing the most frequently used URLs that are accessed by all the cluster
members. The simulation results of our proposed clustering and prefetching
algorithm, shows enormous increase in the performance of streaming server. Our
algorithm helps the servers agent to learn user preferences and discover the
information about the corresponding sources and other similar interested
individuals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1471</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1471</id><created>2009-10-08</created><authors><author><keyname>Dakshayini</keyname><forenames>M</forenames></author><author><keyname>Nair</keyname><forenames>T R GopalaKrishnan</forenames></author></authors><title>Prefix based Chaining Scheme for Streaming Popular Videos using Proxy
  servers in VoD</title><categories>cs.MM cs.NI</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 135-143, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Streaming high quality videos consumes significantly large amount of network
resources. In this context request to service delay, network traffic,
congestion and server overloading are the main parameters to be considered in
video streaming over the internet that effect the quality of service (QoS). In
this paper, we propose an efficient architecture as a cluster of proxy servers
and clients that uses a peer to peer (P2P) approach to cooperatively stream the
video using chaining technique. We consider the following two key issues in the
proposed architecture (1) Prefix caching technique to accommodate more number
of videos close to client (2) Cooperative client and proxy chaining to achieve
the network efficiency. Our simulation results shows that the proposed approach
yields a prefix caching close to the optimal solution minimizing WAN bandwidth
usage on server-proxy path by utilizing the proxy-client and client-client path
bandwidth, which is much cheaper than the expensive server proxy path
bandwidth, server load, and client rejection ratio significantly using
chaining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1475</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1475</id><created>2009-10-08</created><authors><author><keyname>Patil</keyname><forenames>Annapurna P</forenames></author><author><keyname>Sambaturu</keyname><forenames>Narmada</forenames></author><author><keyname>Chunhaviriyakul</keyname><forenames>Krittaya</forenames></author></authors><title>Convergence Time Evaluation of Algorithms in MANETs</title><categories>cs.DS cs.NI</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 144-149, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the advent of wireless communication, the need for mobile ad hoc
networks has been growing exponentially. This has opened up a Pandoras Box of
algorithms for dealing with mobile ad hoc networks, or MANETs, as they are
generally referred to. Most attempts made at evaluating these algorithms so far
have focused on parameters such as throughput, packet delivery ratio, overhead
etc. An analysis of the convergence times of these algorithms is still an open
issue. The work carried out fills this gap by evaluating the algorithms on the
basis of convergence time. Algorithms for MANETs can be classified into three
categories: reactive, proactive, and hybrid protocols. In this project, we
compare the convergence times of representative algorithms in each category,
namely Ad hoc On Demand Distance Vector (AODV) reactive, Destination Sequence
Distance Vector protocol (DSDV) proactive, and Temporally Ordered Routing
Algorithm (TORA) hybrid. The algorithm performances are compared by simulating
them in ns2. Tcl is used to conduct the simulations, while perl is used to
extract data from the simulation output and calculate convergence time. The
design of the experiments carried on is documented using Unified modeling
Language. Also, a user interface is created using perl, which enables the user
to either run a desired simulation and measure convergence time, or measure the
convergence time of a simulation that has been run earlier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1484</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1484</id><created>2009-10-08</created><authors><author><keyname>Lecomte</keyname><forenames>Alain</forenames><affiliation>INRIA Futurs, SFLTAMP</affiliation></author><author><keyname>Quatrini</keyname><forenames>Myriam</forenames><affiliation>IML</affiliation></author></authors><title>Ludics and its Applications to natural Language Semantics</title><categories>cs.CL</categories><proxy>ccsd hal-00422680</proxy><journal-ref>Lecture Notes in Artificial Intelligence LNAI, 5514 (2009) pp
  242--255</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proofs, in Ludics, have an interpretation provided by their counter-proofs,
that is the objects they interact with. We follow the same idea by proposing
that sentence meanings are given by the counter-meanings they are opposed to in
a dialectical interaction. The conception is at the intersection of a
proof-theoretic and a game-theoretic accounts of semantics, but it enlarges
them by allowing to deal with possibly infinite processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1494</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1494</id><created>2009-10-08</created><authors><author><keyname>Syropoulos</keyname><forenames>Apostolos</forenames></author></authors><title>Some Thoughts on Hypercomputation</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hypercomputation is a relatively new branch of computer science that emerged
from the idea that the Church--Turing Thesis, which is supposed to describe
what is computable and what is noncomputable, cannot possible be true. Because
of its apparent validity, the Church--Turing Thesis has been used to
investigate the possible limits of intelligence of any imaginable life form,
and, consequently, the limits of information processing, since living beings
are, among others, information processors. However, in the light of
hypercomputation, which seems to be feasibly in our universe, one cannot impose
arbitrary limits to what intelligence can achieve unless there are specific
physical laws that prohibit the realization of something. In addition,
hypercomputation allows us to ponder about aspects of communication between
intelligent beings that have not been considered before
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1495</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1495</id><created>2009-10-08</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>Estimating Entropy of Data Streams Using Compressed Counting</title><categories>cs.DS cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shannon entropy is a widely used summary statistic, for example, network
traffic measurement, anomaly detection, neural computations, spike trains, etc.
This study focuses on estimating Shannon entropy of data streams. It is known
that Shannon entropy can be approximated by Reenyi entropy or Tsallis entropy,
which are both functions of the p-th frequency moments and approach Shannon
entropy as p-&gt;1.
  Compressed Counting (CC) is a new method for approximating the p-th frequency
moments of data streams. Our contributions include:
  1) We prove that Renyi entropy is (much) better than Tsallis entropy for
approximating Shannon entropy.
  2) We propose the optimal quantile estimator for CC, which considerably
improves the previous estimators.
  3) Our experiments demonstrate that CC is indeed highly effective
approximating the moments and entropies. We also demonstrate the crucial
importance of utilizing the variance-bias trade-off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1511</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1511</id><created>2009-10-08</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Cooperation with an Untrusted Relay: A Secrecy Perspective</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, submitted October 2008,
  revised October 2009. This is the revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the communication scenario where a source-destination pair wishes
to keep the information secret from a relay node despite wanting to enlist its
help. For this scenario, an interesting question is whether the relay node
should be deployed at all. That is, whether cooperation with an untrusted relay
node can ever be beneficial. We first provide an achievable secrecy rate for
the general untrusted relay channel, and proceed to investigate this question
for two types of relay networks with orthogonal components. For the first
model, there is an orthogonal link from the source to the relay. For the second
model, there is an orthogonal link from the relay to the destination. For the
first model, we find the equivocation capacity region and show that answer is
negative. In contrast, for the second model, we find that the answer is
positive. Specifically, we show by means of the achievable secrecy rate based
on compress-and-forward, that, by asking the untrusted relay node to relay
information, we can achieve a higher secrecy rate than just treating the relay
as an eavesdropper. For a special class of the second model, where the relay is
not interfering itself, we derive an upper bound for the secrecy rate using an
argument whose net effect is to separate the eavesdropper from the relay. The
merit of the new upper bound is demonstrated on two channels that belong to
this special class. The Gaussian case of the second model mentioned above
benefits from this approach in that the new upper bound improves the previously
known bounds. For the Cover-Kim deterministic relay channel, the new upper
bound finds the secrecy capacity when the source-destination link is not worse
than the source-relay link, by matching with the achievable rate we present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1528</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1528</id><created>2009-10-08</created><authors><author><keyname>Ang</keyname><forenames>Thomas</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Length of the Shortest Word in the Intersection of Regular Languages</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we give a construction that provides a tight lower bound of
mn-1 for the length of the shortest word in the intersection of two regular
languages with state complexities m and n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1532</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1532</id><created>2009-10-08</created><authors><author><keyname>Cao</keyname><forenames>Yi</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>Capacity Bounds for Two-Hop Interference Networks</title><categories>cs.IT math.IT</categories><comments>8 pages, 5 figures, presented in Allerton Conference'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a two-hop interference network, where two users transmit
independent messages to their respective receivers with the help of two relay
nodes. The transmitters do not have direct links to the receivers; instead, two
relay nodes serve as intermediaries between the transmitters and receivers.
Each hop, one from the transmitters to the relays and the other from the relays
to the receivers, is modeled as a Gaussian interference channel, thus the
network is essentially a cascade of two interference channels. For this
network, achievable symmetric rates for different parameter regimes under
decode-and- forward relaying and amplify-and-forward relaying are proposed and
the corresponding coding schemes are carefully studied. Numerical results are
also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1536</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1536</id><created>2009-10-08</created><updated>2009-10-12</updated><authors><author><keyname>Patra</keyname><forenames>Manas K.</forenames></author><author><keyname>Braunstein</keyname><forenames>Samuel L.</forenames></author></authors><title>An algebraic framework for information theory: Classical Information</title><categories>cs.IT math.IT</categories><comments>35 pages. Typo corrected in the abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a complete algebraic model for classical information
theory. As a precursor the essential probabilistic concepts have been defined
and analyzed in the algebraic setting. Examples from probability and
information theory demonstrate that in addition to theoretical insights
provided by the algebraic model one obtains new computational and anlytical
tools. Several important theorems of classical probahility and information
theory are formulated and proved in the algebraic framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1585</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1585</id><created>2009-10-08</created><updated>2010-10-12</updated><authors><author><keyname>Jaggard</keyname><forenames>Aaron D.</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author><author><keyname>Wright</keyname><forenames>Rebecca N.</forenames></author></authors><title>Distributed Computing with Adaptive Heuristics</title><categories>cs.DC cs.GT</categories><comments>36 pages, four figures. Expands both technical results and discussion
  of v1. Revised version will appear in the proceedings of Innovations in
  Computer Science 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use ideas from distributed computing to study dynamic environments in
which computational nodes, or decision makers, follow adaptive heuristics (Hart
2005), i.e., simple and unsophisticated rules of behavior, e.g., repeatedly
&quot;best replying&quot; to others' actions, and minimizing &quot;regret&quot;, that have been
extensively studied in game theory and economics. We explore when convergence
of such simple dynamics to an equilibrium is guaranteed in asynchronous
computational environments, where nodes can act at any time. Our research
agenda, distributed computing with adaptive heuristics, lies on the borderline
of computer science (including distributed computing and learning) and game
theory (including game dynamics and adaptive heuristics). We exhibit a general
non-termination result for a broad class of heuristics with bounded
recall---that is, simple rules of behavior that depend only on recent history
of interaction between nodes. We consider implications of our result across a
wide variety of interesting and timely applications: game theory, circuit
design, social networks, routing and congestion control. We also study the
computational and communication complexity of asynchronous dynamics and present
some basic observations regarding the effects of asynchrony on no-regret
dynamics. We believe that our work opens a new avenue for research in both
distributed computing and game theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1605</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1605</id><created>2009-10-08</created><updated>2009-10-21</updated><authors><author><keyname>Back</keyname><forenames>Ralph-Johan</forenames><affiliation>&#xc5;bo Akademi University, Finland</affiliation></author><author><keyname>Petre</keyname><forenames>Ion</forenames><affiliation>&#xc5;bo Akademi University, Finland</affiliation></author><author><keyname>de Vink</keyname><forenames>Erik</forenames><affiliation>Eindhoven University of Technology, the Netherlands</affiliation></author></authors><title>Proceedings Second International Workshop on Computational Models for
  Cell Processes</title><categories>cs.CE cs.LO</categories><journal-ref>EPTCS 6, 2009</journal-ref><doi>10.4204/EPTCS.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second international workshop on Computational Models for Cell Processes
(ComProc 2009) took place on November 3, 2009 at the Eindhoven University of
Technology, in conjunction with Formal Methods 2009. The workshop was jointly
organized with the EC-MOAN project. This volume contains the final versions of
all contributions accepted for presentation at the workshop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1623</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1623</id><created>2009-10-08</created><authors><author><keyname>Lu</keyname><forenames>Wei</forenames></author><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Modified Basis Pursuit Denoising(MODIFIED-BPDN) for Noisy Compressive
  Sensing with Partially Known Support</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted ICASSP 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this work, we study the problem of reconstructing a sparse signal from a
limited number of linear 'incoherent' noisy measurements, when a part of its
support is known. The known part of the support may be available from prior
knowledge or from the previous time instant (in applications requiring
recursive reconstruction of a time sequence of sparse signals, e.g. dynamic
MRI). We study a modification of Basis Pursuit Denoising (BPDN) and bound its
reconstruction error. A key feature of our work is that the bounds that we
obtain are computable. Hence, we are able to use Monte Carlo to study their
average behavior as the size of the unknown support increases. We also
demonstrate that when the unknown support size is small, modified-BPDN bounds
are much tighter than those for BPDN, and hold under much weaker sufficient
conditions (require fewer measurements).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1639</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1639</id><created>2009-10-08</created><authors><author><keyname>Chung</keyname><forenames>G.</forenames></author><author><keyname>Vishwanath</keyname><forenames>S.</forenames></author><author><keyname>Hwang</keyname><forenames>C. S.</forenames></author></authors><title>On the Fundamental Limits of Interweaved Cognitive Radios</title><categories>cs.IT math.IT</categories><comments>7 pages, 3 figures, IEEE Radio and Wireless Symposium, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of channel sensing in cognitive radios. The
system model considered is a set of N parallel (dis-similar) channels, where
each channel at any given time is either available or occupied by a legitimate
user. The cognitive radio is permitted to sense channels to determine each of
their states as available or occupied. The end goal of this paper is to select
the best L channels to sense at any given time. Using a convex relaxation
approach, this paper formulates and approximately solves this optimal selection
problem. Finally, the solution obtained to the relaxed optimization problem is
translated into a practical algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1643</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1643</id><created>2009-10-08</created><updated>2010-07-26</updated><authors><author><keyname>Ahn</keyname><forenames>Hee-Kap</forenames></author><author><keyname>Bae</keyname><forenames>Sang Won</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Kim</keyname><forenames>Sang-Sub</forenames></author><author><keyname>Korman</keyname><forenames>Matias</forenames></author><author><keyname>Reinbacher</keyname><forenames>Iris</forenames></author><author><keyname>Son</keyname><forenames>Wanbin</forenames></author></authors><title>Covering Points by Disjoint Boxes with Outliers</title><categories>cs.CG cs.DS</categories><comments>updated version: - changed problem from 'cover exactly n-k points' to
  'cover at least n-k points' to avoid having non-feasible solutions. Results
  are unchanged. - added Proof to Lemma 11, clarified some sections - corrected
  typos and small errors - updated affiliations of two authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a set of n points in the plane, we consider the axis--aligned (p,k)-Box
Covering problem: Find p axis-aligned, pairwise-disjoint boxes that together
contain n-k points. In this paper, we consider the boxes to be either squares
or rectangles, and we want to minimize the area of the largest box. For general
p we show that the problem is NP-hard for both squares and rectangles. For a
small, fixed number p, we give algorithms that find the solution in the
following running times:
  For squares we have O(n+k log k) time for p=1, and O(n log n+k^p log^p k time
for p = 2,3. For rectangles we get O(n + k^3) for p = 1 and O(n log n+k^{2+p}
log^{p-1} k) time for p = 2,3.
  In all cases, our algorithms use O(n) space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1650</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1650</id><created>2009-10-09</created><authors><author><keyname>Xia</keyname><forenames>Dingyin</forenames></author><author><keyname>Wu</keyname><forenames>Fei</forenames></author><author><keyname>Zhang</keyname><forenames>Xuqing</forenames></author><author><keyname>Zhuang</keyname><forenames>Yueting</forenames></author></authors><title>Local and global approaches of affinity propagation clustering for large
  scale data</title><categories>cs.LG cs.CV</categories><comments>9 pages</comments><journal-ref>J Zhejiang Univ Sci A 2008 9(10):1373-1381</journal-ref><doi>10.1631/jzus.A0720058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently a new clustering algorithm called 'affinity propagation' (AP) has
been proposed, which efficiently clustered sparsely related data by passing
messages between data points. However, we want to cluster large scale data
where the similarities are not sparse in many cases. This paper presents two
variants of AP for grouping large scale data with a dense similarity matrix.
The local approach is partition affinity propagation (PAP) and the global
method is landmark affinity propagation (LAP). PAP passes messages in the
subsets of data first and then merges them as the number of initial step of
iterations; it can effectively reduce the number of iterations of clustering.
LAP passes messages between the landmark data points first and then clusters
non-landmark data points; it is a large global approximation method to speed up
clustering. Experiments are conducted on many datasets, such as random data
points, manifold subspaces, images of faces and Chinese calligraphy, and the
results demonstrate that the two approaches are feasible and practicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1688</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1688</id><created>2009-10-09</created><updated>2010-10-07</updated><authors><author><keyname>Ho</keyname><forenames>Zuleita Ka Ming</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Balancing Egoism and Altruism on MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>version 4: 10 pages, journal paper, fixed typo, additional remarks
  and figures for explanation and illustration</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper considers the so-called multiple-input-multiple-output
interference channel (MIMO-IC) which has relevance in applications such as
multi-cell coordination in cellular networks as well as spectrum sharing in
cognitive radio networks among others. We consider a beamforming design
framework based on striking a compromise between beamforming gain at the
intended receiver (Egoism) and the mitigation of interference created towards
other receivers (Altruism). Combining egoistic and altruistic beamforming has
been shown previously in several papers to be instrumental to optimizing the
rates in a multiple-input-single-output interference channel MISO-IC (i.e.
where receivers have no interference canceling capability). Here, by using the
framework of Bayesian games, we shed more light on these game-theoretic
concepts in the more general context of MIMO channels and more particularly
when coordinating parties only have channel state information (CSI) of channels
that they can measure directly. This allows us to derive distributed
beamforming techniques. We draw parallels with existing work on the MIMO-IC,
including rate-optimizing and interference-alignment precoding techniques,
showing how such techniques may be improved or re-interpreted through a common
prism based on balancing egoistic and altruistic beamforming. Our analysis and
simulations currently limited to single stream transmission per user attest the
improvements over known interference alignment based methods in terms of sum
rate performance in the case of so-called asymmetric networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1690</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1690</id><created>2009-10-09</created><authors><author><keyname>Attiogbe</keyname><forenames>Christian</forenames><affiliation>LINA</affiliation></author></authors><title>Tool-Assisted Multi-Facet Analysis of Formal Specifications (Using
  Alelier-B and ProB)</title><categories>cs.SE</categories><proxy>ccsd hal-00420050</proxy><journal-ref>IASTED Conf. on Software Engineering (SE'2006), Innsbruck :
  Austria (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tool-assisted analysis of software systems and convenient guides to practise
the formal methods are still motivating challenges. This article addresses
these challenges. We ex periment on analysing a formal speci?cation from
multiple aspects. The B method and the Atelier-B tool are used for formal
speci?cations, for safety property analysis and for re?nements. The ProB tool
is used to supplement the study with model checking; it helps to discover
errors and there fore to improve the former speci?cations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1691</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1691</id><created>2009-10-09</created><authors><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Steudel</keyname><forenames>Bastian</forenames></author></authors><title>Justifying additive-noise-model based causal discovery via algorithmic
  information theory</title><categories>cs.IT math.IT</categories><comments>17 pages, 1 Figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent method for causal discovery is in many cases able to infer whether X
causes Y or Y causes X for just two observed variables X and Y. It is based on
the observation that there exist (non-Gaussian) joint distributions P(X,Y) for
which Y may be written as a function of X up to an additive noise term that is
independent of X and no such model exists from Y to X. Whenever this is the
case, one prefers the causal model X--&gt; Y.
  Here we justify this method by showing that the causal hypothesis Y--&gt; X is
unlikely because it requires a specific tuning between P(Y) and P(X|Y) to
generate a distribution that admits an additive noise model from X to Y. To
quantify the amount of tuning required we derive lower bounds on the
algorithmic information shared by P(Y) and P(X|Y). This way, our justification
is consistent with recent approaches for using algorithmic information theory
for causal reasoning. We extend this principle to the case where P(X,Y) almost
admits an additive noise model.
  Our results suggest that the above conclusion is more reliable if the
complexity of P(Y) is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1719</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1719</id><created>2009-10-09</created><authors><author><keyname>Calzolari</keyname><forenames>Federico</forenames></author></authors><title>High availability using virtualization</title><categories>cs.DC cs.PF</categories><comments>PhD Thesis in Information Technology Engineering: Electronics,
  Computer Science, Telecommunications, pp. 94, University of Pisa [Italy]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High availability has always been one of the main problems for a data center.
Till now high availability was achieved by host per host redundancy, a highly
expensive method in terms of hardware and human costs. A new approach to the
problem can be offered by virtualization. Using virtualization, it is possible
to achieve a redundancy system for all the services running on a data center.
This new approach to high availability allows to share the running virtual
machines over the servers up and running, by exploiting the features of the
virtualization layer: start, stop and move virtual machines between physical
hosts. The system (3RC) is based on a finite state machine with hysteresis,
providing the possibility to restart each virtual machine over any physical
host, or reinstall it from scratch. A complete infrastructure has been
developed to install operating system and middleware in a few minutes. To
virtualize the main servers of a data center, a new procedure has been
developed to migrate physical to virtual hosts. The whole Grid data center
SNS-PISA is running at the moment in virtual environment under the high
availability system. As extension of the 3RC architecture, several storage
solutions have been tested to store and centralize all the virtual disks, from
NAS to SAN, to grant data safety and access from everywhere. Exploiting
virtualization and ability to automatically reinstall a host, we provide a sort
of host on-demand, where the action on a virtual machine is performed only when
a disaster occurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1757</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1757</id><created>2009-10-09</created><authors><author><keyname>Tapie</keyname><forenames>Laurent</forenames><affiliation>LURPA</affiliation></author><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author></authors><title>Decomposition of forging die for high speed machining</title><categories>cs.RO</categories><proxy>ccsd hal-00422387</proxy><journal-ref>IDMME - Virtual Concept 2008, Beijing : China (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's forging die manufacturing process must be adapted to several
evolutions in machining process generation: CAD/CAM models, CAM software
solutions and High Speed Machining (HSM). In this context, the adequacy between
die shape and HSM process is in the core of machining preparation and process
planning approaches. This paper deals with an original approach of machining
preparation integrating this adequacy in the main tasks carried out. In this
approach, the design of the machining process is based on two levels of
decomposition of the geometrical model of a given die with respect to HSM
cutting conditions (cutting speed and feed rate) and technological constrains
(tool selection, features accessibility). This decomposition assists machining
assistant to generate an HSM process. The result of this decomposition is the
identification of machining features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1758</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1758</id><created>2009-10-09</created><authors><author><keyname>Tapie</keyname><forenames>Laurent</forenames><affiliation>LURPA</affiliation></author><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Anselmetti</keyname><forenames>Bernard</forenames><affiliation>LURPA</affiliation></author></authors><title>Circular tests for HSM machine tools: Bore machining application</title><categories>cs.RO</categories><proxy>ccsd hal-00422388</proxy><journal-ref>International Journal of Machine Tools &amp; Manufacture 47 (2007)
  805-819</journal-ref><doi>10.1016/j.ijmachtools.2006.06.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's High-Speed Machining (HSM) machine tool combines productivity and
part quality. The difficulty inherent in HSM operations lies in understanding
the impact of machine tool behaviour on machining time and part quality.
Analysis of some of the relevant ISO standards (230-1998, 10791-1998) and a
complementary protocol for better understanding HSM technology are presented in
the first part of this paper. These ISO standards are devoted to the procedures
implemented in order to study the behavior of machine tool. As these procedures
do not integrate HSM technology, the need for HSM machine tool tests becomes
critical to improving the trade-off between machining time and part quality. A
new protocol for analysing the HSM technology impact during circular
interpolation is presented in the second part of the paper. This protocol which
allows evaluating kinematic machine tool behaviour during circular
interpolation was designed from tests without machining. These tests are
discussed and their results analysed in the paper. During the circular
interpolation, axis capacities (such as acceleration or Jerk) related to
certain setting parameters of the numerical control unit have a significant
impact on the value of the feed rate. Consequently, a kinematic model for a
circular-interpolated trajectory was developed on the basis of these
parameters. Moreover, the link between part accuracy and kinematic machine tool
behaviour was established. The kinematic model was ultimately validated on a
bore machining simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1760</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1760</id><created>2009-10-09</created><authors><author><keyname>Tapie</keyname><forenames>Laurent</forenames><affiliation>LURPA</affiliation></author><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Anselmetti</keyname><forenames>Bernard</forenames><affiliation>LURPA</affiliation></author></authors><title>Machining strategy choice: performance VIEWER</title><categories>cs.RO</categories><proxy>ccsd hal-00422394</proxy><report-no>Adv-2007-343</report-no><journal-ref>Advances in Integrated Design and Manufacturing in Mechanical
  Engineering II (2007) 343</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays high speed machining (HSM) machine tool combines productivity and
part quality. So mould and die maker invested in HSM. Die and mould features
are more and more complex shaped. Thus, it is difficult to choose the best
machining strategy according to part shape. Geometrical analysis of machining
features is not sufficient to make an optimal choice. Some research show that
security, technical, functional and economical constrains must be taken into
account to elaborate a machining strategy. During complex shape machining,
production system limits induce feed rate decreases, thus loss of productivity,
in some part areas. In this paper we propose to analyse these areas by
estimating tool path quality. First we perform experiments on HSM machine tool
to determine trajectory impact on machine tool behaviour. Then, we extract
critical criteria and establish models of performance loss. Our work is focused
on machine tool kinematical performance and numerical controller unit
calculation capacity. We implement these models on Esprit CAM Software. During
machining trajectory creation, critical part areas can be visualised and
analysed. Parameters, such as, segment or arc lengths, nature of
discontinuities encountered are used to analyse critical part areas. According
to this visualisation, process development engineer should validate or modify
the trajectory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1761</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1761</id><created>2009-10-09</created><authors><author><keyname>Tapie</keyname><forenames>Laurent</forenames><affiliation>LURPA</affiliation></author><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Anselmetti</keyname><forenames>Bernard</forenames><affiliation>LURPA</affiliation></author></authors><title>Decomposition of forging dies for machining planning</title><categories>cs.RO</categories><proxy>ccsd hal-00422403</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper will provide a method to decompose forging dies for machining
planning in the case of high speed machining finishing operations. This method
lies on a machining feature approach model presented in the following paper.
The two main decomposition phases, called Basic Machining Features Extraction
and Process Planning Generation, are presented. These two decomposition phases
integrates machining resources models and expert machining knowledge to provide
an outstanding process planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1762</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1762</id><created>2009-10-09</created><authors><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Tapie</keyname><forenames>Laurent</forenames><affiliation>LURPA</affiliation></author></authors><title>D\'efinition d'une pi\`ece test pour la caract\'erisation d'une machine
  UGV</title><categories>cs.RO</categories><proxy>ccsd hal-00422405</proxy><journal-ref>1er Conrg\`es International Conception et Mod\'elisation des
  Syst\`emes M\'ecaniques, CMSM\'05, Tunisie (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In several fields like aeronautics, die and automotive, the machining of the
parts is done more and more on high speed machines tools. Today, the offer for
purchasing these machine tools is very wide. This situation poses the problem
of the judicious and objective choice meeting industrial needs that must be
necessary well expressed. The choice remains difficult insofar as the technical
data provided to the customers by the manufacturers of machine tools are
insufficient as well quantitatively as qualitatively. In this paper we present
a protocol for the characterization of machines tools in order to direct the
choice. The protocol is based on the one hand on no-load complementary tests to
those recommended by the standards ISO 230 and ISO 10791 and on the other hand
on the tests in load on a part test. In the first part, we present the
industrial needs as well as an analysis of the technical data of machine tools.
The second part is devoted to the study of the standards, the description of
the protocol and the presentation of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1763</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1763</id><created>2009-10-09</created><authors><author><keyname>Goubault</keyname><forenames>Eric</forenames></author><author><keyname>Putot</keyname><forenames>Sylvie</forenames></author></authors><title>A zonotopic framework for functional abstractions</title><categories>cs.LO</categories><comments>23 pages</comments><acm-class>D.2.4; F.3.1; F.3.2; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article formalizes an abstraction of input/output relations, based on
parameterized zonotopes, which we call affine sets. We describe the abstract
transfer functions and prove their correctness, which allows the generation of
accurate numerical invariants. Other applications range from compositional
reasoning to proofs of user-defined complex invariants and test case
generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1787</identifier>
 <datestamp>2010-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1787</id><created>2009-10-09</created><updated>2010-05-05</updated><authors><author><keyname>Kim</keyname><forenames>Jaeweon</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Sensitive White Space Detection with Spectral Covariance Sensing</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel, highly effective spectrum sensing algorithm for
cognitive radio and whitespace applications. The proposed spectral covariance
sensing (SCS) algorithm exploits the different statistical correlations of the
received signal and noise in the frequency domain. Test statistics are computed
from the covariance matrix of a partial spectrogram and compared with a
decision threshold to determine whether a primary signal or arbitrary type is
present or not. This detector is analyzed theoretically and verified through
realistic open-source simulations using actual digital television signals
captured in the US. Compared to the state of the art in the literature, SCS
improves sensitivity by 3 dB for the same dwell time, which is a very
significant improvement for this application. Further, it is shown that SCS is
highly robust to noise uncertainty, whereas many other spectrum sensors are
not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1800</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1800</id><created>2009-10-09</created><authors><author><keyname>Furtlehner</keyname><forenames>Cyril</forenames></author><author><keyname>Sebag</keyname><forenames>Michele</forenames></author><author><keyname>Zhang</keyname><forenames>Xiangliang</forenames></author></authors><title>Scaling Analysis of Affinity Propagation</title><categories>cs.AI cond-mat.stat-mech</categories><comments>28 pages, 14 figures, Inria research report</comments><report-no>7046</report-no><journal-ref>Phys. Rev. E 81,066102 (2010)</journal-ref><doi>10.1103/PhysRevE.81.066102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze and exploit some scaling properties of the Affinity Propagation
(AP) clustering algorithm proposed by Frey and Dueck (2007). First we observe
that a divide and conquer strategy, used on a large data set hierarchically
reduces the complexity ${\cal O}(N^2)$ to ${\cal O}(N^{(h+2)/(h+1)})$, for a
data-set of size $N$ and a depth $h$ of the hierarchical strategy. For a
data-set embedded in a $d$-dimensional space, we show that this is obtained
without notably damaging the precision except in dimension $d=2$. In fact, for
$d$ larger than 2 the relative loss in precision scales like
$N^{(2-d)/(h+1)d}$. Finally, under some conditions we observe that there is a
value $s^*$ of the penalty coefficient, a free parameter used to fix the number
of clusters, which separates a fragmentation phase (for $s&lt;s^*$) from a
coalescent one (for $s&gt;s^*$) of the underlying hidden cluster structure. At
this precise point holds a self-similarity property which can be exploited by
the hierarchical strategy to actually locate its position. From this
observation, a strategy based on \AP can be defined to find out how many
clusters are present in a given dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1808</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1808</id><created>2009-10-09</created><authors><author><keyname>Eschen</keyname><forenames>Elaine M.</forenames></author><author><keyname>Hoang</keyname><forenames>Chinh T.</forenames></author><author><keyname>Spinrad</keyname><forenames>Jeremy P.</forenames></author><author><keyname>Sritharan</keyname><forenames>R.</forenames></author></authors><title>Finding a sun in building-free graphs</title><categories>cs.DM</categories><comments>3 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deciding whether an arbitrary graph contains a sun was recently shown to be
NP-complete. We show that whether a building-free graph contains a sun can be
decided in O(min$\{m{n^3}, m^{1.5}n^2\}$) time and, if a sun exists, it can be
found in the same time bound. The class of building-free graphs contains many
interesting classes of perfect graphs such as Meyniel graphs which, in turn,
contains classes such as hhd-free graphs, i-triangulated graphs, and parity
graphs. Moreover, there are imperfect graphs that are building-free. The class
of building-free graphs generalizes several classes of graphs for which an
efficient test for the presence of a sun is known. We also present a vertex
elimination scheme for the class of (building, gem)-free graphs. The class of
(building, gem)-free graphs is a generalization of the class of distance
hereditary graphs and a restriction of the class of (building, sun)-free
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1838</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1838</id><created>2009-10-09</created><authors><author><keyname>Singh</keyname><forenames>Manoj Kumar</forenames></author></authors><title>Password Based a Generalize Robust Security System Design Using Neural
  Network</title><categories>cs.CR cs.NE</categories><comments>International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp1-9, September 2009</comments><journal-ref>M.K Singh, &quot;Password Based A Generalize Robust Security System
  Design Using Neural Network&quot;, International Journal of Computer Science
  Issues, IJCSI, Volume 4, Issue 2, pp1-9, September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the various means of available resource protection including
biometrics, password based system is most simple, user friendly, cost effective
and commonly used. But this method having high sensitivity with attacks. Most
of the advanced methods for authentication based on password encrypt the
contents of password before storing or transmitting in physical domain. But all
conventional cryptographic based encryption methods are having its own
limitations, generally either in terms of complexity or in terms of efficiency.
Multi-application usability of password today forcing users to have a proper
memory aids. Which itself degrades the level of security. In this paper a
method to exploit the artificial neural network to develop the more secure
means of authentication, which is more efficient in providing the
authentication, at the same time simple in design, has given. Apart from
protection, a step toward perfect security has taken by adding the feature of
intruder detection along with the protection system. This is possible by
analysis of several logical parameters associated with the user activities. A
new method of designing the security system centrally based on neural network
with intrusion detection capability to handles the challenges available with
present solutions, for any kind of resource has presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1844</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1844</id><created>2009-10-09</created><authors><author><keyname>Fallavollita</keyname><forenames>Pascal</forenames></author></authors><title>3D/2D Registration of Mapping Catheter Images for Arrhythmia
  Interventional Assistance</title><categories>cs.CV</categories><comments>International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp10-19, September 2009</comments><journal-ref>P. Fallavollita, &quot; 3D/2D Registration of Mapping Catheter Images
  for Arrhythmia Interventional Assistance&quot;, International Journal of Computer
  Science Issues, IJCSI, Volume 4, Issue 2, pp10-19, September 2009&quot;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiofrequency (RF) catheter ablation has transformed treatment for
tachyarrhythmias and has become first-line therapy for some tachycardias. The
precise localization of the arrhythmogenic site and the positioning of the RF
catheter over that site are problematic: they can impair the efficiency of the
procedure and are time consuming (several hours). Electroanatomic mapping
technologies are available that enable the display of the cardiac chambers and
the relative position of ablation lesions. However, these are expensive and use
custom-made catheters. The proposed methodology makes use of standard catheters
and inexpensive technology in order to create a 3D volume of the heart chamber
affected by the arrhythmia. Further, we propose a novel method that uses a
priori 3D information of the mapping catheter in order to estimate the 3D
locations of multiple electrodes across single view C-arm images. The monoplane
algorithm is tested for feasibility on computer simulations and initial canine
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1845</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1845</id><created>2009-10-09</created><authors><author><keyname>Raju</keyname><forenames>Mandhapati P.</forenames></author></authors><title>Parallel Computation of Finite Element Navier-Stokes codes using MUMPS
  Solver</title><categories>cs.MS</categories><comments>&quot;International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp20-24, September 2009&quot;</comments><journal-ref>M. P. Raju,&quot; Parallel Computation of Finite Element Navier-Stokes
  codes using MUMPS Solver&quot;,International Journal of Computer Science Issues,
  IJCSI, Volume 4, Issue 2, pp20-24, September 2009&quot;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study deals with the parallelization of 2D and 3D finite element based
Navier-Stokes codes using direct solvers. Development of sparse direct solvers
using multifrontal solvers has significantly reduced the computational time of
direct solution methods. Although limited by its stringent memory requirements,
multifrontal solvers can be computationally efficient. First the performance of
MUltifrontal Massively Parallel Solver (MUMPS) is evaluated for both 2D and 3D
codes in terms of memory requirements and CPU times. The scalability of both
Newton and modified Newton algorithms is tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1849</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1849</id><created>2009-10-09</created><authors><author><keyname>Silakari</keyname><forenames>Sanjay</forenames></author><author><keyname>Motwani</keyname><forenames>Mahesh</forenames></author><author><keyname>Maheshwari</keyname><forenames>Manish</forenames></author></authors><title>Color Image Clustering using Block Truncation Algorithm</title><categories>cs.CV</categories><comments>&quot; International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp31-35, September 2009&quot;</comments><journal-ref>S. Silakari, M. Motwani and M. Maheshwari,&quot; Color Image Clustering
  using Block Truncation Algorithm&quot;, International Journal of Computer Science
  Issues, IJCSI, Volume 4, Issue 2, pp31-35, September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advancement in image capturing device, the image data been generated
at high volume. If images are analyzed properly, they can reveal useful
information to the human users. Content based image retrieval address the
problem of retrieving images relevant to the user needs from image databases on
the basis of low-level visual features that can be derived from the images.
Grouping images into meaningful categories to reveal useful information is a
challenging and important problem. Clustering is a data mining technique to
group a set of unsupervised data based on the conceptual clustering principal:
maximizing the intraclass similarity and minimizing the interclass similarity.
Proposed framework focuses on color as feature. Color Moment and Block
Truncation Coding (BTC) are used to extract features for image dataset.
Experimental study using K-Means clustering algorithm is conducted to group the
image dataset into various clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1852</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1852</id><created>2009-10-09</created><authors><author><keyname>Jamali</keyname><forenames>Mohammad Ali Jabraeil</forenames></author><author><keyname>Khademzadeh</keyname><forenames>Ahmad</forenames></author></authors><title>DAMQ-Based Schemes for Efficiently Using the Buffer Spaces of a NoC
  Router</title><categories>cs.DC</categories><comments>&quot; International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp36-41, September 2009&quot;</comments><journal-ref>M. A. J. Jamali and A. Khademzadeh, &quot; DAMQ-Based Schemes for
  Efficiently Using the Buffer Spaces of a NoC Router&quot;, International Journal
  of Computer Science Issues, IJCSI, Volume 4, Issue 2, pp36-41, September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present high performance dynamically allocated multi-queue
(DAMQ) buffer schemes for fault tolerance systems on chip applications that
require an interconnection network. Two or four virtual channels shared the
same buffer space. On the message switching layer, we make improvement to boost
system performance when there are faults involved in the components
communication. The proposed schemes are when a node or a physical channel is
deemed as faulty, the previous hop node will terminate the buffer occupancy of
messages destined to the failed link. The buffer usage decisions are made at
switching layer without interactions with higher abstract layer, thus buffer
space will be released to messages destined to other healthy nodes quickly.
Therefore, the buffer space will be efficiently used in case fault occurs at
some nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1857</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1857</id><created>2009-10-09</created><authors><author><keyname>Noor</keyname><forenames>Ahmad Shukri Mohd</forenames></author><author><keyname>Saman</keyname><forenames>Md Yazid Md</forenames></author></authors><title>Distributed Object Medical Imaging Model</title><categories>cs.SE cs.CV</categories><comments>&quot; International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp42-48, September 2009&quot;</comments><journal-ref>A.S.M. Noor and Y.Saman, &quot;Distributed Object Medical Imaging
  Model&quot;, International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp42-48, September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital medical informatics and images are commonly used in hospitals today,.
Because of the interrelatedness of the radiology department and other
departments, especially the intensive care unit and emergency department, the
transmission and sharing of medical images has become a critical issue. Our
research group has developed a Java-based Distributed Object Medical Imaging
Model(DOMIM) to facilitate the rapid development and deployment of medical
imaging applications in a distributed environment that can be shared and used
by related departments and mobile physiciansDOMIM is a unique suite of
multimedia telemedicine applications developed for the use by medical related
organizations. The applications support realtime patients' data, image files,
audio and video diagnosis annotation exchanges. The DOMIM enables joint
collaboration between radiologists and physicians while they are at distant
geographical locations. The DOMIM environment consists of heterogeneous,
autonomous, and legacy resources. The Common Object Request Broker Architecture
(CORBA), Java Database Connectivity (JDBC), and Java language provide the
capability to combine the DOMIM resources into an integrated, interoperable,
and scalable system. The underneath technology, including IDL ORB, Event
Service, IIOP JDBC/ODBC, legacy system wrapping and Java implementation are
explored. This paper explores a distributed collaborative CORBA/JDBC based
framework that will enhance medical information management requirements and
development. It encompasses a new paradigm for the delivery of health services
that requires process reengineering, cultural changes, as well as
organizational changes
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1862</identifier>
 <datestamp>2009-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1862</id><created>2009-10-12</created><authors><author><keyname>Sherstov</keyname><forenames>Alexander A.</forenames></author></authors><title>The intersection of two halfspaces has high threshold degree</title><categories>cs.CC</categories><comments>Full version of the FOCS'09 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The threshold degree of a Boolean function f:{0,1}^n-&gt;{-1,+1} is the least
degree of a real polynomial p such that f(x)=sgn p(x). We construct two
halfspaces on {0,1}^n whose intersection has threshold degree Theta(sqrt n), an
exponential improvement on previous lower bounds. This solves an open problem
due to Klivans (2002) and rules out the use of perceptron-based techniques for
PAC learning the intersection of two halfspaces, a central unresolved challenge
in computational learning. We also prove that the intersection of two majority
functions has threshold degree Omega(log n), which is tight and settles a
conjecture of O'Donnell and Servedio (2003).
  Our proof consists of two parts. First, we show that for any nonconstant
Boolean functions f and g, the intersection f(x)^g(y) has threshold degree O(d)
if and only if ||f-F||_infty + ||g-G||_infty &lt; 1 for some rational functions F,
G of degree O(d). Second, we settle the least degree required for approximating
a halfspace and a majority function to any given accuracy by rational
functions.
  Our technique further allows us to make progress on Aaronson's challenge
(2008) and contribute strong direct product theorems for polynomial
representations of composed Boolean functions of the form F(f_1,...,f_n). In
particular, we give an improved lower bound on the approximate degree of the
AND-OR tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1863</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1863</id><created>2009-10-09</created><authors><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author><author><keyname>Karipidis</keyname><forenames>Eleftherios</forenames></author></authors><title>Computational Complexity of Decoding Orthogonal Space-Time Block Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational complexity of optimum decoding for an orthogonal space-time
block code G satisfying the orthogonality property that the Hermitian transpose
of G multiplied by G is equal to a constant c times the sum of the squared
symbols of the code times an identity matrix, where c is a positive integer is
quantified. Four equivalent techniques of optimum decoding which have the same
computational complexity are specified. Modifications to the basic formulation
in special cases are calculated and illustrated by means of examples. This
paper corrects and extends [1],[2], and unifies them with the results from the
literature. In addition, a number of results from the literature are extended
to the case c &gt; 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1865</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1865</id><created>2009-10-09</created><authors><author><keyname>Chen</keyname><forenames>Yee Ming</forenames></author><author><keyname>Wang</keyname><forenames>Bo-Yuan</forenames></author></authors><title>Towards Participatory Design of Multi-agent Approach to Transport
  Demands</title><categories>cs.MA</categories><comments>&quot;International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 1, pp10-15, September 2009&quot;</comments><journal-ref>Y. M. Chen and B. Wang, &quot;Towards Participatory Design of
  Multi-agent Approach to Transport Demands &quot;, International Journal of
  Computer Science Issues, IJCSI, Volume 4, Issue 1, pp10-15, September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of multi-agent based simulations (MABS) is up to now mainly done
in laboratories and based on designers' understanding of the activities to be
simulated. Domain experts have little chance to directly validate agent
behaviors. To fill this gap, we are investigating participatory methods of
design, which allow users to participate in the design the pickup and delivery
problem (PDP) in the taxi planning problem. In this paper, we present a
participatory process for designing new socio-technical architectures to afford
the taxi dispatch for this transportation system. The proposed dispatch
architecture attempts to increase passenger satisfaction more globally, by
concurrently dispatching multiple taxis to the same number of passengers in the
same geographical region, and vis-avis human driver and dispatcher
satisfaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1868</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1868</id><created>2009-10-09</created><authors><author><keyname>Goyal</keyname><forenames>Vishal</forenames></author><author><keyname>Lehal</keyname><forenames>Gurpreet Singh</forenames></author></authors><title>Evaluation of Hindi to Punjabi Machine Translation System</title><categories>cs.CL</categories><comments>&quot;International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 1, pp36-39, September 2009&quot;</comments><journal-ref>V.Goyal and G. Singh Lehal, &quot;Evaluation of Hindi to Punjabi
  Machine Translation System&quot;, International Journal of Computer Science
  Issues, IJCSI, Volume 4, Issue 1, pp36-39, September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Translation in India is relatively young. The earliest efforts date
from the late 80s and early 90s. The success of every system is judged from its
evaluation experimental results. Number of machine translation systems has been
started for development but to the best of author knowledge, no high quality
system has been completed which can be used in real applications. Recently,
Punjabi University, Patiala, India has developed Punjabi to Hindi Machine
translation system with high accuracy of about 92%. Both the systems i.e.
system under question and developed system are between same closely related
languages. Thus, this paper presents the evaluation results of Hindi to Punjabi
machine translation system. It makes sense to use same evaluation criteria as
that of Punjabi to Hindi Punjabi Machine Translation System. After evaluation,
the accuracy of the system is found to be about 95%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1869</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1869</id><created>2009-10-09</created><updated>2009-10-27</updated><authors><author><keyname>Chahar</keyname><forenames>Ravita</forenames></author><author><keyname>Hooda</keyname><forenames>Komal</forenames></author><author><keyname>Dhankhar</keyname><forenames>Annu</forenames></author></authors><title>Management Of Volatile Information In Incremental Web Crawler</title><categories>cs.IR</categories><comments>Paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1871</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1871</id><created>2009-10-09</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>MIMO Wireless Communications under Statistical Queueing Constraints</title><categories>cs.IT math.IT</categories><comments>A shorter version is presented at the 2009 Allerton Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of multiple-input multiple-output wireless systems is
investigated in the presence of statistical queueing constraints. Queuing
constraints are imposed as limitations on buffer violation probabilities. The
performance under such constraints is captured through the effective capacity
formulation. A detailed analysis of the effective capacity is carried out in
the low-power, wideband, and high--signal-to-noise ratio (SNR) regimes. In the
low-power analysis, expressions for the first and second derivatives of the
effective capacity with respect to SNR at SNR= 0 are obtained under various
assumptions on the degree of channel state information at the transmitter.
Transmission strategies that are optimal in the sense of achieving the first
and second derivatives are identified. It is shown that while the first
derivative does not get affected by the presence of queueing constraints, the
second derivative gets smaller as the constraints become more stringent.
Through the energy efficiency analysis, this is shown to imply that the minimum
bit energy requirements do not change with more strict limitations but the
wideband slope diminishes. Similar results are obtained in the wideband regime
if rich multipath fading is being experienced. On the other hand, sparse
multipath fading with bounded number of degrees of freedom is shown to increase
the minimum bit energy requirements in the presence of queueing constraints.
Following the low-SNR study, the impact of buffer limitations on the high-SNR
performance is quantified by analyzing the high-SNR slope and the power offset
in Rayleigh fading channels. Finally, numerical results are provided to
illustrate the theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1879</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1879</id><created>2009-10-12</created><updated>2010-09-17</updated><authors><author><keyname>Gross</keyname><forenames>David</forenames></author></authors><title>Recovering low-rank matrices from few coefficients in any basis</title><categories>cs.IT cs.NA math.IT math.NA quant-ph</categories><comments>See also arxiv:0909.3304. v1=v2. v3: Some bounds substantially
  improved. v4, v5: presentation improved. To appear in IEEE Transactions on
  Information Theory</comments><journal-ref>IEEE Trans. on Information Theory, vol. 57, pages 1548 - 1566
  (2011)</journal-ref><doi>10.1109/TIT.2011.2104999</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present novel techniques for analyzing the problem of low-rank matrix
recovery. The methods are both considerably simpler and more general than
previous approaches. It is shown that an unknown (n x n) matrix of rank r can
be efficiently reconstructed from only O(n r nu log^2 n) randomly sampled
expansion coefficients with respect to any given matrix basis. The number nu
quantifies the &quot;degree of incoherence&quot; between the unknown matrix and the
basis. Existing work concentrated mostly on the problem of &quot;matrix completion&quot;
where one aims to recover a low-rank matrix from randomly selected matrix
elements. Our result covers this situation as a special case. The proof
consists of a series of relatively elementary steps, which stands in contrast
to the highly involved methods previously employed to obtain comparable
results. In cases where bounds had been known before, our estimates are
slightly tighter. We discuss operator bases which are incoherent to all
low-rank matrices simultaneously. For these bases, we show that O(n r nu log n)
randomly sampled expansion coefficients suffice to recover any low-rank matrix
with high probability. The latter bound is tight up to multiplicative
constants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1901</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1901</id><created>2009-10-10</created><authors><author><keyname>Attiogbe</keyname><forenames>Christian</forenames><affiliation>LINA</affiliation></author></authors><title>Can Component/Service-Based Systems Be Proved Correct?</title><categories>cs.SE</categories><comments>16 pages</comments><proxy>ccsd hal-00420051</proxy><journal-ref>Conference on Current Trends in Theory and Practice of Computer
  Science, Czech Republic, Spindleruv Ml\'yn, : Czech Republic (2009)</journal-ref><doi>10.1007/978-3-540-95891-8_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component-oriented and service-oriented approaches have gained a strong
enthusiasm in industries and academia with a particular interest for
service-oriented approaches. A component is a software entity with given
functionalities, made available by a provider, and used to build other
application within which it is integrated. The service concept and its use in
web-based application development have a huge impact on reuse practices.
Accordingly a considerable part of software architectures is influenced; these
architectures are moving towards service-oriented architectures. Therefore
applications (re)use services that are available elsewhere and many
applications interact, without knowing each other, using services available via
service servers and their published interfaces and functionalities. Industries
propose, through various consortium, languages, technologies and standards.
More academic works are also undertaken concerning semantics and formalisation
of components and service-based systems. We consider here both streams of works
in order to raise research concerns that will help in building quality
software. Are there new challenging problems with respect to service-based
software construction? Besides, what are the links and the advances compared to
distributed systems?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1922</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1922</id><created>2009-10-10</created><authors><author><keyname>Savin</keyname><forenames>Valentin</forenames></author></authors><title>Binary Linear-Time Erasure Decoding for Non-Binary LDPC codes</title><categories>cs.IT math.IT</categories><comments>5 pages, ITW</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first introduce the extended binary representation of
non-binary codes, which corresponds to a covering graph of the bipartite graph
associated with the non-binary code. Then we show that non-binary codewords
correspond to binary codewords of the extended representation that further
satisfy some simplex-constraint: that is, bits lying over the same symbol-node
of the non-binary graph must form a codeword of a simplex code. Applied to the
binary erasure channel, this description leads to a binary erasure decoding
algorithm of non-binary LDPC codes, whose complexity depends linearly on the
cardinality of the alphabet. We also give insights into the structure of
stopping sets for non-binary LDPC codes, and discuss several aspects related to
upper-layer FEC applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1923</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1923</id><created>2009-10-10</created><authors><author><keyname>Bremner</keyname><forenames>David</forenames></author><author><keyname>Chen</keyname><forenames>Dan</forenames></author></authors><title>A Branch and Cut Algorithm for the Halfspace Depth Problem</title><categories>cs.CG cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of \emph{data depth} in non-parametric multivariate descriptive
statistics is the generalization of the univariate rank method to multivariate
data. \emph{Halfspace depth} is a measure of data depth. Given a set $S$ of
points and a point $p$, the halfspace depth (or rank) of $p$ is defined as the
minimum number of points of $S$ contained in any closed halfspace with $p$ on
its boundary. Computing halfspace depth is NP-hard, and it is equivalent to the
Maximum Feasible Subsystem problem. In this paper a mixed integer program is
formulated with the big-$M$ method for the halfspace depth problem. We suggest
a branch and cut algorithm for these integer programs. In this algorithm,
Chinneck's heuristic algorithm is used to find an upper bound and a related
technique based on sensitivity analysis is used for branching. Irreducible
Infeasible Subsystem (IIS) hitting set cuts are applied. We also suggest a
binary search algorithm which may be more numerically stable. The algorithms
are implemented with the BCP framework from the \textbf{COIN-OR} project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1926</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1926</id><created>2009-10-10</created><authors><author><keyname>Harvey</keyname><forenames>David</forenames></author></authors><title>Faster algorithms for the square root and reciprocal of power series</title><categories>cs.SC cs.DS</categories><comments>6 pages, 1 figure, requires algorithm2e package</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give new algorithms for the computation of square roots and reciprocals of
power series in C[[x]]. If M(n) denotes the cost of multiplying polynomials of
degree n, the square root to order n costs (1.333... + o(1)) M(n) and the
reciprocal costs (1.444... + o(1)) M(n). These improve on the previous best
results, respectively (1.8333... + o(1)) M(n) and (1.5 + o(1)) M(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1938</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1938</id><created>2009-10-10</created><authors><author><keyname>Galeas</keyname><forenames>Patricio</forenames></author><author><keyname>Kretschmer</keyname><forenames>Ralph</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author></authors><title>Information Retrieval via Truncated Hilbert-Space Expansions</title><categories>cs.IR</categories><comments>12 pages, submitted to proceedings of ECIR-2010</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to the frequency of terms in a document collection, the
distribution of terms plays an important role in determining the relevance of
documents. In this paper, a new approach for representing term positions in
documents is presented. The approach allows an efficient evaluation of
term-positional information at query evaluation time. Three applications are
investigated: a function-based ranking optimization representing a user-defined
document region, a query expansion technique based on overlapping the term
distributions in the top-ranked documents, and cluster analysis of terms in
documents. Experimental results demonstrate the effectiveness of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1943</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1943</id><created>2009-10-10</created><authors><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author><author><keyname>Howard</keyname><forenames>Stephen</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author></authors><title>Construction of a Large Class of Deterministic Sensing Matrices that
  Satisfy a Statistical Isometry Property</title><categories>cs.IT math.IT math.PR</categories><comments>16 Pages, 2 figures, to appear in IEEE Journal of Selected Topics in
  Signal Processing, the special issue on Compressed Sensing</comments><doi>10.1109/JSTSP.2010.2043161</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Sensing aims to capture attributes of $k$-sparse signals using
very few measurements. In the standard Compressed Sensing paradigm, the
$\m\times \n$ measurement matrix $\A$ is required to act as a near isometry on
the set of all $k$-sparse signals (Restricted Isometry Property or RIP).
Although it is known that certain probabilistic processes generate $\m \times
\n$ matrices that satisfy RIP with high probability, there is no practical
algorithm for verifying whether a given sensing matrix $\A$ has this property,
crucial for the feasibility of the standard recovery algorithms. In contrast
this paper provides simple criteria that guarantee that a deterministic sensing
matrix satisfying these criteria acts as a near isometry on an overwhelming
majority of $k$-sparse signals; in particular, most such signals have a unique
representation in the measurement domain. Probability still plays a critical
role, but it enters the signal model rather than the construction of the
sensing matrix. We require the columns of the sensing matrix to form a group
under pointwise multiplication. The construction allows recovery methods for
which the expected performance is sub-linear in $\n$, and only quadratic in
$\m$; the focus on expected performance is more typical of mainstream signal
processing than the worst-case analysis that prevails in standard Compressed
Sensing. Our framework encompasses many families of deterministic sensing
matrices, including those formed from discrete chirps, Delsarte-Goethals codes,
and extended BCH codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1954</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1954</id><created>2009-10-10</created><authors><author><keyname>Ahmad</keyname><forenames>Sahand Haji Ali</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Multi-channel Opportunistic Access: A Case of Restless Bandits with
  Multiple Plays</title><categories>cs.IT cs.DM math.IT math.OC</categories><comments>8 pages, 0 figures, Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing, 2009</comments><journal-ref>Proceedings of Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the following stochastic control problem that arises in
opportunistic spectrum access: a system consists of n channels (Gilbert-Elliot
channels)where the state (good or bad) of each channel evolves as independent
and identically distributed Markov processes. A user can select exactly k
channels to sense and access (based on the sensing result) in each time slot. A
reward is obtained whenever the user senses and accesses a good channel. The
objective is to design a channel selection policy that maximizes the expected
discounted total reward accrued over a finite or infinite horizon. In our
previous work we established the optimality of a greedy policy for the special
case of k = 1 (i.e., single channel access) under the condition that the
channel state transitions are positively correlated over time. In this paper we
show under the same condition the greedy policy is optimal for the general case
of k &gt;= 1; the methodology introduced here is thus more general. This problem
may be viewed as a special case of the restless bandit problem, with multiple
plays. We discuss connections between the current problem and existing
literature on this class of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1955</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1955</id><created>2009-10-10</created><updated>2010-08-26</updated><authors><author><keyname>Piasecki</keyname><forenames>R.</forenames></author></authors><title>Microstructure reconstruction using entropic descriptors</title><categories>cond-mat.stat-mech cs.CV</categories><comments>version accepted for publication in Proc. R. Soc. A</comments><journal-ref>Proc. R. Soc. A 467 (2011) 806-820</journal-ref><doi>10.1098/rspa.2010.0296</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-scale approach to the inverse reconstruction of a pattern's
microstructure is reported. Instead of a correlation function, a pair of
entropic descriptors (EDs) is proposed for stochastic optimization method. The
first of them measures a spatial inhomogeneity, for a binary pattern, or
compositional one, for a greyscale image. The second one quantifies a spatial
or compositional statistical complexity. The EDs reveal structural information
that is dissimilar, at least in part, to that given by correlation functions at
almost all of discrete length scales. The method is tested on a few digitized
binary and greyscale images. In each of the cases, the persuasive
reconstruction of the microstructure is found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1969</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1969</id><created>2009-10-11</created><authors><author><keyname>Kale</keyname><forenames>Ajinkya</forenames></author><author><keyname>Vaidya</keyname><forenames>Shaunak</forenames></author><author><keyname>Joglekar</keyname><forenames>Ashish</forenames></author></authors><title>A Generalized Recursive Algorithm for Binary Multiplication based on
  Vedic Mathematics</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalized algorithm for multiplication is proposed through recursive
application of the Nikhilam Sutra from Vedic Mathematics, operating in radix -
2 number system environment suitable for digital platforms. Statistical
analysis has been carried out based on the number of recursions profile as a
function of the smaller multiplicand. The proposed algorithm is efficient for
smaller multiplicands as well, unlike most of the asymptotically fast
algorithms. Further, a basic block schematic of Hardware Implementation of our
algorithm is suggested to exploit parallelism and speed up the implementation
of the algorithm in a multiprocessor environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1974</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1974</id><created>2009-10-11</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Pandey</keyname><forenames>Suraj</forenames></author><author><keyname>Vecchiola</keyname><forenames>Christian</forenames></author></authors><title>Cloudbus Toolkit for Market-Oriented Cloud Computing</title><categories>cs.DC</categories><comments>21 pages, 6 figures, 2 tables, Conference paper</comments><acm-class>C.2.4</acm-class><journal-ref>Proceeding of the 1st International Conference on Cloud Computing
  (CloudCom 2009, Springer, Germany), Beijing, China, December 1-4, 2009</journal-ref><doi>10.1007/978-3-642-10665-1_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This keynote paper: (1) presents the 21st century vision of computing and
identifies various IT paradigms promising to deliver computing as a utility;
(2) defines the architecture for creating market-oriented Clouds and computing
atmosphere by leveraging technologies such as virtual machines; (3) provides
thoughts on market-based resource management strategies that encompass both
customer-driven service management and computational risk management to sustain
SLA-oriented resource allocation; (4) presents the work carried out as part of
our new Cloud Computing initiative, called Cloudbus: (i) Aneka, a Platform as a
Service software system containing SDK (Software Development Kit) for
construction of Cloud applications and deployment on private or public Clouds,
in addition to supporting market-oriented resource management; (ii)
internetworking of Clouds for dynamic creation of federated computing
environments for scaling of elastic applications; (iii) creation of 3rd party
Cloud brokering services for building content delivery networks and e-Science
applications and their deployment on capabilities of IaaS providers such as
Amazon along with Grid mashups; (iv) CloudSim supporting modelling and
simulation of Clouds for performance studies; (v) Energy Efficient Resource
Allocation Mechanisms and Techniques for creation and management of Green
Clouds; and (vi) pathways for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.1979</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.1979</id><created>2009-10-11</created><authors><author><keyname>Vecchiola</keyname><forenames>Christian</forenames></author><author><keyname>Pandey</keyname><forenames>Suraj</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>High-Performance Cloud Computing: A View of Scientific Applications</title><categories>cs.DC</categories><comments>13 pages, 9 figures, conference paper</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 10th International Symposium on Pervasive
  Systems, Algorithms and Networks (I-SPAN 2009, IEEE CS Press, USA),
  Kaohsiung, Taiwan, December 14-16, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientific computing often requires the availability of a massive number of
computers for performing large scale experiments. Traditionally, these needs
have been addressed by using high-performance computing solutions and installed
facilities such as clusters and super computers, which are difficult to setup,
maintain, and operate. Cloud computing provides scientists with a completely
new model of utilizing the computing infrastructure. Compute resources, storage
resources, as well as applications, can be dynamically provisioned (and
integrated within the existing infrastructure) on a pay per use basis. These
resources can be released when they are no more needed. Such services are often
offered within the context of a Service Level Agreement (SLA), which ensure the
desired Quality of Service (QoS). Aneka, an enterprise Cloud computing
solution, harnesses the power of compute resources by relying on private and
public Clouds and delivers to users the desired QoS. Its flexible and service
based infrastructure supports multiple programming paradigms that make Aneka
address a variety of different scenarios: from finance applications to
computational science. As examples of scientific computing in the Cloud, we
present a preliminary case study on using Aneka for the classification of gene
expression data and the execution of fMRI brain imaging workflow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2004</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2004</id><created>2009-10-11</created><updated>2010-04-07</updated><authors><author><keyname>Holtgrewe</keyname><forenames>Manuel</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author><author><keyname>Schulz</keyname><forenames>Christian</forenames></author></authors><title>Engineering a Scalable High Quality Graph Partitioner</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an approach to parallel graph partitioning that scales to
hundreds of processors and produces a high solution quality. For example, for
many instances from Walshaw's benchmark collection we improve the best known
partitioning. We use the well known framework of multi-level graph
partitioning. All components are implemented by scalable parallel algorithms.
Quality improvements compared to previous systems are due to better
prioritization of edges to be contracted, better approximation algorithms for
identifying matchings, better local search heuristics, and perhaps most
notably, a parallelization of the FM local search algorithm that works more
locally than previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2005</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2005</id><created>2009-10-12</created><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Modulation Codes for Flash Memory Based on Load-Balancing Theory</title><categories>cs.IT math.IT</categories><comments>This work was presented in the 47-th Allerton conference</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we consider modulation codes for practical multilevel flash
memory storage systems with cell levels. Instead of maximizing the lifetime of
the device [Ajiang-isit07-01, Ajiang-isit07-02,
Yaakobi_verdy_siegel_wolf_allerton08, Finucane_Liu_Mitzenmacher_aller08], we
maximize the average amount of information stored per cell-level, which is
defined as storage efficiency. Using this framework, we show that the
worst-case criterion [Ajiang-isit07-01, Ajiang-isit07-02,
Yaakobi_verdy_siegel_wolf_allerton08] and the average-case criterion
[Finucane_Liu_Mitzenmacher_aller08] are two extreme cases of our objective
function. A self-randomized modulation code is proposed which is asymptotically
optimal, as, for an arbitrary input alphabet and i.i.d. input distribution.
  In practical flash memory systems, the number of cell-levels is only
moderately large. So the asymptotic performance as may not tell the whole
story. Using the tools from load-balancing theory, we analyze the storage
efficiency of the self-randomized modulation code. The result shows that only a
fraction of the cells are utilized when the number of cell-levels is only
moderately large. We also propose a load-balancing modulation code, based on a
phenomenon known as &quot;the power of two random choices&quot; [Mitzenmacher96thepower],
to improve the storage efficiency of practical systems. Theoretical analysis
and simulation results show that our load-balancing modulation codes can
provide significant gain to practical flash memory storage systems. Though
pseudo-random, our approach achieves the same load-balancing performance, for
i.i.d. inputs, as a purely random approach based on the power of two random
choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2007</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2007</id><created>2009-10-11</created><authors><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Liew</keyname><forenames>Soung-Chang</forenames></author><author><keyname>Lu</keyname><forenames>Lu</forenames></author><author><keyname>Wang</keyname><forenames>Hui</forenames></author></authors><title>Interference with Symbol-misalignment</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the impact of interference asynchrony among different
links in a wireless network. Without deliberate coordination and cooperation
among the active links, there is a naturally occurring misalignment between the
symbols of the targeted signal of a receiver and the symbols of the interfering
signals. Interestingly, we show that the interference asynchrony can actually
improve the BER performance, compared with the situation in which symbols of al
signals ay aligned. In particular, we show that symbol misalignment can
decrease the &quot;effective interference power&quot; and change the distribution of the
interfering signals, in a way that results in lower BER. To ensure that symbol
misalignment can be consistently attained, we propose two simple schemes that
introduce time-varying symbol offsets to obtain an &quot;average&quot; performance of
random symbol misalignment. Notably, our schemes do not change the simple
receiver design structure; only the transmitters are modified in a minor way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2024</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2024</id><created>2009-10-11</created><updated>2009-11-18</updated><authors><author><keyname>Cheeger</keyname><forenames>Jeff</forenames></author><author><keyname>Kleiner</keyname><forenames>Bruce</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>A $(\log n)^{\Omega(1)}$ integrality gap for the Sparsest Cut SDP</title><categories>cs.DS math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Goemans-Linial semidefinite relaxation of the Sparsest Cut
problem with general demands has integrality gap $(\log n)^{\Omega(1)}$. This
is achieved by exhibiting $n$-point metric spaces of negative type whose $L_1$
distortion is $(\log n)^{\Omega(1)}$. Our result is based on quantitative
bounds on the rate of degeneration of Lipschitz maps from the Heisenberg group
to $L_1$ when restricted to cosets of the center.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2026</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2026</id><created>2009-10-11</created><authors><author><keyname>Cheeger</keyname><forenames>Jeff</forenames></author><author><keyname>Kleiner</keyname><forenames>Bruce</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Compression bounds for Lipschitz maps from the Heisenberg group to $L_1$</title><categories>math.MG cs.DS math.DG math.FA math.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a quantitative bi-Lipschitz nonembedding theorem for the Heisenberg
group with its Carnot-Carath\'eodory metric and apply it to give a lower bound
on the integrality gap of the Goemans-Linial semidefinite relaxation of the
Sparsest Cut problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2028</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2028</id><created>2009-10-11</created><authors><author><keyname>Jamali</keyname><forenames>Shahram</forenames></author><author><keyname>Analoui</keyname><forenames>Morteza</forenames></author></authors><title>Congestion Control in the Internet by Employing a Ratio dependent Plant
  Herbivore Carnivorous Model</title><categories>cs.NI cs.DS</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 175-181, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The demand for Internet based services has exploded over the last decade.
Many organizations use the Internet and particularly the World Wide Web as
their primary medium for communication and business. This phenomenal growth has
dramatically increased the performance requirements for the Internet. To have a
high performance Internet, a good congestion control system is essential for
it. The current work proposes that the congestion control in the Internet can
be inspired from the population control tactics of the nature. Toward this
idea, each flow (W) in the network is viewed as a species whose population size
is congestion window size of the flow. By this assumption, congestion control
problem is redefined as population control of flow species. This paper defines
a three trophic food chain analogy in congestion control area, and gives a
ratio dependent model to control population size of W species within this plant
herbivore carnivorous food chain. Simulation results show that this model
achieves fair bandwidth allocation, high utilization and small queue size. It
does not maintain any per flow state in routers and have few computational
loads per packet, which makes it scalable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2029</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2029</id><created>2009-10-11</created><authors><author><keyname>Asadi</keyname><forenames>Roya</forenames></author><author><keyname>Mustapha</keyname><forenames>Norwati</forenames></author><author><keyname>Sulaiman</keyname><forenames>Nasir</forenames></author></authors><title>A Framework For Intelligent Multi Agent System Based Neural Network
  Classification Model</title><categories>cs.NE cs.MA</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 168-174, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TIntelligent multi agent systems have great potentials to use in different
purposes and research areas. One of the important issues to apply intelligent
multi agent systems in real world and virtual environment is to develop a
framework that support machine learning model to reflect the whole complexity
of the real world. In this paper, we proposed a framework of intelligent agent
based neural network classification model to solve the problem of gap between
two applicable flows of intelligent multi agent technology and learning model
from real environment. We consider the new Supervised Multilayers Feed Forward
Neural Network (SMFFNN) model as an intelligent classification for learning
model in the framework. The framework earns the information from the respective
environment and its behavior can be recognized by the weights. Therefore, the
SMFFNN model that lies in the framework will give more benefits in finding the
suitable information and the real weights from the environment which result for
better recognition. The framework is applicable to different domains
successfully and for the potential case study, the clinical organization and
its domain is considered for the proposed framework
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2034</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2034</id><created>2009-10-11</created><updated>2010-11-10</updated><authors><author><keyname>Zanghi</keyname><forenames>Hugo</forenames></author><author><keyname>Picard</keyname><forenames>Franck</forenames></author><author><keyname>Miele</keyname><forenames>Vincent</forenames></author><author><keyname>Ambroise</keyname><forenames>Christophe</forenames></author></authors><title>Strategies for online inference of model-based clustering in large and
  growing networks</title><categories>stat.AP cs.LG</categories><comments>Published in at http://dx.doi.org/10.1214/10-AOAS359 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS359</report-no><journal-ref>Annals of Applied Statistics 2010, Vol. 4, No. 2, 687-714</journal-ref><doi>10.1214/10-AOAS359</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we adapt online estimation strategies to perform model-based
clustering on large networks. Our work focuses on two algorithms, the first
based on the SAEM algorithm, and the second on variational methods. These two
strategies are compared with existing approaches on simulated and real data. We
use the method to decipher the connexion structure of the political websphere
during the US political campaign in 2008. We show that our online EM-based
algorithms offer a good trade-off between precision and speed, when estimating
parameters for mixture distributions in the context of random graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2039</identifier>
 <datestamp>2010-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2039</id><created>2009-10-11</created><updated>2010-05-18</updated><authors><author><keyname>Zahedi</keyname><forenames>Keyan</forenames></author><author><keyname>Ay</keyname><forenames>Nihat</forenames></author><author><keyname>Der</keyname><forenames>Ralf</forenames></author></authors><title>Higher coordination with less control - A result of information
  maximization in the sensorimotor loop</title><categories>cs.AI cs.IT cs.RO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a novel learning method in the context of embodied
artificial intelligence and self-organization, which has as few assumptions and
restrictions as possible about the world and the underlying model. The learning
rule is derived from the principle of maximizing the predictive information in
the sensorimotor loop. It is evaluated on robot chains of varying length with
individually controlled, non-communicating segments. The comparison of the
results shows that maximizing the predictive information per wheel leads to a
higher coordinated behavior of the physically connected robots compared to a
maximization per robot. Another focus of this paper is the analysis of the
effect of the robot chain length on the overall behavior of the robots. It will
be shown that longer chains with less capable controllers outperform those of
shorter length and more complex controllers. The reason is found and discussed
in the information-geometric interpretation of the learning process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2042</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2042</id><created>2009-10-11</created><authors><author><keyname>Raskutti</keyname><forenames>Garvesh</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Yu</keyname><forenames>Bin</forenames></author></authors><title>Minimax rates of estimation for high-dimensional linear regression over
  $\ell_q$-balls</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Presented in part at the Allerton Conference on Control,
  Communication and Computer, Monticello, IL, October 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the standard linear regression model $\y = \Xmat \betastar + w$,
where $\y \in \real^\numobs$ is an observation vector, $\Xmat \in
\real^{\numobs \times \pdim}$ is a design matrix, $\betastar \in \real^\pdim$
is the unknown regression vector, and $w \sim \mathcal{N}(0, \sigma^2 I)$ is
additive Gaussian noise. This paper studies the minimax rates of convergence
for estimation of $\betastar$ for $\ell_\rpar$-losses and in the
$\ell_2$-prediction loss, assuming that $\betastar$ belongs to an
$\ell_{\qpar}$-ball $\Ballq(\myrad)$ for some $\qpar \in [0,1]$. We show that
under suitable regularity conditions on the design matrix $\Xmat$, the minimax
error in $\ell_2$-loss and $\ell_2$-prediction loss scales as $\Rq
\big(\frac{\log \pdim}{n}\big)^{1-\frac{\qpar}{2}}$. In addition, we provide
lower bounds on minimax risks in $\ell_{\rpar}$-norms, for all $\rpar \in [1,
+\infty], \rpar \neq \qpar$. Our proofs of the lower bounds are
information-theoretic in nature, based on Fano's inequality and results on the
metric entropy of the balls $\Ballq(\myrad)$, whereas our proofs of the upper
bounds are direct and constructive, involving direct analysis of least-squares
over $\ell_{\qpar}$-balls. For the special case $q = 0$, a comparison with
$\ell_2$-risks achieved by computationally efficient $\ell_1$-relaxations
reveals that although such methods can achieve the minimax rates up to constant
factors, they require slightly stronger assumptions on the design matrix
$\Xmat$ than algorithms involving least-squares over the $\ell_0$-ball.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2044</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2044</id><created>2009-10-11</created><authors><author><keyname>Mokhov</keyname><forenames>O. I.</forenames></author></authors><title>Consistency on cubic lattices for determinants of arbitrary orders</title><categories>nlin.SI cs.CG cs.DM math-ph math.DS math.MP</categories><journal-ref>Proceedings of the Steklov Institute of Mathematics, 2009, Vol.
  266, pp. 195-209</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a special class of two-dimensional discrete equations defined by
relations on elementary NxN squares, N&gt;2, of the square lattice Z^2, and
propose a new type of consistency conditions on cubic lattices for such
discrete equations that is connected to bending elementary NxN squares, N&gt;2, in
the cubic lattice Z^3. For an arbitrary N we prove such consistency on cubic
lattices for two-dimensional discrete equations defined by the condition that
the determinants of values of the field at the points of the square lattice Z^2
that are contained in elementary NxN squares vanish.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2048</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2048</id><created>2009-10-11</created><authors><author><keyname>Butler</keyname><forenames>Raymond J.</forenames></author></authors><title>The Role of Spreadsheets in the Allied Irish Bank / Allfirst Currency
  Trading Fraud</title><categories>cs.CY</categories><comments>4 Pages. To Appear Proc. European Spreadsheet Risks Interest Group</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This brief paper outlines how spreadsheets were used as one of the vehicles
for John Rusnak's fraud and the revenue control lessons this case gives us.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2058</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2058</id><created>2009-10-12</created><updated>2010-07-01</updated><authors><author><keyname>Laumann</keyname><forenames>C. R.</forenames></author><author><keyname>L&#xe4;uchli</keyname><forenames>A. M.</forenames></author><author><keyname>Moessner</keyname><forenames>R.</forenames></author><author><keyname>Scardicchio</keyname><forenames>A.</forenames></author><author><keyname>Sondhi</keyname><forenames>S. L.</forenames></author></authors><title>On product, generic and random generic quantum satisfiability</title><categories>quant-ph cond-mat.stat-mech cs.CC</categories><comments>9 pages, 5 figures, 1 table. Updated to more closely match published
  version. New proof in appendix</comments><journal-ref>Phys. Rev. A 81, 062345 (2010)</journal-ref><doi>10.1103/PhysRevA.81.062345</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a cluster of results on k-QSAT, the problem of quantum
satisfiability for k-qubit projectors which generalizes classical
satisfiability with k-bit clauses to the quantum setting. First we define the
NP-complete problem of product satisfiability and give a geometrical criterion
for deciding when a QSAT interaction graph is product satisfiable with positive
probability. We show that the same criterion suffices to establish quantum
satisfiability for all projectors. Second, we apply these results to the random
graph ensemble with generic projectors and obtain improved lower bounds on the
location of the SAT--unSAT transition. Third, we present numerical results on
random, generic satisfiability which provide estimates for the location of the
transition for k=3 and k=4 and mild evidence for the existence of a phase which
is satisfiable by entangled states alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2065</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2065</id><created>2009-10-11</created><updated>2010-06-07</updated><authors><author><keyname>Liu</keyname><forenames>Keqin</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Distributed Learning in Multi-Armed Bandit with Multiple Players</title><categories>math.OC cs.LG math.PR</categories><comments>31 pages, 8 figures, revised paper submitted to IEEE Transactions on
  Signal Processing, April, 2010, the pre-agreement in the decentralized TDFS
  policy is eliminated to achieve a complete decentralization among players</comments><doi>10.1109/TSP.2010.2062509</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate and study a decentralized multi-armed bandit (MAB) problem.
There are M distributed players competing for N independent arms. Each arm,
when played, offers i.i.d. reward according to a distribution with an unknown
parameter. At each time, each player chooses one arm to play without exchanging
observations or any information with other players. Players choosing the same
arm collide, and, depending on the collision model, either no one receives
reward or the colliding players share the reward in an arbitrary way. We show
that the minimum system regret of the decentralized MAB grows with time at the
same logarithmic order as in the centralized counterpart where players act
collectively as a single entity by exchanging observations and making decisions
jointly. A decentralized policy is constructed to achieve this optimal order
while ensuring fairness among players and without assuming any pre-agreement or
information exchange among players. Based on a Time Division Fair Sharing
(TDFS) of the M best arms, the proposed policy is constructed and its order
optimality is proven under a general reward model. Furthermore, the basic
structure of the TDFS policy can be used with any order-optimal single-player
policy to achieve order optimality in the decentralized setting. We also
establish a lower bound on the system regret growth rate for a general class of
decentralized polices, to which the proposed policy belongs. This problem finds
potential applications in cognitive radio networks, multi-channel communication
systems, multi-agent systems, web search and advertising, and social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2066</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2066</id><created>2009-10-12</created><updated>2009-10-14</updated><authors><author><keyname>Alipour</keyname><forenames>Philip B.</forenames></author></authors><title>A Lossless Fuzzy Binary AND/OR Compressor</title><categories>cs.IT math.IT</categories><comments>LaTeX format, 44 pages, 8 images, 2 tables. Minor modifications were
  made (pp. 28, 30-33, 37-40); no major content revision. We discussed the
  theoretical approach to feasible conjectures in pattern matching and logic on
  a new data compression model. We hypothesized a greater plausibility on data
  compression and compaction methods relative to data decompression techniques</comments><acm-class>E.3; E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, a new fuzzy 2bit-AND parallel-to-OR, or simply, a fuzzy
binary AND/OR (FBAR) text data compression model as an algorithm is suggested
for bettering spatial locality limits on nodes during database transactions.
The current model incorporates a four-layer application technique:
string-to-AND/OR pairwise binary bit + fuzzy quantum with noise conversions.
This technique promotes a lossless data compression ratio of 2:1 up to values
approximately = 3:1, generating a spatially-efficient compressed data file
compared to nowadays data compressors. Data decompression/specific data
reconstruction initiates an AND/OR pattern match technique in respect of fuzzy
quantum indicators in the binary function field. The reconstruction of data
occurs in the 4th layer using encryption methods. It is hypothesized that
significant data compression ratio of 2n:1 for n&gt;3:1 ratios, e.g., 32~64:1 are
achievable via fuzzy qubit indexing over classical byte blocks for every bit
position fragmented into a (1/2 upper +1/2 lower)-bit noise frequency parallel
to its counterpart signal comprised of AND/ORed-bit polarity orientation, ready
for an identical data decompression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2099</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2099</id><created>2009-10-12</created><authors><author><keyname>Britz</keyname><forenames>Thomas</forenames></author><author><keyname>Heiseldel</keyname><forenames>B&#xe5;rd</forenames></author><author><keyname>Johnsen</keyname><forenames>Trygve</forenames></author><author><keyname>Mayhew</keyname><forenames>Dillon</forenames></author><author><keyname>Shiromoto</keyname><forenames>Keisuke</forenames></author></authors><title>Generalizations of Wei's Duality Theorem</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wei's celebrated Duality Theorem is generalized in several ways, expressed as
duality theorems for linear codes over division rings and, more generally,
duality theorems for matroids. These results are further generalized, resulting
in two Wei-type duality theorems for new combinatorial structures that are
introduced and named {\em demi-matroids}. These generalize matroids and are the
appropriate combinatorial objects for describing the duality in Wei's Duality
Theorem. A new proof of the Duality Theorem is thereby given that explains the
theorem in combinatorial terms. Special cases of the general duality theorems
are also given, including duality theorems for cycles and bonds in graphs and
for transversals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2104</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2104</id><created>2009-10-12</created><updated>2010-04-13</updated><authors><author><keyname>Zhang</keyname><forenames>Guoqiang</forenames></author></authors><title>On cost-effective communication network designing</title><categories>cs.NI physics.gen-ph</categories><comments>6 pages, 4 figures</comments><journal-ref>Europhysics Letters(EPL), 89(2010) 38003</journal-ref><doi>10.1209/0295-5075/89/38003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How to efficiently design a communication network is a paramount task for
network designing and engineering. It is, however, not a single objective
optimization process as perceived by most previous researches, i.e., to
maximize its transmission capacity, but a multi-objective optimization process,
with lowering its cost to be another important objective. These two objectives
are often contradictive in that optimizing one objective may deteriorate the
other. After a deep investigation of the impact that network topology, node
capability scheme and routing algorithm as well as their interplays have on the
two objectives, this letter presents a systematic approach to achieve a
cost-effective design by carefully choosing the three designing aspects. Only
when routing algorithm and node capability scheme are elegantly chosen can
BA-like scale-free networks have the potential of achieving good tradeoff
between the two objectives. Random networks, on the other hand, have the
built-in character for a cost-effective design, especially when other aspects
cannot be determined beforehand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2113</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2113</id><created>2009-10-12</created><authors><author><keyname>Kumar</keyname><forenames>Abhimanu</forenames></author><author><keyname>Das</keyname><forenames>Sanjib Kumar</forenames></author></authors><title>A real world network pricing game with less severe Braess' Paradox</title><categories>cs.GT</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet and graphs are very much related. The graphical structure of
internet has been studied extensively to provide efficient solutions to routing
and other problems. But most of these studies assume a central authority which
controls and manages the internet. In the recent years game theoretic models
have been proposed which do not require a central authority and the users are
assumed to be routing their flows selfishly. The existence of Nash Equilibria,
congestion and the amount of inefficiency caused by this selfish routing is a
major concern in this field. A type of paradox in the selfish routing networks,
Braess' Paradox, first discovered by Braess, is a major contributor to
inefficiency. Several pricing mechanisms have also been provided which give a
game theoretical model between users(consumers) and ISPs ({Internet Service
Providers} or sellers) for the internet.
  We propose a novel pricing mechanism, based on real world Internet network
architecture, which reduces the severity of Braess' Paradox in selfish routing
game theoretic networks. It's a pricing mechanism between combinatorial users
and ISPs. We prove that Nash equilibria exists in this network and provide
bounds on inefficiency . We use graphical properties of internet to prove our
result. Several interesting extensions and future work have also been
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2115</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2115</id><created>2009-10-12</created><authors><author><keyname>Peris-Lopez</keyname><forenames>Pedro</forenames></author><author><keyname>Hernandez-Castro</keyname><forenames>Julio C.</forenames></author><author><keyname>Tapiador</keyname><forenames>J. M. E.</forenames></author><author><keyname>van der Lubbe</keyname><forenames>Jan C. A.</forenames></author></authors><title>Security Flaws in a Recent Ultralightweight RFID Protocol</title><categories>cs.CR</categories><comments>14 pages, 2 figures and 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2006, Peris-Lopez et al. [1, 2, 3] initiated the design of
ultralightweight RFID protocols -with the UMAP family of protocols- involving
only simple bitwise logical or arithmetic operations such as bitwise XOR, OR,
AND, and addition. This combination of operations was revealed later to be
insufficient for security. Then, Chien et al. proposed the SASI protocol [4]
with the aim of offering better security, by adding the bitwise rotation to the
set of supported operations. The SASI protocol represented a milestone in the
design of ultralightweight protocols, although certain attacks have been
published against this scheme [5, 6, 7]. In 2008, a new protocol, named
Gossamer [8], was proposed that can be considered a further development of both
the UMAP family and SASI. Although no attacks have been published against
Gossamer, Lee et al. [9] have recently published an alternative scheme that is
highly reminiscent of SASI. In this paper, we show that Lee et al.'s scheme
fails short of many of its security objectives, being vulnerable to several
important attacks like traceability, full disclosure, cloning and
desynchronization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2140</identifier>
 <datestamp>2013-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2140</id><created>2009-10-12</created><authors><author><keyname>Clegg</keyname><forenames>Richard G.</forenames></author><author><keyname>Di Cairano-Gilfedder</keyname><forenames>Carla</forenames></author><author><keyname>Zhou</keyname><forenames>Shi</forenames></author></authors><title>A critical look at power law modelling of the Internet</title><categories>cs.NI</categories><comments>To appear Computer Communications</comments><doi>10.1016/j.comcom.2009.09.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper takes a critical look at the usefulness of power law models of the
Internet. The twin focuses of the paper are Internet traffic and topology
generation. The aim of the paper is twofold. Firstly it summarises the state of
the art in power law modelling particularly giving attention to existing open
research questions. Secondly it provides insight into the failings of such
models and where progress needs to be made for power law research to feed
through to actual improvements in network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2153</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2153</id><created>2009-10-12</created><authors><author><keyname>Minier</keyname><forenames>Marine</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes, INRIA Rocquencourt, EA 3720, CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes, CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Pousse</keyname><forenames>Benjamin</forenames><affiliation>XLIM</affiliation></author></authors><title>Improving Integral Cryptanalysis against Rijndael with Large Blocks</title><categories>cs.CR</categories><proxy>ccsd inria-00423681</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report presents new four-round integral properties against the Rijndael
cipher with block sizes larger than 128 bits. Using higher-order multiset
distinguishers and other well-known extensions of those properties, the deduced
attacks reach up to 7 and 8 rounds of Rijndael variants with 160 up to 256-bit
blocks. For example, a 7-rounds attack against Rijndael-224 has a time
complexity equal to $2^{80}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2154</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2154</id><created>2009-10-12</created><authors><author><keyname>Tonetti</keyname><forenames>J.</forenames><affiliation>CHU-Grenoble ortho-traumato</affiliation></author><author><keyname>Vadcard</keyname><forenames>L.</forenames><affiliation>LSE</affiliation></author><author><keyname>Girard</keyname><forenames>P.</forenames><affiliation>IHPC</affiliation></author><author><keyname>Dubois</keyname><forenames>M.</forenames><affiliation>LPS</affiliation></author><author><keyname>Merloz</keyname><forenames>P.</forenames><affiliation>CHU-Grenoble ortho-traumato</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Assessment of a percutaneous iliosacral screw insertion simulator</title><categories>cs.OH</categories><proxy>ccsd hal-00423588</proxy><journal-ref>Orthop Traumatol Surg Res (2009) epub ahead of print</journal-ref><doi>10.1016/j.otsr.2009.07.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BACKGROUND: Navigational simulator use for specialized training purposes is
rather uncommon in orthopaedic and trauma surgery. However, it reveals
providing a valuable tool to train orthopaedic surgeons and help them to plan
complex surgical procedures. PURPOSE: This work's objective was to assess
educational efficiency of a path simulator under fluoroscopic guidance applied
to sacroiliac joint percutaneous screw fixation. MATERIALS AND METHODS: We
evaluated 23 surgeons' accuracy inserting a guide-wire in a human cadaver
experiment, following a pre-established procedure. These medical trainees were
defined in three prospective respects: novice or skilled; with or without
theoretical knowledge; with or without surgical procedure familiarity. Analysed
criteria for each tested surgeon included the number of intraoperative X-rays
taken in order to achieve the surgical procedure as well as an iatrogenic index
reflecting the surgeon's ability to detect any hazardous trajectory at the time
of performing said procedure. RESULTS: An average number of 13 X-rays was
required for wire implantation by the G1 group. G2 group, assisted by the
simulator use, required an average of 10 X-rays. A substantial difference was
especially observed within the novice sub-group (N), with an average of 12.75
X-rays for the G1 category and an average of 8.5 X-rays for the G2 category. As
far as the iatrogenic index is concerned, we were unable to observe any
significant difference between the groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2168</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2168</id><created>2009-10-12</created><updated>2010-10-14</updated><authors><author><keyname>Jo</keyname><forenames>Han-Shin</forenames></author><author><keyname>Mun</keyname><forenames>Cheol</forenames></author><author><keyname>Moon</keyname><forenames>June</forenames></author><author><keyname>Yook</keyname><forenames>Jong-Gwan</forenames></author></authors><title>Self-optimized Coverage Coordination in Femtocell Networks</title><categories>cs.NI</categories><comments>16 pages, 5 figures</comments><journal-ref>IEEE Transactions on Wireless Communications, vol.9, no.10,
  pp.2977-2982, Oct. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a self-optimized coverage coordination scheme for
two-tier femtocell networks, in which a femtocell base station adjusts the
transmit power based on the statistics of the signal and the interference power
that is measured at a femtocell downlink. Furthermore, an analytic expression
is derived for the coverage leakage probability that a femtocell coverage area
leaks into an outdoor macrocell. The coverage analysis is verified by
simulation, which shows that the proposed scheme provides sufficient indoor
femtocell coverage and that the femtocell coverage does not leak into an
outdoor macrocell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2173</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2173</id><created>2009-10-12</created><authors><author><keyname>Youssef</keyname><forenames>Roua</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author></authors><title>Distributed Turbo-Like Codes for Multi-User Cooperative Relay Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to ICC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a distributed turbo-like coding scheme for wireless networks
with relays is proposed. We consider a scenario where multiple sources
communicate with a single destination with the help of a relay. The proposed
scheme can be regarded as of the decode-and-forward type. The relay decodes the
information from the sources and it properly combines and re-encodes them to
generate some extra redundancy, which is transmitted to the destination. The
amount of redundancy generated by the relay can simply be adjusted according to
requirements in terms of performance, throughput and/or power. At the
destination, decoding of the information of all sources is performed jointly
exploiting the redundancy provided by the relay in an iterative fashion. The
overall communication network can be viewed as a serially concatenated code.
The proposed distributed scheme achieves significant performance gains with
respect to the non-cooperation system, even for a very large number of users.
Furthermore, it presents a high flexibility in terms of code rate, block length
and number of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2187</identifier>
 <datestamp>2011-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2187</id><created>2009-10-12</created><updated>2011-02-15</updated><authors><author><keyname>Rei&#xdf;ig</keyname><forenames>Gunther</forenames></author></authors><title>Computing abstractions of nonlinear systems</title><categories>math.OC cs.SY math.DS</categories><comments>This work has been accepted for publication in the IEEE Trans.
  Automatic Control. v3: minor modifications; accepted version</comments><msc-class>93C10 (Primary), 93C55 (Secondary), 93C57, 93C15, 93B03</msc-class><journal-ref>IEEE Trans. Automat. Control 56, no 11, Nov 2011, pp. 2583-2598</journal-ref><doi>10.1109/TAC.2011.2118950</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sufficiently accurate finite state models, also called symbolic models or
discrete abstractions, allow one to apply fully automated methods, originally
developed for purely discrete systems, to formally reason about continuous and
hybrid systems, and to design finite state controllers that provably enforce
predefined specifications. We present a novel algorithm to compute such finite
state models for nonlinear discrete-time and sampled systems which depends on
quantizing the state space using polyhedral cells, embedding these cells into
suitable supersets whose attainable sets are convex, and over-approximating
attainable sets by intersections of supporting half-spaces. We prove a novel
recursive description of these half-spaces and propose an iterative procedure
to compute them efficiently. We also provide new sufficient conditions for the
convexity of attainable sets which imply the existence of the aforementioned
embeddings of quantizer cells. Our method yields highly accurate abstractions
and applies to nonlinear systems under mild assumptions, which reduce to
sufficient smoothness in the case of sampled systems. Its practicability in the
design of discrete controllers for nonlinear continuous plants under state and
control constraints is demonstrated by an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2217</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2217</id><created>2009-10-12</created><authors><author><keyname>Mthembu</keyname><forenames>Linda</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author><author><keyname>Friswell</keyname><forenames>Michael I.</forenames></author><author><keyname>Adhikari</keyname><forenames>Sondipon</forenames></author></authors><title>Finite element model selection using Particle Swarm Optimization</title><categories>cs.AI</categories><comments>Accepted for the Proceedings of the International Modal Analysis
  Conference 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the application of particle swarm optimization (PSO) to
the problem of finite element model (FEM) selection. This problem arises when a
choice of the best model for a system has to be made from set of competing
models, each developed a priori from engineering judgment. PSO is a
population-based stochastic search algorithm inspired by the behaviour of
biological entities in nature when they are foraging for resources. Each
potentially correct model is represented as a particle that exhibits both
individualistic and group behaviour. Each particle moves within the model
search space looking for the best solution by updating the parameters values
that define it. The most important step in the particle swarm algorithm is the
method of representing models which should take into account the number,
location and variables of parameters to be updated. One example structural
system is used to show the applicability of PSO in finding an optimal FEM. An
optimal model is defined as the model that has the least number of updated
parameters and has the smallest parameter variable variation from the mean
material properties. Two different objective functions are used to compare
performance of the PSO algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2221</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2221</id><created>2009-10-12</created><authors><author><keyname>Jo</keyname><forenames>Han-Shin</forenames></author><author><keyname>Mun</keyname><forenames>Cheol</forenames></author><author><keyname>Moon</keyname><forenames>June</forenames></author><author><keyname>Yook</keyname><forenames>Jong-Gwan</forenames></author></authors><title>Interference Mitigation Using Uplink Power Control for Two-Tier
  Femtocell Networks</title><categories>cs.NI</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes two interference mitigation strategies that adjust the
maximum transmit power of femtocell users to suppress the cross-tier
interference at a macrocell base station (BS). The open-loop and the
closed-loop control suppress the cross-tier interference less than a fixed
threshold and an adaptive threshold based on the noise and interference (NI)
level at the macrocell BS, respectively. Simulation results show that both
schemes effectively compensate the uplink throughput degradation of the
macrocell BS due to the cross-tier interference and that the closed-loop
control provides better femtocell throughput than the open-loop control at a
minimal cost of macrocell throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2240</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2240</id><created>2009-10-12</created><authors><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author><author><keyname>Poor</keyname><forenames>Vincent H.</forenames></author></authors><title>Repeated Auctions with Learning for Spectrum Access in Cognitive Radio
  Networks</title><categories>cs.IT cs.LG math.IT math.OC</categories><comments>This paper is presented in Allerton Conference on Communication,
  Control, and Computing 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, spectrum access in cognitive radio networks is modeled as a
repeated auction game subject to monitoring and entry costs. For secondary
users, sensing costs are incurred as the result of primary users' activity.
Furthermore, each secondary user pays the cost of transmissions upon successful
bidding for a channel. Knowledge regarding other secondary users' activity is
limited due to the distributed nature of the network. The resulting formulation
is thus a dynamic game with incomplete information. In this paper, an efficient
bidding learning algorithm is proposed based on the outcome of past
transactions. As demonstrated through extensive simulations, the proposed
distributed scheme outperforms a myopic one-stage algorithm, and can achieve a
good balance between efficiency and fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2245</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2245</id><created>2009-10-12</created><authors><author><keyname>Cullina</keyname><forenames>Daniel</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Searching for Minimum Storage Regenerating Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regenerating codes allow distributed storage systems to recover from the loss
of a storage node while transmitting the minimum possible amount of data across
the network. We present a systematic computer search for optimal systematic
regenerating codes. To search the space of potential codes, we reduce the
potential search space in several ways. We impose an additional symmetry
condition on codes that we consider. We specify codes in a simple alternative
way, using additional recovered coefficients rather than transmission
coefficients and place codes into equivalence classes to avoid redundant
checking. Our main finding is a few optimal systematic minimum storage
regenerating codes for $n=5$ and $k=3$, over several finite fields. No such
codes were previously known and the matching of the information theoretic
cut-set bound was an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2263</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2263</id><created>2009-10-12</created><updated>2010-09-27</updated><authors><author><keyname>Huang</keyname><forenames>Shurui</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Minimum cost mirror sites using network coding: Replication vs. coding
  at the source nodes</title><categories>cs.IT math.IT</categories><comments>IEEE Trans. on Information Theory (to appear), 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content distribution over networks is often achieved by using mirror sites
that hold copies of files or portions thereof to avoid congestion and delay
issues arising from excessive demands to a single location. Accordingly, there
are distributed storage solutions that divide the file into pieces and place
copies of the pieces (replication) or coded versions of the pieces (coding) at
multiple source nodes. We consider a network which uses network coding for
multicasting the file. There is a set of source nodes that contains either
subsets or coded versions of the pieces of the file. The cost of a given
storage solution is defined as the sum of the storage cost and the cost of the
flows required to support the multicast. Our interest is in finding the storage
capacities and flows at minimum combined cost. We formulate the corresponding
optimization problems by using the theory of information measures. In
particular, we show that when there are two source nodes, there is no loss in
considering subset sources. For three source nodes, we derive a tight upper
bound on the cost gap between the coded and uncoded cases. We also present
algorithms for determining the content of the source nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2271</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2271</id><created>2009-10-12</created><updated>2009-11-11</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Sinop</keyname><forenames>Ali Kemal</forenames></author></authors><title>Improved Inapproximability Results for Maximum k-Colorable Subgraph</title><categories>cs.CC</categories><comments>16 pages, 2 figures</comments><doi>10.1007/978-3-642-03685-9_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the maximization version of the fundamental graph coloring problem.
Here the goal is to color the vertices of a k-colorable graph with k colors so
that a maximum fraction of edges are properly colored (i.e. their endpoints
receive different colors). A random k-coloring properly colors an expected
fraction 1-1/k of edges. We prove that given a graph promised to be
k-colorable, it is NP-hard to find a k-coloring that properly colors more than
a fraction ~1-O(1/k} of edges. Previously, only a hardness factor of 1-O(1/k^2)
was known. Our result pins down the correct asymptotic dependence of the
approximation factor on k. Along the way, we prove that approximating the
Maximum 3-colorable subgraph problem within a factor greater than 32/33 is
NP-hard. Using semidefinite programming, it is known that one can do better
than a random coloring and properly color a fraction 1-1/k +2 ln k/k^2 of edges
in polynomial time. We show that, assuming the 2-to-1 conjecture, it is hard to
properly color (using k colors) more than a fraction 1-1/k + O(ln k/ k^2) of
edges of a k-colorable graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2276</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2276</id><created>2009-10-13</created><authors><author><keyname>Hurwitz</keyname><forenames>Evan</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>State of the Art Review for Applying Computational Intelligence and
  Machine Learning Techniques to Portfolio Optimisation</title><categories>cs.CE cs.AI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational techniques have shown much promise in the field of Finance,
owing to their ability to extract sense out of dauntingly complex systems. This
paper reviews the most promising of these techniques, from traditional
computational intelligence methods to their machine learning siblings, with
particular view to their application in optimising the management of a
portfolio of financial instruments. The current state of the art is assessed,
and prospective further work is assessed and recommended
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2279</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2279</id><created>2009-10-12</created><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Kim</keyname><forenames>Junae</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author></authors><title>Positive Semidefinite Metric Learning with Boosting</title><categories>cs.CV cs.LG</categories><comments>11 pages, Twenty-Third Annual Conference on Neural Information
  Processing Systems (NIPS 2009), Vancouver, Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The learning of appropriate distance metrics is a critical problem in image
classification and retrieval. In this work, we propose a boosting-based
technique, termed \BoostMetric, for learning a Mahalanobis distance metric. One
of the primary difficulties in learning such a metric is to ensure that the
Mahalanobis matrix remains positive semidefinite. Semidefinite programming is
sometimes used to enforce this constraint, but does not scale well.
\BoostMetric is instead based on a key observation that any positive
semidefinite matrix can be decomposed into a linear positive combination of
trace-one rank-one matrices. \BoostMetric thus uses rank-one positive
semidefinite matrices as weak learners within an efficient and scalable
boosting-based learning process. The resulting method is easy to implement,
does not require tuning, and can accommodate various types of constraints.
Experiments on various datasets show that the proposed algorithm compares
favorably to those state-of-the-art methods in terms of classification accuracy
and running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2285</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2285</id><created>2009-10-12</created><authors><author><keyname>Zhang</keyname><forenames>Guoqing</forenames></author><author><keyname>Zhou</keyname><forenames>Shi</forenames></author><author><keyname>Wang</keyname><forenames>Di</forenames></author><author><keyname>Yan</keyname><forenames>Gang</forenames></author><author><keyname>Zhang</keyname><forenames>Guoqiang</forenames></author></authors><title>Enhancing network transmission capacity by efficiently allocating node
  capability</title><categories>cs.NI</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network's transmission capacity is the maximal rate of traffic inflow that
the network can handle without causing congestion. Here we study how to enhance
this quantity by redistributing the capability of individual nodes while
preserving the total sum of node capability. We propose a practical and
effective node-capability allocation scheme which allocates a node's capability
based on the local knowledge of the node's connectivity. We show the scheme
enhances the transmission capacity by two orders of magnitude for networks with
heterogenous structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2304</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2304</id><created>2009-10-13</created><updated>2010-06-22</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cooperative Multi-Cell Block Diagonalization with Per-Base-Station Power
  Constraints</title><categories>cs.IT math.IT</categories><comments>accepted in JSAC, special issue on cooperative communications on
  cellular networks, June 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block diagonalization (BD) is a practical linear precoding technique that
eliminates the inter-user interference in downlink multiuser multiple-input
multiple-output (MIMO) systems. In this paper, we apply BD to the downlink
transmission in a cooperative multi-cell MIMO system, where the signals from
different base stations (BSs) to all the mobile stations (MSs) are jointly
designed with the perfect knowledge of the downlink channels and transmit
messages. Specifically, we study the optimal BD precoder design to maximize the
weighted sum-rate of all the MSs subject to a set of per-BS power constraints.
This design problem is formulated in an auxiliary MIMO broadcast channel (BC)
with a set of transmit power constraints corresponding to those for individual
BSs in the multi-cell system. By applying convex optimization techniques, this
paper develops an efficient algorithm to solve this problem, and derives the
closed-form expression for the optimal BD precoding matrix. It is revealed that
the optimal BD precoding vectors for each MS in the per-BS power constraint
case are in general non-orthogonal, which differs from the conventional
orthogonal BD precoder design for the MIMO-BC under one single sum-power
constraint. Moreover, for the special case of single-antenna BSs and MSs, the
proposed solution reduces to the optimal zero-forcing beamforming (ZF-BF)
precoder design for the weighted sum-rate maximization in the multiple-input
single-output (MISO) BC with per-antenna power constraints. Suboptimal and
low-complexity BD/ZF-BF precoding schemes are also presented, and their
achievable rates are compared against those with the optimal schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2315</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2315</id><created>2009-10-13</created><authors><author><keyname>Inaba</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author></authors><title>The Complexity of Translation Membership for Macro Tree Transducers</title><categories>cs.FL cs.PL</categories><comments>9 pages, appeared at International Workshop on Programming Language
  Techniques for XML (PLAN-X 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Macro tree transducers (mtts) are a useful formal model for XML query and
transformation languages. In this paper one of the fundamental decision
problems on translations, namely the &quot;translation membership problem&quot; is
studied for mtts. For a fixed translation, the translation membership problem
asks whether a given input/output pair is element of the translation. For
call-by-name mtts this problem is shown to be NP-complete. The main result is
that translation membership for call-by-value mtts is in polynomial time. For
several extensions, such as addition of regular look-ahead or the
generalization to multi-return mtts, it is shown that translation membership
still remains in PTIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2317</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2317</id><created>2009-10-13</created><authors><author><keyname>Dress</keyname><forenames>A.</forenames></author><author><keyname>Huber</keyname><forenames>K. T.</forenames></author><author><keyname>Koolen</keyname><forenames>J.</forenames></author><author><keyname>Moulton</keyname><forenames>V.</forenames></author><author><keyname>Spillner</keyname><forenames>A.</forenames></author></authors><title>An algorithm for computing cutpoints in finite metric spaces</title><categories>cs.DS cs.DM</categories><comments>17 pages, 1 eps-figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of the tight span, a cell complex that can be associated to every
metric $D$, offers a unifying view on existing approaches for analyzing
distance data, in particular for decomposing a metric $D$ into a sum of simpler
metrics as well as for representing it by certain specific edge-weighted
graphs, often referred to as realizations of $D$. Many of these approaches
involve the explicit or implicit computation of the so-called cutpoints of (the
tight span of) $D$, such as the algorithm for computing the &quot;building blocks&quot;
of optimal realizations of $D$ recently presented by A. Hertz and S. Varone.
The main result of this paper is an algorithm for computing the set of these
cutpoints for a metric $D$ on a finite set with $n$ elements in $O(n^3)$ time.
As a direct consequence, this improves the run time of the aforementioned
$O(n^6)$-algorithm by Hertz and Varone by ``three orders of magnitude''.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2324</identifier>
 <datestamp>2009-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2324</id><created>2009-10-13</created><updated>2009-11-14</updated><authors><author><keyname>Khoury</keyname><forenames>Raymes</forenames></author><author><keyname>Burgstaller</keyname><forenames>Bernd</forenames></author><author><keyname>Scholz</keyname><forenames>Bernhard</forenames></author></authors><title>Accelerating the Execution of Matrix Languages on the Cell Broadband
  Engine Architecture</title><categories>cs.PL cs.DC</categories><comments>61 pages, 34 figures</comments><acm-class>D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix languages, including MATLAB and Octave, are established standards for
applications in science and engineering. They provide interactive programming
environments that are easy to use due to their scripting languages with matrix
data types. Current implementations of matrix languages do not fully utilise
high-performance, special-purpose chip architectures such as the IBM PowerXCell
processor (Cell), which is currently used in the fastest computer in the world.
  We present a new framework that extends Octave to harness the computational
power of the Cell. With this framework the programmer is relieved of the burden
of introducing explicit notions of parallelism. Instead the programmer uses a
new matrix data-type to execute matrix operations in parallel on the
synergistic processing elements (SPEs) of the Cell. We employ lazy evaluation
semantics for our new matrix data-type to obtain execution traces of matrix
operations. Traces are converted to data dependence graphs; operations in the
data dependence graph are lowered (split into sub-matrices), scheduled and
executed on the SPEs. Thereby we exploit (1) data parallelism, (2) instruction
level parallelism, (3) pipeline parallelism and (4) task parallelism of matrix
language programs. We conducted extensive experiments to show the validity of
our approach. Our Cell-based implementation achieves speedups of up to a factor
of 12 over code run on recent Intel Core2 Quad processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2350</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2350</id><created>2009-10-13</created><updated>2011-01-09</updated><authors><author><keyname>Dong</keyname><forenames>Daoyi</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R</forenames></author></authors><title>Quantum control theory and applications: A survey</title><categories>quant-ph cs.SY math-ph math.MP</categories><comments>38 pages, invited survey paper from a control systems perspective,
  some references are added, published version</comments><journal-ref>IET Control Theory &amp; Applications, vol. 4, no. 12, pp.2651-2671,
  2010</journal-ref><doi>10.1049/iet-cta.2009.0508</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a survey on quantum control theory and applications from
a control systems perspective. Some of the basic concepts and main developments
(including open-loop control and closed-loop control) in quantum control theory
are reviewed. In the area of open-loop quantum control, the paper surveys the
notion of controllability for quantum systems and presents several control
design strategies including optimal control, Lyapunov-based methodologies,
variable structure control and quantum incoherent control. In the area of
closed-loop quantum control, the paper reviews closed-loop learning control and
several important issues related to quantum feedback control including quantum
filtering, feedback stabilization, LQG control and robust quantum control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2370</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2370</id><created>2009-10-13</created><updated>2009-10-26</updated><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>On the hardness of the noncommutative determinant</title><categories>cs.CC cs.DS</categories><comments>11 pages, v2: 18 pages, some typos removed, new section added on
  Clifford algebras, and some reorganization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the computational complexity of computing the
noncommutative determinant. We first consider the arithmetic circuit complexity
of computing the noncommutative determinant polynomial. Then, more generally,
we also examine the complexity of computing the determinant (as a function)
over noncommutative domains. Our hardness results are summarized below:
  1. We show that if the noncommutative determinant polynomial has small
noncommutative arithmetic circuits then so does the noncommutative permanent.
Consequently, the commutative permanent polynomial has small commutative
arithmetic circuits. 2. For any field F we show that computing the n X n
permanent over F is polynomial-time reducible to computing the 2n X 2n
(noncommutative) determinant whose entries are O(n^2) X O(n^2) matrices over
the field F. 3. We also derive as a consequence that computing the n X n
permanent over nonnegative rationals is polynomial-time reducible to computing
the noncommutative determinant over Clifford algebras of n^{O(1)} dimension.
  Our techniques are elementary and use primarily the notion of the Hadamard
Product of noncommutative polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2381</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2381</id><created>2009-10-13</created><updated>2015-04-07</updated><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Fractional differentiation based image processing</title><categories>cs.CV</categories><comments>Keywords: Fractional calculation, image processing, astronomy,
  Misprints revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many resources useful for processing images, most of them freely
available and quite friendly to use. In spite of this abundance of tools, a
study of the processing methods is still worthy of efforts. Here, we want to
discuss the possibilities arising from the use of fractional differential
calculus. This calculus evolved in the research field of pure mathematics until
1920, when applied science started to use it. Only recently, fractional
calculus was involved in image processing methods. As we shall see, the
fractional calculation is able to enhance the quality of images, with
interesting possibilities in edge detection and image restoration. We suggest
also the fractional differentiation as a tool to reveal faint objects in
astronomical images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2393</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2393</id><created>2009-10-13</created><updated>2011-10-19</updated><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author></authors><title>Big Toy Models: Representing Physical Systems As Chu Spaces</title><categories>quant-ph cs.LO math.CT</categories><comments>24 pages. Accepted for Synthese 16th April 2010. Published online
  20th April 2011</comments><journal-ref>Synthese: Volume 186, Issue 3 (2012), Page 697-718</journal-ref><doi>10.1007/s11229-011-9912-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We pursue a model-oriented rather than axiomatic approach to the foundations
of Quantum Mechanics, with the idea that new models can often suggest new
axioms. This approach has often been fruitful in Logic and Theoretical Computer
Science. Rather than seeking to construct a simplified toy model, we aim for a
`big toy model', in which both quantum and classical systems can be faithfully
represented - as well as, possibly, more exotic kinds of systems.
  To this end, we show how Chu spaces can be used to represent physical systems
of various kinds. In particular, we show how quantum systems can be represented
as Chu spaces over the unit interval in such a way that the Chu morphisms
correspond exactly to the physically meaningful symmetries of the systems - the
unitaries and antiunitaries. In this way we obtain a full and faithful functor
from the groupoid of Hilbert spaces and their symmetries to Chu spaces. We also
consider whether it is possible to use a finite value set rather than the unit
interval; we show that three values suffice, while the two standard
possibilistic reductions to two values both fail to preserve fullness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2405</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2405</id><created>2009-10-13</created><authors><author><keyname>Ramanath</keyname><forenames>Maya</forenames></author><author><keyname>Kumar</keyname><forenames>Kondreddi Sarath</forenames></author><author><keyname>Ifrim</keyname><forenames>Georgiana</forenames></author></authors><title>Generating Concise and Readable Summaries of XML Documents</title><categories>cs.IR cs.DB</categories><report-no>MPI-I-2009-5-002</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML has become the de-facto standard for data representation and exchange,
resulting in large scale repositories and warehouses of XML data. In order for
users to understand and explore these large collections, a summarized, bird's
eye view of the available data is a necessity. In this paper, we are interested
in semantic XML document summaries which present the &quot;important&quot; information
available in an XML document to the user. In the best case, such a summary is a
concise replacement for the original document itself. At the other extreme, it
should at least help the user make an informed choice as to the relevance of
the document to his needs. In this paper, we address the two main issues which
arise in producing such meaningful and concise summaries: i) which tags or text
units are important and should be included in the summary, ii) how to generate
summaries of different sizes.%for different memory budgets. We conduct user
studies with different real-life datasets and show that our methods are useful
and effective in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2415</identifier>
 <datestamp>2014-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2415</id><created>2009-10-13</created><updated>2014-12-04</updated><authors><author><keyname>Durand</keyname><forenames>Bruno</forenames><affiliation>LIF</affiliation></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames><affiliation>LIF</affiliation></author><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>LIF</affiliation></author></authors><title>Fixed-point tile sets and their applications</title><categories>cs.CC math.DS math.LO</categories><comments>v7: updated reference to S.G.Simpson's paper</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An aperiodic tile set was first constructed by R. Berger while proving the
undecidability of the domino problem. It turned out that aperiodic tile sets
appear in many topics ranging from logic (the Entscheidungsproblem) to physics
(quasicrystals). We present a new construction of an aperiodic tile set that is
based on Kleene's fixed-point construction instead of geometric arguments. This
construction is similar to J. von Neumann self-reproducing automata; similar
ideas were also used by P. Gacs in the context of error-correcting
computations. This construction it rather flexible, so it can be used in many
ways: we show how it can be used to implement substitution rules, to construct
strongly aperiodic tile sets (any tiling is far from any periodic tiling), to
give a new proof for the undecidability of the domino problem and related
results, characterize effectively closed 1D subshift it terms of 2D shifts of
finite type (improvement of a result by M. Hochman), to construct a tile set
which has only complex tilings, and to construct a &quot;robust&quot; aperiodic tile set
that does not have periodic (or close to periodic) tilings even if we allow
some (sparse enough) tiling errors. For the latter we develop a hierarchical
classification of points in random sets into islands of different ranks.
Finally, we combine and modify our tools to prove our main result: there exists
a tile set such that all tilings have high Kolmogorov complexity even if
(sparse enough) tiling errors are allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2443</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2443</id><created>2009-10-13</created><updated>2010-04-14</updated><authors><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author></authors><title>P versus NP and geometry</title><categories>math.AG cs.CC math.DG</categories><comments>20 pages, to appear in special issue of J. Symbolic. Comp. dedicated
  to MEGA 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I describe three geometric approaches to resolving variants of P v. NP,
present several results that illustrate the role of group actions in complexity
theory, and make a first step towards completely geometric definitions of
complexity classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2472</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2472</id><created>2009-10-13</created><updated>2010-06-19</updated><authors><author><keyname>Lu</keyname><forenames>Yanbin</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>Towards Plugging Privacy Leaks in Domain Name System</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy leaks are an unfortunate and an integral part of the current Internet
domain name resolution. Each DNS query generated by a user reveals -- to one or
more DNS servers -- the origin and target of that query. Over time, a user's
browsing behavior might be exposed to entities with little or no trust. Current
DNS privacy leaks stem from fundamental DNS features and are not easily fixable
by simple patches. Moreover, privacy issues have been overlooked by DNS
security efforts (i.e. DNSSEC) and are thus likely to propagate into future
versions of DNS.
  In order to mitigate privacy issues in current DNS, this paper proposes a
Privacy-Preserving Domain Name System (PPDNS), which maintains privacy during
domain name resolution. PPDNS is based on distributed hash tables (DHTs), an
alternative naming infrastructure, and computational private information
retrieval (cPIR), an advanced cryptographic construct. PPDNS takes advantage of
the DHT's index structure to improve name resolution query privacy, while
leveraging cPIR to reduce communication overhead for bandwidth-sensitive
clients. Our analysis shows that PPDNS is a viable approach for obtaining a
higher degree of privacy for name resolution queries. PPDNS also serves as a
demonstration of blending advanced systems techniques with their cryptographic
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2486</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2486</id><created>2009-10-13</created><authors><author><keyname>Wu</keyname><forenames>Yunnan</forenames></author></authors><title>A Construction of Systematic MDS Codes with Minimum Repair Bandwidth</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory on August 14,
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a distributed storage system based on erasure coding, an important problem
is the \emph{repair problem}: If a node storing a coded piece fails, in order
to maintain the same level of reliability, we need to create a new encoded
piece and store it at a new node. This paper presents a construction of
systematic $(n,k)$-MDS codes for $2k\le n$ that achieves the minimum repair
bandwidth when repairing from $k+1$ nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2502</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2502</id><created>2009-10-13</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Interference Channels with Strong Secrecy</title><categories>cs.IT math.IT</categories><comments>Presented at the Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that given the real sum of two independent uniformly distributed
lattice points from the same nested lattice codebook, the eavesdropper can
obtain at most 1 bit of information per channel regarding the value of one of
the lattice points. In this work, we study the effect of this 1 bit information
on the equivocation expressed in three commonly used information theoretic
measures, i.e., the Shannon entropy, the Renyi entropy and the min entropy. We
then demonstrate its applications in an interference channel with a
confidential message. In our previous work, we showed that nested lattice codes
can outperform Gaussian codes for this channel when the achieved rate is
measured with the weak secrecy notion. Here, with the Renyi entropy and the min
entropy measure, we prove that the same secure degree of freedom is achievable
with the strong secrecy notion as well. A major benefit of the new coding
scheme is that the strong secrecy is generated from a single lattice point
instead of a sequence of lattice points. Hence the mutual information between
the confidential message and the observation of the eavesdropper decreases much
faster with the number of channel uses than previously known strong secrecy
coding methods for nested lattice codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2525</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2525</id><created>2009-10-13</created><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Utility of Beamforming Strategies for Secrecy in Multiuser MIMO Wiretap
  Channels</title><categories>cs.IT math.IT</categories><comments>This paper was presented at Allerton Conference on Communication,
  Control, and Computing, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines linear beamforming methods for secure communications in a
multiuser wiretap channel with a single transmitter, multiple legitimate
receivers, and a single eavesdropper, where all nodes are equipped with
multiple antennas. No information regarding the eavesdropper is presumed at the
transmitter, and we examine both the broadcast MIMO downlink with independent
information, and the multicast MIMO downlink with common information for all
legitimate receivers. In both cases the information signal is transmitted with
just enough power to guarantee a certain SINR at the desired receivers, while
the remainder of the power is used to broadcast artificial noise. The
artificial interference selectively degrades the passive eavesdropper's signal
while remaining orthogonal to the desired receivers. We analyze the
confidentiality provided by zero-forcing and optimal minimum-power beamforming
designs for the broadcast channel, and optimal minimum-MSE beamformers for the
multicast channel. Numerical simulations for the relative SINR and BER
performance of the eavesdropper demonstrate the effectiveness of the proposed
physical-layer security schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2534</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2534</id><created>2009-10-14</created><authors><author><keyname>Chae</keyname><forenames>Sung ho</forenames></author><author><keyname>Choi</keyname><forenames>Sang Won</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Optimal Multiplexing Gain of K-user Line-of-Sight Interference Channels
  with Polarization</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, to appear in Proc. Allerton Conference on
  Communication, Control, and Computing, Monticello, IL, USA, Sept. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the multiplexing gain (MUXG) of the fully connected K-user
line-of-sight (LOS) interference channels (ICs). A polarimetric antenna
composed of 3 orthogonal electric dipoles and 3 orthogonal magnetic dipoles is
considered where all 6 dipoles are co-located. In case of K-user IC with single
polarization, the maximum achievable MUXG is K regardless of the number of
transmit and receive antennas because of the key-hole effect. With
polarization, a trivial upper bound on the MUXG is 2K. We propose a zero
forcing (ZF) scheme for the K-user LOS IC, where each user uses one or more
polarimetric antennas. By using the proposed ZF scheme, we find minimal antenna
configurations that achieve this bound for K &lt;= 5. For K &gt; 5, we show that the
optimal MUXG of 2K is achieved with M = (K+1)/6 polarimetric antennas at each
user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2540</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2540</id><created>2009-10-14</created><authors><author><keyname>Banday</keyname><forenames>M. Tariq</forenames></author><author><keyname>Jan</keyname><forenames>Tariq R.</forenames></author></authors><title>Effectiveness and Limitations of Statistical Spam Filters</title><categories>cs.LG</categories><comments>International Conference on New Trends in Statistics and
  Optimization, Organized by Department of Statistics, University of Kashmir,
  Srinagar, India, from 20th to 23rd October, 2008</comments><acm-class>K.6.5</acm-class><journal-ref>International Conference on New Trends in Statistics and
  Optimization, Organized by Department of Statistics, University of Kashmir,
  Srinagar, India, from 20th to 23rd October, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the techniques involved in the design of the famous
statistical spam filters that include Naive Bayes, Term Frequency-Inverse
Document Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes
Additive Regression Tree. We compare these techniques with each other in terms
of accuracy, recall, precision, etc. Further, we discuss the effectiveness and
limitations of statistical filters in filtering out various types of spam from
legitimate e-mails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2582</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2582</id><created>2009-10-14</created><authors><author><keyname>Rahn</keyname><forenames>Mirko</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author><author><keyname>Singler</keyname><forenames>Johannes</forenames></author></authors><title>Scalable Distributed-Memory External Sorting</title><categories>cs.DS cs.DC cs.PF</categories><acm-class>F.2.2; E.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We engineer algorithms for sorting huge data sets on massively parallel
machines. The algorithms are based on the multiway merging paradigm. We first
outline an algorithm whose I/O requirement is close to a lower bound. Thus, in
contrast to naive implementations of multiway merging and all other approaches
known to us, the algorithm works with just two passes over the data even for
the largest conceivable inputs. A second algorithm reduces communication
overhead and uses more conventional specifications of the result at the cost of
slightly increased I/O requirements. An implementation wins the well known
sorting benchmark in several categories and by a large margin over its
competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2586</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2586</id><created>2009-10-14</created><updated>2010-01-15</updated><authors><author><keyname>Whitacre</keyname><forenames>James</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author></authors><title>Degeneracy: a link between evolvability, robustness and complexity in
  biological systems</title><categories>nlin.AO cs.NE</categories><comments>accepted in BMC Journal of Theoretical Biology and Medical Modelling</comments><doi>10.1186/1742-4682-7-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A full accounting of biological robustness remains elusive; both in terms of
the mechanisms by which robustness is achieved and the forces that have caused
robustness to grow over evolutionary time. Although its importance to topics
such as ecosystem services and resilience is well recognized, the broader
relationship between robustness and evolution is only starting to be fully
appreciated. A renewed interest in this relationship has been prompted by
evidence that mutational robustness can play a positive role in the discovery
of future adaptive innovations (evolvability) and evidence of an intimate
relationship between robustness and complexity in biology.
  This paper offers a new perspective on the mechanics of evolution and the
origins of complexity, robustness, and evolvability. Here we explore the
hypothesis that degeneracy, a partial overlap in the functioning of
multi-functional components, plays a central role in the evolution and
robustness of complex forms. In support of this hypothesis, we present evidence
that degeneracy is a fundamental source of robustness, it is intimately tied to
multi-scaled complexity, and it establishes conditions that are necessary for
system evolvability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2593</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2593</id><created>2009-10-14</created><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author></authors><title>A Component Based Heuristic Search Method with Evolutionary Eliminations</title><categories>cs.AI cs.NE</categories><comments>27 pages, 4 figures</comments><journal-ref>INFORMS Journal of Computing, 21 (3), 468-479, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nurse rostering is a complex scheduling problem that affects hospital
personnel on a daily basis all over the world. This paper presents a new
component-based approach with evolutionary eliminations, for a nurse scheduling
problem arising at a major UK hospital. The main idea behind this technique is
to decompose a schedule into its components (i.e. the allocated shift pattern
of each nurse), and then to implement two evolutionary elimination strategies
mimicking natural selection and natural mutation process on these components
respectively to iteratively deliver better schedules. The worthiness of all
components in the schedule has to be continuously demonstrated in order for
them to remain there. This demonstration employs an evaluation function which
evaluates how well each component contributes towards the final objective. Two
elimination steps are then applied: the first elimination eliminates a number
of components that are deemed not worthy to stay in the current schedule; the
second elimination may also throw out, with a low level of probability, some
worthy components. The eliminated components are replenished with new ones
using a set of constructive heuristics using local optimality criteria.
Computational results using 52 data instances demonstrate the applicability of
the proposed approach in solving real-world problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2603</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2603</id><created>2009-10-14</created><updated>2010-01-17</updated><authors><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Liew</keyname><forenames>Soung-Chang</forenames></author></authors><title>Physical layer network coding with multiple antennas</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-phase MIMO NC (network coding) scheme can be used to boost the
throughput in a two-way relay channel in which nodes are equipped with multiple
antennas. The obvious strategy is for the relay node to extract the individual
packets from the two end nodes and mix the two packets to form a network-coded
packet. In this paper, we propose a new scheme called MIMO PNC (physical
network coding), in which the relay extracts the summation and difference of
the two end packets and then converts them to the network-coded form. MIMO PNC
is a natural combination of the single-antenna PNC scheme and the linear MIMO
detection scheme. The advantages of MIMO PNC are many. First, it removes the
stringent carrier-phase requirement in single-antenna PNC. Second, it is linear
in complexity with respect to the constellation size and the number of
simultaneous data streams in MIMO. Simulation shows that MIMO PNC outperforms
the straightforward MIMO NC significantly under random Rayleigh fading channel.
Based on our analysis, we further conjecture that MIMO PNC outperforms MIMO NC
under all possible realizations of the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2604</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2604</id><created>2009-10-14</created><authors><author><keyname>Shengli</keyname><forenames>Zhang</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Applying physical layer network coding in wireless networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A main distinguishing feature of a wireless network compared with a wired
network is its broadcast nature, in which the signal transmitted by a node may
reach several other nodes, and a node may receive signals from several other
nodes, simultaneously. Rather than a blessing, this feature is treated more as
an interference-inducing nuisance in most wireless networks today (e.g., IEEE
802.11). This paper shows that the concept of network coding can be applied at
the physical layer to turn the broadcast property into a capacity-boosting
advantage in wireless ad hoc networks. Specifically, we propose a
physical-layer network coding (PNC) scheme to coordinate transmissions among
nodes. In contrast to &quot;straightforward&quot; network coding which performs coding
arithmetic on digital bit streams after they have been received, PNC makes use
of the additive nature of simultaneously arriving electromagnetic (EM) waves
for equivalent coding operation. And in doing so, PNC can potentially achieve
100% and 50% throughput increases compared with traditional transmission and
straightforward network coding, respectively, in 1-D regular linear networks
with multiple random flows. The throughput improvements are even larger in 2-D
regular networks: 200% and 100%, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2626</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2626</id><created>2009-10-14</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author></authors><title>On challenges and opportunities of designing integrated IT platforms for
  supporting knowledge works in organizations</title><categories>cs.DL</categories><comments>39 pages, Sibmitted to journal Vikalpa</comments><acm-class>D.2.10; H.3; H.1.2</acm-class><journal-ref>Vikalpa: The Journal for Decision Makers, Volume 36, No 3, pp 35 -
  60, Jul - Sep 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing and implementing comprehensive IT-based support environments for KM
in organizations is fraught with many problems. Solving them requires intimate
knowledge about the information usage in knowledge works and the scopes of
technology intervention. In this paper, the Task-oriented Organizational
Knowledge Management or TOKM, a design theory for building integrated IT
platforms for supporting organizational KM, is proposed. TOKM brings together
two apparently mutually exclusive practices of building KM systems, the
task-based approach and the generic or universalistic approach. In developing
the design, the information requirements of knowledge workers in light of an
information usage model of knowledge works is studied. Then the model is
extended to study possibilities of more advanced IT support and formulate them
in form of a set of meta-requirements. Following the IS design theory paradigm,
a set of artifacts are hypothesized to meet the requirements. Finally, a design
method, as a possible approach of building an IT-based integrated platform, the
Knowledge Work Support Platform (KWSP) to realize the artifacts in order to
meet the requirements, is outlined. The KWSP is a powerful platform for
building and maintaining a number of task-type specific Knowledge Work Support
Systems (KWSS) on a common sharable platform. Each KWSS, for the task-type
supported by it, can be easily designed to provide extensive and sophisticated
support to individual as well as group of knowledge workers in performing their
respective knowledge work instances
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2632</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2632</id><created>2009-10-14</created><authors><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Saclay - Ile de France, IDSL</affiliation></author></authors><title>Communication scientifique : Pour le meilleur et pour le PEER</title><categories>cs.DL</categories><proxy>ccsd inria-00424254</proxy><journal-ref>Hermes (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an overview (in French) of the European PEER project,
focusing on its origins, the actual objectives and the technical deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2638</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2638</id><created>2009-10-14</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author></authors><title>On building Information Warehouses</title><categories>cs.DL</categories><comments>11 pages 1st IIMA International Conference on Advanced Data Analysis,
  Business Analytics and Intelligence (ICADABAI 2009), 6-7 June, Indian
  Institute of Management, Ahmedabad, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important goals of information management (IM) is supporting
the knowledge workers in performing their works. In this paper we examine
issues of relevance, linkage and provenance of information, as accessed and
used by the knowledge workers. These are usually not adequately addressed in
most of the IT based solutions for IM. Here we propose a non-conventional
approach for building information systems for supporting the knowledge workers
which addresses these issues. The approach leads to the ideas of building
Information Warehouses (IW) and Knowledge work Support Systems (KwSS). Such
systems can open up potential for building innovative applications of
significant impact, including those capable of helping organizations in
implementing processes for double-loop learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2649</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2649</id><created>2009-10-14</created><authors><author><keyname>Karande</keyname><forenames>Chinmay</forenames></author></authors><title>Polynomially Correlated Knapsack is NP-complete</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  0-1 Knapsack is a fundamental NP-complete problem. In this article we prove
that it remains NP-complete even when the weights of the objects in the packing
constraints and their values in the objective function satisfy specific
stringent conditions: the values are integral powers of the weights of the
objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2654</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2654</id><created>2009-10-14</created><authors><author><keyname>Chae</keyname><forenames>Wonseok</forenames></author></authors><title>Type Safe Extensible Programming</title><categories>cs.PL</categories><comments>PhD Thesis submitted October, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software products evolve over time. Sometimes they evolve by adding new
features, and sometimes by either fixing bugs or replacing outdated
implementations with new ones. When software engineers fail to anticipate such
evolution during development, they will eventually be forced to re-architect or
re-build from scratch. Therefore, it has been common practice to prepare for
changes so that software products are extensible over their lifetimes. However,
making software extensible is challenging because it is difficult to anticipate
successive changes and to provide adequate abstraction mechanisms over
potential changes. Such extensibility mechanisms, furthermore, should not
compromise any existing functionality during extension. Software engineers
would benefit from a tool that provides a way to add extensions in a reliable
way. It is natural to expect programming languages to serve this role.
Extensible programming is one effort to address these issues.
  In this thesis, we present type safe extensible programming using the MLPolyR
language. MLPolyR is an ML-like functional language whose type system provides
type-safe extensibility mechanisms at several levels. After presenting the
language, we will show how these extensibility mechanisms can be put to good
use in the context of product line engineering. Product line engineering is an
emerging software engineering paradigm that aims to manage variations, which
originate from successive changes in software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2655</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2655</id><created>2009-10-14</created><updated>2009-10-14</updated><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Karande</keyname><forenames>Chinmay</forenames></author><author><keyname>Sangwan</keyname><forenames>Ashish</forenames></author></authors><title>The Effect of Malice on the Social Optimum in Linear Load Balancing
  Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we consider the following problem to study the effect of
malicious players on the social optimum in load balancing games: Consider two
players SOC and MAL controlling (1-f) and f fraction of the flow in a load
balancing game. SOC tries to minimize the total cost faced by her players while
MAL tries to maximize the same.
  If the latencies are linear, we show that this 2-player zero-sum game has a
pure strategy Nash equilibrium. Moreover, we show that one of the optimal
strategies for MAL is to play selfishly: let the f fraction of the flow be sent
as when the flow was controlled by infinitesimal players playing selfishly and
reaching a Nash equilibrium. This shows that a malicious player cannot cause
more harm in this game than a set of selfish agents.
  We also introduce the notion of Cost of Malice - the ratio of the cost faced
by SOC at equilibrium to (1-f)OPT, where OPT is the social optimum minimizing
the cost of all the players. In linear load balancing games we bound the cost
of malice by (1+f/2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2718</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2718</id><created>2009-10-14</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Two-hop Secure Communication Using an Untrusted Relay</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in EURASIP Journal on Communications and
  Networks, Special Issue on Wireless Physical Layer Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a source-destination pair that can only communicate through an
untrusted intermediate relay node. The intermediate node is willing to employ a
designated relaying scheme to facilitate reliable communication between the
source and the destination. Yet, the information it relays needs to be kept
secret from it. In this two-hop communication scenario, where the use of the
untrusted relay node is essential, we find that a positive secrecy rate is
achievable. The center piece of the achievability scheme is the help provided
by either the destination node with transmission capability, or an external
&quot;good samaritan&quot; node. In either case, the helper performs cooperative jamming
that confuses the eavesdropping relay and disables it from being able to
decipher what it is relaying. We next derive an upper bound on the secrecy rate
for this system. We observe that the gap between the upper bound and the
achievable rate vanishes as the power of the relay node goes to infinity.
Overall, the paper presents a case for intentional interference, i.e.,
cooperative jamming, as an enabler for secure communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2743</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2743</id><created>2009-10-14</created><authors><author><keyname>Khan</keyname><forenames>Usman A.</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>DILAND: An Algorithm for Distributed Sensor Localization with Noisy
  Distance Measurements</title><categories>cs.DC cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Signal Processing. Initial
  submission on May 2009. 12 pages</comments><doi>10.1109/TSP.2009.2038423</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, we present an algorithm for distributed sensor
localization with noisy distance measurements (DILAND) that extends and makes
the DLRE more robust. DLRE is a distributed sensor localization algorithm in
$\mathbb{R}^m$ $(m\geq1)$ introduced in \cite{usman_loctsp:08}. DILAND operates
when (i) the communication among the sensors is noisy; (ii) the communication
links in the network may fail with a non-zero probability; and (iii) the
measurements performed to compute distances among the sensors are corrupted
with noise. The sensors (which do not know their locations) lie in the convex
hull of at least $m+1$ anchors (nodes that know their own locations.) Under
minimal assumptions on the connectivity and triangulation of each sensor in the
network, this correspondence shows that, under the broad random phenomena
described above, DILAND converges almost surely (a.s.) to the exact sensor
locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2771</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2771</id><created>2009-10-15</created><updated>2010-06-28</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Cooperative Interference Management with MISO Beamforming</title><categories>cs.IT math.IT</categories><comments>accepted in IEEE Transactions on Signal Processing, June 2010</comments><doi>10.1109/TSP.2010.2056685</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This correspondence studies the downlink transmission in a multi-cell system,
where multiple base stations (BSs) each with multiple antennas cooperatively
design their respective transmit beamforming vectors to optimize the overall
system performance. For simplicity, it is assumed that all mobile stations
(MSs) are equipped with a single antenna each, and there is one active MS in
each cell at one time. Accordingly, the system of interests can be modeled by a
multiple-input single-output (MISO) interference channel (IC), termed as
MISO-IC, with interference treated as noise. We propose a new method to
characterize different rate-tuples for active MSs on the Pareto boundary of the
achievable rate region for the MISO-IC, by exploring the relationship between
the MISO-IC and the cognitive radio (CR) MISO channel. We show that each
Pareto-boundary rate-tuple of the MISO-IC can be achieved in a decentralized
manner when each of the BSs attains its own channel capacity subject to a
certain set of interference-power constraints (also known as
interference-temperature constraints in the CR system) at the other MS
receivers. Furthermore, we show that this result leads to a new decentralized
algorithm for implementing the multi-cell cooperative downlink beamforming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2818</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2818</id><created>2009-10-15</created><authors><author><keyname>Venkatachalam</keyname><forenames>R.</forenames></author><author><keyname>Krishnan</keyname><forenames>A.</forenames></author></authors><title>Multiple Cross-Layer Design Based Complete Architecture for Mobile Adhoc
  Networks</title><categories>cs.NI</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 182-187, September 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different cross layer design for mobile adhoc network focuses on different
optimization purpose, different Quality of Service (QoS) metric and the
functions like delay, priority handling, security, etc. Existing cross layer
designs provide individual solution for congestion control, fault tolerance,
power conservation, energy minimization and flow control and the major drawback
is of high cost and overhead. In this paper, we propose to design multiple
cross layer design based architecture to provide a combined solution for link
failure management, power conservation, congestion control and admission
control. By simulation results, we show that the average end to end delay,
average energy consumption and the packet loss are considerably reduced with
the increase in high throughput and good delivery ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2829</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2829</id><created>2009-10-15</created><updated>2011-01-08</updated><authors><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author><author><keyname>Cherubini</keyname><forenames>Alessandra</forenames></author><author><keyname>Reghizzi</keyname><forenames>Stefano Crespi</forenames></author></authors><title>A unifying approach to picture grammars</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several old and recent classes of picture grammars, that variously extend
context-free string grammars in two dimensions, are based on rules that rewrite
arrays of pixels. Such grammars can be unified and extended using a tiling
based approach, whereby the right part of a rule is formalized by means of a
finite set of permitted tiles. We focus on a simple type of tiling,named
regional, and define the corresponding regional tile grammars. They include
both Siromoney's (or Matz's) Kolam grammars and their generalization by Prusa,
as well as Drewes's grid grammars. Regionally defined pictures can be
recognized with polynomial-time complexity by an algorithm extending the CKY
one for strings. Regional tile grammars and languages are strictly included
into our previous tile grammars and languages, and are incomparable with
Giammarresi-Restivo tiling systems (or Wang systems).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2832</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2832</id><created>2009-10-15</created><authors><author><keyname>Dauwels</keyname><forenames>Justin</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew</forenames></author><author><keyname>Korl</keyname><forenames>Sascha</forenames></author><author><keyname>Loeliger</keyname><forenames>Hans-Andrea</forenames></author></authors><title>Expectation Maximization as Message Passing - Part I: Principles and
  Gaussian Messages</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown how expectation maximization (EM) may be viewed as a message
passing algorithm in factor graphs. In particular, a general EM message
computation rule is identified. As a factor graph tool, EM may be used to break
cycles in a factor graph, and tractable messages may in some cases be obtained
where the sum-product messages are unwieldy.
  As an exemplary application, the paper considers linear Gaussian state space
models. Unknown coefficients in such models give rise to multipliers in the
corresponding factor graph. A main attraction of EM in such cases is that it
results in purely Gaussian message passing algorithms. These Gaussian EM
messages are tabulated for several (scalar, vector, matrix) multipliers that
frequently appear in applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2849</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2849</id><created>2009-10-15</created><authors><author><keyname>Mitrovi&#x107;</keyname><forenames>Marija</forenames></author><author><keyname>Tadi&#x107;</keyname><forenames>Bosiljka</forenames></author></authors><title>Bloggers Behavior and Emergent Communities in Blog Space</title><categories>cs.CY physics.soc-ph</categories><doi>10.1140/epjb/e2009-00431-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions between users in cyberspace may lead to phenomena different from
those observed in common social networks. Here we analyse large data sets about
users and Blogs which they write and comment, mapped onto a bipartite graph. In
such enlarged Blog space we trace user activity over time, which results in
robust temporal patterns of user--Blog behavior and the emergence of
communities. With the spectral methods applied to the projection on weighted
user network we detect clusters of users related to their common interests and
habits. Our results suggest that different mechanisms may play the role in the
case of very popular Blogs. Our analysis makes a suitable basis for theoretical
modeling of the evolution of cyber communities and for practical study of the
data, in particular for an efficient search of interesting Blog clusters and
further retrieval of their contents by text analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2853</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2853</id><created>2009-10-15</created><updated>2009-10-30</updated><authors><author><keyname>Hirokawa</keyname><forenames>Nao</forenames></author><author><keyname>Middeldorp</keyname><forenames>Aart</forenames></author></authors><title>Decreasing Diagrams and Relative Termination</title><categories>cs.LO cs.SC</categories><comments>v3: missing references added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we use the decreasing diagrams technique to show that a
left-linear term rewrite system R is confluent if all its critical pairs are
joinable and the critical pair steps are relatively terminating with respect to
R. We further show how to encode the rule-labeling heuristic for decreasing
diagrams as a satisfiability problem. Experimental data for both methods are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2859</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2859</id><created>2009-10-15</created><updated>2009-10-26</updated><authors><author><keyname>Syropoulos</keyname><forenames>Apostolos</forenames></author></authors><title>Can we debug the Universe?</title><categories>cs.OH</categories><comments>An early version of this paper was read in the &quot;Future Trends in
  Hypercomputation&quot; Workshop held in Sheffield U.K., 11-13 September 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Roughly, the Church-Turing thesis is a hypothesis that describes exactly what
can be computed by any real or feasible conceptual computing device. Generally
speaking, the computational metaphor is the idea that everything, including the
universe itself, has a computational nature. However, if the Church-Turing
thesis is not valid, then does it make sense to expect the construction of a
computer program capable of simulating the whole Universe? In the lights of
hypercomputation, the scientific discipline that is about computing beyond the
Church-Turing barrier, the most natural answer to this question is: No. This
note is a justification of this answer and its deeper meaning based on
arguments from physics, the philosophy of the mind, and, of course,
(hyper)computability theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2874</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2874</id><created>2009-10-15</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author></authors><title>An Agent Based Classification Model</title><categories>cs.AI cs.MA</categories><comments>4 pages, 2 figures, 9th European Agent Systems Summer School, Durham,
  UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The major function of this model is to access the UCI Wisconsin Breast Can-
cer data-set[1] and classify the data items into two categories, which are
normal and anomalous. This kind of classifi cation can be referred as anomaly
detection, which discriminates anomalous behaviour from normal behaviour in
computer systems. One popular solution for anomaly detection is Artifi cial
Immune Sys- tems (AIS). AIS are adaptive systems inspired by theoretical
immunology and observed immune functions, principles and models which are
applied to prob- lem solving. The Dendritic Cell Algorithm (DCA)[2] is an AIS
algorithm that is developed specifi cally for anomaly detection. It has been
successfully applied to intrusion detection in computer security. It is
believed that agent-based mod- elling is an ideal approach for implementing
AIS, as intelligent agents could be the perfect representations of immune
entities in AIS. This model evaluates the feasibility of re-implementing the
DCA in an agent-based simulation environ- ment called AnyLogic, where the
immune entities in the DCA are represented by intelligent agents. If this model
can be successfully implemented, it makes it possible to implement more
complicated and adaptive AIS models in the agent-based simulation environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2891</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2891</id><created>2009-10-15</created><authors><author><keyname>Jurdzinski</keyname><forenames>Marcin</forenames></author><author><keyname>Trivedi</keyname><forenames>Ashutosh</forenames></author></authors><title>Average-Time Games on Timed Automata</title><categories>cs.GT cs.LO</categories><journal-ref>M. Jurdzinski and A. Trivedi. Average-Time Games, In
  Proc.FSTTCS'08, volume 08004 of Dagstuhl Seminar Proceedings, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An average-time game is played on the infinite graph of configurations of a
finite timed automaton. The two players, Min and Max, construct an infinite run
of the automaton by taking turns to perform a timed transition. Player Min
wants to minimise the average time per transition and player Max wants to
maximise it. A solution of average-time games is presented using a reduction to
average-price game on a finite graph. A direct consequence is an elementary
proof of determinacy for average-time games. This complements our results for
reachability-time games and partially solves a problem posed by Bouyer et al.,
to design an algorithm for solving average-price games on priced timed
automata. The paper also establishes the exact computational complexity of
solving average-time games: the problem is EXPTIME-complete for timed automata
with at least two clocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2917</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2917</id><created>2009-10-15</created><authors><author><keyname>Jodoin</keyname><forenames>P. M.</forenames></author><author><keyname>Saligrama</keyname><forenames>V.</forenames></author><author><keyname>Konrad</keyname><forenames>J.</forenames></author></authors><title>Behavior Subtraction</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background subtraction has been a driving engine for many computer vision and
video analytics tasks. Although its many variants exist, they all share the
underlying assumption that photometric scene properties are either static or
exhibit temporal stationarity. While this works in some applications, the model
fails when one is interested in discovering {\it changes in scene dynamics}
rather than those in a static background; detection of unusual pedestrian and
motor traffic patterns is but one example. We propose a new model and
computational framework that address this failure by considering stationary
scene dynamics as a ``background'' with which observed scene dynamics are
compared. Central to our approach is the concept of an {\it event}, that we
define as short-term scene dynamics captured over a time window at a specific
spatial location in the camera field of view. We compute events by
time-aggregating motion labels, obtained by background subtraction, as well as
object descriptors (e.g., object size). Subsequently, we characterize events
probabilistically, but use a low-memory, low-complexity surrogates in practical
implementation. Using these surrogates amounts to {\it behavior subtraction}, a
new algorithm with some surprising properties. As demonstrated here, behavior
subtraction is an effective tool in anomaly detection and localization. It is
resilient to spurious background motion, such as one due to camera jitter, and
is content-blind, i.e., it works equally well on humans, cars, animals, and
other objects in both uncluttered and highly-cluttered scenes. Clearly,
treating video as a collection of events rather than colored pixels opens new
possibilities for video analytics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2931</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2931</id><created>2009-10-15</created><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author></authors><title>Abstract Scalars, Loops, and Free Traced and Strongly Compact Closed
  Categories</title><categories>quant-ph cs.LO math.CT</categories><comments>32 pages</comments><journal-ref>In Proceedings of CALCO 2005, Springer Lecture Notes in Computer
  Science Vol. 3629, 1--31, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study structures which have arisen in recent work by the present author
and Bob Coecke on a categorical axiomatics for Quantum Mechanics; in
particular, the notion of strongly compact closed category. We explain how
these structures support a notion of scalar which allows quantitative aspects
of physical theory to be expressed, and how the notion of strong compact
closure emerges as a significant refinement of the more classical notion of
compact closed category.
  We then proceed to an extended discussion of free constructions for a
sequence of progressively more complex kinds of structured category,
culminating in the strongly compact closed case. The simple geometric and
combinatorial ideas underlying these constructions are emphasized. We also
discuss variations where a prescribed monoid of scalars can be &quot;glued in&quot; to
the free construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2942</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2942</id><created>2009-10-15</created><authors><author><keyname>Pop</keyname><forenames>Florin</forenames></author><author><keyname>Dobre</keyname><forenames>Ciprian Mihai</forenames></author><author><keyname>Costan</keyname><forenames>Alexandru</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author><author><keyname>Stratan</keyname><forenames>Corina</forenames></author><author><keyname>Cristea</keyname><forenames>Valentin</forenames></author></authors><title>Critical Analysis of Middleware Architectures for Large Scale
  Distributed Systems</title><categories>cs.DC cs.NI</categories><acm-class>C.2.4; D.4</acm-class><journal-ref>Proc. of the 17th Intl. Conf. on Control Systems and Computer
  Science (CSCS), vol. 1, pp. 29-36, Bucharest, Romania, 26-29 May, 2009.
  (ISSN: 2066-4451)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed computing is increasingly being viewed as the next phase of Large
Scale Distributed Systems (LSDSs). However, the vision of large scale resource
sharing is not yet a reality in many areas - Grid computing is an evolving area
of computing, where standards and technology are still being developed to
enable this new paradigm. Hence, in this paper we analyze the current
development of middleware tools for LSDS, from multiple perspectives:
architecture, applications and market research. For each perspective we are
interested in relevant technologies used in undergoing projects, existing
products or services and useful design issues. In the end, based on this
approach, we draw some conclusions regarding the future research directions in
this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2961</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2961</id><created>2009-10-15</created><authors><author><keyname>Zhu</keyname><forenames>Yan</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Isotropic MIMO Interference Channels without CSIT: The Loss of Degrees
  of Freedom</title><categories>cs.IT math.IT</categories><comments>appears in Allerton 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies two-user MIMO interference channel with isotropic fading.
We assume that users are equipped with arbitrary number of antennas and the
channel state information (CSI) is available at receivers only. An outer bound
is obtained for the degree of freedom region, which suggests the loss of
degrees of freedom due to the lack of CSI at transmitters under many
circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.2973</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.2973</id><created>2009-10-15</created><authors><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Zhi</keyname><forenames>Lihong</forenames><affiliation>KLMM</affiliation></author></authors><title>Computing rational points in convex semi-algebraic sets and SOS
  decompositions</title><categories>cs.SC cs.DS math.OC</categories><proxy>ccsd inria-00419983</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let ${\cal P}=\{h_1, ..., h_s\}\subset \Z[Y_1, ..., Y_k]$, $D\geq \deg(h_i)$
for $1\leq i \leq s$, $\sigma$ bounding the bit length of the coefficients of
the $h_i$'s, and $\Phi$ be a quantifier-free ${\cal P}$-formula defining a
convex semi-algebraic set. We design an algorithm returning a rational point in
${\cal S}$ if and only if ${\cal S}\cap \Q\neq\emptyset$. It requires
$\sigma^{\bigO(1)}D^{\bigO(k^3)}$ bit operations. If a rational point is
outputted its coordinates have bit length dominated by $\sigma D^{\bigO(k^3)}$.
Using this result, we obtain a procedure deciding if a polynomial $f\in \Z[X_1,
&gt;..., X_n]$ is a sum of squares of polynomials in $\Q[X_1, ..., X_n]$. Denote
by $d$ the degree of $f$, $\tau$ the maximum bit length of the coefficients in
$f$, $D={{n+d}\choose{n}}$ and $k\leq D(D+1)-{{n+2d}\choose{n}}$. This
procedure requires $\tau^{\bigO(1)}D^{\bigO(k^3)}$ bit operations and the
coefficients of the outputted polynomials have bit length dominated by $\tau
D^{\bigO(k^3)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3028</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3028</id><created>2009-10-15</created><updated>2010-03-19</updated><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>State of the cognitive interference channel: a new unified inner bound</title><categories>cs.IT math.IT</categories><comments>Presented at the 2010 International Zurich Seminar on Communications
  - an 2nd updated version.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of the interference channel in which one transmitter
non-causally knows the message of the other, termed the cognitive interference
channel, has remained open since its inception in 2005. A number of subtly
differing achievable rate regions and outer bounds have been derived, some of
which are tight under specific conditions. In this work we present a new
unified inner bound for the discrete memoryless cognitive interference channel.
We show explicitly how it encompasses all known discrete memoryless achievable
rate regions as special cases. The presented achievable region was recently
used in deriving the capacity region of the general deterministic cognitive
interference channel, and thus also the linear high-SNR deterministic
approximation of the Gaussian cognitive interference channel. The high-SNR
deterministic approximation was then used to obtain the capacity of the
Gaussian cognitive interference channel to within 1.87 bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3033</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3033</id><created>2009-10-16</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Degraded Compound Multi-receiver Wiretap Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, October 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the degraded compound multi-receiver wiretap channel.
The degraded compound multi-receiver wiretap channel consists of two groups of
users and a group of eavesdroppers, where, if we pick an arbitrary user from
each group of users and an arbitrary eavesdropper, they satisfy a certain
Markov chain. We study two different communication scenarios for this channel.
In the first scenario, the transmitter wants to send a confidential message to
users in the first (stronger) group and a different confidential message to
users in the second (weaker) group, where both messages need to be kept
confidential from the eavesdroppers. For this scenario, we assume that there is
only one eavesdropper. We obtain the secrecy capacity region for the general
discrete memoryless channel model, the parallel channel model, and the Gaussian
parallel channel model. For the Gaussian multiple-input multiple-output (MIMO)
channel model, we obtain the secrecy capacity region when there is only one
user in the second group. In the second scenario we study, the transmitter
sends a confidential message to users in the first group which needs to be kept
confidential from the second group of users and the eavesdroppers. Furthermore,
the transmitter sends a different confidential message to users in the second
group which needs to be kept confidential only from the eavesdroppers. For this
scenario, we do not put any restriction on the number of eavesdroppers. As in
the first scenario, we obtain the secrecy capacity region for the general
discrete memoryless channel model, the parallel channel model, and the Gaussian
parallel channel model. For the Gaussian MIMO channel model, we establish the
secrecy capacity region when there is only one user in the second group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3068</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3068</id><created>2009-10-16</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author></authors><title>An Evolutionary Squeaky Wheel Optimisation Approach to Personnel
  Scheduling</title><categories>cs.AI cs.CE cs.NE</categories><comments>21 pages, 5 tables, 1 figure, IEEE Transactions on Evolutionary
  Computation</comments><journal-ref>IEEE Transactions on Evolutionary Computation, 13 (2), 433-443,
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quest for robust heuristics that are able to solve more than one problem
is ongoing. In this paper, we present, discuss and analyse a technique called
Evolutionary Squeaky Wheel Optimisation and apply it to two different personnel
scheduling problems. Evolutionary Squeaky Wheel Optimisation improves the
original Squeaky Wheel Optimisation's effectiveness and execution speed by
incorporating two extra steps (Selection and Mutation) for added evolution. In
the Evolutionary Squeaky Wheel Optimisation, a cycle of
Analysis-Selection-Mutation-Prioritization-Construction continues until
stopping conditions are reached. The aim of the Analysis step is to identify
below average solution components by calculating a fitness value for all
components. The Selection step then chooses amongst these underperformers and
discards some probabilistically based on fitness. The Mutation step further
discards a few components at random. Solutions can become incomplete and thus
repairs may be required. The repairs are carried out by using the
Prioritization to first produce priorities that determine an order by which the
following Construction step then schedules the remaining components. Therefore,
improvement in the Evolutionary Squeaky Wheel Optimisation is achieved by
selective solution disruption mixed with interative improvement and
constructive repair. Strong experimental results are reported on two different
domains of personnel scheduling: bus and rail driver scheduling and hospital
nurse scheduling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3084</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3084</id><created>2009-10-16</created><authors><author><keyname>Borges</keyname><forenames>J.</forenames></author><author><keyname>Dougherty</keyname><forenames>S. T.</forenames></author><author><keyname>Fernandez-Cordoba</keyname><forenames>C.</forenames></author></authors><title>Self-Dual Codes over Z_2xZ_4</title><categories>cs.IT math.IT</categories><comments>Submitted to Designs, Codes and Cryptography</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-dual codes over $\Z_2\times\Z_4$ are subgroups of $\Z_2^\alpha
\times\Z_4^\beta$ that are equal to their orthogonal under an inner-product
that relates to the binary Hamming scheme. Three types of self-dual codes are
defined. For each type, the possible values $\alpha,\beta$ such that there
exist a code $\C\subseteq \Z_2^\alpha \times\Z_4^\beta$ are established.
Moreover, the construction of a $\add$-linear code for each type and possible
pair $(\alpha,\beta)$ is given. Finally, the standard techniques of invariant
theory are applied to describe the weight enumerators for each type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3085</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3085</id><created>2009-10-16</created><updated>2010-02-16</updated><authors><author><keyname>Blumensath</keyname><forenames>Achim</forenames></author></authors><title>Guarded Second-Order Logic, Spanning Trees, and Network Flows</title><categories>cs.LO cs.DM</categories><acm-class>G.2.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (February
  16, 2010) lmcs:1207</journal-ref><doi>10.2168/LMCS-6(1:4)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to a theorem of Courcelle monadic second-order logic and guarded
second-order logic (where one can also quantify over sets of edges) have the
same expressive power over the class of all countable $k$-sparse hypergraphs.
In the first part of the present paper we extend this result to hypergraphs of
arbitrary cardinality. In the second part, we present a generalisation dealing
with methods to encode sets of vertices by single vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3113</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3113</id><created>2009-10-16</created><updated>2010-02-23</updated><authors><author><keyname>Agaev</keyname><forenames>Rafig</forenames></author><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Which Digraphs with Ring Structure are Essentially Cyclic?</title><categories>math.CO cs.DM cs.MA math.SP</categories><comments>19 pages, 8 figures, Advances in Applied Mathematics: accepted for
  publication (2010) http://dx.doi.org/10.1016/j.aam.2010.01.005</comments><msc-class>05C50, 05C05, 05C20, 15A18, 15B51, 93C15</msc-class><journal-ref>Advances in Applied Mathematics 45 (2010), pp. 232-251</journal-ref><doi>10.1016/j.aam.2010.01.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We say that a digraph is essentially cyclic if its Laplacian spectrum is not
completely real. The essential cyclicity implies the presence of directed
cycles, but not vice versa. The problem of characterizing essential cyclicity
in terms of graph topology is difficult and yet unsolved. Its solution is
important for some applications of graph theory, including that in
decentralized control. In the present paper, this problem is solved with
respect to the class of digraphs with ring structure, which models some typical
communication networks. It is shown that the digraphs in this class are
essentially cyclic, except for certain specified digraphs. The main technical
tool we employ is the Chebyshev polynomials of the second kind. A by-product of
this study is a theorem on the zeros of polynomials that differ by one from the
products of Chebyshev polynomials of the second kind. We also consider the
problem of essential cyclicity for weighted digraphs and enumerate the spanning
trees in some digraphs with ring structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3115</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3115</id><created>2009-10-16</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan M</forenames></author></authors><title>An Idiotypic Immune Network as a Short Term Learning Architecture for
  Mobile Robots</title><categories>cs.AI cs.NE cs.RO</categories><comments>13 pages, 5 tables, 4 figures, 7th International Conference on
  Artificial Immune Systems (ICARIS2008), Phuket, Thailand</comments><journal-ref>Proceedings of the 7th International Conference on Artificial
  Imune Systems (ICARIS2008), Phuket, Thailand, 266-278, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to
solving mobile robot navigation problems is presented and tested in both real
and simulated environments. The LTL consists of rapid simulations that use a
Genetic Algorithm to derive diverse sets of behaviours. These sets are then
transferred to an idiotypic Artificial Immune System (AIS), which forms the STL
phase, and the system is said to be seeded. The combined LTL-STL approach is
compared with using STL only, and with using a handdesigned controller. In
addition, the STL phase is tested when the idiotypic mechanism is turned off.
The results provide substantial evidence that the best option is the seeded
idiotypic system, i.e. the architecture that merges LTL with an idiotypic AIS
for the STL. They also show that structurally different environments can be
used for the two phases without compromising transferability
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3117</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3117</id><created>2009-10-16</created><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>An Immune Inspired Approach to Anomaly Detection</title><categories>cs.AI cs.CR cs.NE</categories><comments>19 pages, 4 tables, 2 figures, Handbook of Research on Information
  Security and Assurance</comments><journal-ref>Handbook of Research on Information Security and Assurance,
  Chapter X, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The immune system provides a rich metaphor for computer security: anomaly
detection that works in nature should work for machines. However, early
artificial immune system approaches for computer security had only limited
success. Arguably, this was due to these artificial systems being based on too
simplistic a view of the immune system. We present here a second generation
artificial immune system for process anomaly detection. It improves on earlier
systems by having different artificial cell types that process information.
Following detailed information about how to build such second generation
systems, we find that communication between cells types is key to performance.
Through realistic testing and validation we show that second generation
artificial immune systems are capable of anomaly detection beyond generic
system policies. The paper concludes with a discussion and outline of the next
steps in this exciting area of computer security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3119</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3119</id><created>2009-10-16</created><authors><author><keyname>Soro</keyname><forenames>Alexandre</forenames></author><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author></authors><title>FFT-based Network Coding For Peer-To-Peer Content Delivery</title><categories>cs.IT math.IT</categories><comments>Submitted to ICC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a structured peer-to-peer (P2P) distribution scheme
based on Fast Fourier Transform (FFT) graphs. We build a peer-to-peer network
that reproduces the FFT graph initially designed for hardware FFT codecs. This
topology allows content delivery with a maximum diversity level for a minimum
global complexity. The resulting FFTbased network is a structured architecture
with an adapted network coding that brings flexibility upon content
distribution and robustness upon the dynamic nature of the network. This
structure can achieve optimal capacity in terms of content recovery while
solving the problem of last remaining blocks, even for large networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3123</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3123</id><created>2009-10-16</created><updated>2010-02-19</updated><authors><author><keyname>Fischer</keyname><forenames>Johannes</forenames></author></authors><title>Wee LCP</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that longest common prefix (LCP) information can be stored in much
less space than previously known. More precisely, we show that in the presence
of the text and the suffix array, o(n) additional bits are sufficient to answer
LCP-queries asymptotically in the same time that is needed to retrieve an entry
from the suffix array. This yields the smallest compressed suffix tree with
sub-logarithmic navigation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3124</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3124</id><created>2009-10-16</created><authors><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>An Immune Inspired Network Intrusion Detection System Utilising
  Correlation Context</title><categories>cs.AI cs.CR cs.NE</categories><comments>2 pages, Workshop on Artificial Immune Systems and Immune System
  Modelling</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network Intrusion Detection Systems (NIDS) are computer systems which monitor
a network with the aim of discerning malicious from benign activity on that
network. While a wide range of approaches have met varying levels of success,
most IDSs rely on having access to a database of known attack signatures which
are written by security experts. Nowadays, in order to solve problems with
false positive alerts, correlation algorithms are used to add additional
structure to sequences of IDS alerts. However, such techniques are of no help
in discovering novel attacks or variations of known attacks, something the
human immune system (HIS) is capable of doing in its own specialised domain.
This paper presents a novel immune algorithm for application to the IDS
problem. The goal is to discover packets containing novel variations of attacks
covered by an existing signature base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3127</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3127</id><created>2009-10-16</created><updated>2009-10-16</updated><authors><author><keyname>Nordstr&#xf6;m</keyname><forenames>Jakob</forenames></author><author><keyname>Razborov</keyname><forenames>Alexander</forenames></author></authors><title>On Minimal Unsatisfiability and Time-Space Trade-offs for k-DNF
  Resolution</title><categories>cs.DM cs.CC math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of proving lower bounds on proof space in k-DNF resolution,
[Ben-Sasson and Nordstrom 2009] introduced the concept of minimally
unsatisfiable sets of k-DNF formulas and proved that a minimally unsatisfiable
k-DNF set with m formulas can have at most O((mk)^(k+1)) variables. They also
gave an example of such sets with Omega(mk^2) variables.
  In this paper we significantly improve the lower bound to Omega(m)^k, which
almost matches the upper bound above. Furthermore, we show that this implies
that the analysis of their technique for proving time-space separations and
trade-offs for k-DNF resolution is almost tight. This means that although it is
possible, or even plausible, that stronger results than in [Ben-Sasson and
Nordstrom 2009] should hold, a fundamentally different approach would be needed
to obtain such results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3144</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3144</id><created>2009-10-16</created><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author><author><keyname>Coecke</keyname><forenames>Bob</forenames></author></authors><title>Abstract Physical Traces</title><categories>quant-ph cs.LO math.CT</categories><comments>14 pages</comments><journal-ref>Theory and Applications of Categories, vol 14, pages 111--124,
  2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revise our &quot;Physical Traces&quot; paper in the light of the results in &quot;A
Categorical Semantics of Quantum Protocols&quot;. The key fact is that the notion of
a strongly compact closed category allows abstract notions of adjoint,
bipartite projector and inner product to be defined, and their key properties
to be proved. In this paper we improve on the definition of strong compact
closure as compared to the one presented in Categorical Semantics of Quantum
Protocols. This modification enables an elegant characterization of strong
compact closure in terms of adjoints and a Yanking axiom, and a better
treatment of bipartite projectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3148</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3148</id><created>2009-10-16</created><updated>2010-05-17</updated><authors><author><keyname>Beretta</keyname><forenames>Stefano</forenames></author><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Dondi</keyname><forenames>Riccardo</forenames></author><author><keyname>Pirola</keyname><forenames>Yuri</forenames></author></authors><title>Parameterized Complexity of the k-anonymity Problem</title><categories>cs.DS cs.DB cs.DM</categories><comments>22 pages, 2 figures</comments><journal-ref>J. of Combinatorial Optimization 26.1 (2013) 19-43</journal-ref><doi>10.1007/s10878-011-9428-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of publishing personal data without giving up privacy is becoming
increasingly important. An interesting formalization that has been recently
proposed is the $k$-anonymity. This approach requires that the rows of a table
are partitioned in clusters of size at least $k$ and that all the rows in a
cluster become the same tuple, after the suppression of some entries. The
natural optimization problem, where the goal is to minimize the number of
suppressed entries, is known to be APX-hard even when the records values are
over a binary alphabet and $k=3$, and when the records have length at most 8
and $k=4$ . In this paper we study how the complexity of the problem is
influenced by different parameters. In this paper we follow this direction of
research, first showing that the problem is W[1]-hard when parameterized by the
size of the solution (and the value $k$). Then we exhibit a fixed parameter
algorithm, when the problem is parameterized by the size of the alphabet and
the number of columns. Finally, we investigate the computational (and
approximation) complexity of the $k$-anonymity problem, when restricting the
instance to records having length bounded by 3 and $k=3$. We show that such a
restriction is APX-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3152</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3152</id><created>2009-10-16</created><authors><author><keyname>McGrath</keyname><forenames>Robert E.</forenames></author><author><keyname>Kastner</keyname><forenames>Jason</forenames></author><author><keyname>Rodriguez</keyname><forenames>Alejandro</forenames></author><author><keyname>Myers</keyname><forenames>Jim</forenames></author></authors><title>Towards a Semantic Preservation System</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preserving access to file content requires preserving not just bits but also
meaningful logical structures. The ongoing development of the Data Format
Description Language (DFDL) is a completely general standard that addresses
this need. The Defuddle parser is a generic parser that can use DFDL-style
format descriptions to extract logical structures from ASCII or binary files
written in those formats. DFDL and Defuddle provide a preservation capability
that has minimal format-specific software and cleanly separates issues related
to bits, formats, and logical content. Such a system has the potential to
greatly reduce overall system development and maintenance costs as well as the
per-file-format costs for long term preservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3243</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3243</id><created>2009-10-16</created><authors><author><keyname>Onak</keyname><forenames>Krzysztof</forenames></author></authors><title>Testing Distribution Identity Efficiently</title><categories>cs.DS</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of testing distribution identity. Given a sequence of
independent samples from an unknown distribution on a domain of size n, the
goal is to check if the unknown distribution approximately equals a known
distribution on the same domain. While Batu, Fortnow, Fischer, Kumar,
Rubinfeld, and White (FOCS 2001) proved that the sample complexity of the
problem is O~(sqrt(n) * poly(1/epsilon)), the running time of their tester is
much higher: O(n) + O~(sqrt(n) * poly(1/epsilon)). We modify their tester to
achieve a running time of O~(sqrt(n) * poly(1/epsilon)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3275</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3275</id><created>2009-10-17</created><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Degrees of Freedom of Multi-Source Relay Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, presented at the 47-th Allerton Conference on
  Communication, Control, and Computing, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a multi-source Gaussian relay network consisting of $K$
source--destination pairs having $K$ unicast sessions. We assume $M$ layers of
relays between the sources and the destinations. We find achievable degrees of
freedom of the network. Our schemes are based on interference alignment at the
transmitters and symbol extension and opportunistic interference cancellation
at the relays. For $K$-$L$-$K$ networks, i.e., 2-hop network with $L$ relays,
we show $\min\{K,K/2+L/(2(K-1))\}$ degrees of freedom are achievable. For
$K$-hop networks with $K$ relays in each layer, we show the full $K$ degrees of
freedom are achievable provided that $K$ is even and the channel distribution
satisfies a certain symmetry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3282</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3282</id><created>2009-10-17</created><authors><author><keyname>Yao</keyname><forenames>Andrew C.</forenames></author><author><keyname>Yung</keyname><forenames>Moti</forenames></author><author><keyname>Zhao</keyname><forenames>Yunlei</forenames></author></authors><title>Adaptive Concurrent Non-Malleability with Bare Public-Keys</title><categories>cs.CC</categories><comments>41 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concurrent non-malleability (CNM) is central for cryptographic protocols
running concurrently in environments such as the Internet. In this work, we
formulate CNM in the bare public-key (BPK) model, and show that round-efficient
concurrent non-malleable cryptography with full adaptive input selection can be
established, in general, with bare public-keys (where, in particular, no
trusted assumption is made). Along the way, we clarify the various subtleties
of adaptive concurrent non-malleability in the bare public-key model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3292</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3292</id><created>2009-10-17</created><authors><author><keyname>Firoz</keyname><forenames>Jesun Sahariar</forenames></author><author><keyname>Hasan</keyname><forenames>Masud</forenames></author><author><keyname>Khan</keyname><forenames>Ashik Zinnat</forenames></author><author><keyname>Rahman</keyname><forenames>M. Sohel</forenames></author></authors><title>The 1.375 Approximation Algorithm for Sorting by Transpositions Can Run
  in $O(n\log n)$ Time</title><categories>cs.DS cs.DM</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sorting a Permutation by Transpositions (SPbT) is an important problem in
Bioinformtics. In this paper, we improve the running time of the best known
approximation algorithm for SPbT. We use the permutation tree data structure of
Feng and Zhu and improve the running time of the 1.375 Approximation Algorithm
for SPbT of Elias and Hartman to $O(n\log n)$. The previous running time of EH
algorithm was $O(n^2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3301</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3301</id><created>2009-10-17</created><updated>2010-04-08</updated><authors><author><keyname>McAuley</keyname><forenames>Julian J.</forenames></author><author><keyname>Caetano</keyname><forenames>Tiberio S.</forenames></author></authors><title>Faster Algorithms for Max-Product Message-Passing</title><categories>cs.AI cs.DS</categories><comments>34 pages, 22 figures</comments><acm-class>F.2.2; I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum A Posteriori inference in graphical models is often solved via
message-passing algorithms, such as the junction-tree algorithm, or loopy
belief-propagation. The exact solution to this problem is well known to be
exponential in the size of the model's maximal cliques after it is
triangulated, while approximate inference is typically exponential in the size
of the model's factors. In this paper, we take advantage of the fact that many
models have maximal cliques that are larger than their constituent factors, and
also of the fact that many factors consist entirely of latent variables (i.e.,
they do not depend on an observation). This is a common case in a wide variety
of applications, including grids, trees, and ring-structured models. In such
cases, we are able to decrease the exponent of complexity for message-passing
by 0.5 for both exact and approximate inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3321</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3321</id><created>2009-10-17</created><authors><author><keyname>Mackie</keyname><forenames>Ian</forenames></author><author><keyname>Pinto</keyname><forenames>Jorge Sousa</forenames></author><author><keyname>Vilaca</keyname><forenames>Miguel</forenames></author></authors><title>Iterators, Recursors and Interaction Nets</title><categories>cs.PL</categories><comments>ISBN: 978-972-9348-18-1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for encoding iterators (and recursion operators in
general) using interaction nets (INs). There are two main applications for
this: the method can be used to obtain a visual nota- tion for functional
programs; and it can be used to extend the existing translations of the
lambda-calculus into INs to languages with recursive types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3348</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3348</id><created>2009-10-17</created><authors><author><keyname>Georgiou</keyname><forenames>Harris</forenames></author></authors><title>Algorithms for Image Analysis and Combination of Pattern Classifiers
  with Application to Medical Diagnosis</title><categories>cs.CV cs.AI cs.GT cs.NE</categories><comments>PhD thesis summary, 12 pages</comments><acm-class>I.5.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Medical Informatics and the application of modern signal processing in the
assistance of the diagnostic process in medical imaging is one of the more
recent and active research areas today. This thesis addresses a variety of
issues related to the general problem of medical image analysis, specifically
in mammography, and presents a series of algorithms and design approaches for
all the intermediate levels of a modern system for computer-aided diagnosis
(CAD). The diagnostic problem is analyzed with a systematic approach, first
defining the imaging characteristics and features that are relevant to probable
pathology in mammo-grams. Next, these features are quantified and fused into
new, integrated radio-logical systems that exhibit embedded digital signal
processing, in order to improve the final result and minimize the radiological
dose for the patient. In a higher level, special algorithms are designed for
detecting and encoding these clinically interest-ing imaging features, in order
to be used as input to advanced pattern classifiers and machine learning
models. Finally, these approaches are extended in multi-classifier models under
the scope of Game Theory and optimum collective deci-sion, in order to produce
efficient solutions for combining classifiers with minimum computational costs
for advanced diagnostic systems. The material covered in this thesis is related
to a total of 18 published papers, 6 in scientific journals and 12 in
international conferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3349</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3349</id><created>2009-10-17</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Konig</keyname><forenames>Arnd Christian</forenames></author></authors><title>b-Bit Minwise Hashing</title><categories>cs.DS cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper establishes the theoretical framework of b-bit minwise hashing.
The original minwise hashing method has become a standard technique for
estimating set similarity (e.g., resemblance) with applications in information
retrieval, data management, social networks and computational advertising.
  By only storing the lowest $b$ bits of each (minwise) hashed value (e.g., b=1
or 2), one can gain substantial advantages in terms of computational efficiency
and storage space. We prove the basic theoretical results and provide an
unbiased estimator of the resemblance for any b. We demonstrate that, even in
the least favorable scenario, using b=1 may reduce the storage space at least
by a factor of 21.3 (or 10.7) compared to using b=64 (or b=32), if one is
interested in resemblance &gt; 0.5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3372</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3372</id><created>2009-10-18</created><updated>2010-03-04</updated><authors><author><keyname>Arenas</keyname><forenames>Marcelo</forenames></author><author><keyname>Perez</keyname><forenames>Jorge</forenames></author><author><keyname>Reutter</keyname><forenames>Juan</forenames></author><author><keyname>Riveros</keyname><forenames>Cristian</forenames></author></authors><title>Composition and Inversion of Schema Mappings</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent years, a lot of attention has been paid to the development of
solid foundations for the composition and inversion of schema mappings. In this
paper, we review the proposals for the semantics of these crucial operators.
For each of these proposals, we concentrate on the three following problems:
the definition of the semantics of the operator, the language needed to express
the operator, and the algorithmic issues associated to the problem of computing
the operator. It should be pointed out that we primarily consider the
formalization of schema mappings introduced in the work on data exchange. In
particular, when studying the problem of computing the composition and inverse
of a schema mapping, we will be mostly interested in computing these operators
for mappings specified by source-to-target tuple-generating dependencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3376</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3376</id><created>2009-10-18</created><updated>2011-03-13</updated><authors><author><keyname>Drucker</keyname><forenames>Andrew</forenames><affiliation>MIT</affiliation></author><author><keyname>de Wolf</keyname><forenames>Ronald</forenames><affiliation>CWI Amsterdam</affiliation></author></authors><title>Quantum Proofs for Classical Theorems</title><categories>quant-ph cs.CC</categories><comments>50 pages LaTeX. Updated based on journal version; the journal version
  is open-access and has nicer typesetting
  (http://theoryofcomputing.org/articles/gs002/)</comments><journal-ref>Theory of Computing, Graduate surveys 2, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alongside the development of quantum algorithms and quantum complexity theory
in recent years, quantum techniques have also proved instrumental in obtaining
results in classical (non-quantum) areas. In this paper we survey these results
and the quantum toolbox they use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3383</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3383</id><created>2009-10-19</created><updated>2010-11-30</updated><authors><author><keyname>Baelde</keyname><forenames>David</forenames></author></authors><title>Least and Greatest Fixed Points in Linear Logic</title><categories>cs.LO</categories><comments>Accepted for publication at the ACM Transactions on Computational
  Logic</comments><acm-class>F.4.1; F.3.1; F.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first-order theory of MALL (multiplicative, additive linear logic) over
only equalities is an interesting but weak logic since it cannot capture
unbounded (infinite) behavior. Instead of accounting for unbounded behavior via
the addition of the exponentials (! and ?), we add least and greatest fixed
point operators. The resulting logic, which we call muMALL, satisfies two
fundamental proof theoretic properties: we establish weak normalization for it,
and we design a focused proof system that we prove complete. That second result
provides a strong normal form for cut-free proof structures that can be used,
for example, to help automate proof search. We show how these foundations can
be applied to intuitionistic logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3427</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3427</id><created>2009-10-18</created><updated>2010-06-07</updated><authors><author><keyname>Witte</keyname><forenames>Ernst Martin</forenames></author><author><keyname>Borlenghi</keyname><forenames>Filippo</forenames></author><author><keyname>Ascheid</keyname><forenames>Gerd</forenames></author><author><keyname>Leupers</keyname><forenames>Rainer</forenames></author><author><keyname>Meyr</keyname><forenames>Heinrich</forenames></author></authors><title>A Scalable VLSI Architecture for Soft-Input Soft-Output Depth-First
  Sphere Decoding</title><categories>cs.AR</categories><comments>Accepted for IEEE Transactions on Circuits and Systems II Express
  Briefs, May 2010. This draft from April 2010 will not be updated any more.
  Please refer to IEEE Xplore for the final version. *) The final publication
  will appear with the modified title &quot;A Scalable VLSI Architecture for
  Soft-Input Soft-Output Single Tree-Search Sphere Decoding&quot;</comments><journal-ref>IEEE Transactions on Circuits and Systems-Part II: Express Briefs,
  vol. 57, no. 9, pp. 706-710, Sep 2010</journal-ref><doi>10.1109/TCSII.2010.2056014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input multiple-output (MIMO) wireless transmission imposes huge
challenges on the design of efficient hardware architectures for iterative
receivers. A major challenge is soft-input soft-output (SISO) MIMO demapping,
often approached by sphere decoding (SD). In this paper, we introduce the - to
our best knowledge - first VLSI architecture for SISO SD applying a single
tree-search approach. Compared with a soft-output-only base architecture
similar to the one proposed by Studer et al. in IEEE J-SAC 2008, the
architectural modifications for soft input still allow a one-node-per-cycle
execution. For a 4x4 16-QAM system, the area increases by 57% and the operating
frequency degrades by 34% only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3485</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3485</id><created>2009-10-19</created><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author><author><keyname>Chen</keyname><forenames>Guoqing</forenames></author></authors><title>A Fuzzy Petri Nets Model for Computing With Words</title><categories>cs.AI</categories><comments>double columns 14 pages, 8 figures</comments><journal-ref>IEEE Trans. Fuzzy Syst., vol. 18, no. 3, pp. 486-499, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by Zadeh's paradigm of computing with words rather than numbers,
several formal models of computing with words have recently been proposed.
These models are based on automata and thus are not well-suited for concurrent
computing. In this paper, we incorporate the well-known model of concurrent
computing, Petri nets, together with fuzzy set theory and thereby establish a
concurrency model of computing with words--fuzzy Petri nets for computing with
words (FPNCWs). The new feature of such fuzzy Petri nets is that the labels of
transitions are some special words modeled by fuzzy sets. By employing the
methodology of fuzzy reasoning, we give a faithful extension of an FPNCW which
makes it possible for computing with more words. The language expressiveness of
the two formal models of computing with words, fuzzy automata for computing
with words and FPNCWs, is compared as well. A few small examples are provided
to illustrate the theoretical development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3490</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3490</id><created>2009-10-19</created><updated>2009-10-23</updated><authors><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Adaptive model for recommendation of news</title><categories>cs.IR cs.DL physics.soc-ph</categories><comments>6 pages, 6 figures</comments><journal-ref>EPL 88, 38005, 2009</journal-ref><doi>10.1209/0295-5075/88/38005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most news recommender systems try to identify users' interests and news'
attributes and use them to obtain recommendations. Here we propose an adaptive
model which combines similarities in users' rating patterns with epidemic-like
spreading of news on an evolving network. We study the model by computer
agent-based simulations, measure its performance and discuss its robustness
against bias and malicious behavior. Subject to the approval fraction of news
recommended, the proposed model outperforms the widely adopted recommendation
of news according to their absolute or relative popularity. This model provides
a general social mechanism for recommender systems and may find its
applications also in other types of recommendation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3494</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3494</id><created>2009-10-19</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Liu</keyname><forenames>Youjian</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Sum-capacity of Interference Channels with a Local View: Impact of
  Distributed Decisions</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, October 2009</comments><journal-ref>IEEE Transactions on Information Theory, vol.58, no.3,
  pp.1630,1659, March 2012</journal-ref><doi>10.1109/TIT.2011.2178132</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the large size of wireless networks, it is often impractical for nodes
to track changes in the complete network state. As a result, nodes have to make
distributed decisions about their transmission and reception parameters based
on their local view of the network. In this paper, we characterize the impact
of distributed decisions on the global network performance in terms of
achievable sum-rates. We first formalize the concept of local view by proposing
a protocol abstraction using the concept of local message passing. In the
proposed protocol, nodes forward information about the network state to other
neighboring nodes, thereby allowing network state information to trickle to all
the nodes. The protocol proceeds in rounds, where all transmitters send a
message followed by a message by all receivers. The number of rounds then
provides a natural metric to quantify the extent of local information at each
node.
  We next study three network connectivities, Z-channel, a three-user double
Z-channel and a reduced-parametrization $K$-user stacked Z-channel. In each
case, we characterize achievable sum-rate with partial message passing leading
to three main results. First, in many cases, nodes can make distributed
decisions with only local information about the network and can still achieve
the same sum-capacity as can be attained with global information irrespective
of the actual channel gains. Second, for the case of three-user double
Z-channel, we show that universal optimality is not achievable if the per node
information is below a threshold. Third, using reduced parametrization $K$-user
channel, we show that very few protocol rounds are needed for the case of very
weak or very strong interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3503</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3503</id><created>2009-10-19</created><updated>2010-06-07</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>Searching a bitstream in linear time for the longest substring of any
  given density</title><categories>cs.DS</categories><comments>22 pages, 19 figures; v2: minor edits and enhancements</comments><journal-ref>Algorithmica 61 (2011), no. 3, 555-579</journal-ref><doi>10.1007/s00453-010-9424-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an arbitrary bitstream, we consider the problem of finding the longest
substring whose ratio of ones to zeroes equals a given value. The central
result of this paper is an algorithm that solves this problem in linear time.
The method involves (i) reformulating the problem as a constrained walk through
a sparse matrix, and then (ii) developing a data structure for this sparse
matrix that allows us to perform each step of the walk in amortised constant
time. We also give a linear time algorithm to find the longest substring whose
ratio of ones to zeroes is bounded below by a given value. Both problems have
practical relevance to cryptography and bioinformatics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3509</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3509</id><created>2009-10-19</created><updated>2010-12-06</updated><authors><author><keyname>Yassaee</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Slepian-Wolf Coding Over Cooperative Relay Networks</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of multicasting a set of discrete
memoryless correlated sources (DMCS) over a cooperative relay network.
Necessary conditions with cut-set interpretation are presented. A \emph{Joint
source-Wyner-Ziv encoding/sliding window decoding} scheme is proposed, in which
decoding at each receiver is done with respect to an ordered partition of other
nodes. For each ordered partition a set of feasibility constraints is derived.
Then, utilizing the sub-modular property of the entropy function and a novel
geometrical approach, the results of different ordered partitions are
consolidated, which lead to sufficient conditions for our problem. The proposed
scheme achieves operational separation between source coding and channel
coding. It is shown that sufficient conditions are indeed necessary conditions
in two special cooperative networks, namely, Aref network and finite-field
deterministic network. Also, in Gaussian cooperative networks, it is shown that
reliable transmission of all DMCS whose Slepian-Wolf region intersects the
cut-set bound region within a constant number of bits, is feasible. In
particular, all results of the paper are specialized to obtain an achievable
rate region for cooperative relay networks which includes relay networks and
two-way relay networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3511</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3511</id><created>2009-10-19</created><authors><author><keyname>Herzberg</keyname><forenames>Amir</forenames></author><author><keyname>Shulman</keyname><forenames>Haya</forenames></author></authors><title>Stealth-MITM DoS Attacks on Secure Channels</title><categories>cs.CR</categories><comments>14 figures; 21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define stealth Man-in-the-Middle adversaries, and analyse their ability to
launch denial and degradation of service (DoS) attacks on secure channels. We
show realistic attacks, disrupting TCP communication over secure VPNs using
IPsec. We present:
  First amplifying DoS attack on IPsec, when deployed without anti-replay
window.
  First amplifying attack on IPsec, when deployed with a `small' anti-replay
window, and analysis of `sufficient' window size.
  First amplifying attack on IPsec, when deployed with `sufficient' window
size. This attack (as the previous) is realistic: attacker needs only to
duplicate and speed-up few packets.
  We also suggest a solution designed to prevent the presented attacks, and to
provide secure channel immune to degradation and other DoS attacks. Our
solution involves changes (only) to the two gateway machines running IPsec.
  In addition to their practical importance, our results also raise the
challenge of formally defining secure channels immune to DoS and degradation
attacks, and providing provably-secure implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3529</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3529</id><created>2009-10-19</created><authors><author><keyname>Adler</keyname><forenames>Robert</forenames></author><author><keyname>Ewing</keyname><forenames>John</forenames></author><author><keyname>Taylor</keyname><forenames>Peter</forenames></author></authors><title>Citation Statistics</title><categories>stat.ME cs.DL physics.soc-ph</categories><comments>This paper commented in: [arXiv:0910.3532], [arXiv:0910.3537],
  [arXiv:0910.3543], [arXiv:0910.3546]. Rejoinder in [arXiv:0910.3548].
  Published in at http://dx.doi.org/10.1214/09-STS285 the Statistical Science
  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics
  (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS285</report-no><journal-ref>Statistical Science 2009, Vol. 24, No. 1, 1-14</journal-ref><doi>10.1214/09-STS285</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a report about the use and misuse of citation data in the assessment
of scientific research. The idea that research assessment must be done using
``simple and objective'' methods is increasingly prevalent today. The ``simple
and objective'' methods are broadly interpreted as bibliometrics, that is,
citation data and the statistics derived from them. There is a belief that
citation statistics are inherently more accurate because they substitute simple
numbers for complex judgments, and hence overcome the possible subjectivity of
peer review. But this belief is unfounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3532</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3532</id><created>2009-10-19</created><authors><author><keyname>Silverman</keyname><forenames>Bernard W.</forenames></author></authors><title>Comment: Bibliometrics in the Context of the UK Research Assessment
  Exercise</title><categories>stat.ME cs.DL physics.soc-ph</categories><comments>Published in at http://dx.doi.org/10.1214/09-STS285A the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS285A</report-no><journal-ref>Statistical Science 2009, Vol. 24, No. 1, 15-16</journal-ref><doi>10.1214/09-STS285A</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research funding and reputation in the UK have, for over two decades, been
increasingly dependent on a regular peer-review of all UK departments. This is
to move to a system more based on bibliometrics. Assessment exercises of this
kind influence the behavior of institutions, departments and individuals, and
therefore bibliometrics will have effects beyond simple measurement.
[arXiv:0910.3529]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3537</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3537</id><created>2009-10-19</created><authors><author><keyname>Lehmann</keyname><forenames>Sune</forenames></author><author><keyname>Lautrup</keyname><forenames>Benny E.</forenames></author><author><keyname>Jackson</keyname><forenames>Andrew D.</forenames></author></authors><title>Comment: Citation Statistics</title><categories>stat.ME cs.DL physics.soc-ph</categories><comments>Published in at http://dx.doi.org/10.1214/09-STS285B the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS285B</report-no><journal-ref>Statistical Science 2009, Vol. 24, No. 1, 17-20</journal-ref><doi>10.1214/09-STS285B</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the paper &quot;Citation Statistics&quot; by the Joint Committee on
Quantitative Assessment of Research [arXiv:0910.3529]. In particular, we focus
on a necessary feature of &quot;good&quot; measures for ranking scientific authors: that
good measures must able to accurately distinguish between authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3543</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3543</id><created>2009-10-19</created><authors><author><keyname>Spiegelhalter</keyname><forenames>David</forenames></author><author><keyname>Goldstein</keyname><forenames>Harvey</forenames></author></authors><title>Comment: Citation Statistics</title><categories>stat.ME cs.DL physics.soc-ph</categories><comments>Published in at http://dx.doi.org/10.1214/09-STS285C the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS285C</report-no><journal-ref>Statistical Science 2009, Vol. 24, No. 1, 21-24</journal-ref><doi>10.1214/09-STS285C</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comment on &quot;Citation Statistics&quot; [arXiv:0910.3529]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3546</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3546</id><created>2009-10-19</created><authors><author><keyname>Hall</keyname><forenames>Peter Gavin</forenames></author></authors><title>Comment: Citation Statistics</title><categories>stat.ME cs.DL physics.soc-ph</categories><comments>Published in at http://dx.doi.org/10.1214/09-STS285D the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS285D</report-no><journal-ref>Statistical Science 2009, Vol. 24, No. 1, 25-26</journal-ref><doi>10.1214/09-STS285D</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comment on &quot;Citation Statistics&quot; [arXiv:0910.3529]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3548</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3548</id><created>2009-10-19</created><authors><author><keyname>Adler</keyname><forenames>Robert</forenames></author><author><keyname>Ewing</keyname><forenames>John</forenames></author><author><keyname>Taylor</keyname><forenames>Peter</forenames></author></authors><title>Rejoinder: Citation Statistics</title><categories>stat.ME cs.DL physics.soc-ph</categories><comments>Published in at http://dx.doi.org/10.1214/09-STS285REJ the
  Statistical Science (http://www.imstat.org/sts/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS285REJ</report-no><journal-ref>Statistical Science 2009, Vol. 24, No. 1, 27-28</journal-ref><doi>10.1214/09-STS285REJ</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rejoinder to &quot;Citation Statistics&quot; [arXiv:0910.3529]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3580</identifier>
 <datestamp>2015-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3580</id><created>2009-10-19</created><updated>2010-02-24</updated><authors><author><keyname>Brandt</keyname><forenames>Felix</forenames></author><author><keyname>Harrenstein</keyname><forenames>Paul</forenames></author></authors><title>Set-Rationalizable Choice and Self-Stability</title><categories>cs.MA</categories><comments>20 pages, 2 figure, changed content</comments><journal-ref>Journal of Economic Theory 146(4), 2011</journal-ref><doi>10.1016/j.jet.2011.03.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common assumption in modern microeconomic theory is that choice should be
rationalizable via a binary preference relation, which \citeauthor{Sen71a}
showed to be equivalent to two consistency conditions, namely $\alpha$
(contraction) and $\gamma$ (expansion). Within the context of \emph{social}
choice, however, rationalizability and similar notions of consistency have
proved to be highly problematic, as witnessed by a range of impossibility
results, among which Arrow's is the most prominent. Since choice functions
select \emph{sets} of alternatives rather than single alternatives, we propose
to rationalize choice functions by preference relations over sets
(set-rationalizability). We also introduce two consistency conditions,
$\hat\alpha$ and $\hat\gamma$, which are defined in analogy to $\alpha$ and
$\gamma$, and find that a choice function is set-rationalizable if and only if
it satisfies $\hat\alpha$. Moreover, a choice function satisfies $\hat\alpha$
and $\hat\gamma$ if and only if it is \emph{self-stable}, a new concept based
on earlier work by \citeauthor{Dutt88a}. The class of self-stable social choice
functions contains a number of appealing Condorcet extensions such as the
minimal covering set and the essential set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3603</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3603</id><created>2009-10-19</created><updated>2010-11-15</updated><authors><author><keyname>Chigansky</keyname><forenames>Pavel</forenames></author><author><keyname>van Handel</keyname><forenames>Ramon</forenames></author></authors><title>A complete solution to Blackwell's unique ergodicity problem for hidden
  Markov chains</title><categories>math.PR cs.IT math.IT</categories><comments>Published in at http://dx.doi.org/10.1214/10-AAP688 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP688</report-no><journal-ref>Annals of Applied Probability 2010, Vol. 20, No. 6, 2318-2345</journal-ref><doi>10.1214/10-AAP688</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop necessary and sufficient conditions for uniqueness of the
invariant measure of the filtering process associated to an ergodic hidden
Markov model in a finite or countable state space. These results provide a
complete solution to a problem posed by Blackwell (1957), and subsume earlier
partial results due to Kaijser, Kochman and Reeds. The proofs of our main
results are based on the stability theory of nonlinear filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3658</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3658</id><created>2009-10-19</created><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Secrecy Rate Region of the Broadcast Channel with an Eavesdropper</title><categories>cs.IT math.IT</categories><comments>18 Pages, Submitted to IEEE Transaction on Information Theory
  (Revised Version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a scenario where a source node wishes to broadcast
two confidential messages to two receivers, while a wire-tapper also receives
the transmitted signal. This model is motivated by wireless communications,
where individual secure messages are broadcast over open media and can be
received by any illegitimate receiver. The secrecy level is measured by the
equivocation rate at the eavesdropper. We first study the general
(non-degraded) broadcast channel with an eavesdropper. We present an inner
bound on the secrecy capacity region for this model. This inner bound is based
on a combination of random binning, and the Gelfand-Pinsker binning. We further
study the situation in which the channels are degraded. For the degraded
broadcast channel with an eavesdropper, we present the secrecy capacity region.
Our achievable coding scheme is based on Covers superposition scheme and random
binning. We refer to this scheme as the Secret Superposition Scheme. Our
converse proof is based on a combination of the converse proof of the
conventional degraded broadcast channel and Csiszar Lemma. We then assume that
the channels are Additive White Gaussian Noise (AWGN) and show that the Secret
Superposition Scheme with Gaussian codebook is optimal. The converse proof is
based on Costas entropy power inequality. Finally, we use a broadcast strategy
for the slowly fading wire-tap channel when only the eavesdroppers channel is
fixed and known at the transmitter. We derive the optimum power allocation for
the coding layers, which maximizes the total average rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3713</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3713</id><created>2009-10-19</created><authors><author><keyname>Juba</keyname><forenames>Brendan</forenames></author></authors><title>On Learning Finite-State Quantum Sources</title><categories>quant-ph cs.LG</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the complexity of learning the distributions produced by
finite-state quantum sources. We show how prior techniques for learning hidden
Markov models can be adapted to the quantum generator model to find that the
analogous state of affairs holds: information-theoretically, a polynomial
number of samples suffice to approximately identify the distribution, but
computationally, the problem is as hard as learning parities with noise, a
notorious open question in computational learning theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3719</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3719</id><created>2009-10-19</created><authors><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author></authors><title>Improved Approximation of Linear Threshold Functions</title><categories>cs.CC</categories><comments>full version of CCC'09 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove two main results on how arbitrary linear threshold functions $f(x) =
\sign(w\cdot x - \theta)$ over the $n$-dimensional Boolean hypercube can be
approximated by simple threshold functions.
  Our first result shows that every $n$-variable threshold function $f$ is
$\eps$-close to a threshold function depending only on $\Inf(f)^2 \cdot
\poly(1/\eps)$ many variables, where $\Inf(f)$ denotes the total influence or
average sensitivity of $f.$ This is an exponential sharpening of Friedgut's
well-known theorem \cite{Friedgut:98}, which states that every Boolean function
$f$ is $\eps$-close to a function depending only on $2^{O(\Inf(f)/\eps)}$ many
variables, for the case of threshold functions. We complement this upper bound
by showing that $\Omega(\Inf(f)^2 + 1/\epsilon^2)$ many variables are required
for $\epsilon$-approximating threshold functions.
  Our second result is a proof that every $n$-variable threshold function is
$\eps$-close to a threshold function with integer weights at most $\poly(n)
\cdot 2^{\tilde{O}(1/\eps^{2/3})}.$ This is a significant improvement, in the
dependence on the error parameter $\eps$, on an earlier result of
\cite{Servedio:07cc} which gave a $\poly(n) \cdot 2^{\tilde{O}(1/\eps^{2})}$
bound. Our improvement is obtained via a new proof technique that uses strong
anti-concentration bounds from probability theory. The new technique also gives
a simple and modular proof of the original \cite{Servedio:07cc} result, and
extends to give low-weight approximators for threshold functions under a range
of probability distributions beyond just the uniform distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3736</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3736</id><created>2009-10-20</created><authors><author><keyname>Xia</keyname><forenames>Bingbing</forenames></author><author><keyname>Qiao</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author><author><keyname>Wang</keyname><forenames>Hui</forenames></author></authors><title>A Fault-tolerant Structure for Reliable Multi-core Systems Based on
  Hardware-Software Co-design</title><categories>cs.AR</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To cope with the soft errors and make full use of the multi-core system, this
paper gives an efficient fault-tolerant hardware and software co-designed
architecture for multi-core systems. And with a not large number of test
patterns, it will use less than 33% hardware resources compared with the
traditional hardware redundancy (TMR) and it will take less than 50% time
compared with the traditional software redundancy (time redundant).Therefore,
it will be a good choice for the fault-tolerant architecture for the future
high-reliable multi-core systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3765</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3765</id><created>2009-10-20</created><authors><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author></authors><title>Performance Evaluation of Security Protocols</title><categories>cs.CR</categories><proxy>ccsd hal-00425083</proxy><journal-ref>19th International Conference on Computer Science and
  Energetics-Electrical Engineering, Romania (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a comparative performance evaluation of security protocols. The
novelty of our approach lies in the use of a polynomial mathematical model that
captures the performance of classes of cryptographic algorithms instead of
capturing the performance of each algorithm separately, approach that is used
in other papers. A major advantage of using such a model is that it does not
require implementation-specific information, because the decision is based on
comparing the estimated performances of protocols instead of actually
evaluating them. The approach is validated by comparatively evaluating the
performances of 1000 automatically generated security protocols against the
performances of their actual implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3766</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3766</id><created>2009-10-20</created><authors><author><keyname>Gaiser</keyname><forenames>Andreas</forenames></author><author><keyname>Schwoon</keyname><forenames>Stefan</forenames></author></authors><title>Comparison of Algorithms for Checking Emptiness on Buechi Automata</title><categories>cs.LO</categories><comments>Technical Report, 15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We re-investigate the problem of LTL model-checking for finite-state systems.
Typical solutions, like in Spin, work on the fly, reducing the problem to
Buechi emptiness. This can be done in linear time, and a variety of algorithms
with this property exist. Nonetheless, subtle design decisions can make a great
difference to their actual performance in practice, especially when used
on-the-fly. We compare a number of algorithms experimentally on a large
benchmark suite, measure their actual run-time performance, and propose
improvements. Compared with the algorithm implemented in Spin, our best
algorithm is faster by about 33 % on average. We therefore recommend that, for
on-the-fly explicit-state model checking, nested DFS should be replaced by
better solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3768</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3768</id><created>2009-10-20</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>On the transmit strategy for the interference MIMO relay channel in the
  low power regime</title><categories>cs.IT math.IT</categories><comments>5 pages, accepted for 8th International ITG Conference on Source and
  Channel Coding, Siegen, Germany, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the interference channel with two transmitters and two
receivers in the presence of a MIMO relay in the low transmit power regime. A
communication scheme combining block Markov encoding, beamforming, and Willems'
backward decoding is used. With this scheme, we get an interference channel
with channel gains dependent on the signal power. A power allocation for this
scheme is proposed, and the achievable rate region with this power allocation
is given. We show that, at low transmit powers, with equal power constraints at
the relay and the transmitters, the interference channel with a MIMO relay
achieves a sum rate that is linear in the power. This sum rate is determined by
the channel setup. We also show that in the presence of abundant power at the
relay, the transmit strategy is significantly simplified, and the MAC from the
transmitters to the relay forms the bottle neck of the system from the sum rate
point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3811</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3811</id><created>2009-10-20</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Staicu</keyname><forenames>Stefan</forenames></author></authors><title>Dynamics of the Orthoglide parallel robot</title><categories>cs.RO</categories><proxy>ccsd hal-00425143</proxy><journal-ref>UPB Scientific Bulletin, Series D: Mechanical Engineering 71, 3
  (2009) 3-16</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recursive matrix relations for kinematics and dynamics of the Orthoglide
parallel robot having three concurrent prismatic actuators are established in
this paper. These are arranged according to the Cartesian coordinate system
with fixed orientation, which means that the actuating directions are normal to
each other. Three identical legs connecting to the moving platform are located
on three planes being perpendicular to each other too. Knowing the position and
the translation motion of the platform, we develop the inverse kinematics
problem and determine the position, velocity and acceleration of each element
of the robot. Further, the principle of virtual work is used in the inverse
dynamic problem. Some matrix equations offer iterative expressions and graphs
for the input forces and the powers of the three actuators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3840</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3840</id><created>2009-10-20</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Distributed Universally Optimal Strategies for Interference Channels
  with Partial Message Passing</title><categories>cs.IT math.IT</categories><comments>In Proc. Allerton Conference on Communication, Control, and
  Computing, Monticello, IL, USA, Sept-Oct 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In distributed wireless networks, nodes often do not know the topology
(network size, connectivity and the channel gains) of the network. Thus, they
have to compute their transmission and reception parameters in a distributed
fashion. In this paper, we consider that each of the transmitter know the
channel gains of all the links that are at-most two-hop distant from it and the
receiver knows the channel gains of all the links that are three-hop distant
from it in a deterministic interference channel. With this limited information,
we find a condition on the network connectivity for which there exist a
distributed strategy that can be chosen by the users with partial information
about the network state, which achieves the same sum capacity as that
achievable by the centralized server that knows all the channel gains.
Specifically, distributed decisions are sum-rate optimal only if each connected
component is in a one-to-many configuration or a fully-connected configuration.
In all other cases of network connectivity, the loss can be arbitrarily large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3848</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3848</id><created>2009-10-20</created><authors><author><keyname>Mann</keyname><forenames>Martin</forenames></author><author><keyname>Backofen</keyname><forenames>Rolf</forenames></author><author><keyname>Will</keyname><forenames>Sebastian</forenames></author></authors><title>Equivalence Classes of Optimal Structures in HP Protein Models Including
  Side Chains</title><categories>cs.CE q-bio.BM</categories><comments>Published in Proceedings of the Fifth Workshop on Constraint Based
  Methods for Bioinformatics (WCB09), 2009, 9 pages</comments><acm-class>D.1.6; G.2.1; J.2; J.3</acm-class><journal-ref>In Proceedings of the Fifth Workshop on Constraint Based Methods
  for Bioinformatics (WCB09), 2009, Lisbon</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice protein models, as the Hydrophobic-Polar (HP) model, are a common
abstraction to enable exhaustive studies on structure, function, or evolution
of proteins. A main issue is the high number of optimal structures, resulting
from the hydrophobicity-based energy function applied. We introduce an
equivalence relation on protein structures that correlates to the energy
function. We discuss the efficient enumeration of optimal representatives of
the corresponding equivalence classes and the application of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3880</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3880</id><created>2009-10-20</created><authors><author><keyname>Mann</keyname><forenames>Martin</forenames></author><author><keyname>Hamra</keyname><forenames>Mohamed Abou</forenames></author><author><keyname>Steinh&#xf6;fel</keyname><forenames>Kathleen</forenames></author><author><keyname>Backofen</keyname><forenames>Rolf</forenames></author></authors><title>Constraint-based Local Move Definitions for Lattice Protein Models
  Including Side Chains</title><categories>cs.CE q-bio.BM</categories><comments>Published in Proceedings of the Fifth Workshop on Constraint Based
  Methods for Bioinformatics (WCB09), 2009, 10 pages</comments><acm-class>D.1.6; G.2.1; J.2; J.3</acm-class><journal-ref>In Proceedings of the Fifth Workshop on Constraint Based Methods
  for Bioinformatics (WCB09), 2009, Lisbon</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simulation of a protein's folding process is often done via stochastic
local search, which requires a procedure to apply structural changes onto a
given conformation. Here, we introduce a constraint-based approach to enumerate
lattice protein structures according to k-local moves in arbitrary lattices.
Our declarative description is much more flexible for extensions than standard
operational formulations. It enables a generic calculation of k-local neighbors
in backbone-only and side chain models. We exemplify the procedure using a
simple hierarchical folding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3883</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3883</id><created>2009-10-20</created><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Tahbaz-Salehi</keyname><forenames>Alireza</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Variance Analysis of Randomized Consensus in Switching Directed Networks</title><categories>cs.MA cs.DC cs.NI</categories><comments>6 pages, 3 figures, submitted to American Control Conference 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the asymptotic properties of distributed consensus
algorithms over switching directed random networks. More specifically, we focus
on consensus algorithms over independent and identically distributed, directed
Erdos-Renyi random graphs, where each agent can communicate with any other
agent with some exogenously specified probability $p$. While it is well-known
that consensus algorithms over Erdos-Renyi random networks result in an
asymptotic agreement over the network, an analytical characterization of the
distribution of the asymptotic consensus value is still an open question. In
this paper, we provide closed-form expressions for the mean and variance of the
asymptotic random consensus value, in terms of the size of the network and the
probability of communication $p$. We also provide numerical simulations that
illustrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3913</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3913</id><created>2009-10-20</created><authors><author><keyname>Janota</keyname><forenames>Mikolas</forenames></author><author><keyname>Botterweck</keyname><forenames>Goetz</forenames></author><author><keyname>Grigore</keyname><forenames>Radu</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author></authors><title>How to Complete an Interactive Configuration Process?</title><categories>cs.SE cs.AI cs.LO</categories><comments>to appear in SOFSEM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When configuring customizable software, it is useful to provide interactive
tool-support that ensures that the configuration does not breach given
constraints.
  But, when is a configuration complete and how can the tool help the user to
complete it?
  We formalize this problem and relate it to concepts from non-monotonic
reasoning well researched in Artificial Intelligence. The results are
interesting for both practitioners and theoreticians. Practitioners will find a
technique facilitating an interactive configuration process and experiments
supporting feasibility of the approach. Theoreticians will find links between
well-known formal concepts and a concrete practical application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3928</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3928</id><created>2009-10-20</created><authors><author><keyname>Katselis</keyname><forenames>Dimitris</forenames></author><author><keyname>Kofidis</keyname><forenames>Eleftherios</forenames></author><author><keyname>Rontogiannis</keyname><forenames>Athanasios</forenames></author><author><keyname>Theodoridis</keyname><forenames>Sergios</forenames></author></authors><title>Preamble-Based Channel Estimation for CP-OFDM and OFDM/OQAM Systems: A
  Comparative Study</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2010.2043129</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, preamble-based least squares (LS) channel estimation in OFDM
systems of the QAM and offset QAM (OQAM) types is considered, in both the
frequency and the time domains. The construction of optimal (in the mean
squared error (MSE) sense) preambles is investigated, for both the cases of
full (all tones carrying pilot symbols) and sparse (a subset of pilot tones,
surrounded by nulls or data) preambles. The two OFDM systems are compared for
the same transmit power, which, for cyclic prefix (CP) based OFDM/QAM, also
includes the power spent for CP transmission. OFDM/OQAM, with a sparse preamble
consisting of equipowered and equispaced pilots embedded in zeros, turns out to
perform at least as well as CP-OFDM. Simulations results are presented that
verify the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3959</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3959</id><created>2009-10-20</created><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author></authors><title>Coalgebras, Chu Spaces, and Representations of Physical Systems</title><categories>quant-ph cs.LO math.CT</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit our earlier work on the representation of quantum systems as Chu
spaces, and investigate the use of coalgebra as an alternative framework. On
the one hand, coalgebras allow the dynamics of repeated measurement to be
captured, and provide mathematical tools such as final coalgebras, bisimulation
and coalgebraic logic. However, the standard coalgebraic framework does not
accommodate contravariance, and is too rigid to allow physical symmetries to be
represented. We introduce a fibrational structure on coalgebras in which
contravariance is represented by indexing. We use this structure to give a
universal semantics for quantum systems based on a final coalgebra
construction. We characterize equality in this semantics as projective
equivalence. We also define an analogous indexed structure for Chu spaces, and
use this to obtain a novel categorical description of the category of Chu
spaces. We use the indexed structures of Chu spaces and coalgebras over a
common base to define a truncation functor from coalgebras to Chu spaces. This
truncation functor is used to lift the full and faithful representation of the
groupoid of physical symmetries on Hilbert spaces into Chu spaces, obtained in
our previous work, to the coalgebraic semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3973</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3973</id><created>2009-10-20</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On the Delay-Throughput Tradeoff in Distributed Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory (34 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the delay-throughput analysis of a single-hop wireless
network with $n$ transmitter/receiver pairs. All channels are assumed to be
block Rayleigh fading with shadowing, described by parameters
$(\alpha,\varpi)$, where $\alpha$ denotes the probability of shadowing and
$\varpi$ represents the average cross-link gains. The analysis relies on the
distributed on-off power allocation strategy (i.e., links with a direct channel
gain above a certain threshold transmit at full power and the rest remain
silent) for the deterministic and stochastic packet arrival processes. It is
also assumed that each transmitter has a buffer size of one packet and dropping
occurs once a packet arrives in the buffer while the previous packet has not
been served. In the first part of the paper, we define a new notion of
performance in the network, called effective throughput, which captures the
effect of arrival process in the network throughput, and maximize it for
different cases of packet arrival process. It is proved that the effective
throughput of the network asymptotically scales as $\frac{\log
n}{\hat{\alpha}}$, with $\hat{\alpha} \triangleq \alpha \varpi$, regardless of
the packet arrival process. In the second part of the paper, we present the
delay characteristics of the underlying network in terms of the packet dropping
probability. We derive the sufficient conditions in the asymptotic case of $n
\to \infty$ such that the packet dropping probability tend to zero, while
achieving the maximum effective throughput of the network. Finally, we study
the trade-off between the effective throughput, delay, and packet dropping
probability of the network for different packet arrival processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3975</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3975</id><created>2009-10-20</created><authors><author><keyname>Dikaliotis</keyname><forenames>Theodoros K.</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>On the Delay of Network Coding over Line Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a simple network where a source and a receiver are connected by a
line of erasure channels of different reliabilities. Recent prior work has
shown that random linear network coding can achieve the min-cut capacity and
therefore the asymptotic rate is determined by the worst link of the line
network. In this paper we investigate the delay for transmitting a batch of
packets, which is a function of all the erasure probabilities and the number of
packets in the batch. We show a monotonicity result on the delay function and
derive simple expressions which characterize the expected delay behavior of
line networks. Further, we use a martingale bounded differences argument to
show that the actual delay is tightly concentrated around its expectation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.3991</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.3991</id><created>2009-10-20</created><updated>2011-07-10</updated><authors><author><keyname>Chum</keyname><forenames>Chi Sing</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaowen</forenames></author></authors><title>Improved Latin Square based Secret Sharing Scheme</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper first reviews some basic properties of cryptographic hash
function, secret sharing scheme, and Latin square. Then we discuss why Latin
square or its critical set is a good choice for secret representation and its
relationship with secret sharing scheme. Further we enumerate the limitations
of Latin square in a secret sharing scheme. Finally we propose how to apply
cryptographic hash functions, herding attack technique to a Latin square based
secret sharing scheme to overcome these limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4000</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4000</id><created>2009-10-21</created><authors><author><keyname>Ur-Rehman</keyname><forenames>Raza</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Path placement optimization of manipulators based on energy consumption:
  application to the orthoglide 3-axis</title><categories>cs.RO</categories><proxy>ccsd hal-00425337</proxy><journal-ref>Transactions of the canadian society for mechanical engineering
  (2009) 1-19</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the optimal path placement for a manipulator based on
energy consumption. It proposes a methodology to determine the optimal location
of a given test path within the workspace of a manipulator with minimal
electric energy used by the actuators while taking into account the geometric,
kinematic and dynamic constraints. The proposed methodology is applied to the
Orthoglide~3-axis, a three-degree-of-freedom translational parallel kinematic
machine (PKM), as an illustrative example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4012</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4012</id><created>2009-10-21</created><authors><author><keyname>Kanaan</keyname><forenames>Daniel</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Singularity Analysis of Lower-Mobility Parallel Manipulators Using
  Grassmann-Cayley Algebra</title><categories>cs.RO</categories><proxy>ccsd hal-00425361</proxy><journal-ref>IEEE Transactions on Robotics 25, 5 (2009) 995-1004</journal-ref><doi>10.1109/TRO.2009.2017132</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a methodology to analyze geometrically the
singularities of manipulators, of which legs apply both actuation forces and
constraint moments to their moving platform. Lower-mobility parallel
manipulators and parallel manipulators, of which some legs do not have any
spherical joint, are such manipulators. The geometric conditions associated
with the dependency of six Pl\&quot;ucker vectors of finite lines or lines at
infinity constituting the rows of the inverse Jacobian matrix are formulated
using Grassmann-Cayley Algebra. Accordingly, the singularity conditions are
obtained in vector form. This study is illustrated with the singularity
analysis of four manipulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4024</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4024</id><created>2009-10-21</created><authors><author><keyname>Huc</keyname><forenames>Florian</forenames></author><author><keyname>Jarry</keyname><forenames>Aubin</forenames></author></authors><title>VRAC: Simulation Results #1</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to make full use of geographic routing techniques developed for
large scale networks, nodes must be localized. However, localization and
virtual localization techniques in sensor networks are dependent either on
expensive and sometimes unavailable hardware (e.g. GPS) or on sophisticated
localization calculus (e.g. triangulation) which are both error-prone and with
a costly overhead.
  Instead of localizing nodes in a traditional 2-dimensional space, we use
directly the raw distance to a set of anchors to route messages in a
multi-dimensional space. This should enable us to use any geographic routing
protocol in a robust and efficient manner in a very large range of scenarios.
We test this technique for two different geographic routing algorithms, namely
GRIC and ROAM. The simulation results show that using the raw coordinates does
not decrease their efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4033</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4033</id><created>2009-10-21</created><authors><author><keyname>Chen</keyname><forenames>Han</forenames><affiliation>School of Electronic Engineering and Computer Science, Queen Mary University of London</affiliation></author><author><keyname>Malacaria</keyname><forenames>Pasquale</forenames><affiliation>School of Electronic Engineering and Computer Science, Queen Mary University of London</affiliation></author></authors><title>Studying Maximum Information Leakage Using Karush-Kuhn-Tucker Conditions</title><categories>cs.CR cs.IT cs.LO cs.PL math.IT</categories><journal-ref>EPTCS 7, 2009, pp. 1-15</journal-ref><doi>10.4204/EPTCS.7.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When studying the information leakage in programs or protocols, a natural
question arises: &quot;what is the worst case scenario?&quot;. This problem of
identifying the maximal leakage can be seen as a channel capacity problem in
the information theoretical sense. In this paper, by combining two powerful
theories: Information Theory and Karush-Kuhn-Tucker conditions, we demonstrate
a very general solution to the channel capacity problem. Examples are given to
show how our solution can be applied to practical contexts of programs and
anonymity protocols, and how this solution generalizes previous approaches to
this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4042</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4042</id><created>2009-10-21</created><updated>2011-01-21</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Compression-based investigation of the dynamical properties of cellular
  automata and other systems</title><categories>cs.CC nlin.CG</categories><comments>28 pages. This version includes the conjecture relating the
  transition coefficient to computational universality. Camera ready version</comments><acm-class>E.4</acm-class><journal-ref>Journal of Complex Systems, 19(1), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for studying the qualitative dynamical properties of abstract
computing machines based on the approximation of their program-size complexity
using a general lossless compression algorithm is presented. It is shown that
the compression-based approach classifies cellular automata (CA) into clusters
according to their heuristic behavior, with these clusters showing a
correspondence with Wolfram's main classes of CA behavior. A compression based
method to estimate a characteristic exponent to detect phase transitions and
measure the resiliency or sensitivity of a system to its initial conditions is
also proposed. A conjecture regarding the capability of a system to reach
computational universality related to the values of this phase transition
coefficient is formulated. These ideas constitute a compression-based framework
for investigating the dynamical properties of cellular automata and other
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4044</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4044</id><created>2009-10-21</created><authors><author><keyname>Pang</keyname><forenames>Jun</forenames><affiliation>University of Luxembourg</affiliation></author><author><keyname>Zhang</keyname><forenames>Chenyi</forenames><affiliation>University of Luxembourg</affiliation></author></authors><title>How to Work with Honest but Curious Judges? (Preliminary Report)</title><categories>cs.CR cs.LO cs.PL</categories><journal-ref>EPTCS 7, 2009, pp. 31-45</journal-ref><doi>10.4204/EPTCS.7.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The three-judges protocol, recently advocated by Mclver and Morgan as an
example of stepwise refinement of security protocols, studies how to securely
compute the majority function to reach a final verdict without revealing each
individual judge's decision. We extend their protocol in two different ways for
an arbitrary number of 2n+1 judges. The first generalisation is inherently
centralised, in the sense that it requires a judge as a leader who collects
information from others, computes the majority function, and announces the
final result. A different approach can be obtained by slightly modifying the
well-known dining cryptographers protocol, however it reveals the number of
votes rather than the final verdict. We define a notion of conditional
anonymity in order to analyse these two solutions. Both of them have been
checked in the model checker MCMAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4049</identifier>
 <datestamp>2011-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4049</id><created>2009-10-21</created><updated>2011-04-12</updated><authors><author><keyname>Gasilov</keyname><forenames>N.</forenames></author><author><keyname>Amrahov</keyname><forenames>&#x15e;ahin Emrah</forenames></author><author><keyname>Fatullayev</keyname><forenames>A. Golayoglu</forenames></author><author><keyname>Karakas</keyname><forenames>H. I.</forenames></author><author><keyname>Akin</keyname><forenames>O.</forenames></author></authors><title>A Geometric Approach to Solve Fuzzy Linear Systems</title><categories>cs.NA math.NA</categories><acm-class>G.1.3; G.4; J.2</acm-class><journal-ref>CMES: Computer Modeling in Engineering &amp; Sciences, Vol. 75, No. 3,
  pp. 189-204, 2011</journal-ref><doi>10.3970/cmes.2011.075.189</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, linear systems with a crisp real coefficient matrix and with a
vector of fuzzy triangular numbers on the right-hand side are studied. A new
method, which is based on the geometric representations of linear
transformations, is proposed to find solutions. The method uses the fact that a
vector of fuzzy triangular numbers forms a rectangular prism in n-dimensional
space and that the image of a parallelepiped is also a parallelepiped under a
linear transformation. The suggested method clarifies why in general case
different approaches do not generate solutions as fuzzy numbers. It is
geometrically proved that if the coefficient matrix is a generalized
permutation matrix, then the solution of a fuzzy linear system (FLS) is a
vector of fuzzy numbers irrespective of the vector on the right-hand side. The
most important difference between this and previous papers on FLS is that the
solution is sought as a fuzzy set of vectors (with real components) rather than
a vector of fuzzy numbers. Each vector in the solution set solves the given FLS
with a certain possibility. The suggested method can also be applied in the
case when the right-hand side is a vector of fuzzy numbers in parametric form.
However, in this case, -cuts of the solution can not be determined by geometric
similarity and additional computations are needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4052</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4052</id><created>2009-10-21</created><authors><author><keyname>Yafimau</keyname><forenames>Andrei I.</forenames></author></authors><title>Virtual-Threading: Advanced General Purpose Processors Architecture</title><categories>cs.AR cs.OS</categories><comments>56 pages, 5 PNG figures</comments><acm-class>C.1.2; D.4.1; D.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes the new computers architecture, the main features of
which has been claimed in the Russian Federation patent 2312388 and in the US
patent application 11/991331. This architecture is intended to effective
support of the General Purpose Parallel Computing (GPPC), the essence of which
is extremely frequent switching of threads between states of activity and
states of viewed in the paper the algorithmic latency. To emphasize the same
impact of the architectural latency and the algorithmic latency upon GPPC, is
introduced the new notion of the generalized latency and is defined its
quantitative measure - the Generalized Latency Tolerance (GLT). It is shown
that a well suited for GPPC implementation architecture should have high level
of GLT and is described such architecture, which is called the Virtual-Threaded
Machine. This architecture originates a processor virtualization in the
direction of activities virtualization, which is orthogonal to the well-known
direction of memory virtualization. The key elements of the architecture are 1)
the distributed fine grain representation of the architectural register file,
which elements are hardware swapped through levels of a microarchitectural
memory, 2) the prioritized fine grain direct hardware multiprogramming, 3) the
access controlled virtual addressing and 4) the hardware driven semaphores. The
composition of these features lets to introduce new styles of operating system
(OS) programming, which is free of interruptions, and of applied programming
with a very rare using the OS services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4053</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4053</id><created>2009-10-21</created><authors><author><keyname>Nizamani</keyname><forenames>Qurat ul Ain</forenames><affiliation>Department of Computer Science, University of Leicester, UK</affiliation></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames><affiliation>Department of Computer Science, University of Leicester, UK</affiliation></author></authors><title>Heuristic Methods for Security Protocols</title><categories>cs.CR cs.LO cs.PL</categories><journal-ref>EPTCS 7, 2009, pp. 61-75</journal-ref><doi>10.4204/EPTCS.7.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model checking is an automatic verification technique to verify hardware and
software systems. However it suffers from state-space explosion problem. In
this paper we address this problem in the context of cryptographic protocols by
proposing a security property-dependent heuristic. The heuristic weights the
state space by exploiting the security formulae; the weights may then be used
to explore the state space when searching for attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4056</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4056</id><created>2009-10-21</created><authors><author><keyname>Del Tedesco</keyname><forenames>Filippo</forenames><affiliation>Chalmers University of Technology, Gothenburg, Sweden</affiliation></author><author><keyname>Sands</keyname><forenames>David</forenames><affiliation>Chalmers University of Technology, Gothenburg, Sweden</affiliation></author></authors><title>A User Model for Information Erasure</title><categories>cs.CR cs.LO cs.PL</categories><journal-ref>EPTCS 7, 2009, pp. 16-30</journal-ref><doi>10.4204/EPTCS.7.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hunt and Sands (ESOP'08) studied a notion of information erasure for systems
which receive secrets intended for limited-time use. Erasure demands that once
a secret has fulfilled its purpose the subsequent behaviour of the system
should reveal no information about the erased data. In this paper we address a
shortcoming in that work: for erasure to be possible the user who provides data
must also play his part, but previously that role was only specified
informally. Here we provide a formal model of the user and a collection of
requirements called erasure friendliness. We prove that an erasure-friendly
user can be composed with an erasing system (in the sense of Hunt and Sands) to
obtain a combined system which is jointly erasing in an appropriate sense. In
doing so we identify stronger requirements on the user than those informally
described in the previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4081</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4081</id><created>2009-10-21</created><updated>2009-12-20</updated><authors><author><keyname>Ketema</keyname><forenames>Jeroen</forenames></author><author><keyname>Simonsen</keyname><forenames>Jakob Grue</forenames></author></authors><title>Infinitary Combinatory Reduction Systems: Confluence</title><categories>cs.LO cs.PL</categories><acm-class>D.3.1; F.3.2; F.4.1; F.4.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 4 (December
  20, 2009) lmcs:840</journal-ref><doi>10.2168/LMCS-5(4:3)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study confluence in the setting of higher-order infinitary rewriting, in
particular for infinitary Combinatory Reduction Systems (iCRSs). We prove that
fully-extended, orthogonal iCRSs are confluent modulo identification of
hypercollapsing subterms. As a corollary, we obtain that fully-extended,
orthogonal iCRSs have the normal form property and the unique normal form
property (with respect to reduction). We also show that, unlike the case in
first-order infinitary rewriting, almost non-collapsing iCRSs are not
necessarily confluent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4084</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4084</id><created>2009-10-20</created><authors><author><keyname>Bajaj</keyname><forenames>Chandrajit</forenames></author><author><keyname>Gillette</keyname><forenames>Andrew</forenames></author><author><keyname>Goswami</keyname><forenames>Samrat</forenames></author><author><keyname>Kwon</keyname><forenames>Bong June</forenames></author><author><keyname>Rivera</keyname><forenames>Jose</forenames></author></authors><title>Complementary Space for Enhanced Uncertainty and Dynamics Visualization</title><categories>cs.CG cs.GR</categories><comments>12 pages. To appear as a chapter in &quot;Topological Data Analysis and
  Visualization: Theory, Algorithms and Applications&quot;, Pascucci, Tricoche,
  Hagen, Tierny, Eds., Springer-Verlag, in publication, 2009</comments><acm-class>I.6.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given a computer model of a physical object, it is often quite difficult to
visualize and quantify any global effects on the shape representation caused by
local uncertainty and local errors in the data. This problem is further
amplified when dealing with hierarchical representations containing varying
levels of detail and / or shapes undergoing dynamic deformations. In this
paper, we compute, quantify and visualize the complementary topological and
geometrical features of 3D shape models, namely, the tunnels, pockets and
internal voids of the object. We find that this approach sheds a unique light
on how a model is affected by local uncertainty, errors or modifications and
show how the presence or absence of complementary shape features can be
essential to an object's structural form and function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4116</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4116</id><created>2009-10-21</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author></authors><title>Swarm Intelligence</title><categories>cs.NE cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biologically inspired computing is an area of computer science which uses the
advantageous properties of biological systems. It is the amalgamation of
computational intelligence and collective intelligence. Biologically inspired
mechanisms have already proved successful in achieving major advances in a wide
range of problems in computing and communication systems. The consortium of
bio-inspired computing are artificial neural networks, evolutionary algorithms,
swarm intelligence, artificial immune systems, fractal geometry, DNA computing
and quantum computing, etc. This article gives an introduction to swarm
intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4122</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4122</id><created>2009-10-21</created><updated>2011-11-15</updated><authors><author><keyname>Meka</keyname><forenames>Raghu</forenames></author><author><keyname>Zuckerman</keyname><forenames>David</forenames></author></authors><title>Pseudorandom Generators for Polynomial Threshold Functions</title><categories>cs.CC</categories><comments>Revision 5: Updated to the journal version to appear in SICOMP.
  Revision 4: Improves seed-length for halfspaces to O(log n + log^2(1/eps))
  (the change in analysis is minor: use INW PRG instead of Nisan's PRG).
  Revision 3: Fixed some more minor errors (mainly in proof of Theorem 4.3).
  Revision 2: Corrected the non-explicit bound to O(d log n + log(1/eps)) and
  some minor typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the natural question of constructing pseudorandom generators (PRGs)
for low-degree polynomial threshold functions (PTFs). We give a PRG with
seed-length log n/eps^{O(d)} fooling degree d PTFs with error at most eps.
Previously, no nontrivial constructions were known even for quadratic threshold
functions and constant error eps. For the class of degree 1 threshold functions
or halfspaces, we construct PRGs with much better dependence on the error
parameter eps and obtain a PRG with seed-length O(log n + log^2(1/eps)).
Previously, only PRGs with seed length O(log n log^2(1/eps)/eps^2) were known
for halfspaces. We also obtain PRGs with similar seed lengths for fooling
halfspaces over the n-dimensional unit sphere.
  The main theme of our constructions and analysis is the use of invariance
principles to construct pseudorandom generators. We also introduce the notion
of monotone read-once branching programs, which is key to improving the
dependence on the error rate eps for halfspaces. These techniques may be of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4128</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4128</id><created>2009-10-21</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Secure Communication in the Low-SNR Regime</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secrecy capacity of a multiple-antenna wiretap channel is studied in the low
signal-to-noise ratio (SNR) regime. Expressions for the first and second
derivatives of the secrecy capacity with respect to SNR at SNR = 0 are derived.
Transmission strategies required to achieve these derivatives are identified.
In particular, it is shown that it is optimal in the low-SNR regime to transmit
in the maximal-eigenvalue eigenspace of Phi = H_m* H_m - N_m/N_e H_e* H_e where
H_m and H_e denote the channel matrices associated with the legitimate receiver
and eavesdropper, respectively, and N_m and N_e are the noise variances at the
receiver and eavesdropper, respectively. Energy efficiency is analyzed by
finding the minimum bit energy required for secure and reliable communications,
and the wideband slope. Increased bit energy requirements under secrecy
constraints are quantified. Finally, the impact of fading is investigated, and
the benefits of fading in terms of energy efficiency are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4130</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4130</id><created>2009-10-21</created><updated>2009-10-22</updated><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>On the Achievable Throughput Region of Multiple-Access Fading Channels
  with QoS Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective capacity, which provides the maximum constant arrival rate that a
given service process can support while satisfying statistical delay
constraints, is analyzed in a multiuser scenario. In particular, we study the
achievable effective capacity region of the users in multiaccess fading
channels (MAC) in the presence of quality of service (QoS) constraints. We
assume that channel side information (CSI) is available at both the
transmitters and the receiver, and superposition coding technique with
successive decoding is used. When the power is fixed at the transmitters, we
show that varying the decoding order with respect to the channel state can
significantly increase the achievable throughput region. For a two-user case,
we obtain the optimal decoding strategy when the users have the same QoS
constraints. Meanwhile, it is shown that time-division multiple-access (TDMA)
can achieve better performance than superposition coding with fixed successive
decoding order at the receiver side for certain QoS constraints. For power and
rate adaptation, we determine the optimal power allocation policy with fixed
decoding order at the receiver side. Numerical results are provided to
demonstrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4132</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4132</id><created>2009-10-21</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Collaborative Relay Beamforming for Secrecy</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, collaborative use of relays to form a beamforming system with
the aid of perfect channel state information (CSI) and to provide
physical-layer security is investigated. In particular, a
decode-and-forward-based relay beamforming design subject to total and
individual relay power constraints is studied with the goal of maximizing the
secrecy rate. It is shown that the total power constraint leads to a
closed-form solution. The design under individual relay power constraints is
formulated as an optimization problem which is shown to be easily solved using
two different approaches, namely semidefinite programming and second-order cone
programming. Furthermore, a simplified and suboptimal technique which reduces
the computation complexity under individual power constraints is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4144</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4144</id><created>2009-10-21</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Biswas</keyname><forenames>Soma</forenames></author></authors><title>Digital Curvatures Applied to 3D Object Analysis and Recognition: A Case
  Study</title><categories>cs.CG cs.DM</categories><comments>10 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we propose using curvatures in digital space for 3D object
analysis and recognition. Since direct adjacency has only six types of digital
surface points in local configurations, it is easy to determine and classify
the discrete curvatures for every point on the boundary of a 3D object. Unlike
the boundary simplicial decomposition (triangulation), the curvature can take
any real value. It sometimes makes difficulties to find a right value for
threshold. This paper focuses on the global properties of categorizing
curvatures for small regions. We use both digital Gaussian curvatures and
digital mean curvatures to 3D shapes. This paper proposes a multi-scale method
for 3D object analysis and a vector method for 3D similarity classification. We
use these methods for face recognition and shape classification. We have found
that the Gaussian curvatures mainly describe the global features and average
characteristics such as the five regions of a human face. However, mean
curvatures can be used to find local features and extreme points such as nose
in 3D facial data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4172</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4172</id><created>2009-10-21</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>Piercing translates and homothets of a convex body</title><categories>cs.CG cs.DM</categories><comments>An earlier version of this manuscript appeared in ESA 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to a classical result of Gr\&quot;unbaum, the transversal number
$\tau(\F)$ of any family $\F$ of pairwise-intersecting translates or homothets
of a convex body $C$ in $\RR^d$ is bounded by a function of $d$. Denote by
$\alpha(C)$ (resp. $\beta(C)$) the supremum of the ratio of the transversal
number $\tau(\F)$ to the packing number $\nu(\F)$ over all families $\F$ of
translates (resp. homothets) of a convex body $C$ in $\RR^d$. Kim et al.
recently showed that $\alpha(C)$ is bounded by a function of $d$ for any convex
body $C$ in $\RR^d$, and gave the first bounds on $\alpha(C)$ for convex bodies
$C$ in $\RR^d$ and on $\beta(C)$ for convex bodies $C$ in the plane.
  Here we show that $\beta(C)$ is also bounded by a function of $d$ for any
convex body $C$ in $\RR^d$, and present new or improved bounds on both
$\alpha(C)$ and $\beta(C)$ for various convex bodies $C$ in $\RR^d$ for all
dimensions $d$. Our techniques explore interesting inequalities linking the
covering and packing densities of a convex body. Our methods for obtaining
upper bounds are constructive and lead to efficient constant-factor
approximation algorithms for finding a minimum-cardinality point set that
pierces a set of translates or homothets of a convex body.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4179</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4179</id><created>2009-10-21</created><authors><author><keyname>Gupta</keyname><forenames>Sounak</forenames></author><author><keyname>Paul</keyname><forenames>Goutam</forenames></author></authors><title>Revisiting Fermat's Factorization for the RSA Modulus</title><categories>cs.CR cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit Fermat's factorization method for a positive integer $n$ that is a
product of two primes $p$ and $q$. Such an integer is used as the modulus for
both encryption and decryption operations of an RSA cryptosystem. The security
of RSA relies on the hardness of factoring this modulus. As a consequence of
our analysis, two variants of Fermat's approach emerge. We also present a
comparison between the two methods' effective regions. Though our study does
not yield a new state-of-the-art algorithm for integer factorization, we
believe that it reveals some interesting observations that are open for further
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4186</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4186</id><created>2009-10-21</created><authors><author><keyname>Shiang</keyname><forenames>Hsien-Po</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Media-TCP: A Quality-Centric TCP-Friendly Congestion Control for
  Multimedia Transmission</title><categories>cs.NI cs.MM</categories><comments>15 pages, 8 figures, 4 tables, and 2 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a quality-centric congestion control for multimedia
streaming over IP networks, which we refer to as media-TCP. Unlike existing
congestion control schemes that adapt a user's sending rate merely to the
network condition, our solution adapts the sending rate to both the network
condition and the application characteristics by explicitly considering the
distortion impacts, delay deadlines, and interdependencies of different video
packet classes. Hence, our media-aware solution is able to provide differential
services for transmitting various packet classes and thereby, further improves
the multimedia streaming quality. We model this problem using a Finite-Horizon
Markov Decision Process (FHMDP) and determine the optimal congestion control
policy that maximizes the long-term multimedia quality, while adhering to the
horizon- TCP-friendliness constraint, which ensures long-term fairness with
existing TCP applications. We show that the FHMDP problem can be decomposed
into multiple optimal stopping problems, which admit a low-complexity
threshold-based solution. Moreover, unlike existing congestion control
approaches, which focus on maintaining throughput-based fairness among users,
the proposed media-TCP aims to achieve quality-based fairness among multimedia
users. We also derive sufficient conditions for multiple multimedia users to
achieve quality-based fairness using media-TCP congestion control. Our
simulation results show that the proposed media-TCP achieves more than 3dB
improvement in terms of PSNR over the conventional TCP congestion control
approaches, with the largest improvements observed for real-time streaming
applications requiring stringent playback delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4214</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4214</id><created>2009-10-21</created><authors><author><keyname>Ahmad</keyname><forenames>Sahand Haji Ali</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Wu</keyname><forenames>Yunnan</forenames></author></authors><title>Congestion games with resource reuse and applications in spectrum
  sharing</title><categories>cs.GT cs.MA</categories><comments>9 pages, 3 figures, International Conference on Game Theory for
  Networks (GameNets), May 2009, Istanbul, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider an extension to the classical definition of
congestion games (CG) in which multiple users share the same set of resources
and their payoff for using any resource is a function of the total number of
users sharing it. The classical congestion games enjoy some very appealing
properties, including the existence of a Nash equilibrium and that every
improvement path is finite and leads to such a NE (also called the finite
improvement property or FIP), which is also a local optimum to a potential
function. On the other hand, this class of games does not model well the
congestion or resource sharing in a wireless context, a prominent feature of
which is spatial reuse. What this translates to in the context of a congestion
game is that a users payoff for using a resource (interpreted as a channel) is
a function of the its number of its interfering users sharing that channel,
rather than the total number among all users. This makes the problem quite
different. We will call this the congestion game with resource reuse (CG-RR).
In this paper we study intrinsic properties of such a game; in particular, we
seek to address under what conditions on the underlying network this game
possesses the FIP or NE. We also discuss the implications of these results when
applied to wireless spectrum sharing
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4224</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4224</id><created>2009-10-22</created><updated>2010-02-24</updated><authors><author><keyname>Sherstov</keyname><forenames>Alexander A.</forenames></author></authors><title>Optimal bounds for sign-representing the intersection of two halfspaces
  by polynomials</title><categories>cs.CC</categories><comments>A few minor simplifications added</comments><journal-ref>In Proceedings of the 42nd ACM Symposium on Theory of Computing
  (STOC 2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The threshold degree of a function f:{0,1}^n-&gt;{-1,+1} is the least degree of
a real polynomial p with f(x)=sgn p(x). We prove that the intersection of two
halfspaces on {0,1}^n has threshold degree Omega(n), which matches the trivial
upper bound and completely answers a question due to Klivans (2002). The best
previous lower bound was Omega(sqrt n). Our result shows that the intersection
of two halfspaces on {0,1}^n only admits a trivial 2^{Theta(n)}-time learning
algorithm based on sign-representation by polynomials, unlike the advances
achieved in PAC learning DNF formulas and read-once Boolean formulas. The proof
introduces a new technique of independent interest, based on Fourier analysis
and matrix theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4266</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4266</id><created>2009-10-22</created><updated>2009-11-18</updated><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author></authors><title>The Partition Bound for Classical Communication Complexity and Query
  Complexity</title><categories>cs.CC</categories><comments>28 pages, ver. 2, added content</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe new lower bounds for randomized communication complexity and
query complexity which we call the partition bounds. They are expressed as the
optimum value of linear programs. For communication complexity we show that the
partition bound is stronger than both the rectangle/corruption bound and the
\gamma_2/generalized discrepancy bounds. In the model of query complexity we
show that the partition bound is stronger than the approximate polynomial
degree and classical adversary bounds. We also exhibit an example where the
partition bound is quadratically larger than polynomial degree and classical
adversary bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4292</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4292</id><created>2009-10-22</created><authors><author><keyname>Kostakos</keyname><forenames>Vassilis</forenames></author></authors><title>An empirical study of spatial and transpatial social networks using
  Bluetooth and Facebook</title><categories>cs.CY</categories><comments>17 pages,4 figures, 1 table</comments><journal-ref>IEEE SocialCom, p. 587-594, 2010</journal-ref><doi>10.1109/SocialCom.2010.181</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study provides insights into the quantitative similarities, differences
and relationships between users' spatial, face-to-face, urban social networks
and their transpatial, online counterparts. We explore and map the social ties
within a cohort of 2602 users, and how those ties are mediated via physical
co-presence and online tools. Our analysis focused on isolating two distinct
segments of the social network: one mediated by physical co-presence, and the
other mediated by Facebook. Our results suggest that as a whole the networks
exhibit homogeneous characteristics, but individuals' involvement in those
networks varies considerably. Furthermore this study provides a methodological
approach for jointly analysing spatial &amp; transpatial networks utilising
pervasive and ubiquitous technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4307</identifier>
 <datestamp>2011-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4307</id><created>2009-10-22</created><authors><author><keyname>Gasilov</keyname><forenames>N.</forenames></author><author><keyname>Amrahov</keyname><forenames>Sh. G.</forenames></author><author><keyname>Fatullayev</keyname><forenames>A. Golayoglu</forenames></author></authors><title>A Geometric Approach to Solve Fuzzy Linear Systems of Differential
  Equations</title><categories>cs.NA</categories><comments>13 pages, 3 figures</comments><acm-class>G.1.7; J.2</acm-class><journal-ref>Appl. Math. Inf. Sci. 5, 3 (2011) pp. 484-499</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, systems of linear differential equations with crisp real
coefficients and with initial condition described by a vector of fuzzy numbers
are studied. A new method based on the geometric representations of linear
transformations is proposed to find a solution. The most important difference
between this method and methods offered in previous papers is that the solution
is considered to be a fuzzy set of real vector-functions rather than a fuzzy
vector-function. Each member of the set satisfies the given system with a
certain possibility. It is shown that at any time the solution constitutes a
fuzzy region in the coordinate space, alfa-cuts of which are nested
parallelepipeds. Proposed method is illustrated on examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4325</identifier>
 <datestamp>2010-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4325</id><created>2009-10-22</created><updated>2010-05-18</updated><authors><author><keyname>Blackburn</keyname><forenames>Simon R.</forenames></author><author><keyname>Paterson</keyname><forenames>Maura B.</forenames></author><author><keyname>Stinson</keyname><forenames>Douglas R.</forenames></author></authors><title>Putting Dots in Triangles</title><categories>cs.DM</categories><comments>10 pages Minor rephrasing: final version to submit to journal.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a right-angled triangle of squares in a grid whose horizontal and
vertical sides are $n$ squares long, let N(n) denote the maximum number of dots
that can be placed into the cells of the triangle such that each row, each
column, and each diagonal parallel to the long side of the triangle contains at
most one dot. It has been proven that
  $N(n) = \lfloor \frac{2n+1}{3} \rfloor$.
  In this note, we give a new proof of this result using linear programming
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4336</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4336</id><created>2009-10-22</created><updated>2010-08-24</updated><authors><author><keyname>Forney</keyname><forenames>G. David</forenames><suffix>Jr</suffix></author></authors><title>Minimal realizations of linear systems: The &quot;shortest basis&quot; approach</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>20 pages. Final version, to appear in special issue of IEEE
  Transactions on Information Theory on &quot;Facets of coding theory: From
  algorithms to networks,&quot; dedicated to Ralf Koetter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a controllable discrete-time linear system C, a shortest basis for C is
a set of linearly independent generators for C with the least possible lengths.
A basis B is a shortest basis if and only if it has the predictable span
property (i.e., has the predictable delay and degree properties, and is
non-catastrophic), or alternatively if and only if it has the subsystem basis
property (for any interval J, the generators in B whose span is in J is a basis
for the subsystem C_J). The dimensions of the minimal state spaces and minimal
transition spaces of C are simply the numbers of generators in a shortest basis
B that are active at any given state or symbol time, respectively. A minimal
linear realization for C in controller canonical form follows directly from a
shortest basis for C, and a minimal linear realization for C in observer
canonical form follows directly from a shortest basis for the orthogonal system
C^\perp. This approach seems conceptually simpler than that of classical
minimal realization theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4342</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4342</id><created>2009-10-22</created><authors><author><keyname>Guttman</keyname><forenames>Joshua D.</forenames><affiliation>The MITRE Corporation and Worcester Polytechnic Institute</affiliation></author></authors><title>Fair Exchange in Strand Spaces</title><categories>cs.CR cs.PL</categories><journal-ref>EPTCS 7, 2009, pp. 46-60</journal-ref><doi>10.4204/EPTCS.7.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many cryptographic protocols are intended to coordinate state changes among
principals. Exchange protocols coordinate delivery of new values to the
participants, e.g. additions to the set of values they possess. An exchange
protocol is fair if it ensures that delivery of new values is balanced: If one
participant obtains a new possession via the protocol, then all other
participants will, too. Fair exchange requires progress assumptions, unlike
some other protocol properties. The strand space model is a framework for
design and verification of cryptographic protocols. A strand is a local
behavior of a single principal in a single session of a protocol. A bundle is a
partially ordered global execution built from protocol strands and adversary
activities. The strand space model needs two additions for fair exchange
protocols. First, we regard the state as a multiset of facts, and we allow
strands to cause changes in this state via multiset rewriting. Second, progress
assumptions stipulate that some channels are resilient-and guaranteed to
deliver messages-and some principals are assumed not to stop at certain
critical steps. This method leads to proofs of correctness that cleanly
separate protocol properties, such as authentication and confidentiality, from
invariants governing state evolution. G. Wang's recent fair exchange protocol
illustrates the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4353</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4353</id><created>2009-10-22</created><updated>2009-10-23</updated><authors><author><keyname>Terwijn</keyname><forenames>Sebastiaan A.</forenames><affiliation>University of Amsterdam</affiliation></author><author><keyname>Torenvliet</keyname><forenames>Leen</forenames><affiliation>University of Amsterdam</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Nonapproximablity of the Normalized Information Distance</title><categories>cs.CC cs.IT math.IT</categories><comments>LaTeX 8 pages, Submitted. 2nd version corrected some typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalized information distance (NID) uses the theoretical notion of
Kolmogorov complexity, which for practical purposes is approximated by the
length of the compressed version of the file involved, using a real-world
compression program. This practical application is called `normalized
compression distance' and it is trivially computable. It is a parameter-free
similarity measure based on compression, and is used in pattern recognition,
data mining, phylogeny, clustering, and classification. The complexity
properties of its theoretical precursor, the NID, have been open. We show that
the NID is neither upper semicomputable nor lower semicomputable up to any
reasonable precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4397</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4397</id><created>2009-10-22</created><updated>2013-06-25</updated><authors><author><keyname>Nowak</keyname><forenames>Robert D.</forenames></author></authors><title>The Geometry of Generalized Binary Search</title><categories>stat.ML cs.IT math.IT math.ST stat.TH</categories><comments>corrected typo in Thm 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of determining a binary-valued function
through a sequence of strategically selected queries. The focus is an algorithm
called Generalized Binary Search (GBS). GBS is a well-known greedy algorithm
for determining a binary-valued function through a sequence of strategically
selected queries. At each step, a query is selected that most evenly splits the
hypotheses under consideration into two disjoint subsets, a natural
generalization of the idea underlying classic binary search. This paper
develops novel incoherence and geometric conditions under which GBS achieves
the information-theoretically optimal query complexity; i.e., given a
collection of N hypotheses, GBS terminates with the correct function after no
more than a constant times log N queries. Furthermore, a noise-tolerant version
of GBS is developed that also achieves the optimal query complexity. These
results are applied to learning halfspaces, a problem arising routinely in
image processing and machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4420</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4420</id><created>2009-10-22</created><authors><author><keyname>Boreale</keyname><forenames>Michele</forenames></author><author><keyname>Kremer</keyname><forenames>Steve</forenames></author></authors><title>Proceedings 7th International Workshop on Security Issues in Concurrency</title><categories>cs.CR cs.LO cs.PL</categories><journal-ref>EPTCS 7, 2009</journal-ref><doi>10.4204/EPTCS.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 7th Workshop on Security Issues
in Concurrency (SecCo'09). The workshop was held in Bologna, Italy on September
5th 2009, as a satellite workshop of CONCUR'09. The aim of the SecCo workshop
series is to cover the gap between the security and the concurrency
communities. More precisely, the workshop promotes the exchange of ideas,
trying to focus on common interests and stimulating discussions on central
research questions. In particular, we called for papers dealing with security
issues (such as authentication, integrity, privacy, confidentiality, access
control, denial of service, service availability, safety aspects, fault
tolerance, trust, language-based security, probabilistic and information
theoretic models) in emerging fields like web services, mobile ad-hoc networks,
agent-based infrastructures, peer-to-peer systems, context-aware computing,
global/ubiquitous/pervasive computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4432</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4432</id><created>2009-10-23</created><authors><author><keyname>Iyer</keyname><forenames>K. Viswanathan</forenames></author><author><keyname>Reddy</keyname><forenames>K. R. Uday Kumar</forenames></author></authors><title>Wiener index of binomial trees and Fibonacci trees</title><categories>cs.DM</categories><comments>Accepted for publication in Int'l. J. Math. Engg. with Comp., Sept.
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a closed-form expression for the Wiener index of binomial trees. We
outline efficient algorithms for computing the Wiener indices of Fibonacci and
binary Fibonacci trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4455</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4455</id><created>2009-10-23</created><updated>2010-02-15</updated><authors><author><keyname>Diana</keyname><forenames>Remi</forenames></author><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author></authors><title>ECN verbose mode: a statistical method for network path congestion
  estimation</title><categories>cs.NI</categories><doi>10.1016/j.comnet.2011.04.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a simple and effective methodology to determine the
level of congestion in a network with an ECN-like marking scheme. The purpose
of the ECN bit is to notify TCP sources of an imminent congestion in order to
react before losses occur. However, ECN is a binary indicator which does not
reflect the congestion level (i.e. the percentage of queued packets) of the
bottleneck, thus preventing any adapted reaction. In this study, we use a
counter in place of the traditional ECN marking scheme to assess the number of
times a packet has crossed a congested router. Thanks to this simple counter,
we drive a statistical analysis to accurately estimate the congestion level of
each router on a network path. We detail in this paper an analytical method
validated by some preliminary simulations which demonstrate the feasibility and
the accuracy of the concept proposed. We conclude this paper with possible
applications and expected future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4500</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4500</id><created>2009-10-23</created><updated>2009-10-25</updated><authors><author><keyname>Masini</keyname><forenames>Andrea</forenames></author><author><keyname>Vigan&#xf2;</keyname><forenames>Luca</forenames></author><author><keyname>Volpe</keyname><forenames>Marco</forenames></author></authors><title>A History of Until</title><categories>cs.LO</categories><comments>24 pages, full version of paper at Methods for Modalities 2009
  (M4M-6)</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Until is a notoriously difficult temporal operator as it is both existential
and universal at the same time: A until B holds at the current time instant w
iff either B holds at w or there exists a time instant w' in the future at
which B holds and such that A holds in all the time instants between the
current one and w'. This &quot;ambivalent&quot; nature poses a significant challenge when
attempting to give deduction rules for until. In this paper, in contrast, we
make explicit this duality of until to provide well-behaved natural deduction
rules for linear-time logics by introducing a new temporal operator that allows
us to formalize the &quot;history&quot; of until, i.e., the &quot;internal&quot; universal
quantification over the time instants between the current one and w'. This
approach provides the basis for formalizing deduction systems for temporal
logics endowed with the until operator. For concreteness, we give here a
labeled natural deduction system for a linear-time logic endowed with the new
operator and show that, via a proper translation, such a system is also sound
and complete with respect to the linear temporal logic LTL with until.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4507</identifier>
 <datestamp>2010-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4507</id><created>2009-10-23</created><authors><author><keyname>Skipsey</keyname><forenames>Sam</forenames><affiliation>University of Glasgow, UK</affiliation></author><author><keyname>Ambrose-Griffith</keyname><forenames>David</forenames><affiliation>University of Durham, UK</affiliation></author><author><keyname>Cowan</keyname><forenames>Greig</forenames><affiliation>University of Edinburgh, UK</affiliation></author><author><keyname>Kenyon</keyname><forenames>Mike</forenames><affiliation>University of Glasgow, UK</affiliation></author><author><keyname>Richards</keyname><forenames>Orlando</forenames><affiliation>University of Edinburgh, UK</affiliation></author><author><keyname>Roffe</keyname><forenames>Phil</forenames><affiliation>University of Durham, UK</affiliation></author><author><keyname>Stewart</keyname><forenames>Graeme</forenames><affiliation>University of Glasgow, UK</affiliation></author></authors><title>ScotGrid: Providing an Effective Distributed Tier-2 in the LHC Era</title><categories>cs.DC</categories><comments>Preprint for 17th International Conference on Computing in High
  Energy and Nuclear Physics, 7 pages, 1 figure</comments><report-no>GLAS-PPE/2009-07</report-no><journal-ref>J.Phys.Conf.Ser.219:052014,2010</journal-ref><doi>10.1088/1742-6596/219/5/052014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ScotGrid is a distributed Tier-2 centre in the UK with sites in Durham,
Edinburgh and Glasgow. ScotGrid has undergone a huge expansion in hardware in
anticipation of the LHC and now provides more than 4MSI2K and 500TB to the LHC
VOs. Scaling up to this level of provision has brought many challenges to the
Tier-2 and we show in this paper how we have adopted new methods of organising
the centres, from fabric management and monitoring to remote management of
sites to management and operational procedures, to meet these challenges. We
describe how we have coped with different operational models at the sites,
where Glagsow and Durham sites are managed &quot;in house&quot; but resources at
Edinburgh are managed as a central university resource. This required the
adoption of a different fabric management model at Edinburgh and a special
engagement with the cluster managers. Challenges arose from the different job
models of local and grid submission that required special attention to resolve.
We show how ScotGrid has successfully provided an infrastructure for ATLAS and
LHCb Monte Carlo production. Special attention has been paid to ensuring that
user analysis functions efficiently, which has required optimisation of local
storage and networking to cope with the demands of user analysis. Finally,
although these Tier-2 resources are pledged to the whole VO, we have
established close links with our local physics user communities as being the
best way to ensure that the Tier-2 functions effectively as a part of the LHC
grid computing framework..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4510</identifier>
 <datestamp>2010-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4510</id><created>2009-10-23</created><authors><author><keyname>Skipsey</keyname><forenames>Sam</forenames><affiliation>University of Glasgow, UK</affiliation></author><author><keyname>Cowan</keyname><forenames>Greig</forenames><affiliation>University of Edinburgh, UK</affiliation></author><author><keyname>Kenyon</keyname><forenames>Mike</forenames><affiliation>University of Glasgow, UK</affiliation></author><author><keyname>Purdie</keyname><forenames>Stuart</forenames><affiliation>University of Glasgow, UK</affiliation></author><author><keyname>Stewart</keyname><forenames>Graeme</forenames><affiliation>University of Glasgow, UK</affiliation></author></authors><title>Optimised access to user analysis data using the gLite DPM</title><categories>cs.DC</categories><comments>8 pages, 9 figures, preprint for 17th International Conference on
  Computing in High Energy and Nuclear Physics</comments><journal-ref>J.Phys.Conf.Ser.219:062066,2010</journal-ref><doi>10.1088/1742-6596/219/6/062066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ScotGrid distributed Tier-2 now provides more that 4MSI2K and 500TB for
LHC computing, which is spread across three sites at Durham, Edinburgh and
Glasgow. Tier-2 sites have a dual role to play in the computing models of the
LHC VOs. Firstly, their CPU resources are used for the generation of Monte
Carlo event data. Secondly, the end user analysis data is distributed across
the grid to the site's storage system and held on disk ready for processing by
physicists' analysis jobs. In this paper we show how we have designed the
ScotGrid storage and data management resources in order to optimise access by
physicists to LHC data. Within ScotGrid, all sites use the gLite DPM storage
manager middleware. Using the EGEE grid to submit real ATLAS analysis code to
process VO data stored on the ScotGrid sites, we present an analysis of the
performance of the architecture at one site, and procedures that may be
undertaken to improve such. The results will be presented from the point of
view of the end user (in terms of number of events processed/second) and from
the point of view of the site, which wishes to minimise load and the impact
that analysis activity has on other users of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4518</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4518</id><created>2009-10-23</created><authors><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author><author><keyname>Wahlstrom</keyname><forenames>Magnus</forenames></author></authors><title>Preprocessing of Min Ones Problems: A Dichotomy</title><categories>cs.CC</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A parameterized problem consists of a classical problem and an additional
component, the so-called parameter. This point of view allows a formal
definition of preprocessing: Given a parameterized instance (I,k), a polynomial
kernelization computes an equivalent instance (I',k') of size and parameter
bounded by a polynomial in k. We give a complete classification of Min Ones
Constraint Satisfaction problems, i.e., Min Ones SAT(\Gamma), with respect to
admitting or not admitting a polynomial kernelization (unless NP \subseteq
coNP/poly). For this we introduce the notion of mergeability. If all relations
of the constraint language \Gamma are mergeable, then a new variant of
sunflower kernelization applies, based on non-zero-closed cores. We obtain a
kernel with O(k^{d+1}) variables and polynomial total size, where d is the
maximum arity of a constraint in \Gamma, comparing nicely with the bound of
O(k^{d-1}) vertices for the less general and arguably simpler d-Hitting Set
problem. Otherwise, any relation in \Gamma that is not mergeable permits us to
construct a log-cost selection formula, i.e., an n-ary selection formula with
O(log n) true local variables. From this we can construct our lower bound using
recent results by Bodlaender et al. as well as Fortnow and Santhanam, proving
that there is no polynomial kernelization, unless NP \subseteq coNP/poly and
the polynomial hierarchy collapses to the third level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4555</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4555</id><created>2009-10-23</created><authors><author><keyname>Ang</keyname><forenames>Thomas</forenames></author><author><keyname>Pighizzini</keyname><forenames>Giovanni</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Automata and Reduced Words in the Free Group</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider some questions about formal languages that arise when inverses of
letters, words and languages are defined. The reduced representation of a
language over the free monoid is its unique equivalent representation in the
free group. We show that the class of regular languages is closed under taking
the reduced representation, while the class of context-free languages is not.
We also give an upper bound on the state complexity of the reduced
representation of a regular language, and prove upper and lower bounds on the
length of the shortest reducible string in a regular language. Finally we show
that the set of all words which are equivalent to the words in a regular
language can be nonregular, and that regular languages are not closed under
taking a generalized form of the reduced representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4565</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4565</id><created>2009-10-23</created><updated>2010-06-01</updated><authors><author><keyname>Abraham</keyname><forenames>Uri</forenames></author></authors><title>Classification with Tarskian system executions (Bakery Algorithms as an
  example)</title><categories>cs.LO</categories><comments>The paper is withdrawn since an improved version is being submitted</comments><acm-class>D.2.4; D.3.1; D.4.1; F.3; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that predicate languages and their Tarskian structures have an
important place for the study of concurrency. The argument in our paper is
based on an example: we show that two seemingly dissimilar algorithms have a
common set of high-level properties, which reveals their affinity. The
algorithms are a variant of Lamport's Bakery Algorithm and the Ricart and
Agrawala algorithm. They seem different because one uses shared memory and the
other message passing for communication. Yet it is intuitively obvious that
they are in some sense very similar, and they belong to the same &quot;family of
Bakery Algorithms&quot;. The aim of this paper is to express in a formal way this
intuition that classifies the two algorithms together. For this aim of
expressing the abstract high level properties that are shared by the two
algorithms we use predicate languages and their Taskian structures. We find a
set of properties expressed in quantification language which are satisfied by
every Tarskian system execution that models a run by either one of the
protocols, and which is strong enough to ensure that the mutual exclusion
property holds in these runs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4568</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4568</id><created>2009-10-23</created><authors><author><keyname>Sriram</keyname><forenames>Ilango</forenames></author></authors><title>SPECI, a simulation tool exploring cloud-scale data centres</title><categories>cs.DC</categories><journal-ref>Ilango Sriram, SPECI, a Simulation Tool Exploring Cloud-Scale Data
  Centres, In: CloudCom 2009, LNCS 5931, pp. 381-392, 2009, M.G. Jaatun, G.
  Zhao, and C. Rong (Eds.), Springer-Verlag Berlin Heidelberg 2009</journal-ref><doi>10.1007/978-3-642-10665-1_35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a rapid increase in the size of data centres (DCs) used to provide
cloud computing services. It is commonly agreed that not all properties in the
middleware that manages DCs will scale linearly with the number of components.
Further, &quot;normal failure&quot; complicates the assessment of the per-formance of a
DC. However, unlike in other engineering domains, there are no well established
tools that allow the prediction of the performance and behav-iour of future
generations of DCs. SPECI, Simulation Program for Elastic Cloud
Infrastructures, is a simulation tool which allows exploration of aspects of
scaling as well as performance properties of future DCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4572</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4572</id><created>2009-10-23</created><authors><author><keyname>Bunn</keyname><forenames>Paul</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>Throughput in Asynchronous Networks</title><categories>cs.NI cs.DC</categories><acm-class>C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new, &quot;worst-case&quot; model for an asynchronous communication
network and investigate the simplest (yet central) task in this model, namely
the feasibility of end-to-end routing. Motivated by the question of how
successful a protocol can hope to perform in a network whose reliability is
guaranteed by as few assumptions as possible, we combine the main
&quot;unreliability&quot; features encountered in network models in the literature,
allowing our model to exhibit all of these characteristics simultaneously. In
particular, our model captures networks that exhibit the following properties:
1) On-line; 2) Dynamic Topology; 3)Distributed/Local Control 4) Asynchronous
Communication; 5) (Polynomially) Bounded Memory; 6) No Minimal Connectivity
Assumptions. In the confines of this network, we evaluate throughput
performance and prove matching upper and lower bounds. In particular, using
competitive analysis (perhaps somewhat surprisingly) we prove that the optimal
competitive ratio of any on-line protocol is 1/n (where n is the number of
nodes in the network), and then we describe a specific protocol and prove that
it is n-competitive. The model we describe in the paper and for which we
achieve the above matching upper and lower bounds for throughput represents the
&quot;worst-case&quot; network, in that it makes no reliability assumptions. In many
practical applications, the optimal competitive ratio of 1/n may be
unacceptable, and consequently stronger assumptions must be imposed on the
network to improve performance. However, we believe that a fundamental starting
point to understanding which assumptions are necessary to impose on a network
model, given some desired throughput performance, is to understand what is
achievable in the worst case for the simplest task (namely end-to-end routing).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4613</identifier>
 <datestamp>2009-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4613</id><created>2009-10-23</created><updated>2009-12-29</updated><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Fading Cognitive Multiple-Access Channels With Confidential Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, December
  2009. The material in this paper was presented in part at the Forty-Seventh
  Annual Allerton Conference on Communication, Control, and Computing,
  September 30-October 2, 2009, Monticello, Illinois</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The fading cognitive multiple-access channel with confidential messages
(CMAC-CM) is investigated, in which two users attempt to transmit common
information to a destination and user 1 also has confidential information
intended for the destination. User 1 views user 2 as an eavesdropper and wishes
to keep its confidential information as secret as possible from user 2. The
multiple-access channel (both the user-to-user channel and the
user-to-destination channel) is corrupted by multiplicative fading gain
coefficients in addition to additive white Gaussian noise. The channel state
information (CSI) is assumed to be known at both the users and the destination.
A parallel CMAC-CM with independent subchannels is first studied. The secrecy
capacity region of the parallel CMAC-CM is established, which yields the
secrecy capacity region of the parallel CMAC-CM with degraded subchannels.
Next, the secrecy capacity region is established for the parallel Gaussian
CMAC-CM, which is used to study the fading CMAC-CM. When both users know the
CSI, they can dynamically change their transmission powers with the channel
realization to achieve the optimal performance. The closed-form power
allocation function that achieves every boundary point of the secrecy capacity
region is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4618</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4618</id><created>2009-10-24</created><updated>2010-01-23</updated><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>A Game Theoretic Analysis of Incentives in Content Production and
  Sharing over Peer-to-Peer Networks</title><categories>cs.NI cs.GT</categories><comments>31 pages, 3 figures, 1 table</comments><journal-ref>IEEE Journal of Selected Topics in Signal Processing, vol. 4, no.
  4, pp. 704-717, Aug. 2010</journal-ref><doi>10.1109/JSTSP.2010.2048609</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User-generated content can be distributed at a low cost using peer-to-peer
(P2P) networks, but the free-rider problem hinders the utilization of P2P
networks. In order to achieve an efficient use of P2P networks, we investigate
fundamental issues on incentives in content production and sharing using game
theory. We build a basic model to analyze non-cooperative outcomes without an
incentive scheme and then use different game formulations derived from the
basic model to examine five incentive schemes: cooperative, payment, repeated
interaction, intervention, and enforced full sharing. The results of this paper
show that 1) cooperative peers share all produced content while non-cooperative
peers do not share at all without an incentive scheme; 2) a cooperative scheme
allows peers to consume more content than non-cooperative outcomes do; 3) a
cooperative outcome can be achieved among non-cooperative peers by introducing
an incentive scheme based on payment, repeated interaction, or intervention;
and 4) enforced full sharing has ambiguous welfare effects on peers. In
addition to describing the solutions of different formulations, we discuss
enforcement and informational requirements to implement each solution, aiming
to offer a guideline for protocol designers when designing incentive schemes
for P2P networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4624</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4624</id><created>2009-10-26</created><authors><author><keyname>Ryan</keyname><forenames>&#xd8;.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author></authors><title>Convolution operations arising from Vandermonde matrices</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. 16 pages, 1
  figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different types of convolution operations involving large Vandermonde
matrices are considered. The convolutions parallel those of large Gaussian
matrices and additive and multiplicative free convolution. First additive and
multiplicative convolution of Vandermonde matrices and deterministic diagonal
matrices are considered. After this, several cases of additive and
multiplicative convolution of two independent Vandermonde matrices are
considered. It is also shown that the convergence of any combination of
Vandermonde matrices is almost sure. We will divide the considered convolutions
into two types: those which depend on the phase distribution of the Vandermonde
matrices, and those which depend only on the spectra of the matrices. A general
criterion is presented to find which type applies for any given convolution. A
simulation is presented, verifying the results. Implementations of all
considered convolutions are provided and discussed, together with the
challenges in making these implementations efficient. The implementation is
based on the technique of Fourier-Motzkin elimination, and is quite general as
it can be applied to virtually any combination of Vandermonde matrices.
Generalizations to related random matrices, such as Toeplitz and Hankel
matrices, are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4627</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4627</id><created>2009-10-24</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Self-concordant analysis for logistic regression</title><categories>cs.LG math.ST stat.TH</categories><proxy>ccsd hal-00426227</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the non-asymptotic theoretical work in regression is carried out for
the square loss, where estimators can be obtained through closed-form
expressions. In this paper, we use and extend tools from the convex
optimization literature, namely self-concordant functions, to provide simple
extensions of theoretical results for the square loss to the logistic loss. We
apply the extension techniques to logistic regression with regularization by
the $\ell_2$-norm and regularization by the $\ell_1$-norm, showing that new
results for binary classification through logistic regression can be easily
derived from corresponding results for least-squares regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4632</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4632</id><created>2009-10-24</created><authors><author><keyname>Liu</keyname><forenames>Meicheng</forenames></author><author><keyname>Lin</keyname><forenames>Dongdai</forenames></author></authors><title>Fast Algebraic Attacks and Decomposition of Symmetric Boolean Functions</title><categories>cs.CR cs.IT math.IT</categories><comments>13 pages, submitted to IEEE Transactions on Information Theory</comments><acm-class>E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic and fast algebraic attacks are power tools to analyze stream
ciphers. A class of symmetric Boolean functions with maximum algebraic immunity
were found vulnerable to fast algebraic attacks at EUROCRYPT'06. Recently, the
notion of AAR (algebraic attack resistant) functions was introduced as a
unified measure of protection against both classical algebraic and fast
algebraic attacks. In this correspondence, we first give a decomposition of
symmetric Boolean functions, then we show that almost all symmetric Boolean
functions, including these functions with good algebraic immunity, behave badly
against fast algebraic attacks, and we also prove that no symmetric Boolean
functions are AAR functions. Besides, we improve the relations between
algebraic degree and algebraic immunity of symmetric Boolean functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4664</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4664</id><created>2009-10-24</created><authors><author><keyname>Yedidia</keyname><forenames>Adam B.</forenames></author></authors><title>Counting Independent Sets and Kernels of Regular Graphs</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chandrasekaran, Chertkov, Gamarnik, Shah, and Shin recently proved that the
average number of independent sets of random regular graphs of size n and
degree 3 approaches w^n for large n, where w is approximately 1.54563,
consistent with the Bethe approximation. They also made the surprising
conjecture that the fluctuations of the logarithm of the number of independent
sets were only O(1) as n grew large, which would mean that the Bethe
approximation is amazingly accurate for all 3-regular graphs. Here, I provide
numerical evidence supporting this conjecture obtained from exact counts of
independent sets using binary decision diagrams. I also provide numerical
evidence that supports the novel conjectures that the number of kernels of
3-regular graphs of size n is given by y^n, where y is approximately 1.299, and
that the fluctuations in the logarithm of the number of kernels is also only
O(1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4667</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4667</id><created>2009-10-24</created><authors><author><keyname>Kocak</keyname><forenames>Fatih</forenames></author><author><keyname>Celebi</keyname><forenames>Hasari</forenames></author><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Qaraqe</keyname><forenames>Khalid A.</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Time Delay Estimation in Cognitive Radio Systems</title><categories>cs.IT math.IT</categories><comments>To appear at CAMSAP 2009</comments><doi>10.1155/2010/675959</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio systems, secondary users can utilize multiple dispersed
bands that are not used by primary users. In this paper, time delay estimation
of signals that occupy multiple dispersed bands is studied. First, theoretical
limits on time delay estimation are reviewed. Then, two-step time delay
estimators that provide trade-offs between computational complexity and
performance are investigated. In addition, asymptotic optimality properties of
the two-step time delay estimators are discussed. Finally, simulation results
are presented to explain the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4668</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4668</id><created>2009-10-24</created><authors><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Lubicz</keyname><forenames>David</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Robert</keyname><forenames>Damien</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Computing modular correspondences for abelian varieties</title><categories>cs.SC</categories><proxy>ccsd hal-00426338</proxy><doi>10.1016/j.jalgebra.2011.06.031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to give a higher dimensional equivalent of the
classical modular polynomials $\Phi_\ell(X,Y)$. If $j$ is the $j$-invariant
associated to an elliptic curve $E_k$ over a field $k$ then the roots of
$\Phi_\ell(j,X)$ correspond to the $j$-invariants of the curves which are
$\ell$-isogeneous to $E_k$. Denote by $X_0(N)$ the modular curve which
parametrizes the set of elliptic curves together with a $N$-torsion subgroup.
It is possible to interpret $\Phi_\ell(X,Y)$ as an equation cutting out the
image of a certain modular correspondence $X_0(\ell) \to X_0(1) \times X_0(1)$
in the product $X_0(1) \times X_0(1)$. Let $g$ be a positive integer and
$\overn \in \N^g$. We are interested in the moduli space that we denote by
$\Mn$ of abelian varieties of dimension $g$ over a field $k$ together with an
ample symmetric line bundle $\pol$ and a symmetric theta structure of type
$\overn$. If $\ell$ is a prime and let $\overl=(\ell, ..., \ell)$, there exists
a modular correspondence $\Mln \to \Mn \times \Mn$. We give a system of
algebraic equations defining the image of this modular correspondence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4681</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4681</id><created>2009-10-24</created><updated>2011-07-25</updated><authors><author><keyname>Kelmans</keyname><forenames>Alexander</forenames></author></authors><title>Packing 3-vertex paths in claw-free graphs and related topics</title><categories>math.CO cs.DM</categories><comments>29 pages</comments><msc-class>05C10, 05C70, 90C27</msc-class><journal-ref>Discrete Applied Mathematics, 159 (2011) 112-127</journal-ref><doi>10.1016/j.dam.2010.05.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An L-factor of a graph G is a spanning subgraph of G whose every component is
a 3-vertex path. Let v(G) be the number of vertices of G and d(G) the
domination number of G. A claw is a graph with four vertices and three edges
incident to the same vertex. A graph is claw-free if it has no induced subgraph
isomorphic to a claw. Our results include the following. Let G be a 3-connected
claw-free graph, x a vertex in G, e = xy an edge in G, and P a 3-vertex path in
G. Then
  (a1) if v(G) = 0 mod 3, then G has an L-factor containing (avoiding) e, (a2)
if v(G) = 1 mod 3, then G - x has an L-factor, (a3) if v(G) = 2 mod 3, then G -
{x,y} has an L-factor, (a4) if v(G) = 0 mod 3 and G is either cubic or
4-connected, then G - P has an L-factor, (a5) if G is cubic with v(G) &gt; 5 and E
is a set of three edges in G, then G - E has an L-factor if and only if the
subgraph induced by E in G is not a claw and not a triangle, (a6) if v(G) = 1
mod 3, then G - {v,e} has an L-factor for every vertex v and every edge e in G,
(a7) if v(G) = 1 mod 3, then there exist a 4-vertex path N and a claw Y in G
such that G - N and G - Y have L-factors, and (a8) d(G) &lt; v(G)/3 +1 and if in
addition G is not a cycle and v(G) = 1 mod 3, then d(G) &lt; v(G)/3.
  We explore the relations between packing problems of a graph and its line
graph to obtain some results on different types of packings. We also discuss
relations between L-packing and domination problems as well as between induced
L-packings and the Hadwiger conjecture.
  Keywords: claw-free graph, cubic graph, vertex disjoint packing, edge
disjoint packing, 3-vertex factor, 3-vertex packing, path-factor, induced
packing, graph domination, graph minor, the Hadwiger conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4683</identifier>
 <datestamp>2010-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4683</id><created>2009-10-24</created><updated>2010-05-10</updated><authors><author><keyname>Zhdanov</keyname><forenames>Fedor</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Competing with Gaussian linear experts</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of online regression. We prove a theoretical bound on
the square loss of Ridge Regression. We do not make any assumptions about input
vectors or outcomes. We also show that Bayesian Ridge Regression can be thought
of as an online algorithm competing with all the Gaussian linear experts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4686</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4686</id><created>2009-10-24</created><updated>2010-06-03</updated><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose</forenames></author></authors><title>Moderate Deviations of the Random Riccati Equation</title><categories>math.PR cs.IT math.DS math.IT math.OC</categories><comments>Revised Version, 35 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the invariant filtering measures resulting from Kalman
filtering with intermittent observations (\cite{Bruno}), where the observation
arrival is modeled as a Bernoulli process. In \cite{Riccati-weakconv}, it was
shown that there exists a $\overline{\gamma}^{\{\scriptsize{sb}}}&gt;0$ such that
for every observation packet arrival probability $\overline{\gamma}$,
$\overline{\gamma}&gt;\overline{\gamma}^{\{\scriptsize{sb}}}&gt;0$, the sequence of
random conditional error covariance matrices converges in distribution to a
unique invariant distribution $\mathbb{\mu}^{\overline{\gamma}}$ (independent
of the filter initialization.) In this paper, we prove that, for controllable
and observable systems, $\overline{\gamma}^{\{\scriptsize{sb}}}=0$ and that, as
$\overline{\gamma}\uparrow 1$, the family
$\{\mathbb{\mu}^{\overline{\gamma}}\}_{\overline{\gamma}&gt;0}$ of invariant
distributions satisfies a moderate deviations principle (MDP) with a good rate
function $I$. The rate function $I$ is explicitly identified. In particular,
our results show:
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4688</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4688</id><created>2009-10-24</created><authors><author><keyname>Hadjiliadis</keyname><forenames>Olympia</forenames></author><author><keyname>Schaefer</keyname><forenames>Tobias</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Quickest detection in coupled systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 48th IEEE Conference on Decision and Control, Shanghai 2009
  December 16 - 18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the problem of quickest detection of signals in a coupled
system of N sensors, which receive continuous sequential observations from the
environment. It is assumed that the signals, which are modeled a general Ito
processes, are coupled across sensors, but that their onset times may differ
from sensor to sensor. The objective is the optimal detection of the first time
at which any sensor in the system receives a signal. The problem is formulated
as a stochastic optimization problem in which an extended average Kullback-
Leibler divergence criterion is used as a measure of detection delay, with a
constraint on the mean time between false alarms. The case in which the sensors
employ cumulative sum (CUSUM) strategies is considered, and it is proved that
the minimum of N CUSUMs is asymptotically optimal as the mean time between
false alarms increases without bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4698</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4698</id><created>2009-10-25</created><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author></authors><title>BQP and the Polynomial Hierarchy</title><categories>quant-ph cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationship between BQP and PH has been an open problem since the
earliest days of quantum computing. We present evidence that quantum computers
can solve problems outside the entire polynomial hierarchy, by relating this
question to topics in circuit complexity, pseudorandomness, and Fourier
analysis.
  First, we show that there exists an oracle relation problem (i.e., a problem
with many valid outputs) that is solvable in BQP, but not in PH. This also
yields a non-oracle relation problem that is solvable in quantum logarithmic
time, but not in AC0.
  Second, we show that an oracle decision problem separating BQP from PH would
follow from the Generalized Linial-Nisan Conjecture, which we formulate here
and which is likely of independent interest. The original Linial-Nisan
Conjecture (about pseudorandomness against constant-depth circuits) was
recently proved by Braverman, after being open for twenty years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4699</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4699</id><created>2009-10-24</created><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Fischer</keyname><forenames>Felix</forenames></author><author><keyname>Procaccia</keyname><forenames>Ariel D.</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Sum of Us: Strategyproof Selection from the Selectors</title><categories>cs.GT cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider directed graphs over a set of n agents, where an edge (i,j) is
taken to mean that agent i supports or trusts agent j. Given such a graph and
an integer k\leq n, we wish to select a subset of k agents that maximizes the
sum of indegrees, i.e., a subset of k most popular or most trusted agents. At
the same time we assume that each individual agent is only interested in being
selected, and may misreport its outgoing edges to this end. This problem
formulation captures realistic scenarios where agents choose among themselves,
which can be found in the context of Internet search, social networks like
Twitter, or reputation systems like Epinions.
  Our goal is to design mechanisms without payments that map each graph to a
k-subset of agents to be selected and satisfy the following two constraints:
strategyproofness, i.e., agents cannot benefit from misreporting their outgoing
edges, and approximate optimality, i.e., the sum of indegrees of the selected
subset of agents is always close to optimal. Our first main result is a
surprising impossibility: for k \in {1,...,n-1}, no deterministic strategyproof
mechanism can provide a finite approximation ratio. Our second main result is a
randomized strategyproof mechanism with an approximation ratio that is bounded
from above by four for any value of k, and approaches one as k grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4704</identifier>
 <datestamp>2012-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4704</id><created>2009-10-24</created><updated>2012-11-29</updated><authors><author><keyname>Park</keyname><forenames>Jihoon</forenames></author><author><keyname>Pawe&#x142;czak</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>&#x10c;abri&#x107;</keyname><forenames>Danijela</forenames></author></authors><title>Performance of Joint Spectrum Sensing and MAC Algorithms for
  Multichannel Opportunistic Spectrum Access Ad Hoc Networks</title><categories>cs.NI</categories><comments>43 pages, 14 figures. Includes a concluding discussion on the
  validity of the analytical model in P. Pawelczak, S. Pollin, H-S. W. So, A.
  Bahai, R.V. Prasad, R. Hekmat, Performance Analysis of Multichannel Medium
  Access Control Algorithms for Opportunistic Spectrum Access, IEEE
  Transactions on Vehicular Technology, vol. 58, no. 6, pp. 3014-3031, Jul.
  2009</comments><journal-ref>IEEE Transactions on Mobile Computing, vol. 10, no. 7, pp.
  1011-1027, 2011</journal-ref><doi>10.1109/TMC.2010.255</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytical framework to assess the link layer throughput of
multichannel Opportunistic Spectrum Access (OSA) ad hoc networks. Specifically,
we focus on analyzing various combinations of collaborative spectrum sensing
and Medium Access Control (MAC) protocol abstractions. We decompose
collaborative spectrum sensing into layers, parametrize each layer, classify
existing solutions, and propose a new protocol called Truncated Time Division
Multiple Access (TTDMA) that supports efficient distribution of sensing results
in &quot;k out of N&quot; fusion rule. In case of multichannel MAC protocols we evaluate
two main approaches of control channel design with (i) dedicated and (ii)
hopping channel. We propose to augment these protocols with options of handling
secondary user (SU) connections preempted by primary user (PU) by (i)
connection buffering until PU departure and (ii) connection switching to a
vacant PU channel. By comparing and optimizing different design combinations we
show that (i) it is generally better to buffer preempted SU connections than to
switch them to PU vacant channels and (ii) TTDMA is a promising design option
for collaborative spectrum sensing process when k does not change over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4711</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4711</id><created>2009-10-26</created><authors><author><keyname>Annaji</keyname><forenames>Rajashekar</forenames></author><author><keyname>Rao</keyname><forenames>Shrisha</forenames></author></authors><title>Parallelization of the LBG Vector Quantization Algorithm for Shared
  Memory Systems</title><categories>cs.CV cs.DC</categories><comments>14 pages</comments><acm-class>I.4.1; I.4.2; D.1.3</acm-class><journal-ref>International Journal of Image Processing, vol. 3, no. 4,
  July/August 2009, pp. 170-183</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a parallel approach for the Vector Quantization (VQ)
problem in image processing. VQ deals with codebook generation from the input
training data set and replacement of any arbitrary data with the nearest
codevector. Most of the efforts in VQ have been directed towards designing
parallel search algorithms for the codebook, and little has hitherto been done
in evolving a parallelized procedure to obtain an optimum codebook. This
parallel algorithm addresses the problem of designing an optimum codebook using
the traditional LBG type of vector quantization algorithm for shared memory
systems and for the efficient usage of parallel processors. Using the codebook
formed from a training set, any arbitrary input data is replaced with the
nearest codevector from the codebook. The effectiveness of the proposed
algorithm is indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4738</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4738</id><created>2009-10-25</created><authors><author><keyname>Ramponi</keyname><forenames>Federico</forenames></author><author><keyname>Chatterjee</keyname><forenames>Debasish</forenames></author><author><keyname>Summers</keyname><forenames>Sean</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>On the connections between PCTL and Dynamic Programming</title><categories>math.OC cs.SY</categories><comments>Submitted</comments><msc-class>60J10</msc-class><journal-ref>HSCC Stockholm, 2010, pages 253-262</journal-ref><doi>10.1145/1755952.1755988</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic Computation Tree Logic (PCTL) is a well-known modal logic which
has become a standard for expressing temporal properties of finite-state Markov
chains in the context of automated model checking. In this paper, we give a
definition of PCTL for noncountable-space Markov chains, and we show that there
is a substantial affinity between certain of its operators and problems of
Dynamic Programming. After proving some uniqueness properties of the solutions
to the latter, we conclude the paper with two examples to show that some
recovery strategies in practical applications, which are naturally stated as
reach-avoid problems, can be actually viewed as particular cases of PCTL
formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4748</identifier>
 <datestamp>2013-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4748</id><created>2009-10-25</created><updated>2013-04-19</updated><authors><author><keyname>Giacobazzi</keyname><forenames>Roberto</forenames></author><author><keyname>Ranzato</keyname><forenames>Francesco</forenames></author></authors><title>Correctness Kernels of Abstract Interpretations</title><categories>cs.PL cs.LO</categories><comments>An extended abstract of this paper appeared in Proceedings of the
  37th International Colloquium on Automata, Languages, and Programming (ICALP
  '10), Bordeaux, France. LNCS vol. 6199, pages 211-222, Springer, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In abstract interpretation-based static analysis, approximation is encoded by
abstract domains. They provide systematic guidelines for designing abstract
semantic functions that approximate some concrete system behaviors under
analysis. It may happen that an abstract domain contains redundant information
for the specific purpose of approximating a given concrete semantic function.
This paper introduces the notion of correctness kernel of abstract
interpretations, a methodology for simplifying abstract domains, i.e. removing
abstract values from them, in a maximal way while retaining exactly the same
approximate behavior of the system under analysis. We show that in abstract
model checking correctness kernels provide a simplification paradigm of the
abstract state space that is guided by examples, meaning that this
simplification preserves spuriousness of examples (i.e., abstract paths). In
particular, we show how correctness kernels can be integrated with the
well-known CEGAR (CounterExample-Guided Abstraction Refinement) methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4769</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4769</id><created>2009-10-25</created><authors><author><keyname>Harbaoui</keyname><forenames>Azza</forenames><affiliation>ENSI-Riadi-GDL</affiliation></author><author><keyname>Ghenima</keyname><forenames>Malek</forenames><affiliation>ENSI-Riadi-GDL</affiliation></author><author><keyname>Sidhom</keyname><forenames>Sahbi</forenames><affiliation>LORIA, Loria</affiliation></author></authors><title>Enrichissement des contenus par la r\'eindexation des usagers : un
  \'etat de l'art sur la probl\'ematique</title><categories>cs.IR</categories><proxy>ccsd inria-00426376</proxy><journal-ref>conf\'erence internationale sur les Syst\`emes d'information et
  Intelligence \'economique, Hammamet : Tunisie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information retrieval (IR) is a user approach to obtain relevant information
which meets needs with the help of a IR system (IRS). However, the IRS shows
certain differences between user relevance and system relevance. These gaps are
essentially related to the imperfection of the indexing process (as approach
related to the IR), to problems related to the misunderstanding of the natural
language and the non correspondence between the real needs of the user and the
results of his query. As idea is to think about an ?intellectual? indexing that
takes into account the point of view of the user. By consulting the document,
user can build information as added-value on the existing content: new
information which grows contents and allows the semantic visibility or
facilitates the reading by the annotations, by links to other content, by new
descriptors, specific new abstracts of users: it is the reindexing of the
contents by the contribution or the vote of the uses
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4836</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4836</id><created>2009-10-26</created><authors><author><keyname>Schubert</keyname><forenames>Gerald</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Fehske</keyname><forenames>Holger</forenames></author></authors><title>Performance limitations for sparse matrix-vector multiplications on
  current multicore environments</title><categories>cs.PF</categories><comments>16 pages, 9 figures</comments><journal-ref>High Performance Computing in Science and Engineering,
  Garching/Munich 2009. Springer, (2010), 13-26</journal-ref><doi>10.1007/978-3-642-13872-0_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing importance of multicore processors calls for a reevaluation of
established numerical algorithms in view of their ability to profit from this
new hardware concept. In order to optimize the existent algorithms, a detailed
knowledge of the different performance-limiting factors is mandatory. In this
contribution we investigate sparse matrix-vector multiplication, which is the
dominant operation in many sparse eigenvalue solvers. Two conceptually
different storage schemes and computational kernels have been conceived in the
past to target cache-based and vector architectures, respectively. Starting
from a series of microbenchmarks we apply the gained insight on optimized
sparse MVM implementations, whose serial and OpenMP-parallel performance we
review on state-of-the-art multicore systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4839</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4839</id><created>2009-10-26</created><updated>2009-11-03</updated><authors><author><keyname>Bradley</keyname><forenames>Patrick Erik</forenames></author></authors><title>A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting</title><categories>cs.CV</categories><comments>15 pages; typos removed, abstract changed, computation error removed</comments><journal-ref>p-Adic Numbers, Ultrametric Analysis, and Applications, Vol. 2,
  No. 1 (2010), 55-67</journal-ref><doi>10.1134/S2070046610010048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $p$-adic variation of the Ran(dom) Sa(mple) C(onsensus) method for solving
the relative pose problem in stereo vision is developped. From two 2-adically
encoded images a random sample of five pairs of corresponding points is taken,
and the equations for the essential matrix are solved by lifting solutions
modulo 2 to the 2-adic integers. A recently devised $p$-adic hierarchical
classification algorithm imitating the known LBG quantisation method classifies
the solutions for all the samples after having determined the number of
clusters using the known intra-inter validity of clusterings. In the successful
case, a cluster ranking will determine the cluster containing a 2-adic
approximation to the &quot;true&quot; solution of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4854</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4854</id><created>2009-10-26</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>She</keyname><forenames>Yingying</forenames></author></authors><title>Yet Another Pacman 3D Adventures</title><categories>cs.GR</categories><comments>31 pages, 8 figures. A 2006 report, corresponding to the open source
  project here: http://sourceforge.net/projects/yap3dad/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This game is meant to be extension of the overly-beaten pacman-style game
(code-named &quot;Yet Another Pacman 3D Adventures&quot;, or YAP3DAD) from the proposed
ideas and other projects with advance visual and computer graphics features,
including a-game-in-a-game approach. The project is an open-source project
published on SourceForge.net for possible future development and extension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4865</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4865</id><created>2009-10-26</created><authors><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Multi-core architectures: Complexities of performance prediction and the
  impact of cache topology</title><categories>cs.PF cs.AR</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The balance metric is a simple approach to estimate the performance of
bandwidth-limited loop kernels. However, applying the method to in-cache
situations and modern multi-core architectures yields unsatisfactory results.
This paper analyzes the in uence of cache hierarchy design on performance
predictions for bandwidth-limited loop kernels on current mainstream
processors. We present a diagnostic model with improved predictive power,
correcting the limitations of the simple balance metric. The importance of code
execution overhead even in bandwidth-bound situations is emphasized. Finally we
analyze the impact of synchronization overhead on multi-threaded performance
with a special emphasis on the in uence of cache topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4874</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4874</id><created>2009-10-26</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Vondrak</keyname><forenames>Jan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>K-User Fading Interference Channels: The Ergodic Very Strong Case</title><categories>cs.IT math.IT</categories><comments>Presented at the Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing, Sep. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sufficient conditions required to achieve the interference-free capacity
region of ergodic fading K-user interference channels (IFCs) are obtained. In
particular, this capacity region is shown to be achieved when every receiver
decodes all K transmitted messages such that the channel statistics and the
waterfilling power policies for all K (interference-free) links satisfy a set
of K(K-1) ergodic very strong conditions. The result is also of independent
interest in combinatorics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4899</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4899</id><created>2009-10-26</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dasgupta</keyname><forenames>Dipankar</forenames></author></authors><title>Artificial Immune Systems</title><categories>cs.AI cs.NE</categories><comments>29 pages,4 figures,</comments><journal-ref>Search Methodologies: Introductory Tutorials in Optimisation and
  Decision Support Techniques, 375-399, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The biological immune system is a robust, complex, adaptive system that
defends the body from foreign pathogens. It is able to categorize all cells (or
molecules) within the body as self-cells or non-self cells. It does this with
the help of a distributed task force that has the intelligence to take action
from a local and also a global perspective using its network of chemical
messengers for communication. There are two major branches of the immune
system. The innate immune system is an unchanging mechanism that detects and
destroys certain invading organisms, whilst the adaptive immune system responds
to previously unknown foreign cells and builds a response to them that can
remain in the body over a long period of time. This remarkable information
processing biological system has caught the attention of computer science in
recent years. A novel computational intelligence technique, inspired by
immunology, has emerged, called Artificial Immune Systems. Several concepts
from the immune have been extracted and applied for solution to real world
science and engineering problems. In this tutorial, we briefly describe the
immune system metaphors that are relevant to existing Artificial Immune Systems
methods. We will then show illustrative real-world problems suitable for
Artificial Immune Systems and give a step-by-step algorithm walkthrough for one
such problem. A comparison of the Artificial Immune Systems to other well-known
algorithms, areas for future work, tips &amp; tricks and a list of resources will
round this tutorial off. It should be noted that as Artificial Immune Systems
is still a young and evolving field, there is not yet a fixed algorithm
template and hence actual implementations might differ somewhat from time to
time and from those examples given here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4901</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4901</id><created>2009-10-26</created><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distortion Exponent in MIMO Channels with Feedback</title><categories>cs.IT math.IT</categories><comments>Presented at the IEEE Information Theory Workshop (ITW), Taormina,
  Italy, Oct. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transmission of a Gaussian source over a block-fading multiple antenna
channel in the presence of a feedback link is considered. The feedback link is
assumed to be an error and delay free link of capacity 1 bit per channel use.
Under the short-term power constraint, the optimal exponential behavior of the
end-to-end average distortion is characterized for all source-channel bandwidth
ratios. It is shown that the optimal transmission strategy is successive
refinement source coding followed by progressive transmission over the channel,
in which the channel block is allocated dynamically among the layers based on
the channel state using the feedback link as an instantaneous automatic repeat
request (ARQ) signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4903</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4903</id><created>2009-10-26</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author></authors><title>Articulation and Clarification of the Dendritic Cell Algorithm</title><categories>cs.AI cs.NE</categories><comments>14 pages, 4 figures, 5th International Conference on Artificial
  Immune Systems (ICARIS2006)</comments><journal-ref>Proceedings of 5th International Conference on Artificial Immune
  Systems (ICARIS2006), 404-417, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dendritic Cell algorithm (DCA) is inspired by recent work in innate
immunity. In this paper a formal description of the DCA is given. The DCA is
described in detail, and its use as an anomaly detector is illustrated within
the context of computer security. A port scan detection task is performed to
substantiate the influence of signal selection on the behaviour of the
algorithm. Experimental results provide a comparison of differing input signal
mappings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4932</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4932</id><created>2009-10-26</created><updated>2009-10-26</updated><authors><author><keyname>To</keyname><forenames>Anthony Widjaja</forenames></author><author><keyname>Libkin</keyname><forenames>Leonid</forenames></author></authors><title>Algorithmic metatheorems for decidable LTL model checking over infinite
  systems</title><categories>cs.LO</categories><comments>Conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By algorithmic metatheorems for a model checking problem P over
infinite-state systems we mean generic results that can be used to infer
decidability (possibly complexity) of P not only over a specific class of
infinite systems, but over a large family of classes of infinite systems. Such
results normally start with a powerful formalism of infinite-state systems,
over which P is undecidable, and assert decidability when is restricted by
means of an extra &quot;semantic condition&quot; C. We prove various algorithmic
metatheorems for the problems of model checking LTL and its two common
fragments LTL(Fs,Gs) and LTLdet over the expressive class of word/tree
automatic transition systems, which are generated by synchronized finite-state
transducers operating on finite words and trees. We present numerous
applications, where we derive (in a unified manner) many known and previously
unknown decidability and complexity results of model checking LTL and its
fragments over specific classes of infinite-state systems including pushdown
systems; prefix-recognizable systems; reversal-bounded counter systems with
discrete clocks and a free counter; concurrent pushdown systems with a bounded
number of context-switches; various subclasses of Petri nets; weakly extended
PA-processes; and weakly extended ground-tree rewrite systems. In all cases,we
are able to derive optimal (or near optimal) complexity. Finally, we pinpoint
the exact locations in the arithmetic and analytic hierarchies of the problem
of checking a relevant semantic condition and the LTL model checking problems
over all word/tree automatic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.4955</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.4955</id><created>2009-10-26</created><authors><author><keyname>Nayyar</keyname><forenames>Ashutosh</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>On the Structure of Real-Time Encoders and Decoders in a Multi-Terminal
  Communication System</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A real-time communication system with two encoders communicating with a
single receiver over separate noisy channels is considered. The two encoders
make distinct partial observations of a Markov source. Each encoder must encode
its observations into a sequence of discrete symbols. The symbols are
transmitted over noisy channels to a finite memory receiver that attempts to
reconstruct some function of the state of the Markov source. Encoding and
decoding must be done in real-time, that is, the distortion measure does not
tolerate delays. Under the assumption that the encoders' observations are
conditionally independent Markov chains given an unobserved time-invariant
random variable, results on the structure of optimal real-time encoders and the
receiver are obtained. It is shown that there exist finite-dimensional
sufficient statistics for the encoders. The problem with noiseless channels and
perfect memory at the receiver is then considered. A new methodology to find
the structure of optimal real-time encoders is employed. A sufficient statistic
with a time-invariant domain is found for this problem. This methodology
exploits the presence of common information between the encoders and the
receiver when communication is over noiseless channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5001</identifier>
 <datestamp>2015-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5001</id><created>2009-10-26</created><authors><author><keyname>Dodig-Crnkovic</keyname><forenames>Gordana</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Vincent C.</forenames></author></authors><title>A Dialogue Concerning Two World Systems: Info-Computational vs.
  Mechanistic</title><categories>cs.GL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dialogue develops arguments for and against adopting a new world system,
info-computationalist naturalism, that is poised to replace the traditional
mechanistic world system. We try to figure out what the info-computational
paradigm would mean, in particular its pancomputationalism. We make some steps
towards developing the notion of computing that is necessary here, especially
in relation to traditional notions. We investigate whether pancomputationalism
can possibly provide the basic causal structure to the world, whether the
overall research programme appears productive and whether it can revigorate
computationalism in the philosophy of mind.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5002</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5002</id><created>2009-10-26</created><authors><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author></authors><title>An Iterative Shrinkage Approach to Total-Variation Image Restoration</title><categories>cs.CV</categories><comments>The paper was submitted to the IEEE Transactions on Image Processing
  on October 22nd, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of restoration of digital images from their degraded measurements
plays a central role in a multitude of practically important applications. A
particularly challenging instance of this problem occurs in the case when the
degradation phenomenon is modeled by an ill-conditioned operator. In such a
case, the presence of noise makes it impossible to recover a valuable
approximation of the image of interest without using some a priori information
about its properties. Such a priori information is essential for image
restoration, rendering it stable and robust to noise. Particularly, if the
original image is known to be a piecewise smooth function, one of the standard
priors used in this case is defined by the Rudin-Osher-Fatemi model, which
results in total variation (TV) based image restoration. The current arsenal of
algorithms for TV-based image restoration is vast. In the present paper, a
different approach to the solution of the problem is proposed based on the
method of iterative shrinkage (aka iterated thresholding). In the proposed
method, the TV-based image restoration is performed through a recursive
application of two simple procedures, viz. linear filtering and soft
thresholding. Therefore, the method can be identified as belonging to the group
of first-order algorithms which are efficient in dealing with images of
relatively large sizes. Another valuable feature of the proposed method
consists in its working directly with the TV functional, rather then with its
smoothed versions. Moreover, the method provides a single solution for both
isotropic and anisotropic definitions of the TV functional, thereby
establishing a useful connection between the two formulae.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5027</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5027</id><created>2009-10-26</created><authors><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Mathur</keyname><forenames>Suhas</forenames></author><author><keyname>Reznik</keyname><forenames>Alex</forenames></author><author><keyname>Shah</keyname><forenames>Yogendra</forenames></author><author><keyname>Trappe</keyname><forenames>Wade</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author></authors><title>Information-theoretically Secret Key Generation for Fading Wireless
  Channels</title><categories>cs.CR cs.IT math.IT</categories><comments>32 pages, 9 figures. Manuscript first submitted to the IEEE
  Transactions on Information Forensics and Security on 23 February,
  2009.Portions of this work have been previous presented at the IEEE
  International Symposium on Information Theory, Seattle, WA, July 2006 and ACM
  Conference on Mobile Computing and Networking, San Francisco, CA, Sept. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multipath-rich wireless environment associated with typical wireless
usage scenarios is characterized by a fading channel response that is
time-varying, location-sensitive, and uniquely shared by a given
transmitter-receiver pair. The complexity associated with a richly scattering
environment implies that the short-term fading process is inherently hard to
predict and best modeled stochastically, with rapid decorrelation properties in
space, time and frequency. In this paper, we demonstrate how the channel state
between a wireless transmitter and receiver can be used as the basis for
building practical secret key generation protocols between two entities. We
begin by presenting a scheme based on level crossings of the fading process,
which is well-suited for the Rayleigh and Rician fading models associated with
a richly scattering environment. Our level crossing algorithm is simple, and
incorporates a self-authenticating mechanism to prevent adversarial
manipulation of message exchanges during the protocol. Since the level crossing
algorithm is best suited for fading processes that exhibit symmetry in their
underlying distribution, we present a second and more powerful approach that is
suited for more general channel state distributions. This second approach is
motivated by observations from quantizing jointly Gaussian processes, but
exploits empirical measurements to set quantization boundaries and a heuristic
log likelihood ratio estimate to achieve an improved secret key generation
rate. We validate both proposed protocols through experimentations using a
customized 802.11a platform, and show for the typical WiFi channel that
reliable secret key establishment can be accomplished at rates on the order of
10 bits/second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5040</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5040</id><created>2009-10-27</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Liu</keyname><forenames>Yong</forenames></author><author><keyname>Luo</keyname><forenames>Feng</forenames></author></authors><title>A Note on Gradually Varied Functions and Harmonic Functions</title><categories>cs.DM math.CA</categories><comments>7 pages and 2 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Any constructive continuous function must have a gradually varied
approximation in compact space. However, the refinement of domain for
$\sigma-$-net might be very small. Keeping the original discretization (square
or triangulation), can we get some interesting properties related to gradual
variation? In this note, we try to prove that many harmonic functions are
gradually varied or near gradually varied; this means that the value of the
center point differs from that of its neighbor at most by 2. It is obvious that
most of the gradually varied functions are not harmonic.This note discusses
some of the basic harmonic functions in relation to gradually varied functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5046</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5046</id><created>2009-10-27</created><authors><author><keyname>Visan</keyname><forenames>Ana Maria</forenames></author><author><keyname>Polyakov</keyname><forenames>Artem</forenames></author><author><keyname>Solanki</keyname><forenames>Praveen S.</forenames></author><author><keyname>Arya</keyname><forenames>Kapil</forenames></author><author><keyname>Denniston</keyname><forenames>Tyler</forenames></author><author><keyname>Cooperman</keyname><forenames>Gene</forenames></author></authors><title>Temporal Debugging using URDB</title><categories>cs.OS cs.SE</categories><comments>20 pages, 3 figures, 5 tables; software at urdb.sourceforge.net</comments><acm-class>D.2.5; D.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new style of temporal debugging is proposed. The new URDB debugger can
employ such techniques as temporal search for finding an underlying fault that
is causing a bug. This improves on the standard iterative debugging style,
which iteratively re-executes a program under debugger control in the search
for the underlying fault. URDB acts as a meta-debugger, with current support
for four widely used debuggers: gdb, MATLAB, python, and perl. Support for a
new debugger can be added in a few hours. Among its points of novelty are: (i)
the first reversible debuggers for MATLAB, python, and perl; (ii) support for
today's multi-core architectures; (iii) reversible debugging of multi-process
and distributed computations; and (iv) temporal search on changes in program
expressions. URDB gains its reversibility and temporal abilities through the
fast checkpoint-restart capability of DMTCP (Distributed MultiThreaded
CheckPointing). The recently enhanced DMTCP also adds ptrace support, enabling
one to freeze, migrate, and replicate debugging sessions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5073</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5073</id><created>2009-10-27</created><updated>2010-11-06</updated><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Wong</keyname><forenames>Wing Shing</forenames></author><author><keyname>Chen</keyname><forenames>Chung Shue</forenames></author></authors><title>A General Upper Bound on the Size of Constant-Weight Conflict-Avoiding
  Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 56, no.7, p.3265-3276, Jul, 2010</journal-ref><doi>10.1109/TIT.2010.2048508</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conflict-avoiding codes are used in the multiple-access collision channel
without feedback. The number of codewords in a conflict-avoiding code is the
number of potential users that can be supported in the system. In this paper, a
new upper bound on the size of conflict-avoiding codes is proved. This upper
bound is general in the sense that it is applicable to all code lengths and all
Hamming weights. Several existing constructions for conflict-avoiding codes,
which are known to be optimal for Hamming weights equal to four and five, are
shown to be optimal for all Hamming weights in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5076</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5076</id><created>2009-10-27</created><updated>2010-06-28</updated><authors><author><keyname>Takahashi</keyname><forenames>Hayato</forenames></author></authors><title>Algorithmic randomness and monotone complexity on product space</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study algorithmic randomness and monotone complexity on product of the set
of infinite binary sequences. We explore the following problems: monotone
complexity on product space, Lambalgen's theorem for correlated probability,
classification of random sets by likelihood ratio tests, decomposition of
complexity and independence, Bayesian statistics for individual random
sequences. Formerly Lambalgen's theorem for correlated probability is shown
under a uniform computability assumption in [H. Takahashi Inform. Comp. 2008].
In this paper we show the theorem without the assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5099</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5099</id><created>2009-10-27</created><authors><author><keyname>Chevalier</keyname><forenames>Yannick</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author><author><keyname>Rusinowitch</keyname><forenames>Michael</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author></authors><title>Compiling and securing cryptographic protocols</title><categories>cs.LO</categories><comments>A short version was submitted to IPL</comments><proxy>ccsd inria-00426669</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protocol narrations are widely used in security as semi-formal notations to
specify conversations between roles. We define a translation from a protocol
narration to the sequences of operations to be performed by each role. Unlike
previous works, we reduce this compilation process to well-known decision
problems in formal protocol analysis. This allows one to define a natural
notion of prudent translation and to reuse many known results from the
literature in order to cover more crypto-primitives. In particular this work is
the first one to show how to compile protocols parameterised by the properties
of the available operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5107</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5107</id><created>2009-10-27</created><updated>2010-01-20</updated><authors><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>The Complexity of Iterated Strategy Elimination</title><categories>cs.CC cs.GT</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the computational complexity of the question whether a certain
strategy can be removed from a game by means of iterated elimination of
dominated strategies. In particular, we study the influence of different
definitions of domination and of the number of different payoff values. In
addition, the consequence of restriction to constant-sum games is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5135</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5135</id><created>2009-10-27</created><authors><author><keyname>Manin</keyname><forenames>Yuri I.</forenames></author><author><keyname>Marcolli</keyname><forenames>Matilde</forenames></author></authors><title>Error-correcting codes and phase transitions</title><categories>cs.IT math.IT math.QA</categories><comments>amstex 57 pages, 3 eps figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of error-correcting codes is concerned with constructing codes
that optimize simultaneously transmission rate and relative minimum distance.
These conflicting requirements determine an asymptotic bound, which is a
continuous curve in the space of parameters. The main goal of this paper is to
relate the asymptotic bound to phase diagrams of quantum statistical mechanical
systems. We first identify the code parameters with Hausdorff and von Neumann
dimensions, by considering fractals consisting of infinite sequences of code
words. We then construct operator algebras associated to individual codes.
These are Toeplitz algebras with a time evolution for which the KMS state at
critical temperature gives the Hausdorff measure on the corresponding fractal.
We extend this construction to algebras associated to limit points of codes,
with non-uniform multi-fractal measures, and to tensor products over varying
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5146</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5146</id><created>2009-10-27</created><updated>2010-05-01</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author><author><keyname>Willett</keyname><forenames>Rebecca M.</forenames></author><author><keyname>Harmany</keyname><forenames>Zachary T.</forenames></author><author><keyname>Marcia</keyname><forenames>Roummel F.</forenames></author></authors><title>Compressed sensing performance bounds under Poisson noise</title><categories>cs.IT math.IT</categories><comments>12 pages, 3 pdf figures; accepted for publication in IEEE
  Transactions on Signal Processing</comments><doi>10.1109/TSP.2010.2049997</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes performance bounds for compressed sensing (CS) where the
underlying sparse or compressible (sparsely approximable) signal is a vector of
nonnegative intensities whose measurements are corrupted by Poisson noise. In
this setting, standard CS techniques cannot be applied directly for several
reasons. First, the usual signal-independent and/or bounded noise models do not
apply to Poisson noise, which is non-additive and signal-dependent. Second, the
CS matrices typically considered are not feasible in real optical systems
because they do not adhere to important constraints, such as nonnegativity and
photon flux preservation. Third, the typical $\ell_2$--$\ell_1$ minimization
leads to overfitting in the high-intensity regions and oversmoothing in the
low-intensity areas. In this paper, we describe how a feasible positivity- and
flux-preserving sensing matrix can be constructed, and then analyze the
performance of a CS reconstruction approach for Poisson data that minimizes an
objective function consisting of a negative Poisson log likelihood term and a
penalty term which measures signal sparsity. We show that, as the overall
intensity of the underlying signal increases, an upper bound on the
reconstruction error decays at an appropriate rate (depending on the
compressibility of the signal), but that for a fixed signal intensity, the
signal-dependent part of the error bound actually grows with the number of
measurements or sensors. This surprising fact is both proved theoretically and
justified based on physical intuition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5147</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5147</id><created>2009-10-27</created><authors><author><keyname>Fountoulakis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Panagiotou</keyname><forenames>Konstantinos</forenames></author></authors><title>Sharp Load Thresholds for Cuckoo Hashing</title><categories>cs.DS cs.DM math.CO math.PR</categories><comments>26 pages</comments><acm-class>E.2; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paradigm of many choices has influenced significantly the design of
efficient data structures and, most notably, hash tables. Cuckoo hashing is a
technique that extends this concept. There,we are given a table with $n$
locations, and we assume that each location can hold one item. Each item to be
inserted chooses randomly k&gt;1 locations and has to be placed in any one of
them. How much load can cuckoo hashing handle before collisions prevent the
successful assignment of the available items to the chosen locations? Practical
evaluations of this method have shown that one can allocate a number of
elements that is a large proportion of the size of the table, being very close
to 1 even for small values of k such as 4 or 5.
  In this paper we show that there is a critical value for this proportion:
with high probability, when the amount of available items is below this value,
then these can be allocated successfully, but when it exceeds this value, the
allocation becomes impossible. We give explicitly for each k&gt;1 this critical
value. This answers an open question posed by Mitzenmacher (ESA '09) and
underpins theoretically the experimental results. Our proofs are based on the
translation of the question into a hypergraph setting, and the study of the
related typical properties of random k-uniform hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5215</identifier>
 <datestamp>2009-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5215</id><created>2009-10-27</created><authors><author><keyname>Fan</keyname><forenames>Shuai</forenames></author><author><keyname>Zhang</keyname><forenames>Lin</forenames></author><author><keyname>Ren</keyname><forenames>Yong</forenames></author></authors><title>Approximation Algorithms for Link Scheduling with Physical Interference
  Model in Wireless Multi-hop Networks</title><categories>cs.NI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The link scheduling in wireless multi-hop networks is addressed. Different
from most of work that adopt the protocol interference model which merely take
consideration of packet collisions, our proposed algorithms use the physical
interference model to reflect the aggregated signal to interference and noise
ratio (SINR), which is a more accurate abstraction of the real scenario. We
first propose a centralized scheduling method based on the Integer Linear
Programming (ILP) and resolve it by an approximate solution based on the
randomized rounding method. The probability bound of getting a guaranteed
approximate factor is given. We then extend the centralized algorithm to a
distributed solution, which is favorable in wireless networks. It is proven
that with the distributed scheduling method, all links can transmit without
interference, and the approximate ratio of the algorithm is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5260</identifier>
 <datestamp>2013-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5260</id><created>2009-10-27</created><updated>2009-11-03</updated><authors><author><keyname>Keshavan</keyname><forenames>Raghunandan H.</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author></authors><title>A Gradient Descent Algorithm on the Grassman Manifold for Matrix
  Completion</title><categories>cs.NA cs.LG</categories><comments>26 pages, 15 figures</comments><doi>10.1016/j.trc.2012.12.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstructing a low-rank matrix from a small
subset of its entries. In this paper, we describe the implementation of an
efficient algorithm called OptSpace, based on singular value decomposition
followed by local manifold optimization, for solving the low-rank matrix
completion problem. It has been shown that if the number of revealed entries is
large enough, the output of singular value decomposition gives a good estimate
for the original matrix, so that local optimization reconstructs the correct
matrix with high probability. We present numerical results which show that this
algorithm can reconstruct the low rank matrix exactly from a very small subset
of its entries. We further study the robustness of the algorithm with respect
to noise, and its performance on actual collaborative filtering datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5261</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5261</id><created>2009-10-27</created><authors><author><keyname>Ozyesil</keyname><forenames>Onur</forenames></author><author><keyname>Mihcak</keyname><forenames>M. Kivanc</forenames></author><author><keyname>Altug</keyname><forenames>Yucel</forenames></author></authors><title>On Detection With Partial Information In The Gaussian Setup</title><categories>cs.IT cs.CR math.IT</categories><comments>Proceedings of the Forty-Seventh Annual Allerton Conference on
  Communication, Control, and Computing, September 30-October 2, 2009,
  Monticello, Illinois; 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the problem of communication with partial information, where
there is an asymmetry between the transmitter and the receiver codebooks.
Practical applications of the proposed setup include the robust signal hashing
problem within the context of multimedia security and asymmetric communications
with resource-lacking receivers. We study this setup in a binary detection
theoretic context for the additive colored Gaussian noise channel. In our
proposed setup, the partial information available at the detector consists of
dimensionality-reduced versions of the transmitter codewords, where the
dimensionality reduction is achieved via a linear transform. We first derive
the corresponding MAP-optimal detection rule and the corresponding conditional
probability of error (conditioned on the partial information the detector
possesses). Then, we constructively quantify an optimal class of linear
transforms, where the cost function is the expected Chernoff bound on the
conditional probability of error of the MAP-optimal detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5264</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5264</id><created>2009-10-27</created><authors><author><keyname>Nayyar</keyname><forenames>Ashutosh</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>A Sequential Problem in Decentralized Detection with Communication</title><categories>math.OC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sequential problem in decentralized detection is considered. Two observers
can make repeated noisy observations of a binary hypothesis on the state of the
environment. At any time, observer 1 can stop and send a final binary message
to observer 2 or it may continue to take more measurements. Every time observer
1 postpones its final message to observer 2, it incurs a penalty. Observer 2's
operation under two different scenarios is explored. In the first scenario,
observer 2 waits to receive the final message from observer 1 and then starts
taking measurements of its own. It is then faced with a stopping problem on
whether to stop and declare a decision on the hypothesis or to continue taking
measurements. In the second scenario, observer 2 starts taking measurements
from the beginning. It is then faced with a different stopping problem. At any
time, observer 2 can decide whether to stop and declare a decision on the
hypothesis or to continue to take more measurements and wait for observer 1 to
send its final message. Parametric characterization of optimal policies for the
two observers are obtained under both scenarios. A sequential methodology for
finding the optimal policies is presented. The parametric characterizations are
then extended to problem with increased communication alphabet for the final
message from observer 1 to observer 2; and to the case of multiple peripheral
sensors that each send a single final message to a coordinating sensor who
makes the final decision on the hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5301</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5301</id><created>2009-10-28</created><updated>2014-04-16</updated><authors><author><keyname>Kumar</keyname><forenames>Abhinav</forenames></author><author><keyname>Lokam</keyname><forenames>Satyanarayana V.</forenames></author><author><keyname>Patankar</keyname><forenames>Vijay M.</forenames></author><author><keyname>N</keyname><forenames>Jayalal Sarma M.</forenames></author></authors><title>Using Elimination Theory to construct Rigid Matrices</title><categories>cs.CC math.AG</categories><comments>25 Pages, minor typos corrected</comments><journal-ref>Computational Complexity 23 (2014), 531-563</journal-ref><doi>10.1007/s00037-013-0061-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rigidity of a matrix A for target rank r is the minimum number of entries
of A that must be changed to ensure that the rank of the altered matrix is at
most r. Since its introduction by Valiant (1977), rigidity and similar
rank-robustness functions of matrices have found numerous applications in
circuit complexity, communication complexity, and learning complexity. Almost
all nxn matrices over an infinite field have a rigidity of (n-r)^2. It is a
long-standing open question to construct infinite families of explicit matrices
even with superlinear rigidity when r = Omega(n).
  In this paper, we construct an infinite family of complex matrices with the
largest possible, i.e., (n-r)^2, rigidity. The entries of an n x n matrix in
this family are distinct primitive roots of unity of orders roughly exp(n^2 log
n). To the best of our knowledge, this is the first family of concrete (but not
entirely explicit) matrices having maximal rigidity and a succinct algebraic
description.
  Our construction is based on elimination theory of polynomial ideals. In
particular, we use results on the existence of polynomials in elimination
ideals with effective degree upper bounds (effective Nullstellensatz). Using
elementary algebraic geometry, we prove that the dimension of the affine
variety of matrices of rigidity at most k is exactly n^2-(n-r)^2+k. Finally, we
use elimination theory to examine whether the rigidity function is
semi-continuous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5339</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5339</id><created>2009-10-28</created><authors><author><keyname>Sarikaya</keyname><forenames>Yunus</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>On Physically Secure and Stable Slotted ALOHA System</title><categories>cs.IT math.IT</categories><comments>7 Pages, 8 Figures, Allerton 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we consider the standard discrete-time slotted ALOHA with a
finite number of terminals with infinite size buffers. In our study, we jointly
consider the stability of this system together with the physical layer
security. We conduct our studies on both dominant and original systems, where
in a dominant system each terminal always has a packet in its buffer unlike in
the original system. For N = 2, we obtain the secrecy-stability regions for
both dominant and original systems. Furthermore, we obtain the transmission
probabilities, which optimize system throughput. Lastly, this paper proposes a
new methodology in terms of obtaining the joint stability and secrecy regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5370</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5370</id><created>2009-10-27</created><authors><author><keyname>Shumow</keyname><forenames>Daniel</forenames></author></authors><title>Isogenies of Elliptic Curves: A Computational Approach</title><categories>cs.CR cs.MS</categories><comments>Submitted as a Masters Thesis in the Mathematics department of the
  University of Washington</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isogenies, the mappings of elliptic curves, have become a useful tool in
cryptology. These mathematical objects have been proposed for use in computing
pairings, constructing hash functions and random number generators, and
analyzing the reducibility of the elliptic curve discrete logarithm problem.
With such diverse uses, understanding these objects is important for anyone
interested in the field of elliptic curve cryptography. This paper, targeted at
an audience with a knowledge of the basic theory of elliptic curves, provides
an introduction to the necessary theoretical background for understanding what
isogenies are and their basic properties. This theoretical background is used
to explain some of the basic computational tasks associated with isogenies.
Herein, algorithms for computing isogenies are collected and presented with
proofs of correctness and complexity analyses. As opposed to the complex
analytic approach provided in most texts on the subject, the proofs in this
paper are primarily algebraic in nature. This provides alternate explanations
that some with a more concrete or computational bias may find more clear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5380</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5380</id><created>2009-10-28</created><updated>2011-10-09</updated><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Chitnis</keyname><forenames>Rajesh</forenames></author><author><keyname>Kumar</keyname><forenames>Ramanjit</forenames></author></authors><title>On the SIG dimension of trees under $L_{\infty}$ metric</title><categories>math.CO cs.DM cs.DS</categories><comments>24 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the $SIG$ dimension of trees under $L_{\infty}$ metric and answer an
open problem posed by Michael and Quint (Discrete Applied Mathematics: 127,
pages 447-460, 2003). Let $T$ be a tree with atleast two vertices. For each
$v\in V(T)$, let leaf-degree$(v)$ denote the number of neighbours of $v$ that
are leaves. We define the maximum leaf-degree as $\alpha(T) = \max_{x \in
V(T)}$ leaf-degree$(x)$. Let $S = \{v\in V(T) |$ leaf-degree$(v) = \alpha\}$.
If $|S| = 1$, we define $\beta(T) = \alpha(T) - 1$. Otherwise define $\beta(T)
= \alpha(T)$. We show that for a tree $T$, $SIG_\infty(T) = \lceil \log_2(\beta
+ 2)\rceil$ where $\beta = \beta (T)$, provided $\beta$ is not of the form $2^k
- 1$, for some positive integer $k \geq 1$. If $\beta = 2^k - 1$, then
$SIG_\infty (T) \in \{k, k+1\}$. We show that both values are possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5386</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5386</id><created>2009-10-28</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author></authors><title>A theoretical foundation for building Knowledge-work Support Systems</title><categories>cs.HC cs.DL cs.IR</categories><comments>40 pages, Created June 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel approach aimed at building a new class of
information system platforms which we call the &quot;Knowledge-work Support Systems&quot;
or KwSS. KwSS can play a significant role in enhancing the IS support for
knowledge management processes, including those customarily identified as less
amenable to IS support. In our approach we try to enhance basic functionalities
provided by the computer-based information systems, namely, that of improving
the efficiency of the knowledge workers in accessing, processing and creating
useful information. The improvement, along with proper focus on cultural,
social and other aspects of the knowledge management processes, can enhance the
workers' efficiency significantly in performing high quality knowledge works.
In order to build the proposed approach, we develop several new concepts. The
approach analyzes the information availability and usage from the knowledge
workers and their works' perspectives and consequently brings forth more
transparency in various aspects of information life-cycle with respect to
knowledge management. KsSSes are technology platforms, which can be implemented
independently as well as in conjunction with other knowledge management and
data management technology platforms, to provide significant boost in the
knowledge capabilities of organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5399</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5399</id><created>2009-10-28</created><updated>2010-01-12</updated><authors><author><keyname>McCusker</keyname><forenames>Guy</forenames></author></authors><title>A Graph Model for Imperative Computation</title><categories>cs.LO</categories><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (January
  12, 2010) lmcs:919</journal-ref><doi>10.2168/LMCS-6(1:2)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scott's graph model is a lambda-algebra based on the observation that
continuous endofunctions on the lattice of sets of natural numbers can be
represented via their graphs. A graph is a relation mapping finite sets of
input values to output values.
  We consider a similar model based on relations whose input values are finite
sequences rather than sets. This alteration means that we are taking into
account the order in which observations are made. This new notion of graph
gives rise to a model of affine lambda-calculus that admits an interpretation
of imperative constructs including variable assignment, dereferencing and
allocation.
  Extending this untyped model, we construct a category that provides a model
of typed higher-order imperative computation with an affine type system. An
appropriate language of this kind is Reynolds's Syntactic Control of
Interference. Our model turns out to be fully abstract for this language. At a
concrete level, it is the same as Reddy's object spaces model, which was the
first &quot;state-free&quot; model of a higher-order imperative programming language and
an important precursor of games models. The graph model can therefore be seen
as a universal domain for Reddy's model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5405</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5405</id><created>2009-10-28</created><authors><author><keyname>Feyereisl</keyname><forenames>Jan</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Artificial Immune Tissue using Self-Orgamizing Networks</title><categories>cs.AI cs.NE</categories><comments>2 pages, 1 figure, Workshop on Artificial Immune Systems and Immune
  Systems Modelling (AISB06)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As introduced by Bentley et al. (2005), artificial immune systems (AIS) are
lacking tissue, which is present in one form or another in all living
multi-cellular organisms. Some have argued that this concept in the context of
AIS brings little novelty to the already saturated field of the immune inspired
computational research. This article aims to show that such a component of an
AIS has the potential to bring an advantage to a data processing algorithm in
terms of data pre-processing, clustering and extraction of features desired by
the immune inspired system. The proposed tissue algorithm is based on
self-organizing networks, such as self-organizing maps (SOM) developed by
Kohonen (1996) and an analogy of the so called Toll-Like Receptors (TLR)
affecting the activation function of the clusters developed by the SOM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5410</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5410</id><created>2009-10-28</created><authors><author><keyname>Fernandez-Amoros</keyname><forenames>David</forenames></author><author><keyname>Gonzalo</keyname><forenames>Julio</forenames></author><author><keyname>Verdejo</keyname><forenames>Felisa</forenames></author></authors><title>The Uned systems at Senseval-2</title><categories>cs.CL cs.AI</categories><comments>latex2e, 5 pages, appeared in SENSEVAL-2, held with ACL-02</comments><journal-ref>In Proceedings of the Second International Workshop on Evaluating
  Word Sense Disambiguation Systems (SENSEVAL), Toulouse 2002</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have participated in the SENSEVAL-2 English tasks (all words and lexical
sample) with an unsupervised system based on mutual information measured over a
large corpus (277 million words) and some additional heuristics. A supervised
extension of the system was also presented to the lexical sample task.
  Our system scored first among unsupervised systems in both tasks: 56.9%
recall in all words, 40.2% in lexical sample. This is slightly worse than the
first sense heuristic for all words and 3.6% better for the lexical sample, a
strong indication that unsupervised Word Sense Disambiguation remains being a
strong challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5419</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5419</id><created>2009-10-28</created><authors><author><keyname>Fernandez-Amoros</keyname><forenames>David</forenames></author></authors><title>Word Sense Disambiguation Based on Mutual Information and Syntactic
  Patterns</title><categories>cs.CL cs.AI</categories><comments>latex2e, 5 pages, appeared in SENSEVAL-3, Barcelona 2004</comments><journal-ref>In proceedings of the Third International Workshop on Evaluating
  Word Sense Disambiguation Systems (SENSEVAL) 2004, Barcelona</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a hybrid system for WSD, presented to the English
all-words and lexical-sample tasks, that relies on two different unsupervised
approaches. The first one selects the senses according to mutual information
proximity between a context word a variant of the sense. The second heuristic
analyzes the examples of use in the glosses of the senses so that simple
syntactic patterns are inferred. This patterns are matched against the
disambiguation contexts. We show that the first heuristic obtains a precision
and recall of .58 and .35 respectively in the all words task while the second
obtains .80 and .25. The high precision obtained recommends deeper research of
the techniques. Results for the lexical sample task are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5426</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5426</id><created>2009-10-28</created><updated>2009-10-29</updated><authors><author><keyname>Silva</keyname><forenames>Alonso</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Bernhard</keyname><forenames>Pierre</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Continuum Equilibria and Global Optimization for Routing in Dense Static
  Ad Hoc Networks</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider massively dense ad hoc networks and study their continuum limits
as the node density increases and as the graph providing the available routes
becomes a continuous area with location and congestion dependent costs. We
study both the global optimal solution as well as the non-cooperative routing
problem among a large population of users where each user seeks a path from its
origin to its destination so as to minimize its individual cost. Finally, we
seek for a (continuum version of the) Wardrop equilibrium. We first show how to
derive meaningful cost models as a function of the scaling properties of the
capacity of the network and of the density of nodes. We present various
solution methodologies for the problem: (1) the viscosity solution of the
Hamilton-Jacobi-Bellman equation, for the global optimization problem, (2) a
method based on Green's Theorem for the least cost problem of an individual,
and (3) a solution of the Wardrop equilibrium problem using a transformation
into an equivalent global optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5434</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5434</id><created>2009-10-28</created><authors><author><keyname>Petschow</keyname><forenames>Matthias</forenames></author><author><keyname>Di Napoli</keyname><forenames>Edoardo</forenames></author><author><keyname>Bientinesi</keyname><forenames>Paolo</forenames></author></authors><title>An Example of Symmetry Exploitation for Energy-related Eigencomputations</title><categories>cs.NA</categories><comments>To appear in the proceedings of the 7th International Conference on
  Computational Methods in Science and Engineering (ICCMSE '09)</comments><report-no>AICES-2009-18</report-no><acm-class>G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most used approaches in simulating materials is the tight-binding
approximation. When using this method in a material simulation, it is necessary
to compute the eigenvalues and eigenvectors of the Hamiltonian describing the
system. In general, the system possesses few explicit symmetries. Due to them,
the problem has many degenerate eigenvalues. The ambiguity in choosing a
orthonormal basis of the invariant subspaces, associated with degenerate
eigenvalues, will result in eigenvectors which are not invariant under the
action of the symmetry operators in matrix form. A meaningful computation of
the eigenvectors needs to take those symmetries into account. A natural choice
is a set of eigenvectors, which simultaneously diagonalizes the Hamiltonian and
the symmetry matrices. This is possible because all the matrices commute with
each other. The simultaneous eigenvectors and the corresponding eigenvalues
will be in a parametrized form in terms of the lattice momentum components.
This functional dependence of the eigenvalues is the dispersion relation and
describes the band structure of a material. Therefore it is important to find
this functional dependence in any numerical computation related to material
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5435</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5435</id><created>2009-10-28</created><updated>2010-04-05</updated><authors><author><keyname>Tygert</keyname><forenames>Mark</forenames></author></authors><title>Fast algorithms for spherical harmonic expansions, III</title><categories>cs.NA</categories><comments>14 pages, 1 figure, 6 tables</comments><journal-ref>Fast algorithms for spherical harmonic expansions, III, Journal of
  Computational Physics, 229 (18): 6181-6192, 2010</journal-ref><doi>10.1016/j.jcp.2010.05.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We accelerate the computation of spherical harmonic transforms, using what is
known as the butterfly scheme. This provides a convenient alternative to the
approach taken in the second paper from this series on &quot;Fast algorithms for
spherical harmonic expansions.&quot; The requisite precomputations become manageable
when organized as a &quot;depth-first traversal&quot; of the program's control-flow
graph, rather than as the perhaps more natural &quot;breadth-first traversal&quot; that
processes one-by-one each level of the multilevel procedure. We illustrate the
results via several numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5454</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5454</id><created>2009-10-28</created><authors><author><keyname>McGuire</keyname><forenames>P. C.</forenames></author><author><keyname>Gross</keyname><forenames>C.</forenames></author><author><keyname>Wendt</keyname><forenames>L.</forenames></author><author><keyname>Bonnici</keyname><forenames>A.</forenames></author><author><keyname>Souza-Egipsy</keyname><forenames>V.</forenames></author><author><keyname>Ormo</keyname><forenames>J.</forenames></author><author><keyname>Diaz-Martinez</keyname><forenames>E.</forenames></author><author><keyname>Foing</keyname><forenames>B. H.</forenames></author><author><keyname>Bose</keyname><forenames>R.</forenames></author><author><keyname>Walter</keyname><forenames>S.</forenames></author><author><keyname>Oesker</keyname><forenames>M.</forenames></author><author><keyname>Ontrup</keyname><forenames>J.</forenames></author><author><keyname>Haschke</keyname><forenames>R.</forenames></author><author><keyname>Ritter</keyname><forenames>H.</forenames></author></authors><title>The Cyborg Astrobiologist: Testing a Novelty-Detection Algorithm on Two
  Mobile Exploration Systems at Rivas Vaciamadrid in Spain and at the Mars
  Desert Research Station in Utah</title><categories>cs.CV astro-ph.EP astro-ph.IM cs.LG stat.ML</categories><comments>28 pages, 12 figures, accepted for publication in the International
  Journal of Astrobiology</comments><journal-ref>International Journal of Astrobiology, Vol. 9, pp. 11-27 (2010).</journal-ref><doi>10.1017/S1473550409990358</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (ABRIDGED) In previous work, two platforms have been developed for testing
computer-vision algorithms for robotic planetary exploration (McGuire et al.
2004b,2005; Bartolo et al. 2007). The wearable-computer platform has been
tested at geological and astrobiological field sites in Spain (Rivas
Vaciamadrid and Riba de Santiuste), and the phone-camera has been tested at a
geological field site in Malta. In this work, we (i) apply a Hopfield
neural-network algorithm for novelty detection based upon color, (ii) integrate
a field-capable digital microscope on the wearable computer platform, (iii)
test this novelty detection with the digital microscope at Rivas Vaciamadrid,
(iv) develop a Bluetooth communication mode for the phone-camera platform, in
order to allow access to a mobile processing computer at the field sites, and
(v) test the novelty detection on the Bluetooth-enabled phone-camera connected
to a netbook computer at the Mars Desert Research Station in Utah. This systems
engineering and field testing have together allowed us to develop a real-time
computer-vision system that is capable, for example, of identifying lichens as
novel within a series of images acquired in semi-arid desert environments. We
acquired sequences of images of geologic outcrops in Utah and Spain consisting
of various rock types and colors to test this algorithm. The algorithm robustly
recognized previously-observed units by their color, while requiring only a
single image or a few images to learn colors as familiar, demonstrating its
fast learning capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5461</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5461</id><created>2009-10-28</created><authors><author><keyname>Zhao</keyname><forenames>Manqi</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Anomaly Detection with Score functions based on Nearest Neighbor Graphs</title><categories>cs.LG</categories><comments>10 pages, 10 figures, accepted by NIPS 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel non-parametric adaptive anomaly detection algorithm for
high dimensional data based on score functions derived from nearest neighbor
graphs on $n$-point nominal data. Anomalies are declared whenever the score of
a test sample falls below $\alpha$, which is supposed to be the desired false
alarm level. The resulting anomaly detector is shown to be asymptotically
optimal in that it is uniformly most powerful for the specified false alarm
level, $\alpha$, for the case when the anomaly density is a mixture of the
nominal and a known density. Our algorithm is computationally efficient, being
linear in dimension and quadratic in data size. It does not require choosing
complicated tuning parameters or function approximation classes and it can
adapt to local structure such as local change in dimensionality. We demonstrate
the algorithm on both artificial and real data sets in high dimensional feature
spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5516</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5516</id><created>2009-10-28</created><updated>2010-10-14</updated><authors><author><keyname>Gregory</keyname><forenames>Steve</forenames></author></authors><title>Finding overlapping communities in networks by label propagation</title><categories>physics.soc-ph cs.SI</categories><journal-ref>New J. Phys. 12 103018 (2010)</journal-ref><doi>10.1088/1367-2630/12/10/103018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm for finding overlapping community structure in very
large networks. The algorithm is based on the label propagation technique of
Raghavan, Albert, and Kumara, but is able to detect communities that overlap.
Like the original algorithm, vertices have labels that propagate between
neighbouring vertices so that members of a community reach a consensus on their
community membership. Our main contribution is to extend the label and
propagation step to include information about more than one community: each
vertex can now belong to up to v communities, where v is the parameter of the
algorithm. Our algorithm can also handle weighted and bipartite networks. Tests
on an independently designed set of benchmarks, and on real networks, show the
algorithm to be highly effective in recovering overlapping communities. It is
also very fast and can process very large and dense networks in a short time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5535</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5535</id><created>2009-10-28</created><updated>2009-11-17</updated><authors><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Melsted</keyname><forenames>P&#xe1;ll</forenames></author></authors><title>Maximum Matchings in Random Bipartite Graphs and the Space Utilization
  of Cuckoo Hashtables</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the the following question in Random Graphs. We are given two
disjoint sets $L,R$ with $|L|=n=\alpha m$ and $|R|=m$. We construct a random
graph $G$ by allowing each $x\in L$ to choose $d$ random neighbours in $R$. The
question discussed is as to the size $\mu(G)$ of the largest matching in $G$.
When considered in the context of Cuckoo Hashing, one key question is as to
when is $\mu(G)=n$ whp? We answer this question exactly when $d$ is at least
four. We also establish a precise threshold for when Phase 1 of the Karp-Sipser
Greedy matching algorithm suffices to compute a maximum matching whp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5537</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5537</id><created>2009-10-28</created><authors><author><keyname>Godrich</keyname><forenames>Hana</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>An Analysis of Phase Synchronization Mismatch Sensitivity for Coherent
  MIMO Radar Systems</title><categories>cs.IT math.IT</categories><comments>To be presented at CAMSAP 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, the hybrid Cramer-Rao bound (CRB) is developed for target
localization, to establish the sensitivity of the estimation mean-square error
(MSE) to the level of phase synchronization mismatch in coherent Multiple-Input
Multiple-Output (MIMO) radar systems with widely distributed antennas. The
lower bound on the MSE is derived for the joint estimation of the vector of
unknown parameters, consisting of the target location and the mismatch of the
allegedly known system parameters, i.e., phase offsets at the radars.
Synchronization errors are modeled as being random and Gaussian. A closed-form
expression for the hybrid CRB is derived for the case of orthogonal
waveforms.The bound on the target localization MSE is expressed as the sum of
two terms - the first represents the CRB with no phase mismatch, and the second
captures the mismatch effect. The latter is shown to depend on the phase error
variance, the number of mismatched transmitting and receiving sensors and the
system geometry. For a given phase synchronization error variance, this
expression offers the means to analyze the achievable localization accuracy.
Alternatively, for a predetermined localization MSE target value, the derived
expression may be used to determine the necessary phase synchronization level
in the distributed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5542</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5542</id><created>2009-10-28</created><authors><author><keyname>Spirov</keyname><forenames>Alexander V.</forenames></author><author><keyname>Kazansky</keyname><forenames>Alexander B.</forenames></author><author><keyname>Zamdborg</keyname><forenames>Leonid</forenames></author><author><keyname>Merelo</keyname><forenames>Juan J.</forenames></author><author><keyname>Levchenko</keyname><forenames>Vladimir F.</forenames></author></authors><title>Forced Evolution in Silico by Artificial Transposons and their Genetic
  Operators: The John Muir Ant Problem</title><categories>cs.NE cs.AI</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern evolutionary computation utilizes heuristic optimizations based upon
concepts borrowed from the Darwinian theory of natural selection. We believe
that a vital direction in this field must be algorithms that model the activity
of genomic parasites, such as transposons, in biological evolution. This
publication is our first step in the direction of developing a minimal
assortment of algorithms that simulate the role of genomic parasites.
Specifically, we started in the domain of genetic algorithms (GA) and selected
the Artificial Ant Problem as a test case. We define these artificial
transposons as a fragment of an ant's code that possesses properties that cause
it to stand apart from the rest. We concluded that artificial transposons,
analogous to real transposons, are truly capable of acting as intelligent
mutators that adapt in response to an evolutionary problem in the course of
co-evolution with their hosts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5559</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5559</id><created>2009-10-29</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN, CIM</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>On the characterization of the regions of feasible trajectories in the
  workspace of parallel manipulators</title><categories>cs.RO</categories><proxy>ccsd hal-00428530</proxy><journal-ref>Tenth World Congress On The Theory Of Machines And Mechanisms,
  Oulu : Finland (1999)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was shown recently that parallel manipulators with several inverse
kinematic solutions have the ability to avoid parallel singularities [Chablat
1998a] and self-collisions [Chablat 1998b] by choosing appropriate joint
configurations for the legs. In effect, depending on the joint configurations
of the legs, a given configuration of the end-effector may or may not be free
of singularity and collision. Characterization of the
collision/singularity-free workspace is useful but may be insufficient since
two configurations can be accessible without collisions nor singularities but
it may not exist a feasible trajectory between them. The goal of this paper is
to define the maximal regions of the workspace where it is possible to execute
trajectories. Twodifferent families of regions are defined : 1. those regions
where the end-effector can move between any set of points, and 2. the regions
where any continuous path can be tracked. These regions are characterized from
the notion of aspects and free-aspects recently defined for parallel
manipulators [Chablat 1998b]. The construction of these regions is achieved by
enrichment techniques and using an extension of the octree structures to spaces
of dimension greater than three. Illustrative examples show the interest of
this study to the optimization of trajectories and the design of parallel
manipulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5564</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5564</id><created>2009-10-29</created><updated>2012-03-07</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Instruction sequence processing operators</title><categories>cs.LO cs.PL</categories><comments>37 pages; missing equations in table 3 added; combined with
  arXiv:0911.1851 [cs.PL] and arXiv:0911.5018 [cs.LO]; introduction and
  concluding remarks rewritten; remarks and examples added; minor error in
  proof of theorem 4 corrected</comments><acm-class>D.3.3; F.1.1; F.4.1</acm-class><journal-ref>Acta Informatica, 49(3):139--172, 2012</journal-ref><doi>10.1007/s00236-012-0154-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instruction sequence is a key concept in practice, but it has as yet not come
prominently into the picture in theoretical circles. This paper concerns
instruction sequences, the behaviours produced by them under execution, the
interaction between these behaviours and components of the execution
environment, and two issues relating to computability theory. Positioning
Turing's result regarding the undecidability of the halting problem as a result
about programs rather than machines, and taking instruction sequences as
programs, we analyse the autosolvability requirement that a program of a
certain kind must solve the halting problem for all programs of that kind. We
present novel results concerning this autosolvability requirement. The analysis
is streamlined by using the notion of a functional unit, which is an abstract
state-based model of a machine. In the case where the behaviours exhibited by a
component of an execution environment can be viewed as the behaviours of a
machine in its different states, the behaviours concerned are completely
determined by a functional unit. The above-mentioned analysis involves
functional units whose possible states represent the possible contents of the
tapes of Turing machines with a particular tape alphabet. We also investigate
functional units whose possible states are the natural numbers. This
investigation yields a novel computability result, viz. the existence of a
universal computable functional unit for natural numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5577</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5577</id><created>2009-10-29</created><authors><author><keyname>Norros</keyname><forenames>Ilkka</forenames></author><author><keyname>Reittu</keyname><forenames>Hannu</forenames></author><author><keyname>Eirola</keyname><forenames>Timo</forenames></author></authors><title>On the stability of two-chunk file-sharing systems</title><categories>cs.OS math.PR</categories><comments>19 pages, 7 figures</comments><msc-class>60K25, 68M14</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider five different peer-to-peer file sharing systems with two chunks,
with the aim of finding chunk selection algorithms that have provably stable
performance with any input rate and assuming non-altruistic peers who leave the
system immediately after downloading the second chunk. We show that many
algorithms that first looked promising lead to unstable or oscillating
behavior. However, we end up with a system with desirable properties. Most of
our rigorous results concern the corresponding deterministic large system
limits, but in two simplest cases we provide proofs for the stochastic systems
also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5595</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5595</id><created>2009-10-29</created><authors><author><keyname>Mansouri</keyname><forenames>Shohreh Sharif</forenames></author><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author></authors><title>An Improved Implementation of Grain</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common approach to protect confidential information is to use a stream
cipher which combines plain text bits with a pseudo-random bit sequence. Among
the existing stream ciphers, Non-Linear Feedback Shift Register (NLFSR)-based
ones provide the best trade-off between cryptographic security and hardware
efficiency. In this paper, we show how to further improve the hardware
efficiency of Grain stream cipher. By transforming the NLFSR of Grain from its
original Fibonacci configuration to the Galois configuration and by introducing
a clock division block, we double the throughput of the 80 and 128-bit key
1bit/cycle architectures of Grain with no area penalty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5599</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5599</id><created>2009-10-29</created><authors><author><keyname>Patt-Shamir</keyname><forenames>Boaz</forenames></author><author><keyname>Rawitz</keyname><forenames>Dror</forenames></author></authors><title>Vector Bin Packing with Multiple-Choice</title><categories>cs.DS</categories><doi>10.1007/978-3-642-13731-0_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variant of bin packing called multiple-choice vector bin
packing. In this problem we are given a set of items, where each item can be
selected in one of several $D$-dimensional incarnations. We are also given $T$
bin types, each with its own cost and $D$-dimensional size. Our goal is to pack
the items in a set of bins of minimum overall cost. The problem is motivated by
scheduling in networks with guaranteed quality of service (QoS), but due to its
general formulation it has many other applications as well. We present an
approximation algorithm that is guaranteed to produce a solution whose cost is
about $\ln D$ times the optimum. For the running time to be polynomial we
require $D=O(1)$ and $T=O(\log n)$. This extends previous results for vector
bin packing, in which each item has a single incarnation and there is only one
bin type. To obtain our result we also present a PTAS for the multiple-choice
version of multidimensional knapsack, where we are given only one bin and the
goal is to pack a maximum weight set of (incarnations of) items in that bin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5643</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5643</id><created>2009-10-29</created><authors><author><keyname>Silva</keyname><forenames>Alonso</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Alfano</keyname><forenames>Giuseppa</forenames></author></authors><title>Magnetworks: how mobility impacts the design of Mobile Networks</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the optimal placement and optimal number of active
relay nodes through the traffic density in mobile sensor ad-hoc networks. We
consider a setting in which a set of mobile sensor sources is creating data and
a set of mobile sensor destinations receiving that data. We make the assumption
that the network is massively dense, i.e., there are so many sources,
destinations, and relay nodes, that it is best to describe the network in terms
of macroscopic parameters, such as their spatial density, rather than in terms
of microscopic parameters, such as their individual placements.
  We focus on a particular physical layer model that is characterized by the
following assumptions: i) the nodes must only transport the data from the
sources to the destinations, and do not need to sense the data at the sources,
or deliver them at the destinations once the data arrive at their physical
locations, and ii) the nodes have limited bandwidth available to them, but they
use it optimally to locally achieve the network capacity.
  In this setting, the optimal distribution of nodes induces a traffic density
that resembles the electric displacement that will be created if we substitute
the sources and destinations with positive and negative charges respectively.
The analogy between the two settings is very tight and have a direct
interpretation in wireless sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5673</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5673</id><created>2009-10-29</created><updated>2011-06-27</updated><authors><author><keyname>Dorfler</keyname><forenames>Florian</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Synchronization and Transient Stability in Power Networks and
  Non-Uniform Kuramoto Oscillators</title><categories>math.OC cs.SY math-ph math.DS math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by recent interest for multi-agent systems and smart power grid
architectures, we discuss the synchronization problem for the network-reduced
model of a power system with non-trivial transfer conductances. Our key insight
is to exploit the relationship between the power network model and a
first-order model of coupled oscillators. Assuming overdamped generators
(possibly due to local excitation controllers), a singular perturbation
analysis shows the equivalence between the classic swing equations and a
non-uniform Kuramoto model. Here, non-uniform Kuramoto oscillators are
characterized by multiple time constants, non-homogeneous coupling, and
non-uniform phase shifts. Extending methods from transient stability,
synchronization theory, and consensus protocols, we establish sufficient
conditions for synchronization of non-uniform Kuramoto oscillators. These
conditions reduce to and improve upon previously-available tests for the
standard Kuramoto model. Combining our singular perturbation and Kuramoto
analyses, we derive concise and purely algebraic conditions that relate
synchronization and transient stability of a power network to the underlying
system parameters and initial conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5682</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5682</id><created>2009-10-29</created><authors><author><keyname>Fernandez-Amoros</keyname><forenames>David</forenames></author></authors><title>Word Sense Disambiguation Using English-Spanish Aligned Phrases over
  Comparable Corpora</title><categories>cs.CL cs.AI</categories><comments>latex2e, 8 pages, 1 figure, published in the Proceedings of
  Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca, held during
  the summer school EUROLAN 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a WSD experiment based on bilingual English-Spanish
comparable corpora in which individual noun phrases have been identified and
aligned with their respective counterparts in the other language. The
evaluation of the experiment has been carried out against SemCor.
  We show that, with the alignment algorithm employed, potential precision is
high (74.3%), however the coverage of the method is low (2.7%), due to
alignments being far less frequent than we expected.
  Contrary to our intuition, precision does not rise consistently with the
number of alignments. The coverage is low due to several factors; there are
important domain differences, and English and Spanish are too close languages
for this approach to be able to discriminate efficiently between senses,
rendering it unsuitable for WSD, although the method may prove more productive
in machine translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5697</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5697</id><created>2009-10-29</created><updated>2010-04-26</updated><authors><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>High Dimensional Error-Correcting Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we construct multidimensional codes with high dimension. The
codes can correct high dimensional errors which have the form of either small
clusters, or confined to an area with a small radius. We also consider small
number of errors in a small area. The clusters which are discussed are mainly
spheres such as semi-crosses and crosses. Also considered are clusters with
small number of errors such as 2-bursts, two errors in various clusters, and
three errors on a line. Our main focus is on the redundancy of the codes when
the most dominant parameter is the dimension of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5714</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5714</id><created>2009-10-29</created><updated>2010-06-09</updated><authors><author><keyname>Feigenbaum</keyname><forenames>Joan</forenames></author><author><keyname>Jaggard</keyname><forenames>Aaron D.</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author></authors><title>Approximate Privacy: Foundations and Quantification</title><categories>cs.CR cs.GT</categories><comments>33 pages, seven figures, two tables. Changes in version 2 include an
  expanded discussion of other approaches to approximate privacy and added
  acknowledgements</comments><report-no>DIMACS TR 2009-14</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing use of computers and networks in business, government, recreation,
and almost all aspects of daily life has led to a proliferation of online
sensitive data about individuals and organizations. Consequently, concern about
the privacy of these data has become a top priority, particularly those data
that are created and used in electronic commerce. There have been many
formulations of privacy and, unfortunately, many negative results about the
feasibility of maintaining privacy of sensitive data in realistic networked
environments. We formulate communication-complexity-based definitions, both
worst-case and average-case, of a problem's privacy-approximation ratio. We use
our definitions to investigate the extent to which approximate privacy is
achievable in two standard problems: the second-price Vickrey auction and the
millionaires problem of Yao.
  For both the second-price Vickrey auction and the millionaires problem, we
show that not only is perfect privacy impossible or infeasibly costly to
achieve, but even close approximations of perfect privacy suffer from the same
lower bounds. By contrast, we show that, if the values of the parties are drawn
uniformly at random from {0,...,2^k-1}, then, for both problems, simple and
natural communication protocols have privacy-approximation ratios that are
linear in k (i.e., logarithmic in the size of the space of possible inputs). We
conjecture that this improved privacy-approximation ratio is achievable for any
probability distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5744</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5744</id><created>2009-10-29</created><authors><author><keyname>Galand</keyname><forenames>Lucie</forenames></author><author><keyname>Spanjaard</keyname><forenames>Olivier</forenames></author></authors><title>Exact algorithms for OWA-optimization in multiobjective spanning tree
  problems</title><categories>cs.DS</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the multiobjective version of the optimal spanning tree
problem. More precisely, we are interested in determining the optimal spanning
tree according to an Ordered Weighted Average (OWA) of its objective values. We
first show that the problem is weakly NP-hard. In the case where the weights of
the OWA are strictly decreasing, we then propose a mixed integer programming
formulation, and provide dedicated optimality conditions yielding an important
reduction of the size of the program. Next, we present two bounds that can be
used to prune subspaces of solutions either in a shaving phase or in a branch
and bound procedure. The validity of these bounds does not depend on specific
properties of the weights (apart from non-negativity). All these exact
resolution algorithms are compared on the basis of numerical experiments,
according to their respective validity scopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5745</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5745</id><created>2009-10-29</created><updated>2010-07-14</updated><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author><author><keyname>Meadows</keyname><forenames>Catherine</forenames></author></authors><title>Quantifying pervasive authentication: the case of the Hancke-Kuhn
  protocol</title><categories>cs.CR</categories><comments>31 pages, 2 figures; short version of this paper appeared in the
  Proceedings of MFPS 2010</comments><acm-class>D.4.6; C.2.1; C.2.2; K.6.5; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As mobile devices pervade physical space, the familiar authentication
patterns are becoming insufficient: besides entity authentication, many
applications require, e.g., location authentication. Many interesting protocols
have been proposed and implemented to provide such strengthened forms of
authentication, but there are very few proofs that such protocols satisfy the
required security properties. The logical formalisms, devised for reasoning
about security protocols on standard computer networks, turn out to be
difficult to adapt for reasoning about hybrid protocols, used in pervasive and
heterogenous networks. &lt;p&gt;
  We refine the Dolev-Yao-style algebraic method for protocol analysis by a
probabilistic model of guessing, needed to analyze protocols that mix weak
cryptography with physical properties of nonstandard communication channels.
Applying this model, we provide a precise security proof for a proximity
authentication protocol, due to Hancke and Kuhn, that uses a subtle form of
probabilistic reasoning to achieve its goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5759</identifier>
 <datestamp>2012-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5759</id><created>2009-10-29</created><updated>2012-12-06</updated><authors><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Secure Source Coding with a Helper</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a secure source coding problem with a rate-limited helper. In
particular, Alice observes an independent and identically distributed (i.i.d.)
source X and wishes to transmit this source losslessly to Bob over a
rate-limited link. A helper (Helen), observes an i.i.d. correlated source Y and
can transmit information to Bob over a separate rate-limited link. A passive
eavesdropper (Eve) can observe the coded output of Alice, i.e., the link from
Alice to Bob is public. The uncertainty about the source X at Eve, is measured
by the conditional entropy of the source given the coded output of Alice. We
completely characterize the rate-equivocation region for this secure source
coding model, where we show that Slepian-Wolf binning of X with respect to the
coded side information received at Bob is optimal. We next consider a
modification of this model in which Alice also has access to the coded output
of Helen. For the two-sided helper model, we characterize the rate-equivocation
region. While the availability of side information at Alice does not reduce the
rate of transmission from Alice, it significantly enhances the resulting
equivocation at Eve. In particular, the resulting equivocation for the
two-sided helper case is shown to be min(H(X),R_y), i.e., one bit from the
two-sided helper provides one bit of uncertainty at Eve. From this result, we
infer that Slepian-Wolf binning of X is suboptimal and one can further decrease
the information leakage to the eavesdropper by utilizing the side information
at Alice. We finally generalize these results to the case in which there is
additional un-coded side information W available at Bob and characterize the
rate-equivocation regions under the assumption that Y-X-W forms a Markov chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5761</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5761</id><created>2009-10-29</created><authors><author><keyname>Bento</keyname><forenames>Jose</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Which graphical models are difficult to learn?</title><categories>stat.ML cond-mat.stat-mech cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning the structure of Ising models (pairwise
binary Markov random fields) from i.i.d. samples. While several methods have
been proposed to accomplish this task, their relative merits and limitations
remain somewhat obscure. By analyzing a number of concrete examples, we show
that low-complexity algorithms systematically fail when the Markov random field
develops long-range correlations. More precisely, this phenomenon appears to be
related to the Ising model phase transition (although it does not coincide with
it).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5765</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5765</id><created>2009-10-30</created><updated>2010-05-03</updated><authors><author><keyname>Briet</keyname><forenames>Jop</forenames></author><author><keyname>Filho</keyname><forenames>Fernando Mario de Oliveira</forenames></author><author><keyname>Vallentin</keyname><forenames>Frank</forenames></author></authors><title>The positive semidefinite Grothendieck problem with rank constraint</title><categories>math.OC cs.DS math.CO math.FA</categories><comments>(v3) to appear in Proceedings of the 37th International Colloquium on
  Automata, Languages and Programming, 12 pages</comments><msc-class>68W25, 90C22</msc-class><journal-ref>ICALP, Part I, LNCS 6198, 2010, pages 31-42</journal-ref><doi>10.1007/978-3-642-14165-2_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a positive integer n and a positive semidefinite matrix A = (A_{ij}) of
size m x m, the positive semidefinite Grothendieck problem with
rank-n-constraint (SDP_n) is
  maximize \sum_{i=1}^m \sum_{j=1}^m A_{ij} x_i \cdot x_j, where x_1, ..., x_m
\in S^{n-1}.
  In this paper we design a polynomial time approximation algorithm for SDP_n
achieving an approximation ratio of
  \gamma(n) = \frac{2}{n}(\frac{\Gamma((n+1)/2)}{\Gamma(n/2)})^2 = 1 -
\Theta(1/n).
  We show that under the assumption of the unique games conjecture the achieved
approximation ratio is optimal: There is no polynomial time algorithm which
approximates SDP_n with a ratio greater than \gamma(n). We improve the
approximation ratio of the best known polynomial time algorithm for SDP_1 from
2/\pi to 2/(\pi\gamma(m)) = 2/\pi + \Theta(1/m), and we show a tighter
approximation ratio for SDP_n when A is the Laplacian matrix of a graph with
nonnegative edge weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5794</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5794</id><created>2009-10-30</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>ROBOTIC Laboratory, Irccyn</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Gomolitsky</keyname><forenames>Roman</forenames><affiliation>ROBOTIC Laboratory</affiliation></author></authors><title>Calibration of 3-d.o.f. Translational Parallel Manipulators Using Leg
  Observations</title><categories>cs.RO</categories><comments>ISBN: 978-3-902613-20-2</comments><proxy>ccsd hal-00428919</proxy><journal-ref>Parallel Manipulators, New Developments, Jee-Hwan Ryu (Ed.) (2008)
  225-240</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a novel approach for the geometrical model calibration of
quasi-isotropic parallel kinematic mechanisms of the Orthoglide family. It is
based on the observations of the manipulator leg parallelism during motions
between the specific test postures and employs a low-cost measuring system
composed of standard comparator indicators attached to the universal magnetic
stands. They are sequentially used for measuring the deviation of the relevant
leg location while the manipulator moves the TCP along the Cartesian axes.
Using the measured differences, the developed algorithm estimates the joint
offsets and the leg lengths that are treated as the most essential parameters.
Validity of the proposed calibration technique is confirmed by the experimental
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5816</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5816</id><created>2009-10-30</created><updated>2009-11-02</updated><authors><author><keyname>Notarstefano</keyname><forenames>Giuseppe</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Distributed Abstract Optimization via Constraints Consensus: Theory and
  Applications</title><categories>cs.DC cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed abstract programs are a novel class of distributed optimization
problems where (i) the number of variables is much smaller than the number of
constraints and (ii) each constraint is associated to a network node. Abstract
optimization programs are a generalization of linear programs that captures
numerous geometric optimization problems. We propose novel constraints
consensus algorithms for distributed abstract programs: as each node
iteratively identifies locally active constraints and exchanges them with its
neighbors, the network computes the active constraints determining the global
optimum. The proposed algorithms are appropriate for networks with weak
time-dependent connectivity requirements and tight memory constraints. We show
how suitable target localization and formation control problems can be tackled
via constraints consensus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5819</identifier>
 <datestamp>2015-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5819</id><created>2009-10-30</created><updated>2015-06-25</updated><authors><author><keyname>Lasota</keyname><forenames>Slawomir</forenames></author><author><keyname>Poturalski</keyname><forenames>Marcin</forenames></author></authors><title>Undecidability of performance equivalence of Petri nets</title><categories>cs.CC cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate bisimulation equivalence on Petri nets under durational
semantics. Our motivation was to verify the conjecture that in durational
setting, the bisimulation equivalence checking problem becomes more tractable
than in ordinary setting (which is the case, e.g., over communication-free
nets). We disprove this conjecture in three of four proposed variants of
durational semantics. The fourth variant remains an intriguing open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5833</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5833</id><created>2009-10-30</created><authors><author><keyname>Carre</keyname><forenames>Jean-Loup</forenames></author><author><keyname>Hymans</keyname><forenames>Charles</forenames></author></authors><title>From Single-thread to Multithreaded: An Efficient Static Analysis
  Algorithm</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A great variety of static analyses that compute safety properties of
single-thread programs have now been developed. This paper presents a
systematic method to extend a class of such static analyses, so that they
handle programs with multiple POSIX-style threads. Starting from a pragmatic
operational semantics, we build a denotational semantics that expresses
reasoning a la assume-guarantee. The final algorithm is then derived by
abstract interpretation. It analyses each thread in turn, propagating
interferences between threads, in addition to other semantic information. The
combinatorial explosion, ensued from the explicit consideration of all
interleavings, is thus avoided. The worst case complexity is only increased by
a factor n compared to the single-thread case, where n is the number of
instructions in the program. We have implemented prototype tools, demonstrating
the practicality of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5844</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5844</id><created>2009-10-30</created><authors><author><keyname>Tan</keyname><forenames>Tony</forenames></author></authors><title>On Pebble Automata for Data Languages with Decidable Emptiness Problem</title><categories>cs.FL</categories><comments>An extended abstract of this work has been published in the
  proceedings of the 34th International Symposium on Mathematical Foundations
  of Computer Science (MFCS) 2009}, Springer, Lecture Notes in Computer Science
  5734, pages 712-723</comments><acm-class>F.1.1; F.4.1; F.4.3</acm-class><doi>10.1007/978-3-642-03816-7_60</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a subclass of pebble automata (PA) for data languages
for which the emptiness problem is decidable. Namely, we introduce the
so-called top view weak PA. Roughly speaking, top view weak PA are weak PA
where the equality test is performed only between the data values seen by the
two most recently placed pebbles. The emptiness problem for this model is
decidable. We also show that it is robust: alternating, nondeterministic and
deterministic top view weak PA have the same recognition power. Moreover, this
model is strong enough to accept all data languages expressible in Linear
Temporal Logic with the future-time operators, augmented with one register
freeze quantifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5904</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5904</id><created>2009-10-30</created><updated>2009-11-18</updated><authors><author><keyname>Bodmann</keyname><forenames>Bernhard G.</forenames></author><author><keyname>Casazza</keyname><forenames>Peter G.</forenames></author><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author></authors><title>A quantitative notion of redundancy for finite frames</title><categories>math.FA cs.IT math.IT</categories><comments>19 pages, LateX with AMS macros; corrections addressing complications
  due to zero vectors and spark</comments><msc-class>94A12; 42C15; 15A04; 68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to improve the customary definition of
redundancy by providing quantitative measures in its place, which we coin upper
and lower redundancies, that match better with an intuitive understanding of
redundancy for finite frames in a Hilbert space. This motivates a carefully
chosen list of desired properties for upper and lower redundancies. The means
to achieve these properties is to consider the maximum and minimum of a
redundancy function, which is interesting in itself. The redundancy function is
defined on the sphere of the Hilbert space and measures the concentration of
frame vectors around each point. A complete characterization of functions on
the sphere which coincide with a redundancy function for some frame is given.
The upper and lower redundancies obtained from this function are shown to
satisfy all of the intuitively desirable properties. In addition, the range of
values they assume is characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5920</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5920</id><created>2009-10-30</created><authors><author><keyname>O'Callaghan</keyname><forenames>David</forenames></author><author><keyname>Doran</keyname><forenames>Louise</forenames></author><author><keyname>Coghlan</keyname><forenames>Brian</forenames></author></authors><title>Evaluating Trust in Grid Certificates</title><categories>cs.CR cs.DC</categories><comments>5 pages, 1 figure, accepted for ACM SAC 2010</comments><acm-class>K.6.5; E.3; H.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital certificates are used to secure international computation and data
storage grids used for e-Science projects, like the Worldwide Large Hadron
Collider Computing Grid. The International Grid Trust Federation has defined
the Grid Certificate Profile: a set of guidelines for digital certificates used
for grid authentication. We have designed and implemented a program and related
test suites for checking X.509 certificates against the certificate profiles
and policies relevant for use on the Grid. The result is a practical tool that
assists implementers and users of public key infrastructures to reach
appropriate trust decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5932</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5932</id><created>2009-10-30</created><authors><author><keyname>Jain</keyname><forenames>Prateek</forenames></author><author><keyname>Kulis</keyname><forenames>Brian</forenames></author><author><keyname>Davis</keyname><forenames>Jason V.</forenames></author><author><keyname>Dhillon</keyname><forenames>Inderjit S.</forenames></author></authors><title>Metric and Kernel Learning using a Linear Transformation</title><categories>cs.LG cs.CV cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metric and kernel learning are important in several machine learning
applications. However, most existing metric learning algorithms are limited to
learning metrics over low-dimensional data, while existing kernel learning
algorithms are often limited to the transductive setting and do not generalize
to new data points. In this paper, we study metric learning as a problem of
learning a linear transformation of the input data. We show that for
high-dimensional data, a particular framework for learning a linear
transformation of the data based on the LogDet divergence can be efficiently
kernelized to learn a metric (or equivalently, a kernel function) over an
arbitrarily high dimensional space. We further demonstrate that a wide class of
convex loss functions for learning linear transformations can similarly be
kernelized, thereby considerably expanding the potential applications of metric
learning. We demonstrate our learning approach by applying it to large-scale
real world problems in computer vision and text mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5947</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5947</id><created>2009-10-30</created><updated>2010-02-08</updated><authors><author><keyname>Kloke</keyname><forenames>Jennifer</forenames></author><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author></authors><title>Topological De-Noising: Strengthening the Topological Signal</title><categories>cs.CG cs.NA</categories><comments>13 pages, 37 figures, content added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Topological methods, including persistent homology, are powerful tools for
analysis of high-dimensional data sets but these methods rely almost
exclusively on thresholding techniques. In noisy data sets, thresholding does
not always allow for the recovery of topological information. We present an
easy to implement, computationally efficient pre-processing algorithm to
prepare noisy point cloud data sets for topological data analysis. The
topological de-noising algorithm allows for the recovery of topological
information that is inaccessible by thresholding methods. We apply the
algorithm to synthetically-generated noisy data sets and show the recovery of
topological information which is impossible to obtain by thresholding. We also
apply the algorithm to natural image data in R^8 and show a very clean recovery
of topological information previously only available with large amounts of
thresholding. Finally, we discuss future directions for improving this
algorithm using zig-zag persistence methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0910.5950</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0910.5950</id><created>2009-10-30</created><authors><author><keyname>Taherzadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Limits on the Robustness of MIMO Joint Source-Channel Codes</title><categories>cs.IT math.IT</categories><comments>presented at Allerton Conference 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the theoretical limits on the robustness of MIMO joint source
channel codes is investigated. The case in which a single joint source channel
code is used for the entire range of SNRs and for all levels of required
fidelity is considered. Limits on the asymptotic performance of such a system
are characterized in terms of upper bounds on the diversity-fidelity tradeoff,
which can be viewed as an analog version of the diversity-multiplexing
tradeoff. In particular, it is shown that there is a considerable gap between
the diversity-fidelity tradeoff of robust joint source-channel codes and the
optimum tradeoff (without the constraint of robustness).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0028</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0028</id><created>2009-11-02</created><authors><author><keyname>Elalfi</keyname><forenames>A. E. E.</forenames></author><author><keyname>Elalami</keyname><forenames>M. E.</forenames></author><author><keyname>Asem</keyname><forenames>Y. M .</forenames></author></authors><title>Knowledge Extraction for Discriminating Male and Female in Logical
  Reasoning from Student Model</title><categories>cs.OH</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 006-015, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The learning process is a process of communication and interaction between
the teacher and his students on one side and between the students and each
others on the other side. Interaction of the teacher with his students has a
great importance in the process of learning and education. The pattern and
style of this interaction is determined by the educational situation, trends
and concerns, and educational characteristics. Classroom interaction has an
importance and a big role in increasing the efficiency of the learning process
and raising the achievement levels of students. Students need to learn skills
and habits of study, especially at the university level. The effectiveness of
learning is affected by several factors that include the prevailing patterns of
interactive behavior in the classroom. These patterns are reflected in the
activities of teacher and learners during the learning process. The
effectiveness of learning is also influenced by the cognitive and non cognitive
characteristics of teacher that help him to succeed, the characteristics of
learners, teaching subject, and the teaching methods. This paper presents a
machine learning algorithm for extracting knowledge from student model. The
proposed algorithm utilizes the inherent characteristic of genetic algorithm
and neural network for extracting comprehensible rules from the student
database. The knowledge is used for discriminating male and female levels in
logical reasoning as a part of an expert system course.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0039</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0039</id><created>2009-10-30</created><updated>2009-12-09</updated><authors><author><keyname>Golovchinsky</keyname><forenames>Gene</forenames></author><author><keyname>Carter</keyname><forenames>Scott</forenames></author><author><keyname>Biehl</keyname><forenames>Jacob</forenames></author></authors><title>Beyond the Drawing Board: Toward More Effective Use of Whiteboard
  Content</title><categories>cs.HC</categories><comments>Modified acknowledgments</comments><report-no>FXPAL-TR-09-004</report-no><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We developed a system that augments traditional office whiteboards with
computation for the purposes of retrieving, reusing, and sharing whiteboard
content. Our system automatically captures changes to whiteboard images,
detects significant changes, and identifies potential collaborative activities.
Users then browse and search the collection of images captured from their
camera or shared from other users' cameras based on aspects such as location,
time, collaboration, etc. We report on the results of a formative study and on
an evaluation of effectiveness of our system, and discuss additional
functionality that can be built on our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0050</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0050</id><created>2009-10-30</created><authors><author><keyname>Kim</keyname><forenames>Hyoungshick</forenames></author><author><keyname>Yoon</keyname><forenames>Ji Won</forenames></author></authors><title>How to Compare the Scientific Contributions between Research Groups</title><categories>cs.IR cs.CY</categories><report-no>0911.0049</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to analyse the scientific contributions between research
groups. Given multiple research groups, we construct their journal/proceeding
graphs and then compute the similarity/gap between them using network analysis.
This analysis can be used for measuring similarity/gap of the topics/qualities
between research groups' scientific contributions. We demonstrate the
practicality of our method by comparing the scientific contributions by Korean
researchers with those by the global researchers for information security in
2006 - 2008. The empirical analysis shows that the current security research in
South Korea has been isolated from the global research trend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0054</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0054</id><created>2009-10-30</created><updated>2015-05-16</updated><authors><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author><author><keyname>Sridharan</keyname><forenames>Karthik</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>Learning Exponential Families in High-Dimensions: Strong Convexity and
  Sparsity</title><categories>cs.LG stat.ML</categories><comments>Errata added. Incorrect claim about cumulants of the Bernoulli
  distribution fixed</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The versatility of exponential families, along with their attendant convexity
properties, make them a popular and effective statistical model. A central
issue is learning these models in high-dimensions, such as when there is some
sparsity pattern of the optimal parameter. This work characterizes a certain
strong convexity property of general exponential families, which allow their
generalization ability to be quantified. In particular, we show how this
property can be used to analyze generic exponential families under L_1
regularization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0086</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0086</id><created>2009-10-31</created><updated>2013-01-21</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Jungers</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author></authors><title>Sorting under Partial Information (without the Ellipsoid Algorithm)</title><categories>cs.DS cs.DM</categories><comments>v3: Minor changes. A preliminary version appeared in the proceedings
  of the 42th ACM Symposium on Theory of Computing (STOC 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the well-known problem of sorting under partial information: sort
a finite set given the outcomes of comparisons between some pairs of elements.
The input is a partially ordered set P, and solving the problem amounts to
discovering an unknown linear extension of P, using pairwise comparisons. The
information-theoretic lower bound on the number of comparisons needed in the
worst case is log e(P), the binary logarithm of the number of linear extensions
of P. In a breakthrough paper, Jeff Kahn and Jeong Han Kim (J. Comput. System
Sci. 51 (3), 390-399, 1995) showed that there exists a polynomial-time
algorithm for the problem achieving this bound up to a constant factor. Their
algorithm invokes the ellipsoid algorithm at each iteration for determining the
next comparison, making it impractical.
  We develop efficient algorithms for sorting under partial information. Like
Kahn and Kim, our approach relies on graph entropy. However, our algorithms
differ in essential ways from theirs. Rather than resorting to convex
programming for computing the entropy, we approximate the entropy, or make sure
it is computed only once, in a restricted class of graphs, permitting the use
of a simpler algorithm. Specifically, we present:
  - an O(n^2) algorithm performing O(log n log e(P)) comparisons;
  - an O(n^2.5) algorithm performing at most (1+ epsilon) log e(P) + O_epsilon
(n) comparisons;
  - an O(n^2.5) algorithm performing O(log e(P)) comparisons.
  All our algorithms can be implemented in such a way that their computational
bottleneck is confined in a preprocessing phase, while the sorting phase is
completed in O(q) + O(n) time, where q denotes the number of comparisons
performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0089</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0089</id><created>2009-10-31</created><authors><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author><author><keyname>Liu</keyname><forenames>Xi</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>A Secure Communication Game with a Relay Helping the Eavesdropper</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, published in proceedings of IEEE Information
  Theory Workshop, Taormina, Italy, October 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a four terminal Gaussian network composed of a source, a
destination, an eavesdropper and a jammer relay is studied. The jammer relay
does not hear the source transmission. It assists the eavesdropper and aims to
decrease the achievable secrecy rates. The source, on the other hand, aims to
increase the achievable secrecy rates. Assuming Gaussian strategies at the
source and the jammer relay, this problem is formulated as a two-player
zero-sum continuous game, where the payoff is the achieved secrecy rate. For
this game the Nash Equilibrium is generally achieved with mixed strategies. The
optimal cumulative distribution functions for the source and the jammer relay
that achieve the value of the game, which is the equilibrium secrecy rate, are
found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0090</identifier>
 <datestamp>2012-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0090</id><created>2009-10-31</created><authors><author><keyname>Ceccherini-Silberstein</keyname><forenames>Tullio</forenames></author><author><keyname>Woess</keyname><forenames>Wolfgang</forenames></author></authors><title>Context-free pairs of groups I: Context-free pairs and graphs</title><categories>math.GR cs.IT math.IT</categories><msc-class>20F10, 68Q45, 05C25</msc-class><journal-ref>European J. Combin. 33 (2012) 1449-1466</journal-ref><doi>10.1016/j.ejc.2012.03.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a finitely generated group, $A$ a finite set of generators and $K$
a subgroup of $G$. We call the pair $(G,K)$ context-free if the set of all
words over $A$ that reduce in $G$ to an element of $K$ is a context-free
language. When $K$ is trivial, $G$ itself is called context-free; context-free
groups have been classified more than 20 years ago in celebrated work of Muller
and Schupp as the virtually free groups.
  Here, we derive some basic properties of such group pairs. Context-freeness
is independent of the choice of the generating set. It is preserved under
finite index modifications of $G$ and finite index enlargements of $K$. If $G$
is virtually free and $K$ is finitely generated then $(G,K)$ is context-free. A
basic tool is the following: $(G,K)$ is context-free if and only if the
Schreier graph of $(G,K)$ with respect to $A$ is a context-free graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0105</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0105</id><created>2009-10-31</created><authors><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author><author><keyname>D&#xfc;ntsch</keyname><forenames>Ivo</forenames></author></authors><title>Functions Definable by Numerical Set-Expressions</title><categories>cs.LO</categories><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A &quot;numerical set-expression&quot; is a term specifying a cascade of arithmetic and
logical operations to be performed on sets of non-negative integers. If these
operations are confined to the usual Boolean operations together with the
result of lifting addition to the level of sets, we speak of &quot;additive
circuits&quot;. If they are confined to the usual Boolean operations together with
the result of lifting addition and multiplication to the level of sets, we
speak of &quot;arithmetic circuits&quot;. In this paper, we investigate the definability
of sets and functions by means of additive and arithmetic circuits,
occasionally augmented with additional operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0121</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0121</id><created>2009-11-02</created><updated>2009-11-26</updated><authors><author><keyname>Kim</keyname><forenames>Boseung</forenames></author><author><keyname>Lee</keyname><forenames>Joohyun</forenames></author><author><keyname>Shin</keyname><forenames>Yongtae</forenames></author></authors><title>(RCFT) ReClustering Formation Technique in Hierarchical Sensor Network</title><categories>cs.NI</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 052-055, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TBecause of limited energy of nodes, an important issue for sensor network is
efficient use of the energy. The clustering technique reduces energy
consumption as cluster head sends sensed information to a sink node. Because of
such character of clustering technique, electing cluster head is an important
element for networks. This paper proposes RCFT (ReClustering Formation
Technique) that reconstruct clusters in hierarchical sensor networks. RCFT is a
protocol that reconstructed clusters considering position of a cluster head and
nodes in randomly constructed clusters. And this paper demonstrated that
clusters are composed evenly through simulation, accordingly this simulation
shows the result reducing energy consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0130</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0130</id><created>2009-11-01</created><updated>2010-03-17</updated><authors><author><keyname>Norton</keyname><forenames>Graham H.</forenames></author></authors><title>Minimal Polynomial Algorithms for Finite Sequences</title><categories>cs.IT cs.DM cs.SC math.IT</categories><comments>Section 2 added, remarks and references expanded. To appear in IEEE
  Transactions on Information Theory.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a straightforward rewrite of a known minimal polynomial
algorithm yields a simpler version of a recent algorithm of A. Salagean.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0136</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0136</id><created>2009-11-01</created><authors><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Yu</keyname><forenames>Jianping</forenames></author><author><keyname>Cao</keyname><forenames>Jiannong</forenames></author><author><keyname>Ma</keyname><forenames>Xiaoxing</forenames></author><author><keyname>Tao</keyname><forenames>Xianping</forenames></author><author><keyname>Lu</keyname><forenames>Jian</forenames></author></authors><title>Checking Behavioral Consistency Constraints for Pervasive Context in
  Asynchronous Environments</title><categories>cs.SE cs.LO</categories><comments>9 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context consistency checking, the checking of specified constraint on
properties of contexts, is essential to context-aware applications. In order to
delineate and adapt to dynamic changes in the pervasive computing environment,
context-aware applications often need to specify and check behavioral
consistency constraints over the contexts. This problem is challenging mainly
due to the distributed and asynchronous nature of pervasive computing
environments. Specifically, the critical issue in checking behavioral
constraints is the temporal ordering of contextual activities. The contextual
activities usually involve multiple context collecting devices, which are
fully-decentralized and interact in an asynchronous manner. However, existing
context consistency checking schemes do not work in asynchronous environments,
since they implicitly assume the availability of a global clock or relay on
synchronized interactions.
  To this end, we propose the Ordering Global Activity (OGA) algorithm, which
detects the ordering of the global activities based on predicate detection in
asynchronous environments. The essence of our approach is the message causality
and its on-the-fly coding as logic vector clocks in asynchronous environments.
We implement the Middleware Infrastructure for Predicate detection in
Asynchronous environments (MIPA), over which the OGA algorithm is implemented
and evaluated. The evaluation results show the impact of asynchrony on the
checking of behavioral consistency constraints, which justifies the primary
motivation of our work. They also show that OGA can achieve accurate checking
of behavioral consistency constraints in dynamic pervasive computing
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0137</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0137</id><created>2009-11-01</created><updated>2010-07-20</updated><authors><author><keyname>Darbha</keyname><forenames>S.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>On the vibrations of lumped parameter systems governed by
  differential-algebraic equations</title><categories>cs.NA physics.class-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the vibratory motions of lumped parameter systems
wherein the components of the system cannot be described by constitutive
expressions for the force in terms of appropriate kinematical quantities. Such
physical systems reduce to a system of differential-algebraic equations, which
invariably need to be solved numerically. To illustrate the issues with
clarity, we consider a simple system in which the dashpot is assumed to contain
a &quot;Bingham&quot; fluid for which one cannot describe the force in the dashpot as a
function of the velocity. On the other hand, one can express the velocity as a
function of the force.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0141</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0141</id><created>2009-11-01</created><authors><author><keyname>Aboue-Nze</keyname><forenames>C&#xe9;dric Ga&#xeb;l</forenames><affiliation>LITIS</affiliation></author><author><keyname>Guinand</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LITIS</affiliation></author><author><keyname>Pign&#xe9;</keyname><forenames>Yoann</forenames><affiliation>LITIS</affiliation></author></authors><title>Impact of Obstacles on the Degree of Mobile Ad Hoc Connection Graphs</title><categories>cs.NI</categories><proxy>ccsd hal-00426737</proxy><journal-ref>International Conference on Networking and Services, Valence :
  Spain (2009)</journal-ref><doi>10.1109/ICNS.2009.36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the impact of obstacles on the graphs of connections between stations
in Mobile Ad hoc Networks? In order to answer, at least partially, this
question, the first step is to define both an environment with obstacles and a
mobility model for the stations in such an environment. The present paper
focuses on a new way of considering the mobility within environments with
obstacles, while keeping the core ideas of the well-known Random WayPoint
mobility model (a.k.a RWP). Based on a mesh-partitioning of the space, we
propose a new model called RSP-O-G for which we compute the spatial
distribution of stations and analyse how the presence of obstacles impacts this
distribution compared to the distribution when no obstacles are present.
Coupled with a simple model of radio propagation, and according to the density
of stations in the environment, we study the mean degree of the connection
graphs corresponding to such mobile ad hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0142</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0142</id><created>2009-11-01</created><updated>2010-07-26</updated><authors><author><keyname>Huss</keyname><forenames>Wilfried</forenames></author><author><keyname>Sava</keyname><forenames>Ecaterina</forenames></author><author><keyname>Woess</keyname><forenames>Wolfgang</forenames></author></authors><title>Entropy sensitivity of languages defined by infinite automata, via
  Markov chains with forbidden transitions</title><categories>cs.FL math.PR</categories><comments>to appear in Theoretical Computer Science, 2010</comments><msc-class>05C63, 37A35, 60J10, 68Q45</msc-class><journal-ref>Theoretical Computer Science 411 (2010), 3917-3922</journal-ref><doi>10.1016/j.tcs.2010.07.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A language L over a finite alphabet is growth-sensitive (or entropy
sensitive) if forbidding any set of subwords F yields a sub-language L^F whose
exponential growth rate (entropy) is smaller than that of L. Let (X, E, l) be
an infinite, oriented, labelled graph. Considering the graph as an (infinite)
automaton, we associate with any pair of vertices x,y in X the language
consisting of all words that can be read as the labels along some path from x
to y. Under suitable, general assumptions we prove that these languages are
growth-sensitive. This is based on using Markov chains with forbidden
transitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0143</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0143</id><created>2009-11-01</created><authors><author><keyname>Omrani</keyname><forenames>Reza</forenames></author><author><keyname>Garg</keyname><forenames>Gagan</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Bhambhani</keyname><forenames>Pankaj</forenames></author></authors><title>Large Families of Optimal Two-Dimensional Optical Orthogonal Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nine new 2-D OOCs are presented here, all sharing the common feature of a
code size that is much larger in relation to the number of time slots than
those of constructions appearing previously in the literature. Each of these
constructions is either optimal or asymptotically optimal with respect to
either the original Johnson bound or else a non-binary version of the Johnson
bound introduced in this paper.
  The first 5 codes are constructed using polynomials over finite fields - the
first construction is optimal while the remaining 4 are asymptotically optimal.
The next two codes are constructed using rational functions in place of
polynomials and these are asymptotically optimal. The last two codes, also
asymptotically optimal, are constructed by composing two of the above codes
with a constant weight binary code.
  Also presented, is a three-dimensional OOC that exploits the polarization
dimension.
  Finally, phase-encoded optical CDMA is considered and construction of two
efficient codes are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0151</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0151</id><created>2009-11-02</created><authors><author><keyname>Vasilescu</keyname><forenames>Rares</forenames></author></authors><title>An Alternative To Common Content Management Techniques</title><categories>cs.OH</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 056-060, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content management systems use various strategies to store and manage
information. One of the most usual methods encountered in commercial products
is to make use of the file system to store the raw content information, while
the associated metadata is kept synchronized in a relational database
management system. This strategy has its advantages but we believe it also has
significant limitations which should be addressed and eventually solved. In
this paper we propose an alternative method of storing and managing content
aiming at finding solutions for current limitations both in terms of functional
and nonfunctional requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0174</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0174</id><created>2009-11-02</created><authors><author><keyname>Qureshi</keyname><forenames>Muhammad Aasim</forenames></author><author><keyname>Hassan</keyname><forenames>Dr. Fadzil B.</forenames></author><author><keyname>Safdar</keyname><forenames>Sohail</forenames></author><author><keyname>Akbar</keyname><forenames>Rehan</forenames></author></authors><title>A O(E) Time Shortest Path Algorithm For Non Negative Weighted Undirected
  Graphs</title><categories>cs.DS</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 040-046, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most of the shortest path problems like vehicle routing problems and
network routing problems, we only need an efficient path between two points
source and destination, and it is not necessary to calculate the shortest path
from source to all other nodes. This paper concentrates on this very idea and
presents an algorithm for calculating shortest path for (i) nonnegative
weighted undirected graphs (ii) unweighted undirected graphs. The algorithm
completes its execution in O(E) for all graphs except few in which longer path
(in terms of number of edges) from source to some node makes it best selection
for that node. The main advantage of the algorithms is its simplicity and it
does not need complex data structures for implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0183</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0183</id><created>2009-11-01</created><authors><author><keyname>Panayirci</keyname><forenames>Erdal</forenames></author><author><keyname>Dogan</keyname><forenames>Hakan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Gibbs Sampling Based MAP Detection Algorithm for OFDM Over Rapidly
  Varying Mobile Radio Channels</title><categories>cs.IT math.AC math.IT</categories><comments>6 pages, 4 figures</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In orthogonal frequency-division multiplexing (OFDM) systems operating over
rapidly time-varying channels, the orthogonality between subcarriers is
destroyed leading to inter-carrier interference (ICI) and resulting in an
irreducible error floor. In this paper, a new and low-complexity maximum {\em a
posteriori} probability (MAP) detection algorithm is proposed for OFDM systems
operating over rapidly time-varying multipath channels. The detection algorithm
exploits the banded structure of the frequency-domain channel matrix whose
bandwidth is a parameter to be adjusted according to the speed of the mobile
terminal. Based on this assumption, the received signal vector is decomposed
into reduced dimensional sub-observations in such a way that all components of
the observation vector contributing to the symbol to be detected are included
in the decomposed observation model. The data symbols are then detected by the
MAP algorithm by means of a Markov chain Monte Carlo (MCMC) technique in an
optimal and computationally efficient way. Computational complexity
investigation as well as simulation results indicate that this algorithm has
significant performance and complexity advantages over existing suboptimal
detection and equalization algorithms proposed earlier in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0201</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0201</id><created>2009-11-01</created><authors><author><keyname>Kempe</keyname><forenames>Julia</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author></authors><title>No Strong Parallel Repetition with Entangled and Non-signaling Provers</title><categories>quant-ph cs.CC</categories><comments>15 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider one-round games between a classical verifier and two provers. One
of the main questions in this area is the \emph{parallel repetition question}:
If the game is played $\ell$ times in parallel, does the maximum winning
probability decay exponentially in $\ell$? In the classical setting, this
question was answered in the affirmative by Raz. More recently the question
arose whether the decay is of the form $(1-\Theta(\eps))^\ell$ where $1-\eps$
is the value of the game and $\ell$ is the number of repetitions. This question
is known as the \emph{strong parallel repetition question} and was motivated by
its connections to the unique games conjecture. It was resolved by Raz who
showed that strong parallel repetition does \emph{not} hold, even in the very
special case of games known as XOR games.
  This opens the question whether strong parallel repetition holds in the case
when the provers share entanglement. Evidence for this is provided by the
behavior of XOR games, which have strong (in fact \emph{perfect}) parallel
repetition, and by the recently proved strong parallel repetition of linear
unique games. A similar question was open for games with so-called
non-signaling provers. Here the best known parallel repetition theorem is due
to Holenstein, and is of the form $(1-\Theta(\eps^2))^\ell$.
  We show that strong parallel repetition holds neither with entangled provers
nor with non-signaling provers. In particular we obtain that Holenstein's bound
is tight. Along the way we also provide a tight characterization of the
asymptotic behavior of the entangled value under parallel repetition of unique
games in terms of a semidefinite program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0225</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0225</id><created>2009-11-02</created><authors><author><keyname>Deepthi</keyname><forenames>Dasika Ratna</forenames></author><author><keyname>Eswaran</keyname><forenames>K.</forenames></author></authors><title>A Mirroring Theorem and its Application to a New Method of Unsupervised
  Hierarchical Pattern Classification</title><categories>cs.LG</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 016-025, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove a crucial theorem called Mirroring Theorem which
affirms that given a collection of samples with enough information in it such
that it can be classified into classes and subclasses then (i) There exists a
mapping which classifies and subclassifies these samples (ii) There exists a
hierarchical classifier which can be constructed by using Mirroring Neural
Networks (MNNs) in combination with a clustering algorithm that can approximate
this mapping. Thus, the proof of the Mirroring theorem provides a theoretical
basis for the existence and a practical feasibility of constructing
hierarchical classifiers, given the maps. Our proposed Mirroring Theorem can
also be considered as an extension to Kolmogrovs theorem in providing a
realistic solution for unsupervised classification. The techniques we develop,
are general in nature and have led to the construction of learning machines
which are (i) tree like in structure, (ii) modular (iii) with each module
running on a common algorithm (tandem algorithm) and (iv) selfsupervised. We
have actually built the architecture, developed the tandem algorithm of such a
hierarchical classifier and demonstrated it on an example problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0231</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0231</id><created>2009-11-01</created><updated>2011-01-11</updated><authors><author><keyname>Karimadini</keyname><forenames>Mohammad</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Synchronized Task Decomposition for Cooperative Multi-agent Systems</title><categories>cs.MA cs.DC cs.SY</categories><comments>Submitted for publication, 2010</comments><report-no>NUS-ACT-10-Ver.3-001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is an amazing fact that remarkably complex behaviors could emerge from a
large collection of very rudimentary dynamical agents through very simple local
interactions. However, it still remains elusive on how to design these local
interactions among agents so as to achieve certain desired collective
behaviors. This paper aims to tackle this challenge and proposes a
divide-and-conquer approach to guarantee specified global behaviors through
local coordination and control design for multi-agent systems. The basic idea
is to decompose the requested global specification into subtasks for each
individual agent. It should be noted that the decomposition is not arbitrary.
The global specification should be decomposed in such a way that the fulfilment
of these subtasks by each individual agent will imply the satisfaction of the
global specification as a team. First, it is shown by a counterexample that not
all specifications can be decomposed in this sense. Then, a natural follow-up
question is what the necessary and sufficient condition should be for the
proposed decomposability of a global specification. The main part of the paper
is set to answer this question. The case of two cooperative agents is
investigated first, and a necessary and sufficient condition is presented and
proven. Later on, the result is generalized to the case of arbitrary finite
number of agents, and a hierarchical algorithm is proposed, which is shown to
be a sufficient condition. Finally, a cooperative control scenario for a team
of three robots is developed to illustrate the task decomposition procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0232</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0232</id><created>2009-11-01</created><updated>2011-10-17</updated><authors><author><keyname>Gharesifard</keyname><forenames>Bahman</forenames></author><author><keyname>Cortes</keyname><forenames>Jorge</forenames></author></authors><title>Distributed strategies for generating weight-balanced and doubly
  stochastic digraphs</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weight-balanced and doubly stochastic digraphs are two classes of digraphs
that play an essential role in a variety of cooperative control problems,
including formation control, distributed averaging, and optimization. We refer
to a digraph as doubly stochasticable (weight-balanceable) if it admits a
doubly stochastic (weight-balanced) adjacency matrix. This paper studies the
characterization of both classes of digraphs, and introduces distributed
algorithms to compute the appropriate set of weights in each case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0257</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0257</id><created>2009-11-02</created><updated>2011-06-09</updated><authors><author><keyname>Silva</keyname><forenames>Alonso</forenames></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Spatial games and global optimization for mobile association problems</title><categories>cs.GT</categories><comments>Part of this work has been presented at the 49th IEEE Conference on
  Decision and Control 2010. This work has been submitted to IEEE Transactions
  on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic optimal transportation problem consists in finding the most
effective way of moving masses from one location to another, while minimizing
the transportation cost. Such concept has been found to be useful to understand
various mathematical, economical, and control theory phenomena, such as
Witsenhausen's counterexam-ple in stochastic control theory, principal-agent
problem in microeco- nomic theory, location and planning problems, etc. In this
work, we focus on mobile association problems: the determina-tion of the cells
corresponding to each base station, i.e., the locations at which intelligent
mobile terminals prefer to connect to a given base station rather than to
others. This work combines game theory and optimal transport theory to
characterize the solution based on fluid approximations. We characterize the
optimal solution from both the global network and the mobile user points of
view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0285</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0285</id><created>2009-11-02</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP, Ictt</affiliation></author><author><keyname>Prevot</keyname><forenames>Patrick</forenames><affiliation>LIESP, Ictt</affiliation></author></authors><title>Knowledge Management Concepts For Training By Project An observation of
  the case of project management education</title><categories>cs.CY</categories><comments>6p</comments><proxy>ccsd hal-00399587</proxy><journal-ref>International conference on Knowledge Management and information
  sharing (KMIS 2009), Madeira : Portugal (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Project management education programmes are often proposed in higher
education to give students competences in project planning (Gantt's chart),
project organizing, human and technical resource management, quality control
and also social competences (collaboration, communication), emotional ones
(empathy, consideration of the other, humour, ethics), and organizational ones
(leadership, political vision, and so on). This training is often given
according a training-by-project type of learning with case studies. This
article presents one course characterized by a pedagogical organization based
upon Knowledge Management (KM) concepts: knowledge transfer and construction
throughout a learning circle and social interactions. The course is supported
by a rich and complex tutor organization. We have observed this course by using
another KM method inspired from KADS with various return of experience
formalized into cards and charts. Our intention is, according to the model of
Argyris and Sch\&quot;on (Smith, 2001), to gain feedback information about local and
global processes and about actors' experience in order to improve the course.
This paper describes precisely the course (pedagogical method and tutor
activity) and the KM observation method permitting to identify problem to
solve. In our case, we observe problem of pedacogical coordination and skills
acquisition. We propose to design a metacognitive tool for tutors and students,
usable for improving knowledge construction and learning process organisation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0310</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0310</id><created>2009-11-02</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP</affiliation></author><author><keyname>Garrot-Lavou&#xe9;</keyname><forenames>Elise</forenames><affiliation>LIESP, SICOMOR</affiliation></author></authors><title>Meshat: Monitoring and Experience Sharing Tool for Project-Based
  Learning</title><categories>cs.CY</categories><comments>8p</comments><proxy>ccsd hal-00429270</proxy><journal-ref>IADIS International Conference Cognition and Exploratory Learning
  in Digital Age (CELDA 2009), Rome : Italy (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work aims at studying tools offered to learners and tutors involved in
face-to-face or blended project-based learning activities. To understand better
the needs and expectations of each actor, we are especially interested in the
specific case of project management training. The results of a course
observation show that the lack of monitoring and expertise transfer tools
involves important dysfunctions in the course organisation and therefore
dissatisfaction for tutors and students (in particular about the acquisition of
knowledge and expertise). So as to solve this problem, we propose a
personalised platform (according to the actor: project group, student or tutor)
which gives information to monitor activities and supports the acquisition and
transfer of expertise. This platform is meant for the complex educational
context of project-based learning. Indeed, as for the majority of project-based
learning activities, the articulation conceptualisation-experiment is an
important part of the process. The originality of our approach relies on also
supporting the articulation between action (experiment or conceptualisation)
and reflection. This approach so improves the acquisition of complex skills
(e.g. management, communication and collaboration), which requires a
behavioural evolution. We aim at making the students become able ?to learn to
learn' and evolve according to contexts. We facilitate their ability to have a
critical analysis of their actions according to the situations they encounter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0344</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0344</id><created>2009-11-02</created><authors><author><keyname>Allesina</keyname><forenames>Stefano</forenames></author></authors><title>Accelerating the pace of discovery by changing the peer review algorithm</title><categories>cs.DL physics.soc-ph q-bio.OT</categories><comments>9 pages 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of scientific publications is constantly rising, increasing the
strain on the review process. The number of submissions is actually higher, as
each manuscript is often reviewed several times before publication. To face the
deluge of submissions, top journals reject a considerable fraction of
manuscripts without review, potentially declining manuscripts with merit. The
situation is frustrating for authors, reviewers and editors alike. Recently,
several editors wrote about the ``tragedy of the reviewer commons', advocating
for urgent corrections to the system. Almost every scientist has ideas on how
to improve the system, but it is very difficult, if not impossible, to perform
experiments to test which measures would be most effective. Surprisingly,
relatively few attempts have been made to model peer review. Here I implement a
simulation framework in which ideas on peer review can be quantitatively
tested. I incorporate authors, reviewers, manuscripts and journals into an
agent-based model and a peer review system emerges from their interactions. As
a proof-of-concept, I contrast an implementation of the current system, in
which authors decide the journal for their submissions, with a system in which
journals bid on manuscripts for publication. I show that, all other things
being equal, this latter system solves most of the problems currently
associated with the peer review process. Manuscripts' evaluation is faster,
authors publish more and in better journals, and reviewers' effort is optimally
utilized. However, more work is required from editors. This modeling framework
can be used to test other solutions for peer review, leading the way for an
improvement of how science is disseminated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0351</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0351</id><created>2009-11-02</created><authors><author><keyname>Artigue</keyname><forenames>Cedric</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author></authors><title>On the precoder design of flat fading MIMO systems equipped with MMSE
  receivers: a large system approach</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to the design of precoders maximizing the ergodic
mutual information (EMI) of bi-correlated flat fading MIMO systems equiped with
MMSE receivers. The channel state information and the second order statistics
of the channel are assumed available at the receiver side and at the
transmitter side respectively. As the direct maximization of the EMI needs the
use of non attractive algorithms, it is proposed to optimize an approximation
of the EMI, introduced recently, obtained when the number of transmit and
receive antennas $t$ and $r$ converge to $\infty$ at the same rate. It is
established that the relative error between the actual EMI and its
approximation is a $O(\frac{1}{t^{2}})$ term. It is shown that the left
singular eigenvectors of the optimum precoder coincide with the eigenvectors of
the transmit covariance matrix, and its singular values are solution of a
certain maximization problem. Numerical experiments show that the mutual
information provided by this precoder is close from what is obtained by
maximizing the true EMI, but that the algorithm maximizing the approximation is
much less computationally intensive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0397</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0397</id><created>2009-11-02</created><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author><author><keyname>Ha</keyname><forenames>Hong Pyo</forenames></author></authors><title>Algorithm as Defining Dynamic Systems</title><categories>cs.DS</categories><comments>3 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 026-028, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new view to algorithms, Algorithms as defining dynamic
systems. This view extends the traditional, deterministic view that an
algorithm is a step by step procedure with nondeterminism. As a dynamic system
can be designed by a set of its defining laws, it is also desirable to design
an algorithm by a (possibly nondeterministic) set of defining laws. This
observation requires some changes to algorithm development. We propose a two
step approach, the first step is to design an algorithm via a set of defining
laws of dynamic system. The second step is to translate these laws (written in
a natural language) into a formal language such as linear logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0399</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0399</id><created>2009-11-02</created><authors><author><keyname>Essaouabi</keyname><forenames>A.</forenames></author><author><keyname>Regragui</keyname><forenames>F.</forenames></author><author><keyname>Ibnelhaj</keyname><forenames>E.</forenames></author></authors><title>A Wavelet-Based Digital Watermarking for Video</title><categories>cs.MM</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 029-033, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel video watermarking system operating in the three dimensional wavelet
transform is here presented. Specifically the video sequence is partitioned
into spatio temporal units and the single shots are projected onto the 3D
wavelet domain. First a grayscale watermark image is decomposed into a series
of bitplanes that are preprocessed with a random location matrix. After that
the preprocessed bitplanes are adaptively spread spectrum and added in 3D
wavelet coefficients of the video shot. Our video watermarking algorithm is
robust against the attacks of frame dropping, averaging and swapping.
Furthermore, it allows blind retrieval of embedded watermark which does not
need the original video and the watermark is perceptually invisible. The
algorithm design, evaluation, and experimentation of the proposed scheme are
described in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0402</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0402</id><created>2009-11-02</created><authors><author><keyname>Dogra</keyname><forenames>Sudip</forenames></author><author><keyname>Ray</keyname><forenames>Ritwik</forenames></author><author><keyname>Ghosh</keyname><forenames>Saustav</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Debharshi</forenames></author><author><keyname>Sarkar</keyname><forenames>Subir Kr.</forenames></author></authors><title>A Cost Effective RFID Based Customized DVD-ROM to Thwart Software Piracy</title><categories>cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 034-039, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software piracy has been a very perilous adversary of the software based
industry, from the very beginning of the development of the latter into a
significant business. There has been no developed foolproof system that has
been developed to appropriately tackle this vile issue. We have in our scheme
tried to develop a way to embark upon this problem using a very recently
developed technology of RFID.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0405</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0405</id><created>2009-11-02</created><authors><author><keyname>Safdar</keyname><forenames>Sohail</forenames></author><author><keyname>Hassan</keyname><forenames>Mohd. Fadzil B.</forenames></author><author><keyname>Qureshi</keyname><forenames>Muhammad Aasim</forenames></author><author><keyname>Akbar</keyname><forenames>Rehan</forenames></author></authors><title>Biologically Inspired Execution Framework for Vulnerable Workflow
  Systems</title><categories>cs.CR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 047-051, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of the research is to introduce a biologically inspired
execution framework for workflow systems under threat due to some intrusion
attack. Usually vulnerable systems need to be stop and put into wait state,
hence to insure the data security and privacy while being recovered. This
research ensures the availability of services and data to the end user by
keeping the data security, privacy and integrity intact. To achieve the
specified goals, the behavior of chameleons and concept of hibernation has been
considered in combination. Hence the workflow systems become more robust using
biologically inspired methods and remain available to the business consumers
safely even in a vulnerable state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0428</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0428</id><created>2009-11-02</created><authors><author><keyname>Deneckere</keyname><forenames>Rebecca</forenames><affiliation>CRI</affiliation></author><author><keyname>Iacovelli</keyname><forenames>Adrian</forenames><affiliation>CRI</affiliation></author><author><keyname>Kornyshova</keyname><forenames>Elena</forenames><affiliation>CRI</affiliation></author><author><keyname>Souveyet</keyname><forenames>Carine</forenames><affiliation>CRI</affiliation></author></authors><title>From Method Fragments to Method Services</title><categories>cs.SE</categories><proxy>ccsd hal-00428991</proxy><journal-ref>Exploring Modeling Methods for Systems Analysis and Design
  (EMMSAD'08), Montpellier : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Method Engineering (ME) science, the key issue is the consideration of
information system development methods as fragments. Numerous ME approaches
have produced several definitions of method parts. Different in nature, these
fragments have nevertheless some common disadvantages: lack of implementation
tools, insufficient standardization effort, and so on. On the whole, the
observed drawbacks are related to the shortage of usage orientation. We have
proceeded to an in-depth analysis of existing method fragments within a
comparison framework in order to identify their drawbacks. We suggest
overcoming them by an improvement of the ?method service? concept. In this
paper, the method service is defined through the service paradigm applied to a
specific method fragment ? chunk. A discussion on the possibility to develop a
unique representation of method fragment completes our contribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0430</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0430</id><created>2009-11-02</created><authors><author><keyname>Deneckere</keyname><forenames>Rebecca</forenames><affiliation>CRI</affiliation></author><author><keyname>Kornyshova</keyname><forenames>Elena</forenames><affiliation>CRI</affiliation></author><author><keyname>Rolland</keyname><forenames>Colette</forenames><affiliation>CRI</affiliation></author></authors><title>Enhancing the Guidance of the Intentional Model &quot;MAP&quot;: Graph Theory
  Application</title><categories>cs.SE</categories><comments>9 pages</comments><proxy>ccsd hal-00428986</proxy><journal-ref>Research challenges in Information Systems, Fes : Morocco (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MAP model was introduced in information system engineering in order to
model processes on a flexible way. The intentional level of this model helps an
engineer to execute a process with a strong relationship to the situation of
the project at hand. In the literature, attempts for having a practical use of
maps are not numerous. Our aim is to enhance the guidance mechanisms of the
process execution by reusing graph algorithms. After clarifying the existing
relationship between graphs and maps, we improve the MAP model by adding
qualitative criteria. We then offer a way to express maps with graphs and
propose to use Graph theory algorithms to offer an automatic guidance of the
map. We illustrate our proposal by an example and discuss its limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0460</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0460</id><created>2009-11-03</created><updated>2009-11-04</updated><authors><author><keyname>Sill</keyname><forenames>Joseph</forenames></author><author><keyname>Takacs</keyname><forenames>Gabor</forenames></author><author><keyname>Mackey</keyname><forenames>Lester</forenames></author><author><keyname>Lin</keyname><forenames>David</forenames></author></authors><title>Feature-Weighted Linear Stacking</title><categories>cs.LG cs.AI</categories><comments>17 pages, 1 figure, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensemble methods, such as stacking, are designed to boost predictive accuracy
by blending the predictions of multiple machine learning models. Recent work
has shown that the use of meta-features, additional inputs describing each
example in a dataset, can boost the performance of ensemble methods, but the
greatest reported gains have come from nonlinear procedures requiring
significant tuning and training time. Here, we present a linear technique,
Feature-Weighted Linear Stacking (FWLS), that incorporates meta-features for
improved accuracy while retaining the well-known virtues of linear regression
regarding speed, stability, and interpretability. FWLS combines model
predictions linearly using coefficients that are themselves linear functions of
meta-features. This technique was a key facet of the solution of the second
place team in the recently concluded Netflix Prize competition. Significant
increases in accuracy over standard linear stacking are demonstrated on the
Netflix Prize collaborative filtering dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0462</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0462</id><created>2009-11-02</created><authors><author><keyname>Weinstein</keyname><forenames>Marvin</forenames></author></authors><title>Strange Bedfellows: Quantum Mechanics and Data Mining</title><categories>cs.LG physics.data-an quant-ph</categories><comments>11 pages, 7 figures, Invited Talk at Light Cone 2009</comments><report-no>SLAC-PUB-13832</report-no><doi>10.1016/j.nuclphysbps.2010.02.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Last year, in 2008, I gave a talk titled {\it Quantum Calisthenics}. This
year I am going to tell you about how the work I described then has spun off
into a most unlikely direction. What I am going to talk about is how one maps
the problem of finding clusters in a given data set into a problem in quantum
mechanics. I will then use the tricks I described to let quantum evolution lets
the clusters come together on their own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0465</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0465</id><created>2009-11-02</created><authors><author><keyname>Lappas</keyname><forenames>Theodoros</forenames></author><author><keyname>Pelechrinis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Faloutsos</keyname><forenames>Michalis</forenames></author></authors><title>A Simple Conceptual Generator for the Internet Graph</title><categories>cs.NI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of the Internet during the last years, has lead to a dramatic
increase of the size of its graph at the Autonomous System (AS) level. Soon -
if not already - its size will make the latter impractical for use from the
research community, e.g. for protocol testing. Reproducing a smaller size,
snapshot of the AS graph is thus important. However, the first step towards
this direction is to obtain the ability to faithfully reproduce the full AS
topology. The objective of our work, is to create a generator able to
accurately emulate and reproduce the distinctive properties of the Internet
graph. Our approach is based on (a) the identification of the jellyfish-like
structure [1] of the Internet and (b) the consideration of the peer-to-peer and
customer-provider relations between ASs. We are the first to exploit the
distinctive structure of the Internet graph together with utilizing the
information provided by the AS relationships in order to create a tool with the
aforementioned capabilities. Comparing our generator with the existing ones in
the literature, the main difference is found on the fact that our tool does not
try to satisfy specific metrics, but tries to remain faithful to the conceptual
model of the Internet structure. In addition, our approach can lead to (i) the
identification of important attributes and patterns in the Internet AS
topology, as well as, (ii) the extraction of valuable information on the
various relationships between ASs and their effect on the formulation of the
Internet structure. We implement our graph generator and we evaluate it using
the largest and most recent available dataset for the AS topology. Our
evaluations, clearly show the ability of our tool to capture the structural
properties of the Internet topology at the AS level with high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0467</identifier>
 <datestamp>2011-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0467</id><created>2009-11-02</created><updated>2011-10-26</updated><authors><author><keyname>Cui</keyname><forenames>Tao</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author></authors><title>On Secure Network Coding with Nonuniform or Restricted Wiretap Sets</title><categories>cs.IT math.IT</categories><comments>24 pages, revision submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secrecy capacity of a network, for a given collection of permissible
wiretap sets, is the maximum rate of communication such that observing links in
any permissible wiretap set reveals no information about the message. This
paper considers secure network coding with nonuniform or restricted wiretap
sets, for example, networks with unequal link capacities where a wiretapper can
wiretap any subset of $k$ links, or networks where only a subset of links can
be wiretapped. Existing results show that for the case of uniform wiretap sets
(networks with equal capacity links/packets where any $k$ can be wiretapped),
the secrecy capacity is given by the cut-set bound, and can be achieved by
injecting $k$ random keys at the source which are decoded at the sink along
with the message. This is the case whether or not the communicating users have
information about the choice of wiretap set. In contrast, we show that for the
nonuniform case, the cut-set bound is not achievable in general when the
wiretap set is unknown, whereas it is achievable when the wiretap set is made
known. We give achievable strategies where random keys are canceled at
intermediate non-sink nodes, or injected at intermediate non-source nodes.
Finally, we show that determining the secrecy capacity is a NP-hard problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0480</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0480</id><created>2009-11-02</created><updated>2009-11-26</updated><authors><author><keyname>Kim</keyname><forenames>Boseung</forenames></author><author><keyname>Lim</keyname><forenames>Huibin</forenames></author><author><keyname>Shin</keyname><forenames>Yongtae</forenames></author></authors><title>Routing Technique Based on Clustering for Data Duplication Prevention in
  Wireless Sensor Network</title><categories>cs.NI cs.DC cs.PF</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 061-065, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks is important to nodes energy consumption for long
activity of sensor nodes because nodes that compose sensor network are small
size, and battery capacity is limited. For energy consumption decrease of
sensor nodes, sensor networks routing technique is divided by flat routing and
hierarchical routing technique. Specially, hierarchical routing technique is
energy efficient routing protocol to pare down energy consumption of whole
sensor nodes and to scatter energy consumption of sensor nodes by forming
cluster and communicating with cluster head. but though hierarchical routing
technique based on clustering is advantage more than flat routing technique,
this is not used for reason that is not realistic. The reason that is not
realistic is because hierarchical routing technique does not consider data
transmission radius of sensor node in actually. so this paper propose realistic
routing technique base on clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0481</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0481</id><created>2009-11-02</created><authors><author><keyname>Krishnaveni</keyname><forenames>M.</forenames></author><author><keyname>Thakur</keyname><forenames>Suresh Kumar</forenames></author><author><keyname>Subashini</keyname><forenames>P.</forenames></author></authors><title>An Optimal Method For Wake Detection In SAR Images Using Radon
  Transformation Combined With Wavelet Filters</title><categories>cs.CV</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 066-069, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new fangled method for ship wake detection in synthetic aperture radar
(SAR) images is explored here. Most of the detection procedure applies the
Radon transform as its properties outfit more than any other transformation for
the detection purpose. But still it holds problems when the transform is
applied to an image with a high level of noise. Here this paper articulates the
combination between the radon transformation and the shrinkage methods which
increase the mode of wake detection process. The latter shrinkage method with
RT maximize the signal to noise ratio hence it leads to most optimal detection
of lines in the SAR images. The originality mainly works on the denoising
segment of the proposed algorithm. Experimental work outs are carried over both
in simulated and real SAR images. The detection process is more adequate with
the proposed method and improves better than the conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0482</identifier>
 <datestamp>2009-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0482</id><created>2009-11-02</created><updated>2009-11-26</updated><authors><author><keyname>Lee</keyname><forenames>Hyubgun</forenames></author><author><keyname>Lee</keyname><forenames>Kyounghwa</forenames></author><author><keyname>Shin</keyname><forenames>Yongtae</forenames></author></authors><title>AES Implementation and Performance Evaluation on 8-bit Microcontrollers</title><categories>cs.CR cs.PF</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 070-074, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sensor network is a network technique for the implementation of
Ubiquitous computing environment. It is wireless network environment that
consists of the many sensors of lightweight and low power. Though sensor
network provides various capabilities, it is unable to ensure the secure
authentication between nodes. Eventually it causes the losing reliability of
the entire network and many secure problems. Therefore, encryption algorithm
for the implementation of reliable sensor network environments is required to
the applicable sensor network. In this paper, we proposed the solution of
reliable sensor network to analyze the communication efficiency through
measuring performance of AES encryption algorithm by plaintext size, and cost
of operation per hop according to the network scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0484</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0484</id><created>2009-11-02</created><authors><author><keyname>Perez</keyname><forenames>Francisco J. Rodriguez</forenames></author><author><keyname>Sanchez</keyname><forenames>Jose Luis Gonzalez</forenames></author><author><keyname>Cervero</keyname><forenames>Alfonso Gazo</forenames></author></authors><title>GoS Proposal to Improve Trust and Delay of MPLS Flows for MCN Services</title><categories>cs.NI cs.PF</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 075-082, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, Guarantee of Service (GoS) is defined as a proposal to
improve the integration of Mission Critical Networking (MCN) services in the
Internet, analyzing the congestion impact on those privileged flows with high
requirements of trust and delay. Multiprotocol Label Switching (MPLS) is a
technology that offers flow differentiation and QoS in the Internet. Therefore,
in order to improve network performance in case of congested domains, GoS is
proposed as a technique that allows the local recovering of lost packets of
MPLS privileged flows. To fulfill the GoS requirements for integration of MCN
in MPLS, a minimum set of extensions to RSVPTE has been proposed to provide GoS
capable routes. Moreover, we have carried out an analytical study of GoS
scalability and a performance improvement analysis by means of simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0485</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0485</id><created>2009-11-02</created><authors><author><keyname>Tran</keyname><forenames>Tich Phuoc</forenames></author><author><keyname>Cao</keyname><forenames>Longbing</forenames></author><author><keyname>Tran</keyname><forenames>Dat</forenames></author><author><keyname>Nguyen</keyname><forenames>Cuong Duc</forenames></author></authors><title>Novel Intrusion Detection using Probabilistic Neural Network and
  Adaptive Boosting</title><categories>cs.NE cs.LG</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 083-091, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article applies Machine Learning techniques to solve Intrusion Detection
problems within computer networks. Due to complex and dynamic nature of
computer networks and hacking techniques, detecting malicious activities
remains a challenging task for security experts, that is, currently available
defense systems suffer from low detection capability and high number of false
alarms. To overcome such performance limitations, we propose a novel Machine
Learning algorithm, namely Boosted Subspace Probabilistic Neural Network
(BSPNN), which integrates an adaptive boosting technique and a semi parametric
neural network to obtain good tradeoff between accuracy and generality. As the
result, learning bias and generalization variance can be significantly
minimized. Substantial experiments on KDD 99 intrusion benchmark indicate that
our model outperforms other state of the art learning algorithms, with
significantly improved detection accuracy, minimal false alarms and relatively
small computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0486</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0486</id><created>2009-11-02</created><authors><author><keyname>Nguyen</keyname><forenames>Dang Tuan</forenames></author><author><keyname>Luong</keyname><forenames>Ha Quy-Tinh</forenames></author><author><keyname>Do</keyname><forenames>Tuyen Thi-Thanh</forenames></author></authors><title>Building a Vietnamese Language Query Processing Framework for ELibrary
  Searching Systems</title><categories>cs.DL cs.IR</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 092-096, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the objective of building intelligent searching systems for Elibraries or
online bookstores, we have proposed a searching system model based on a
Vietnamese language query processing component. Such document searching systems
based on this model can allow users to use Vietnamese queries that represent
content information as input, instead of entering keywords for searching in
specific fields in database. To simplify the realization process of system
based on this searching system model, we set a target of building a framework
to support the rapid development of Vietnamese language query processing
components. Such framework let the implementation of Vietnamese language query
processing component in similar systems in this domain to be done more easily.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0487</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0487</id><created>2009-11-02</created><authors><author><keyname>Manasrah</keyname><forenames>Ahmed M.</forenames></author><author><keyname>Hasan</keyname><forenames>Awsan</forenames></author><author><keyname>Abouabdalla</keyname><forenames>Omar Amer</forenames></author><author><keyname>Ramadass</keyname><forenames>Sureswaran</forenames></author></authors><title>Detecting Botnet Activities Based on Abnormal DNS traffic</title><categories>cs.NI cs.CR</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 097-104, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IThe botnet is considered as a critical issue of the Internet due to its fast
growing mechanism and affect. Recently, Botnets have utilized the DNS and query
DNS server just like any legitimate hosts. In this case, it is difficult to
distinguish between the legitimate DNS traffic and illegitimate DNS traffic. It
is important to build a suitable solution for botnet detection in the DNS
traffic and consequently protect the network from the malicious Botnets
activities. In this paper, a simple mechanism is proposed to monitors the DNS
traffic and detects the abnormal DNS traffic issued by the botnet based on the
fact that botnets appear as a group of hosts periodically. The proposed
mechanism is also able to classify the DNS traffic requested by group of hosts
(group behavior) and single hosts (individual behavior), consequently detect
the abnormal domain name issued by the malicious Botnets. Finally, the
experimental results proved that the proposed mechanism is robust and able to
classify DNS traffic, and efficiently detects the botnet activity with average
detection rate of 89 percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0488</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0488</id><created>2009-11-02</created><authors><author><keyname>Minaei</keyname><forenames>Behrouz</forenames></author><author><keyname>Saadat</keyname><forenames>Parinaz</forenames></author></authors><title>SOAP Serialization Performance Enhancement, Design And Implementation Of
  A Middleware</title><categories>cs.SE cs.PF</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 105-110, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most straightforward way to improve performance of any system is to
define the bottlenecks and think of ways to remove them. Web services are the
inseparable part of any web application, as a result enhancing performance of
web services will have a great effect on the overall performance of the system.
The most widely used communication protocol in the web services model, SOAP, is
a simple protocol for the exchange of messages. The serialization of large SOAP
responses is a major performance bottleneck in a SOAP message exchange.
Clearly, some web servers can expect to receive many similar messages for a
particular web service as they share the same signature. The idea behind this
paper is to avoid the redundant serialization stage of SOAP responses for
request which have the same call parameters. The technique exploits the
similarities between call parameters to improve web service Response Time by
avoiding redundant serialization of the same response with the help of a
middleware running on top of web server. The middleware will maintain a trie of
incoming parameters for every set of current requests. This way request
processing and serialization of the response of same requests will be done only
once. In a nutshell, to serialize only the different responses is the simplest
way to avoid extra work done by a serializer. It might worth noting that
although our approach is to utilize the exact repeating portion parameters, the
middleware can be configured to apply changes made to the result set of
response to the serialized response being maintained in a trie to generate
valid results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0490</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0490</id><created>2009-11-02</created><authors><author><keyname>Rejani</keyname><forenames>Y. Ireaneus Anna</forenames></author><author><keyname>Selvi</keyname><forenames>S. Thamarai</forenames></author></authors><title>Breast Cancer Detection Using Multilevel Thresholding</title><categories>cs.CV</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 111-115, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algorithm which aims to assist the radiologist in
identifying breast cancer at its earlier stages. It combines several image
processing techniques like image negative, thresholding and segmentation
techniques for detection of tumor in mammograms. The algorithm is verified by
using mammograms from Mammographic Image Analysis Society. The results obtained
by applying these techniques are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0492</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0492</id><created>2009-11-02</created><updated>2012-03-30</updated><authors><author><keyname>Gu</keyname><forenames>Ming</forenames></author><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author><author><keyname>Wu</keyname><forenames>Cinna Julie</forenames></author></authors><title>PARNES: A rapidly convergent algorithm for accurate recovery of sparse
  and approximately sparse signals</title><categories>math.OC cs.SY math.NA</categories><comments>22 pages, 1 figure</comments><msc-class>49M29, 58E17, 65F22, 65K05, 90C25, 90C46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose an algorithm, NESTA-LASSO, for the LASSO problem,
i.e., an underdetermined linear least-squares problem with a 1-norm constraint
on the solution. We prove under the assumption of the restricted isometry
property (RIP) and a sparsity condition on the solution, that NESTA-LASSO is
guaranteed to be almost always locally linearly convergent. As in the case of
the algorithm NESTA proposed by Becker, Bobin, and Candes, we rely on
Nesterov's accelerated proximal gradient method, which takes O(e^{-1/2})
iterations to come within e &gt; 0 of the optimal value. We introduce a
modification to Nesterov's method that regularly updates the prox-center in a
provably optimal manner, and the aforementioned linear convergence is in part
due to this modification.
  In the second part of this article, we attempt to solve the basis pursuit
denoising BPDN problem (i.e., approximating the minimum 1-norm solution to an
underdetermined least squares problem) by using NESTA-LASSO in conjunction with
the Pareto root-finding method employed by van den Berg and Friedlander in
their SPGL1 solver. The resulting algorithm is called PARNES. We provide
numerical evidence to show that it is comparable to currently available
solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0493</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0493</id><created>2009-11-02</created><authors><author><keyname>Mukesh</keyname><forenames>Rajeswari</forenames></author><author><keyname>Damodaram</keyname><forenames>A.</forenames></author><author><keyname>Bharathi</keyname><forenames>V. Subbiah</forenames></author></authors><title>Energy Efficient Security Architecture for Wireless BioMedical Sensor
  Networks</title><categories>cs.CR</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 116-122, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latest developments in VLSI, wireless communications, and biomedical sensing
devices allow very small, lightweight, low power, intelligent sensing devices
called biosensors. A set of these devices can be integrated into a Wireless
Biomedical Sensor Network (WBSN), a new breakthrough technology used in
telemedicine for monitoring the physiological condition of an individual. The
biosensor nodes in WBSN has got resource limitations in terms of battery
lifetime, CPU processing capability, and memory capacity. Replacement or
recharging of batteries on thousands of biosensor nodes is quiet difficult or
too costly. So, a key challenge in wireless biomedical sensor networks is the
reduction of energy and memory consumption. Considering, the sensitivity of
information in WBSN, we must provide security and patient privacy, as it is an
important issue in the design of such systems. Hence this paper proposes an
energy efficient security protocol for WBSN where security is provided to the
physiological data, which is being transmitted from the sensor node to the sink
device. This is achieved by authenticating the data using patients biometric,
encrypting the data using Quasi Group cryptography after compressing the image
data using an energy efficient number theory based technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0494</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0494</id><created>2009-11-02</created><authors><author><keyname>Banerjee</keyname><forenames>C.</forenames></author><author><keyname>Pandey</keyname><forenames>S. K.</forenames></author></authors><title>Software Security Rules, SDLC Perspective</title><categories>cs.SE cs.CR</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 123-128, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software has become an integral part of everyday life. Everyday, millions of
people perform transaction through internet, ATM, mobile phone, they send email
and Egreetings, and use word processing and spreadsheet for various purpose.
People use software bearing in mind that it is reliable and can be trust upon
and the operation they perform is secured. Now, if these software have
exploitable security hole then how can they be safe for use. Security brings
value to software in terms of peoples trust. The value provided by secure
software is of vital importance because many critical functions are entirely
dependent on the software. That is why security is a serious topic which should
be given proper attention during the entire SDLC, right from the beginning. For
the proper implementation of security in the software, twenty one security
rules are proposed in this paper along with validation results. It is found
that by applying these rules as per given implementation mechanism, most of the
vulnerabilities are eliminated in the software and a more secure software can
be built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0497</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0497</id><created>2009-11-03</created><authors><author><keyname>Razavi</keyname><forenames>Negin</forenames></author><author><keyname>Rahmani</keyname><forenames>Amir Masoud</forenames></author><author><keyname>Mohsenzadeh</keyname><forenames>Mehran</forenames></author></authors><title>A Context-based Trust Management Model for Pervasive Computing Systems</title><categories>cs.CR</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 137-142, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trust plays an important role in making collaborative decisions about service
evaluation and service selection in pervasive computing. Context is a
fundamental concept in pervasive systems, which is based on the interpretation
of environment and systems. The dynamic nature of context can strongly affect
trust management and service selection. In this paper, we present a
context-based trust management model for pervasive computing systems. The
concept of context is considered in basic components of the model such as trust
computation module, recommender assessment module, transaction management
module, and request responder. In order to measure a predicted trustworthiness
according to the fuzzy nature of trust in pervasive environments, fuzzy
concepts are integrated in the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0498</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0498</id><created>2009-11-03</created><authors><author><keyname>Siadat</keyname><forenames>Safieh</forenames></author><author><keyname>Rahmani</keyname><forenames>Amir Masoud</forenames></author><author><keyname>Mohsenzadeh</keyname><forenames>Mehran</forenames></author></authors><title>Proposed platform for improving grid security by trust management system</title><categories>cs.CR</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 143-148, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With increasing the applications of grid system, the risk in security field
is enhancing too. Recently Trust management system has been recognized as a
noticeable approach in enhancing of security in grid systems. In this article
due to improve the grid security a new trust management system with two levels
is proposed. The benefits of this platform are adding new domain in grid
system, selecting one service provider which has closest adaption with user
requests and using from domains security attribute as an important factor in
computing the trust value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0499</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0499</id><created>2009-11-03</created><authors><author><keyname>Perumal</keyname><forenames>Vani</forenames></author><author><keyname>Ramaswamy</keyname><forenames>Jagannathan</forenames></author></authors><title>An Innovative Scheme For Effectual Fingerprint Data Compression Using
  Bezier Curve Representations</title><categories>cs.CV cs.CR cs.MM</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 149-157, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Naturally, with the mounting application of biometric systems, there arises a
difficulty in storing and handling those acquired biometric data. Fingerprint
recognition has been recognized as one of the most mature and established
technique among all the biometrics systems. In recent times, with fingerprint
recognition receiving increasingly more attention the amount of fingerprints
collected has been constantly creating enormous problems in storage and
transmission. Henceforth, the compression of fingerprints has emerged as an
indispensable step in automated fingerprint recognition systems. Several
researchers have presented approaches for fingerprint image compression. In
this paper, we propose a novel and efficient scheme for fingerprint image
compression. The presented scheme utilizes the Bezier curve representations for
effective compression of fingerprint images. Initially, the ridges present in
the fingerprint image are extracted along with their coordinate values using
the approach presented. Subsequently, the control points are determined for all
the ridges by visualizing each ridge as a Bezier curve. The control points of
all the ridges determined are stored and are used to represent the fingerprint
image. When needed, the fingerprint image is reconstructed from the stored
control points using Bezier curves. The quality of the reconstructed
fingerprint is determined by a formal evaluation. The proposed scheme achieves
considerable memory reduction in storing the fingerprint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0501</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0501</id><created>2009-11-03</created><authors><author><keyname>Hosam</keyname><forenames>Al-Sammarraie</forenames></author><author><keyname>Mustafa</keyname><forenames>Adli</forenames></author><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author><author><keyname>Abbas</keyname><forenames>Merza</forenames></author></authors><title>Exception Agent Detection System for IP Spoofing Over Online
  Environments</title><categories>cs.CR</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 158-164, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the recent years, IP and email spoofing gained much importance for
security concerns due to the current changes in manipulating the system
performance in different online environments. Intrusion Detection System (IDS)
has been used to secure these environments for sharing their data over network
and host based IDS approaches. However, the rapid growth of intrusion events
over Internet and local area network become responsible for the distribution of
different threats and vulnerabilities in the computing systems. The current
signature detection approach used by IDS, detects unclear actions based on
analyzing and describing the action patterns such as time, text, password etc
and has been faced difficulties in updating information, detect unknown novel
attacks, maintenance of an IDS which is necessarily connected with analyzing
and patching of security holes, and the lack of information on user privileges
and attack signature structure. Thus, this paper proposes an EADS (Exception
agent detection system) for securing the header information carried by IP over
online environments. The study mainly concerns with the deployment of new
technique for detecting and eliminating the unknown threats attacks during the
data sharing over online environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0503</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0503</id><created>2009-11-03</created><authors><author><keyname>Rajaram</keyname><forenames>A.</forenames></author><author><keyname>Palaniswami</keyname><forenames>Dr. S.</forenames></author></authors><title>A Trust Based Cross Layer Security Protocol for Mobile Ad hoc Networks</title><categories>cs.CR</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 165-172, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a trust based security protocol based on a cross
layer approach which attains confidentiality and authentication of packets in
both routing and link layers of MANETs. In the first phase of the protocol, we
design a trust based packet forwarding scheme for detecting and isolating the
malicious nodes using the routing layer information. It uses trust values to
favor packet forwarding by maintaining a trust counter for each node. A node is
punished or rewarded by decreasing or increasing the trust counter. If the
trust counter value falls below a trust threshold, the corresponding
intermediate node is marked as malicious. In the next phase of the protocol, we
provide link layer security using the CBCX mode of authentication and
encryption. By simulation results, we show that the proposed cross layer
security protocol achieves high packet delivery ratio while attaining low delay
and overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0505</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0505</id><created>2009-11-03</created><authors><author><keyname>Borne</keyname><forenames>Kirk</forenames><affiliation>George Mason University</affiliation></author></authors><title>Scientific Data Mining in Astronomy</title><categories>astro-ph.IM cs.DB cs.IR physics.data-an</categories><comments>26 pages</comments><journal-ref>Borne, K., in Next Generation of Data Mining (Taylor &amp; Francis:
  CRC Press), pp. 91-114 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the application of data mining algorithms to research problems in
astronomy. We posit that data mining has always been fundamental to
astronomical research, since data mining is the basis of evidence-based
discovery, including classification, clustering, and novelty discovery. These
algorithms represent a major set of computational tools for discovery in large
databases, which will be increasingly essential in the era of data-intensive
astronomy. Historical examples of data mining in astronomy are reviewed,
followed by a discussion of one of the largest data-producing projects
anticipated for the coming decade: the Large Synoptic Survey Telescope (LSST).
To facilitate data-driven discoveries in astronomy, we envision a new
data-oriented research paradigm for astronomy and astrophysics --
astroinformatics. Astroinformatics is described as both a research approach and
an educational imperative for modern data-intensive astronomy. An important
application area for large time-domain sky surveys (such as LSST) is the rapid
identification, characterization, and classification of real-time sky events
(including moving objects, photometrically variable objects, and the appearance
of transients). We describe one possible implementation of a classification
broker for such events, which incorporates several astroinformatics techniques:
user annotation, semantic tagging, metadata markup, heterogeneous data
integration, and distributed data mining. Examples of these types of
collaborative classification and discovery approaches within other science
disciplines are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0508</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0508</id><created>2009-11-03</created><authors><author><keyname>Guravannavar</keyname><forenames>Ravindra</forenames></author></authors><title>Optimization and Evaluation of Nested Queries and Procedures</title><categories>cs.DB</categories><comments>Ph.D. thesis, 167 pages</comments><acm-class>H.2.4; H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many database applications perform complex data retrieval and update tasks.
Nested queries, and queries that invoke user-defined functions, which are
written using a mix of procedural and SQL constructs, are often used in such
applications. A straight-forward evaluation of such queries involves repeated
execution of parameterized sub-queries or blocks containing queries and
procedural code.
  An important problem that arises while optimizing nested queries as well as
queries with joins, aggregates and set operations is the problem of finding an
optimal sort order from a factorial number of possible sort orders. We show
that even a special case of this problem is NP-Hard, and present practical
heuristics that are effective and easy to incorporate in existing query
optimizers.
  We also consider iterative execution of queries and updates inside complex
procedural blocks such as user-defined functions and stored procedures.
Parameter batching is an important means of improving performance as it enables
set-orientated processing. The key challenge to parameter batching lies in
rewriting a given procedure/function to process a batch of parameter values. We
propose a solution, based on program analysis and rewrite rules, to automate
the generation of batched forms of procedures and replace iterative database
calls within imperative loops with a single call to the batched form.
  We present experimental results for the proposed techniques, and the results
show significant gains in performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0519</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0519</id><created>2009-11-03</created><updated>2011-03-08</updated><authors><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Elron</keyname><forenames>Asaf</forenames></author></authors><title>Xampling: Signal Acquisition and Processing in Union of Subspaces</title><categories>cs.IT math.IT</categories><comments>16 pages, 9 figures, submitted to IEEE for possible publication</comments><report-no>CCIT Report #747 Oct-09, EE Pub No. 1704, EE Dept., Technion -
  Israel Institute of Technology (refers to v1)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Xampling, a unified framework for signal acquisition and
processing of signals in a union of subspaces. The main functions of this
framework are two. Analog compression that narrows down the input bandwidth
prior to sampling with commercial devices. A nonlinear algorithm then detects
the input subspace prior to conventional signal processing. A representative
union model of spectrally-sparse signals serves as a test-case to study these
Xampling functions. We adopt three metrics for the choice of analog
compression: robustness to model mismatch, required hardware accuracy and
software complexities. We conduct a comprehensive comparison between two
sub-Nyquist acquisition strategies for spectrally-sparse signals, the random
demodulator and the modulated wideband converter (MWC), in terms of these
metrics and draw operative conclusions regarding the choice of analog
compression. We then address lowrate signal processing and develop an algorithm
for that purpose that enables convenient signal processing at sub-Nyquist rates
from samples obtained by the MWC. We conclude by showing that a variety of
other sampling approaches for different union classes fit nicely into our
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0542</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0542</id><created>2009-11-03</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Yoon</keyname><forenames>HeeSeok</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Radio Transmission Performance of EPCglobal Gen-2 RFID System</title><categories>cs.OH</categories><comments>6 6ages, 13 figures, 3 tables, International Conference on Advanced
  Communication Technology 2008</comments><journal-ref>ICACT, Korea, Phoenix Park, Feb. 2008, pp. 1423-1428</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the performance of the encoding and the modulation
processes in the downlink and uplink of the EPCglobal Gen2 system through the
analysis and simulation. Furthermore, the synchronization issues on time and
frequency domain and the preamble architecture are evaluated. Through the
simulation in the uplink, we find that the detection probability of FM0 and
Miller coding approaches 1 at 13dB Eb/N0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0547</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0547</id><created>2009-11-03</created><authors><author><keyname>Avron</keyname><forenames>Haim</forenames></author><author><keyname>Shklarski</keyname><forenames>Gil</forenames></author><author><keyname>Toledo</keyname><forenames>Sivan</forenames></author></authors><title>On Element SDD Approximability</title><categories>cs.NA</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short communication shows that in some cases scalar elliptic finite
element matrices cannot be approximated well by an SDD matrix. We also give a
theoretical analysis of a simple heuristic method for approximating an element
by an SDD matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0577</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0577</id><created>2009-11-03</created><updated>2010-09-08</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author></authors><title>Fast Arc-Annotated Subsequence Matching in Linear Space</title><categories>cs.DS</categories><comments>To appear in Algoritmica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An arc-annotated string is a string of characters, called bases, augmented
with a set of pairs, called arcs, each connecting two bases. Given
arc-annotated strings $P$ and $Q$ the arc-preserving subsequence problem is to
determine if $P$ can be obtained from $Q$ by deleting bases from $Q$. Whenever
a base is deleted any arc with an endpoint in that base is also deleted.
Arc-annotated strings where the arcs are ``nested'' are a natural model of RNA
molecules that captures both the primary and secondary structure of these. The
arc-preserving subsequence problem for nested arc-annotated strings is basic
primitive for investigating the function of RNA molecules. Gramm et al. [ACM
Trans. Algorithms 2006] gave an algorithm for this problem using $O(nm)$ time
and space, where $m$ and $n$ are the lengths of $P$ and $Q$, respectively. In
this paper we present a new algorithm using $O(nm)$ time and $O(n + m)$ space,
thereby matching the previous time bound while significantly reducing the space
from a quadratic term to linear. This is essential to process large RNA
molecules where the space is likely to be a bottleneck. To obtain our result we
introduce several novel ideas which may be of independent interest for related
problems on arc-annotated strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0626</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0626</id><created>2009-11-03</created><updated>2009-11-03</updated><authors><author><keyname>Hu</keyname><forenames>Yifan</forenames></author></authors><title>Visualizing Graphs with Node and Edge Labels</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When drawing graphs whose edges and nodes contain text or graphics, such
informa tion needs to be displayed without overlaps, either as part of the
initial layout or as a post-processing step. The core problem in removing
overlaps lies in retaining the structural information inherent in a layout,
minimizing the additional area required, and keeping edges as straight as
possible. This paper presents a unified node and edge overlap removal algorithm
that does well at solving this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0630</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0630</id><created>2009-11-03</created><updated>2011-07-07</updated><authors><author><keyname>Beffara</keyname><forenames>Emmanuel</forenames><affiliation>IML</affiliation></author></authors><title>Order algebras: a quantitative model of interaction</title><categories>cs.LO cs.DM math.CO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quantitative model of concurrent interaction is introduced. The basic
objects are linear combinations of partial order relations, acted upon by a
group of permutations that represents potential non-determinism in
synchronisation. This algebraic structure is shown to provide faithful
interpretations of finitary process algebras, for an extension of the standard
notion of testing semantics, leading to a model that is both denotational (in
the sense that the internal workings of processes are ignored) and
non-interleaving. Constructions on algebras and their subspaces enjoy a good
structure that make them (nearly) a model of differential linear logic, showing
that the underlying approach to the representation of non-determinism as linear
combinations is the same.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0645</identifier>
 <datestamp>2009-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0645</id><created>2009-11-03</created><updated>2009-11-21</updated><authors><author><keyname>Huggins</keyname><forenames>Peter</forenames></author><author><keyname>Li</keyname><forenames>Wenbin</forenames></author><author><keyname>Haws</keyname><forenames>David</forenames></author><author><keyname>Friedrich</keyname><forenames>Thomas</forenames></author><author><keyname>Liu</keyname><forenames>Jinze</forenames></author><author><keyname>Yoshida</keyname><forenames>Ruriko</forenames></author></authors><title>Bayes estimators for phylogenetic reconstruction</title><categories>q-bio.PE cs.LG q-bio.QM</categories><comments>31 pages, 4 figures, and 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tree reconstruction methods are often judged by their accuracy, measured by
how close they get to the true tree. Yet most reconstruction methods like ML do
not explicitly maximize this accuracy. To address this problem, we propose a
Bayesian solution. Given tree samples, we propose finding the tree estimate
which is closest on average to the samples. This ``median'' tree is known as
the Bayes estimator (BE). The BE literally maximizes posterior expected
accuracy, measured in terms of closeness (distance) to the true tree. We
discuss a unified framework of BE trees, focusing especially on tree distances
which are expressible as squared euclidean distances. Notable examples include
Robinson--Foulds distance, quartet distance, and squared path difference. Using
simulated data, we show Bayes estimators can be efficiently computed in
practice by hill climbing. We also show that Bayes estimators achieve higher
accuracy, compared to maximum likelihood and neighbor joining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0660</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0660</id><created>2009-11-03</created><authors><author><keyname>Gohary</keyname><forenames>Ramy H.</forenames></author><author><keyname>Davidson</keyname><forenames>Timothy N.</forenames></author></authors><title>The capacity region of a product of two unmatched Gaussian broadcast
  channels with three particular messages and a common message</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a Gaussian broadcast channel with two unmatched degraded
components, three particular messages, and a common message that is intended
for all three receivers. It is shown that for this channel superposition coding
and Gaussian signalling is sufficient to achieve every point in the capacity
region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0664</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0664</id><created>2009-11-03</created><updated>2013-11-30</updated><authors><author><keyname>Potechin</keyname><forenames>Aaron</forenames></author></authors><title>Bounds on monotone switching networks for directed connectivity</title><categories>cs.CC</categories><comments>52 pages, 17 figures</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We separate monotone analogues of L and NL by proving that any monotone
switching network solving directed connectivity on a set V(G) of n vertices
must have size at least n^(Omega(\lg(n))).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0696</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0696</id><created>2009-11-03</created><authors><author><keyname>Gurvits</keyname><forenames>Leonid</forenames></author></authors><title>A proof of the log-concavity conjecture related to the computation of
  the ergodic capacity of MIMO channels</title><categories>cs.IT math.IT</categories><comments>6 pages, a proof of a conjecture posed in arXiv:0903.1952. We used
  techniques, developed in arXiv:0711.3496</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An upper bound on the ergodic capacity of {\bf MIMO} channels was introduced
recently in arXiv:0903.1952. This upper bound amounts to the maximization on
the simplex of some multilinear polynomial $p(\lambda_1,...,\lambda_n)$ with
non-negative coefficients. Interestingly, the coefficients are subpermanents of
some non-negative matrix. In general, such maximizations problems are {\bf
NP-HARD}. But if say, the functional $\log(p)$ is concave on the simplex and
can be efficiently evaluated, then the maximization can also be done
efficiently. Such log-concavity was conjectured in arXiv:0903.1952. We give in
this paper self-contained proof of the conjecture, based on the theory of {\bf
H-Stable} polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0709</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0709</id><created>2009-11-03</created><authors><author><keyname>Park</keyname><forenames>Hong Ju</forenames></author><author><keyname>Li</keyname><forenames>Boyu</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Constellation Precoded Multiple Beamforming</title><categories>cs.IT math.IT</categories><comments>submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beamforming techniques that employ Singular Value Decomposition (SVD) are
commonly used in Multi-Input Multi-Output (MIMO) wireless communication
systems. In the absence of channel coding, when a single symbol is transmitted,
these systems achieve the full diversity order provided by the channel; whereas
when multiple symbols are simultaneously transmitted, this property is lost.
When channel coding is employed, full diversity order can be achieved. For
example, when Bit-Interleaved Coded Modulation (BICM) is combined with this
technique, full diversity order of NM in an MxN MIMO channel transmitting S
parallel streams is possible, provided a condition on S and the BICM
convolutional code rate is satisfied. In this paper, we present constellation
precoded multiple beamforming which can achieve the full diversity order both
with BICM-coded and uncoded SVD systems. We provide an analytical proof of this
property. To reduce the computational complexity of Maximum Likelihood (ML)
decoding in this system, we employ Sphere Decoding (SD). We report an SD
technique that reduces the computational complexity beyond commonly used
approaches to SD. This technique achieves several orders of magnitude reduction
in computational complexity not only with respect to conventional ML decoding
but also, with respect to conventional SD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0727</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0727</id><created>2009-11-03</created><authors><author><keyname>Agarwal</keyname><forenames>Animesh</forenames></author><author><keyname>Shrimali</keyname><forenames>Vaibhav</forenames></author><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author></authors><title>GSM Security Using Identity-based Cryptography</title><categories>cs.CR</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current security model in Global System for Mobile Communications (GSM)
predominantly use symmetric key cryptography. The rapid advancement of Internet
technology facilitates online trading, banking, downloading, emailing using
resource-constrained handheld devices such as personal digital assistants and
cell phones. However, these applications require more security than the present
GSM supports. Consequently, a careful design of GSM security using both
symmetric and asymmetric key cryptography would make GSM security more
adaptable in security intensive applications. This paper presents a secure and
efficient protocol for GSM security using identity based cryptography. The
salient features of the proposed protocol are (i) authenticated key exchange;
(ii) mutual authentication amongst communicating entities; and (iii) user
anonymity. The security analysis of the protocol shows its strength against
some known threats observed in conventional GSM security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0736</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0736</id><created>2009-11-04</created><authors><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Laska</keyname><forenames>Jason N.</forenames></author><author><keyname>Boufounos</keyname><forenames>Petros T.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>A simple proof that random matrices are democratic</title><categories>math.NA cs.IT math.IT</categories><report-no>Rice University Department of Electrical and Computer Engineering
  Technical Report TREE0906</report-no><msc-class>41A46, 68W20, 90C27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently introduced theory of compressive sensing (CS) enables the
reconstruction of sparse or compressible signals from a small set of
nonadaptive, linear measurements. If properly chosen, the number of
measurements can be significantly smaller than the ambient dimension of the
signal and yet preserve the significant signal information. Interestingly, it
can be shown that random measurement schemes provide a near-optimal encoding in
terms of the required number of measurements. In this report, we explore
another relatively unexplored, though often alluded to, advantage of using
random matrices to acquire CS measurements. Specifically, we show that random
matrices are democractic, meaning that each measurement carries roughly the
same amount of signal information. We demonstrate that by slightly increasing
the number of measurements, the system is robust to the loss of a small number
of arbitrary measurements. In addition, we draw connections to oversampling and
demonstrate stability from the loss of significantly more measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0737</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0737</id><created>2009-11-04</created><authors><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Multiple Description Coding of Discrete Ergodic Sources</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, presented at 2009 Allerton Conference on
  Communication, Control and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of Multiple Description (MD) coding of discrete
ergodic processes. We introduce the notion of MD stationary coding, and
characterize its relationship to the conventional block MD coding. In
stationary coding, in addition to the two rate constraints normally considered
in the MD problem, we consider another rate constraint which reflects the
conditional entropy of the process generated by the third decoder given the
reconstructions of the two other decoders. The relationship that we establish
between stationary and block MD coding enables us to devise a universal
algorithm for MD coding of discrete ergodic sources, based on simulated
annealing ideas that were recently proven useful for the standard rate
distortion problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0753</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0753</id><created>2009-11-04</created><authors><author><keyname>De Meo</keyname><forenames>P.</forenames></author><author><keyname>Quattrone</keyname><forenames>G.</forenames></author><author><keyname>Terracina</keyname><forenames>G.</forenames></author><author><keyname>Ursino</keyname><forenames>D.</forenames></author></authors><title>An XML-based Multi-Agent System for Supporting Online Recruitment
  Services</title><categories>cs.MA</categories><comments>16 pages, 5 figures</comments><journal-ref>IEEE Transactions on Systems, Man, and Cybernetics, Part A 37(4):
  464-480 (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an XML-based multi-agent recommender system for
supporting online recruitment services. Our system is characterized by the
following features: {\em (i)} it handles user profiles for personalizing the
job search over the Internet; {\em (ii)} it is based on the Intelligent Agent
Technology; {\em (iii)} it uses XML for guaranteeing a light, versatile and
standard mechanism for information representation, storing and exchange. The
paper discusses the basic features of the proposed system, presents the results
of an experimental study we have carried out for evaluating its performance,
and makes a comparison between the proposed system and other e-recruitment
systems already presented in the past.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0781</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0781</id><created>2009-11-04</created><authors><author><keyname>Saxena</keyname><forenames>Kanak</forenames></author><author><keyname>Rajpoot</keyname><forenames>D. S</forenames></author></authors><title>A Way to Understand Various Patterns of Data Mining Techniques for
  Selected Domains</title><categories>cs.DB cs.IR</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 186-191, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This has much in common with traditional work in statistics and machine
learning. However, there are important new issues which arise because of the
sheer size of the data. One of the important problem in data mining is the
Classification-rule learning which involves finding rules that partition given
data into predefined classes. In the data mining domain where millions of
records and a large number of attributes are involved, the execution time of
existing algorithms can become prohibitive, particularly in interactive
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0785</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0785</id><created>2009-11-04</created><authors><author><keyname>Irfan</keyname><forenames>M.</forenames></author><author><keyname>Baig</keyname><forenames>M. M. Tahir N.</forenames></author><author><keyname>Khan</keyname><forenames>Furqan H.</forenames></author><author><keyname>Hashmi</keyname><forenames>Raheel M.</forenames></author><author><keyname>Shehzad</keyname><forenames>Khurram</forenames></author><author><keyname>Ali</keyname><forenames>Assad</forenames></author></authors><title>Management of Location Based Advertisement Services using Spatial
  Triggers in Cellular Networks</title><categories>cs.NI</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 181-185, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the advent of new technologies which have emerged under
the area of Location Based Services (LBS). An innovative implementation and
approach has been presented for design of applications which are inventive and
attractive towards the user. Spatial Trigger is one of the most promising
additions to the LBS technologies. This paper describes ways in which mobile
advertisement services can be introduced effectively in the cellular market by
bringing innovation in them through effective usage of Spatial Triggers. Hence,
opening new horizons to make the consumer cellular networks, commercially, more
effective and informative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0787</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0787</id><created>2009-11-04</created><authors><author><keyname>Singh</keyname><forenames>Shailendra</forenames></author><author><keyname>Silakari</keyname><forenames>Sanjay</forenames></author></authors><title>Generalized Discriminant Analysis algorithm for feature reduction in
  Cyber Attack Detection System</title><categories>cs.CR cs.CV cs.NE</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 173-180, October 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Generalized Discriminant Analysis (GDA) has provided an extremely
powerful approach to extracting non linear features. The network traffic data
provided for the design of intrusion detection system always are large with
ineffective information, thus we need to remove the worthless information from
the original high dimensional database. To improve the generalization ability,
we usually generate a small set of features from the original input variables
by feature extraction. The conventional Linear Discriminant Analysis (LDA)
feature reduction technique has its limitations. It is not suitable for non
linear dataset. Thus we propose an efficient algorithm based on the Generalized
Discriminant Analysis (GDA) feature reduction technique which is novel approach
used in the area of cyber attack detection. This not only reduces the number of
the input features but also increases the classification accuracy and reduces
the training and testing time of the classifiers by selecting most
discriminating features. We use Artificial Neural Network (ANN) and C4.5
classifiers to compare the performance of the proposed technique. The result
indicates the superiority of algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0790</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0790</id><created>2009-11-04</created><updated>2011-07-11</updated><authors><author><keyname>Gasilov</keyname><forenames>Nizami</forenames></author><author><keyname>Fatullayev</keyname><forenames>Afet Golayo&#x11f;lu</forenames></author><author><keyname>Amrahov</keyname><forenames>&#x15e;ahin Emrah</forenames></author></authors><title>Solution of Non-Square Fuzzy Linear Systems</title><categories>cs.NA</categories><comments>15 pages, 3 figure</comments><acm-class>G.1.3; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a linear system of equations with crisp coefficients and fuzzy
right-hand sides is investigated. All possible cases pertaining to the number
of variables, n, and the number of equations, m, are dealt with. A solution is
sought not as a fuzzy vector, as usual, but as a fuzzy set of vectors. Each
vector in the solution set solves the given fuzzy linear system with a certain
possibility. Assuming that the coefficient matrix is a full rank matrix, three
cases are considered: For m = n (square system), the solution set is shown to
be a parallelepiped in coordinate space and is expressed by an explicit
formula. For m &gt; n (overdetermined system), the solution set is proved to be a
convex polyhedron and a novel geometric method is proposed to compute it. For m
&lt; n (underdetermined system), by determining the contribution of free
variables, general solution is computed. From the results of three cases
mentioned above, a method is proposed to handle the general case, in which the
coefficient matrix is not necessarily a full rank matrix. Comprehensive
examples are provided and investigated in depth to illustrate each case and
suggested method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0801</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0801</id><created>2009-11-04</created><updated>2011-12-06</updated><authors><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author></authors><title>Tractable hypergraph properties for constraint satisfaction and
  conjunctive queries</title><categories>cs.DS cs.CC cs.DB cs.DM</categories><comments>Extended abstract appeared in STOC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important question in the study of constraint satisfaction problems (CSP)
is understanding how the graph or hypergraph describing the incidence structure
of the constraints influences the complexity of the problem. For binary CSP
instances (i.e., where each constraint involves only two variables), the
situation is well understood: the complexity of the problem essentially depends
on the treewidth of the graph of the constraints. However, this is not the
correct answer if constraints with unbounded number of variables are allowed,
and in particular, for CSP instances arising from query evaluation problems in
database theory. Formally, if H is a class of hypergraphs, then let CSP(H) be
CSP restricted to instances whose hypergraph is in H. Our goal is to
characterize those classes of hypergraphs for which CSP(H) is polynomial-time
solvable or fixed-parameter tractable, parameterized by the number of
variables. Note that in the applications related to database query evaluation,
we usually assume that the number of variables is much smaller than the size of
the instance, thus parameterization by the number of variables is a meaningful
question. The most general known property of H that makes CSP(H)
polynomial-time solvable is bounded fractional hypertree width. Here we
introduce a new hypergraph measure called submodular width, and show that
bounded submodular width of H implies that CSP(H) is fixed-parameter tractable.
In a matching hardness result, we show that if H has unbounded submodular
width, then CSP(H) is not fixed-parameter tractable, unless the Exponential
Time Hypothesis fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0820</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0820</id><created>2009-11-04</created><updated>2009-11-11</updated><authors><author><keyname>Ahmedin</keyname><forenames>Ahmed</forenames></author><author><keyname>Ali</keyname><forenames>Marwa</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>Power and Transmission Duration Control for Un-Slotted Cognitive Radio
  Networks</title><categories>cs.IT math.IT</categories><comments>submitted to DySPAN 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an unslotted primary channel with alternating on/off activity and
provide a solution to the problem of finding the optimal secondary transmission
power and duration given some sensing outcome. The goal is to maximize a
weighted sum of the primary and secondary throughput where the weight is
determined by the minimum rate required by the primary terminals. The primary
transmitter sends at a fixed power and a fixed rate. Its on/off durations
follow an exponential distribution. Two sensing schemes are considered: perfect
sensing in which the actual state of the primary channel is revealed, and soft
sensing in which the secondary transmission power and time are determined based
on the sensing metric directly. We use an upperbound for the secondary
throughput assuming that the secondary receiver tracks the instantaneous
secondary channel state information. The objective function is non-convex and,
hence, the optimal solution is obtained via exhaustive search. Our results show
that an increase in the overall weighted throughput can be obtained by allowing
the secondary to transmit even when the channel is found to be busy. For the
examined system parameter values, the throughput gain from soft sensing is
marginal. Further investigation is needed for assessing the potential of soft
sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0838</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0838</id><created>2009-11-04</created><updated>2010-01-04</updated><authors><author><keyname>Martin</keyname><forenames>St&#xe9;phane</forenames><affiliation>LIF</affiliation></author><author><keyname>Lugiez</keyname><forenames>Denis</forenames><affiliation>LIF</affiliation></author></authors><title>Research report : Collaborative Peer 2 Peer Edition: Avoiding Conflicts
  is Better than Solving Conflicts</title><categories>cs.HC</categories><comments>12 pages</comments><proxy>ccsd hal-00429612</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative edition is achieved by distinct sites that work independently
on (a copy of) a shared document. Conflicts may arise during this process and
must be solved by the collaborative editor. In pure Peer to Peer collaborative
editing, no centralization nor locks nor time-stamps are used which make
conflict resolution difficult. We propose an algorithm which relies on the
notion or semantics dependence and avoids the need of any integration
transformation to solve conflicts. Furthermore, it doesn't use any history file
recording operations performed since starting the edition process. We show how
to define editing operations for semi-structured documents i.e. XML-like trees,
that are enriched with informations derived for free from the editing process.
Then we define the semantics dependence relation required by the algorithm and
we present preliminary results obtained by a prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0844</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0844</id><created>2009-11-04</created><authors><author><keyname>Nashed</keyname><forenames>M. Zuhair</forenames></author><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author></authors><title>Sampling and Reconstruction of Signals in a Reproducing Kernel Subspace
  of $L^p({\Bbb R}^d)$</title><categories>cs.IT math.FA math.IT</categories><journal-ref>Journal of Functional Analysis Volume 258, Issue 7, 1 April 2010,
  Pages 2422-2452</journal-ref><doi>10.1016/j.jfa.2009.12.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider sampling and reconstruction of signals in a
reproducing kernel subspace of $L^p(\Rd), 1\le p\le \infty$, associated with an
idempotent integral operator whose kernel has certain off-diagonal decay and
regularity. The space of $p$-integrable non-uniform splines and the
shift-invariant spaces generated by finitely many localized functions are our
model examples of such reproducing kernel subspaces of $L^p(\Rd)$. We show that
a signal in such reproducing kernel subspaces can be reconstructed in a stable
way from its samples taken on a relatively-separated set with sufficiently
small gap. We also study the exponential convergence, consistency, and the
asymptotic pointwise error estimate of the iterative approximation-projection
algorithm and the iterative frame algorithm for reconstructing a signal in
those reproducing kernel spaces from its samples with sufficiently small gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0874</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0874</id><created>2009-11-04</created><authors><author><keyname>Cuff</keyname><forenames>Paul</forenames><affiliation>Princeton University</affiliation></author></authors><title>State Information in Bayesian Games</title><categories>cs.IT cs.CR cs.GT math.IT</categories><comments>Presented at Allerton 2009, 6 pages, 5 eps figures, uses IEEEtran.cls</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-player zero-sum repeated games are well understood. Computing the value
of such a game is straightforward. Additionally, if the payoffs are dependent
on a random state of the game known to one, both, or neither of the players,
the resulting value of the game has been analyzed under the framework of
Bayesian games. This investigation considers the optimal performance in a game
when a helper is transmitting state information to one of the players.
  Encoding information for an adversarial setting (game) requires a different
result than rate-distortion theory provides. Game theory has accentuated the
importance of randomization (mixed strategy), which does not find a significant
role in most communication modems and source coding codecs. Higher rates of
communication, used in the right way, allow the message to include the
necessary random component useful in games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0878</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0878</id><created>2009-11-04</created><authors><author><keyname>Ib&#xe1;&#xf1;ez</keyname><forenames>S. A.</forenames></author><author><keyname>Fierens</keyname><forenames>P. I.</forenames></author><author><keyname>Patterson</keyname><forenames>G. A.</forenames></author><author><keyname>Perazzo</keyname><forenames>R. P. J.</forenames></author><author><keyname>Grosz</keyname><forenames>D. F.</forenames></author></authors><title>One-bit stochastic resonance storage device</title><categories>nlin.AO cond-mat.other cs.OH</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing capacity of modern computers, driven by Moore's Law, is
accompanied by smaller noise margins and higher error rates. In this paper we
propose a memory device, consisting of a ring of two identical overdamped
bistable forward-coupled oscillators, which may serve as a building block in a
larger scale solution to this problem. We show that such a system is capable of
storing one bit and its performance improves with the addition of noise. The
proposed device can be regarded as asynchronous, in the sense that stored
information can be retrieved at any time and, after a certain synchronization
time, the probability of erroneous retrieval does not depend on the
interrogated oscillator. We characterize memory persistence time and show it to
be maximized for the same noise range that both minimizes the probability of
error and ensures synchronization. We also present experimental results for a
hard-wired version of the proposed memory, consisting of a loop of two Schmitt
triggers. We show that this device is capable of storing one bit and does so
more efficiently in the presence of noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0894</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0894</id><created>2009-11-04</created><authors><author><keyname>Rama</keyname><forenames>N.</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Meenakshi</forenames></author></authors><title>A New Computational Schema for Euphonic Conjunctions in Sanskrit
  Processing</title><categories>cs.CL</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 5,
  pp43-51, October 2009</comments><journal-ref>Rama N. and M. Lakshmanan, &quot;A New Computational Schema for
  Euphonic Conjunctions in Sanskrit Processing&quot;, International Journal of
  Computer Science Issues, IJCSI, Volume 5, pp43-51, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated language processing is central to the drive to enable facilitated
referencing of increasingly available Sanskrit E texts. The first step towards
processing Sanskrit text involves the handling of Sanskrit compound words that
are an integral part of Sanskrit texts. This firstly necessitates the
processing of euphonic conjunctions or sandhis, which are points in words or
between words, at which adjacent letters coalesce and transform. The ancient
Sanskrit grammarian Panini's codification of the Sanskrit grammar is the
accepted authority in the subject. His famed sutras or aphorisms, numbering
approximately four thousand, tersely, precisely and comprehensively codify the
rules of the grammar, including all the rules pertaining to sandhis. This work
presents a fresh new approach to processing sandhis in terms of a computational
schema. This new computational model is based on Panini's complex codification
of the rules of grammar. The model has simple beginnings and is yet powerful,
comprehensive and computationally lean.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0900</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0900</id><created>2009-11-04</created><updated>2009-11-05</updated><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author></authors><title>Construction of a Non-2-colorable k-uniform Hypergraph with Few Edges</title><categories>cs.DM</categories><comments>3 pages</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to construct a non-2-colorable k-uniform hypergraph with (2^(1 +
o(1)))^k edges. By the duality of hypergraphs and monotone k-CNF-formulas this
gives an unsatisfiable monotone k-CNF with (2^(1 + o(1)))^k clauses
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0902</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0902</id><created>2009-11-04</created><authors><author><keyname>Essaouabi</keyname><forenames>A.</forenames></author><author><keyname>Ibnelhaj</keyname><forenames>E.</forenames></author><author><keyname>Fegragui</keyname><forenames>F.</forenames></author></authors><title>Digital Image Watermarking for Arbitrarily Shaped Objects Based On
  SA-DWT</title><categories>cs.GR</categories><comments>International Journal of Computer Science Issues, Volume 5, pp1-8,
  October 2009</comments><journal-ref>A.Essaouabi, E.Ibnelhaj and F.regragui, &quot;Digital Image
  Watermarking for Arbitrarily Shaped Objects Based On SA-DWT&quot;, International
  Journal of Computer Science Issues, Volume 5, pp1-8, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many image watermarking schemes have been proposed in recent years, but they
usually involve embedding a watermark to the entire image without considering
only a particular object in the image, which the image owner may be interested
in. This paper proposes a watermarking scheme that can embed a watermark to an
arbitrarily shaped object in an image. Before embedding, the image owner
specifies an object of arbitrary shape that is of a concern to him. Then the
object is transformed into the wavelet domain using in place lifting shape
adaptive DWT(SADWT) and a watermark is embedded by modifying the wavelet
coefficients. In order to make the watermark robust and transparent, the
watermark is embedded in the average of wavelet blocks using the visual model
based on the human visual system. Wavelet coefficients n least significant bits
(LSBs) are adjusted in concert with the average. Simulation results shows that
the proposed watermarking scheme is perceptually invisible and robust against
many attacks such as lossy compression (e.g.JPEG, JPEG2000), scaling, adding
noise, filtering, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0905</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0905</id><created>2009-11-04</created><authors><author><keyname>Salim</keyname><forenames>Umer</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author></authors><title>Combining Training and Quantized Feedback in Multi-Antenna Reciprocal
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communication between a multiple-antenna transmitter and multiple
receivers (users) with either a single or multiple-antenna each can be
significantly enhanced by providing the channel state information at the
transmitter (CSIT) of the users, as this allows for scheduling, beamforming and
multiuser multiplexing gains. The traditional view on how to enable CSIT has
been as follows so far: In time-division duplexed (TDD) systems, uplink (UL)
and downlink (DL) channel reciprocity allows the use of a training sequence in
the UL direction, which is exploited to obtain an UL channel estimate. This
estimate is in turn recycled in the next downlink slot. In frequency-division
duplexed (FDD) systems, which lack the UL and DL reciprocity, the CSIT is
provided via the use of a dedicated feedback link of limited capacity between
the receivers and the transmitter. In this paper, we focus on TDD systems and
put this classical approach in question. In particular, we show that the
traditional TDD setup above fails to fully exploit the channel reciprocity in
its true sense. In fact, we show that the system can benefit from a combined
CSIT acquisition strategy mixing the use of limited feedback and that of a
training sequence. This combining gives rise to a very interesting joint
estimation and detection problem for which we propose two iterative algorithms.
An outage rate based framework is also developed which gives the optimal
resource split between training and feedback. We demonstrate the potential of
this hybrid combining in terms of the improved CSIT quality under a global
training and feedback resource constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0907</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0907</id><created>2009-11-04</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Kaustubh</forenames></author><author><keyname>Sarma</keyname><forenames>Kandarpa Kumar</forenames></author></authors><title>ANN-based Innovative Segmentation Method for Handwritten text in
  Assamese</title><categories>cs.CL</categories><comments>International Journal of Computer Science Issues, Volume 5, pp9-16,
  October 2009</comments><journal-ref>K. Bhattacharyya and K. K. Sarma, &quot;ANN-based Innovative
  Segmentation Method for Handwritten text in Assamese&quot;, International Journal
  of Computer Science Issues, Volume 5, pp9-16, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Neural Network (ANN) s has widely been used for recognition of
optically scanned character, which partially emulates human thinking in the
domain of the Artificial Intelligence. But prior to recognition, it is
necessary to segment the character from the text to sentences, words etc.
Segmentation of words into individual letters has been one of the major
problems in handwriting recognition. Despite several successful works all over
the work, development of such tools in specific languages is still an ongoing
process especially in the Indian context. This work explores the application of
ANN as an aid to segmentation of handwritten characters in Assamese- an
important language in the North Eastern part of India. The work explores the
performance difference obtained in applying an ANN-based dynamic segmentation
algorithm compared to projection- based static segmentation. The algorithm
involves, first training of an ANN with individual handwritten characters
recorded from different individuals. Handwritten sentences are separated out
from text using a static segmentation method. From the segmented line,
individual characters are separated out by first over segmenting the entire
line. Each of the segments thus obtained, next, is fed to the trained ANN. The
point of segmentation at which the ANN recognizes a segment or a combination of
several segments to be similar to a handwritten character, a segmentation
boundary for the character is assumed to exist and segmentation performed. The
segmented character is next compared to the best available match and the
segmentation boundary confirmed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0909</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0909</id><created>2009-11-04</created><authors><author><keyname>Ponce-Medellin</keyname><forenames>Rafael</forenames></author><author><keyname>Gonzalez-Serna</keyname><forenames>Gabriel</forenames></author><author><keyname>Vargas</keyname><forenames>Rocio</forenames></author><author><keyname>Ruiz</keyname><forenames>Lirio</forenames></author></authors><title>Technology Integration around the Geographic Information: A State of the
  Art</title><categories>cs.CY</categories><comments>International Journal of Computer Science Issues, Volume 5, pp17-26,
  October 2009</comments><journal-ref>R. Ponce-Medellin, G. Gonzalez-Serna, R. Vargas and L. Ruiz,
  &quot;Technology Integration around the Geographic Information: A State of the
  Art&quot;, IJCSI, Volume 5, pp17-26, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the elements that have popularized and facilitated the use of
geographical information on a variety of computational applications has been
the use of Web maps; this has opened new research challenges on different
subjects, from locating places and people, the study of social behavior or the
analyzing of the hidden structures of the terms used in a natural language
query used for locating a place. However, the use of geographic information
under technological features is not new, instead it has been part of a
development and technological integration process. This paper presents a state
of the art review about the application of geographic information under
different approaches: its use on location based services, the collaborative
user participation on it, its contextual-awareness, its use in the Semantic Web
and the challenges of its use in natural languge queries. Finally, a prototype
that integrates most of these areas is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0910</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0910</id><created>2009-11-04</created><authors><author><keyname>Raju</keyname><forenames>Mandhapati P.</forenames></author><author><keyname>Khaitan</keyname><forenames>Siddhartha</forenames></author></authors><title>Domain Decomposition Based High Performance Parallel Computing</title><categories>cs.DC</categories><comments>International Journal of Computer Science Issues, IJCSI, Volume 5,
  pp27-32, October 2009</comments><journal-ref>M. P. Raju and S. Khaitan, &quot;Domain Decomposition Based High
  Performance Parallel Computing&quot;, International Journal of Computer Science
  Issues,IJCSI, Volume 5, pp27-32, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study deals with the parallelization of finite element based
Navier-Stokes codes using domain decomposition and state-ofart sparse direct
solvers. There has been significant improvement in the performance of sparse
direct solvers. Parallel sparse direct solvers are not found to exhibit good
scalability. Hence, the parallelization of sparse direct solvers is done using
domain decomposition techniques. A highly efficient sparse direct solver
PARDISO is used in this study. The scalability of both Newton and modified
Newton algorithms are tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0912</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0912</id><created>2009-11-04</created><authors><author><keyname>Sindhu</keyname><forenames>Ritu</forenames></author><author><keyname>Wahid</keyname><forenames>Abdul</forenames></author><author><keyname>Purohit</keyname><forenames>G. N.</forenames></author></authors><title>Multi-Agent System Interaction in Integrated SCM</title><categories>cs.MA</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 5,
  pp33-37, October 2009</comments><journal-ref>R. Sindhu, A. W. and G.N.Purohit, &quot;Multi-Agent System Interaction
  in Integrated SCM&quot;, International Journal of Computer Science Issues, IJCSI,
  Volume 5, pp33-37, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordination between organizations on strategic, tactical and operation
levels leads to more effective and efficient supply chains. Supply chain
management is increasing day by day in modern enterprises. The environment is
becoming competitive and many enterprises will find it difficult to survive if
they do not make their sourcing, production and distribution more efficient.
Multi-agent supply chain management has recognized as an effective methodology
for supply chain management. Multi-agent systems (MAS) offer new methods
compared to conventional, centrally organized architectures in the scope of
supply chain management (SCM). Since necessary data are not available within
the whole supply chain, an integrated approach for production planning and
control taking into account all the partners involved is not feasible. In this
study we show how MAS architecture interacts in the integrated SCM architecture
with the help of various intelligent agents to highlight the above problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0914</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0914</id><created>2009-11-04</created><updated>2009-11-17</updated><authors><author><keyname>Ramachandran</keyname><forenames>Sumalatha</forenames></author><author><keyname>Paulraj</keyname><forenames>Sujaya</forenames></author><author><keyname>Joseph</keyname><forenames>Sharon</forenames></author><author><keyname>Ramaraj</keyname><forenames>Vetriselvi</forenames></author></authors><title>Enhanced Trustworthy and High-Quality Information Retrieval System for
  Web Search Engines</title><categories>cs.IR</categories><comments>International Journal of Computer Science Issues, IJCSI Volume 5,
  pp38-42, October 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The WWW is the most important source of information. But, there is no
guarantee for information correctness and lots of conflicting information is
retrieved by the search engines and the quality of provided information also
varies from low quality to high quality. We provide enhanced trustworthiness in
both specific (entity) and broad (content) queries in web searching. The
filtering of trustworthiness is based on 5 factors: Provenance, Authority, Age,
Popularity, and Related Links. The trustworthiness is calculated based on these
5 factors and it is stored thereby increasing the performance in retrieving
trustworthy websites. The calculated trustworthiness is stored only for static
websites. Quality is provided based on policies selected by the user. Quality
based ranking of retrieved trusted information is provided using WIQA (Web
Information Quality Assessment) Framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0916</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0916</id><created>2009-11-04</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>Toward a Gigabit Wireless Communications System</title><categories>cs.NI</categories><proxy>ccsd hal-00429807</proxy><journal-ref>International Journal of Communication Networks and Information
  Security (IJCNIS) Vol. 1,, No. 2, (2009) 7 pages</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and the realization of a hybrid wireless
Gigabit Ethernet indoor communications system operating at 60 GHz. As the 60
GHz radio link operates only in a single-room configuration, an additional
Radio over Fiber (RoF) link is used to ensure the communications within all the
rooms of a residential environment. The system uses low complexity baseband
processing modules. A byte synchronization technique is designed to provide a
high value of the preamble detection probability and a very small value of the
false detection probability. Conventional RS (255, 239) encoder and decoder are
used for channel forward error correction (FEC). The FEC parameters are
determined by the tradeoff between higher coding gain and hardware complexity.
The results of bit error rate measurements at 875 Mbps are presented for
various antennas configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0971</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0971</id><created>2009-11-05</created><updated>2009-11-06</updated><authors><author><keyname>Bang</keyname><forenames>H. J.</forenames></author><author><keyname>Gesbert</keyname><forenames>D.</forenames></author></authors><title>Multicell Zero-Forcing and User Scheduling on the Downlink of a Linear
  Cell Array</title><categories>cs.IT math.IT</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordinated base station (BS) transmission has attracted much interest for
its potential to increase the capacity of wireless networks. Yet at the same
time, the achievable sum-rate with single-cell processing (SCP) scales
optimally with the number of users under Rayleigh fading conditions. One may
therefore ask if the value of BS coordination is limited in the many-user
regime from a sum-rate perspective. With this in mind we consider multicell
zero-forcing beamforming (ZFBF) on the downlink of a linear cell-array. We
first identify the beamforming weights and the optimal scheduling policy under
a per-base power constraint. We then compare the number of users m and n
required per-cell to achieve the same mean SINR, after optimal scheduling, with
SCP and ZFBF respectively. Specifically, we show that the ratio m/n grows
logarithmically with n. Finally, we demonstrate that the gain in sum-rate
between ZFBF and SCP is significant for all practical values of number of
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0978</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0978</id><created>2009-11-05</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author><author><keyname>Tnaguy</keyname><forenames>Eric</forenames><affiliation>IREENA</affiliation></author><author><keyname>Hongwu</keyname><forenames>Li</forenames><affiliation>IREENA</affiliation></author><author><keyname>Charbonier</keyname><forenames>Benoit</forenames></author></authors><title>Hybrid, Optical and Wireless Near-Gigabit Communications System</title><categories>cs.NI</categories><proxy>ccsd hal-00429844</proxy><journal-ref>The Sixth International Symposium on Wireless Communication
  Systems 2009 (ISWCS'09), Italy Sienna : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the study and the realization of a hybrid 60 GHz wireless
communications system. As the 60 GHz radio link operates only in a single-room
configuration, an additional Radio over Fibre (RoF) link is used to ensure the
communications in all the rooms of a residential environment. A single carrier
architecture is adopted. The system uses low complexity baseband processing
modules. A byte/frame synchronization technique is designed to provide a high
value of the preamble detection probability and a very small value of the false
alarm probability. Conventional RS (255, 239) encoder and decoder are used to
correct errors in the transmission channel. Results of Bit Error Rate (BER)
measurements are presented for various antennas configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.0996</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.0996</id><created>2009-11-05</created><updated>2014-02-06</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author></authors><title>The Need for Structure in Quantum Speedups</title><categories>quant-ph cs.CC</categories><comments>31 pages; journal version; fixed several significant errors (which
  were indeed fixable); improved main result from a 9th-power to a 7th-power
  relation. Conference version in Proceedings of ICS (Innovations in Computer
  Science) 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is there a general theorem that tells us when we can hope for exponential
speedups from quantum algorithms, and when we cannot? In this paper, we make
two advances toward such a theorem, in the black-box model where most quantum
algorithms operate.
  First, we show that for any problem that is invariant under permuting inputs
and outputs (like the collision or the element distinctness problems), the
quantum query complexity is at least the 7th root of the classical randomized
query complexity. (An earlier version of this paper gave the 9th root.) This
resolves a conjecture of Watrous from 2002.
  Second, inspired by recent work of O'Donnell et al. (2005) and Dinur et al.
(2006), we conjecture that every bounded low-degree polynomial has a &quot;highly
influential&quot; variable. Assuming this conjecture, we show that every T-query
quantum algorithm can be simulated on most inputs by a poly(T)-query classical
algorithm, and that one essentially cannot hope to prove P!=BQP relative to a
random oracle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1004</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1004</id><created>2009-11-05</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author><author><keyname>Klop</keyname><forenames>Jan Willem</forenames></author></authors><title>Let's Make a Difference!</title><categories>cs.DM cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the behaviour of iterations of the difference operator delta on
streams over {0,1}. In particular, we show that a stream sigma is eventually
periodic if and only if the sequence of differences sigma, delta(sigma),
delta(delta(sigma)), ..., the `delta-orbit' of sigma as we call it, is
eventually periodic. Moreover, we generalise this result to operations delta_d
that sum modulo 2 the elements of each consecutive block of length d+1 in a
given 01-stream. Some experimentation with delta-orbits of well-known streams
reveals a surprising connexion between the Sierpinski stream and the Mephisto
Waltz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1009</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1009</id><created>2009-11-05</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Grabmayer</keyname><forenames>Clemens</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author><author><keyname>Klop</keyname><forenames>Jan Willem</forenames></author></authors><title>Unique Normal Forms in Infinitary Weakly Orthogonal Term Rewriting</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of finite and infinitary term rewriting is extensively developed
for orthogonal rewrite systems, but to a lesser degree for weakly orthogonal
rewrite systems. In this note we present some contributions to the latter case
of weak orthogonality, where critial pairs are admitted provided they are
trivial.
  We start with a refinement of the by now classical Compression Lemma, as a
tool for establishing infinitary confluence, and hence the property of unique
infinitary normal forms, for the case of weakly orthogonal TRSs that do not
contain collapsing rewrite rules.
  That this restriction of collapse-freeness is crucial, is shown in a
elaboration of a simple TRS which is weakly orthogonal, but has two collapsing
rules. It turns out that all the usual theory breaks down dramatically.
  We conclude with establishing a positive fact: the diamond property for
infinitary developments for weakly orthogonal TRSs, by means of a detailed
analysis initiated by van Oostrom for the finite case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1021</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1021</id><created>2009-11-05</created><authors><author><keyname>Kalles</keyname><forenames>Dimitris</forenames></author><author><keyname>Fykouras</keyname><forenames>Ilias</forenames></author></authors><title>Examples as Interaction: On Humans Teaching a Computer to Play a Game</title><categories>cs.AI cs.GT</categories><comments>15 pages, 1 figure, 13 tables, submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews an experiment in human-computer interaction, where
interaction takes place when humans attempt to teach a computer to play a
strategy board game. We show that while individually learned models can be
shown to improve the playing performance of the computer, their straightforward
composition results in diluting what was earlier learned. This observation
suggests that interaction cannot be easily distributed when one hopes to
harness multiple human experts to develop a quality computer player. This is
related to similar approaches in robot task learning and to classic approaches
to human learning and reinforces the need to develop tools that facilitate the
mix of human-based tuition and computer self-learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1036</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1036</id><created>2009-11-05</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>Syst\`eme de Communications Sans Fil Tr\`es Haut D\'ebit \`a 60 GHz</title><categories>cs.NI</categories><proxy>ccsd hal-00429852</proxy><journal-ref>XXIIe Colloque Traitement du Signal et des Images (GRETSI '09),
  Dijon : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the study and the realization at IETR of a high data rate
60 GHz wireless communications system. The system uses a simple single carrier
architecture. The receiver architecture is based on a differential demodulation
which minimizes the intersymbol interference (ISI) effect and a signal
processing unit composed of a joint frame and byte synchronization block and a
conventional RS (255, 239) decoder. The byte synchronization technique provides
a high preamble detection probability and a very small value of the false
detection probability. First measurement results show a good communication link
quality in line of sight environments with directional antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1054</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1054</id><created>2009-11-05</created><authors><author><keyname>Razi</keyname><forenames>Adeel</forenames></author><author><keyname>Ryan</keyname><forenames>Daniel J.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Sum Rates, Rate Allocation, and User Scheduling for Multi-User MIMO
  Vector Perturbation Precoding</title><categories>cs.IT math.IT</categories><comments>27 pages with 6 figures and 2 tables. Accepted for publication in
  IEEE Trans. Wireless Commu</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the multiuser multiple-input multiple-output (MIMO)
broadcast channel. We consider the case where the multiple transmit antennas
are used to deliver independent data streams to multiple users via vector
perturbation. We derive expressions for the sum rate in terms of the average
energy of the precoded vector, and use this to derive a high signal-to-noise
ratio (SNR) closed-form upper bound, which we show to be tight via simulation.
We also propose a modification to vector perturbation where different rates can
be allocated to different users. We conclude that for vector perturbation
precoding most of the sum rate gains can be achieved by reducing the rate
allocation problem to the user selection problem. We then propose a
low-complexity user selection algorithm that attempts to maximize the high-SNR
sum rate upper bound. Simulations show that the algorithm outperforms other
user selection algorithms of similar complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1072</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1072</id><created>2009-11-05</created><authors><author><keyname>Bitouze</keyname><forenames>Nicolas</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author></authors><title>Error Correcting Coding for a Non-symmetric Ternary Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. Part of this
  work was presented at the Information Theory and Applications Workshop 2009</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 56, no. 11, pp. 5715-5729, Nov. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ternary channels can be used to model the behavior of some memory devices,
where information is stored in three different levels. In this paper, error
correcting coding for a ternary channel where some of the error transitions are
not allowed, is considered. The resulting channel is non-symmetric, therefore
classical linear codes are not optimal for this channel. We define the
maximum-likelihood (ML) decoding rule for ternary codes over this channel and
show that it is complex to compute, since it depends on the channel error
probability. A simpler alternative decoding rule which depends only on code
properties, called $\da$-decoding, is then proposed. It is shown that
$\da$-decoding and ML decoding are equivalent, i.e., $\da$-decoding is optimal,
under certain conditions. Assuming $\da$-decoding, we characterize the error
correcting capabilities of ternary codes over the non-symmetric ternary
channel. We also derive an upper bound and a constructive lower bound on the
size of codes, given the code length and the minimum distance. The results
arising from the constructive lower bound are then compared, for short sizes,
to optimal codes (in terms of code size) found by a clique-based search. It is
shown that the proposed construction method gives good codes, and that in some
cases the codes are optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1082</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1082</id><created>2009-11-05</created><authors><author><keyname>Zhu</keyname><forenames>Yan</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Ergodic Fading One-sided Interference Channels without State Information
  at Transmitters</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the capacity region of a two-user ergodic interference
channel with fading, where only one of the users is subject to interference
from the other user, and the channel state information (CSI) is only available
at the receivers. A layered erasure model with one-sided interference and with
arbitrary fading statistics is studied first, whose capacity region is
completely determined as a polygon. Each dominant rate pair can be regarded as
the outcome of a trade-off between the rate gain of the interference-free user
and the rate loss of the other user due to interference. Using insights from
the layered erasure model, inner and outer bounds of the capacity region are
provided for the one-sided fading Gaussian interference channels. In
particular, the inner bound is achieved by artificially creating layers in the
signaling of the interference-free user. The outer bound is developed by
characterizing a similar trade-off as in the erasure model by taking a
&quot;layered&quot; view using the incremental channel approach. Furthermore, the gap
between the inner and outer bounds is no more than 12.772 bits per channel use
per user, regardless of the signal-to-noise ratios and fading statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1090</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1090</id><created>2009-11-05</created><updated>2009-11-20</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Junior</keyname><forenames>Valdemar Cardoso da Rocha</forenames></author><author><keyname>Pimentel</keyname><forenames>Cecilio</forenames></author></authors><title>On the Capacity of Constrained Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, to be presented at SCC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first chapter of Shannon's &quot;A Mathematical Theory of Communication,&quot;
it is shown that the maximum entropy rate of an input process of a constrained
system is limited by the combinatorial capacity of the system. Shannon
considers systems where the constraints define regular languages and uses
results from matrix theory in his derivations. In this work, the regularity
constraint is dropped. Using generating functions, it is shown that the maximum
entropy rate of an input process is upper-bounded by the combinatorial capacity
in general. The presented results also allow for a new approach to systems with
regular constraints. As an example, the results are applied to binary sequences
that fulfill the (j,k) run-length constraint and by using the proposed
framework, a simple formula for the combinatorial capacity is given and a
maxentropic input process is defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1112</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1112</id><created>2009-11-05</created><updated>2009-11-06</updated><authors><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Balakireva</keyname><forenames>Lyudmila L.</forenames></author><author><keyname>Ainsworth</keyname><forenames>Scott</forenames></author><author><keyname>Shankar</keyname><forenames>Harihar</forenames></author></authors><title>Memento: Time Travel for the Web</title><categories>cs.IR cs.DL</categories><comments>14 pages, 5 figures</comments><acm-class>H.3.5; H.3.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Web is ephemeral. Many resources have representations that change over
time, and many of those representations are lost forever. A lucky few manage to
reappear as archived resources that carry their own URIs. For example, some
content management systems maintain version pages that reflect a frozen prior
state of their changing resources. Archives recurrently crawl the web to obtain
the actual representation of resources, and subsequently make those available
via special-purpose archived resources. In both cases, the archival copies have
URIs that are protocol-wise disconnected from the URI of the resource of which
they represent a prior state. Indeed, the lack of temporal capabilities in the
most common Web protocol, HTTP, prevents getting to an archived resource on the
basis of the URI of its original. This turns accessing archived resources into
a significant discovery challenge for both human and software agents, which
typically involves following a multitude of links from the original to the
archival resource, or of searching archives for the original URI. This paper
proposes the protocol-based Memento solution to address this problem, and
describes a proof-of-concept experiment that includes major servers of archival
content, including Wikipedia and the Internet Archive. The Memento solution is
based on existing HTTP capabilities applied in a novel way to add the temporal
dimension. The result is a framework in which archived resources can seamlessly
be reached via the URI of their original: protocol-based time travel for the
Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1166</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1166</id><created>2009-11-05</created><updated>2010-09-07</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Waveform Transmission Method, a New Waveform-relaxation Based Algorithm
  to Solve Ordinary Differential Equations in Parallel</title><categories>math.NA cs.DC math.CA</categories><comments>More info, see my web page http://weifei00.googlepages.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Waveform Relaxation method (WR) is a beautiful algorithm to solve Ordinary
Differential Equations (ODEs). However, because of its poor convergence
capability, it was rarely used. In this paper, we propose a new distributed
algorithm, named Waveform Transmission Method (WTM), by virtually inserting
waveform transmission lines into the dynamical system to achieve distributed
computing of extremely large ODEs. WTM has better convergence capability than
the traditional WR algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1174</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1174</id><created>2009-11-05</created><authors><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Sharp Dichotomies for Regret Minimization in Metric Spaces</title><categories>cs.DS cs.LG</categories><comments>Full version of a paper in ACM-SIAM SODA 2010</comments><acm-class>F.2.2; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lipschitz multi-armed bandit (MAB) problem generalizes the classical
multi-armed bandit problem by assuming one is given side information consisting
of a priori upper bounds on the difference in expected payoff between certain
pairs of strategies. Classical results of (Lai and Robbins 1985) and (Auer et
al. 2002) imply a logarithmic regret bound for the Lipschitz MAB problem on
finite metric spaces. Recent results on continuum-armed bandit problems and
their generalizations imply lower bounds of $\sqrt{t}$, or stronger, for many
infinite metric spaces such as the unit interval. Is this dichotomy universal?
We prove that the answer is yes: for every metric space, the optimal regret of
a Lipschitz MAB algorithm is either bounded above by any $f\in \omega(\log t)$,
or bounded below by any $g\in o(\sqrt{t})$. Perhaps surprisingly, this
dichotomy does not coincide with the distinction between finite and infinite
metric spaces; instead it depends on whether the completion of the metric space
is compact and countable. Our proof connects upper and lower bound techniques
in online learning with classical topological notions such as perfect sets and
the Cantor-Bendixson theorem. Among many other results, we show a similar
dichotomy for the &quot;full-feedback&quot; (a.k.a., &quot;best-expert&quot;) version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1226</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1226</id><created>2009-11-06</created><updated>2011-11-09</updated><authors><author><keyname>Liu</keyname><forenames>Yaning</forenames></author><author><keyname>Simon</keyname><forenames>Gwendal</forenames></author></authors><title>Large-Scale Time-Shifted Streaming Delivery</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An attractive new feature of connected TV systems consists in allowing users
to access past portions of the TV channel. This feature, called time-shifted
streaming, is now used by millions of TV viewers. We address in this paper the
design of a large-scale delivery system for time-shifted streaming. We
highlight the characteristics of time-shifted streaming that prevent known
video delivery systems to be used. Then, we present two proposals that meet the
demand for two radically different types of TV operator. First, the
Peer-Assisted Catch-Up Streaming system, namely PACUS, aims at reducing the
load on the server of a large TV broadcasters without losing the control of the
TV delivery. Second, the turntable structure, is an overlay of nodes that allow
an independent content delivery network or a small independent TV broadcaster
to ensure that all past TV programs are stored and as available as possible. We
show through extensive simulations that our objectives are reached, with a
reduction of up to three quarters of the traffic for PACUS and a 100\%
guaranteed availability for the turntable structure. We also compare our
proposals to the main previous works in the area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1240</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1240</id><created>2009-11-06</created><authors><author><keyname>Wool</keyname><forenames>Avishai</forenames></author></authors><title>Firewall Configuration Errors Revisited</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first quantitative evaluation of the quality of corporate firewall
configurations appeared in 2004, based on Check Point FireWall-1 rule-sets. In
general that survey indicated that corporate firewalls were often enforcing
poorly written rule-sets, containing many mistakes.
  The goal of this work is to revisit the first survey. The current study is
much larger. Moreover, for the first time, the study includes configurations
from two major vendors. The study also introduce a novel &quot;Firewall Complexity&quot;
(FC) measure, that applies to both types of firewalls.
  The findings of the current study indeed validate the 2004 study's main
observations: firewalls are (still) poorly configured, and a rule-set's
complexity is (still) positively correlated with the number of detected risk
items. Thus we can conclude that, for well-configured firewalls, ``small is
(still) beautiful''. However, unlike the 2004 study, we see no significant
indication that later software versions have fewer errors (for both vendors).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1275</identifier>
 <datestamp>2013-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1275</id><created>2009-11-06</created><updated>2013-04-02</updated><authors><author><keyname>Kelbert</keyname><forenames>Mark</forenames></author><author><keyname>Suhov</keyname><forenames>Yuri</forenames></author></authors><title>Continuity of mutual entropy in the large signal-to-noise ratio limit</title><categories>cs.IT cs.IR math.IT math.PR</categories><comments>This paper has been withdrawn since it has been already published,
  in: {\it Stochastic Analysis 2010.} Springer-Verlag: Berlin, 2010, pp.
  281--299; arXiv:0911</comments><msc-class>60H30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article addresses the issue of the proof of the entropy power inequality
(EPI), an important tool in the analysis of Gaussian channels of information
transmission, proposed by Shannon.
  We analyse continuity properties of the mutual entropy of the input and
output signals in an additive memoryless channel and discuss assumptions under
which the entropy-power inequality holds true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1288</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1288</id><created>2009-11-06</created><authors><author><keyname>Cance</keyname><forenames>Caroline</forenames></author><author><keyname>Genevois</keyname><forenames>Hugues</forenames></author><author><keyname>Dubois</keyname><forenames>Dani&#xe8;le</forenames></author></authors><title>What is instrumentality in new digital msuical devices ? A contribution
  from cognitive linguistics and psychology</title><categories>cs.HC</categories><comments>11 pages</comments><proxy>ccsd hal-00430397</proxy><journal-ref>What is instrumentality in new digital musical devices ? A
  contribution from cognitive linguistics and psychology, Paris : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As far as music is concerned, instruments have always been part of a cultural
?landscape? (on technical, expressive and symbolic levels). The present
contribution explores the changes brought about by the shift that occurred
during the 20th century, from mechanical to digital instruments (also named
?virtual instruments?). First and foremost, a short recall of some historical
steps of the technological developments that have renewed our relationship to
sound, music, and instruments will be presented. Second, an analysis of
different discourses and terminologies presently used in the domains of
musicology and computer music will account for the evolution of the notion of
instrumentality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1298</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1298</id><created>2009-11-06</created><updated>2010-06-11</updated><authors><author><keyname>Beelen</keyname><forenames>Peter</forenames></author><author><keyname>Ghorpade</keyname><forenames>Sudhir R.</forenames></author><author><keyname>Hoeholdt</keyname><forenames>Tom</forenames></author></authors><title>Affine Grassmann Codes</title><categories>cs.IT math.AG math.IT</categories><comments>Slightly Revised Version; 18 pages</comments><msc-class>94B05, 94B27, 14M15, 15A24</msc-class><journal-ref>IEEE Trans. Inform. Theory 56 (2010), no. 7, 3166-3176</journal-ref><doi>10.1109/TIT.2010.2048470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a new class of linear codes, called affine Grassmann codes. These
can be viewed as a variant of generalized Reed-Muller codes and are closely
related to Grassmann codes. We determine the length, dimension, and the minimum
distance of any affine Grassmann code. Moreover, we show that affine Grassmann
codes have a large automorphism group and determine the number of minimum
weight codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1305</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1305</id><created>2009-11-06</created><authors><author><keyname>Arencibia-Jorge</keyname><forenames>Ricardo</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Chinchilla-Rodriguez</keyname><forenames>Zaida</forenames></author><author><keyname>Rousseau</keyname><forenames>Ronald</forenames></author><author><keyname>Paris</keyname><forenames>Soren W.</forenames></author></authors><title>Retrieval of very large numbers of items in the Web of Science: an
  exercise to develop accurate search strategies</title><categories>cs.DL cs.IR physics.soc-ph</categories><journal-ref>El Profesional de la Informacion 18(5) (2009) 555-559</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current communication presents a simple exercise with the aim of solving
a singular problem: the retrieval of extremely large amounts of items in the
Web of Science interface. As it is known, Web of Science interface allows a
user to obtain at most 100,000 items from a single query. But what about
queries that achieve a result of more than 100,000 items? The exercise
developed one possible way to achieve this objective. The case study is the
retrieval of the entire scientific production from the United States in a
specific year. Different sections of items were retrieved using the field
Source of the database. Then, a simple Boolean statement was created with the
aim of eliminating overlapping and to improve the accuracy of the search
strategy. The importance of team work in the development of advanced search
strategies was noted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1308</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1308</id><created>2009-11-06</created><authors><author><keyname>Lucio-Arias</keyname><forenames>Diana</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Dynamics of Exchanges and References among Scientific Texts, and the
  Autopoiesis of Discursive Knowledge</title><categories>cs.CY cs.DL physics.soc-ph</categories><journal-ref>Journal of Informetrics 3(3) (2009) 261-271</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discursive knowledge emerges as codification in flows of communication. The
flows of communication are constrained and enabled by networks of
communications as their historical manifestations at each moment of time. New
publications modify the existing networks by changing the distributions of
attributes and relations in document sets, while the networks are
self-referentially updated along trajectories. Codification operates
reflexively: the network structures are reconstructed from the perspective of
hindsight. Codification along different axes differentiates discursive
knowledge into specialties. These intellectual control structures are
constructed bottom-up, but feed top-down back upon the production of new
knowledge. However, the forward dynamics of diffusion in the development of the
communication networks along trajectories differs from the feedback mechanisms
of control. Analysis of the development of scientific communication in terms of
evolving scientific literatures provides us with a model which makes these
evolutionary processes amenable to measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1318</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1318</id><created>2009-11-06</created><authors><author><keyname>Egghe</keyname><forenames>Leo</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The relation between Pearson's correlation coefficient r and Salton's
  cosine measure</title><categories>cs.IR stat.ME</categories><journal-ref>Journal of the American Society for Information Science and
  Technology 60(5) (2009) 1027-1036</journal-ref><doi>10.1016/j.eswa.2012.07.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relation between Pearson's correlation coefficient and Salton's cosine
measure is revealed based on the different possible values of the division of
the L1-norm and the L2-norm of a vector. These different values yield a sheaf
of increasingly straight lines which form together a cloud of points, being the
investigated relation. The theoretical results are tested against the author
co-citation relations among 24 informetricians for whom two matrices can be
constructed, based on co-citations: the asymmetric occurrence matrix and the
symmetric co-citation matrix. Both examples completely confirm the theoretical
results. The results enable us to specify an algorithm which provides a
threshold value for the cosine above which none of the corresponding Pearson
correlations would be negative. Using this threshold value can be expected to
optimize the visualization of the vector space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1320</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1320</id><created>2009-11-06</created><authors><author><keyname>Park</keyname><forenames>Han</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Knowledge linkage structures in communication studies using citation
  analysis among communication journals</title><categories>cs.DL cs.IR physics.soc-ph</categories><journal-ref>Scientometrics 81(1) (2009) 157-175</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research analyzes a &quot;who cites whom&quot; matrix in terms of aggregated,
journal-journal citations to determine the location of communication studies on
the academic spectrum. Using the Journal of Communication as the seed journal,
the 2006 data in the Journal Citation Reports are used to map communication
studies. The results show that social and experimental psychology journals are
the most frequently used sources of information in this field. In addition,
several journals devoted to the use and effects of media and advertising are
weakly integrated into the larger communication research community, whereas
communication studies are dominated by American journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1340</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1340</id><created>2009-11-06</created><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Francoise</forenames></author></authors><title>Bounding the radii of balls meeting every connected component of
  semi-algebraic sets</title><categories>cs.SC cs.CG</categories><comments>11 pages</comments><journal-ref>J. Symbolic Comput. 45 (12):1270-1279, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove explicit bounds on the radius of a ball centered at the origin which
is guaranteed to contain all bounded connected components of a semi-algebraic
set $S \subset \mathbbm{R}^k$ defined by a quantifier-free formula involving
$s$ polynomials in $\mathbbm{Z}[X_1, ..., X_k]$ having degrees at most $d$, and
whose coefficients have bitsizes at most $\tau$. Our bound is an explicit
function of $s, d, k$ and $\tau$, and does not contain any undetermined
constants. We also prove a similar bound on the radius of a ball guaranteed to
intersect every connected component of $S$ (including the unbounded
components). While asymptotic bounds of the form $2^{\tau d^{O (k)}}$ on these
quantities were known before, some applications require bounds which are
explicit and which hold for all values of $s, d, k$ and $\tau$. The bounds
proved in this paper are of this nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1346</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1346</id><created>2009-11-06</created><authors><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Tripathi</keyname><forenames>Pushkar</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Optimal Approximation Algorithms for Multi-agent Combinatorial Problems
  with Discounted Price Functions</title><categories>cs.MA cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submodular functions are an important class of functions in combinatorial
optimization which satisfy the natural properties of decreasing marginal costs.
The study of these functions has led to strong structural properties with
applications in many areas. Recently, there has been significant interest in
extending the theory of algorithms for optimizing combinatorial problems (such
as network design problem of spanning tree) over submodular functions.
Unfortunately, the lower bounds under the general class of submodular functions
are known to be very high for many of the classical problems.
  In this paper, we introduce and study an important subclass of submodular
functions, which we call discounted price functions. These functions are
succinctly representable and generalize linear cost functions. In this paper we
study the following fundamental combinatorial optimization problems: Edge
Cover, Spanning Tree, Perfect Matching and Shortest Path, and obtain tight
upper and lower bounds for these problems.
  The main technical contribution of this paper is designing novel adaptive
greedy algorithms for the above problems. These algorithms greedily build the
solution whist rectifying mistakes made in the previous steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1368</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1368</id><created>2009-11-06</created><updated>2009-11-25</updated><authors><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author><author><keyname>Willett</keyname><forenames>Rebecca</forenames></author><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Performance Bounds for Expander-based Compressed Sensing in the presence
  of Poisson Noise</title><categories>cs.IT math.IT</categories><comments>Received the best student paper award in Asilomar 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides performance bounds for compressed sensing in the presence
of Poisson noise using expander graphs. The Poisson noise model is appropriate
for a variety of applications, including low-light imaging and digital
streaming, where the signal-independent and/or bounded noise models used in the
compressed sensing literature are no longer applicable. In this paper, we
develop a novel sensing paradigm based on expander graphs and propose a MAP
algorithm for recovering sparse or compressible signals from Poisson
observations. The geometry of the expander graphs and the positivity of the
corresponding sensing matrices play a crucial role in establishing the bounds
on the signal reconstruction error of the proposed algorithm. The geometry of
the expander graphs makes them provably superior to random dense sensing
matrices, such as Gaussian or partial Fourier ensembles, for the Poisson noise
model. We support our results with experimental demonstrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1370</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1370</id><created>2009-11-06</created><authors><author><keyname>Kubica</keyname><forenames>Marcin</forenames></author><author><keyname>Radoszewski</keyname><forenames>Jakub</forenames></author><author><keyname>Rytter</keyname><forenames>Wojciech</forenames></author><author><keyname>Walen</keyname><forenames>Tomasz</forenames></author></authors><title>On the maximal number of cubic subwords in a string</title><categories>cs.FL cs.DM</categories><comments>14 pages</comments><doi>10.1007/978-3-642-10217-2_34</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of the maximum number of cubic subwords (of the
form $www$) in a given word. We also consider square subwords (of the form
$ww$). The problem of the maximum number of squares in a word is not well
understood. Several new results related to this problem are produced in the
paper. We consider two simple problems related to the maximum number of
subwords which are squares or which are highly repetitive; then we provide a
nontrivial estimation for the number of cubes. We show that the maximum number
of squares $xx$ such that $x$ is not a primitive word (nonprimitive squares) in
a word of length $n$ is exactly $\lfloor \frac{n}{2}\rfloor - 1$, and the
maximum number of subwords of the form $x^k$, for $k\ge 3$, is exactly $n-2$.
In particular, the maximum number of cubes in a word is not greater than $n-2$
either. Using very technical properties of occurrences of cubes, we improve
this bound significantly. We show that the maximum number of cubes in a word of
length $n$ is between $(1/2)n$ and $(4/5)n$. (In particular, we improve the
lower bound from the conference version of the paper.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1379</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1379</id><created>2009-11-06</created><updated>2010-03-24</updated><authors><author><keyname>Chu</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Sethu</keyname><forenames>Harish</forenames></author></authors><title>On Improving the Representation of a Region Achieved by a Sensor Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report considers the class of applications of sensor networks in which
each sensor node makes measurements, such as temperature or humidity, at the
precise location of the node. Such spot-sensing applications approximate the
physical condition of the entire region of interest by the measurements made at
only the points where the sensor nodes are located. Given a certain density of
nodes in a region, a more spatially uniform distribution of the nodes leads to
a better approximation of the physical condition of the region. This report
considers the error in this approximation and seeks to improve the quality of
representation of the physical condition of the points in the region in the
data collected by the sensor network. We develop two essential metrics which
together allow a rigorous quantitative assessment of the quality of
representation achieved: the average representation error and the unevenness of
representation error, the latter based on a well-accepted measure of inequality
used in economics. We present the rationale behind the use of these metrics and
derive relevant theoretical bounds on them in the common scenario of a planar
region of arbitrary shape covered by a sensor network deployment. A simple new
heuristic algorithm is presented for each node to determine if and when it
should sense or sleep to conserve energy while also preserving the quality of
representation. Simulation results show that it achieves a significant
improvement in the quality of representation compared to other related
distributed algorithms. Interestingly, our results also show that improved
spatial uniformity has the welcome side-effect of a significant increase in the
network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1383</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1383</id><created>2009-11-09</created><authors><author><keyname>Harper</keyname><forenames>Marc</forenames></author></authors><title>Information Geometry and Evolutionary Game Theory</title><categories>cs.IT cs.GT math.DS math.IT nlin.AO</categories><comments>Added references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shahshahani geometry of evolutionary game theory is realized as the
information geometry of the simplex, deriving from the Fisher information
metric of the manifold of categorical probability distributions. Some essential
concepts in evolutionary game theory are realized information-theoretically.
Results are extended to the Lotka-Volterra equation and to multiple population
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1386</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1386</id><created>2009-11-06</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Machine Learning: When and Where the Horses Went Astray?</title><categories>cs.AI cs.LG</categories><comments>The paper is accepted to be published in the Machine Learning serie
  of the InTech</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Learning is usually defined as a subfield of AI, which is busy with
information extraction from raw data sets. Despite of its common acceptance and
widespread recognition, this definition is wrong and groundless. Meaningful
information does not belong to the data that bear it. It belongs to the
observers of the data and it is a shared agreement and a convention among them.
Therefore, this private information cannot be extracted from the data by any
means. Therefore, all further attempts of Machine Learning apologists to
justify their funny business are inappropriate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1388</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1388</id><created>2009-11-06</created><updated>2011-07-31</updated><authors><author><keyname>Coppersmith</keyname><forenames>Don</forenames></author><author><keyname>Miller</keyname><forenames>Victor S.</forenames></author></authors><title>Binary Non-tiles</title><categories>cs.DM cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset V of GF(2)^n is a tile if GF(2)^n can be covered by disjoint
translates of V. In other words, V is a tile if and only if there is a subset A
of GF(2)^n such that V+A = GF(2)^n uniquely (i.e., v + a = v' + a' implies that
v=v' and a=a' where v,v' in V and a,a' in A). In some problems in coding theory
and hashing we are given a putative tile V, and wish to know whether or not it
is a tile. In this paper we give two computational criteria for certifying that
V is not a tile. The first involves impossibility of a bin-packing problem, and
the second involves infeasibility of a linear program. We apply both criteria
to a list of putative tiles given by Gordon, Miller, and Ostapenko in that none
of them are, in fact, tiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1393</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1393</id><created>2009-11-07</created><updated>2013-06-30</updated><authors><author><keyname>Hillar</keyname><forenames>Christopher</forenames></author><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author></authors><title>Most tensor problems are NP-hard</title><categories>cs.CC cs.NA math.NA</categories><comments>38 pages; to appear in Journal of the ACM</comments><acm-class>F.2; F.2.1; G.1.2; G.1.3; G.1.5; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that multilinear (tensor) analogues of many efficiently computable
problems in numerical linear algebra are NP-hard. Our list here includes:
determining the feasibility of a system of bilinear equations, deciding whether
a 3-tensor possesses a given eigenvalue, singular value, or spectral norm;
approximating an eigenvalue, eigenvector, singular vector, or the spectral
norm; and determining the rank or best rank-1 approximation of a 3-tensor.
Furthermore, we show that restricting these problems to symmetric tensors does
not alleviate their NP-hardness. We also explain how deciding nonnegative
definiteness of a symmetric 4-tensor is NP-hard and how computing the
combinatorial hyperdeterminant of a 4-tensor is NP-, #P-, and VNP-hard. We
shall argue that our results provide another view of the boundary separating
the computational tractability of linear/convex problems from the
intractability of nonlinear/nonconvex ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1412</identifier>
 <datestamp>2013-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1412</id><created>2009-11-07</created><updated>2013-02-23</updated><authors><author><keyname>Grabmayer</keyname><forenames>Clemens</forenames></author></authors><title>From Abstract Rewriting Systems to Abstract Proof Systems</title><categories>cs.LO cs.SC</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some personal recollections on the introduction of `abstract proof systems'
as a framework for formulating syntax-independent, general results about rule
derivability and admissibility. With a particular eye on the inspiration I owe
to Roel de Vrijer: the analogy with abstract rewriting systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1419</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1419</id><created>2009-11-07</created><updated>2010-05-02</updated><authors><author><keyname>Watanabe</keyname><forenames>Yusuke</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Belief Propagation and Loop Calculus for the Permanent of a Non-Negative
  Matrix</title><categories>cs.DS cond-mat.stat-mech cs.DM cs.LG cs.NA math.OC</categories><comments>11 pages; submitted to Journal of Physics A: Mathematical Theoretical</comments><doi>10.1088/1751-8113/43/24/242002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider computation of permanent of a positive $(N\times N)$ non-negative
matrix, $P=(P_i^j|i,j=1,\cdots,N)$, or equivalently the problem of weighted
counting of the perfect matchings over the complete bipartite graph $K_{N,N}$.
The problem is known to be of likely exponential complexity. Stated as the
partition function $Z$ of a graphical model, the problem allows exact Loop
Calculus representation [Chertkov, Chernyak '06] in terms of an interior
minimum of the Bethe Free Energy functional over non-integer doubly stochastic
matrix of marginal beliefs, $\beta=(\beta_i^j|i,j=1,\cdots,N)$, also
correspondent to a fixed point of the iterative message-passing algorithm of
the Belief Propagation (BP) type. Our main result is an explicit expression of
the exact partition function (permanent) in terms of the matrix of BP
marginals, $\beta$, as $Z=\mbox{Perm}(P)=Z_{BP}
\mbox{Perm}(\beta_i^j(1-\beta_i^j))/\prod_{i,j}(1-\beta_i^j)$, where $Z_{BP}$
is the BP expression for the permanent stated explicitly in terms if $\beta$.
We give two derivations of the formula, a direct one based on the Bethe Free
Energy and an alternative one combining the Ihara graph-$\zeta$ function and
the Loop Calculus approaches. Assuming that the matrix $\beta$ of the Belief
Propagation marginals is calculated, we provide two lower bounds and one
upper-bound to estimate the multiplicative term. Two complementary lower bounds
are based on the Gurvits-van der Waerden theorem and on a relation between the
modified permanent and determinant respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1426</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1426</id><created>2009-11-09</created><authors><author><keyname>Bagheri</keyname><forenames>Hossein</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On the Capacity of the Half-Duplex Diamond Channel</title><categories>cs.IT math.IT</categories><comments>25 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a dual-hop communication system composed of a source S and a
destination D connected through two non-interfering half-duplex relays, R1 and
R2, is considered. In the literature of Information Theory, this configuration
is known as the diamond channel. In this setup, four transmission modes are
present, namely: 1) S transmits, and R1 and R2 listen (broadcast mode), 2) S
transmits, R1 listens, and simultaneously, R2 transmits and D listens. 3) S
transmits, R2 listens, and simultaneously, R1 transmits and D listens. 4) R1,
R2 transmit, and D listens (multiple-access mode). Assuming a constant power
constraint for all transmitters, a parameter $\Delta$ is defined, which
captures some important features of the channel. It is proven that for
$\Delta$=0 the capacity of the channel can be attained by successive relaying,
i.e, using modes 2 and 3 defined above in a successive manner. This strategy
may have an infinite gap from the capacity of the channel when $\Delta\neq$0.
To achieve rates as close as 0.71 bits to the capacity, it is shown that the
cases of $\Delta$&gt;0 and $\Delta$&lt;0 should be treated differently. Using new
upper bounds based on the dual problem of the linear program associated with
the cut-set bounds, it is proven that the successive relaying strategy needs to
be enhanced by an additional broadcast mode (mode 1), or multiple access mode
(mode 4), for the cases of $\Delta$&lt;0 and $\Delta$&gt;0, respectively.
Furthermore, it is established that under average power constraints the
aforementioned strategies achieve rates as close as 3.6 bits to the capacity of
the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1440</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1440</id><created>2009-11-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Caveats for the Use of Citation Indicators in Research and Journal
  Evaluations</title><categories>physics.soc-ph cs.DL</categories><journal-ref>Loet Leydesdorff, Caveats for the Use of Citation Indicators in
  Research and Journal Evaluations, Journal of the American Society for
  Information Science and Technology 59(2), 278-287, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ageing of publications, percentage of self-citations, and impact vary from
journal to journal within fields of science. The assumption that citation and
publication practices are homogenous within specialties and fields of science
is invalid. Furthermore, the delineation of fields and among specialties is
fuzzy. Institutional units of analysis and persons may move between fields or
span different specialties. The match between the citation index and
institutional profiles varies among institutional units and nations. The
respective matches may heavily affect the representation of the units. Non-ISI
journals are increasingly cornered into &quot;transdisciplinary&quot; Mode-2 functions
with the exception of specialist journals publishing in languages other than
English. An &quot;externally cited impact factor&quot; can be calculated for these
journals. The citation impact of non-ISI journals will be demonstrated using
Science and Public Policy as the example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1445</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1445</id><created>2009-11-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The delineation of nanoscience and nanotechnology in terms of journals
  and patents: a most recent update</title><categories>physics.soc-ph cs.DL</categories><journal-ref>Loet Leydesdorff, The delineation of nanoscience and
  nanotechnology in terms of journals and patents: a most recent update.
  Scientometrics 76(1), 159-167, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The journal set which provides a representation of nanoscience and
nanotechnology at the interfaces among applied physics, chemistry, and the life
sciences is developing rapidly because of the introduction of new journals. The
relevant contributions of nations can be expected to change according to the
representations of the relevant interfaces among journal sets. In the 2005 set
the position of the USA decreased more than in the 2004-set, while the EU-27
gained in terms of its percentage of world share of citations. The tag &quot;Y01N&quot;
which was newly added to the EU classification system for patents, allows for
the visualization of national profiles of nanotechnology in terms of relevant
patents and patent classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1447</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1447</id><created>2009-11-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>On the Normalization and Visualization of Author Co-Citation Data
  Salton's Cosine versus the Jaccard Index</title><categories>physics.soc-ph cs.DL cs.IR</categories><journal-ref>Loet Leydesdorff, On the Normalization and Visualization of Author
  Co-citation Data: Salton's cosine versus the Jaccard Index, Journal of the
  American Society for Information Science and Technology, 59(1), 77-85, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The debate about which similarity measure one should use for the
normalization in the case of Author Co-citation Analysis (ACA) is further
complicated when one distinguishes between the symmetrical co-citation--or,
more generally, co-occurrence--matrix and the underlying asymmetrical
citation--occurrence--matrix. In the Web environment, the approach of
retrieving original citation data is often not feasible. In that case, one
should use the Jaccard index, but preferentially after adding the number of
total citations (occurrences) on the main diagonal. Unlike Salton's cosine and
the Pearson correlation, the Jaccard index abstracts from the shape of the
distributions and focuses only on the intersection and the sum of the two sets.
Since the correlations in the co-occurrence matrix may partially be spurious,
this property of the Jaccard index can be considered as an advantage in this
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1451</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1451</id><created>2009-11-07</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Zhou</keyname><forenames>Ping</forenames></author></authors><title>Co-word Analysis using the Chinese Character Set</title><categories>cs.CL cs.DL</categories><journal-ref>Co-Word Analysis using the Chinese Character Set, Journal of the
  American Society for Information Science and Technology 59(9), 1528-1530,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Until recently, Chinese texts could not be studied using co-word analysis
because the words are not separated by spaces in Chinese (and Japanese). A word
can be composed of one or more characters. The online availability of programs
that separate Chinese texts makes it possible to analyze them using semantic
maps. Chinese characters contain not only information, but also meaning. This
may enhance the readability of semantic maps. In this study, we analyze 58
words which occur ten or more times in the 1652 journal titles of the China
Scientific and Technical Papers and Citations Database. The word occurrence
matrix is visualized and factor-analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1454</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1454</id><created>2009-11-07</created><authors><author><keyname>Lucio-Arias</keyname><forenames>Diana</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Main-path analysis and path-dependent transitions in HistCite(TM)-based
  historiograms</title><categories>physics.soc-ph cs.DL</categories><journal-ref>Journal of the American Society for Information Science and
  Technology 59(12), 1948-1962, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the program HistCite(TM) it is possible to generate and visualize the
most relevant papers in a set of documents retrieved from the Science Citation
Index. Historical reconstructions of scientific developments can be represented
chronologically as developments in networks of citation relations extracted
from scientific literature. This study aims to go beyond the historical
reconstruction of scientific knowledge, enriching the output of HistCite(TM)
with algorithms from social network analysis and information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1456</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1456</id><created>2009-11-07</created><authors><author><keyname>Park</keyname><forenames>Han Woo</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Korean journals in the Science Citation Index: What do they reveal about
  the intellectual structure of S&amp;T in Korea?</title><categories>physics.soc-ph cs.DL</categories><journal-ref>Han Woo Park &amp; Loet Leydesdorff, Korean journals in the Science
  Citation Index: What do they reveal about the intellectual structure of ST in
  Korea Scientometrics 75(3) (2008) 439-462</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last decade, we have witnessed a sustained growth of South Korea's
research output in terms of the world share of publications in the Science
Citation Index database. However, Korea's citation performance is not yet as
competitive as publication performance. In this study, the authors examine the
intellectual structure of Korean S&amp;T field based on social network analysis of
journal-journal citation data using the ten Korean SCI journals as seed
journals. The results reveal that Korean SCI journals function more like
publication places, neither research channels nor information sources among
national scientists. Thus, these journals may provide Korean scholars with
access to international scientific communities by facilitating the respective
entry barriers. However, there are no citation relations based on their Korean
background. Furthermore, we intend to draw some policy implications which may
be helpful to increase Korea's research potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1494</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1494</id><created>2009-11-08</created><authors><author><keyname>Nehan</keyname><forenames>Yves-Roger</forenames><affiliation>CRI</affiliation></author><author><keyname>Deneckere</keyname><forenames>Rebecca</forenames><affiliation>CRI</affiliation></author></authors><title>Situational Method Engineering: Fundamentals and Experiences</title><categories>cs.SE</categories><proxy>ccsd hal-00430094</proxy><journal-ref>Situational Method Engineering: Fundamentals and Experiences,
  Geneve : Switzerland (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work presented in this paper is related to the area of Situational Method
Engineering (SME) which focuses on project-specific method construction. We
propose a faceted framework to understand and classify issues in system
development SME. The framework identifies four different but complementary
viewpoints. Each view allows us to capture a particular aspect of situational
methods. Inter-relationships between these views show how they influence each
other. In order to study, understand and classify a particular view of SME in
its diversity, we associate a set of facets with each view. As a facet allows
an in-depth description of one specific aspect of SME, the views show the
variety and diversity of these aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1495</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1495</id><created>2009-11-08</created><authors><author><keyname>Kornyshova</keyname><forenames>Elena</forenames><affiliation>CRI</affiliation></author><author><keyname>Deneckere</keyname><forenames>Rebecca</forenames><affiliation>CRI</affiliation></author><author><keyname>Salinesi</keyname><forenames>Camille</forenames><affiliation>CRI</affiliation></author></authors><title>Method Chunks Selection by Multicriteria Techniques: an Extension of the
  Assembly-based Approach</title><categories>cs.SE</categories><proxy>ccsd hal-00430084</proxy><journal-ref>Situational Method Engineering: Fundamentals and Experiences,
  Geneve : Suisse (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work presented in this paper is related to the area of situational method
engineering (SME). In this domain, approaches are developed accordingly to
specific project specifications. We propose to adapt an existing method
construction process, namely the assembly-based one. One of the particular
features of assembly-based SME approach is the selection of method chunks. Our
proposal is to offer a better guidance in the retrieval of chunks by the
introduction of multicriteria techniques. To use them efficiently, we defined a
typology of projects characteristics, in order to identify all their critical
aspects, which will offer a priorisation to help the method engineer in the
choice between similar chunks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1496</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1496</id><created>2009-11-08</created><authors><author><keyname>Kornyshova</keyname><forenames>Elena</forenames><affiliation>CRI</affiliation></author><author><keyname>Deneckere</keyname><forenames>Rebecca</forenames><affiliation>CRI</affiliation></author><author><keyname>Salinesi</keyname><forenames>Camille</forenames><affiliation>CRI</affiliation></author></authors><title>Improving Software Development Processes with Multicriteria Methods</title><categories>cs.SE</categories><comments>11 pages</comments><proxy>ccsd hal-00430026</proxy><journal-ref>Atelier: M\'ethodes avanc\'ee de d\'eveloppement des SI,
  Fontainebleau : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All software development processes include steps where several alternatives
induce a choice, a decision-making. Sometimes, methodologies offer a way to
make decisions. However, in a lot of cases, the arguments to carry out the
decision are very poor and the choice is made in an intuitive and hazardous
way. The aim of our work is to offer a scientifically founded way to guide the
engineer through tactical choices with the application of multicriteria methods
in software development processes. This approach is illustrated with three
cases: risks, use cases and tools within Rational Unified Process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1502</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1502</id><created>2009-11-08</created><authors><author><keyname>Bhutani</keyname><forenames>Gitanjali</forenames></author></authors><title>A Round-based Pricing Scheme for Maximizing Service Provider's Revenue
  in P2PTV Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze a round-based pricing scheme that encourages
favorable behavior from users of real-time P2P applications like P2PTV. In the
design of pricing schemes, we consider price to be a function of usage and
capacity of download/upload streams, and quality of content served. Users are
consumers and servers at the same time in such networks, and often exhibit
behavior that is unfavorable towards maximization of social benefits.
Traditionally, network designers have overcome this difficulty by building-in
traffic latencies. However, using simulations, we show that appropriate pricing
schemes and usage terms can enable designers to limit required traffic
latencies, and be able to earn nearly 30% extra revenue from providing P2PTV
services. The service provider adjusts the prices of individual programs
incrementally within rounds, while making relatively large-scale adjustments at
the end of each round. Through simulations, we show that it is most beneficial
for the service provider to carry out 5 such rounds of price adjustments for
maximizing his average profit and minimizing the associated standard deviation
at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1504</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1504</id><created>2009-11-08</created><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Zhong</keyname><forenames>Yingji</forenames></author><author><keyname>Islam</keyname><forenames>S. M. Riazul</forenames></author><author><keyname>Nessa</keyname><forenames>Ahasanun</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>Throughput Limits of IEEE 802.11 and IEEE 802.15.3</title><categories>cs.NI cs.PF</categories><comments>4 pages, 6 figures, 1 table, 4th International Conference on Wireless
  Communications, Networking and Mobile Computing, 2008. WiCOM '08</comments><doi>10.1109/WiCom.2008.731</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IEEE 802.11 and IEEE 802.15.3 are wireless standards originally designed for
wireless local area network (WLAN) and wireless personal area network (WPAN).
This paper studies MAC throughput analysis of both standards. We present a
comparative analysis of both standards in terms of MAC throughput and bandwidth
efficiency. Numerical results show that the performance of IEEE 802.15.3
transcends IEEE 802.11 in all cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1507</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1507</id><created>2009-11-08</created><updated>2010-07-27</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Khan</keyname><forenames>Pervez</forenames></author><author><keyname>Choi</keyname><forenames>Young-Woo</forenames></author><author><keyname>Lee</keyname><forenames>Hyung-Soo</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>MAC Layer Hurdles in BSNs</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author due to crucial problems
  with the results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last few decades have seen considerable research progress in
microelectronics and integrated circuits, system-on-chip design, wireless
communication, and sensor technology. This progress has enabled the seamless
integration of autonomous wireless sensor nodes around a human body to create a
Body Sensor Network (BSN). The development of a proactive and ambulatory BSN
induces a number of enormous issues and challenges. This paper presents the
technical hurdles during the design and implementation of a low-power Medium
Access Control (MAC) protocol for in-body and on-body sensor networks. We
analyze the performance of IEEE 802.15.4 protocol for the on-body sensor
network. We also provide a comprehensive insight into the heterogeneous
characteristics of the in-body sensor network. A low-power technique called
Pattern-Based Wake-up Table is proposed to handle the normal traffic in a BSN.
The proposed technique provides a reliable solution towards low-power
communication in the in-body sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1508</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1508</id><created>2009-11-08</created><authors><author><keyname>Nessa</keyname><forenames>Ahasanun</forenames></author><author><keyname>Yang</keyname><forenames>Qinghai</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Kabir</keyname><forenames>Humaun</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>Performance Analysis of Two-Hop Cooperative MIMO transmission with Relay
  Selection in Rayleigh Fading Channel</title><categories>cs.NI</categories><comments>5 figures, 4th International Conference on Wireless Communications,
  Networking and Mobile Computing, 2008. WiCOM '08</comments><doi>10.1109/WiCom.2008.122</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless relaying is one of the promising solutions to overcome the channel
impairments and provide high data rate coverage that appears for beyond 3G
mobile communications. In this paper we present an end to end BER performance
analysis of dual hop wireless communication systems equipped with multiple
decode and forward relays over the Rayleigh fading channel with relay
selection. We select the best relay based on end to end channel conditions. We
apply orthogonal space time block coding (OSTBC) at source, and also present
how the multiple antennas at the source terminal affects the end to end BER
performance. This intermediate relay technique will cover long distance where
destination is out of reach from source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1509</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1509</id><created>2009-11-08</created><updated>2010-07-27</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Khan</keyname><forenames>Pervez</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>On the Development of Low Power MAC Protocol for WBANs</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author due to crucial problems
  with the results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current advances in wireless communication, microelectronics, semiconductor
technologies, and intelligent sensors have contributed to the development of
unobtrusive WBANs. These networks provide long term health monitoring of
patients without any constraint in their normal activities. Traditional MAC
protocols do not accommodate the assorted WBAN traffic requirements in a power
efficient manner. In this paper, we present a brief discussion on the
development process of a low power MAC protocol for WBANs. We observe the
behavior of a beacon-enabled IEEE 802.15.4 for on-body sensor networks. We
further propose a low power technique called traffic based wakeup mechanism for
a WBAN that exploits the traffic patterns of the BAN Nodes to ensure power
efficient and reliable communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1510</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1510</id><created>2009-11-08</created><authors><author><keyname>Bhutani</keyname><forenames>Gitanjali</forenames></author></authors><title>A Near-Optimal Scheme for TCP ACK Pacing to Maintain Throughput in
  Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of fourth generation technologies in wireless networks and the
rapid growth of 3G have heralded an era that will require researchers to find
reliable and easily implement-able solutions to the problem of poor TCP
performance in the wireless environment. Since a large part of the Internet is
TCP-based, solving this problem will be instrumental in determining if the move
from wired to wireless will be seamless or not. This paper proposes a scheme
that uses the base station's ability to predict the time at which the link may
be going down and to estimate the period for which the mobile would be
unreachable due to conditions like fading. By using cross-layer and ACK pacing
algorithms, the base station prevents the fixed host from timing out while
waiting for ACKs from the mobile. This in turn prevents TCP on the fixed host
from bringing down the throughput drastically due to temporary network
conditions, caused by mobility or the unreliability of wireless links.
Experimental results indicate a reasonable increase in throughput when the ACK
holding scheme is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1511</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1511</id><created>2009-11-08</created><updated>2010-08-06</updated><authors><author><keyname>Zhong</keyname><forenames>Yingji</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author></authors><title>MIMO Cluster Cooperative Assignment Cross Layer Scheme for Hybrid
  Wireless Sensor Networks</title><categories>cs.NI</categories><comments>4 figures, 9th International Symposium on Communication and
  Information Technology 2009 (ISCIT 2009), September 28-30, 2009, South Korea</comments><doi>10.1109/ISCIT.2009.5341234</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dual-cross scenario of the hybrid wireless sensor networks (WSNs) is
studied and a novel MIMO Cluster Cooperative Assignment Cross Layer Scheduling
Scheme (MCCA-CLSS) is proposed in this paper. The comparison and the
predominance of the proposed scheme are demonstrated, the clusters are
optimized. With the help of the simulations, the relative energy consumption
and the end-to-end blocking probability are all improved. The addressing ratio
of success in the condition of the unchanged parameters and external
information can be increased and the network can tolerate more hops to support
reliable transportation by the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1512</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1512</id><created>2009-11-08</created><authors><author><keyname>Zhong</keyname><forenames>Yingji</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>A Novel Cross Layer Scheme for Multi-Channel Hybrid Cognitive Ad-hoc
  Networks</title><categories>cs.NI</categories><comments>3 figures, KICS Summer Conference 08, Jeju Island, South Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A special scenario of the topology in the hybrid Cognitive Ad-hoc networks is
studied and a novel cross layer scheme is proposed in this paper. The proposed
scheme integrated the attributes both of the new performance evaluation machine
check time metric and the topology space in special scenario. The topology and
power consumption of each node can all be optimized due to the minimum link
occupation with the help of this scheme. Simulation results show that the novel
scheme can give schedule guarantee to the multi-channel networks in the
variable node loads and transmission powers, and make the node stable to
support multi-hops at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1514</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1514</id><created>2009-11-08</created><authors><author><keyname>Ali</keyname><forenames>Murad</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Khan</keyname><forenames>Pervez</forenames></author></authors><title>Managing Innovation and Technology in Developing Countries</title><categories>cs.CY</categories><comments>The 5th annual International New Exploratory Technologies Conference
  2008 (NEXT 2008), Turku, Finland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Innovation and technology management is an inevitable issue in the high end
technological and innovative organizations. Today, most of the innovations are
limited with developed countries like USA, Japan and Europe while developing
countries are still behind in the field of innovation and management of
technology. But it is also becoming a subject for rapid progress and
development in developing countries. Innovation and technology environment in
developing countries are by nature, problematic, characterized by poor business
models, political instability and governance conditions, low education level
and lack of world-class research universities, an underdeveloped and mediocre
physical infrastructure, and lack of solid technology based on trained human
resources. This paper provides a theoretical and conceptual framework analysis
for managing innovation and technology in developing countries like India and
China. We present the issues and challenges in innovation and technology
management and come up with proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1516</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1516</id><created>2009-11-08</created><updated>2010-07-28</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Khan</keyname><forenames>M. A.</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>A Discourse-based Approach in Text-based Machine Translation</title><categories>cs.CL</categories><comments>1 figure, 3 tables, ICCIT 07, Vol. 3, pp 1073-1074, Busan, June 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a theoretical research based approach to ellipsis
resolution in machine translation. The formula of discourse is applied in order
to resolve ellipses. The validity of the discourse formula is analyzed by
applying it to the real world text, i.e., newspaper fragments. The source text
is converted into mono-sentential discourses where complex discourses require
further dissection either directly into primitive discourses or first into
compound discourses and later into primitive ones. The procedure of dissection
needs further improvement, i.e., discovering as many primitive discourse forms
as possible. An attempt has been made to investigate new primitive discourses
or patterns from the given text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1517</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1517</id><created>2009-11-09</created><updated>2010-07-28</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Hussain</keyname><forenames>M. Asdaque</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>Resolution of Unidentified Words in Machine Translation</title><categories>cs.CL</categories><comments>4 pages, 2 figures, 2 tables, The 4th annual International New
  Exploratory Technologies Conference 2007 (NEXT 2007), Seoul, South Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a mechanism of resolving unidentified lexical units in
Text-based Machine Translation (TBMT). In a Machine Translation (MT) system it
is unlikely to have a complete lexicon and hence there is intense need of a new
mechanism to handle the problem of unidentified words. These unknown words
could be abbreviations, names, acronyms and newly introduced terms. We have
proposed an algorithm for the resolution of the unidentified words. This
algorithm takes discourse unit (primitive discourse) as a unit of analysis and
provides real time updates to the lexicon. We have manually applied the
algorithm to news paper fragments. Along with anaphora and cataphora
resolution, many unknown words especially names and abbreviations were updated
to the lexicon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1520</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1520</id><created>2009-11-08</created><authors><author><keyname>Nessa</keyname><forenames>Ahasanun</forenames></author><author><keyname>Ameen</keyname><forenames>M. A.</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>Applicability of Telemedicine in Bangladesh: Current Status and Future
  Prospects</title><categories>cs.CY</categories><comments>ICCIT 08, Vol. 1, pp.948-953, Busan, November 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Telemedicine refers to the use of information and communication technology to
provide and support health care mainly for the purpose of providing
consultation. It is also a way to provide medical procedures or examinations to
remote locations. It has the potential to improve both the quality and the
access to health care services delivery while lowering costs even in the
scarcity of resources. Understanding the potentiality of telemedicine, many
developing countries are implementing telemedicine to provide health care
facility to remote area where health care facilities are deficient. Bangladesh
is not an exception to this either. In this paper we mention the reasons why
Bangladesh has to move for telemedicine. We also present the past and on-going
telemedicine activities and projects in Bangladesh. Analyzing these projects we
have found out some factors which should be assessed carefully for successful
implementation of telemedicine application. Finally we propose a prototype
telemedicine network for Bangladesh that can improve health facilities through
telemedicine by making a connection between rural health facility providers and
special hospitals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1544</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1544</id><created>2009-11-08</created><updated>2010-02-02</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>An</keyname><forenames>Xizhi</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>Towards Power Efficient MAC Protocol for In-Body and On-Body Sensor
  Networks</title><categories>cs.NI</categories><comments>11 pages, 5 figures, 3 tables,KES AMSTA 09, LNAI 5559, pp.335-345,
  Uppsala, June 2009</comments><doi>10.1007/978-3-642-01665-3_34</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an empirical discussion on the design and implementation
of a power-efficient Medium Access Control (MAC) protocol for in-body and
on-body sensor networks. We analyze the performance of a beacon-enabled IEEE
802.15.4, PB-TDMA, and S-MAC protocols for on-body sensor networks. We further
present a Traffic Based Wakeup Mechanism that utilizes the traffic patterns of
the BAN Nodes (BNs) to accommodate the entire BSN traffic. To enable a logical
connection between different BNs working on different frequency bands, a method
called Bridging function is proposed. The Bridging function integrates all BNs
working on different bands into a complete BSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1546</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1546</id><created>2009-11-08</created><updated>2009-11-12</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Higgins</keyname><forenames>Henry</forenames></author><author><keyname>Siddiqui</keyname><forenames>M. Arif</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>A Study of Implanted and Wearable Body Sensor Networks</title><categories>cs.NI</categories><comments>KES-AMSTA 08, LNAI 4953, pp. 464-473, Incheon, March 2008</comments><doi>10.1007/978-3-540-78582-8_47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in intelligent sensors, microelectronics and integrated
circuit, system-on-chip design and low power wireless communication introduced
the development of miniaturised and autonomous sensor nodes. These tiny sensor
nodes can be deployed to develop a proactive Body Sensor Network (BSN). The
rapid advancement in ultra low-power RF (radio frequency) technology enables
invasive and non-invasive devices to communicate with a remote station. This
communication revolutionizes healthcare system by enabling long term health
monitoring of a patient and providing real time feedback to the medical
experts. In this paper, we present In-body and On-body communication networks
with a special focus on the methodologies of wireless communication between
implanted medical devices with external monitoring equipment and recent
technological growth in both areas. We also discuss open issues and challenges
in a BSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1564</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1564</id><created>2009-11-08</created><authors><author><keyname>Cai</keyname><forenames>T. Tony</forenames></author><author><keyname>Wang</keyname><forenames>Lie</forenames></author><author><keyname>Xu</keyname><forenames>Guangwu</forenames></author></authors><title>New Bounds for Restricted Isometry Constants</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that if the restricted isometry constant $\delta_k$ of
the compressed sensing matrix satisfies \[ \delta_k &lt; 0.307, \] then $k$-sparse
signals are guaranteed to be recovered exactly via $\ell_1$ minimization when
no noise is present and $k$-sparse signals can be estimated stably in the noisy
case. It is also shown that the bound cannot be substantively improved. An
explicitly example is constructed in which $\delta_{k}=\frac{k-1}{2k-1} &lt; 0.5$,
but it is impossible to recover certain $k$-sparse signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1582</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1582</id><created>2009-11-08</created><authors><author><keyname>Russell</keyname><forenames>Tyrel</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Manipulating Tournaments in Cup and Round Robin Competitions</title><categories>cs.AI cs.GT cs.MA</categories><comments>Proceedings of Algorithmic Decision Theory, First International
  Conference, ADT 2009, Venice, Italy, October 20-23, 2009</comments><acm-class>I.2.4</acm-class><doi>10.1007/978-3-642-04428-1_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sports competitions, teams can manipulate the result by, for instance,
throwing games. We show that we can decide how to manipulate round robin and
cup competitions, two of the most popular types of sporting competitions in
polynomial time. In addition, we show that finding the minimal number of games
that need to be thrown to manipulate the result can also be determined in
polynomial time. Finally, we show that there are several different variations
of standard cup competitions where manipulation remains polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1583</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1583</id><created>2009-11-08</created><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>Mao</keyname><forenames>Huina</forenames></author></authors><title>Modeling public mood and emotion: Twitter sentiment and socio-economic
  phenomena</title><categories>cs.CY</categories><comments>submitted to WWW2010</comments><journal-ref>Proceedings of the Fifth International AAAI Conference on Weblogs
  and Social Media (ICWSM 2011), 17-21 July 2011, Barcelona, Spain</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microblogging is a form of online communication by which users broadcast
brief text updates, also known as tweets, to the public or a selected circle of
contacts. A variegated mosaic of microblogging uses has emerged since the
launch of Twitter in 2006: daily chatter, conversation, information sharing,
and news commentary, among others. Regardless of their content and intended
use, tweets often convey pertinent information about their author's mood
status. As such, tweets can be regarded as temporally-authentic microscopic
instantiations of public mood state. In this article, we perform a sentiment
analysis of all public tweets broadcasted by Twitter users between August 1 and
December 20, 2008. For every day in the timeline, we extract six dimensions of
mood (tension, depression, anger, vigor, fatigue, confusion) using an extended
version of the Profile of Mood States (POMS), a well-established psychometric
instrument. We compare our results to fluctuations recorded by stock market and
crude oil price indices and major events in media and popular culture, such as
the U.S. Presidential Election of November 4, 2008 and Thanksgiving Day. We
find that events in the social, political, cultural and economic sphere do have
a significant, immediate and highly specific effect on the various dimensions
of public mood. We speculate that large scale analyses of mood can provide a
solid platform to model collective emotive trends in terms of their predictive
value with regards to existing social as well as economic indicators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1619</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1619</id><created>2009-11-09</created><authors><author><keyname>D&#xfc;tting</keyname><forenames>Paul</forenames></author><author><keyname>Henzinger</keyname><forenames>Monika</forenames></author><author><keyname>Weber</keyname><forenames>Ingmar</forenames></author></authors><title>On the Pricing of Recommendations and Recommending Strategically</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If you recommend a product to me and I buy it, how much should you be paid by
the seller? And if your sole interest is to maximize the amount paid to you by
the seller for a sequence of recommendations, how should you recommend
optimally if I become more inclined to ignore you with each irrelevant
recommendation you make? Finding an answer to these questions is a key
challenge in all forms of marketing that rely on and explore social ties;
ranging from personal recommendations to viral marketing.
  In the first part of this paper, we show that there can be no pricing
mechanism that is &quot;truthful&quot; with respect to the seller, and we use solution
concepts from coalitional game theory, namely the Core, the Shapley Value, and
the Nash Bargaining Solution, to derive provably &quot;fair&quot; prices for settings
with one or multiple recommenders. We then investigate pricing mechanisms for
the setting where recommenders have different &quot;purchase arguments&quot;. Here we
show that it might be beneficial for the recommenders to withhold some of their
arguments, unless anonymity-proof solution concepts, such as the
anonymity-proof Shapley value, are used.
  In the second part of this paper, we analyze the setting where the
recommendee loses trust in the recommender for each irrelevant recommendation.
Here we prove that even if the recommendee regains her initial trust on each
successful recommendation, the expected total profit the recommender can make
over an infinite period is bounded. This can only be overcome when the
recommendee also incrementally regains trust during periods without any
recommendation. Here, we see an interesting connection to &quot;banner blindness&quot;,
suggesting that showing fewer ads can lead to a higher long-term profit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1626</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1626</id><created>2009-11-09</created><updated>2010-06-17</updated><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Kowalik</keyname><forenames>Lukasz</forenames></author><author><keyname>Mucha</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author></authors><title>Fast Approximation in Subspaces by Doubling Metric Decomposition</title><categories>cs.DS</categories><acm-class>E.1; F.2.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose and study a new complexity model for approximation
algorithms. The main motivation are practical problems over large data sets
that need to be solved many times for different scenarios, e.g., many multicast
trees that need to be constructed for different groups of users. In our model
we allow a preprocessing phase, when some information of the input graph
$G=(V,E)$ is stored in a limited size data structure. Next, the data structure
enables processing queries of the form ``solve problem A for an input
$S\subseteq V$''. We consider problems like {\sc Steiner Forest}, {\sc Facility
Location}, {\sc $k$-Median}, {\sc $k$-Center} and {\sc TSP} in the case when
the graph induces a doubling metric. Our main results are data structures of
near-linear size that are able to answer queries in time close to linear in
$|S|$. This improves over typical worst case reuniting time of approximation
algorithms in the classical setting which is $\Omega(|E|)$ independently of the
query size. In most cases, our approximation guarantees are arbitrarily close
to those in the classical setting. Additionally, we present the first fully
dynamic algorithm for the Steiner tree problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1647</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1647</id><created>2009-11-09</created><authors><author><keyname>Kale</keyname><forenames>Ajinkya</forenames></author><author><keyname>Chakravarthy</keyname><forenames>Ananth</forenames></author><author><keyname>Jadhav</keyname><forenames>Nitin</forenames></author></authors><title>An extendible User-Command Framework based on tagging system</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memorizing the user commands has been a problem since long. In this study we
try to propose solutions to overcome two problems - the problem of selecting
appropriate commands names during application development and the problem of
memorizing these command names. The proposed solution includes a framework in
which the applications can plug into, to get their application commands and
corresponding tags in to the new command execution application.We also propose
a mechanism where user can generate her own set of tags for a command and share
those with peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1672</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1672</id><created>2009-11-09</created><authors><author><keyname>Akula</keyname><forenames>Balaji</forenames></author><author><keyname>Cusick</keyname><forenames>James</forenames></author></authors><title>Biological Computing Fundamentals and Futures</title><categories>cs.CE q-bio.OT</categories><comments>Introduction to Biological computing, 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fields of computing and biology have begun to cross paths in new ways. In
this paper a review of the current research in biological computing is
presented. Fundamental concepts are introduced and these foundational elements
are explored to discuss the possibilities of a new computing paradigm. We
assume the reader to possess a basic knowledge of Biology and Computer Science
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1677</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1677</id><created>2009-11-09</created><authors><author><keyname>Schuh</keyname><forenames>Bernd R.</forenames></author></authors><title>Logical Primes, Metavariables and Satisfiability</title><categories>math.LO cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For formulas F of propositional calculus I introduce a &quot;metavariable&quot; MF and
show how it can be used to define an algorithm for testing satisfiability. MF
is a formula which is true/false under all possible truth assignments iff F is
satisfiable/unsatisfiable. In this sense MF is a metavariable with the
&quot;meaning&quot; 'F is SAT'. For constructing MF a group of transformations of the
basic variables ai is used which corresponds to 'flipping&quot; literals to their
negation. The whole procedure corresponds to branching algorithms where a
formula is split with respect to the truth values of its variables, one by one.
Each branching step corresponds to an approximation to the metatheorem which
doubles the chance to find a satisfying truth assignment but also doubles the
length of the formulas to be tested, in principle. Simplifications arise by
additional length reductions. I also discuss the notion of &quot;logical primes&quot; and
show that each formula can be written as a uniquely defined product of such
prime factors. Satisfying truth assignments can be found by determining the
&quot;missing&quot; primes in the factorization of a formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1678</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1678</id><created>2009-11-09</created><updated>2009-12-17</updated><authors><author><keyname>Darbari</keyname><forenames>Ashish</forenames></author><author><keyname>Fischer</keyname><forenames>Bernd</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author></authors><title>Industrial-Strength Formally Certified SAT Solving</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boolean Satisfiability (SAT) solvers are now routinely used in the
verification of large industrial problems. However, their application in
safety-critical domains such as the railways, avionics, and automotive
industries requires some form of assurance for the results, as the solvers can
(and sometimes do) have bugs. Unfortunately, the complexity of modern, highly
optimized SAT solvers renders impractical the development of direct formal
proofs of their correctness. This paper presents an alternative approach where
an untrusted, industrial-strength, SAT solver is plugged into a trusted,
formally certified, SAT proof checker to provide industrial-strength certified
SAT solving. The key novelties and characteristics of our approach are (i) that
the checker is automatically extracted from the formal development, (ii), that
the combined system can be used as a standalone executable program independent
of any supporting theorem prover, and (iii) that the checker certifies any SAT
solver respecting the agreed format for satisfiability and unsatisfiability
claims. The core of the system is a certified checker for unsatisfiability
claims that is formally designed and verified in Coq. We present its formal
design and outline the correctness proofs. The actual standalone checker is
automatically extracted from the the Coq development. An evaluation of the
certified checker on a representative set of industrial benchmarks from the SAT
Race Competition shows that, albeit it is slower than uncertified SAT checkers,
it is significantly faster than certified checkers implemented on top of an
interactive theorem prover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1681</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1681</id><created>2009-11-09</created><updated>2015-04-02</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Ali</keyname><forenames>Murad</forenames></author><author><keyname>Hussain</keyname><forenames>Asdaque</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>Applications of UWB Technology</title><categories>cs.NI</categories><comments>Report (informal)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in wideband impulse technology, low power communication along
with unlicensed band have enabled ultra wide band (UWB) as a leading technology
for future wireless applications. This paper outlines the applications of
emerging UWB technology in a private and commercial sector. We further talk
about UWB technology for a wireless body area network (WBAN).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1685</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1685</id><created>2009-11-09</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Guillaume</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Multi-Objective Optimisation Method for Posture Prediction and Analysis
  with Consideration of Fatigue Effect and its Application Case</title><categories>cs.RO</categories><proxy>ccsd hal-00430645</proxy><journal-ref>Computers &amp; Industrial Engineering 57, 4 (2009) 1235-1246</journal-ref><doi>10.1016/j.cie.2009.06.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automation technique has been widely used in manufacturing industry, but
there are still manual handling operations required in assembly and maintenance
work in industry. Inappropriate posture and physical fatigue might result in
musculoskeletal disorders (MSDs) in such physical jobs. In ergonomics and
occupational biomechanics, virtual human modelling techniques have been
employed to design and optimize the manual operations in design stage so as to
avoid or decrease potential MSD risks. In these methods, physical fatigue is
only considered as minimizing the muscle or joint stress, and the fatigue
effect along time for the posture is not considered enough. In this study,
based on the existing methods and multiple objective optimisation method (MOO),
a new posture prediction and analysis method is proposed for predicting the
optimal posture and evaluating the physical fatigue in the manual handling
operation. The posture prediction and analysis problem is mathematically
described and a special application case is demonstrated for analyzing a
drilling assembly operation in European Aeronautic Defence &amp; Space Company
(EADS) in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1691</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1691</id><created>2009-11-09</created><updated>2010-02-16</updated><authors><author><keyname>Amossen</keyname><forenames>Rasmus Resen</forenames></author></authors><title>Vertical partitioning of relational OLTP databases using integer
  programming</title><categories>cs.DB cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A way to optimize performance of relational row store databases is to reduce
the row widths by vertically partitioning tables into table fractions in order
to minimize the number of irrelevant columns/attributes read by each
transaction. This paper considers vertical partitioning algorithms for
relational row-store OLTP databases with an H-store-like architecture, meaning
that we would like to maximize the number of single-sited transactions. We
present a model for the vertical partitioning problem that, given a schema
together with a vertical partitioning and a workload, estimates the costs
(bytes read/written by storage layer access methods and bytes transferred
between sites) of evaluating the workload on the given partitioning. The cost
model allows for arbitrarily prioritizing load balancing of sites vs. total
cost minimization. We show that finding a minimum-cost vertical partitioning in
this model is NP-hard and present two algorithms returning solutions in which
single-sitedness of read queries is preserved while allowing column replication
(which may allow a drastically reduced cost compared to disjoint partitioning).
The first algorithm is a quadratic integer program that finds optimal
minimum-cost solutions with respect to the model, and the second algorithm is a
more scalable heuristic based on simulated annealing. Experiments show that the
algorithms can reduce the cost of the model objective by 37% when applied to
the TPC-C benchmark and the heuristic is shown to obtain solutions with cost
close to the ones found using the quadratic program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1696</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1696</id><created>2009-11-09</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Kempe</keyname><forenames>Julia</forenames></author><author><keyname>Sattath</keyname><forenames>Or</forenames></author></authors><title>A Quantum Lovasz Local Lemma</title><categories>quant-ph cs.CC</categories><comments>19 pages</comments><journal-ref>Journal of the ACM, Volume 59 Issue 5, October 2012, Article No.
  24</journal-ref><doi>10.1145/2371656.2371659</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lovasz Local Lemma (LLL) is a powerful tool in probability theory to show
the existence of combinatorial objects meeting a prescribed collection of
&quot;weakly dependent&quot; criteria. We show that the LLL extends to a much more
general geometric setting, where events are replaced with subspaces and
probability is replaced with relative dimension, which allows to lower bound
the dimension of the intersection of vector spaces under certain independence
conditions. Our result immediately applies to the k-QSAT problem: For instance
we show that any collection of rank 1 projectors with the property that each
qubit appears in at most $2^k/(e \cdot k)$ of them, has a joint satisfiable
state.
  We then apply our results to the recently studied model of random k-QSAT.
Recent works have shown that the satisfiable region extends up to a density of
1 in the large k limit, where the density is the ratio of projectors to qubits.
Using a hybrid approach building on work by Laumann et al. we greatly extend
the known satisfiable region for random k-QSAT to a density of
$\Omega(2^k/k^2)$. Since our tool allows us to show the existence of joint
satisfying states without the need to construct them, we are able to penetrate
into regions where the satisfying states are conjectured to be entangled,
avoiding the need to construct them, which has limited previous approaches to
product states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1707</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1707</id><created>2009-11-09</created><authors><author><keyname>Nabaa</keyname><forenames>Michel</forenames><affiliation>LITIS</affiliation></author><author><keyname>Bertelle</keyname><forenames>Cyrille</forenames><affiliation>LITIS</affiliation></author><author><keyname>Dutot</keyname><forenames>Antoine</forenames><affiliation>LITIS</affiliation></author><author><keyname>Olivier</keyname><forenames>Damien</forenames><affiliation>LITIS</affiliation></author><author><keyname>Mallet</keyname><forenames>Pascal</forenames></author></authors><title>A Dynamic Vulnerability Map to Assess the Risk of Road Network Traffic
  Utilization</title><categories>cs.AI physics.soc-ph</categories><proxy>ccsd hal-00430696</proxy><journal-ref>International Symposium on Risk Models and Applications, Ki\`ev :
  Ukraine (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Le Havre agglomeration (CODAH) includes 16 establishments classified Seveso
with high threshold. In the literature, we construct vulnerability maps to help
decision makers assess the risk. Such approaches remain static and do take into
account the population displacement in the estimation of the vulnerability. We
propose a decision making tool based on a dynamic vulnerability map to evaluate
the difficulty of evacuation in the different sectors of CODAH. We use a
Geographic Information system (GIS) to visualize the map which evolves with the
road traffic state through a detection of communities in large graphs
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1708</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1708</id><created>2009-11-09</created><authors><author><keyname>Tranouez</keyname><forenames>Pierrick</forenames><affiliation>LITIS, IDEES</affiliation></author><author><keyname>Dutot</keyname><forenames>Antoine</forenames><affiliation>LITIS</affiliation></author></authors><title>Different goals in multiscale simulations and how to reach them</title><categories>cs.AI nlin.AO</categories><proxy>ccsd hal-00430674</proxy><journal-ref>Complex Systems and Self-organization Modelling, Bertelle,
  Cyrille; Duchamp, G\'erard H.E.; Kadri-Dahmani, Hakima (Ed.) (2009) 29-39</journal-ref><doi>10.1007/978-3-540-88073-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we sum up our works on multiscale programs, mainly simulations.
We ?rst start with describing what multiscaling is about, how it helps
perceiving signal from a background noise in a ?ow of data for example, for a
direct perception by a user or for a further use by another program. We then
give three examples of multiscale techniques we used in the past, maintaining a
summary, using an environmental marker introducing an history in the data and
?nally using a knowledge on the behavior of the di?erent scales to really
handle them at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1713</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1713</id><created>2009-11-09</created><authors><author><keyname>Bogaerts</keyname><forenames>Mathieu</forenames></author></authors><title>Isometries and Construction of Permutation Arrays</title><categories>math.CO cs.IT math.IT</categories><comments>6 pages, 2 tables</comments><msc-class>05B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An (n,d)-permutation code is a subset C of Sym(n) such that the Hamming
distance d_H between any two distinct elements of C is at least equal to d. In
this paper, we use the characterisation of the isometry group of the metric
space (Sym(n),d_H) in order to develop generating algorithms with rejection of
isomorphic objects. To classify the (n,d)-permutation codes up to isometry, we
construct invariants and study their efficiency. We give the numbers of
non-isometric (4,3)- and (5,4)- permutation codes. Maximal and balanced
(n,d)-permutation codes are enumerated in a constructive way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1720</identifier>
 <datestamp>2009-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1720</id><created>2009-11-09</created><authors><author><keyname>Roca</keyname><forenames>Carlos P.</forenames></author><author><keyname>Cuesta</keyname><forenames>Jos&#xe9; A.</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Angel</forenames></author></authors><title>Evolutionary game theory: Temporal and spatial effects beyond replicator
  dynamics</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>Review, 48 pages, 26 figures</comments><journal-ref>Physics of Life Reviews 6, 208-249 (2009)</journal-ref><doi>10.1016/j.plrev.2009.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary game dynamics is one of the most fruitful frameworks for
studying evolution in different disciplines, from Biology to Economics. Within
this context, the approach of choice for many researchers is the so-called
replicator equation, that describes mathematically the idea that those
individuals performing better have more offspring and thus their frequency in
the population grows. While very many interesting results have been obtained
with this equation in the three decades elapsed since it was first proposed, it
is important to realize the limits of its applicability. One particularly
relevant issue in this respect is that of non-mean-field effects, that may
arise from temporal fluctuations or from spatial correlations, both neglected
in the replicator equation. This review discusses these temporal and spatial
effects focusing on the non-trivial modifications they induce when compared to
the outcome of replicator dynamics. Alongside this question, the hypothesis of
linearity and its relation to the choice of the rule for strategy update is
also analyzed. The discussion is presented in terms of the emergence of
cooperation, as one of the current key problems in Biology and in other
disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1739</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1739</id><created>2009-11-09</created><authors><author><keyname>Friedland</keyname><forenames>Shmuel</forenames></author></authors><title>Graph isomorphism and volumes of convex bodies</title><categories>cs.CC cs.DM</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a nontrivial graph isomorphism problem of two undirected graphs,
and more generally, the permutation similarity of two given $n\times n$
matrices, is equivalent to equalities of volumes of the induced three convex
bounded polytopes intersected with a given sequence of balls, centered at the
origin with radii $t_i\in (0,\sqrt{n-1})$, where $\{t_i\}$ is an increasing
sequence converging to $\sqrt{n-1}$. These polytopes are characterized by $n^2$
inequalities in at most $n^2$ variables. The existence of fpras for computing
volumes of convex bodies gives rise to a semi-frpas of order $O^*(n^{14})$ at
most to find if given two undirected graphs are isomorphic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1741</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1741</id><created>2009-11-09</created><updated>2010-03-10</updated><authors><author><keyname>King</keyname><forenames>Andrew D.</forenames></author></authors><title>Hitting all maximum cliques with a stable set using lopsided independent
  transversals</title><categories>cs.DM math.CO</categories><comments>7 pages. v4: Correction to statement of Lemma 8 and clarified proof.</comments><doi>10.1002/jgt.20532</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rabern recently proved that any graph with omega &gt;= (3/4)(Delta+1) contains a
stable set meeting all maximum cliques. We strengthen this result, proving that
such a stable set exists for any graph with omega &gt; (2/3)(Delta+1). This is
tight, i.e. the inequality in the statement must be strict. The proof relies on
finding an independent transversal in a graph partitioned into vertex sets of
unequal size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1743</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1743</id><created>2009-11-09</created><authors><author><keyname>Hinton</keyname><forenames>Ryan</forenames><affiliation>University of Virginia and L-3 Communications CSW</affiliation></author><author><keyname>Wilson</keyname><forenames>Stephen G.</forenames><affiliation>University of Virginia</affiliation></author></authors><title>Analysis of peeling decoder for MET ensembles</title><categories>cs.IT math.IT</categories><comments>Preprint of submission to Information Theory Workshop (ITW) 2010. 5
  pages, two figures (from seven files). Processed with PDFLaTeX including
  IEEEtran style, amsmath, amsfonts, cite, array, graphicx, and amsthm packages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The peeling decoder introduced by Luby, et al. allows analysis of LDPC
decoding for the binary erasure channel (BEC). For irregular ensembles, they
analyze the decoder state as a Markov process and present a solution to the
differential equations describing the process mean. Multi-edge type (MET)
ensembles allow greater precision through specifying graph connectivity. We
generalize the the peeling decoder for MET ensembles and derive analogous
differential equations. We offer a new change of variables and solution to the
node fraction evolutions in the general (MET) case. This result is preparatory
to investigating finite-length ensemble behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1745</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1745</id><created>2009-11-09</created><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Sequence Folding, Lattice Tiling, and Multidimensional Coding</title><categories>cs.IT math.CO math.IT</categories><comments>21 pages</comments><msc-class>94A55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Folding a sequence $S$ into a multidimensional box is a well-known method
which is used as a multidimensional coding technique. The operation of folding
is generalized in a way that the sequence $S$ can be folded into various shapes
and not just a box. The new definition of folding is based on a lattice tiling
for the given shape $\cS$ and a direction in the $D$-dimensional integer grid.
Necessary and sufficient conditions that a lattice tiling for $\cS$ combined
with a direction define a folding of a sequence into $\cS$ are derived. The
immediate and most impressive application is some new lower bounds on the
number of dots in two-dimensional synchronization patterns. This can be also
generalized for multidimensional synchronization patterns. The technique and
its application for two-dimensional synchronization patterns, raise some
interesting problems in discrete geometry. We will also discuss these problems.
It is also shown how folding can be used to construct multidimensional
error-correcting codes. Finally, by using the new definition of folding,
multidimensional pseudo-random arrays with various shapes are generated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1763</identifier>
 <datestamp>2010-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1763</id><created>2009-11-09</created><updated>2010-05-03</updated><authors><author><keyname>Harper</keyname><forenames>Marc</forenames></author></authors><title>The Replicator Equation as an Inference Dynamic</title><categories>math.DS cs.IT math.IT</categories><comments>Added a discussion of the discrete dynamic.</comments><msc-class>37N25, Secondary: 62F15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The replicator equation is interpreted as a continuous inference equation and
a formal similarity between the discrete replicator equation and Bayesian
inference is described. Further connections between inference and the
replicator equation are given including a discussion of information divergences
and exponential families as solutions for the replicator dynamic, using Fisher
information and information geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1764</identifier>
 <datestamp>2012-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1764</id><created>2009-11-09</created><updated>2012-02-24</updated><authors><author><keyname>Harper</keyname><forenames>Marc</forenames></author></authors><title>Escort Evolutionary Game Theory</title><categories>math.DS cs.IT math.DG math.IT</categories><comments>Minor typo correction</comments><msc-class>37N25, 91A22, 94A15</msc-class><journal-ref>Physica D: Nonlinear Phenomena, Volume 240, Issue 18, 1 September
  2011, Pages 1411-1415</journal-ref><doi>10.1016/j.physd.2011.04.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A family of replicator-like dynamics, called the escort replicator equation,
is constructed using information-geometric concepts and generalized information
entropies and diverenges from statistical thermodynamics. Lyapunov functions
and escort generalizations of basic concepts and constructions in evolutionary
game theory are given, such as an escorted Fisher's Fundamental theorem and
generalizations of the Shahshahani geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1765</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1765</id><created>2009-11-09</created><authors><author><keyname>Kennedy</keyname><forenames>Justin</forenames></author><author><keyname>Mandoiu</keyname><forenames>Ion I.</forenames></author><author><keyname>Pasaniuc</keyname><forenames>Bogdan</forenames></author></authors><title>GEDI: Scalable Algorithms for Genotype Error Detection and Imputation</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genome-wide association studies generate very large datasets that require
scalable analysis algorithms. In this report we describe the GEDI software
package, which implements efficient algorithms for performing several common
tasks in the analysis of population genotype data, including genotype error
detection and correction, imputation of both randomly missing and untyped
genotypes, and genotype phasing. Experimental results show that GEDI achieves
high accuracy with a runtime scaling linearly with the number of markers and
samples. The open source C++ code of GEDI, released under the GNU General
Public License, is available for download at
http://dna.engr.uconn.edu/software/GEDI/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1767</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1767</id><created>2009-11-09</created><updated>2010-05-07</updated><authors><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>A Natural Dynamics for Bargaining on Exchange Networks</title><categories>cs.GT</categories><comments>28 pages, 1 figure, second part of this work with different analysis
  and stronger results available at arXiv:1004.2079v1 [cs.GT]. This paper
  unchanged in update.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bargaining networks model the behavior of a set of players that need to reach
pairwise agreements for making profits. Nash bargaining solutions are special
outcomes of such games that are both stable and balanced. Kleinberg and Tardos
proved a sharp algorithmic characterization of such outcomes, but left open the
problem of how the actual bargaining process converges to them. A partial
answer was provided by Azar et al. who proposed a distributed algorithm for
constructing Nash bargaining solutions, but without polynomial bounds on its
convergence rate. In this paper, we introduce a simple and natural model for
this process, and study its convergence rate to Nash bargaining solutions. At
each time step, each player proposes a deal to each of her neighbors. The
proposal consists of a share of the potential profit in case of agreement. The
share is chosen to be balanced in Nash's sense as far as this is feasible (with
respect to the current best alternatives for both players). We prove that,
whenever the Nash bargaining solution is unique (and satisfies a positive gap
condition) this dynamics converges to it in polynomial time. Our analysis is
based on an approximate decoupling phenomenon between the dynamics on different
substructures of the network. This approach may be of general interest for the
analysis of local algorithms on networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1783</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1783</id><created>2009-11-09</created><updated>2011-05-22</updated><authors><author><keyname>Leykin</keyname><forenames>Anton</forenames></author></authors><title>Numerical Algebraic Geometry for Macaulay2</title><categories>math.AG cs.MS</categories><comments>7 pages</comments><report-no>Mittag-Leffler-2011spring</report-no><msc-class>14Q99, 68N01</msc-class><journal-ref>Numerical algebraic geometry. JSAG, 3:5-10, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical Algebraic Geometry uses numerical data to describe algebraic
varieties. It is based on the methods of numerical polynomial homotopy
continuation, an alternative to the classical symbolic approaches of
computational algebraic geometry. We present a package, the driving idea behind
which is to interlink the existing symbolic methods of Macaulay2 and the
powerful engine of numerical approximate computations. The core procedures of
the package exhibit performance competitive with the other homotopy
continuation software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1807</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1807</id><created>2009-11-09</created><updated>2010-04-29</updated><authors><author><keyname>West</keyname><forenames>Jevin</forenames></author><author><keyname>Bergstrom</keyname><forenames>Theodore</forenames></author><author><keyname>Bergstrom</keyname><forenames>Carl</forenames></author></authors><title>Big Macs and Eigenfactor Scores: Don't Let Correlation Coefficients Fool
  You</title><categories>cs.DL</categories><comments>Version 2 This is a response to Phil Davis's 2008 paper
  (arXiv:0807.2678)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Eigenfactor Metrics provide an alternative way of evaluating scholarly
journals based on an iterative ranking procedure analogous to Google's PageRank
algorithm. These metrics have recently been adopted by Thomson-Reuters and are
listed alongside the Impact Factor in the Journal Citation Reports. But do
these metrics differ sufficiently so as to be a useful addition to the
bibliometric toolbox? Davis (2008) has argued otherwise, based on his finding
of a 0.95 correlation coefficient between Eigenfactor score and Total Citations
for a sample of journals in the field of medicine. This conclusion is mistaken;
here we illustrate the basic statistical fallacy to which Davis succumbed. We
provide a complete analysis of the 2006 Journal Citation Reports and
demonstrate that there are statistically and economically significant
differences between the information provided by the Eigenfactor Metrics and
that provided by Impact Factor and Total Citations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1813</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1813</id><created>2009-11-09</created><updated>2011-01-19</updated><authors><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Roughgarden</keyname><forenames>Tim</forenames></author></authors><title>Interactive Privacy via the Median Mechanism</title><categories>cs.CR cs.CC cs.DB cs.DS</categories><comments>Appeared in STOC 2010</comments><acm-class>F.0; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new interactive differentially private mechanism -- the median
mechanism -- for answering arbitrary predicate queries that arrive online.
Relative to fixed accuracy and privacy constraints, this mechanism can answer
exponentially more queries than the previously best known interactive privacy
mechanism (the Laplace mechanism, which independently perturbs each query
result). Our guarantee is almost the best possible, even for non-interactive
privacy mechanisms. Conceptually, the median mechanism is the first privacy
mechanism capable of identifying and exploiting correlations among queries in
an interactive setting.
  We also give an efficient implementation of the median mechanism, with
running time polynomial in the number of queries, the database size, and the
domain size. This efficient implementation guarantees privacy for all input
databases, and accurate query results for almost all input databases. The
dependence of the privacy on the number of queries in this mechanism improves
over that of the best previously known efficient mechanism by a
super-polynomial factor, even in the non-interactive setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1826</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1826</id><created>2009-11-09</created><updated>2016-02-10</updated><authors><author><keyname>Koolen</keyname><forenames>J. H.</forenames><affiliation>USTC</affiliation></author><author><keyname>Lee</keyname><forenames>W. S.</forenames><affiliation>POSTECH</affiliation></author><author><keyname>Martin</keyname><forenames>W. J.</forenames><affiliation>WPI</affiliation></author><author><keyname>Tanaka</keyname><forenames>H.</forenames><affiliation>Tohoku</affiliation></author></authors><title>Arithmetic completely regular codes</title><categories>math.CO cs.IT math.IT</categories><comments>26 pages, 1 figure</comments><msc-class>05E30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore completely regular codes in the Hamming graphs and
related graphs. Experimental evidence suggests that many completely regular
codes have the property that the eigenvalues of the code are in arithmetic
progression. In order to better understand these &quot;arithmetic completely regular
codes&quot;, we focus on cartesian products of completely regular codes and products
of their corresponding coset graphs in the additive case. Employing earlier
results, we are then able to prove a theorem which nearly classifies these
codes in the case where the graph admits a completely regular partition into
such codes (e.g, the cosets of some additive completely regular code).
Connections to the theory of distance-regular graphs are explored and several
open questions are posed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1842</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1842</id><created>2009-11-10</created><authors><author><keyname>Ide</keyname><forenames>Nancy</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Standards for Language Resources</title><categories>cs.CL</categories><comments>Colloque avec actes et comit\'e de lecture. internationale</comments><proxy>ccsd inria-00100589</proxy><report-no>A01-R-287 || ide01b</report-no><journal-ref>IRCS Workshop on Linguistic Databases, Philadelphia : United
  States (2001)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is two-fold: to present an abstract data model for
linguistic annotations and its implementation using XML, RDF and related
standards; and to outline the work of a newly formed committee of the
International Standards Organization (ISO), ISO/TC 37/SC 4 Language Resource
Management, which will use this work as its starting point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1849</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1849</id><created>2009-11-10</created><updated>2010-10-13</updated><authors><author><keyname>Ayach</keyname><forenames>Omar El</forenames></author><author><keyname>Peters</keyname><forenames>Steven W.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>The Feasibility of Interference Alignment over Measured MIMO-OFDM
  Channels</title><categories>cs.IT math.IT</categories><comments>13 double column pages, 16 figures, accepted for publication in IEEE
  Transactions on Vehicular Technology</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol. 59, no. 9, pp.
  4309-4321, November 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment (IA) has been shown to achieve the maximum achievable
degrees of freedom in the interference channel. This results in sum rate
scaling linearly with the number of users in the high signal-to-noise-ratio
(SNR) regime. Linear scaling is achieved by precoding transmitted signals to
align interference subspaces at the receivers, given channel knowledge of all
transmit-receive pairs, effectively reducing the number of discernible
interferers. The theory of IA was derived under assumptions about the richness
of scattering in the propagation channel; practical channels do not guarantee
such ideal characteristics. This paper presents the first experimental study of
IA in measured multiple-input multiple-output orthogonal frequency-division
multiplexing (MIMO-OFDM) interference channels. Our measurement campaign
includes a variety of indoor and outdoor measurement scenarios at The
University of Texas at Austin. We show that IA achieves the claimed scaling
factors, or degrees of freedom, in several measured channel settings for a 3
user, 2 antennas per node setup. In addition to verifying the claimed
performance, we characterize the effect of Kronecker spatial correlation on sum
rate and present two other correlation measures, which we show are more tightly
related to the achieved sum rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1851</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1851</id><created>2009-11-10</created><updated>2010-10-17</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Functional units for natural numbers</title><categories>cs.PL cs.LO</categories><comments>17 pages; notational mistakes in tables 5 and 6 corrected; erroneous
  definition at bottom of page 9 corrected</comments><report-no>PRG0913</report-no><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interaction with services provided by an execution environment forms part of
the behaviours exhibited by instruction sequences under execution. Mechanisms
related to the kind of interaction in question have been proposed in the
setting of thread algebra. Like thread, service is an abstract behavioural
concept. The concept of a functional unit is similar to the concept of a
service, but more concrete. A state space is inherent in the concept of a
functional unit, whereas it is not inherent in the concept of a service. In
this paper, we establish the existence of a universal computable functional
unit for natural numbers and related results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1862</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1862</id><created>2009-11-10</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames><affiliation>Reykjavik University</affiliation></author><author><keyname>Ingolfsdottir</keyname><forenames>Anna</forenames><affiliation>Reykjavik University</affiliation></author><author><keyname>Sack</keyname><forenames>Joshua</forenames><affiliation>Reykjavik University</affiliation></author></authors><title>Characteristic Formulae for Fixed-Point Semantics: A General Framework</title><categories>cs.LO</categories><journal-ref>EPTCS 8, 2009, pp. 1-15</journal-ref><doi>10.4204/EPTCS.8.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The literature on concurrency theory offers a wealth of examples of
characteristic-formula constructions for various behavioural relations over
finite labelled transition systems and Kripke structures that are defined in
terms of fixed points of suitable functions. Such constructions and their
proofs of correctness have been developed independently, but have a common
underlying structure. This study provides a general view of characteristic
formulae that are expressed in terms of logics with a facility for the
recursive definition of formulae. It is shown how several examples of
characteristic-formula constructions from the literature can be recovered as
instances of the proposed general framework, and how the framework can be used
to yield novel constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1891</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1891</id><created>2009-11-10</created><authors><author><keyname>Partala</keyname><forenames>Juha</forenames></author></authors><title>A note on conjugacy search and racks</title><categories>cs.CR</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for every effective left conjugacy closed left quasigroup, there
is an induced rack that retains the conjugation structure of the left
translations. This means that cryptographic protocols relying on conjugacy
search can be secure only if conjugacy search of left translations is
infeasible in the induced rack. We note that, in fact, protocols based on
conjugacy search could be simply implemented using a rack. We give an
exposition of the Anshel-Anshel-Goldfeld protocol in such a case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1900</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1900</id><created>2009-11-10</created><updated>2009-11-11</updated><authors><author><keyname>Raible</keyname><forenames>Daniel</forenames></author><author><keyname>Fernau</keyname><forenames>Henning</forenames></author></authors><title>A Faster Exact Algorithm for the Directed Maximum Leaf Spanning Tree
  Problem</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed graph $G=(V,A)$, the Directed Maximum Leaf Spanning Tree
problem asks to compute a directed spanning tree (i.e., an out-branching) with
as many leaves as possible. By designing a Branch-and-Reduced algorithm
combined with the Measure &amp; Conquer technique for running time analysis, we
show that the problem can be solved in time $\Oh^*(1.9043^n)$ using polynomial
space. Hitherto, there have been only few examples. Provided exponential space
this run time upper bound can be lowered to $\Oh^*(1.8139^n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1934</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1934</id><created>2009-11-10</created><authors><author><keyname>Gilardoni</keyname><forenames>Gustavo L.</forenames></author></authors><title>On a Gel'fand-Yaglom-Peres theorem for f-divergences</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>1+4 pages, no figures</comments><msc-class>94A17, 26D15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that the $f$-divergence between two probability measures $P$ and
$R$ equals the supremum of the same $f$-divergence computed over all finite
measurable partitions of the original space, thus generalizing results
previously proved by Gel'fand and Yaglom and by Peres for the Information
Divergence and more recently by Dukkipati, Bhatnagar and Murty for the Tsallis'
and Renyi's divergences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1965</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1965</id><created>2009-11-10</created><authors><author><keyname>Madnani</keyname><forenames>Nitin</forenames></author><author><keyname>Jing</keyname><forenames>Hongyan</forenames></author><author><keyname>Kambhatla</keyname><forenames>Nanda</forenames></author><author><keyname>Roukos</keyname><forenames>Salim</forenames></author></authors><title>Active Learning for Mention Detection: A Comparison of Sentence
  Selection Strategies</title><categories>cs.CL cs.AI</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and compare various sentence selection strategies for active
learning for the task of detecting mentions of entities. The best strategy
employs the sum of confidences of two statistical classifiers trained on
different views of the data. Our experimental results show that, compared to
the random selection strategy, this strategy reduces the amount of required
labeled training data by over 50% while achieving the same performance. The
effect is even more significant when only named mentions are considered: the
system achieves the same performance by using only 42% of the training data
required by the random selection strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.1972</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.1972</id><created>2009-11-10</created><authors><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Wilson</keyname><forenames>Joey</forenames></author></authors><title>People-Sensing Spatial Characteristics of RF Sensor Networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An &quot;RF sensor&quot; network can monitor RSS values on links in the network and
perform device-free localization, i.e., locating a person or object moving in
the area in which the network is deployed. This paper provides a statistical
model for the RSS variance as a function of the person's position w.r.t. the
transmitter (TX) and receiver (RX). We show that the ensemble mean of the RSS
variance has an approximately linear relationship with the expected total
affected power (ETAP). We then use analysis to derive approximate expressions
for the ETAP as a function of the person's position, for both scattering and
reflection. Counterintuitively, we show that reflection, not scattering, causes
the RSS variance contours to be shaped like Cassini ovals. Experimental tests
reported here and in past literature are shown to validate the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2022</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2022</id><created>2009-11-10</created><authors><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>Interference Channels With Arbitrarily Correlated Sources</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communicating arbitrarily correlated sources over interference channels is
considered in this paper. A sufficient condition is found for the lossless
transmission of a pair of correlated sources over a discrete memoryless
interference channel. With independent sources, the sufficient condition
reduces to the Han-Kobayashi achievable rate region for the interference
channel. For a special correlation structure (in the sense of Slepian-Wolf,
1973), the proposed region reduces to the known achievable region for
interference channels with common information. A simple example is given to
show that the separation approach, with Slepian-Wolf encoding followed by
optimal channel coding, is strictly suboptimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2023</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2023</id><created>2009-11-10</created><updated>2011-06-29</updated><authors><author><keyname>Mahajan</keyname><forenames>Aditya</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Opportunistic capacity and error exponent regions for compound channel
  with feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variable length communication over a compound channel with feedback is
considered. Traditionally, capacity of a compound channel without feedback is
defined as the maximum rate that is determined before the start of
communication such that communication is reliable. This traditional definition
is pessimistic. In the presence of feedback, an opportunistic definition is
given. Capacity is defined as the maximum rate that is determined at the end of
communication such that communication is reliable. Thus, the transmission rate
can adapt to the channel chosen by nature. Under this definition, feedback
communication over a compound channel is conceptually similar to multi-terminal
communication. Transmission rate is a vector rather than a scalar; channel
capacity is a region rather than a scalar; error exponent is a region rather
than a scalar. In this paper, variable length communication over a compound
channel with feedback is formulated, its opportunistic capacity region is
characterized, and lower bounds for its error exponent region are provided..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2033</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2033</id><created>2009-11-10</created><authors><author><keyname>Babiak</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>&#x158;eh&#xe1;k</keyname><forenames>Vojt&#x11b;ch</forenames></author><author><keyname>Strej&#x10d;ek</keyname><forenames>Jan</forenames></author></authors><title>Almost Linear B\&quot;uchi Automata</title><categories>cs.FL cs.GT</categories><journal-ref>EPTCS 8, 2009, pp. 16-25</journal-ref><doi>10.4204/EPTCS.8.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new fragment of Linear temporal logic (LTL) called LIO and a
new class of Buechi automata (BA) called Almost linear Buechi automata (ALBA).
We provide effective translations between LIO and ALBA showing that the two
formalisms are expressively equivalent. While standard translations of LTL into
BA use some intermediate formalisms, the presented translation of LIO into ALBA
is direct. As we expect applications of ALBA in model checking, we compare the
expressiveness of ALBA with other classes of Buechi automata studied in this
context and we indicate possible applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2034</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2034</id><created>2009-11-10</created><authors><author><keyname>Daylight</keyname><forenames>Edgar G.</forenames><affiliation>Institute of Logic, Language, and Computation, University of Amsterdam</affiliation></author><author><keyname>Shukla</keyname><forenames>Sandeep K.</forenames><affiliation>Department of Electrical and Computer Engineering, Virginia Tech</affiliation></author><author><keyname>Sergio</keyname><forenames>Davide</forenames><affiliation>Institute of Logic, Language, and Computation, University of Amsterdam</affiliation></author></authors><title>Expressing the Behavior of Three Very Different Concurrent Systems by
  Using Natural Extensions of Separation Logic</title><categories>cs.LO cs.SE</categories><journal-ref>EPTCS 8, 2009, pp. 26-40</journal-ref><doi>10.4204/EPTCS.8.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separation Logic is a non-classical logic used to verify pointer-intensive
code. In this paper, however, we show that Separation Logic, along with its
natural extensions, can also be used as a specification language for
concurrent-system design. To do so, we express the behavior of three very
different concurrent systems: a Subway, a Stopwatch, and a 2x2 Switch. The
Subway is originally implemented in LUSTRE, the Stopwatch in Esterel, and the
2x2 Switch in Bluespec.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2035</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2035</id><created>2009-11-10</created><authors><author><keyname>Gazda</keyname><forenames>Maciej</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author></authors><title>Modal Logic and the Approximation Induction Principle</title><categories>cs.LO</categories><journal-ref>EPTCS 8, 2009, pp. 41-50</journal-ref><doi>10.4204/EPTCS.8.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a compactness theorem in the context of Hennessy-Milner logic. It is
used to derive a sufficient condition on modal characterizations for the
Approximation Induction Principle to be sound modulo the corresponding process
equivalence. We show that this condition is necessary when the equivalence in
question is compositional with respect to the projection operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2036</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2036</id><created>2009-11-10</created><authors><author><keyname>Guttman</keyname><forenames>Joshua</forenames><affiliation>Worcester Polytechnic Institute</affiliation></author></authors><title>Security Theorems via Model Theory</title><categories>cs.CR cs.LO</categories><journal-ref>EPTCS 8, 2009, pp. 51-65</journal-ref><doi>10.4204/EPTCS.8.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model-theoretic approach can establish security theorems for cryptographic
protocols. Formulas expressing authentication and non-disclosure properties of
protocols have a special form. They are quantified implications for all xs .
(phi implies for some ys . psi). Models (interpretations) for these formulas
are *skeletons*, partially ordered structures consisting of a number of local
protocol behaviors. Realized skeletons contain enough local sessions to explain
all the behavior, when combined with some possible adversary behaviors. We show
two results. (1) If phi is the antecedent of a security goal, then there is a
skeleton A_phi such that, for every skeleton B, phi is satisfied in B iff there
is a homomorphism from A_phi to B. (2) A protocol enforces for all xs . (phi
implies for some ys . psi) iff every realized homomorphic image of A_phi
satisfies psi. Hence, to verify a security goal, one can use the Cryptographic
Protocol Shapes Analyzer CPSA (TACAS, 2007) to identify minimal realized
skeletons, or &quot;shapes,&quot; that are homomorphic images of A_phi. If psi holds in
each of these shapes, then the goal holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2053</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2053</id><created>2009-11-11</created><authors><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Interference Mitigation Through Limited Receiver Cooperation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. 69 pages, 14
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is a major issue limiting the performance in wireless networks.
Cooperation among receivers can help mitigate interference by forming
distributed MIMO systems. The rate at which receivers cooperate, however, is
limited in most scenarios. How much interference can one bit of receiver
cooperation mitigate? In this paper, we study the two-user Gaussian
interference channel with conferencing decoders to answer this question in a
simple setting. We identify two regions regarding the gain from receiver
cooperation: linear and saturation regions. In the linear region receiver
cooperation is efficient and provides a degrees-of-freedom gain, which is
either one cooperation bit buys one more bit or two cooperation bits buy one
more bit until saturation. In the saturation region receiver cooperation is
inefficient and provides a power gain, which is at most a constant regardless
of the rate at which receivers cooperate. The conclusion is drawn from the
characterization of capacity region to within two bits. The proposed strategy
consists of two parts: (1) the transmission scheme, where superposition
encoding with a simple power split is employed, and (2) the cooperative
protocol, where one receiver quantize-bin-and-forwards its received signal, and
the other after receiving the side information decode-bin-and-forwards its
received signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2075</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2075</id><created>2009-11-11</created><authors><author><keyname>Zhang</keyname><forenames>Guoqiang</forenames></author></authors><title>A scientific understanding of network designing</title><categories>cs.NI</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Internet becomes severely overburdened with exponentially growing
traffic demand, it becomes a general belief that a new generation data network
is in urgent need today. However, standing at this crossroad, we find that we
are in a situation that lacks a theory of network designing. This issue becomes
even more serious as the recent progress of network measurement and modeling
challenges the foundation of network research in the past decades.
  This paper tries to set up a scientific foundation for network designing by
formalizing it as a multi-objective optimization process and quantifying the
way different designing choices independently and collectively influence these
objectives. A cartesian coordinate system is introduced to map the effect of
each designing scheme to a coordinate. We investigated the achievable area of
the network designing space and proved some boundary conditions. It is shown
that different kind of networks display different shapes of achievable areas in
the cartesian coordinate and exhibit different abilities to achieve
cost-effective and scalable designing. In particular, we found that the
philosophy underlying current empirical network designing and engineering fails
to meet the cost-effective and evolvable requirements of network designing. We
demonstrated that the efficient routing combined with effective betweenness
based link bandwidth allocation scheme is a cost-effective and scalable design
for BA-like scale-free networks, whereas if other designing choices cannot be
determined beforehand, ER network is a markedly good candidate for
cost-effective and scalable design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2142</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2142</id><created>2009-11-11</created><updated>2010-04-20</updated><authors><author><keyname>Edelsbrunner</keyname><forenames>Herbert</forenames></author><author><keyname>Morozov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Patel</keyname><forenames>Amit</forenames></author></authors><title>Quantifying Transversality by Measuring the Robustness of Intersections</title><categories>cs.CG math.GM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By definition, transverse intersections are stable under infinitesimal
perturbations. Using persistent homology, we extend this notion to a measure.
Given a space of perturbations, we assign to each homology class of the
intersection its robustness, the magnitude of a perturbations in this space
necessary to kill it, and prove that robustness is stable. Among the
applications of this result is a stable notion of robustness for fixed points
of continuous mappings and a statement of stability for contours of smooth
mappings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2174</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2174</id><created>2009-11-11</created><updated>2009-12-23</updated><authors><author><keyname>Baier</keyname><forenames>H.</forenames></author><author><keyname>Boettiger</keyname><forenames>H.</forenames></author><author><keyname>Drochner</keyname><forenames>M.</forenames></author><author><keyname>Eicker</keyname><forenames>N.</forenames></author><author><keyname>Fischer</keyname><forenames>U.</forenames></author><author><keyname>Fodor</keyname><forenames>Z.</forenames></author><author><keyname>Frommer</keyname><forenames>A.</forenames></author><author><keyname>Gomez</keyname><forenames>C.</forenames></author><author><keyname>Goldrian</keyname><forenames>G.</forenames></author><author><keyname>Heybrock</keyname><forenames>S.</forenames></author><author><keyname>Hierl</keyname><forenames>D.</forenames></author><author><keyname>H&#xfc;sken</keyname><forenames>M.</forenames></author><author><keyname>Huth</keyname><forenames>T.</forenames></author><author><keyname>Krill</keyname><forenames>B.</forenames></author><author><keyname>Lauritsen</keyname><forenames>J.</forenames></author><author><keyname>Lippert</keyname><forenames>T.</forenames></author><author><keyname>Maurer</keyname><forenames>T.</forenames></author><author><keyname>Mendl</keyname><forenames>B.</forenames></author><author><keyname>Meyer</keyname><forenames>N.</forenames></author><author><keyname>Nobile</keyname><forenames>A.</forenames></author><author><keyname>Ouda</keyname><forenames>I.</forenames></author><author><keyname>Pivanti</keyname><forenames>M.</forenames></author><author><keyname>Pleiter</keyname><forenames>D.</forenames></author><author><keyname>Ries</keyname><forenames>M.</forenames></author><author><keyname>Sch&#xe4;fer</keyname><forenames>A.</forenames></author><author><keyname>Schick</keyname><forenames>H.</forenames></author><author><keyname>Schifano</keyname><forenames>F.</forenames></author><author><keyname>Simma</keyname><forenames>H.</forenames></author><author><keyname>Solbrig</keyname><forenames>S.</forenames></author><author><keyname>Streuer</keyname><forenames>T.</forenames></author><author><keyname>Sulanke</keyname><forenames>K. -H.</forenames></author><author><keyname>Tripiccione</keyname><forenames>R.</forenames></author><author><keyname>Vogt</keyname><forenames>J. -S.</forenames></author><author><keyname>Wettig</keyname><forenames>T.</forenames></author><author><keyname>Winter</keyname><forenames>F.</forenames></author></authors><title>QPACE -- a QCD parallel computer based on Cell processors</title><categories>hep-lat cs.AR</categories><comments>21 pages. Poster by T. Maurer and plenary talk by D. Pleiter
  presented at the &quot;XXVII International Symposium on Lattice Field Theory&quot;,
  July 26-31 2009, Peking University, Beijing, China. Information on recent
  Green500 ranking added and list of authors extended</comments><journal-ref>PoS LAT2009:001,2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  QPACE is a novel parallel computer which has been developed to be primarily
used for lattice QCD simulations. The compute power is provided by the IBM
PowerXCell 8i processor, an enhanced version of the Cell processor that is used
in the Playstation 3. The QPACE nodes are interconnected by a custom,
application optimized 3-dimensional torus network implemented on an FPGA. To
achieve the very high packaging density of 26 TFlops per rack a new water
cooling concept has been developed and successfully realized. In this paper we
give an overview of the architecture and highlight some important technical
details of the system. Furthermore, we provide initial performance results and
report on the installation of 8 QPACE racks providing an aggregate peak
performance of 200 TFlops.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2193</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2193</id><created>2009-11-11</created><authors><author><keyname>Wilde</keyname><forenames>Erik</forenames></author></authors><title>Feeds as Query Result Serializations</title><categories>cs.NI</categories><report-no>UCB ISchool Report 2009-030</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many Web-based data sources and services are available as feeds, a model that
provides consumers with a loosely coupled way of interacting with providers.
The current feed model is limited in its capabilities, however. Though it is
simple to implement and scales well, it cannot be transferred to a wider range
of application scenarios. This paper conceptualizes feeds as a way to serialize
query results, describes the current hardcoded query semantics of such a
perspective, and surveys the ways in which extensions of this hardcoded model
have been proposed or implemented. Our generalized view of feeds as query
result serializations has implications for the applicability of feeds as a
generic Web service for any collection that is providing access to individual
information items. As one interesting and compelling class of applications, we
describe a simple way in which a query-based approach to feeds can be used to
support location-based services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2197</identifier>
 <datestamp>2009-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2197</id><created>2009-11-11</created><authors><author><keyname>Mana</keyname><forenames>P. G. L. Porta</forenames></author></authors><title>On the relation between plausibility logic and the maximum-entropy
  principle: a numerical study</title><categories>math.PR cs.IT math.IT physics.data-an</categories><comments>24 pages of main text and references, 8 pages of tables, 7 pages of
  additional references</comments><report-no>pi-other-154</report-no><msc-class>03B48; 60G09; 60A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the relationship between plausibility logic and the principle of
maximum entropy? When does the principle give unreasonable or wrong results?
When is it appropriate to use the rule `expectation = average'? Can
plausibility logic give the same answers as the principle, and better answers
if those of the principle are unreasonable? To try to answer these questions,
this study offers a numerical collection of plausibility distributions given by
the maximum-entropy principle and by plausibility logic for a set of fifteen
simple problems: throwing dice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2214</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2214</id><created>2009-11-11</created><updated>2010-07-08</updated><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schudy</keyname><forenames>Warren</forenames></author></authors><title>Approximation Schemes for the Betweenness Problem in Tournaments and
  Related Ranking Problems</title><categories>cs.DS cs.DM</categories><comments>15 pages. Minor changes to presentation from version 2</comments><acm-class>F.2.2; G.2.1; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design the first polynomial time approximation schemes (PTASs) for the
Minimum Betweenness problem in tournaments and some related higher arity
ranking problems. This settles the approximation status of the Betweenness
problem in tournaments along with other ranking problems which were open for
some time now. The results depend on a new technique of dealing with fragile
ranking constraints and could be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2233</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2233</id><created>2009-11-11</created><authors><author><keyname>Chiniforooshan</keyname><forenames>Ehsan</forenames></author><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Xu</keyname><forenames>Zhi</forenames></author></authors><title>Pseudo-Power Avoidance</title><categories>cs.FL cs.DS</categories><acm-class>F.4.3; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Repetition avoidance has been studied since Thue's work. In this paper, we
considered another type of repetition, which is called pseudo-power. This
concept is inspired by Watson-Crick complementarity in DNA sequence and is
defined over an antimorphic involution $\phi$. We first classify the alphabet
$\Sigma$ and the antimorphic involution $\phi$, under which there exists
sufficiently long pseudo-$k$th-power-free words. Then we present algorithms to
test whether a finite word $w$ is pseudo-$k$th-power-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2258</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2258</id><created>2009-11-11</created><updated>2011-06-08</updated><authors><author><keyname>Ohsawa</keyname><forenames>Tomoki</forenames></author><author><keyname>Bloch</keyname><forenames>Anthony M.</forenames></author><author><keyname>Leok</keyname><forenames>Melvin</forenames></author></authors><title>Discrete Hamilton-Jacobi Theory</title><categories>math.OC cs.SY</categories><comments>26 pages, 2 figures</comments><msc-class>70H20, 49L20, 93C55, 49J15, 70H05, 70H25</msc-class><journal-ref>SIAM J. Control Optim. 49 (2011), pp. 1829-1856</journal-ref><doi>10.1137/090776822</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a discrete analogue of Hamilton-Jacobi theory in the framework of
discrete Hamiltonian mechanics. The resulting discrete Hamilton-Jacobi equation
is discrete only in time. We describe a discrete analogue of Jacobi's solution
and also prove a discrete version of the geometric Hamilton-Jacobi theorem. The
theory applied to discrete linear Hamiltonian systems yields the discrete
Riccati equation as a special case of the discrete Hamilton-Jacobi equation. We
also apply the theory to discrete optimal control problems, and recover some
well-known results, such as the Bellman equation (discrete-time HJB equation)
of dynamic programming and its relation to the costate variable in the
Pontryagin maximum principle. This relationship between the discrete
Hamilton-Jacobi equation and Bellman equation is exploited to derive a
generalized form of the Bellman equation that has controls at internal stages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2270</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2270</id><created>2009-11-11</created><updated>2009-11-13</updated><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Jafarpour</keyname><forenames>B.</forenames></author></authors><title>An Iteratively Reweighted Algorithm for Sparse Reconstruction of
  Subsurface Flow Properties from Nonlinear Dynamic Data</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a practical algorithm based on sparsity
regularization to effectively solve nonlinear dynamic inverse problems that are
encountered in subsurface model calibration. We use an iteratively reweighted
algorithm that is widely used to solve linear inverse problems with sparsity
constraint known as compressed sensing to estimate permeability fields from
nonlinear dynamic flow data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2280</identifier>
 <datestamp>2014-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2280</id><created>2009-11-12</created><updated>2012-01-18</updated><authors><author><keyname>Cs&#xe1;ji</keyname><forenames>Bal&#xe1;zs Csan&#xe1;d</forenames></author><author><keyname>Jungers</keyname><forenames>Rapha&#xeb;l M.</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>PageRank Optimization by Edge Selection</title><categories>cs.DS cs.CC cs.SI</categories><comments>30 pages, 3 figures</comments><acm-class>F.2.2; G.3</acm-class><journal-ref>Discrete Applied Mathematics, Volume 169, 2014, Pages 73-87</journal-ref><doi>10.1016/j.dam.2014.01.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of a node in a directed graph can be measured by its PageRank.
The PageRank of a node is used in a number of application contexts - including
ranking websites - and can be interpreted as the average portion of time spent
at the node by an infinite random walk. We consider the problem of maximizing
the PageRank of a node by selecting some of the edges from a set of edges that
are under our control. By applying results from Markov decision theory, we show
that an optimal solution to this problem can be found in polynomial time. Our
core solution results in a linear programming formulation, but we also provide
an alternative greedy algorithm, a variant of policy iteration, which runs in
polynomial time, as well. Finally, we show that, under the slight modification
for which we are given mutually exclusive pairs of edges, the problem of
PageRank optimization becomes NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2284</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2284</id><created>2009-11-11</created><updated>2009-11-18</updated><authors><author><keyname>Guerrero</keyname><forenames>Fabio G.</forenames></author></authors><title>A New Look at the Classical Entropy of Written English</title><categories>cs.CL</categories><comments>Submitted to the IEEE Transactions on Information Theory. Reference
  on page 5 corrected. Weighted average of HL on page 12 corrected (average
  redundancy R has therefore been updated). Abstract slightly changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple method for finding the entropy and redundancy of a reasonable long
sample of English text by direct computer processing and from first principles
according to Shannon theory is presented. As an example, results on the entropy
of the English language have been obtained based on a total of 20.3 million
characters of written English, considering symbols from one to five hundred
characters in length. Besides a more realistic value of the entropy of English,
a new perspective on some classic entropy-related concepts is presented. This
method can also be extended to other Latin languages. Some implications for
practical applications such as plagiarism-detection software, and the minimum
number of words that should be used in social Internet network messaging, are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2293</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2293</id><created>2009-11-11</created><authors><author><keyname>Bloem</keyname><forenames>Michael</forenames></author><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>A Robust Control Framework for Malware Filtering</title><categories>cs.CR</categories><comments>8 pages, 10 figures, IEEE format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study and develop a robust control framework for malware filtering and
network security. We investigate the malware filtering problem by capturing the
tradeoff between increased security on one hand and continued usability of the
network on the other. We analyze the problem using a linear control system
model with a quadratic cost structure and develop algorithms based on H
infinity-optimal control theory. A dynamic feedback filter is derived and shown
via numerical analysis to be an improvement over various heuristic approaches
to malware filtering. The results are verified and demonstrated with packet
level simulations on the Ns-2 network simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2317</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2317</id><created>2009-11-12</created><authors><author><keyname>Ablayev</keyname><forenames>Farid</forenames></author><author><keyname>Vasiliev</keyname><forenames>Alexander</forenames></author></authors><title>Algorithms for Quantum Branching Programs Based on Fingerprinting</title><categories>cs.CC cs.DM</categories><journal-ref>EPTCS 9, 2009, pp. 1-11</journal-ref><doi>10.4204/EPTCS.9.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper we develop a method for constructing quantum algorithms for
computing Boolean functions by quantum ordered read-once branching programs
(quantum OBDDs). Our method is based on fingerprinting technique and
representation of Boolean functions by their characteristic polynomials. We use
circuit notation for branching programs for desired algorithms presentation.
For several known functions our approach provides optimal QOBDDs. Namely we
consider such functions as Equality, Palindrome, and Permutation Matrix Test.
We also propose a generalization of our method and apply it to the Boolean
variant of the Hidden Subgroup Problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2319</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2319</id><created>2009-11-12</created><authors><author><keyname>Bernardinello</keyname><forenames>Luca</forenames></author><author><keyname>Pomello</keyname><forenames>Lucia</forenames></author><author><keyname>Rombol&#xe0;</keyname><forenames>Stefania</forenames></author></authors><title>Orthomodular Lattices Induced by the Concurrency Relation</title><categories>cs.LO</categories><journal-ref>EPTCS 9, 2009, pp. 12-21</journal-ref><doi>10.4204/EPTCS.9.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply to locally finite partially ordered sets a construction which
associates a complete lattice to a given poset; the elements of the lattice are
the closed subsets of a closure operator, defined starting from the concurrency
relation. We show that, if the partially ordered set satisfies a property of
local density, i.e.: N-density, then the associated lattice is also
orthomodular. We then consider occurrence nets, introduced by C.A. Petri as
models of concurrent computations, and define a family of subsets of the
elements of an occurrence net; we call those subsets &quot;causally closed&quot; because
they can be seen as subprocesses of the whole net which are, intuitively,
closed with respect to the forward and backward local state changes. We show
that, when the net is K-dense, the causally closed sets coincide with the
closed sets induced by the closure operator defined starting from the
concurrency relation. K-density is a property of partially ordered sets
introduced by Petri, on the basis of former axiomatizations of special
relativity theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2320</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2320</id><created>2009-11-12</created><authors><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>De Felice</keyname><forenames>Clelia</forenames></author><author><keyname>Zizza</keyname><forenames>Rosalba</forenames></author></authors><title>Circular Languages Generated by Complete Splicing Systems and Pure
  Unitary Languages</title><categories>cs.FL</categories><journal-ref>EPTCS 9, 2009, pp. 22-31</journal-ref><doi>10.4204/EPTCS.9.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circular splicing systems are a formal model of a generative mechanism of
circular words, inspired by a recombinant behaviour of circular DNA. Some
unanswered questions are related to the computational power of such systems,
and finding a characterization of the class of circular languages generated by
circular splicing systems is still an open problem. In this paper we solve this
problem for complete systems, which are special finite circular splicing
systems. We show that a circular language L is generated by a complete system
if and only if the set Lin(L) of all words corresponding to L is a pure unitary
language generated by a set closed under the conjugacy relation. The class of
pure unitary languages was introduced by A. Ehrenfeucht, D. Haussler, G.
Rozenberg in 1983, as a subclass of the class of context-free languages,
together with a characterization of regular pure unitary languages by means of
a decidable property. As a direct consequence, we characterize (regular)
circular languages generated by complete systems. We can also decide whether
the language generated by a complete system is regular. Finally, we point out
that complete systems have the same computational power as finite simple
systems, an easy type of circular splicing system defined in the literature
from the very beginning, when only one rule is allowed. From our results on
complete systems, it follows that finite simple systems generate a class of
context-free languages containing non-regular languages, showing the
incorrectness of a longstanding result on simple systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2322</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2322</id><created>2009-11-12</created><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author></authors><title>Random Constraint Satisfaction Problems</title><categories>cs.DM cs.CC cs.DS</categories><journal-ref>EPTCS 9, 2009, pp. 32-37</journal-ref><doi>10.4204/EPTCS.9.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random instances of constraint satisfaction problems such as k-SAT provide
challenging benchmarks. If there are m constraints over n variables there is
typically a large range of densities r=m/n where solutions are known to exist
with probability close to one due to non-constructive arguments. However, no
algorithms are known to find solutions efficiently with a non-vanishing
probability at even much lower densities. This fact appears to be related to a
phase transition in the set of all solutions. The goal of this extended
abstract is to provide a perspective on this phenomenon, and on the
computational challenge that it poses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2323</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2323</id><created>2009-11-12</created><authors><author><keyname>Dezani-Ciancaglini</keyname><forenames>Mariangiola</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Giannini</keyname><forenames>Paola</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; del Piemonte Orientale</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author></authors><title>A Type System for Required/Excluded Elements in CLS</title><categories>cs.LO cs.CE</categories><acm-class>F.3.3; J.3; F.1.2</acm-class><journal-ref>EPTCS 9, 2009, pp. 38-48</journal-ref><doi>10.4204/EPTCS.9.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The calculus of looping sequences is a formalism for describing the evolution
of biological systems by means of term rewriting rules. We enrich this calculus
with a type discipline to guarantee the soundness of reduction rules with
respect to some biological properties deriving from the requirement of certain
elements, and the repellency of others. As an example, we model a toy system
where the repellency of a certain element is captured by our type system and
forbids another element to exit a compartment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2324</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2324</id><created>2009-11-12</created><authors><author><keyname>F&#xfc;rer</keyname><forenames>Martin</forenames></author></authors><title>Deterministic Autopoietic Automata</title><categories>cs.NE cs.FL</categories><journal-ref>EPTCS 9, 2009, pp. 49-53</journal-ref><doi>10.4204/EPTCS.9.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies two issues related to the paper on Computing by
Self-reproduction: Autopoietic Automata by Jiri Wiedermann. It is shown that
all results presented there extend to deterministic computations. In
particular, nondeterminism is not needed for a lineage to generate all
autopoietic automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2325</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2325</id><created>2009-11-12</created><authors><author><keyname>Gomaa</keyname><forenames>Walid</forenames><affiliation>Alexandria University</affiliation></author></authors><title>Characterizing Polynomial Time Computability of Rational and Real
  Functions</title><categories>cs.CC</categories><acm-class>F.1.3; F.1.1</acm-class><journal-ref>EPTCS 9, 2009, pp. 54-64</journal-ref><doi>10.4204/EPTCS.9.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recursive analysis was introduced by A. Turing [1936], A. Grzegorczyk [1955],
and D. Lacombe [1955]. It is based on a discrete mechanical framework that can
be used to model computation over the real numbers. In this context the
computational complexity of real functions defined over compact domains has
been extensively studied. However, much less have been done for other kinds of
real functions. This article is divided into two main parts. The first part
investigates polynomial time computability of rational functions and the role
of continuity in such computation. On the one hand this is interesting for its
own sake. On the other hand it provides insights into polynomial time
computability of real functions for the latter, in the sense of recursive
analysis, is modeled as approximations of rational computations. The main
conclusion of this part is that continuity does not play any role in the
efficiency of computing rational functions. The second part defines polynomial
time computability of arbitrary real functions, characterizes it, and compares
it with the corresponding notion over rational functions. Assuming continuity,
the main conclusion is that there is a conceptual difference between polynomial
time computation over the rationals and the reals manifested by the fact that
there are polynomial time computable rational functions whose extensions to the
reals are not polynomial time computable and vice versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2327</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2327</id><created>2009-11-12</created><authors><author><keyname>Kahramano&#x11f;ullari</keyname><forenames>Ozan</forenames></author><author><keyname>Cardelli</keyname><forenames>Luca</forenames></author><author><keyname>Caron</keyname><forenames>Emmanuelle</forenames></author></authors><title>An Intuitive Automated Modelling Interface for Systems Biology</title><categories>cs.PL cs.CE cs.LO q-bio.QM</categories><journal-ref>EPTCS 9, 2009, pp. 73-86</journal-ref><doi>10.4204/EPTCS.9.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a natural language interface for building stochastic pi calculus
models of biological systems. In this language, complex constructs describing
biochemical events are built from basic primitives of association, dissociation
and transformation. This language thus allows us to model biochemical systems
modularly by describing their dynamics in a narrative-style language, while
making amendments, refinements and extensions on the models easy. We
demonstrate the language on a model of Fc-gamma receptor phosphorylation during
phagocytosis. We provide a tool implementation of the translation into a
stochastic pi calculus language, Microsoft Research's SPiM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2330</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2330</id><created>2009-11-12</created><authors><author><keyname>Konkoli</keyname><forenames>Zoran</forenames></author></authors><title>Diffusion Controlled Reactions, Fluctuation Dominated Kinetics, and
  Living Cell Biochemistry</title><categories>cs.CE cs.OH q-bio.QM</categories><journal-ref>EPTCS 9, 2009, pp. 98-107</journal-ref><doi>10.4204/EPTCS.9.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years considerable portion of the computer science community has
focused its attention on understanding living cell biochemistry and efforts to
understand such complication reaction environment have spread over wide front,
ranging from systems biology approaches, through network analysis (motif
identification) towards developing language and simulators for low level
biochemical processes. Apart from simulation work, much of the efforts are
directed to using mean field equations (equivalent to the equations of
classical chemical kinetics) to address various problems (stability,
robustness, sensitivity analysis, etc.). Rarely is the use of mean field
equations questioned. This review will provide a brief overview of the
situations when mean field equations fail and should not be used. These
equations can be derived from the theory of diffusion controlled reactions, and
emerge when assumption of perfect mixing is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2346</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2346</id><created>2009-11-12</created><authors><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Tian</keyname><forenames>Chao</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas N.</forenames></author></authors><title>Asymmetric Multilevel Diversity Coding and Asymmetric Gaussian Multiple
  Descriptions</title><categories>cs.IT math.IT</categories><comments>42 pages, 9 figures, submitted to IEEE transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the asymmetric multilevel diversity (A-MLD) coding problem, where
a set of $2^K-1$ information sources, ordered in a decreasing level of
importance, is encoded into $K$ messages (or descriptions). There are $2^K-1$
decoders, each of which has access to a non-empty subset of the encoded
messages. Each decoder is required to reproduce the information sources up to a
certain importance level depending on the combination of descriptions available
to it. We obtain a single letter characterization of the achievable rate region
for the 3-description problem. In contrast to symmetric multilevel diversity
coding, source-separation coding is not sufficient in the asymmetric case, and
ideas akin to network coding need to be used strategically. Based on the
intuitions gained in treating the A-MLD problem, we derive inner and outer
bounds for the rate region of the asymmetric Gaussian multiple description (MD)
problem with three descriptions. Both the inner and outer bounds have a similar
geometric structure to the rate region template of the A-MLD coding problem,
and moreover, we show that the gap between them is small, which results in an
approximate characterization of the asymmetric Gaussian three description rate
region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2364</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2364</id><created>2009-11-12</created><authors><author><keyname>Dolfsma</keyname><forenames>Wilfred</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Journals as constituents of scientific discourse: economic heterodoxy</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Wilfred Dolfsma &amp; Loet Leydesdorff, Journals as Constituents of
  Scientific Discourse: Economic Heterodoxy, On the Horizon 16(4), 214-225,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: to provide a view and analysis of the immediate field of journals
which surround a number of key heterodox economics journals.
Design/methodology/approach: Using citation data from the Science and Social
Science Citation Index, the individual and collective networks of a number of
journals in this field are analyzed. Findings: The size and shape of the
citation networks of journals can differ substantially, even if in a broadly
similar category. Heterodox economics cannot (yet) be considered as an
integrated specialty: authors in several journals in heterodox economics cite
more from mainstream economics than from other heterodox journals. There are
also strong links with other disciplinary fields such as geography, development
studies, women studies, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2381</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2381</id><created>2009-11-12</created><authors><author><keyname>Mart&#xed;n</keyname><forenames>Ferm&#xed;n Moscoso del Prado</forenames></author></authors><title>Analytical Determination of Fractal Structure in Stochastic Time Series</title><categories>physics.data-an cond-mat.stat-mech cs.LG nlin.CD stat.ME</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current methods for determining whether a time series exhibits fractal
structure (FS) rely on subjective assessments on estimators of the Hurst
exponent (H). Here, I introduce the Bayesian Assessment of Scaling, an
analytical framework for drawing objective and accurate inferences on the FS of
time series. The technique exploits the scaling property of the diffusion
associated to a time series. The resulting criterion is simple to compute and
represents an accurate characterization of the evidence supporting different
hypotheses on the scaling regime of a time series. Additionally, a closed-form
Maximum Likelihood estimator of H is derived from the criterion, and this
estimator outperforms the best available estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2390</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2390</id><created>2009-11-12</created><authors><author><keyname>Leijnen</keyname><forenames>Stefan</forenames></author><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>How Creative Should Creators Be To Optimize the Evolution of Ideas? A
  Computational Model</title><categories>cs.AI cs.NE physics.soc-ph</categories><journal-ref>EPTCS 9, 2009, pp. 108-119</journal-ref><doi>10.4204/EPTCS.9.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are both benefits and drawbacks to creativity. In a social group it is
not necessary for all members to be creative to benefit from creativity; some
merely imitate or enjoy the fruits of others' creative efforts. What proportion
should be creative? This paper contains a very preliminary investigation of
this question carried out using a computer model of cultural evolution referred
to as EVOC (for EVOlution of Culture). EVOC is composed of neural network based
agents that evolve fitter ideas for actions by (1) inventing new ideas through
modification of existing ones, and (2) imitating neighbors' ideas. The ideal
proportion with respect to fitness of ideas occurs when thirty to forty percent
of the individuals is creative. When creators are inventing 50% of iterations
or less, mean fitness of actions in the society is a positive function of the
ratio of creators to imitators; otherwise mean fitness of actions starts to
drop when the ratio of creators to imitators exceeds approximately 30%. For all
levels or creativity, the diversity of ideas in a population is positively
correlated with the ratio of creative agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2405</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2405</id><created>2009-11-12</created><authors><author><keyname>Mahboub</keyname><forenames>Karim</forenames></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Evelyne</forenames></author><author><keyname>Bertelle</keyname><forenames>Cyrille</forenames></author><author><keyname>Jay</keyname><forenames>V&#xe9;ronique</forenames></author></authors><title>Emotion: Appraisal-coping model for the &quot;Cascades&quot; problem</title><categories>cs.AI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modelling emotion has become a challenge nowadays. Therefore, several models
have been produced in order to express human emotional activity. However, only
a few of them are currently able to express the close relationship existing
between emotion and cognition. An appraisal-coping model is presented here,
with the aim to simulate the emotional impact caused by the evaluation of a
particular situation (appraisal), along with the consequent cognitive reaction
intended to face the situation (coping). This model is applied to the
&quot;Cascades&quot; problem, a small arithmetical exercise designed for ten-year-old
pupils. The goal is to create a model corresponding to a child's behaviour when
solving the problem using his own strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2423</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2423</id><created>2009-11-12</created><authors><author><keyname>Purkeypile</keyname><forenames>Matt</forenames></author></authors><title>Cove: A Practical Quantum Computer Programming Framework</title><categories>cs.PL quant-ph</categories><comments>Doctoral dissertation, 272 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While not yet in commercial existence, quantum computers have the ability to
solve certain classes of problems that are not efficiently solvable on existing
Turing Machine based (classical) computers. For quantum computers to be of use,
methods of programming them must exist. Proposals exist for programming quantum
computers, but all of the existing ones suffer from flaws that make them
impractical in commercial software development environments. Cove is a
framework for programming quantum computers that extends existing classical
languages to allow for quantum computation, thus providing a quantum computing
toolkit for commercial software developers. Since the target users of Cove are
commercial developers, it is an object oriented framework that can be used by
multiple languages and also places emphasis on complete documentation. The
focus of Cove is not so much on the software product, but on the fundamental
concepts that make quantum computing practical for common developers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2466</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2466</id><created>2009-11-12</created><authors><author><keyname>Kandregula</keyname><forenames>Renuka</forenames></author></authors><title>Towards a Number Theoretic Discrete Hilbert Transform</title><categories>cs.DM</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach for the development of a number theoretic
discrete Hilbert transform. The forward transformation has been applied by
taking the odd reciprocals that occur in the DHT matrix with respect to a power
of 2. Specifically, the expression for a 16-point transform is provided and
results of a few representative signals are provided. The inverse transform is
the inverse of the forward 16-point matrix. But at this time the inverse
transform is not identical to the forward transform and, therefore, our
proposed number theoretic transform must be taken as a provisional result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2484</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2484</id><created>2009-11-12</created><authors><author><keyname>Chen</keyname><forenames>Dan</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Memoryless Routing in Convex Subdivisions: Random Walks are Optimal</title><categories>cs.CG</categories><comments>11 pages, 6 figures</comments><journal-ref>Computational Geometry: Theory and Applications, Volume 45, Issue
  4, May 2012, Pages 178-185</journal-ref><doi>10.1016/j.comgeo.2011.12.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A memoryless routing algorithm is one in which the decision about the next
edge on the route to a vertex t for a packet currently located at vertex v is
made based only on the coordinates of v, t, and the neighbourhood, N(v), of v.
The current paper explores the limitations of such algorithms by showing that,
for any (randomized) memoryless routing algorithm A, there exists a convex
subdivision on which A takes Omega(n^2) expected time to route a message
between some pair of vertices. Since this lower bound is matched by a random
walk, this result implies that the geometric information available in convex
subdivisions is not helpful for this class of routing algorithms. The current
paper also shows the existence of triangulations for which the Random-Compass
algorithm proposed by Bose etal (2002,2004) requires 2^{\Omega(n)} time to
route between some pair of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2501</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2501</id><created>2009-11-12</created><authors><author><keyname>Mahboub</keyname><forenames>Karim</forenames><affiliation>LITIS</affiliation></author><author><keyname>Bertelle</keyname><forenames>Cyrille</forenames><affiliation>LITIS</affiliation></author><author><keyname>Jay</keyname><forenames>V&#xe9;ronique</forenames><affiliation>LITIS</affiliation></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Evelyne</forenames></author></authors><title>Emotion : mod\`ele d'appraisal-coping pour le probl\`eme des Cascades</title><categories>cs.AI</categories><proxy>ccsd hal-00431517</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling emotion has become a challenge nowadays. Therefore, several models
have been produced in order to express human emotional activity. However, only
a few of them are currently able to express the close relationship existing
between emotion and cognition. An appraisal-coping model is presented here,
with the aim to simulate the emotional impact caused by the evaluation of a
particular situation (appraisal), along with the consequent cognitive reaction
intended to face the situation (coping). This model is applied to the
?Cascades? problem, a small arithmetical exercise designed for ten-year-old
pupils. The goal is to create a model corresponding to a child's behavior when
solving the problem using his own strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2508</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2508</id><created>2009-11-12</created><authors><author><keyname>Harmer</keyname><forenames>Russ</forenames><affiliation>CNRS &amp; Universit&#xe9; Paris Diderot-Paris 7</affiliation></author></authors><title>Rule-based Modelling and Tunable Resolution</title><categories>cs.OH</categories><journal-ref>EPTCS 9, 2009, pp. 65-72</journal-ref><doi>10.4204/EPTCS.9.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the use of an extension of rule-based modelling for cellular
signalling to create a structured space of model variants. This enables the
incremental development of rule sets that start from simple mechanisms and
which, by a gradual increase in agent and rule resolution, evolve into more
detailed descriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2538</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2538</id><created>2009-11-13</created><authors><author><keyname>Jonckheere</keyname><forenames>Edmond</forenames><affiliation>USC</affiliation></author><author><keyname>Lou</keyname><forenames>Mingji</forenames><affiliation>USC</affiliation></author><author><keyname>Bonahon</keyname><forenames>Francis</forenames><affiliation>USC</affiliation></author><author><keyname>Baryshnikov</keyname><forenames>Yuliy</forenames><affiliation>Bell Labs</affiliation></author></authors><title>Euclidean versus hyperbolic congestion in idealized versus experimental
  networks</title><categories>cs.NI</categories><comments>23 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a mathematical justification of the phenomenon of extreme
congestion at a very limited number of nodes in very large networks. It is
argued that this phenomenon occurs as a combination of the negative curvature
property of the network together with minimum length routing. More
specifically, it is shown that, in a large n-dimensional hyperbolic ball B of
radius R viewed as a roughly similar model of a Gromov hyperbolic network, the
proportion of traffic paths transiting through a small ball near the center is
independent of the radius R whereas, in a Euclidean ball, the same proportion
scales as 1/R^{n-1}. This discrepancy persists for the traffic load, which at
the center of the hyperbolic ball scales as the square of the volume, whereas
the same traffic load scales as the volume to the power (n+1)/n in the
Euclidean ball. This provides a theoretical justification of the experimental
exponent discrepancy observed by Narayan and Saniee between traffic loads in
Gromov-hyperbolic networks from the Rocketfuel data base and synthetic
Euclidean lattice networks. It is further conjectured that for networks that do
not enjoy the obvious symmetry of hyperbolic and Euclidean balls, the point of
maximum traffic is near the center of mass of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2551</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2551</id><created>2009-11-13</created><updated>2010-05-31</updated><authors><author><keyname>Unnikrishnan</keyname><forenames>Jayakrishnan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author></authors><title>Minimax Robust Quickest Change Detection</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Submitted to IEEE Transactions on Information Theory, Nov. 2009.
  Revised May 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The popular criteria of optimality for quickest change detection procedures
are the Lorden criterion, the Shiryaev-Roberts-Pollak criterion, and the
Bayesian criterion. In this paper a robust version of these quickest change
detection problems is considered when the pre-change and post-change
distributions are not known exactly but belong to known uncertainty classes of
distributions. For uncertainty classes that satisfy a specific condition, it is
shown that one can identify least favorable distributions (LFDs) from the
uncertainty classes, such that the detection rule designed for the LFDs is
optimal for the robust problem in a minimax sense. The condition is similar to
that required for the identification of LFDs for the robust hypothesis testing
problem originally studied by Huber. An upper bound on the delay incurred by
the robust test is also obtained in the asymptotic setting under the Lorden
criterion of optimality. This bound quantifies the delay penalty incurred to
guarantee robustness. When the LFDs can be identified, the proposed test is
easier to implement than the CUSUM test based on the Generalized Likelihood
Ratio (GLR) statistic which is a popular approach for such robust change
detection problems. The proposed test is also shown to give better performance
than the GLR test in simulations for some parameter values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2564</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2564</id><created>2009-11-13</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Distributed Coalition Formation Games for Secure Wireless Transmission</title><categories>cs.IT math.IT</categories><comments>Invited paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation among wireless nodes has been recently proposed for improving the
physical layer (PHY) security of wireless transmission in the presence of
multiple eavesdroppers. While existing PHY security literature answered the
question ``what are the link-level secrecy rate gains from cooperation?'', this
paper attempts to answer the question of ``how to achieve those gains in a
practical decentralized wireless network and in the presence of a cost for
information exchange?''. For this purpose, we model the PHY security
cooperation problem as a coalitional game with non-transferable utility and
propose a distributed algorithm for coalition formation. Through the proposed
algorithm, the wireless users can cooperate and self-organize into disjoint
independent coalitions, while maximizing their secrecy rate taking into account
the security costs during information exchange. We analyze the resulting
coalitional structures for both decode-and-forward and amplify-and-forward
cooperation and study how the users can adapt the network topology to
environmental changes such as mobility. Through simulations, we assess the
performance of the proposed algorithm and show that, by coalition formation
using decode-and-forward, the average secrecy rate per user is increased of up
to 25.3 % and 24.4 % (for a network with 45 users) relative to the
non-cooperative and amplify-and-forward cases, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2567</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2567</id><created>2009-11-13</created><updated>2010-12-21</updated><authors><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Guinez</keyname><forenames>Flavio</forenames></author><author><keyname>Lozano</keyname><forenames>Antoni</forenames></author><author><keyname>Thang</keyname><forenames>Nguyen Kim</forenames></author></authors><title>Tile Packing Tomography is NP-hard</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete tomography deals with reconstructing finite spatial objects from
lower dimensional projections and has applications for example in timetable
design. In this paper we consider the problem of reconstructing a tile packing
from its row and column projections. It consists of disjoint copies of a fixed
tile, all contained in some rectangular grid. The projections tell how many
cells are covered by a tile in each row and column. How difficult is it to
construct a tile packing satisfying given projections? It was known to be
solvable by a greedy algorithm for bars (tiles of width or height 1), and
NP-hardness results were known for some specific tiles. This paper shows that
the problem is NP-hard whenever the tile is not a bar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2603</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2603</id><created>2009-11-13</created><authors><author><keyname>Stern</keyname><forenames>Daniel</forenames></author></authors><title>Cybermatter</title><categories>cs.CY cs.HC</categories><comments>Seventh International Computer Ethics Conference (CEPE 2007)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we examine several aspects of the impact of Cyberworld onto our
Reality conceptions, and their social implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2619</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2619</id><created>2009-11-13</created><authors><author><keyname>Sukhov</keyname><forenames>A. M.</forenames></author><author><keyname>Sidelnikov</keyname><forenames>D. I.</forenames></author><author><keyname>Galtsev</keyname><forenames>A.</forenames></author><author><keyname>Platonov</keyname><forenames>A. P.</forenames></author><author><keyname>Strizhov</keyname><forenames>M. V.</forenames></author></authors><title>Active Flows in Diagnostic of Troubleshooting on Backbone Links</title><categories>cs.NI</categories><comments>7 pages, 6 figures, RELARN2009 conference (in Russian)</comments><report-no>RIPN121109</report-no><acm-class>C.2.3; C.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper aims to identify the operational region of a link in terms of its
utilization and alert operators at the point where the link becomes overloaded
and requires a capacity upgrade. The number of active flows is considered the
real network state and is proposed to use a proxy for utilization. The Gaussian
approximation gives the expression for the confidence interval on an
operational region. The easy rule has been formulated to display the network
defects by means of measurements of router loading and number of active flows.
Mean flow performance is considered as the basic universal index characterized
quality of network services provided to single user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2620</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2620</id><created>2009-11-13</created><authors><author><keyname>Saquib</keyname><forenames>Nazmus</forenames></author><author><keyname>Sakib</keyname><forenames>Md. Sabbir Rahman</forenames></author><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author></authors><title>Performance Analysis of MANET Routing Protocols Using An Elegant Visual
  Simulation Tool</title><categories>cs.SE cs.NI</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of simulation is often complicated for which many naive users often
seek for relatively easier solutions. In many cases, simulations are done
without any visual output which makes them non-attractive. In this paper, we
present ViSim; a new simulation tool that has a user-friendly graphical
interface. ViSim could be useful for researchers, students, teachers in their
works, and for the demonstration of various wireless network scenarios on
computer screen. It could make the task of simulation more exciting and enhance
the interest of the users without going into complex command-only text
interface. ViSim is not a simulation engine rather it calls ns-2 simulations in
the background and makes the task easy for the users to visualize the
simulation in Windows environment. Though ViSim is mainly a simulation
demonstration tool, any user with the knowledge of ns-2 and Tcl scripting is
also allowed to do necessary modifications and quick configurations for any
other MANET routing scenario. Using our simulation tool, we measured the
performances of several Mobile Ad-hoc Network (MANET) routing protocols. In
this paper, we present the performance analysis of three prominent MANET
routing protocols; DSDV, DSR, and AODV using our tool. The details of various
features of ViSim, brief descriptions of the selected routing protocols and
their comparisons, details about the performed experiments, and the gained
results are presented in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2632</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2632</id><created>2009-11-13</created><authors><author><keyname>Moed</keyname><forenames>Henk F.</forenames></author></authors><title>Measuring contextual citation impact of scientific journals</title><categories>cs.DL cs.IR</categories><comments>Version 13 November 2009; 23 pages; 1 appendix; 7 tables; 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores a new indicator of journal citation impact, denoted as
source normalized impact per paper (SNIP). It measures a journal's contextual
citation impact, taking into account characteristics of its properly defined
subject field, especially the frequency at which authors cite other papers in
their reference lists, the rapidity of maturing of citation impact, and the
extent to which a database used for the assessment covers the field's
literature. It further develops Eugene Garfield's notions of a field's
'citation potential' defined as the average length of references lists in a
field and determining the probability of being cited, and the need in fair
performance assessments to correct for differences between subject fields. A
journal's subject field is defined as the set of papers citing that journal.
SNIP is defined as the ratio of the journal's citation count per paper and the
citation potential in its subject field. It aims to allow direct comparison of
sources in different subject fields. Citation potential is shown to vary not
only between journal subject categories - groupings of journals sharing a
research field - or disciplines (e.g., journals in mathematics, engineering and
social sciences tend to have lower values than titles in life sciences), but
also between journals within the same subject category. For instance, basic
journals tend to show higher citation potentials than applied or clinical
journals, and journals covering emerging topics higher than periodicals in
classical subjects or more general journals. SNIP corrects for such
differences. Its strengths and limitations are critically discussed, and
suggestions are made for further research. All empirical results are derived
from Elsevier's Scopus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2731</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2731</id><created>2009-11-13</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Visualization of the Citation Impact Environments of Scientific
  Journals: An online mapping exercise</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Visualization of the Citation Impact Environments of Scientific
  Journals: An online mapping exercise, Journal of the American Society for
  Information Science and Technology 58(1), 25-38, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aggregated journal-journal citation networks based on the Journal Citation
Reports 2004 of the Science Citation Index (5968 journals) and the Social
Science Citation Index (1712 journals) are made accessible from the perspective
of any of these journals. The user is thus able to analyze the citation
environment in terms of links and graphs. Furthermore, the local impact of a
journal is defined as its share of the total citations in the specific
journal's citation environments; the vertical size of the nodes is varied
proportionally to this citation impact. The horizontal size of each node can be
used to provide the same information after correction for within-journal
(self)-citations. In the &quot;citing&quot; environment, the equivalents of this measure
can be considered as a citation activity index which maps how the relevant
journal environment is perceived by the collective of authors of a given
journal. As a policy application, the mechanism of interdisciplinary
developments among the sciences is elaborated for the case of nanotechnology
journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2746</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2746</id><created>2009-11-15</created><updated>2010-04-29</updated><authors><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author></authors><title>Model Selection: Two Fundamental Measures of Coherence and Their
  Algorithmic Significance</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>5 pages; Accepted for Proc. 2010 IEEE International Symposium on
  Information Theory (ISIT 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of model selection arises in a number of contexts, such as
compressed sensing, subset selection in linear regression, estimation of
structures in graphical models, and signal denoising. This paper generalizes
the notion of \emph{incoherence} in the existing literature on model selection
and introduces two fundamental measures of coherence---termed as the worst-case
coherence and the average coherence---among the columns of a design matrix. In
particular, it utilizes these two measures of coherence to provide an in-depth
analysis of a simple one-step thresholding (OST) algorithm for model selection.
One of the key insights offered by the ensuing analysis is that OST is feasible
for model selection as long as the design matrix obeys an easily verifiable
property. In addition, the paper also characterizes the model-selection
performance of OST in terms of the worst-case coherence, \mu, and establishes
that OST performs near-optimally in the low signal-to-noise ratio regime for N
x C design matrices with \mu = O(N^{-1/2}). Finally, in contrast to some of the
existing literature on model selection, the analysis in the paper is
nonasymptotic in nature, it does not require knowledge of the true model order,
it is applicable to generic (random or deterministic) design matrices, and it
neither requires submatrices of the design matrix to have full rank, nor does
it assume a statistical prior on the values of the nonzero entries of the data
vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2760</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2760</id><created>2009-11-15</created><authors><author><keyname>Iltgen</keyname><forenames>Katrin</forenames></author><author><keyname>Vogler</keyname><forenames>Walter</forenames></author></authors><title>Robustness of a bisimulation-type faster-than preorder</title><categories>cs.LO</categories><comments>Express Workshop</comments><journal-ref>EPTCS 8, 2009, pp. 66-79</journal-ref><doi>10.4204/EPTCS.8.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TACS is an extension of CCS where upper time bounds for delays can be
specified. Luettgen and Vogler defined three variants of bismulation-type
faster-than relations and showed that they all three lead to the same preorder,
demonstrating the robustness of their approach. In the present paper, the
operational semantics of TACS is extended; it is shown that two of the variants
still give the same preorder as before, underlining robustness. An explanation
is given why this result fails for the third variant. It is also shown that
another variant, which mixes old and new operational semantics, can lead to
smaller relations that prove the same preorder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0911.2784</identifier>
 <datestamp>2011-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0911.2784</id><created>2009-11-14</created><updated>2011-10-05</updated><authors><author><keyname>Stummer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Vajda</keyname><forenames>Igor</forenames></author></authors><title>On Bregman Distances and Divergences of Probability Measures</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>12 two-column pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces scaled Bregman distances of probability distributions
which admit non-uniform contributions of observed events. They are introduced
in a general form covering not only the distances of discrete and continuous
stochastic observations, but also the distances of random processes and
signals. It is shown that the scaled Bregman distances extend not only the
classical ones studied in the previous literature, but also the information
divergence and the related wider class of convex divergences of probability
measures. An information processing theorem is established too, but only in the
sense of invariance w.r.t. statistically sufficient transformations and not in
the sense of universal monotonicity. Pathological situations where coding can
increase the classical Bregman distance are illustrated by a concrete example.
In addition to the classical areas of application of the Bregman distances and
convex divergences such as recognition, classification, learning and evaluation
of proximity of various features and signals, the paper mentions a new
application in 3D-exploratory data analysis. Explicit expressions for the
scaled Bregman distances are obtained in general exponential families, with
concrete applications in the binomial, Poisson and Rayleigh families, and in
the families of exponential processes such as the Poisson and diffusion
processes including the classical examples of the Wiener process and geometric
Brownian motion.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="9000" completeListSize="102538">1122234|10001</resumptionToken>
</ListRecords>
</OAI-PMH>
