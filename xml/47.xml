<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T01:13:15Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|46001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5050</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5050</id><created>2013-05-22</created><updated>2013-07-16</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Simon</keyname><forenames>Sunil</forenames></author></authors><title>Social Network Games with Obligatory Product Selection</title><categories>cs.GT</categories><comments>In Proceedings GandALF 2013, arXiv:1307.4162</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 119, 2013, pp. 180-193</journal-ref><doi>10.4204/EPTCS.119.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Apt and Markakis introduced a model for product adoption in social
networks with multiple products, where the agents, influenced by their
neighbours, can adopt one out of several alternatives (products). To analyze
these networks we introduce social network games in which product adoption is
obligatory.
  We show that when the underlying graph is a simple cycle, there is a
polynomial time algorithm allowing us to determine whether the game has a Nash
equilibrium. In contrast, in the arbitrary case this problem is NP-complete. We
also show that the problem of determining whether the game is weakly acyclic is
co-NP hard.
  Using these games we analyze various types of paradoxes that can arise in the
considered networks. One of them corresponds to the well-known Braess paradox
in congestion games. In particular, we show that social networks exist with the
property that by adding an additional product to a specific node, the choices
of the nodes will unavoidably evolve in such a way that everybody is strictly
worse off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5053</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5053</id><created>2013-05-22</created><updated>2015-02-15</updated><authors><author><keyname>Dey</keyname><forenames>Palash</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author></authors><title>Asymptotic Collusion-Proofness of Voting Rules: The Case of Large Number
  of Candidates</title><categories>cs.GT</categories><comments>Accepted as an extended abstract in AAMAS 2014</comments><acm-class>I.2.11; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical results in voting theory show that strategic manipulation by voters
is inevitable if a voting rule simultaneously satisfy certain desirable
properties. Motivated by this, we study the relevant question of how often a
voting rule is manipulable. It is well known that elections with a large number
of voters are rarely manipulable under impartial culture (IC) assumption.
However, the manipulability of voting rules when the number of candidates is
large has hardly been addressed in the literature and our paper focuses on this
problem. First, we propose two properties (1) asymptotic strategy-proofness and
(2) asymptotic collusion-proofness, with respect to new voters, which makes the
two notions more relevant from the perspective of computational problem of
manipulation. In addition to IC, we explore a new culture of society where all
score vectors of the candidates are equally likely. This new notion has its
motivation in computational social choice and we call it impartial scores
culture (ISC) assumption. We study asymptotic strategy-proofness and asymptotic
collusion-proofness for plurality, veto, $k$-approval, and Borda voting rules
under IC as well as ISC assumptions. Specifically, we prove bounds for the
fraction of manipulable profiles when the number of candidates is large. Our
results show that the size of the coalition and the tie-breaking rule play a
crucial role in determining whether or not a voting rule satisfies the above
two properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5055</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5055</id><created>2013-05-22</created><updated>2015-03-28</updated><authors><author><keyname>Wimmer</keyname><forenames>Ralf</forenames><affiliation>University of Freiburg, Germany</affiliation></author><author><keyname>Jansen</keyname><forenames>Nils</forenames><affiliation>RWTH Aachen University, Germany</affiliation></author><author><keyname>&#xc3;?brah&#xc3;?m</keyname><forenames>Erika</forenames><affiliation>RWTH Aachen University, Germany</affiliation></author><author><keyname>Katoen</keyname><forenames>Joost-Pieter</forenames><affiliation>RWTH Aachen University, Germany</affiliation></author></authors><title>High-level Counterexamples for Probabilistic Automata</title><categories>cs.SE cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 11, Issue 1 (March 31,
  2015) lmcs:945</journal-ref><doi>10.2168/LMCS-11(1:15)2015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing compact and understandable counterexamples for violated system
properties is an essential task in model checking. Existing works on
counterexamples for probabilistic systems so far computed either a large set of
system runs or a subset of the system's states, both of which are of limited
use in manual debugging. Many probabilistic systems are described in a guarded
command language like the one used by the popular model checker PRISM. In this
paper we describe how a smallest possible subset of the commands can be
identified which together make the system erroneous. We additionally show how
the selected commands can be further simplified to obtain a well-understandable
counterexample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5078</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5078</id><created>2013-05-22</created><authors><author><keyname>Wieczorkowska</keyname><forenames>Alicja A.</forenames></author><author><keyname>Kursa</keyname><forenames>Miron B.</forenames></author></authors><title>A Comparison of Random Forests and Ferns on Recognition of Instruments
  in Jazz Recordings</title><categories>cs.LG cs.IR cs.SD</categories><journal-ref>Foundations of Intelligent Systems, Lecture Notes in Computer
  Science Volume 7661, 2012, pp 208-217</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first apply random ferns for classification of real music
recordings of a jazz band. No initial segmentation of audio data is assumed,
i.e., no onset, offset, nor pitch data are needed. The notion of random ferns
is described in the paper, to familiarize the reader with this classification
algorithm, which was introduced quite recently and applied so far in image
recognition tasks. The performance of random ferns is compared with random
forests for the same data. The results of experiments are presented in the
paper, and conclusions are drawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5082</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5082</id><created>2013-05-22</created><authors><author><keyname>Fang</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Lin</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Tong</keyname><forenames>Kin-Fai</forenames></author></authors><title>Performance of Joint Channel and Physical Network Coding Based on
  Alamouti STBC</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, accpeted</comments><journal-ref>2013 IEEE ICUWB</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the protograph-coded physical network coding (PNC) based
on Alamouti space-time block coding (STBC) over Nakagami-fading two-way relay
channels, in which both the two sources and relay possess two antennas. We
first propose a novel precoding scheme at the two sources so as to implement
the iterative decoder efficiently at the relay. We further address a simplified
updating rule of the log-likelihood-ratio (LLR) in such a decoder. Based on the
simplified LLR-updating rule and Gaussian approximation, we analyze the
theoretical bit-error-rate (BER) of the system, which is shown to be consistent
with the decoding thresholds and simulated results. Moreover, the theoretical
analysis has lower computational complexity than the protograph extrinsic
information transfer (PEXIT) algorithm. Consequently, the analysis not only
provides a simple way to evaluate the error performance but also facilitates
the design of the joint channel-and-PNC (JCNC) in wireless communication
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5120</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5120</id><created>2013-05-21</created><authors><author><keyname>Berljafa</keyname><forenames>Mario</forenames><affiliation>Department of Mathematics, University of Zagreb</affiliation></author><author><keyname>Di Napoli</keyname><forenames>Edoardo</forenames><affiliation>Juelich Supercomputing Centre, Forschungszentrum Juelich</affiliation><affiliation>AICES, RWTH Aachen</affiliation></author></authors><title>A Parallel and Scalable Iterative Solver for Sequences of Dense
  Eigenproblems Arising in FLAPW</title><categories>cs.DC cs.MS physics.comp-ph</categories><comments>Submitted to 10th International Conference on Parallel Processing and
  Applied Mathematics(PPAM 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In one of the most important methods in Density Functional Theory - the
Full-Potential Linearized Augmented Plane Wave (FLAPW) method - dense
generalized eigenproblems are organized in long sequences. Moreover each
eigenproblem is strongly correlated to the next one in the sequence. We propose
a novel approach which exploits such correlation through the use of an
eigensolver based on subspace iteration and accelerated with Chebyshev
polynomials. The resulting solver, parallelized using the Elemental library
framework, achieves excellent scalability and is competitive with current dense
parallel eigensolvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5132</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5132</id><created>2013-05-22</created><authors><author><keyname>Sakaguchi</keyname><forenames>Kei</forenames></author><author><keyname>Nguyen</keyname><forenames>Van Ky</forenames></author><author><keyname>Tao</keyname><forenames>Yu</forenames></author><author><keyname>Tran</keyname><forenames>Gia Khanh</forenames></author><author><keyname>Araki</keyname><forenames>Kiyomichi</forenames></author></authors><title>Distributed Power Control Network and Green Building Test-bed for Demand
  Response in Smart Grid</title><categories>cs.SY</categories><comments>PAPER Special Section on Networked Control Systems: Theories
  Applications, Vol E96-A, No.5, May 2013</comments><doi>10.1587/transfun.E96.A.896</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that demand and supply power balancing is an essential method to
operate power delivery system and prevent blackouts caused by power shortage.
In this paper, we focus on the implementation of demand response strategy to
save power during peak hours by using Smart Grid. It is obviously impractical
with centralized power control network to realize the real-time control
performance, where a single central controller measures the huge metering data
and sends control command back to all customers. For that purpose, we propose a
new architecture of hierarchical distributed power control network which is
scalable regardless of the network size. The sub-controllers are introduced to
partition the large system into smaller distributed clusters where low-latency
local feedback power control loops are conducted to guarantee control
stability. Furthermore, sub-controllers are stacked up in an hierarchical
manner such that data are fed back layer-by-layer in the inbound while in the
outbound control responses are decentralized in each local sub-controller for
realizing the global objectives. Numerical simulations in a realistic scenario
of up to 5000 consumers show the effectiveness of the proposed scheme to
achieve a desired 10% peak power saving by using off-the-shelf wireless devices
with IEEE802.15.4g standard. In addition, a small scale power control system
for green building test-bed is implemented to demonstrate the potential use of
the proposed scheme for power saving in real life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5136</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5136</id><created>2013-05-22</created><updated>2013-12-27</updated><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>Group detection in complex networks: An algorithm and comparison of the
  state of the art</title><categories>cs.SI physics.data-an physics.soc-ph</categories><comments>15 pages, 6 figures, 6 tables</comments><journal-ref>Physica A 397, 144-156 (2014)</journal-ref><doi>10.1016/j.physa.2013.12.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex real-world networks commonly reveal characteristic groups of nodes
like communities and modules. These are of value in various applications,
especially in the case of large social and information networks. However, while
numerous community detection techniques have been presented in the literature,
approaches for other groups of nodes are relatively rare and often limited in
some way. We present a simple propagation-based algorithm for general group
detection that requires no a priori knowledge and has near ideal complexity.
The main novelty here is that different types of groups are revealed through an
adequate hierarchical group refinement procedure. The proposed algorithm is
validated on various synthetic and real-world networks, and rigorously compared
against twelve other state-of-the-art approaches on group detection, hierarchy
discovery and link prediction tasks. The algorithm is comparable to the state
of the art in community detection, while superior in general group detection
and link prediction. Based on the comparison, we also dis- cuss some prominent
directions for future work on group detection in complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5160</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5160</id><created>2013-05-22</created><authors><author><keyname>Xiao</keyname><forenames>Bo</forenames></author><author><keyname>Jing</keyname><forenames>Yuefeng</forenames></author><author><keyname>Guan</keyname><forenames>Yonghong</forenames></author></authors><title>A novel automatic thresholding segmentation method with local adaptive
  thresholds</title><categories>cs.CV</categories><comments>3 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel method for segmenting bright objects from dark background for
grayscale image is proposed. The concept of this method can be stated simply
as: to pick out the local-thinnest bands on the grayscale grade-map. It turns
out to be a threshold-based method with local adaptive thresholds, where each
local threshold is determined by requiring the average normal-direction
gradient on the object boundary to be local minimal. The method is highly
automatic and the segmentation mimics a man's natural expectation even the
object boundaries are fuzzy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5170</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5170</id><created>2013-05-22</created><authors><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author></authors><title>A Truth Serum for Sharing Rewards</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a problem where a group of agents has to decide how a joint reward
should be shared among them. We focus on settings where the share that each
agent receives depends on the subjective opinions of its peers concerning that
agent's contribution to the group. To this end, we introduce a mechanism to
elicit and aggregate subjective opinions as well as for determining agents'
shares. The intuition behind the proposed mechanism is that each agent who
believes that the others are telling the truth has its expected share maximized
to the extent that it is well-evaluated by its peers and that it is truthfully
reporting its opinions. Under the assumptions that agents are Bayesian
decision-makers and that the underlying population is sufficiently large, we
show that our mechanism is incentive-compatible, budget-balanced, and
tractable. We also present strategies to make this mechanism individually
rational and fair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5176</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5176</id><created>2013-05-22</created><authors><author><keyname>Berg</keyname><forenames>Nathan</forenames></author><author><keyname>Chen</keyname><forenames>Chunyu</forenames></author><author><keyname>Kantarcioglu</keyname><forenames>Murat</forenames></author></authors><title>Experiments in Information Sharing</title><categories>cs.GT cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports experimental data describing the dynamics of three key
information-sharing outcomes: quantity of information shared, falsification and
accuracy. The experimental design follows a formal model predicting that
cooperative incentives are needed to motivate subsidiaries of large
organizations to share information. Empirical reaction functions reveal how
lagged values of information-sharing outcomes influence information sharing in
the current round. Cooperative treatments pay bonuses to everyone if at least
one individual (or subsidiary) achieves accuracy. Tournament treatments pay a
single bonus to whoever achieves accuracy first. As expected, tournament
incentives tend to reduce sharing, increase falsification and impair accuracy.
Several surprises not predicted by the formal model emerge from the data.
Conditional cooperation occurs regardless of the incentive scheme, implying
that the mechanism through which incentives influence improvements in
information sharing is indirect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5179</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5179</id><created>2013-05-22</created><authors><author><keyname>Cuomo</keyname><forenames>Salvatore</forenames></author><author><keyname>Gallettiy</keyname><forenames>Ardelio</forenames></author><author><keyname>Giuntay</keyname><forenames>Giulio</forenames></author><author><keyname>Staracey</keyname><forenames>Alfredo</forenames></author></authors><title>Surface Reconstruction from Scattered Point via RBF Interpolation on GPU</title><categories>cs.DC cs.NA math.NA</categories><comments>arXiv admin note: text overlap with arXiv:0909.5413 by other authors</comments><msc-class>65Y05, 68W10, 65D18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a parallel implicit method based on radial basis
functions (RBF) for surface reconstruction. The applicability of RBF methods is
hindered by its computational demand, that requires the solution of linear
systems of size equal to the number of data points. Our reconstruction
implementation relies on parallel scientific libraries and is supported for
massively multi-core architectures, namely Graphic Processor Units (GPUs). The
performance of the proposed method in terms of accuracy of the reconstruction
and computing time shows that the RBF interpolant can be very effective for
such problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5189</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5189</id><created>2013-05-22</created><authors><author><keyname>Caplar</keyname><forenames>Neven</forenames></author><author><keyname>Suznjevic</keyname><forenames>Mirko</forenames></author><author><keyname>Matijasevic</keyname><forenames>Maja</forenames></author></authors><title>Analysis of player's in-game performance vs rating: Case study of Heroes
  of Newerth</title><categories>physics.soc-ph cs.SI physics.data-an physics.pop-ph</categories><comments>8 pages, 14 figures, to appear in proceedings of &quot;Foundation of
  Digital Games 2013&quot; conference (14-17 May 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We evaluate the rating system of &quot;Heroes of Newerth&quot; (HoN), a multiplayer
online action role-playing game, by using statistical analysis and comparison
of a player's in-game performance metrics and the player rating assigned by the
rating system. The datasets for the analysis have been extracted from the web
sites that record the players' ratings and a number of empirical metrics.
Results suggest that the HoN's Matchmaking rating algorithm, while generally
capturing the skill level of the player well, also has weaknesses, which have
been exploited by players to achieve a higher placement on the ranking ladder
than deserved by actual skill. In addition, we also illustrate the effects of
the choice of the business model (from pay-to-play to free-to-play) on player
population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5209</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5209</id><created>2013-05-22</created><authors><author><keyname>De Carufel</keyname><forenames>Jean-Lou</forenames></author><author><keyname>Grimm</keyname><forenames>Carsten</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Owen</keyname><forenames>Megan</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>A Note on the Unsolvability of the Weighted Region Shortest Path Problem</title><categories>cs.CG</categories><comments>6 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let S be a subdivision of the plane into polygonal regions, where each region
has an associated positive weight. The weighted region shortest path problem is
to determine a shortest path in S between two points s, t in R^2, where the
distances are measured according to the weighted Euclidean metric-the length of
a path is defined to be the weighted sum of (Euclidean) lengths of the
sub-paths within each region. We show that this problem cannot be solved in the
Algebraic Computation Model over the Rational Numbers (ACMQ). In the ACMQ, one
can compute exactly any number that can be obtained from the rationals Q by
applying a finite number of operations from +, -, \times, \div, \sqrt[k]{}, for
any integer k &gt;= 2. Our proof uses Galois theory and is based on Bajaj's
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5216</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5216</id><created>2013-05-22</created><updated>2014-04-24</updated><authors><author><keyname>Ji</keyname><forenames>Mingyue</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Wireless Device-to-Device Caching Networks: Basic Principles and System
  Performance</title><categories>cs.IT cs.MM cs.NI math.IT</categories><comments>35 pages; 13 figures; Revised version of the manuscript submitted to
  IEEE Journal on Selected Areas in Communications, Special Issue on Device to
  Device Communications in Cellular Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As wireless video transmission is the fastest-growing form of data traffic,
methods for spectrally efficient video on-demand wireless streaming are
essential to service providers and users alike. A key property of video
on-demand is the asynchronous content reuse, such that a few dominant videos
account for a large part of the traffic, but are viewed by users at different
times. Caching of content on devices in conjunction with D2D communications
allows to exploit this property, and provide a network throughput that is
significantly in excess of both the conventional approach of unicasting from
the base station and the traditional D2D networks for regular data traffic.
This paper presents in a semi-tutorial concise form some recent results on the
throughput scaling laws of wireless networks with caching and asynchronous
content reuse, contrasting the D2D approach with a competing approach based on
combinatorial cache design and network coded transmission from the base station
(BS) only, referred to as coded multicasting. Interestingly, the spatial reuse
gain of the former and the coded multicasting gain of the latter yield, somehow
surprisingly, the same near-optimal throughput behavior in the relevant regime
where the number of video files in the library is smaller than the number of
streaming users. Based on our recent theoretical results, we propose a holistic
D2D system design that incorporates traditional microwave (2 GHz) as well as
millimeter-wave D2D links; the direct connections to the base station can be
used to provide those rare video requests that cannot be found in local caches.
We provide extensive simulations under a variety of system settings, and
compare our scheme with other existing schemes by the BS. We show that, despite
the similar behavior of the scaling laws, the proposed D2D approach offers very
significant throughput gains with respect to the BS-only schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5222</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5222</id><created>2013-05-22</created><authors><author><keyname>Rodriguez</keyname><forenames>Oscar Filio</forenames></author><author><keyname>Primak</keyname><forenames>Serguei</forenames></author><author><keyname>Kontorovich</keyname><forenames>Valeri</forenames></author><author><keyname>Shami</keyname><forenames>Abdallah</forenames></author></authors><title>A Game Theory Interpretation for Multiple Access in Cognitive Radio
  Networks with Random Number of Secondary Users</title><categories>cs.GT cs.IT math.IT</categories><comments>12 pages, 11 figures. Submitted for possible publication in IEEE
  Journal in Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new multiple access algorithm for cognitive radio networks
based on game theory is presented. We address the problem of a multiple access
system where the number of users and their types are unknown. In order to do
this, the framework is modelled as a non-cooperative Poisson game in which all
the players are unaware of the total number of devices participating
(population uncertainty). We propose a scheme where failed attempts to transmit
(collisions) are penalized. In terms of this, we calculate the optimum
penalization in mixed strategies. The proposed scheme conveys to a Nash
equilibrium where a maximum in the possible throughput is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5228</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5228</id><created>2013-05-22</created><updated>2013-06-13</updated><authors><author><keyname>Abdulla</keyname><forenames>Parosh Aziz</forenames></author><author><keyname>Clemente</keyname><forenames>Lorenzo</forenames></author><author><keyname>Mayr</keyname><forenames>Richard</forenames></author><author><keyname>Sandberg</keyname><forenames>Sven</forenames></author></authors><title>Stochastic Parity Games on Lossy Channel Systems</title><categories>cs.GT cs.LO</categories><comments>19 pages</comments><report-no>EDI-INF-RR-1416</report-no><msc-class>68Q60</msc-class><acm-class>D.2.4; G.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We give an algorithm for solving stochastic parity games with almost-sure
winning conditions on lossy channel systems, for the case where the players are
restricted to finite-memory strategies. First, we describe a general framework,
where we consider the class of 2.5-player games with almost-sure parity winning
conditions on possibly infinite game graphs, assuming that the game contains a
finite attractor. An attractor is a set of states (not necessarily absorbing)
that is almost surely re-visited regardless of the players' decisions. We
present a scheme that characterizes the set of winning states for each player.
Then, we instantiate this scheme to obtain an algorithm for stochastic game
lossy channel systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5233</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5233</id><created>2013-05-22</created><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Imrich</keyname><forenames>Wilfried</forenames></author><author><keyname>Mathew</keyname><forenames>Rogers</forenames></author><author><keyname>Rajendraprasad</keyname><forenames>Deepak</forenames></author></authors><title>Boxicity and Cubicity of Product Graphs</title><categories>math.CO cs.DM</categories><comments>14 pages</comments><msc-class>05C62, 05C76</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 'boxicity' ('cubicity') of a graph G is the minimum natural number k such
that G can be represented as an intersection graph of axis-parallel rectangular
boxes (axis-parallel unit cubes) in $R^k$. In this article, we give estimates
on the boxicity and the cubicity of Cartesian, strong and direct products of
graphs in terms of invariants of the component graphs. In particular, we study
the growth, as a function of $d$, of the boxicity and the cubicity of the
$d$-th power of a graph with respect to the three products. Among others, we
show a surprising result that the boxicity and the cubicity of the $d$-th
Cartesian power of any given finite graph is in $O(\log d / \log\log d)$ and
$\theta(d / \log d)$, respectively. On the other hand, we show that there
cannot exist any sublinear bound on the growth of the boxicity of powers of a
general graph with respect to strong and direct products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5235</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5235</id><created>2013-05-22</created><authors><author><keyname>Doerr</keyname><forenames>Christian</forenames></author><author><keyname>Blenn</keyname><forenames>Norbert</forenames></author><author><keyname>Van Mieghem</keyname><forenames>Piet</forenames></author></authors><title>Lognormal Infection Times of Online Information Spread</title><categories>physics.soc-ph cs.SI</categories><journal-ref>PLoS ONE 8(5): e64349, 2013</journal-ref><doi>10.1371/journal.pone.0064349</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The infection times of individuals in online information spread such as the
inter-arrival time of Twitter messages or the propagation time of news stories
on a social media site can be explained through a convolution of lognormally
distributed observation and reaction times of the individual participants.
Experimental measurements support the lognormal shape of the individual
contributing processes, and have resemblance to previously reported lognormal
distributions of human behavior and contagious processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5236</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5236</id><created>2013-05-22</created><updated>2013-08-27</updated><authors><author><keyname>Wolinsky</keyname><forenames>David Isaac</forenames></author><author><keyname>Syta</keyname><forenames>Ewa</forenames></author><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>Hang With Your Buddies to Resist Intersection Attacks</title><categories>cs.CR</categories><comments>15 pages, 8 figures</comments><acm-class>C.2.0</acm-class><journal-ref>ACM CCS'13, Nov 04-08 2013, Berlin, Germany</journal-ref><doi>10.1145/2508859.2516740</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some anonymity schemes might in principle protect users from pervasive
network surveillance - but only if all messages are independent and unlinkable.
Users in practice often need pseudonymity - sending messages intentionally
linkable to each other but not to the sender - but pseudonymity in dynamic
networks exposes users to intersection attacks. We present Buddies, the first
systematic design for intersection attack resistance in practical anonymity
systems. Buddies groups users dynamically into buddy sets, controlling message
transmission to make buddies within a set behaviorally indistinguishable under
traffic analysis. To manage the inevitable tradeoffs between anonymity
guarantees and communication responsiveness, Buddies enables users to select
independent attack mitigation policies for each pseudonym. Using trace-based
simulations and a working prototype, we find that Buddies can guarantee
non-trivial anonymity set sizes in realistic chat/microblogging scenarios, for
both short-lived and long-lived pseudonyms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5239</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5239</id><created>2013-05-22</created><updated>2013-06-27</updated><authors><author><keyname>Abbes</keyname><forenames>Samy</forenames><affiliation>Universit&#xe9; Paris Diderot/PPS CNRS UMR 7123</affiliation></author></authors><title>Markov two-components processes</title><categories>cs.SY</categories><comments>34 pages</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 2 (June 28,
  2013) lmcs:1088</journal-ref><doi>10.2168/LMCS-9(2:14)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Markov two-components processes (M2CP) as a probabilistic model of
asynchronous systems based on the trace semantics for concurrency. Considering
an asynchronous system distributed over two sites, we introduce concepts and
tools to manipulate random trajectories in an asynchronous framework: stopping
times, an Asynchronous Strong Markov property, recurrent and transient states
and irreducible components of asynchronous probabilistic processes. The
asynchrony assumption implies that there is no global totally ordered clock
ruling the system. Instead, time appears as partially ordered and random. We
construct and characterize M2CP through a finite family of transition matrices.
M2CP have a local independence property that guarantees that local components
are independent in the probabilistic sense, conditionally to their
synchronization constraints. A synchronization product of two Markov chains is
introduced, as a natural example of M2CP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5240</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5240</id><created>2013-05-22</created><authors><author><keyname>Kent</keyname><forenames>Robert E.</forenames></author></authors><title>FOLE: The First-order Logical Environment</title><categories>cs.LO math.CT</categories><comments>Conceptual Structures for STEM Research and Education, 20th
  International Conference on Conceptual Structures, ICCS 2013, Mumbai, India,
  January 10-12, 2013. Proceedings. Can be found online at:
  http://link.springer.com/chapter/10.1007%2F978-3-642-35786-2_15</comments><msc-class>03B10 (Primary) 03C07, 68P15, 68Q55 (Secondary)</msc-class><acm-class>F.4.1; H.2.4; H.2.5</acm-class><journal-ref>Lecture Notes in Computer Science, Volume 7735, 2013, pp 210-230.
  Springer Berlin Heidelberg</journal-ref><doi>10.1007/978-3-642-35786-2_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the first-order logical environment FOLE. Institutions
in general, and logical environments in particular, give equivalent
heterogeneous and homogeneous representations for logical systems. As such,
they offer a rigorous and principled approach to distributed interoperable
information systems via system consequence. Since FOLE is a particular logical
environment, this provides a rigorous and principled approach to distributed
interoperable first-order information systems. The FOLE represents the
formalism and semantics of first-order logic in a classification form. By using
an interpretation form, a companion approach defines the formalism and
semantics of first-order logical/relational database systems. In a strict
sense, the two forms have transformational passages (generalized inverses)
between one another. The classification form of first-order logic in the FOLE
corresponds to ideas discussed in the Information Flow Framework (IFF). The
FOLE representation follows a conceptual structures approach, that is
completely compatible with formal concept analysis and information flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5266</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5266</id><created>2013-05-22</created><updated>2014-07-28</updated><authors><author><keyname>Daechert</keyname><forenames>Kerstin</forenames></author><author><keyname>Klamroth</keyname><forenames>Kathrin</forenames></author></authors><title>A linear bound on the number of scalarizations needed to solve discrete
  tricriteria optimization problems</title><categories>math.OC cs.DS</categories><comments>32 pages, 8 figures, Journal of Global Optimization, 2014</comments><doi>10.1007/s10898-014-0205-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General multi-objective optimization problems are often solved by a sequence
of parametric single objective problems, so-called scalarizations. If the set
of nondominated points is finite, and if an appropriate scalarization is
employed, the entire nondominated set can be generated in this way. In the
bicriteria case it is well known that this can be realized by an adaptive
approach which, given an appropriate initial search space, requires the
solution of a number of subproblems which is at most two times the number of
nondominated points. For higher dimensional problems, no linear methods were
known up to now. We present a new procedure for finding the entire nondominated
set of tricriteria optimization problems for which the number of scalarized
subproblems to be solved is at most three times the number of nondominated
points of the underlying problem. The approach includes an iterative update of
the search space that, given a (sub-)set of nondominated points, describes the
area in which additional nondominated points may be located. In particular, we
show that the number of boxes, into which the search space is decomposed,
depends linearly on the number of nondominated points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5267</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5267</id><created>2013-05-22</created><authors><author><keyname>Gelley</keyname><forenames>Bluma S.</forenames></author></authors><title>Investigating Deletion in Wikipedia</title><categories>cs.CY cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several hundred Wikipedia articles are deleted every day because they lack
sufficient significance to be included in the encyclopedia. We collect a
dataset of deleted articles and analyze them to determine whether or not the
deletions were justified. We find evidence to support the hypothesis that many
deletions are carried out correctly, but also find that a large number were
done very quickly. Based on our conclusions, we make some recommendations to
reduce the number of non-significant pages and simultaneously improve retention
of new editors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5278</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5278</id><created>2013-05-22</created><updated>2014-09-25</updated><authors><author><keyname>Brandao</keyname><forenames>Fernando G. S. L.</forenames></author><author><keyname>Horodecki</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Ng</keyname><forenames>Nelly Huei Ying</forenames></author><author><keyname>Oppenheim</keyname><forenames>Jonathan</forenames></author><author><keyname>Wehner</keyname><forenames>Stephanie</forenames></author></authors><title>The second laws of quantum thermodynamics</title><categories>quant-ph cond-mat.stat-mech cs.IT math.IT</categories><comments>v3: 39 pages, 2 figures. Substantial expansion of the previous text,
  conditions in terms of generalised alpha free energies, addition on
  discussion about the role of zeroeth and first laws of thermodynamics,
  addition of two new figures</comments><journal-ref>PNAS 112, 3275 (2015)</journal-ref><doi>10.1073/pnas.1411728112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second law of thermodynamics tells us which state transformations are so
statistically unlikely that they are effectively forbidden. Its original
formulation, due to Clausius, states that &quot;Heat can never pass from a colder to
a warmer body without some other change, connected therewith, occurring at the
same time&quot;. The second law applies to systems composed of many particles
interacting; however, we are seeing that one can make sense of thermodynamics
in the regime where we only have a small number of particles interacting with a
heat bath. Is there a second law of thermodynamics in this regime? Here, we
find that for processes which are cyclic or very close to cyclic, the second
law for microscopic systems takes on a very di?erent form than it does at the
macroscopic scale, imposing not just one constraint on what state
transformations are possible, but an entire family of constraints. In
particular, we find a family of free energies which generalise the traditional
one, and show that they can never increase. We further find that there are
three regimes which determine which family of second laws govern state
transitions, depending on how cyclic the process is. In one regime one can
cause an apparent violation of the usual second law, through a process of
embezzling work from a large system which remains arbitrarily close to its
original state. These second laws are not only relevant for small systems, but
also apply to individual macroscopic systems interacting via long-range
interactions, which only satisfy the ordinary second law on average. By making
precise the definition of thermal operations, the laws of thermodynamics take
on a simple form with the first law defining the class of thermal operations,
the zeroeth law emerging as a unique condition ensuring the theory is
nontrivial, and the remaining laws being a monotonicity property of our
generalised free energies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5306</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5306</id><created>2013-05-22</created><authors><author><keyname>Zheng</keyname><forenames>Yin</forenames></author><author><keyname>Zhang</keyname><forenames>Yu-Jin</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author></authors><title>A Supervised Neural Autoregressive Topic Model for Simultaneous Image
  Classification and Annotation</title><categories>cs.CV cs.LG stat.ML</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Topic modeling based on latent Dirichlet allocation (LDA) has been a
framework of choice to perform scene recognition and annotation. Recently, a
new type of topic model called the Document Neural Autoregressive Distribution
Estimator (DocNADE) was proposed and demonstrated state-of-the-art performance
for document modeling. In this work, we show how to successfully apply and
extend this model to the context of visual scene modeling. Specifically, we
propose SupDocNADE, a supervised extension of DocNADE, that increases the
discriminative power of the hidden topic features by incorporating label
information into the training objective of the model. We also describe how to
leverage information about the spatial position of the visual words and how to
embed additional image annotations, so as to simultaneously perform image
classification and annotation. We test our model on the Scene15, LabelMe and
UIUC-Sports datasets and show that it compares favorably to other topic models
such as the supervised variant of LDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5316</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5316</id><created>2013-05-23</created><authors><author><keyname>Chang</keyname><forenames>Ronald Y.</forenames></author><author><keyname>Lin</keyname><forenames>Sian-Jheng</forenames></author><author><keyname>Chung</keyname><forenames>Wei-Ho</forenames></author></authors><title>Energy Efficient Transmission over Space Shift Keying Modulated MIMO
  Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Communications, vol. 60, no. 10, pp.
  2950-2959, October 2012</journal-ref><doi>10.1109/TAP.2012.2194657</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-efficient communication using a class of spatial modulation (SM) that
encodes the source information entirely in the antenna indices is considered in
this paper. The energy-efficient modulation design is formulated as a convex
optimization problem, where minimum achievable average symbol power consumption
is derived with rate, performance, and hardware constraints. The theoretical
result bounds any modulation scheme of this class, and encompasses the existing
space shift keying (SSK), generalized SSK (GSSK), and Hamming code-aided SSK
(HSSK) schemes as special cases. The theoretical optimum is achieved by the
proposed practical energy-efficient HSSK (EE-HSSK) scheme that incorporates a
novel use of the Hamming code and Huffman code techniques in the alphabet and
bit-mapping designs. Experimental studies demonstrate that EE-HSSK
significantly outperforms existing schemes in achieving near-optimal energy
efficiency. An analytical exposition of key properties of the existing GSSK
(including SSK) modulation that motivates a fundamental consideration for the
proposed energy-efficient modulation design is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5330</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5330</id><created>2013-05-23</created><authors><author><keyname>Zapatrin</keyname><forenames>Roman</forenames></author></authors><title>A toy model of information retrieval system based on quantum probability</title><categories>cs.IR</categories><msc-class>68P20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent numerical results show that non-Bayesian knowledge revision may be
helpful in search engine training and optimization. In order to demonstrate how
basic assumption about about the physical nature (and hence the observed
statistics) of retrieved documents can affect the performance of search engines
we suggest an idealized toy model with minimal number of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5337</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5337</id><created>2013-05-23</created><authors><author><keyname>Tabakov</keyname><forenames>Valery</forenames></author></authors><title>System error of project ETONN and EIAS</title><categories>cs.SE</categories><comments>8 pages in Ukrainian, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detected a system error of the project ETONN&amp;EIAS.NET, which consists in the
use of the developers EIAS.NET the Windows operating system in the software
EIAS.NET, which in accordance with the requirements of the specification for
the project EIAS.NET should provide information exchange in real time . It is
concluded that it is impossible to meet the requirement specification for the
project EIAS.NET about providing work ETONN/ETNaSP with the support of EIAS /
EIAS.NET in real time, providing the use of the Windows operating system in the
software EIAS.NET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5339</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5339</id><created>2013-05-23</created><updated>2014-11-14</updated><authors><author><keyname>Kasperski</keyname><forenames>Adam</forenames></author><author><keyname>Zielinski</keyname><forenames>Pawel</forenames></author></authors><title>Combinatorial optimization problems with uncertain costs and the OWA
  criterion</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a class of combinatorial optimization problems with uncertain
costs is discussed. The uncertainty is modeled by specifying a discrete
scenario set containing $K$ distinct cost scenarios. The Ordered Weighted
Averaging (OWA for short) aggregation operator is applied to choose a solution.
The well-known criteria such as: the maximum, minimum, average, Hurwicz and
median are special cases of OWA. By using OWA, the traditional min-max approach
to combinatorial optimization problems with uncertain costs, often regarded as
too conservative, can be generalized. The computational complexity and
approximability of the problem of minimizing OWA for the considered class of
problems are investigated and some new positive and negative results in this
area are provided. These results remain valid for many important problems, such
as network or resource allocation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5352</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5352</id><created>2013-05-23</created><authors><author><keyname>Barletta</keyname><forenames>Luca</forenames></author><author><keyname>Magarini</keyname><forenames>Maurizio</forenames></author><author><keyname>Spalvieri</keyname><forenames>Arnaldo</forenames></author></authors><title>Tight Upper and Lower Bounds to the Information Rate of the Phase Noise
  Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures. Accepted for presentation at ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical upper and lower bounds to the information rate transferred through
the additive white Gaussian noise channel affected by discrete-time
multiplicative autoregressive moving-average (ARMA) phase noise are proposed in
the paper. The state space of the ARMA model being multidimensional, the
problem cannot be approached by the conventional trellis-based methods that
assume a first-order model for phase noise and quantization of the phase space,
because the number of state of the trellis would be enormous. The proposed
lower and upper bounds are based on particle filtering and Kalman filtering.
Simulation results show that the upper and lower bounds are so close to each
other that we can claim of having numerically computed the actual information
rate of the multiplicative ARMA phase noise channel, at least in the cases
studied in the paper. Moreover, the lower bound, which is virtually
capacity-achieving, is obtained by demodulation of the incoming signal based on
a Kalman filter aided by past data. Thus we can claim of having found the
virtually optimal demodulator for the multiplicative phase noise channel, at
least for the cases considered in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5359</identifier>
 <datestamp>2014-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5359</id><created>2013-05-23</created><updated>2014-11-05</updated><authors><author><keyname>Gopalkrishnan</keyname><forenames>Manoj</forenames></author></authors><title>A coercion-resistant protocol for conducting elections by telephone</title><categories>cs.CR cs.CY</categories><comments>v2: 15 pages, no figures. We point out that the protocol requires an
  assumption of a trusted election authority, unlike traditional paper ballots;
  v1: 14 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a protocol that allows voters to phone in their votes. Our
protocol makes it expensive for a candidate and a voter to cooperate to prove
to the candidate who the voter voted for. When the electoral pool is large
enough, the cost to the candidate of manipulating sufficiently many votes to
have an influence on the election results becomes impossibly expensive. Hence,
the protocol provides candidates no incentive to attempt inducement or coercion
of voters, resulting in free and fair elections with the promise of cost
savings and higher voter turnout over traditional elections. One major
inadequacy with our suggested protocol is that we assume the existence of a
trusted election authority to count the votes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5376</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5376</id><created>2013-05-23</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>Approximate Sum-Capacity of the Y-channel</title><categories>cs.IT math.IT</categories><comments>36 pages, 8 figures, accepted for publication in IEEE Trans. Info.
  Theory. arXiv admin note: text overlap with arXiv:1102.2787</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network where three users want to establish multiple unicasts between each
other via a relay is considered. This network is called the Y-channel and
resembles an elemental ingredient of future wireless networks. The sum-capacity
of this network is studied. A characterization of the sum-capacity within an
additive gap of 2 bits, and a multiplicative gap of 4, for all values of
channel gains and transmit powers is obtained. Contrary to similar setups where
the cut-set bounds can be achieved within a constant gap, they can not be
achieved in our case, where they are dominated by our new genie-aided bounds.
Furthermore, it is shown that a time-sharing strategy, in which at each time
two users exchange information using coding strategies of the bi-directional
relay channel, achieves the upper bounds to within a constant gap. This result
is further extended to the K-user case, where it is shown that the same scheme
achieves the sum-capacity within 2log(K-1) bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5399</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5399</id><created>2013-05-23</created><authors><author><keyname>Mannor</keyname><forenames>Shie</forenames><affiliation>EE-Technion</affiliation></author><author><keyname>Perchet</keyname><forenames>Vianney</forenames><affiliation>LPMA</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>INRIA Paris - Rocquencourt, DMA, GREGH</affiliation></author></authors><title>A Primal Condition for Approachability with Partial Monitoring</title><categories>math.OC cs.GT cs.LG stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In approachability with full monitoring there are two types of conditions
that are known to be equivalent for convex sets: a primal and a dual condition.
The primal one is of the form: a set C is approachable if and only all
containing half-spaces are approachable in the one-shot game; while the dual
one is of the form: a convex set C is approachable if and only if it intersects
all payoff sets of a certain form. We consider approachability in games with
partial monitoring. In previous works (Perchet 2011; Mannor et al. 2011) we
provided a dual characterization of approachable convex sets; we also exhibited
efficient strategies in the case where C is a polytope. In this paper we
provide primal conditions on a convex set to be approachable with partial
monitoring. They depend on a modified reward function and lead to
approachability strategies, based on modified payoff functions, that proceed by
projections similarly to Blackwell's (1956) strategy; this is in contrast with
previously studied strategies in this context that relied mostly on the
signaling structure and aimed at estimating well the distributions of the
signals received. Our results generalize classical results by Kohlberg 1975
(see also Mertens et al. 1994) and apply to games with arbitrary signaling
structure as well as to arbitrary convex sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5400</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5400</id><created>2013-05-23</created><authors><author><keyname>Smith</keyname><forenames>Benjamin</forenames><affiliation>INRIA Saclay - Ile de France, LIX</affiliation></author></authors><title>Families of fast elliptic curves from Q-curves</title><categories>math.NT cs.CR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct new families of elliptic curves over \(\FF_{p^2}\) with
efficiently computable endomorphisms, which can be used to accelerate elliptic
curve-based cryptosystems in the same way as Gallant-Lambert-Vanstone (GLV) and
Galbraith-Lin-Scott (GLS) endomorphisms. Our construction is based on reducing
\(\QQ\)-curves-curves over quadratic number fields without complex
multiplication, but with isogenies to their Galois conjugates-modulo inert
primes. As a first application of the general theory we construct, for every
\(p &gt; 3\), two one-parameter families of elliptic curves over \(\FF_{p^2}\)
equipped with endomorphisms that are faster than doubling. Like GLS (which
appears as a degenerate case of our construction), we offer the advantage over
GLV of selecting from a much wider range of curves, and thus finding secure
group orders when \(p\) is fixed. Unlike GLS, we also offer the possibility of
constructing twist-secure curves. Among our examples are prime-order curves
equipped with fast endomorphisms, with almost-prime-order twists, over
\(\FF_{p^2}\) for \(p = 2^{127}-1\) and \(p = 2^{255}-19\).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5404</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5404</id><created>2013-05-23</created><authors><author><keyname>Ding</keyname><forenames>Wenkui</forenames></author><author><keyname>Wu</keyname><forenames>Tao</forenames></author><author><keyname>Qin</keyname><forenames>Tao</forenames></author><author><keyname>Liu</keyname><forenames>Tie-Yan</forenames></author></authors><title>Pure Price of Anarchy for Generalized Second Price Auction</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Generalized Second Price auction (GSP) has been widely used by search
engines to sell ad slots. Previous studies have shown that the pure Price Of
Anarchy (POA) of GSP is 1.25 when there are two ad slots and 1.259 when three
ad slots. For the cases with more than three ad slots, however, only some
untight upper bounds of the pure POA were obtained. In this work, we improve
previous results in two aspects: (1) We prove that the pure POA for GSP is
1.259 when there are four ad slots, and (2) We show that the pure POA for GSP
with more than four ad slots is also 1.259 given the bidders are ranked
according to a particular permutation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5408</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5408</id><created>2013-05-23</created><authors><author><keyname>Garland</keyname><forenames>Joshua</forenames></author><author><keyname>James</keyname><forenames>Ryan</forenames></author><author><keyname>Bradley</keyname><forenames>Elizabeth</forenames></author></authors><title>Determinism, Complexity, and Predictability in Computer Performance</title><categories>nlin.CD cs.IT cs.PF math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computers are deterministic dynamical systems (CHAOS 19:033124, 2009). Among
other things, that implies that one should be able to use deterministic
forecast rules to predict their behavior. That statement is sometimes-but not
always-true. The memory and processor loads of some simple programs are easy to
predict, for example, but those of more-complex programs like compilers are
not. The goal of this paper is to determine why that is the case. We conjecture
that, in practice, complexity can effectively overwhelm the predictive power of
deterministic forecast models. To explore that, we build models of a number of
performance traces from different programs running on different Intel-based
computers. We then calculate the permutation entropy-a temporal entropy metric
that uses ordinal analysis-of those traces and correlate those values against
the prediction success
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5436</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5436</id><created>2013-05-23</created><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Schipani</keyname><forenames>Davide</forenames></author></authors><title>Using LDGM Codes and Sparse Syndromes to Achieve Digital Signatures</title><categories>cs.CR cs.IT math.IT</categories><comments>16 pages. The final publication is available at springerlink.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of achieving efficient code-based
digital signatures with small public keys. The solution we propose exploits
sparse syndromes and randomly designed low-density generator matrix codes.
Based on our evaluations, the proposed scheme is able to outperform existing
solutions, permitting to achieve considerable security levels with very small
public keys.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5464</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5464</id><created>2013-05-21</created><authors><author><keyname>Macchiavello</keyname><forenames>Bruno</forenames></author><author><keyname>Dorea</keyname><forenames>Camilo</forenames></author><author><keyname>Hung</keyname><forenames>Edson M.</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Tan</keyname><forenames>Wai-tian</forenames></author></authors><title>Loss-resilient Coding of Texture and Depth for Free-viewpoint Video
  Conferencing</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free-viewpoint video conferencing allows a participant to observe the remote
3D scene from any freely chosen viewpoint. An intermediate virtual viewpoint
image is commonly synthesized using two pairs of transmitted texture and depth
maps from two neighboring captured viewpoints via depth-image-based rendering
(DIBR). To maintain high quality of synthesized images, it is imperative to
contain the adverse effects of network packet losses that may arise during
texture and depth video transmission. Towards this end, we develop an
integrated approach that exploits the representation redundancy inherent in the
multiple streamed videos a voxel in the 3D scene visible to two captured views
is sampled and coded twice in the two views. In particular, at the receiver we
first develop an error concealment strategy that adaptively blends
corresponding pixels in the two captured views during DIBR, so that pixels from
the more reliable transmitted view are weighted more heavily. We then couple it
with a sender-side optimization of reference picture selection (RPS) during
real-time video coding, so that blocks containing samples of voxels that are
visible in both views are more error-resiliently coded in one view only, given
adaptive blending will erase errors in the other view. Further, synthesized
view distortion sensitivities to texture versus depth errors are analyzed, so
that relative importance of texture and depth code blocks can be computed for
system-wide RPS optimization. Experimental results show that the proposed
scheme can outperform the use of a traditional feedback channel by up to 0.82
dB on average at 8% packet loss rate, and by as much as 3 dB for particular
frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5468</identifier>
 <datestamp>2015-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5468</id><created>2013-05-23</created><authors><author><keyname>Ethier</keyname><forenames>S. N.</forenames></author><author><keyname>Gamez</keyname><forenames>Carlos</forenames></author></authors><title>A game-theoretic analysis of baccara chemin de fer</title><categories>cs.GT</categories><comments>28 pages</comments><msc-class>91A05</msc-class><journal-ref>Games, 4 (2013) 711-737</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assuming that cards are dealt with replacement from a single deck and that
each of Player and Banker sees the total of his own two-card hand but not its
composition, baccara is a 2 x 2^88 matrix game, which was solved by Kemeny and
Snell in 1957. Assuming that cards are dealt without replacement from a d-deck
shoe and that Banker sees the composition of his own two-card hand while Player
sees only his own total, baccara is a 2 x 2^484 matrix game, which was solved
by Downton and Lockwood in 1975 for d=1,2,...,8. Assuming that cards are dealt
without replacement from a d-deck shoe and that each of Player and Banker sees
the composition of his own two-card hand, baccara is a 2^5 x 2^484 matrix game,
which is solved herein for every positive integer d.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5483</identifier>
 <datestamp>2014-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5483</id><created>2013-05-23</created><authors><author><keyname>Gelenbe</keyname><forenames>Erol</forenames></author><author><keyname>Gorbil</keyname><forenames>Gokce</forenames></author><author><keyname>Tzovaras</keyname><forenames>Dimitrios</forenames></author><author><keyname>Liebergeld</keyname><forenames>Steffen</forenames></author><author><keyname>Garcia</keyname><forenames>David</forenames></author><author><keyname>Baltatu</keyname><forenames>Madalina</forenames></author><author><keyname>Lyberopoulos</keyname><forenames>George</forenames></author></authors><title>NEMESYS: Enhanced Network Security for Seamless Service Provisioning in
  the Smart Mobile Ecosystem</title><categories>cs.NI cs.CR</categories><comments>Accepted for publication in Proceedings of the 28th International
  Symposium on Computer and Information Sciences (ISCIS'13); 9 pages; 1 figure</comments><acm-class>C.2.3; K.6.5</acm-class><doi>10.1007/978-3-319-01604-7_36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a consequence of the growing popularity of smart mobile devices, mobile
malware is clearly on the rise, with attackers targeting valuable user
information and exploiting vulnerabilities of the mobile ecosystems. With the
emergence of large-scale mobile botnets, smartphones can also be used to launch
attacks on mobile networks. The NEMESYS project will develop novel security
technologies for seamless service provisioning in the smart mobile ecosystem,
and improve mobile network security through better understanding of the threat
landscape. NEMESYS will gather and analyze information about the nature of
cyber-attacks targeting mobile users and the mobile network so that appropriate
counter-measures can be taken. We will develop a data collection infrastructure
that incorporates virtualized mobile honeypots and a honeyclient, to gather,
detect and provide early warning of mobile attacks and better understand the
modus operandi of cyber-criminals that target mobile devices. By correlating
the extracted information with the known patterns of attacks from wireline
networks, we will reveal and identify trends in the way that cyber-criminals
launch attacks against mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5486</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5486</id><created>2013-05-23</created><updated>2013-06-10</updated><authors><author><keyname>Scoville</keyname><forenames>John</forenames></author></authors><title>Fast Autocorrelated Context Models for Data Compression</title><categories>cs.IT cs.MM math.IT</categories><comments>v2 includes bibliography</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is presented to automatically generate context models of data by
calculating the data's autocorrelation function. The largest values of the
autocorrelation function occur at the offsets or lags in the bitstream which
tend to be the most highly correlated to any particular location. These offsets
are ideal for use in predictive coding, such as predictive partial match (PPM)
or context-mixing algorithms for data compression, making such algorithms more
efficient and more general by reducing or eliminating the need for ad-hoc
models based on particular types of data. Instead of using the definition of
the autocorrelation function, which considers the pairwise correlations of data
requiring O(n^2) time, the Weiner-Khinchin theorem is applied, quickly
obtaining the autocorrelation as the inverse Fast Fourier transform of the
data's power spectrum in O(n log n) time, making the technique practical for
the compression of large data objects. The method is shown to produce the
highest levels of performance obtained to date on a lossless image compression
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5500</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5500</id><created>2013-05-23</created><updated>2013-10-23</updated><authors><author><keyname>Khot</keyname><forenames>Subhash</forenames></author><author><keyname>Tulsiani</keyname><forenames>Madhur</forenames></author><author><keyname>Worah</keyname><forenames>Pratik</forenames></author></authors><title>A Characterization of Approximation Resistance</title><categories>cs.CC cs.DS</categories><comments>62 pages. The previous version of this paper gave a characterization
  of a modified notion called &quot;Strong Approximation Resistance&quot;. We now present
  a characterization of approximation resistance</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A predicate f:{-1,1}^k -&gt; {0,1} with \rho(f) = \frac{|f^{-1}(1)|}{2^k} is
called {\it approximation resistant} if given a near-satisfiable instance of
CSP(f), it is computationally hard to find an assignment that satisfies at
least \rho(f)+\Omega(1) fraction of the constraints.
  We present a complete characterization of approximation resistant predicates
under the Unique Games Conjecture. We also present characterizations in the
{\it mixed} linear and semi-definite programming hierarchy and the
Sherali-Adams linear programming hierarchy. In the former case, the
characterization coincides with the one based on UGC. Each of the two
characterizations is in terms of existence of a probability measure with
certain symmetry properties on a natural convex polytope associated with the
predicate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5506</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5506</id><created>2013-04-25</created><authors><author><keyname>Tucci</keyname><forenames>Robert R.</forenames></author></authors><title>Introduction to Judea Pearl's Do-Calculus</title><categories>cs.AI</categories><comments>16 pages (11 files: 1 .tex, 1 .sty, 9 .jpg)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a purely pedagogical paper with no new results. The goal of the paper
is to give a fairly self-contained introduction to Judea Pearl's do-calculus,
including proofs of his 3 rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5520</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5520</id><created>2013-05-23</created><updated>2013-11-20</updated><authors><author><keyname>Ghaffari</keyname><forenames>Mohsen</forenames></author><author><keyname>Kuhn</keyname><forenames>Fabian</forenames></author></authors><title>Distributed Minimum Cut Approximation</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing approximate minimum edge cuts by
distributed algorithms. We use a standard synchronous message passing model
where in each round, $O(\log n)$ bits can be transmitted over each edge (a.k.a.
the CONGEST model). We present a distributed algorithm that, for any weighted
graph and any $\epsilon \in (0, 1)$, with high probability finds a cut of size
at most $O(\epsilon^{-1}\lambda)$ in $O(D) + \tilde{O}(n^{1/2 + \epsilon})$
rounds, where $\lambda$ is the size of the minimum cut. This algorithm is based
on a simple approach for analyzing random edge sampling, which we call the
random layering technique. In addition, we also present another distributed
algorithm, which is based on a centralized algorithm due to Matula [SODA '93],
that with high probability computes a cut of size at most $(2+\epsilon)\lambda$
in $\tilde{O}((D+\sqrt{n})/\epsilon^5)$ rounds for any $\epsilon&gt;0$.
  The time complexities of both of these algorithms almost match the
$\tilde{\Omega}(D + \sqrt{n})$ lower bound of Das Sarma et al. [STOC '11], thus
leading to an answer to an open question raised by Elkin [SIGACT-News '04] and
Das Sarma et al. [STOC '11].
  Furthermore, we also strengthen the lower bound of Das Sarma et al. by
extending it to unweighted graphs. We show that the same lower bound also holds
for unweighted multigraphs (or equivalently for weighted graphs in which
$O(w\log n)$ bits can be transmitted in each round over an edge of weight $w$),
even if the diameter is $D=O(\log n)$. For unweighted simple graphs, we show
that even for networks of diameter $\tilde{O}(\frac{1}{\lambda}\cdot
\sqrt{\frac{n}{\alpha\lambda}})$, finding an $\alpha$-approximate minimum cut
in networks of edge connectivity $\lambda$ or computing an
$\alpha$-approximation of the edge connectivity requires $\tilde{\Omega}(D +
\sqrt{\frac{n}{\alpha\lambda}})$ rounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5522</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5522</id><created>2013-05-23</created><updated>2013-09-18</updated><authors><author><keyname>Balakuntala</keyname><forenames>Shreyas</forenames></author><author><keyname>Venkatesh</keyname><forenames>Sandeep</forenames></author></authors><title>An Intelligent System to Detect, Avoid and Maintain Potholes: A Graph
  Theoretic Approach</title><categories>cs.AI cs.MA</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a conceptual framework where a centralized system,
classifies the road based upon the level of damage. The centralized system also
identifies the traffic intensity thereby prioritizing the roads that need quick
action to be taken upon. Moreover, the system helps the driver to detect the
level of damage to the road stretch and route the vehicle from an alternative
path to its destination. The system sends a feedback to the concerned
authorities for a quick response to the condition of the roads. The system we
use comprises a laser sensor and pressure sensors in shock absorbers to detect
and quantify the intensity of the pothole, a centralized server which maintains
a database of locations of all the potholes which can be accessed by another
unit inside the vehicle. A point to point connection device is also installed
in vehicles so that, when a vehicle detects a pothole which is not in the
database, all the vehicles within a range of 20 meters are warned about the
pothole. The system computes a route with least number of potholes which is
nearest to the desired destination . If the destination is unknown, then the
system will check for potholes in the current road and displays the level of
damage. The system is flexible enough that the destination can be added,
removed or changed any time during the travel. The best possible route is
suggested by the system upon the alteration. We prove that the algorithm
returns an efficient path with least number of potholes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5524</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5524</id><created>2013-05-23</created><authors><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Yoo</keyname><forenames>Dongchul</forenames></author><author><keyname>Yau</keyname><forenames>Stephen S. -T.</forenames></author></authors><title>Denoising the 3-Base Periodicity Walks of DNA Sequences in Gene Finding</title><categories>cs.CE q-bio.QM</categories><msc-class>68Uxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonlinear Tracking-Differentiator is one-input-two-output system that can
generate smooth approximation of measured signals and get the derivatives of
the signals. The nonlinear tracking-Differentiator is explored to denoise and
generate the derivatives of the walks of the 3-periodicity of DNA sequences. An
improved algorithm for gene finding is presented using the nonlinear
Tracking-Differentiator. The gene finding algorithm employs the 3-base
periodicity of coding region. The 3-base periodicity DNA walks are denoised and
tracked using the nonlinear Tracking-Differentiator. Case studies demonstrate
that the nonlinear Tracking-Differentiator is an effective method to improve
the accuracy of the gene finding algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5530</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5530</id><created>2013-05-23</created><authors><author><keyname>Ozel</keyname><forenames>Omur</forenames></author><author><keyname>Shahzad</keyname><forenames>Khurram</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Optimal Scheduling for Energy Harvesting Transmitters with Hybrid Energy
  Storage</title><categories>cs.IT cs.NI math.IT</categories><comments>To be presented at ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider data transmission with an energy harvesting transmitter which has
a hybrid energy storage unit composed of a perfectly efficient super-capacitor
(SC) and an inefficient battery. The SC has finite space for energy storage
while the battery has unlimited space. The transmitter can choose to store the
harvested energy in the SC or in the battery. The energy is drained from the SC
and the battery simultaneously. In this setting, we consider the offline
throughput maximization problem by a deadline over a point-to-point channel. In
contrast to previous works, the hybrid energy storage model with finite and
unlimited storage capacities imposes a generalized set of constraints on the
transmission policy. As such, we show that the solution generalizes that for a
single battery and is obtained by applying directional water-filling algorithm
multiple times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5534</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5534</id><created>2013-05-23</created><authors><author><keyname>Vogt</keyname><forenames>Fr&#xe9;d&#xe9;ric P. A.</forenames></author><author><keyname>Shingles</keyname><forenames>Luke J.</forenames></author></authors><title>Augmented Reality in Astrophysics</title><categories>astro-ph.IM cs.HC</categories><comments>15 pages, 11 figures. Accepted for publication in Ap&amp;SS. The final
  publication will be available at link.springer.com</comments><doi>10.1007/s10509-013-1499-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Augmented Reality consists of merging live images with virtual layers of
information. The rapid growth in the popularity of smartphones and tablets over
recent years has provided a large base of potential users of Augmented Reality
technology, and virtual layers of information can now be attached to a wide
variety of physical objects. In this article, we explore the potential of
Augmented Reality for astrophysical research with two distinct experiments: (1)
Augmented Posters and (2) Augmented Articles. We demonstrate that the emerging
technology of Augmented Reality can already be used and implemented without
expert knowledge using currently available apps. Our experiments highlight the
potential of Augmented Reality to improve the communication of scientific
results in the field of astrophysics. We also present feedback gathered from
the Australian astrophysics community that reveals evidence of some interest in
this technology by astronomers who experimented with Augmented Posters. In
addition, we discuss possible future trends for Augmented Reality applications
in astrophysics, and explore the current limitations associated with the
technology. This Augmented Article, the first of its kind, is designed to allow
the reader to directly experiment with this technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5551</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5551</id><created>2013-05-23</created><authors><author><keyname>Bolshoy</keyname><forenames>Alexander</forenames></author><author><keyname>Kirzhner</keyname><forenames>Valery</forenames></author></authors><title>Algorithms of an optimal integer tree labeling</title><categories>cs.DS q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we label the vertices of a tree by positive integers. The weight of
an edge is defined by a monotonically increasing function of the absolute value
of the difference of the labels of its endpoints. We define the total cost of
the labeling to be the sum of weight of all the edges.The problem we consider
is that of determining for a given tree G and given a labeling of the leaves of
G the minimum total cost labellings of G. In this paper we present an algorithm
that works for any cost function satisfies the condition of monotony mentioned
above. In a case of the function defined as the absolute value of the
difference of the labels the fast algorithm is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5561</identifier>
 <datestamp>2013-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5561</id><created>2013-05-23</created><updated>2013-07-30</updated><authors><author><keyname>Chalcraft</keyname><forenames>Adam</forenames></author><author><keyname>Kutin</keyname><forenames>Samuel</forenames></author><author><keyname>Moulton</keyname><forenames>David Petrie</forenames></author></authors><title>The Promise Polynomial Hierarchy</title><categories>cs.CC</categories><comments>12 pages</comments><msc-class>68Q15</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The polynomial hierarchy is a grading of problems by difficulty, including P,
NP and coNP as the best known classes. The promise polynomial hierarchy is
similar, but extended to include promise problems. It turns out that the
promise polynomial hierarchy is considerably simpler to work with, and many
open questions about the polynomial hierarchy can be resolved in the promise
polynomial hierarchy.
  Our main theorem is that, in the world of promise problems, if phi has a weak
(Turing, Cook) reduction to SAT then phi has a strong (Karp, many-one)
reduction to UVAL2, where UVAL2(f) is the promise problem of finding the unique
x such that f(x,y)=1 for all y. We also give a complete promise problem for the
promise problem equivalent of UP intersect coUP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5566</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5566</id><created>2013-05-23</created><updated>2013-07-08</updated><authors><author><keyname>Yasseri</keyname><forenames>Taha</forenames></author><author><keyname>Spoerri</keyname><forenames>Anselm</forenames></author><author><keyname>Graham</keyname><forenames>Mark</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>The most controversial topics in Wikipedia: A multilingual and
  geographical analysis</title><categories>physics.soc-ph cs.CL cs.DL cs.SI physics.data-an</categories><comments>This is a draft of a book chapter to be published in 2014 by
  Scarecrow Press. Please cite as: Yasseri T., Spoerri A., Graham M., and
  Kert\'esz J., The most controversial topics in Wikipedia: A multilingual and
  geographical analysis. In: Fichman P., Hara N., editors, Global
  Wikipedia:International and cross-cultural issues in online collaboration.
  Scarecrow Press (2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present, visualize and analyse the similarities and differences between
the controversial topics related to &quot;edit wars&quot; identified in 10 different
language versions of Wikipedia. After a brief review of the related work we
describe the methods developed to locate, measure, and categorize the
controversial topics in the different languages. Visualizations of the degree
of overlap between the top 100 lists of most controversial articles in
different languages and the content related to geographical locations will be
presented. We discuss what the presented analysis and visualizations can tell
us about the multicultural aspects of Wikipedia and practices of
peer-production. Our results indicate that Wikipedia is more than just an
encyclopaedia; it is also a window into convergent and divergent social-spatial
priorities, interests and preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5580</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5580</id><created>2013-05-23</created><updated>2014-03-17</updated><authors><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Subspace Embeddings and $\ell_p$-Regression Using Exponential Random
  Variables</title><categories>cs.DS</categories><comments>Corrected some technical issues in Sec. 4.4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Oblivious low-distortion subspace embeddings are a crucial building block for
numerical linear algebra problems. We show for any real $p, 1 \leq p &lt; \infty$,
given a matrix $M \in \mathbb{R}^{n \times d}$ with $n \gg d$, with constant
probability we can choose a matrix $\Pi$ with $\max(1, n^{1-2/p}) \poly(d)$
rows and $n$ columns so that simultaneously for all $x \in \mathbb{R}^d$,
$\|Mx\|_p \leq \|\Pi Mx\|_{\infty} \leq \poly(d) \|Mx\|_p.$ Importantly, $\Pi
M$ can be computed in the optimal $O(\nnz(M))$ time, where $\nnz(M)$ is the
number of non-zero entries of $M$. This generalizes all previous oblivious
subspace embeddings which required $p \in [1,2]$ due to their use of $p$-stable
random variables. Using our matrices $\Pi$, we also improve the best known
distortion of oblivious subspace embeddings of $\ell_1$ into $\ell_1$ with
$\tilde{O}(d)$ target dimension in $O(\nnz(M))$ time from $\tilde{O}(d^3)$ to
$\tilde{O}(d^2)$, which can further be improved to $\tilde{O}(d^{3/2})
\log^{1/2} n$ if $d = \Omega(\log n)$, answering a question of Meng and Mahoney
(STOC, 2013).
  We apply our results to $\ell_p$-regression, obtaining a
$(1+\eps)$-approximation in $O(\nnz(M)\log n) + \poly(d/\eps)$ time, improving
the best known $\poly(d/\eps)$ factors for every $p \in [1, \infty) \setminus
\{2\}$. If one is just interested in a $\poly(d)$ rather than a
$(1+\eps)$-approximation to $\ell_p$-regression, a corollary of our results is
that for all $p \in [1, \infty)$ we can solve the $\ell_p$-regression problem
without using general convex programming, that is, since our subspace embeds
into $\ell_{\infty}$ it suffices to solve a linear programming problem.
Finally, we give the first protocols for the distributed $\ell_p$-regression
problem for every $p \geq 1$ which are nearly optimal in communication and
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5585</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5585</id><created>2013-05-23</created><authors><author><keyname>Ye</keyname><forenames>Qiaoyang</forenames></author><author><keyname>Al-Shalash</keyname><forenames>Mazin</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>On/Off Macrocells and Load Balancing in Heterogeneous Cellular Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rate distribution in heterogeneous networks (HetNets) greatly benefits
from load balancing, by which mobile users are pushed onto lightly-loaded small
cells despite the resulting loss in SINR. This offloading can be made more
aggressive and robust if the macrocells leave a fraction of time/frequency
resource blank, which reduces the interference to the offloaded users. We
investigate the joint optimization of this technique - referred to in 3GPP as
enhanced intercell interference coordination (eICIC) via almost blank subframes
(ABSs) - with offloading in this paper. Although the joint cell association and
blank resource (BR) problem is nominally combinatorial, by allowing users to
associate with multiple base stations (BSs), the problem becomes convex, and
upper bounds the performance versus a binary association. We show both
theoretically and through simulation that the optimal solution of the relaxed
problem still results in an association that is mostly binary. The optimal
association differs significantly when the macrocell is on or off; in
particular the offloading can be much more aggressive when the resource is left
blank by macro BSs. Further, we observe that jointly optimizing the offloading
with BR is important. The rate gain for cell edge users (the worst 3-10%) is
very large - on the order of 5-10x - versus a naive association strategy
without macrocell blanking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5588</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5588</id><created>2013-05-23</created><authors><author><keyname>Feng</keyname><forenames>Hao</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Diversity Backpressure Scheduling and Routing with Mutual Information
  Accumulation in Wireless Ad-hoc Networks</title><categories>cs.NI</categories><comments>56 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest and analyze algorithms for routing in multi-hop wireless ad-hoc
networks that exploit mutual information accumulation as the physical layer
transmission scheme, and are capable of routing multiple packet streams
(commodities) when only the average channel state information is present and
that only locally. The proposed algorithms are modifications of the Diversity
Backpressure (DIVBAR) algorithm, under which the packet whose commodity has the
largest &quot;backpressure metric&quot; is chosen to be transmitted and is forwarded
through the link with the largest differential backlog (queue length). In
contrast to traditional DIVBAR, each receiving node stores and accumulates the
partially received packet in a separate &quot;partial packet queue&quot;, thus increasing
the probability of successful reception during a later possible retransmission.
We present two variants of the algorithm: DIVBAR-RMIA, under which all the
receiving nodes clear the received partial information of a packet once one or
more receiving nodes firstly decode the packet; and DIVBAR-MIA, under which all
the receiving nodes retain the partial information of a packet until the packet
has reached its destination. We characterize the network capacity region with
RMIA and prove that (under certain mild conditions) it is strictly larger than
the network capacity region with the repetition (REP) transmission scheme that
is used by the traditional DIVBAR. We also prove that DIVBAR-RMIA is
throughput-optimum among the polices with RMIA, i.e., it achieves the network
capacity region with RMIA, which in turn demonstrates that DIVBAR-RMIA
outperforms traditional DIVBAR on the achievable throughput. Moreover, we prove
that DIVBAR-MIA performs at least as well as DIVBAR-RMIA with respect to
throughput. Simulations also confirm these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5592</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5592</id><created>2013-05-23</created><authors><author><keyname>Shaghaghi</keyname><forenames>Mahdi</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Finite-Length and Asymptotic Analysis of Correlogram for Undersampled
  Data</title><categories>cs.IT math.IT</categories><comments>28 pages, 6 figures, submitted to the IEEE Trans. Signal Processing
  in May 2012 and current version in May 2013. arXiv admin note: text overlap
  with arXiv:1202.2408</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a spectrum estimation method for the case that the samples
are obtained at a rate lower than the Nyquist rate. The method is referred to
as the correlogram for undersampled data. The algorithm partitions the spectrum
into a number of segments and estimates the average power within each spectral
segment. This method is able to estimate the power spectrum density of a signal
from undersampled data without essentially requiring the signal to be sparse.
We derive the bias and the variance of the spectrum estimator, and show that
there is a tradeoff between the accuracy of the estimation, the frequency
resolution, and the complexity of the estimator. A closed-form approximation of
the estimation variance is also derived, which clearly shows how the variance
is related to different parameters. The asymptotic behavior of the estimator is
also investigated, and it is proved that this spectrum estimator is consistent.
Moreover, the estimation made for different spectral segments becomes
uncorrelated as the signal length tends to infinity. Finally, numerical
examples and simulation results are provided, which approve the theoretical
conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5601</identifier>
 <datestamp>2014-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5601</id><created>2013-05-23</created><updated>2014-04-17</updated><authors><author><keyname>Liu</keyname><forenames>Sijia</forenames></author><author><keyname>Fardad</keyname><forenames>Makan</forenames></author><author><keyname>Masazade</keyname><forenames>Engin</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Optimal Periodic Sensor Scheduling in Networks of Dynamical Systems</title><categories>stat.AP cs.SY</categories><comments>Accepted in IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding optimal time-periodic sensor schedules for
estimating the state of discrete-time dynamical systems. We assume that
{multiple} sensors have been deployed and that the sensors are subject to
resource constraints, which limits the number of times each can be activated
over one period of the periodic schedule. We seek an algorithm that strikes a
balance between estimation accuracy and total sensor activations over one
period. We make a correspondence between active sensors and the nonzero columns
of estimator gain. We formulate an optimization problem in which we minimize
the trace of the error covariance with respect to the estimator gain while
simultaneously penalizing the number of nonzero columns of the estimator gain.
This optimization problem is combinatorial in nature, and we employ the
alternating direction method of multipliers (ADMM) to find its locally optimal
solutions. Numerical results and comparisons with other sensor scheduling
algorithms in the literature are provided to illustrate the effectiveness of
our proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5608</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5608</id><created>2013-05-23</created><authors><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Baochun</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>To Reserve or Not to Reserve: Optimal Online Multi-Instance Acquisition
  in IaaS Clouds</title><categories>cs.DC</categories><comments>Part of this paper has appeared in USENIX ICAC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infrastructure-as-a-Service (IaaS) clouds offer diverse instance purchasing
options. A user can either run instances on demand and pay only for what it
uses, or it can prepay to reserve instances for a long period, during which a
usage discount is entitled. An important problem facing a user is how these two
instance options can be dynamically combined to serve time-varying demands at
minimum cost. Existing strategies in the literature, however, require either
exact knowledge or the distribution of demands in the long-term future, which
significantly limits their use in practice. Unlike existing works, we propose
two practical online algorithms, one deterministic and another randomized, that
dynamically combine the two instance options online without any knowledge of
the future. We show that the proposed deterministic (resp., randomized)
algorithm incurs no more than 2-alpha (resp., e/(e-1+alpha)) times the minimum
cost obtained by an optimal offline algorithm that knows the exact future a
priori, where alpha is the entitled discount after reservation. Our online
algorithms achieve the best possible competitive ratios in both the
deterministic and randomized cases, and can be easily extended to cases when
short-term predictions are reliable. Simulations driven by a large volume of
real-world traces show that significant cost savings can be achieved with
prevalent IaaS prices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5610</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5610</id><created>2013-05-23</created><authors><author><keyname>Glover</keyname><forenames>Fred</forenames></author><author><keyname>Ye</keyname><forenames>Tao</forenames></author><author><keyname>Punnen</keyname><forenames>Abraham P.</forenames></author><author><keyname>Kochenberger</keyname><forenames>Gary</forenames></author></authors><title>Integrating tabu search and VLSN search to develop enhanced algorithms:
  A case study using bipartite boolean quadratic programs</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bipartite boolean quadratic programming problem (BBQP) is a
generalization of the well studied boolean quadratic programming problem. The
model has a variety of real life applications; however, empirical studies of
the model are not available in the literature, except in a few isolated
instances. In this paper, we develop efficient heuristic algorithms based on
tabu search, very large scale neighborhood (VLSN) search, and a hybrid
algorithm that integrates the two. The computational study establishes that
effective integration of simple tabu search with VLSN search results in
superior outcomes, and suggests the value of such an integration in other
settings. Complexity analysis and implementation details are provided along
with conclusions drawn from experimental analysis. In addition, we obtain
solutions better than the best previously known for almost all medium and large
size benchmark instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5617</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5617</id><created>2013-05-24</created><authors><author><keyname>Niemeyer</keyname><forenames>Alice C.</forenames></author><author><keyname>Popiel</keyname><forenames>Tomasz</forenames></author><author><keyname>Praeger</keyname><forenames>Cheryl E.</forenames></author></authors><title>Straight-line programs with memory and matrix Bruhat decomposition</title><categories>cs.DS math.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We advocate that straight-line programs designed for algebraic computations
should be accompanied by a comprehensive complexity analysis that takes into
account both the number of fundamental algebraic operations needed, as well as
memory requirements arising during evaluation. We introduce an approach for
formalising this idea and, as illustration, construct and analyse straight-line
programs for the Bruhat decomposition of $d \times d$ matrices with determinant
1 over a finite field of order $q$ that have length $O(d^2 \log(q))$ and
require storing only $O(\log(q))$ matrices during evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5625</identifier>
 <datestamp>2013-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5625</id><created>2013-05-24</created><updated>2013-10-17</updated><authors><author><keyname>Chandrasetty</keyname><forenames>Vikram Arkalgud</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author><author><keyname>Lechner</keyname><forenames>Gottfried</forenames></author></authors><title>Memory Efficient Decoders using Spatially Coupled Quasi-Cyclic LDPC
  Codes</title><categories>cs.IT math.IT</categories><comments>6 pages, 8 figures, 1 table, submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose the construction of Spatially Coupled Low-Density
Parity-Check (SC-LDPC) codes using a periodic time-variant Quasi-Cyclic (QC)
algorithm. The QC based approach is optimized to obtain memory efficiency in
storing the parity-check matrix in the decoders. A hardware model of the
parity-check storage units has been designed for Xilinx FPGA to compare the
logic and memory requirements for various approaches. It is shown that the
proposed QC SC-LDPC code (with optimization) can be stored with reasonable
logic resources and without the need of block memory in the FPGA. In addition,
a significant improvement in the processing speed is also achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5626</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5626</id><created>2013-05-24</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Erasure/list exponents for Slepian-Wolf decoding</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>22 pages; Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze random coding error exponents associated with erasure/list
Slepian-Wolf decoding using two different methods and then compare the
resulting bounds. The first method follows the well known techniques of
Gallager and Forney and the second method is based on a technique of distance
enumeration, or more generally, type class enumeration, which is rooted in the
statistical mechanics of a disordered system that is related to the random
energy model (REM). The second method is guaranteed to yield exponent functions
which are at least as tight as those of the first method, and it is
demonstrated that for certain combinations of coding rates and thresholds, the
bounds of the second method are strictly tighter than those of the first
method, by an arbitrarily large factor. In fact, the second method may even
yield an infinite exponent at regions where the first method gives finite
values. We also discuss the option of variable-rate Slepian-Wolf encoding and
demonstrate how it can improve on the resulting exponents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5634</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5634</id><created>2013-05-24</created><authors><author><keyname>Derrick</keyname><forenames>John</forenames><affiliation>University of Sheffield</affiliation></author><author><keyname>Boiten</keyname><forenames>Eerke</forenames><affiliation>University of Kent</affiliation></author><author><keyname>Reeves</keyname><forenames>Steve</forenames><affiliation>University of Waikato</affiliation></author></authors><title>Proceedings 16th International Refinement Workshop</title><categories>cs.SE cs.LO</categories><comments>This volume is dedicated to the memory of Kaisa Sere</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 115, 2013</journal-ref><doi>10.4204/EPTCS.115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 16th BCS-FACS Refinement Workshop was co-located with iFM 2013 held in
Turku, Finland on June 11th, 2013. This volume contains the 6 papers selected
for presentation at the workshop following a peer review process. The papers
cover a wide range of topics in the theory and application of refinement.
Refinement is one of the cornerstones of a formal approach to software
engineering: the process of developing a more detailed design or implementation
from an abstract specification through a sequence of mathematically-based steps
that maintain correctness with respect to the original specification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5637</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5637</id><created>2013-05-24</created><authors><author><keyname>Tirri</keyname><forenames>Seppo Ilari</forenames></author></authors><title>Algebraic Net Class Rewriting Systems, Syntax and Semantics for
  Knowledge Representation and Automated Problem Solving</title><categories>cs.AI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intention of the present study is to establish general framework for
automated problem solving by approaching the task universal algebraically
introducing knowledge as realizations of generalized free algebra based nets,
graphs with gluing forms connecting in- and out-edges to nodes. Nets are caused
to undergo transformations in conceptual level by type wise differentiated
intervening net rewriting systems dispersing problems to abstract parts,
matching being determined by substitution relations. Achieved sets of
conceptual nets constitute congruent classes. New results are obtained within
construction of problem solving systems where solution algorithms are derived
parallel with other candidates applied to the same net classes. By applying
parallel transducer paths consisting of net rewriting systems to net classes
congruent quotient algebras are established and the manifested class rewriting
comprises all solution candidates whenever produced nets are in anticipated
languages liable to acceptance of net automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5639</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5639</id><created>2013-05-24</created><authors><author><keyname>Wang</keyname><forenames>Ruonan</forenames></author><author><keyname>Harris</keyname><forenames>Christopher</forenames></author></authors><title>Scaling Radio Astronomy Signal Correlation on Heterogeneous
  Supercomputers Using Various Data Distribution Methodologies</title><categories>astro-ph.IM cs.DC</categories><doi>10.1007/s10686-013-9340-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next generation radio telescopes will require orders of magnitude more
computing power to provide a view of the universe with greater sensitivity. In
the initial stages of the signal processing flow of a radio telescope, signal
correlation is one of the largest challenges in terms of handling huge data
throughput and intensive computations. We implemented a GPU cluster based
software correlator with various data distribution models and give a systematic
comparison based on testing results obtained using the Fornax supercomputer. By
analyzing the scalability and throughput of each model, optimal approaches are
identified across a wide range of problem sizes, covering the scale of next
generation telescopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5640</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5640</id><created>2013-05-24</created><updated>2013-06-21</updated><authors><author><keyname>Yang</keyname><forenames>Li</forenames></author><author><keyname>Zhou</keyname><forenames>Rui-Rui</forenames></author></authors><title>On the post-quantum security of encrypted key exchange protocols</title><categories>quant-ph cs.CR</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the post-quantum security of the encrypted key exchange(EKE)
protocols based on some basic physical parameters of ion-trap quantum computer,
and show that the EKE protocol with a 40-bit password will be secure against a
quantum adversary with several ion-trap quantum computers. We present a
password encrypted no-key protocol to resist middle-man attack, and prove that
it is also with the post-quantum security. The analysis presented here is
probably of general meaning for the security evaluation of various hybrid
cryptosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5653</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5653</id><created>2013-05-24</created><authors><author><keyname>Garbis</keyname><forenames>George</forenames></author><author><keyname>Kyzirakos</keyname><forenames>Kostis</forenames></author><author><keyname>Koubarakis</keyname><forenames>Manolis</forenames></author></authors><title>Geographica: A Benchmark for Geospatial RDF Stores</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geospatial extensions of SPARQL like GeoSPARQL and stSPARQL have recently
been defined and corresponding geospatial RDF stores have been implemented.
However, there is no widely used benchmark for evaluating geospatial RDF stores
which takes into account recent advances to the state of the art in this area.
In this paper, we develop a benchmark, called Geographica, which uses both
real-world and synthetic data to test the offered functionality and the
performance of some prominent geospatial RDF stores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5655</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5655</id><created>2013-05-24</created><authors><author><keyname>Chebukov</keyname><forenames>Dmitry E.</forenames></author><author><keyname>Izaak</keyname><forenames>Alexander D.</forenames></author><author><keyname>Misyurina</keyname><forenames>Olga G.</forenames></author><author><keyname>Pupyrev</keyname><forenames>Yuri A.</forenames></author><author><keyname>Zhizhchenko</keyname><forenames>Alexey B.</forenames></author></authors><title>Math-Net.Ru as a Digital Archive of the Russian Mathematical Knowledge
  from the XIX Century to Today</title><categories>cs.DL</categories><journal-ref>Lecture Notes in Computer Science, 7961, ed. J. Carette et al.,
  2013, 344-348</journal-ref><doi>10.1007/978-3-642-39320-4_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of the project Math-Net.Ru is to collect scientific
publications in Russian and Soviet mathematics journals since their foundation
to today and the authors of these publications into a single database and to
provide access to full-text articles for broad international mathematical
community. Leading Russian mathematics journals have been comprehensively
digitized dating back to the first volumes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5662</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5662</id><created>2013-05-24</created><authors><author><keyname>Tapolcai</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>R&#xe9;tv&#xe1;ri</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>K\Hor&#xf6;si</keyname><forenames>Attila</forenames></author></authors><title>Memory size bounds of prefix DAGs</title><categories>cs.DS cs.IT math.IT</categories><comments>3 pages, G. R\'etv\'ari, J. Tapolcai, A. K\H{o}r\&quot;osi, A. Majd\'an,
  Z. Heszberger, &quot;Compressing IP Forwarding Tables: Towards Entropy Bounds and
  Beyond&quot;, In ACM Sigcomm, 2013</comments><msc-class>94A05, 68P30</msc-class><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report an entropy bound on the memory size is given for a compression
method of leaf-labeled trees. The compression converts the tree into a Directed
Acyclic Graph (DAG) by merging isomorphic subtrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5663</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5663</id><created>2013-05-24</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author><author><keyname>Nitta</keyname><forenames>Tohru</forenames></author><author><keyname>Kuroe</keyname><forenames>Yasuaki</forenames></author></authors><title>Applications of Clifford's Geometric Algebra</title><categories>math.RA cs.CV</categories><comments>26 pages, 91 references</comments><msc-class>Primary 15A66, Secondary 68T40, 62M45, 68U10, 60G35</msc-class><journal-ref>Advances in Applied Clifford Algebras: Volume 23, Issue 2 (2013),
  Page 377-404</journal-ref><doi>10.1007/s00006-013-0378-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey the development of Clifford's geometric algebra and some of its
engineering applications during the last 15 years. Several recently developed
applications and their merits are discussed in some detail. We thus hope to
clearly demonstrate the benefit of developing problem solutions in a unified
framework for algebra and geometry with the widest possible scope: from quantum
computing and electromagnetism to satellite navigation, from neural computing
to camera geometry, image processing, robotics and beyond.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5665</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5665</id><created>2013-05-24</created><authors><author><keyname>Abdelali</keyname><forenames>Boussadi</forenames></author><author><keyname>Thibaut</keyname><forenames>Caruba</forenames></author><author><keyname>Alexandre</keyname><forenames>Karras</forenames></author><author><keyname>Sarah</keyname><forenames>Berdot</forenames></author><author><keyname>Patrice</keyname><forenames>Degoulet</forenames></author><author><keyname>Pierre</keyname><forenames>Durieux</forenames></author><author><keyname>Brigitte</keyname><forenames>Sabatier</forenames></author></authors><title>Validity of a clinical decision rule based alert system for drug dose
  adjustment in patients with renal failure intended to improve pharmacists'
  analysis of medication orders in hospitals</title><categories>cs.AI</categories><comments>Word count Body: 3753 Abstract: 280 tables: 5 figures: 1 pages: 26
  references: 29 This article is the pre print version of an article submitted
  to the International Journal of Medical Informatics (IJMI, Elsevier) funding:
  This work was supported by Programme de recherche en qualit\'e hospitali\`ere
  (PREQHOS-PHRQ 1034 SADPM), The French Ministry of Health, grant number 115189</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: The main objective of this study was to assess the diagnostic
performances of an alert system integrated into the CPOE/EMR system for renally
cleared drug dosing control. The generated alerts were compared with the daily
routine practice of pharmacists as part of the analysis of medication orders.
Materials and Methods: The pharmacists performed their analysis of medication
orders as usual and were not aware of the alert system interventions that were
not displayed for the purpose of the study neither to the physician nor to the
pharmacist but kept with associate recommendations in a log file. A senior
pharmacist analyzed the results of medication order analysis with and without
the alert system. The unit of analysis was the drug prescription line. The
primary study endpoints were the detection of drug-dose prescription errors and
inter-rater reliability between the alert system and the pharmacists in the
detection of drug dose error. Results: The alert system fired alerts in 8.41%
(421/5006) of cases: 5.65% (283/5006) exceeds max daily dose alerts and 2.76%
(138/5006) under dose alerts. The alert system and the pharmacists showed a
relatively poor concordance: 0.106 (CI 95% [0.068, 0.144]). According to the
senior pharmacist review, the alert system fired more appropriate alerts than
pharmacists, and made fewer errors than pharmacists in analyzing drug dose
prescriptions: 143 for the alert system and 261 for the pharmacists. Unlike the
alert system, most diagnostic errors made by the pharmacists were false
negatives. The pharmacists were not able to analyze a significant number (2097;
25.42%) of drug prescription lines because understaffing. Conclusion: This
study strongly suggests that an alert system would be complementary to the
pharmacists activity and contribute to drug prescription safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5670</identifier>
 <datestamp>2015-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5670</id><created>2013-05-24</created><authors><author><keyname>Chen</keyname><forenames>Min</forenames></author><author><keyname>Floridi</keyname><forenames>Luciano</forenames></author><author><keyname>Borgo</keyname><forenames>Rita</forenames></author></authors><title>What is Visualization Really for?</title><categories>cs.HC</categories><journal-ref>In The Philosophy of Information Quality. Springer Synthese
  Library Volume 358, pp 75-93 . 2014</journal-ref><doi>10.1007/978-3-319-07121-3_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whenever a visualization researcher is asked about the purpose of
visualization, the phrase &quot;gaining insight&quot; by and large pops out
instinctively. However, it is not absolutely factual that all uses of
visualization are for gaining a deep understanding, unless the term insight is
broadened to encompass all types of thought. Even when insight is the focus of
a visualization task, it is rather difficult to know what insight is gained,
how much, or how accurate. In this paper, we propose that &quot;saving time&quot; in
accomplishing a user's task is the most fundamental objective. By giving
emphasis to saving time, we can establish a concrete metric, alleviate
unnecessary contention caused by different interpretations of insight, and
stimulate new research efforts in some aspects of visualization, such as
empirical studies, design optimisation and theories of visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5675</identifier>
 <datestamp>2014-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5675</id><created>2013-05-24</created><updated>2014-12-30</updated><authors><author><keyname>Agarwal</keyname><forenames>Rachit</forenames></author><author><keyname>Gauthier</keyname><forenames>Vincent</forenames></author><author><keyname>Becker</keyname><forenames>Monique</forenames></author><author><keyname>Toukabri</keyname><forenames>Thouraya</forenames></author><author><keyname>Afifi</keyname><forenames>Hossam</forenames></author></authors><title>Large Scale Model for Information Dissemination with Device to Device
  Communication using Call Details Records</title><categories>cs.NI</categories><comments>Accepted in Computer Communications journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a network of devices in close proximity such as Device to Device ($D2D$)
communication, we study the dissemination of public safety information at
country scale level. In order to provide a realistic model for the information
dissemination, we extract a spatial distribution of the population of Ivory
Coast from census data and determine migration pattern from the Call Detail
Records ($CDR$) obtained during the Data for Development ($D4D$) challenge. We
later apply epidemic model towards the information dissemination process based
on the spatial properties of the user mobility extracted from the provided
$CDR$. We then propose enhancements by adding latent states to the epidemic
model in order to model more realistic user dynamics. Finally, we study
dynamics of the evolution of the information spreading through the population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5703</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5703</id><created>2013-05-24</created><authors><author><keyname>Quaresma</keyname><forenames>Pedro</forenames></author><author><keyname>Santos</keyname><forenames>Vanda</forenames></author><author><keyname>Bouallegue</keyname><forenames>Seifeddine</forenames></author></authors><title>The Web Geometry Laboratory Project</title><categories>cs.CY cs.CG</categories><comments>5 pages; 2 figures; Conferences on Intelligent Computer Mathematics
  (CICM2013), July 8-12, 2013, University of Bath, Bath, England</comments><msc-class>68U35, 97G99</msc-class><journal-ref>CICM 2013, LNAI (7961), 364-368, Springer, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The &quot;Web Geometry Laboratory&quot; (WGL) project's goal is to build an adaptive
and collaborative blended-learning Web-environment for geometry. In its current
version (1.0) the WGL is already a collaborative blended-learning
Web-environment integrating a dynamic geometry system (DGS) and having some
adaptive features. All the base features needed to implement the adaptive
module and to allow the integration of a geometry automated theorem prover
(GATP) are also already implemented. The actual testing of the WGL platform by
high-school teachers is underway and a field-test with high-school students is
being prepared. The adaptive module and the GATP integration will be the next
steps of this project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5710</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5710</id><created>2013-05-24</created><authors><author><keyname>Tankink</keyname><forenames>Carst</forenames></author><author><keyname>Kaliszyk</keyname><forenames>Cezary</forenames></author><author><keyname>Urban</keyname><forenames>Josef</forenames></author><author><keyname>Geuvers</keyname><forenames>Herman</forenames></author></authors><title>Formal Mathematics on Display: A Wiki for Flyspeck</title><categories>cs.MS cs.DL</categories><comments>16 pages, published as part of the CICM 2013 conference proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Agora system is a prototype &quot;Wiki for Formal Mathematics&quot;, with an aim to
support developing and documenting large formalizations of mathematics in a
proof assistant. The functions implemented in Agora include in-browser editing,
strong AI/ATP proof advice, verification, and HTML rendering. The HTML
rendering contains hyperlinks and provides on-demand explanation of the proof
state for each proof step. In the present paper we show the prototype Flyspeck
Wiki as an instance of Agora for HOL Light formalizations. The wiki can be used
for formalizations of mathematics and for writing informal wiki pages about
mathematics. Such informal pages may contain islands of formal text, which is
used here for providing an initial cross-linking between Hales's informal
Flyspeck book, and the formal Flyspeck development.
  The Agora platform intends to address distributed wiki-style collaboration on
large formalization projects, in particular both the aspect of immediate
editing, verification and rendering of formal code, and the aspect of gradual
and mutual refactoring and correspondence of the initial informal text and its
formalization. Here, we highlight these features within the Flyspeck Wiki.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5713</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5713</id><created>2013-05-24</created><authors><author><keyname>Brand</keyname><forenames>Michael</forenames></author></authors><title>Computing with and without arbitrary large numbers</title><categories>cs.CC</categories><comments>12 pages (main text) + 30 pages (appendices), 1 figure. Extended
  abstract. The full paper was presented at TAMC 2013. (Reference given is for
  the paper version, as it appears in the proceedings.)</comments><msc-class>68Q05, 68Q10, 68Q15</msc-class><acm-class>F.1.1; F.1.2; F.1.3; I.1.1</acm-class><journal-ref>TAMC 2013, LNCS 7876, Springer, Heidelberg, pp. 181--192</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the study of random access machines (RAMs) it has been shown that the
availability of an extra input integer, having no special properties other than
being sufficiently large, is enough to reduce the computational complexity of
some problems. However, this has only been shown so far for specific problems.
We provide a characterization of the power of such extra inputs for general
problems. To do so, we first correct a classical result by Simon and Szegedy
(1992) as well as one by Simon (1981). In the former we show mistakes in the
proof and correct these by an entirely new construction, with no great change
to the results. In the latter, the original proof direction stands with only
minor modifications, but the new results are far stronger than those of Simon
(1981). In both cases, the new constructions provide the theoretical tools
required to characterize the power of arbitrary large numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5719</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5719</id><created>2013-05-24</created><updated>2016-01-31</updated><authors><author><keyname>Franchi</keyname><forenames>Antonio</forenames></author><author><keyname>Giordano</keyname><forenames>Paolo Robuffo</forenames></author></authors><title>Online Leader Selection for Improved Collective Tracking and Formation
  Maintenance</title><categories>cs.SY cs.MA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this work is to propose an extension of the popular
leader-follower framework for multi-agent collective tracking and formation
maintenance in presence of a time- varying leader. In particular, the leader is
persistently selected online so as to optimize the tracking performance of an
exogenous collective velocity command while also maintaining a desired
formation via a (possibly time-varying) communication-graph topology. The
effects of a change in the leader identity are theoretically analyzed and
exploited for defining a suitable error metric able to capture the tracking
performance of the multi- agent group. Both the group performance and the
metric design are found to depend upon the spectral properties of a special
directed graph induced by the identity of the chosen leader. By exploiting
these results, as well as distributed estimation techniques, we are then able
to detail a fully-decentralized adaptive strategy able to periodically select
online the best leader among the neighbors of the current leader. Numerical
simulations show that the application of the proposed technique results in an
improvement of the overall performance of the group behavior w.r.t. other
possible strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5724</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5724</id><created>2013-05-24</created><authors><author><keyname>Libbrecht</keyname><forenames>Paul</forenames></author></authors><title>Escaping the Trap of too Precise Topic Queries</title><categories>cs.DL cs.IR</categories><comments>12 pages, Conference on Intelligent Computer Mathematics 2013 Bath,
  UK</comments><acm-class>H.3.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  At the very center of digital mathematics libraries lie controlled
vocabularies which qualify the {\it topic} of the documents. These topics are
used when submitting a document to a digital mathematics library and to perform
searches in a library. The latter are refined by the use of these topics as
they allow a precise classification of the mathematics area this document
addresses. However, there is a major risk that users employ too precise topics
to specify their queries: they may be employing a topic that is only &quot;close-by&quot;
but missing to match the right resource. We call this the {\it topic trap}.
Indeed, since 2009, this issue has appeared frequently on the i2geo.net
platform. Other mathematics portals experience the same phenomenon. An approach
to solve this issue is to introduce tolerance in the way queries are understood
by the user. In particular, the approach of including fuzzy matches but this
introduces noise which may prevent the user of understanding the function of
the search engine.
  In this paper, we propose a way to escape the topic trap by employing the
navigation between related topics and the count of search results for each
topic. This supports the user in that search for close-by topics is a click
away from a previous search. This approach was realized with the i2geo search
engine and is described in detail where the relation of being {\it related} is
computed by employing textual analysis of the definitions of the concepts
fetched from the Wikipedia encyclopedia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5728</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5728</id><created>2013-05-24</created><authors><author><keyname>El-Zaart</keyname><forenames>Ali</forenames></author><author><keyname>Al-Jibory</keyname><forenames>Wafaa Kamel</forenames></author></authors><title>Edge Detection in Radar Images Using Weibull Distribution</title><categories>cs.CV</categories><comments>9 pages,6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar images can reveal information about the shape of the surface terrain as
well as its physical and biophysical properties. Radar images have long been
used in geological studies to map structural features that are revealed by the
shape of the landscape. Radar imagery also has applications in vegetation and
crop type mapping, landscape ecology, hydrology, and volcanology. Image
processing is using for detecting for objects in radar images. Edge detection;
which is a method of determining the discontinuities in gray level images; is a
very important initial step in Image processing. Many classical edge detectors
have been developed over time. Some of the well-known edge detection operators
based on the first derivative of the image are Roberts, Prewitt, Sobel which is
traditionally implemented by convolving the image with masks. Also Gaussian
distribution has been used to build masks for the first and second derivative.
However, this distribution has limit to only symmetric shape. This paper will
use to construct the masks, the Weibull distribution which was more general
than Gaussian because it has symmetric and asymmetric shape. The constructed
masks are applied to images and we obtained good results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5734</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5734</id><created>2013-05-24</created><authors><author><keyname>Song</keyname><forenames>Yin</forenames></author><author><keyname>Cao</keyname><forenames>Longbing</forenames></author><author><keyname>Fan</keyname><forenames>Xuhui</forenames></author><author><keyname>Cao</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author></authors><title>Characterizing A Database of Sequential Behaviors with Latent Dirichlet
  Hidden Markov Models</title><categories>stat.ML cs.LG</categories><acm-class>H.2.8; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a generative model, the latent Dirichlet hidden Markov
models (LDHMM), for characterizing a database of sequential behaviors
(sequences). LDHMMs posit that each sequence is generated by an underlying
Markov chain process, which are controlled by the corresponding parameters
(i.e., the initial state vector, transition matrix and the emission matrix).
These sequence-level latent parameters for each sequence are modeled as latent
Dirichlet random variables and parameterized by a set of deterministic
database-level hyper-parameters. Through this way, we expect to model the
sequence in two levels: the database level by deterministic hyper-parameters
and the sequence-level by latent parameters. To learn the deterministic
hyper-parameters and approximate posteriors of parameters in LDHMMs, we propose
an iterative algorithm under the variational EM framework, which consists of E
and M steps. We examine two different schemes, the fully-factorized and
partially-factorized forms, for the framework, based on different assumptions.
We present empirical results of behavior modeling and sequence classification
on three real-world data sets, and compare them to other related models. The
experimental results prove that the proposed LDHMMs produce better
generalization performance in terms of log-likelihood and deliver competitive
results on the sequence classification problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5750</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5750</id><created>2013-05-23</created><updated>2013-06-30</updated><authors><author><keyname>Raza</keyname><forenames>Khalid</forenames></author><author><keyname>Jaiswal</keyname><forenames>Rajni</forenames></author></authors><title>Reconstruction and Analysis of Cancer-specific Gene Regulatory Networks
  from Gene Expression Profiles</title><categories>cs.SY cs.CE</categories><comments>10 pages, 1 figure, 2 tables</comments><journal-ref>International Journal on Bioinformatics &amp; Biosciences (IJBB),
  3(2):25-34, June 2013</journal-ref><doi>10.5121/ijbb.2013.3103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of Systems Biology research is to reconstruct biological
networks for its topological analysis so that reconstructed networks can be
used for the identification of various kinds of disease. The availability of
high-throughput data generated by microarray experiments fueled researchers to
use whole-genome gene expression profiles to understand cancer and to
reconstruct key cancer-specific gene regulatory network. Now, the researchers
are taking a keen interest in the development of algorithm for the
reconstruction of gene regulatory network from whole genome expression
profiles. In this study, a cancer-specific gene regulatory network (prostate
cancer) has been constructed using a simple and novel statistics based
approach. First, significant genes differentially expressing them self in the
disease condition has been identified using a two-stage filtering approach
t-test and fold-change measure. Next, regulatory relationships between the
identified genes has been computed using Pearson correlation coefficient. The
obtained results has been validated with the available databases and
literature. We obtained a cancer-specific regulatory network of 29 genes with a
total of 55 regulatory relations in which some of the genes has been identified
as hub genes that can act as drug target for the cancer diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5753</identifier>
 <datestamp>2014-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5753</id><created>2013-05-22</created><updated>2014-11-20</updated><authors><author><keyname>Bruza</keyname><forenames>Peter D.</forenames></author><author><keyname>Kitto</keyname><forenames>Kirsty</forenames></author><author><keyname>Ramm</keyname><forenames>Brentyn J.</forenames></author><author><keyname>Sitbon</keyname><forenames>Laurianne</forenames></author></authors><title>A probabilistic framework for analysing the compositionality of
  conceptual combinations</title><categories>cs.CL</categories><comments>Revisions (Journal of Mathematical Psychology)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conceptual combination performs a fundamental role in creating the broad
range of compound phrases utilized in everyday language. This article provides
a novel probabilistic framework for assessing whether the semantics of
conceptual combinations are compositional, and so can be considered as a
function of the semantics of the constituent concepts, or not. While the
systematicity and productivity of language provide a strong argument in favor
of assuming compositionality, this very assumption is still regularly
questioned in both cognitive science and philosophy. Additionally, the
principle of semantic compositionality is underspecified, which means that
notions of both &quot;strong&quot; and &quot;weak&quot; compositionality appear in the literature.
Rather than adjudicating between different grades of compositionality, the
framework presented here contributes formal methods for determining a clear
dividing line between compositional and non-compositional semantics. In
addition, we suggest that the distinction between these is contextually
sensitive. Utilizing formal frameworks developed for analyzing composite
systems in quantum theory, we present two methods that allow the semantics of
conceptual combinations to be classified as &quot;compositional&quot; or
&quot;non-compositional&quot;. Compositionality is first formalised by factorising the
joint probability distribution modeling the combination, where the terms in the
factorisation correspond to individual concepts. This leads to the necessary
and sufficient condition for the joint probability distribution to exist. A
failure to meet this condition implies that the underlying concepts cannot be
modeled in a single probability space when considering their combination, and
the combination is thus deemed &quot;non-compositional&quot;. The formal analysis methods
are demonstrated by applying them to an empirical study of twenty-four
non-lexicalised conceptual combinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5756</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5756</id><created>2013-05-24</created><authors><author><keyname>Meyer</keyname><forenames>Fernand</forenames></author></authors><title>Flooding edge or node weighted graphs</title><categories>cs.CV</categories><comments>165 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstruction closings have all properties of a physical flooding of a
topographic surface. They are precious for simplifying gradient images or,
filling unwanted catchment basins, on which a subsequent watershed transform
extracts the targeted objects. Flooding a topographic surface may be modeled as
flooding a node weighted graph (TG), with unweighted edges, the node weights
representing the ground level. The progression of a flooding may also be
modeled on the region adjacency graph (RAG) of a topographic surface. On a RAG
each node represents a catchment basin and edges connect neighboring nodes. The
edges are weighted by the altitude of the pass point between both adjacent
regions. The graph is flooded from sources placed at the marker positions and
each node is assigned to the source by which it has been flooded. The level of
the flood is represented on the nodes on each type of graphs. The same flooding
may thus be modeled on a TG or on a RAG. We characterize all valid floodings on
both types of graphs, as they should verify the laws of hydrostatics. We then
show that each flooding of a node weighted graph also is a flooding of an edge
weighted graph with appropriate edge weights. The highest flooding under a
ceiling function may be interpreted as the shortest distance to the root for
the ultrametric flooding distance in an augmented graph. The ultrametric
distance between two nodes is the minimal altitude of a flooding for which both
nodes are flooded. This remark permits to flood edge or node weighted graphs by
using shortest path algorithms. It appears that the collection of all lakes of
a RAG has the structure of a dendrogram, on which the highest flooding under a
ceiling function may be rapidly found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5757</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5757</id><created>2013-05-24</created><authors><author><keyname>Wei-Kleiner</keyname><forenames>Fang</forenames></author></authors><title>Tree Decomposition based Steiner Tree Computation over Large Graphs</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we present an exact algorithm for the Steiner tree problem.
The algorithm is based on certain pre-computed index structures. Our algorithm
offers a practical solution for the Steiner tree problems on graphs of large
size and bounded number of terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5762</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5762</id><created>2013-05-24</created><updated>2013-10-04</updated><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Liu</keyname><forenames>Shuiyin</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Decoding by Sampling - Part II: Derandomization and Soft-output Decoding</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transaction on Communications 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a derandomized algorithm for sampling decoding is proposed to
achieve near-optimal performance in lattice decoding. By setting a probability
threshold to sample candidates, the whole sampling procedure becomes
deterministic, which brings considerable performance improvement and complexity
reduction over to the randomized sampling. Moreover, the upper bound on the
sample size K, which corresponds to near-maximum likelihood (ML) performance,
is derived. We also find that the proposed algorithm can be used as an
efficient tool to implement soft-output decoding in multiple-input
multiple-output (MIMO) systems. An upper bound of the sphere radius R in list
sphere decoding (LSD) is derived. Based on it, we demonstrate that the
derandomized sampling algorithm is capable of achieving near-maximum a
posteriori (MAP) performance. Simulation results show that near-optimum
performance can be achieved by a moderate size K in both lattice decoding and
soft-output decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5764</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5764</id><created>2013-05-24</created><authors><author><keyname>Olmez</keyname><forenames>Oktay</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>Replication based storage systems with local repair</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of regenerating codes for distributed storage systems
that enjoy the property of local, exact and uncoded repair, i.e., (a) upon
failure, a node can be regenerated by simply downloading packets from the
surviving nodes and (b) the number of surviving nodes contacted is strictly
smaller than the number of nodes that need to be contacted for reconstructing
the stored file.
  Our codes consist of an outer MDS code and an inner fractional repetition
code that specifies the placement of the encoded symbols on the storage nodes.
For our class of codes, we identify the tradeoff between the local repair
property and the minimum distance. We present codes based on graphs of high
girth, affine resolvable designs and projective planes that meet the minimum
distance bound for specific choices of file sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5765</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5765</id><created>2013-05-24</created><updated>2013-06-11</updated><authors><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>Gray codes and Enumerative Coding for vector spaces</title><categories>cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gray codes for vector spaces are considered in two graphs: the Grassmann
graph, and the projective-space graph, both of which have recently found
applications in network coding. For the Grassmann graph, constructions of
cyclic optimal codes are given for all parameters. As for the projective-space
graph, two constructions for specific parameters are provided, as well some
non-existence results.
  Furthermore, encoding and decoding algorithms are given for the Grassmannian
Gray code, which induce an enumerative-coding scheme. The computational
complexity of the algorithms is at least as low as known schemes, and for
certain parameter ranges, the new scheme outperforms previously-known ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5777</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5777</id><created>2013-05-24</created><updated>2014-09-03</updated><authors><author><keyname>Friedland</keyname><forenames>Shmuel</forenames></author><author><keyname>Li</keyname><forenames>Qun</forenames></author><author><keyname>Schonfeld</keyname><forenames>Dan</forenames></author></authors><title>Compressive Sensing of Sparse Tensors</title><categories>cs.CV cs.IT math.IT</categories><comments>10 pages, 83 figures</comments><msc-class>15A69, 65D18, 68U05</msc-class><doi>10.1109/TIP.2014.2348796</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) has triggered enormous research activity since its
first appearance. CS exploits the signal's sparsity or compressibility in a
particular domain and integrates data compression and acquisition, thus
allowing exact reconstruction through relatively few non-adaptive linear
measurements. While conventional CS theory relies on data representation in the
form of vectors, many data types in various applications such as color imaging,
video sequences, and multi-sensor networks, are intrinsically represented by
higher-order tensors. Application of CS to higher-order data representation is
typically performed by conversion of the data to very long vectors that must be
measured using very large sampling matrices, thus imposing a huge computational
and memory burden. In this paper, we propose Generalized Tensor Compressive
Sensing (GTCS)--a unified framework for compressive sensing of higher-order
tensors which preserves the intrinsic structure of tensor data with reduced
computational complexity at reconstruction. GTCS offers an efficient means for
representation of multidimensional data by providing simultaneous acquisition
and compression from all tensor modes. In addition, we propound two
reconstruction procedures, a serial method (GTCS-S) and a parallelizable method
(GTCS-P). We then compare the performance of the proposed method with Kronecker
compressive sensing (KCS) and multi way compressive sensing (MWCS). We
demonstrate experimentally that GTCS outperforms KCS and MWCS in terms of both
reconstruction accuracy (within a range of compression ratios) and processing
speed. The major disadvantage of our methods (and of MWCS as well), is that the
compression ratios may be worse than that offered by KCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5782</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5782</id><created>2013-05-24</created><authors><author><keyname>Aicher</keyname><forenames>Christopher</forenames></author><author><keyname>Jacobs</keyname><forenames>Abigail Z.</forenames></author><author><keyname>Clauset</keyname><forenames>Aaron</forenames></author></authors><title>Adapting the Stochastic Block Model to Edge-Weighted Networks</title><categories>stat.ML cs.LG cs.SI physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the stochastic block model to the important case in which edges
are annotated with weights drawn from an exponential family distribution. This
generalization introduces several technical difficulties for model estimation,
which we solve using a Bayesian approach. We introduce a variational algorithm
that efficiently approximates the model's posterior distribution for dense
graphs. In specific numerical experiments on edge-weighted networks, this
weighted stochastic block model outperforms the common approach of first
applying a single threshold to all weights and then applying the classic
stochastic block model, which can obscure latent block structure in networks.
This model will enable the recovery of latent structure in a broader range of
network data than was previously possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5785</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5785</id><created>2013-05-24</created><authors><author><keyname>Srikumar</keyname><forenames>Vivek</forenames></author><author><keyname>Roth</keyname><forenames>Dan</forenames></author></authors><title>An Inventory of Preposition Relations</title><categories>cs.CL</categories><comments>Supplementary material for Srikumar and Roth, 2013. Modeling Semantic
  Relations Expressed by Prepositions, TACL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an inventory of semantic relations that are expressed by
prepositions. We define these relations by building on the word sense
disambiguation task for prepositions and propose a mapping from preposition
senses to the relation labels by collapsing semantically related senses across
prepositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5786</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5786</id><created>2013-05-24</created><updated>2013-09-24</updated><authors><author><keyname>Buliga</keyname><forenames>Marius</forenames></author></authors><title>Graphic lambda calculus</title><categories>cs.LO math.GT math.LO</categories><comments>v2: Minor typos and figure corrections in section 3. v1: Massive
  revision of all previous descriptions of graphic lambda calculus, based on
  arXiv:1207.0332 and arXiv:1302.0778, with a lot of material added and
  harmonized exposition</comments><journal-ref>Complex Systems 22, 4 (2013), 311-360</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce and study graphic lambda calculus, a visual language which can
be used for representing untyped lambda calculus, but it can also be used for
computations in emergent algebras or for representing Reidemeister moves of
locally planar tangle diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5794</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5794</id><created>2013-05-24</created><authors><author><keyname>Consolini</keyname><forenames>Luca</forenames></author><author><keyname>Maggiore</keyname><forenames>Manfredi</forenames></author></authors><title>Control of a Bicycle Using Virtual Holonomic Constraints</title><categories>math.OC cs.SY</categories><comments>18 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the problem of making Getz's bicycle model traverse a
strictly convex Jordan curve with bounded roll angle and bounded speed. The
approach to solving this problem is based on the virtual holonomic constraint
(VHC) method. Specifically, a VHC is enforced making the roll angle of the
bicycle become a function of the bicycle's position along the curve. It is
shown that the VHC can be automatically generated as a periodic solution of a
scalar periodic differential equation, which we call virtual constraint
generator. Finally, it is shown that if the curve is sufficiently long as
compared to the height of the bicycle's centre of mass and its wheel base, then
the enforcement of a suitable VHC makes the bicycle traverse the curve with a
steady-state speed profile which is periodic and independent of initial
conditions. An outcome of this work is a proof that the constrained dynamics of
a Lagrangian control system subject to a VHC are generally not Lagrangian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5796</identifier>
 <datestamp>2013-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5796</id><created>2013-05-24</created><updated>2013-07-18</updated><authors><author><keyname>Cioaca</keyname><forenames>Alexandru</forenames></author><author><keyname>Sandu</keyname><forenames>Adrian</forenames></author><author><keyname>de Sturler</keyname><forenames>Eric</forenames></author></authors><title>Efficient methods for computing observation impact in 4D-Var data
  assimilation</title><categories>cs.CE math.NA</categories><report-no>CSL-TR-2-2013</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a practical computational approach to quantify the effect
of individual observations in estimating the state of a system. Such an
analysis can be used for pruning redundant measurements, and for designing
future sensor networks. The mathematical approach is based on computing the
sensitivity of the reanalysis (unconstrained optimization solution) with
respect to the data. The computational cost is dominated by the solution of a
linear system, whose matrix is the Hessian of the cost function, and is only
available in operator form. The right hand side is the gradient of a scalar
cost function that quantifies the forecast error of the numerical model. The
use of adjoint models to obtain the necessary first and second order
derivatives is discussed. We study various strategies to accelerate the
computation, including matrix-free iterative solvers, preconditioners, and an
in-house multigrid solver. Experiments are conducted on both a small-size
shallow-water equations model, and on a large-scale numerical weather
prediction model, in order to illustrate the capabilities of the new
methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5800</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5800</id><created>2013-05-24</created><authors><author><keyname>Dice</keyname><forenames>Dave</forenames></author><author><keyname>Hendler</keyname><forenames>Danny</forenames></author><author><keyname>Mirsky</keyname><forenames>Ilya</forenames></author></authors><title>Lightweight Contention Management for Efficient Compare-and-Swap
  Operations</title><categories>cs.DC</categories><comments>25 pages, to be published in Euro-Par 2013 proceedings</comments><acm-class>D.1.3; D.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many concurrent data-structure implementations use the well-known
compare-and-swap (CAS) operation, supported in hardware by most modern
multiprocessor architectures for inter-thread synchronization. A key weakness
of the CAS operation is the degradation in its performance in the presence of
memory contention.
  In this work we study the following question: can software-based contention
management improve the efficiency of hardware-provided CAS operations? Our
performance evaluation establishes that lightweight contention management
support can greatly improve performance under medium and high contention levels
while typically incurring only small overhead when contention is low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5820</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5820</id><created>2013-05-24</created><authors><author><keyname>Piro</keyname><forenames>Robert</forenames></author></authors><title>Model Theoretic Characterisations of Description Logics</title><categories>cs.LO math.LO</categories><comments>PhD-Thesis submitted Aug 2012. PhD to be awarded</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This thesis studies the model theoretic properties of the Description Logics
(DLs) ALC, ALCI, ALCQ, as well as ALCO, ALCQO, ALCQIO and EL.
  TBoxes of ALC, ALCI and ALCQ are characterised as fragments of FO which are
invariant under global bisimulation and disjoint unions. The logics ALCO, ALCQO
and ALCQIO, which incorporate individuals, are characterised w.r.t. to the
class K of all interpretations which interpret individuals as singleton sets.
The characterisations for TBoxes of ALCO and ALCQO both require additionally
that an FO-sentence is, under certain circumstances, preserved under forward
generated subinterpretations. FO-sentences equivalent to ALCQIO-TBoxes, are -
due to ALCQIO's inverse roles - characterised similarly but are required to be
preserved under generated subinterpretations.
  EL as sub-boolean DL is characterised on concept level as the FO-fragment
which is preserved under simulation and preserved under direct products.
Equally valid is the characterisation by being preserved under simulation and
having minimal models. For EL-TBoxes, a global version of simulation was not
sufficient but FO-sentences of EL-TBoxes are invariant under global
equi-simulation, disjoint unions and direct products.
  For each of these description logics, the characteristic concepts are
explicated and the characterisation is accompanied by an investigation under
which notion of saturation the logic in hand enjoys the
Hennessy-and-Milner-Property.
  As application of the results we determine the minimal globally bisimilar
companion w.r.t. ALCQO-bisimulation and introduce the L1-to-L2-rewritability
problem for TBoxes, where L1 and L2 are (description) logics. The latter is the
problem to decide whether or not an L1-TBox can be equivalently expressed as
L2-TBox. We give algorithms which decide ALCI-to-ALC-rewritability and
ALC-to-EL-rewritability. (See also abstract in the thesis.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5823</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5823</id><created>2013-05-24</created><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames></author><author><keyname>Harutyunyan</keyname><forenames>Anna</forenames></author></authors><title>Maximum st-flow in directed planar graphs via shortest paths</title><categories>cs.DS cs.DM math.CO</categories><comments>20 pages, 4 figures. Short version to be published in proceedings of
  IWOCA'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimum cuts have been closely related to shortest paths in planar graphs via
planar duality - so long as the graphs are undirected. Even maximum flows are
closely related to shortest paths for the same reason - so long as the source
and the sink are on a common face. In this paper, we give a correspondence
between maximum flows and shortest paths via duality in directed planar graphs
with no constraints on the source and sink. We believe this a promising avenue
for developing algorithms that are more practical than the current
asymptotically best algorithms for maximum st-flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5824</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5824</id><created>2013-05-24</created><authors><author><keyname>Bouker</keyname><forenames>Slim</forenames></author><author><keyname>Saidi</keyname><forenames>Rabie</forenames></author><author><keyname>Yahia</keyname><forenames>Sadok Ben</forenames></author><author><keyname>Nguifo</keyname><forenames>Engelbert Mephu</forenames></author></authors><title>Towards a semantic and statistical selection of association rules</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The increasing growth of databases raises an urgent need for more accurate
methods to better understand the stored data. In this scope, association rules
were extensively used for the analysis and the comprehension of huge amounts of
data. However, the number of generated rules is too large to be efficiently
analyzed and explored in any further process. Association rules selection is a
classical topic to address this issue, yet, new innovated approaches are
required in order to provide help to decision makers. Hence, many interesting-
ness measures have been defined to statistically evaluate and filter the
association rules. However, these measures present two major problems. On the
one hand, they do not allow eliminating irrelevant rules, on the other hand,
their abun- dance leads to the heterogeneity of the evaluation results which
leads to confusion in decision making. In this paper, we propose a two-winged
approach to select statistically in- teresting and semantically incomparable
rules. Our statis- tical selection helps discovering interesting association
rules without favoring or excluding any measure. The semantic comparability
helps to decide if the considered association rules are semantically related
i.e comparable. The outcomes of our experiments on real datasets show promising
results in terms of reduction in the number of rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5826</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5826</id><created>2013-05-24</created><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Cao</keyname><forenames>Nannan</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Ouyang</keyname><forenames>Ruofei</forenames></author><author><keyname>Tan</keyname><forenames>Colin Keng-Yan</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author></authors><title>Parallel Gaussian Process Regression with Low-Rank Covariance Matrix
  Approximations</title><categories>stat.ML cs.DC cs.LG</categories><comments>29th Conference on Uncertainty in Artificial Intelligence (UAI 2013),
  Extended version with proofs, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian processes (GP) are Bayesian non-parametric models that are widely
used for probabilistic regression. Unfortunately, it cannot scale well with
large data nor perform real-time predictions due to its cubic time cost in the
data size. This paper presents two parallel GP regression methods that exploit
low-rank covariance matrix approximations for distributing the computational
load among parallel machines to achieve time efficiency and scalability. We
theoretically guarantee the predictive performances of our proposed parallel
GPs to be equivalent to that of some centralized approximate GP regression
methods: The computation of their centralized counterparts can be distributed
among parallel machines, hence achieving greater time efficiency and
scalability. We analytically compare the properties of our parallel GPs such as
time, space, and communication complexity. Empirical evaluation on two
real-world datasets in a cluster of 20 computing nodes shows that our parallel
GPs are significantly more time-efficient and scalable than their centralized
counterparts and exact/full GP while achieving predictive performances
comparable to full GP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5827</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5827</id><created>2013-05-24</created><authors><author><keyname>Shekhar</keyname><forenames>Monica</forenames></author><author><keyname>K</keyname><forenames>Saravanaguru RA.</forenames></author></authors><title>Semantic Web Search based on Ontology Modeling using Protege Reasoner</title><categories>cs.IR cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semantic Web works on the existing Web which presents the meaning of
information as well-defined vocabularies understood by the people. Semantic
Search, at the same time, works on improving the accuracy if a search by
understanding the intent of the search and providing contextually relevant
results. This paper describes a semantic approach toward web search through a
PHP application. The goal was to parse through a user's browsing history and
return semantically relevant web pages for the search query provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5829</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5829</id><created>2013-05-24</created><authors><author><keyname>Lai</keyname><forenames>Shu-Zhen</forenames></author><author><keyname>Li</keyname><forenames>Hou-Biao</forenames></author><author><keyname>Zhang</keyname><forenames>Zu-Tao</forenames></author></authors><title>A Symmetric Rank-one Quasi Newton Method for Non-negative Matrix
  Factorization</title><categories>math.NA cs.LG cs.NA</categories><comments>19 pages, 13 figures, Submitted to PP on Feb. 5, 2013</comments><msc-class>15A18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we all known, the nonnegative matrix factorization (NMF) is a dimension
reduction method that has been widely used in image processing, text
compressing and signal processing etc. In this paper, an algorithm for
nonnegative matrix approximation is proposed. This method mainly bases on the
active set and the quasi-Newton type algorithm, by using the symmetric rank-one
and negative curvature direction technologies to approximate the Hessian
matrix. Our method improves the recent results of those methods in [Pattern
Recognition, 45(2012)3557-3565; SIAM J. Sci. Comput., 33(6)(2011)3261-3281;
Neural Computation, 19(10)(2007)2756-2779, etc.]. Moreover, the object function
decreases faster than many other NMF methods. In addition, some numerical
experiments are presented in the synthetic data, imaging processing and text
clustering. By comparing with the other six nonnegative matrix approximation
methods, our experiments confirm to our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5859</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5859</id><created>2013-05-24</created><updated>2014-01-27</updated><authors><author><keyname>Lessard</keyname><forenames>Laurent</forenames></author><author><keyname>Lall</keyname><forenames>Sanjay</forenames></author></authors><title>Convexity of Decentralized Controller Synthesis</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In decentralized control problems, a standard approach is to specify the set
of allowable decentralized controllers as a closed subspace of linear
operators. This then induces a corresponding set of Youla parameters. Previous
work has shown that quadratic invariance of the controller set implies that the
set of Youla parameters is convex. In this paper, we prove the converse. We
thereby show that the only decentralized control problems for which the set of
Youla parameters is convex are those which are quadratically invariant. We
further show that under additional assumptions, quadratic invariance is
necessary and sufficient for the set of achievable closed-loop maps to be
convex. We give two versions of our results. The first applies to bounded
linear operators on a Banach space and the second applies to (possibly
unstable) causal LTI systems in discrete or continuous time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5884</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5884</id><created>2013-05-25</created><authors><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Ruan</keyname><forenames>Liangzhong</forenames></author><author><keyname>Chen</keyname><forenames>Junting</forenames></author><author><keyname>Xiao</keyname><forenames>Dengkun</forenames></author></authors><title>Hierarchical Radio Resource Optimization for Heterogeneous Networks with
  Enhanced Inter-cell Interference Coordination (eICIC)</title><categories>cs.IT math.IT</categories><comments>14 pages, 8 figures</comments><doi>10.1109/TSP.2014.2302748</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is a major performance bottleneck in Heterogeneous Network
(HetNet) due to its multi-tier topological structure. We propose almost blank
resource block (ABRB) for interference control in HetNet. When an ABRB is
scheduled in a macro BS, a resource block (RB) with blank payload is
transmitted and this eliminates the interference from this macro BS to the pico
BSs. We study a two timescale hierarchical radio resource management (RRM)
scheme for HetNet with dynamic ABRB control. The long term controls, such as
dynamic ABRB, are adaptive to the large scale fading at a RRM server for
co-Tier and cross-Tier interference control. The short term control (user
scheduling) is adaptive to the local channel state information within each BS
to exploit the multi-user diversity. The two timescale optimization problem is
challenging due to the exponentially large solution space. We exploit the
sparsity in the interference graph of the HetNet topology and derive structural
properties for the optimal ABRB control. Based on that, we propose a two
timescale alternative optimization solution for the user scheduling and ABRB
control. The solution has low complexity and is asymptotically optimal at high
SNR. Simulations show that the proposed solution has significant gain over
various baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5886</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5886</id><created>2013-05-25</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Homomorphic Encryption: Theory &amp; Applications</title><categories>cs.CR</categories><comments>Book Chapter accepted for publication in the book entitled: Theory
  and Practice of Cryptography and Network Security Protocols and Technologies,
  ISBN: 980-953-307-848-4, Sen, J. (Ed.), to be published by INTECH Publishers,
  Croatia. Expected month of publication: June 2013. This book chapter is a
  state of the art survey on homomorphic encryption mechanisms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this chapter is to present a survey of homomorphic encryption
techniques and their applications. After a detailed discussion on the
introduction and motivation of the chapter, we present some basic concepts of
cryptography. The fundamental theories of homomorphic encryption are then
discussed with suitable examples. The chapter then provides a survey of some of
the classical homomorphic encryption schemes existing in the current
literature. Various applications and salient properties of homomorphic
encryption schemes are then discussed in detail. The chapter then introduces
the most important and recent research direction in the filed - fully
homomorphic encryption. A significant number of propositions on fully
homomorphic encryption is then discussed. Finally, the chapter concludes by
outlining some emerging research trends in this exicting field of cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5901</identifier>
 <datestamp>2015-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5901</id><created>2013-05-25</created><updated>2015-07-02</updated><authors><author><keyname>Haddadpour</keyname><forenames>Farzin</forenames></author><author><keyname>Yassaee</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Beigi</keyname><forenames>Salman</forenames></author><author><keyname>Gohari</keyname><forenames>Amin</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Simulation of a Channel with Another Channel</title><categories>cs.IT math.IT</categories><comments>27 pages, 9 figures, and some parts of this work were published at
  ITW 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of simulating a DMC channel from another
DMC channel under an average-case and an exact model. We present several
achievability and infeasibility results, with tight characterizations in
special cases. In particular for the exact model, we fully characterize when a
BSC channel can be simulated from a BEC channel when there is no shared
randomness. We also provide infeasibility and achievability results for
simulation of a binary channel from another binary channel in the case of no
shared randomness. To do this, we use properties of R\'enyi capacity of a given
order. We also introduce a notion of &quot;channel diameter&quot; which is shown to be
additive and satisfy a data processing inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5905</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5905</id><created>2013-05-25</created><authors><author><keyname>Piater</keyname><forenames>Justus</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Antonio J. Rodr&#xed;guez</forenames></author></authors><title>\&quot;OAGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association
  for Pattern Recognition</title><categories>cs.CV</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</comments><report-no>OAGM-AAPR/2013/00</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this editorial, the organizers summarize facts and background about the
event.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5913</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5913</id><created>2013-05-25</created><authors><author><keyname>Khan</keyname><forenames>Fahd Ahmed</forenames></author><author><keyname>Tourki</keyname><forenames>Kamel</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Qaraqe</keyname><forenames>Khalid A.</forenames></author></authors><title>Performance of Opportunistic Fixed Gain Bidirectional Relaying With
  Outdated CSI</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the impact of using outdated channel state information for
relay selection on the performance of a network where two sources communicate
with each other via fixed-gain amplifyand- forward relays. For a Rayleigh faded
channel, closed-form expressions for the outage probability, moment generating
function and symbol error rate are derived. Simulations results are also
presented to corroborate the derived analytical results. It is shown that
adding relays does not improve the performance if the channel is substantially
outdated. Furthermore, relay location is also taken into consideration and it
is shown that the performance can be improved by placing the relay closer to
the source whose channel is more outdated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5918</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5918</id><created>2013-05-25</created><authors><author><keyname>Zhang</keyname><forenames>Kaixu</forenames></author><author><keyname>Sun</keyname><forenames>Maosong</forenames></author></authors><title>Reduce Meaningless Words for Joint Chinese Word Segmentation and
  Part-of-speech Tagging</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Conventional statistics-based methods for joint Chinese word segmentation and
part-of-speech tagging (S&amp;T) have generalization ability to recognize new words
that do not appear in the training data. An undesirable side effect is that a
number of meaningless words will be incorrectly created. We propose an
effective and efficient framework for S&amp;T that introduces features to
significantly reduce meaningless words generation. A general lexicon, Wikepedia
and a large-scale raw corpus of 200 billion characters are used to generate
word-based features for the wordhood. The word-lattice based framework consists
of a character-based model and a word-based model in order to employ our
word-based features. Experiments on Penn Chinese treebank 5 show that this
method has a 62.9% reduction of meaningless word generation in comparison with
the baseline. As a result, the F1 measure for segmentation is increased to
0.984.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5919</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5919</id><created>2013-05-25</created><authors><author><keyname>Wu</keyname><forenames>Baofeng</forenames></author><author><keyname>Zheng</keyname><forenames>Jia</forenames></author></authors><title>A remark on algebraic immunity of Boolean functions</title><categories>cs.CR</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, an equivalent definition of algebraic immunity of
Boolean functions is posed, which can clear up the confusion caused by the
proof of optimal algebraic immunity of the Carlet-Feng function and some other
functions constructed by virtue of Carlet and Feng's idea.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5934</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5934</id><created>2013-05-25</created><updated>2013-09-05</updated><authors><author><keyname>Suk</keyname><forenames>Andrew</forenames></author></authors><title>A note on order-type homogeneous point sets</title><categories>math.CO cs.CG</categories><doi>10.1112/S0025579313000247</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let OT_d(n) be the smallest integer N such that every N-element point
sequence in R^d in general position contains an order-type homogeneous subset
of size n, where a set is order-type homogeneous if all (d+1)-tuples from this
set have the same orientation. It is known that a point sequence in R^d that is
order-type homogeneous forms the vertex set of a convex polytope that is
combinatorially equivalent to a cyclic polytope in R^d. Two famous theorems of
Erdos and Szekeres from 1935 imply that OT_1(n) = Theta(n^2) and OT_2(n) =
2^(Theta(n)). For d \geq 3, we give new bounds for OT_d(n). In particular:
  1. We show that OT_3(n) = 2^(2^(Theta(n))), answering a question of
Eli\'a\v{s} and Matou\v{s}ek.
  2. For d \geq 4, we show that OT_d(n) is bounded above by an exponential
tower of height d with O(n) in the topmost exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5941</identifier>
 <datestamp>2014-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5941</id><created>2013-05-25</created><updated>2014-03-28</updated><authors><author><keyname>Huang</keyname><forenames>Yichen</forenames></author></authors><title>Computing quantum discord is NP-complete</title><categories>quant-ph cs.CC</categories><comments>The (published) journal version
  http://iopscience.iop.org/1367-2630/16/3/033027/article is more updated than
  the arXiv versions, and is accompanied with a general scientific summary for
  non-specialists in computational complexity</comments><journal-ref>New Journal of Physics 16, 033027 (2014)</journal-ref><doi>10.1088/1367-2630/16/3/033027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational complexity of quantum discord (a measure of
quantum correlation beyond entanglement), and prove that computing quantum
discord is NP-complete. Therefore, quantum discord is computationally
intractable: the running time of any algorithm for computing quantum discord is
believed to grow exponentially with the dimension of the Hilbert space so that
computing quantum discord in a quantum system of moderate size is not possible
in practice. As by-products, some entanglement measures (namely entanglement
cost, entanglement of formation, relative entropy of entanglement, squashed
entanglement, classical squashed entanglement, conditional entanglement of
mutual information, and broadcast regularization of mutual information) and
constrained Holevo capacity are NP-hard/NP-complete to compute. These
complexity-theoretic results are directly applicable in common randomness
distillation, quantum state merging, entanglement distillation, superdense
coding, and quantum teleportation; they may offer significant insights into
quantum information processing. Moreover, we prove the NP-completeness of two
typical problems: linear optimization over classical states and detecting
classical states in a convex set, providing evidence that working with
classical states is generically computationally intractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5946</identifier>
 <datestamp>2013-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5946</id><created>2013-05-25</created><updated>2013-12-17</updated><authors><author><keyname>Kong</keyname><forenames>Weihao</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Qin</keyname><forenames>Tao</forenames></author><author><keyname>Liu</keyname><forenames>Tie-Yan</forenames></author></authors><title>Optimal Groupon Allocations</title><categories>cs.GT cs.DS</categories><comments>Web and Internet Economics (WINE) 2013</comments><acm-class>G.2.1; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group-buying websites represented by Groupon.com are very popular in
electronic commerce and online shopping nowadays. They have multiple slots to
provide deals with significant discounts to their visitors every day. The
current user traffic allocation mostly relies on human decisions. We study the
problem of automatically allocating the user traffic of a group-buying website
to different deals to maximize the total revenue and refer to it as the
Group-buying Allocation Problem (\GAP). The key challenge of \GAP\ is how to
handle the tipping point (lower bound) and the purchase limit (upper bound) of
each deal. We formulate \GAP\ as a knapsack-like problem with variable-sized
items and majorization constraints. Our main results for \GAP\ can be
summarized as follows. (1) We first show that for a special case of \GAP, in
which the lower bound equals the upper bound for each deal, there is a simple
dynamic programming-based algorithm that can find an optimal allocation in
pseudo-polynomial time. (2) The general case of \GAP\ is much more difficult
than the special case. To solve the problem, we first discover several
structural properties of the optimal allocation, and then design a two-layer
dynamic programming-based algorithm leveraging those properties. This algorithm
can find an optimal allocation in pseudo-polynomial time. (3) We convert the
two-layer dynamic programming based algorithm to a fully polynomial time
approximation scheme (FPTAS), using the technique developed in
\cite{ibarra1975fast}, combined with some careful modifications of the dynamic
programs. Besides these results, we further investigate some natural
generalizations of \GAP, and propose effective algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5948</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5948</id><created>2013-05-25</created><authors><author><keyname>Galliani</keyname><forenames>Pietro</forenames></author><author><keyname>V&#xe4;&#xe4;n&#xe4;nen</keyname><forenames>Jouko</forenames></author></authors><title>On Dependence Logic</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an overview of some developments in dependence and independence
logic. This is a tiny selection, intended for a newcomer, from a rapidly
growing literature on the topic. Furthermore, we discuss conditional
independence atoms and we prove that conditional and non-conditional
independence logic are equivalent. Finally, we briefly discuss an application
of our logics to belief representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5950</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5950</id><created>2013-05-25</created><authors><author><keyname>Venkatesh</keyname><forenames>Sandeep</forenames></author><author><keyname>Balakuntala</keyname><forenames>Shreyas</forenames></author><author><keyname>S</keyname><forenames>Rajarajeswari</forenames></author><author><keyname>Shetty</keyname><forenames>Nytika N</forenames></author><author><keyname>Shetty</keyname><forenames>Namratha</forenames></author><author><keyname>Sudhakar</keyname><forenames>Neha</forenames></author></authors><title>Agent Based Intelligent Alert System for Smart-Phones</title><categories>cs.HC cs.CY cs.MA</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper deals with the design of an agent which modifies and enhances the
various alert systems in the smartphones. The actions of the agent includes
sorting the notifications abiding to human thinking, helping the user to have a
safe conversation, assisting in tracking back the reach-ability status of the
caller when needed, conveying the user about the notifications in times of
situations like drained battery and smartly alerting the user in situations
like sleeping. The agent uses the information gathered from a survey, to modify
the existing methods of alerts and produce alerts which abide by the human
cognitive responses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5956</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5956</id><created>2013-05-25</created><updated>2013-12-26</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>de Leeuw</keyname><forenames>Karl</forenames></author></authors><title>Questions related to Bitcoin and other Informational Money</title><categories>cs.CY</categories><comments>31 pages. In v2 the section on patterns for use and misuse has been
  improved and expanded with so-called contaminations. Other small improvements
  were made and 13 additional references have been included</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collection of questions about Bitcoin and its hypothetical relatives
Bitguilder and Bitpenny is formulated. These questions concern technical issues
about protocols, security issues, issues about the formalizations of
informational monies in various contexts, and issues about forms of use and
misuse. Some questions are formulated in the more general setting of
informational monies and near-monies.
  We also formulate questions about legal, psychological, and ethical aspects
of informational money. Finally we formulate a number of questions concerning
the economical merits of and outlooks for Bitcoin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5959</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5959</id><created>2013-05-25</created><updated>2013-06-11</updated><authors><author><keyname>AlSum</keyname><forenames>Ahmed</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>ArcLink: Optimization Techniques to Build and Retrieve the Temporal Web
  Graph</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Archiving the web is socially and culturally critical, but presents problems
of scale. The Internet Archive's Wayback Machine can replay captured web pages
as they existed at a certain point in time, but it has limited ability to
provide extensive content and structural metadata about the web graph. While
the live web has developed a rich ecosystem of APIs to facilitate web
applications (e.g., APIs from Google and Twitter), the web archiving community
has not yet broadly implemented this level of access.
  We present ArcLink, a proof-of-concept system that complements open source
Wayback Machine installations by optimizing the construction, storage, and
access to the temporal web graph. We divide the web graph construction into
four stages (filtering, extraction, storage, and access) and explore
optimization for each stage. ArcLink extends the current Web archive interfaces
to return content and structural metadata for each URI. We show how this API
can be applied to such applications as retrieving inlinks, outlinks,
anchortext, and PageRank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5960</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5960</id><created>2013-05-25</created><updated>2013-06-25</updated><authors><author><keyname>Huang</keyname><forenames>Sheng</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Coding for Computing Irreducible Markovian Functions of Sources with
  Memory</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One open problem in source coding is to characterize the limits of
representing losslessly a non-identity discrete function of the data encoded
independently by the encoders of several correlated sources with memory. This
paper investigates this problem under Markovian conditions, namely either the
sources or the functions considered are Markovian. We propose using linear
mappings over finite rings as encoders. If the function considered admits
certain polynomial structure, the linear encoders can make use of this
structure to establish &quot;implicit collaboration&quot; and boost the performance. In
fact, this approach universally applies to any scenario (arbitrary function)
because any discrete function admits a polynomial presentation of required
format.
  There are several useful discoveries in the paper. The first says that linear
encoder over non-field ring can be equally optimal for compressing data
generated by an irreducible Markov source. Secondly, regarding the previous
function-encoding problem, there are infinitely many circumstances where linear
encoder over non-field ring strictly outperforms its field counterpart. To be
more precise, it is seen that the set of coding rates achieved by linear
encoder over certain non-field rings is strictly larger than the one achieved
by the field version, regardless which finite field is considered. Therefore,
in this sense, linear coding over finite field is not optimal. In addition, for
certain scenarios where the sources do not possess the ergodic property, our
ring approach is still able to offer a solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5968</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5968</id><created>2013-05-25</created><updated>2013-10-14</updated><authors><author><keyname>Gabbay</keyname><forenames>Murdoch J.</forenames></author><author><keyname>Gabbay</keyname><forenames>Michael J.</forenames></author></authors><title>Representation and duality of the untyped lambda-calculus in nominal
  lattice and topological semantics, with a proof of topological completeness</title><categories>cs.LO math.LO</categories><acm-class>F.4.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a semantics for the lambda-calculus based on a topological duality
theorem in nominal sets. A novel interpretation of lambda is given in terms of
adjoints, and lambda-terms are interpreted absolutely as sets (no valuation is
necessary).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5970</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5970</id><created>2013-05-25</created><updated>2014-08-27</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author></authors><title>The Private Classical Capacity of a Partially Degradable Quantum Channel</title><categories>quant-ph cs.IT math.IT</categories><comments>10 pages, Journal-ref: Physica Scripta, Special Issue on Quantum
  Information (2014)</comments><doi>10.1088/0031-8949/2014/T163/014030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a partially degradable (PD) channel, the channel output state can be used
to simulate the degraded environment state. The quantum capacity of a PD
channel has been proven to be additive. Here, we show that the private
classical capacity of arbitrary dimensional PD channels is equal to the quantum
capacity of the channel and also single-letterizes. We prove that higher rates
of private classical communication can be achieved over a PD channel in
comparison to standard degradable channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5976</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5976</id><created>2013-05-25</created><authors><author><keyname>Jiang</keyname><forenames>Xinwen</forenames></author></authors><title>A Polynomial Time Algorithm for the Hamilton Circuit Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a so-called Multistage graph Simple Path (MSP)
problem and show that the Hamilton Circuit (HC) problem can be polynomially
reducible to the MSP problem. To solve the MSP problem, we propose a polynomial
algorithm and prove its NP-completeness. Our result implies NP=P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5981</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5981</id><created>2013-05-25</created><authors><author><keyname>Zhang</keyname><forenames>Daqiang</forenames></author><author><keyname>Zhu</keyname><forenames>Rongbo</forenames></author><author><keyname>Men</keyname><forenames>Shuqiqiu</forenames></author><author><keyname>Raychoudhury</keyname><forenames>Vaskar</forenames></author></authors><title>Query Representation with Global Consistency on User Click Graph</title><categories>cs.IR cs.HC cs.NI</categories><comments>accepted by Journal of Internet Technology on Sep. 9, 2012. To appear
  in Vol. 4, September, 2013</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extensive research has been conducted on query log analysis. A query log is
generally represented as a bipartite graph on a query set and a URL set. Most
of the traditional methods used the raw click frequency to weigh the link
between a query and a URL on the click graph. In order to address the
disadvantages of raw click frequency, researchers proposed the entropy-biased
model, which incorporates raw click frequency with inverse query frequency of
the URL as the weighting scheme for query representation. In this paper, we
observe that the inverse query frequency can be considered a global property of
the URL on the click graph, which is more informative than raw click frequency,
which can be considered a local property of the URL. Based on this insight, we
develop the global consistency model for query representation, which utilizes
the click frequency and the inverse query frequency of a URL in a consistent
manner. Furthermore, we propose a new scheme called inverse URL frequency as an
effective way to capture the global property of a URL. Experiments have been
conducted on the AOL search engine log data. The result shows that our global
consistency model achieved better performance than the current models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5992</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5992</id><created>2013-05-26</created><authors><author><keyname>Bloch</keyname><forenames>Matthieu R.</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author></authors><title>Strong Coordination over a Line Network</title><categories>cs.IT math.IT</categories><comments>To be presented at ISIT 2013, Istanbul, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of strong coordination in a three-terminal line network,
in which agents use common randomness and communicate over a line network to
ensure that their actions follow a prescribed behavior, modeled by a target
joint distribution of actions. We provide inner and outer bounds to the
coordination capacity region, and show that these bounds are partially optimal.
We leverage this characterization to develop insight into the interplay between
communication and coordination. Specifically, we show that common randomness
helps to achieve optimal communication rates between agents, and that matching
the network topology to the behavior structure may reduce inter-agent
communication rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5998</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5998</id><created>2013-05-26</created><updated>2013-07-18</updated><authors><author><keyname>Kolliopoulos</keyname><forenames>Stavros G.</forenames></author><author><keyname>Moysoglou</keyname><forenames>Yannis</forenames></author></authors><title>Integrality gaps for strengthened LP relaxations of Capacitated and
  Lower-Bounded Facility Location</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The metric uncapacitated facility location problem (UFL) enjoys a special
stature in approximation algorithms as a testbed for various techniques. Two
generalizations of UFL are capacitated facility location (CFL) and
lower-bounded facility location (LBFL). In the former, every facility has a
capacity which is the maximum demand that can be assigned to it, while in the
latter, every open facility is required to serve a given minimum amount of
demand. Both CFL and LBFL are approximable within a constant factor but their
respective natural LP relaxations have an unbounded integrality gap. According
to Shmoys and Williamson, the existence of a relaxation-based algorithm for CFL
is one of the top 10 open problems in approximation algorithms.
  In this paper we give the first results on this problem. We provide
substantial evidence against the existence of a good LP relaxation for CFL by
showing unbounded integrality gaps for two families of strengthened
formulations.
  The first family we consider is the hierarchy of LPs resulting from repeated
applications of the lift-and-project Lov\'{a}sz-Schrijver procedure starting
from the standard relaxation. We show that the LP relaxation for CFL resulting
after $\Omega(n)$ rounds, where $n$ is the number of facilities in the
instance, has unbounded integrality gap. Note that the Lov\'{a}sz-Schrijver
procedure is known to yield an exact formulation for CFL in at most $n$ rounds.
  We also introduce the family of proper relaxations which generalizes to its
logical extreme the classic star relaxation, an equivalent form of the natural
LP. We characterize the integrality gap of proper relaxations for both LBFL and
CFL and show a threshold phenomenon under which it decreases from unbounded to
1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6000</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6000</id><created>2013-05-26</created><authors><author><keyname>Duchi</keyname><forenames>John C.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</title><categories>math.ST cs.CR cs.IT math.IT stat.TH</categories><comments>27 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a detailed study of the estimation of probability
distributions---discrete and continuous---in a stringent setting in which data
is kept private even from the statistician. We give sharp minimax rates of
convergence for estimation in these locally private settings, exhibiting
fundamental tradeoffs between privacy and convergence rate, as well as
providing tools to allow movement along the privacy-statistical efficiency
continuum. One of the consequences of our results is that Warner's classical
work on randomized response is an optimal way to perform survey sampling while
maintaining privacy of the respondents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6003</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6003</id><created>2013-05-26</created><authors><author><keyname>Afifi</keyname><forenames>Wessam</forenames></author><author><keyname>Krunz</keyname><forenames>Marwan</forenames></author></authors><title>Exploiting Self-Interference Suppression for Improved Spectrum
  Awareness/Efficiency in Cognitive Radio Systems</title><categories>cs.NI cs.IT math.IT math.OC</categories><comments>9 pages, 12 figures, In Proceedings of the IEEE INFOCOM 2013
  Main-Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by recent developments in full-duplex communications, we propose and
study new modes of operation for cognitive radios with the goal of achieving
improved primary user (PU) detection and/or secondary user (SU) throughput.
Specifically, we consider an opportunistic PU/SU setting in which the SU is
equipped with partial/complete self-interference suppression (SIS), enabling it
to transmit and receive/sense at the same time. Following a brief sensing
period, the SU can operate in either simultaneous transmit-and-sense (TS) mode
or simultaneous transmit-and-receive (TR) mode. We analytically study the
performance metrics for the two modes, namely the detection and false-alarm
probabilities, the PU outage probability, and the SU throughput. From this
analysis, we evaluate the sensing-throughput tradeoff for both modes. Our
objective is to find the optimal sensing and transmission durations for the SU
that maximize its throughput subject to a given outage probability. We also
explore the spectrum awareness/efficiency tradeoff that arises from the two
modes by determining an efficient adaptive strategy for the SU link. This
strategy has a threshold structure, which depends on the PU traffic load. Our
study considers both perfect and imperfect sensing as well as perfect/imperfect
SIS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6010</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6010</id><created>2013-05-26</created><updated>2013-11-04</updated><authors><author><keyname>Hilman</keyname><forenames>M.</forenames></author><author><keyname>Setiadi</keyname><forenames>F.</forenames></author><author><keyname>Sarika</keyname><forenames>I.</forenames></author><author><keyname>Budiasto</keyname><forenames>J.</forenames></author><author><keyname>Alfian</keyname><forenames>R.</forenames></author></authors><title>Comparative Study of ERP Implementation Methodology Case Study:
  Accelerated SAP VS Dantes &amp; Hasibuan Methodology</title><categories>cs.OH</categories><comments>This paper has been withdrawn by the author due to acceptance in
  Jurnal Sistem Informasi, Vol.8, No.1, pp.8-15, April, 2012. link:
  http://jsi.cs.ui.ac.id/index.php/jsi/article/view/318</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enterprise Resource Planning (ERP) system is a concept of enterprise system
that describe the integration of the whole process in the organization. Study
in this field mostly about external development paradigm on information system
development. So, issue in ERP is all about how to adopt it in the organization,
not about the application development. This paper reviews two methodologies on
ERP system implementation, one is vendor perspective methodology and new
generic perspective methodology. Comparation of both methodology is done in
this study using certain metric measurements. Result is the vendor perspective
slightly superior than new generic perspective methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6011</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6011</id><created>2013-05-26</created><updated>2013-11-04</updated><authors><author><keyname>Hilman</keyname><forenames>Muhammad</forenames></author></authors><title>Information System as a Service: Issues and Challenges</title><categories>cs.OH</categories><comments>This paper has been withdrawn by the author due to the acceptance in
  Jurnal Sistem Informasi, Vol.8, No.2, pp.71-77, October, 2012. link:
  http://jsi.cs.ui.ac.id/index.php/jsi/article/view/328</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information system evolved as the evolution of information technology. The
current state of information technology, placed the internet as a main
resources of computing. Cloud technology as the backbone of internet has been
utilized as a powerful computing resources. Therefore, cloud introduced new
term of service oriented technology, popular with &quot;as a service&quot; kind of name.
In this paper, the service oriented paradigm will be used to address future
trend of information system. Thus, this paper try to introduce the term
&quot;information system as a service&quot;, holistic view of infrastructure as a
service, platform as a service, software as a service, and data as a service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6012</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6012</id><created>2013-05-26</created><authors><author><keyname>Cai</keyname><forenames>Sheng-Ming</forenames></author><author><keyname>Gong</keyname><forenames>Yi</forenames></author></authors><title>Cognitive Beamforming for Multiple Secondary Data Streams With
  Individual SNR Constraints</title><categories>cs.IT math.IT</categories><comments>This is the longer version of a paper to appear in the IEEE
  Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider cognitive beamforming for multiple secondary data
streams subject to individual signal-to-noise ratio (SNR) requirements for each
secondary data stream. In such a cognitive radio system, the secondary user is
permitted to use the spectrum allocated to the primary user as long as the
caused interference at the primary receiver is tolerable. With both secondary
SNR constraint and primary interference power constraint, we aim to minimize
the secondary transmit power consumption. By exploiting the individual SNR
requirements, we formulate this cognitive beamforming problem as an
optimization problem on the Stiefel manifold. Both zero forcing beamforming
(ZFB) and nonzero forcing beamforming (NFB) are considered. For the ZFB case,
we derive a closed form beamforming solution. For the NFB case, we prove that
the strong duality holds for the nonconvex primal problem and thus the optimal
solution can be easily obtained by solving the dual problem. Finally, numerical
results are presented to illustrate the performance of the proposed cognitive
beamforming solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6021</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6021</id><created>2013-05-26</created><updated>2013-11-11</updated><authors><author><keyname>Xu</keyname><forenames>Guangwu</forenames></author><author><keyname>Xu</keyname><forenames>Zhiqiang</forenames></author></authors><title>On the $\ell_1$-Norm Invariant Convex k-Sparse Decomposition of Signals</title><categories>cs.IT math.IT</categories><comments>Add some comments for the noise case</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by an interesting idea of Cai and Zhang, we formulate and prove the
convex $k$-sparse decomposition of vectors which is invariant with respect to
$\ell_1$ norm. This result fits well in discussing compressed sensing problems
under RIP, but we believe it also has independent interest. As an application,
a simple derivation of the RIP recovery condition $\delta_k+\theta_{k,k} &lt; 1$
is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6026</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6026</id><created>2013-05-26</created><authors><author><keyname>Abdel-Aty</keyname><forenames>Mahmoud</forenames></author></authors><title>New Index for Quantifying an Individual's Scientific Research Output</title><categories>cs.DL</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifying researchers according to the quality of their published work
rather than the quantity is a curtail issue. We attempt to introduce a new
formula of the percentage range to be used for evaluating qualitatively the
researchers' production. The suggested equation depends on the number of the
single-author published papers and their citations to be added as a new factor
to the known h-index. These factors give an advantage and make a clear evidence
of innovative authors and reduce the known h-index for authors who are gaining
citations by adding their names to multi-author papers. It is shown that
various dimensions of ethical integrity and originality will be effective in
this new index. An important scenario arising from the analysis is shown in
terms of examples. It refers to larger differences between the h- and the new
index which comes from the whole work and the one comes from the single-author
papers only, is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6037</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6037</id><created>2013-05-26</created><authors><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Semi-bounded Rationality: A model for decision making</title><categories>cs.AI q-fin.GN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the theory of semi-bounded rationality is proposed as an
extension of the theory of bounded rationality. In particular, it is proposed
that a decision making process involves two components and these are the
correlation machine, which estimates missing values, and the causal machine,
which relates the cause to the effect. Rational decision making involves using
information which is almost always imperfect and incomplete as well as some
intelligent machine which if it is a human being is inconsistent to make
decisions. In the theory of bounded rationality this decision is made
irrespective of the fact that the information to be used is incomplete and
imperfect and the human brain is inconsistent and thus this decision that is to
be made is taken within the bounds of these limitations. In the theory of
semi-bounded rationality, signal processing is used to filter noise and
outliers in the information and the correlation machine is applied to complete
the missing information and artificial intelligence is used to make more
consistent decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6045</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6045</id><created>2013-05-26</created><authors><author><keyname>Graziotin</keyname><forenames>Daniel</forenames><affiliation>Free University of Bozen-Bolzano, Italy</affiliation></author></authors><title>The Dynamics of Creativity in Software Development</title><categories>cs.SE</categories><comments>6 Pages. To be presented in the 14th International Conference on
  Product-Focused Software Process Improvement (PROFES 2013) - Doctoral
  Symposium, 12 June 2013, Paphos, Cyprus. This is the final, accepted version
  (after peer review)</comments><acm-class>H.1.2; D.2.9</acm-class><doi>10.6084/m9.figshare.703568</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Software is primarily developed for people by people and human factors must
be studied in all software engineering phases. Creativity is the source to
improvise solutions to problems for dominating complex systems such as software
development. However, there is a lack of knowledge in what creativity is in
software development and what its dynamics are. This study describes the
current state of the research plan towards a theory on creativity in software
development. More specifically, it (1) states the motivation for studying
creativity in software development under a multidisciplinary view; it (2)
provides a first review of the literature identifying the shortcomings in the
field; it (3) proposes a research design, which includes rarely employed
methods in software engineering. To understand creativity in software
development will provide a better knowledge of the software construction
process and how individuals intellectually contribute to the creation of
better, innovative products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6046</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6046</id><created>2013-05-26</created><authors><author><keyname>Mokeddem</keyname><forenames>Sidahmed</forenames></author><author><keyname>Atmani</keyname><forenames>Baghdad</forenames></author><author><keyname>Mokaddem</keyname><forenames>Mostefa</forenames></author></authors><title>Supervised Feature Selection for Diagnosis of Coronary Artery Disease
  Based on Genetic Algorithm</title><categories>cs.LG cs.CE</categories><comments>First International Conference on Computational Science and
  Engineering (CSE-2013), May 18 ~ 19, 2013, Dubai, UAE. Volume Editors:
  Sundarapandian Vaidyanathan, Dhinaharan Nagamalai</comments><doi>10.5121/csit.2013.3305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature Selection (FS) has become the focus of much research on decision
support systems areas for which data sets with tremendous number of variables
are analyzed. In this paper we present a new method for the diagnosis of
Coronary Artery Diseases (CAD) founded on Genetic Algorithm (GA) wrapped Bayes
Naive (BN) based FS. Basically, CAD dataset contains two classes defined with
13 features. In GA BN algorithm, GA generates in each iteration a subset of
attributes that will be evaluated using the BN in the second step of the
selection procedure. The final set of attribute contains the most relevant
feature model that increases the accuracy. The algorithm in this case produces
85.50% classification accuracy in the diagnosis of CAD. Thus, the asset of the
Algorithm is then compared with the use of Support Vector Machine (SVM),
MultiLayer Perceptron (MLP) and C4.5 decision tree Algorithm. The result of
classification accuracy for those algorithms are respectively 83.5%, 83.16% and
80.85%. Consequently, the GA wrapped BN Algorithm is correspondingly compared
with other FS algorithms. The Obtained results have shown very promising
outcomes for the diagnosis of CAD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6052</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6052</id><created>2013-05-26</created><updated>2013-08-05</updated><authors><author><keyname>Farmer</keyname><forenames>William M.</forenames></author></authors><title>The Formalization of Syntax-Based Mathematical Algorithms Using
  Quotation and Evaluation</title><categories>cs.LO</categories><comments>Appears in Intelligent Computer Mathematics (proceedings of CICM
  2013), Lecture Notes in Computer Science, Vol. 7961, pp. 35-50,
  Springer-Verlag, 2013. The final publication will be available at
  link.springer.com. This research was supported by NSERC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms like those for differentiating functional expressions manipulate
the syntactic structure of mathematical expressions in a mathematically
meaningful way. A formalization of such an algorithm should include a
specification of its computational behavior, a specification of its
mathematical meaning, and a mechanism for applying the algorithm to actual
expressions. Achieving these goals requires the ability to integrate reasoning
about the syntax of the expressions with reasoning about what the expressions
mean. A syntax framework is a mathematical structure that is an abstract model
for a syntax reasoning system. It contains a mapping of expressions to
syntactic values that represent the syntactic structures of the expressions; a
language for reasoning about syntactic values; a quotation mechanism to refer
to the syntactic value of an expression; and an evaluation mechanism to refer
to the value of the expression represented by a syntactic value. We present and
compare two approaches, based on instances of a syntax framework, to formalize
a syntax-based mathematical algorithm in a formal theory T. In the first
approach the syntactic values for the expressions manipulated by the algorithm
are members of an inductive type in T, but quotation and evaluation are
functions defined in the metatheory of T. In the second approach every
expression in T is represented by a syntactic value, and quotation and
evaluation are operators in T itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6067</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6067</id><created>2013-05-26</created><authors><author><keyname>Samsonov</keyname><forenames>Timofey E.</forenames></author><author><keyname>Semin</keyname><forenames>Vladimir N.</forenames></author><author><keyname>Konstantinov</keyname><forenames>Pavel I.</forenames></author><author><keyname>Varentzov</keyname><forenames>Mikhail I.</forenames></author></authors><title>Calculation of geometric characteristics of land cover and urban canyon
  for multi-scale parameterization of megalopolis meteorological models</title><categories>cs.OH</categories><comments>in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The results of studies on the development of computational techniques for
geometric and thematic characteristics of the underlying surface and urban
canyon are presented. These characteristics are intended for parameterization
of the local model of energy-mass exchange between the surface layer of the
atmosphere and the surface of the active layer of the underlying urban areas
(cities). Multiscale database of parameters of the underlying surface with a
resolution of 200, 500 and 1000 meters is obtained. The use of
micro-meteorology models that take into account the specificity of the urban
environment, coupled with mesoscale prognostic models will significantly
improve the sound quality of the meteorological fields and local operational
weather forecasting in the metropolitan areas where considering the
hydrometeorological situation is particularly important.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6074</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6074</id><created>2013-05-26</created><authors><author><keyname>Holzer</keyname><forenames>Andreas</forenames></author><author><keyname>Schallhart</keyname><forenames>Christian</forenames></author><author><keyname>Tautschnig</keyname><forenames>Michael</forenames></author><author><keyname>Veith</keyname><forenames>Helmut</forenames></author></authors><title>On the Structure and Complexity of Rational Sets of Regular Languages</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent thread of papers, we have introduced FQL, a precise specification
language for test coverage, and developed the test case generation engine
FShell for ANSI C. In essence, an FQL test specification amounts to a set of
regular languages, each of which has to be matched by at least one test
execution. To describe such sets of regular languages, the FQL semantics uses
an automata-theoretic concept known as rational sets of regular languages
(RSRLs). RSRLs are automata whose alphabet consists of regular expressions.
Thus, the language accepted by the automaton is a set of regular expressions.
  In this paper, we study RSRLs from a theoretic point of view. More
specifically, we analyze RSRL closure properties under common set theoretic
operations, and the complexity of membership checking, i.e., whether a regular
language is an element of a RSRL. For all questions we investigate both the
general case and the case of finite sets of regular languages. Although a few
properties are left as open problems, the paper provides a systematic semantic
foundation for the test specification language FQL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6076</identifier>
 <datestamp>2014-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6076</id><created>2013-05-26</created><updated>2014-02-20</updated><authors><author><keyname>Cui</keyname><forenames>Shawn X.</forenames></author><author><keyname>Freedman</keyname><forenames>Michael H.</forenames></author><author><keyname>Wang</keyname><forenames>Zhenghan</forenames></author></authors><title>Complexity Classes as Mathematical Axioms II</title><categories>cs.CC math.GT</categories><comments>To appear in Quantum Topology</comments><msc-class>57M25, 68Q15, 81P68</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second author previously discussed how classical complexity separation
conjectures, we call them &quot;axioms&quot;, have implications in three manifold
topology: polynomial length stings of operations which preserve certain Jones
polynomial evaluations cannot produce exponential simplifications of link
diagrams. In this paper, we continue this theme, exploring now more subtle
separation axioms for quantum complexity classes. Surprisingly, we now find
that similar strings are unable to effect even linear simplifications of the
diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6091</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6091</id><created>2013-05-26</created><authors><author><keyname>Li</keyname><forenames>William Wei-Liang</forenames><affiliation>Angela</affiliation></author><author><keyname>Shen</keyname><forenames>Yuan</forenames><affiliation>Angela</affiliation></author><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Robust power allocation for energy-efficient location aware networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless location-aware networks, mobile nodes (agents) typically obtain
their positions through ranging with respect to nodes with known positions
(anchors). Transmit power allocation not only affects network lifetime,
throughput, and interference, but also determines localization accuracy. In
this paper, we present an optimization framework for robust power allocation in
network localization to tackle imperfect knowledge of network parameters. In
particular, we formulate power allocation problems to minimize the squared
position error bound (SPEB) and the maximum directional position error bound
(mDPEB), respectively, for a given power budget. We show that such formulations
can be efficiently solved via conic programming. Moreover, we design an
efficient power allocation scheme that allows distributed computations among
agents. The simulation results show that the proposed schemes significantly
outperform uniform power allocation, and the robust schemes outperform their
non-robust counterparts when the network parameters are subject to uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6095</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6095</id><created>2013-05-26</created><authors><author><keyname>Yamamoto</keyname><forenames>Jun'ichi</forenames></author><author><keyname>I</keyname><forenames>Tomohiro</forenames></author><author><keyname>Bannai</keyname><forenames>Hideo</forenames></author><author><keyname>Inenaga</keyname><forenames>Shunsuke</forenames></author><author><keyname>Takeda</keyname><forenames>Masayuki</forenames></author></authors><title>Faster Compact On-Line Lempel-Ziv Factorization</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new on-line algorithm for computing the Lempel-Ziv factorization
of a string that runs in $O(N\log N)$ time and uses only $O(N\log\sigma)$ bits
of working space, where $N$ is the length of the string and $\sigma$ is the
size of the alphabet. This is a notable improvement compared to the performance
of previous on-line algorithms using the same order of working space but
running in either $O(N\log^3N)$ time (Okanohara &amp; Sadakane 2009) or
$O(N\log^2N)$ time (Starikovskaya 2012). The key to our new algorithm is in the
utilization of an elegant but less popular index structure called Directed
Acyclic Word Graphs, or DAWGs (Blumer et al. 1985). We also present an
opportunistic variant of our algorithm, which, given the run length encoding of
size $m$ of a string of length $N$, computes the Lempel-Ziv factorization
on-line, in $O\left(m \cdot \min \left\{\frac{(\log\log m)(\log \log
N)}{\log\log\log N}, \sqrt{\frac{\log m}{\log \log m}} \right\}\right)$ time
and $O(m\log N)$ bits of space, which is faster and more space efficient when
the string is run-length compressible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6108</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6108</id><created>2013-05-27</created><updated>2013-08-03</updated><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author></authors><title>Bounded Choice Queries for Logic Programming</title><categories>cs.PL</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adding versatile interactions to goals and queries in logic programming is an
essential task. Unfortunately, existing logic languages can take input from the
user only via the $read$ construct.
  We propose to add a new interactive goal to allow for more controlled and
more guided participation from the user. We illustrate our idea via \muprolog,
an extension of Prolog with bounded choice goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6110</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6110</id><created>2013-05-27</created><authors><author><keyname>Sekerinski</keyname><forenames>Emil</forenames><affiliation>McMaster University</affiliation></author><author><keyname>Zhang</keyname><forenames>Tian</forenames><affiliation>McMaster University</affiliation></author></authors><title>On a New Notion of Partial Refinement</title><categories>cs.LO</categories><comments>In Proceedings Refine 2013, arXiv:1305.5634</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 115, 2013, pp. 1-14</journal-ref><doi>10.4204/EPTCS.115.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal specification techniques allow expressing idealized specifications,
which abstract from restrictions that may arise in implementations. However,
partial implementations are universal in software development due to practical
limitations. Our goal is to contribute to a method of program refinement that
allows for partial implementations. For programs with a normal and an
exceptional exit, we propose a new notion of partial refinement which allows an
implementation to terminate exceptionally if the desired results cannot be
achieved, provided the initial state is maintained. Partial refinement leads to
a systematic method of developing programs with exception handling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6111</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6111</id><created>2013-05-27</created><authors><author><keyname>Dongol</keyname><forenames>Brijesh</forenames><affiliation>The University of Sheffield</affiliation></author><author><keyname>Derrick</keyname><forenames>John</forenames><affiliation>The University of Sheffield</affiliation></author></authors><title>Data refinement for true concurrency</title><categories>cs.LO</categories><comments>In Proceedings Refine 2013, arXiv:1305.5634</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 115, 2013, pp. 15-35</journal-ref><doi>10.4204/EPTCS.115.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The majority of modern systems exhibit sophisticated concurrent behaviour,
where several system components modify and observe the system state with
fine-grained atomicity. Many systems (e.g., multi-core processors, real-time
controllers) also exhibit truly concurrent behaviour, where multiple events can
occur simultaneously. This paper presents data refinement defined in terms of
an interval-based framework, which includes high-level operators that capture
non-deterministic expression evaluation. By modifying the type of an interval,
our theory may be specialised to cover data refinement of both discrete and
continuous systems. We present an interval-based encoding of forward
simulation, then prove that our forward simulation rule is sound with respect
to our data refinement definition. A number of rules for decomposing forward
simulation proofs over both sequential and parallel composition are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6112</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6112</id><created>2013-05-27</created><authors><author><keyname>Butler</keyname><forenames>Michael</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Colley</keyname><forenames>John</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Edmunds</keyname><forenames>Andrew</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Snook</keyname><forenames>Colin</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Evans</keyname><forenames>Neil</forenames><affiliation>AWE</affiliation></author><author><keyname>Grant</keyname><forenames>Neil</forenames><affiliation>AWE</affiliation></author><author><keyname>Marshall</keyname><forenames>Helen</forenames><affiliation>AWE</affiliation></author></authors><title>Modelling and Refinement in CODA</title><categories>cs.SE</categories><comments>In Proceedings Refine 2013, arXiv:1305.5634</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 115, 2013, pp. 36-51</journal-ref><doi>10.4204/EPTCS.115.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an overview of the CODA framework for modelling and
refinement of component-based embedded systems. CODA is an extension of Event-B
and UML-B and is supported by a plug-in for the Rodin toolset. CODA augments
Event-B with constructs for component-based modelling including components,
communications ports, port connectors, timed communications and timing
triggers. Component behaviour is specified through a combination of UML-B state
machines and Event-B. CODA communications and timing are given an Event-B
semantics through translation rules. Refinement is based on Event-B refinement
and allows layered construction of CODA models in a consistent way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6113</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6113</id><created>2013-05-27</created><authors><author><keyname>Zeyda</keyname><forenames>Frank</forenames><affiliation>University of York</affiliation></author><author><keyname>Cavalcanti</keyname><forenames>Ana</forenames><affiliation>University of York</affiliation></author></authors><title>Refining SCJ Mission Specifications into Parallel Handler Designs</title><categories>cs.LO cs.DC cs.PL</categories><comments>In Proceedings Refine 2013, arXiv:1305.5634</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 115, 2013, pp. 52-67</journal-ref><doi>10.4204/EPTCS.115.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Safety-Critical Java (SCJ) is a recent technology that restricts the
execution and memory model of Java in such a way that applications can be
statically analysed and certified for their real-time properties and safe use
of memory. Our interest is in the development of comprehensive and sound
techniques for the formal specification, refinement, design, and implementation
of SCJ programs, using a correct-by-construction approach. As part of this
work, we present here an account of laws and patterns that are of general use
for the refinement of SCJ mission specifications into designs of parallel
handlers used in the SCJ programming paradigm. Our notation is a combination of
languages from the Circus family, supporting state-rich reactive models with
the addition of class objects and real-time properties. Our work is a first
step to elicit laws of programming for SCJ and fits into a refinement strategy
that we have developed previously to derive SCJ programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6114</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6114</id><created>2013-05-27</created><authors><author><keyname>Am&#xe1;lio</keyname><forenames>Nuno</forenames><affiliation>University of Luxembourg</affiliation></author></authors><title>Relaxing Behavioural Inheritance</title><categories>cs.SE</categories><comments>In Proceedings Refine 2013, arXiv:1305.5634</comments><proxy>EPTCS</proxy><acm-class>D.2.4</acm-class><journal-ref>EPTCS 115, 2013, pp. 68-83</journal-ref><doi>10.4204/EPTCS.115.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented (OO) inheritance allows the definition of families of classes
in a hierarchical way. In behavioural inheritance, a strong version, it should
be possible to substitute an object of a subclass for an object of its
superclass without any observable effect on the system. Behavioural inheritance
is related to formal refinement, but, as observed in the literature, the
refinement constraints are too restrictive, ruling out many useful OO
subclassings. This paper studies behavioural inheritance in the context of ZOO,
an object-oriented style for Z. To overcome refinement's restrictions, this
paper proposes relaxations to the behavioural inheritance refinement rules. The
work is presented for Z, but the results are applicable to any OO language that
supports design-by-contract.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6115</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6115</id><created>2013-05-27</created><authors><author><keyname>Madeira</keyname><forenames>Alexandre</forenames><affiliation>Haslab-INESC TEC and Universidade do Minho</affiliation></author><author><keyname>Martins</keyname><forenames>Manuel A.</forenames><affiliation>CIDMA - Math. Department U. Aveiro</affiliation></author><author><keyname>Barbosa</keyname><forenames>Lu&#xed;s Soares</forenames><affiliation>Haslab-INESC TEC and Universidade do Minho</affiliation></author></authors><title>Bisimilarity and refinement for hybrid(ised) logics</title><categories>cs.LO</categories><comments>In Proceedings Refine 2013, arXiv:1305.5634</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 115, 2013, pp. 84-98</journal-ref><doi>10.4204/EPTCS.115.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of modern software systems entails the need for
reconfiguration mechanisms gov- erning the dynamic evolution of their execution
configurations in response to both external stimulus or internal performance
measures. Formally, such systems may be represented by transition systems whose
nodes correspond to the different configurations they may assume. Therefore,
each node is en- dowed with, for example, an algebra, or a first-order
structure, to precisely characterise the semantics of the services provided in
the corresponding configuration. Hybrid logics, which add to the modal
description of transition structures the ability to refer to specific states,
offer a generic framework to approach the specification and design of this sort
of systems. Therefore, the quest for suitable notions of equivalence and
refinement between models of hybrid logic specifications becomes fundamental to
any design discipline adopting this perspective. This paper contributes to this
effort from a distinctive point of view: instead of focussing on a specific
hybrid logic, the paper introduces notions of bisimilarity and refinement for
hybridised logics, i.e. standard specification logics (e.g. propositional,
equational, fuzzy, etc) to which modal and hybrid features were added in a
systematic way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6123</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6123</id><created>2013-05-27</created><authors><author><keyname>kumar</keyname><forenames>S. M. M. M Kalyan</forenames></author><author><keyname>Pradhan</keyname><forenames>Dr S C</forenames></author></authors><title>Building Internal Cloud at NIC : A Preview</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most of computing environments in the IT support organization like NIC
are designed to run in centralized datacentre. The centralized infrastructure
of various development projects are used to deploy their services on it and
connecting remotely to that datacentre from all the stations of organization.
Currently these servers are mostly underutilized due to the static and
conventional approaches used for accessing and utilizing of these resources.
The cloud patterns is much needful for optimizing resource utilization and
reducing the investments on unnecessary costs. So, we build up and prototyped a
private cloud system called nIC(NIC Internal Cloud) to leverage the benefits of
cloud environment. For this system we adopted the combination of various
techniques from open source software community. The user-base of nIC consists
developers, web and database admins, service providers and desktop users from
various projects in NIC. We can optimize the resource usage by customizing the
user based template services on these virtualized infrastructure. It will also
increases the flexibility of the managing and maintenance of the operations
like archiving, disaster recovery and scaling of resources. The open-source
approach is further decreases the enterprise costs. In this paper, we describe
the design and analysis of implementing issues on internal cloud environments
in NIC and similar organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6126</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6126</id><created>2013-05-27</created><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Problems on q-Analogs in Coding Theory</title><categories>cs.IT math.CO math.IT</categories><comments>arXiv admin note: text overlap with arXiv:0805.3528 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interest in $q$-analogs of codes and designs has been increased in the
last few years as a consequence of their new application in error-correction
for random network coding. There are many interesting theoretical, algebraic,
and combinatorial coding problems concerning these q-analogs which remained
unsolved. The first goal of this paper is to make a short summary of the large
amount of research which was done in the area mainly in the last few years and
to provide most of the relevant references. The second goal of this paper is to
present one hundred open questions and problems for future research, whose
solution will advance the knowledge in this area. The third goal of this paper
is to present and start some directions in solving some of these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6129</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6129</id><created>2013-05-27</created><authors><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Dolan</keyname><forenames>John M.</forenames></author><author><keyname>Khosla</keyname><forenames>Pradeep</forenames></author></authors><title>Information-Theoretic Approach to Efficient Adaptive Path Planning for
  Mobile Robotic Environmental Sensing</title><categories>cs.LG cs.AI cs.MA cs.RO</categories><comments>19th International Conference on Automated Planning and Scheduling
  (ICAPS 2009), Extended version with proofs, 11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research in robot exploration and mapping has focused on sampling
environmental hotspot fields. This exploration task is formalized by Low,
Dolan, and Khosla (2008) in a sequential decision-theoretic planning under
uncertainty framework called MASP. The time complexity of solving MASP
approximately depends on the map resolution, which limits its use in
large-scale, high-resolution exploration and mapping. To alleviate this
computational difficulty, this paper presents an information-theoretic approach
to MASP (iMASP) for efficient adaptive path planning; by reformulating the
cost-minimizing iMASP as a reward-maximizing problem, its time complexity
becomes independent of map resolution and is less sensitive to increasing robot
team size as demonstrated both theoretically and empirically. Using the
reward-maximizing dual, we derive a novel adaptive variant of maximum entropy
sampling, thus improving the induced exploration policy performance. It also
allows us to establish theoretical bounds quantifying the performance advantage
of optimal adaptive over non-adaptive policies and the performance quality of
approximately optimal vs. optimal adaptive policies. We show analytically and
empirically the superior performance of iMASP-based policies for sampling the
log-Gaussian process to that of policies for the widely-used Gaussian process
in mapping the hotspot field. Lastly, we provide sufficient conditions that,
when met, guarantee adaptivity has no benefit under an assumed environment
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6137</identifier>
 <datestamp>2013-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6137</id><created>2013-05-27</created><updated>2013-11-27</updated><authors><author><keyname>Madnani</keyname><forenames>Khushraj</forenames></author><author><keyname>Krishna</keyname><forenames>Shankara Narayanan</forenames></author><author><keyname>Pandya</keyname><forenames>Paritosh K.</forenames></author></authors><title>On the Decidability and Complexity of Some Fragments of Metric Temporal
  Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metric Temporal Logic, $\mtlfull$ is amongst the most studied real-time
logics. It exhibits considerable diversity in expressiveness and decidability
properties based on the permitted set of modalities and the nature of time
interval constraints $I$. \oomit{The classical results of Alur and Henzinger
showed that $\mtlfull$ is undecidable where as $\mitl$ which uses only
non-singular intervals $NS$ is decidable. In a surprizing result, Ouaknine and
Worrell showed that the satisfiability of $\mtl$ is decidable over finite
pointwise models, albeit with NPR decision complexity, whereas it remains
undecidable for infinite pointwise models or for continuous time.} In this
paper, we sharpen the decidability results by showing that the satisfiability
of $\mtlsns$ (where $NS$ denotes non-singular intervals) is also decidable over
finite pointwise strictly monotonic time. We give a satisfiability preserving
reduction from the logic $\mtlsns$ to decidable logic $\mtl$ of Ouaknine and
Worrell using the technique of temporal projections. We also investigate the
decidability of unary fragment $\mtlfullunary$ (a question posed by A.
Rabinovich) and show that $\mtlfut$ over continuous time as well as
$\mtlfullunary$ over finite pointwise time are both undecidable. Moreover,
$\mathsf{MTL}^{pw}[\fut_I]$ over finite pointwise models already has NPR lower
bound for satisfiability checking. We also compare the expressive powers of
some of these fragments using the technique of EF games for $\mathsf{MTL}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6143</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6143</id><created>2013-05-27</created><updated>2013-09-16</updated><authors><author><keyname>Narayanan</keyname><forenames>Vivek</forenames></author><author><keyname>Arora</keyname><forenames>Ishan</forenames></author><author><keyname>Bhatia</keyname><forenames>Arjun</forenames></author></authors><title>Fast and accurate sentiment classification using an enhanced Naive Bayes
  model</title><categories>cs.CL cs.IR cs.LG</categories><comments>8 pages, 2 figures</comments><acm-class>I.2.7</acm-class><journal-ref>Intelligent Data Engineering and Automated Learning IDEAL 2013
  Lecture Notes in Computer Science Volume 8206, 2013, pp 194-201</journal-ref><doi>10.1007/978-3-642-41278-3_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have explored different methods of improving the accuracy of a Naive Bayes
classifier for sentiment analysis. We observed that a combination of methods
like negation handling, word n-grams and feature selection by mutual
information results in a significant improvement in accuracy. This implies that
a highly accurate and fast sentiment classifier can be built using a simple
Naive Bayes model that has linear training and testing time complexities. We
achieved an accuracy of 88.80% on the popular IMDB movie reviews dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6146</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6146</id><created>2013-05-27</created><updated>2013-05-28</updated><authors><author><keyname>Dinh</keyname><forenames>Tien Tuan Anh</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>Streamforce: outsourcing access control enforcement for stream data to
  the clouds</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As tremendous amount of data being generated everyday from human activity and
from devices equipped with sensing capabilities, cloud computing emerges as a
scalable and cost-effective platform to store and manage the data. While
benefits of cloud computing are numerous, security concerns arising when data
and computation are outsourced to a third party still hinder the complete
movement to the cloud. In this paper, we focus on the problem of data privacy
on the cloud, particularly on access controls over stream data. The nature of
stream data and the complexity of sharing data make access control a more
challenging issue than in traditional archival databases. We present
Streamforce - a system allowing data owners to securely outsource their data to
the cloud. The owner specifies fine-grained policies which are enforced by the
cloud. The latter performs most of the heavy computations, while learning
nothing about the data. To this end, we employ a number of encryption schemes,
including deterministic encryption, proxy-based attribute based encryption and
sliding-window encryption. In Streamforce, access control policies are modeled
as secure continuous queries, which entails minimal changes to existing stream
processing engines, and allows for easy expression of a wide-range of policies.
In particular, Streamforce comes with a number of secure query operators
including Map, Filter, Join and Aggregate. Finally, we implement Streamforce
over an open source stream processing engine (Esper) and evaluate its
performance on a cloud platform. The results demonstrate practical performance
for many real-world applications, and although the security overhead is
visible, Streamforce is highly scalable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6151</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6151</id><created>2013-05-27</created><updated>2013-07-12</updated><authors><author><keyname>Truong</keyname><forenames>Kien T.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Effects of Channel Aging in Massive MIMO Systems</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE/KICS Journal of Communications and Networks,
  Special Issue on Massive MIMO, August, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MIMO communication may provide high spectral efficiency through the
deployment of a very large number of antenna elements at the base stations. The
gains from massive MIMO communication come from the use of multi-user MIMO on
the uplink and downlink, but with a large excess of antennas at the base
station compared to the number of served users. Initial work on massive MIMO
did not fully address several practical issues associated with its deployment.
This paper considers the impact of channel aging on the performance of massive
MIMO systems. The effects of channel variation are characterized as a function
of different system parameters assuming a simple model for the channel time
variations at the transmitter. Channel prediction is proposed to overcome
channel aging effects. The analytical results on aging show how capacity is
lost due to time variation in the channel. Numerical results in a multicell
network show that massive MIMO works even with some channel variation and that
channel prediction could partially overcome channel aging effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6161</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6161</id><created>2013-05-27</created><updated>2013-11-19</updated><authors><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Power Control for D2D Underlaid Cellular Networks: Modeling, Algorithms
  and Analysis</title><categories>cs.IT math.IT</categories><comments>12 pages, 6 figures, Submitted JSAC on D2D communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a device-to-device (D2D) underlaid cellular network
where an uplink cellular user communicates with the base station while multiple
direct D2D links share the uplink spectrum. This paper proposes a random
network model based on stochastic geometry and develops centralized and
distributed power control algorithms. The goal of the proposed power control
algorithms is two-fold: ensure the cellular users have sufficient coverage
probability by limiting the interference created by underlaid D2D users, while
also attempting to support as many D2D links as possible. For the distributed
power control method, expressions for the coverage probabilities of cellular
and D2D links are derived and a lower bound on the sum rate of the D2D links is
provided. The analysis reveals the impact of key system parameters on the
network performance. For example, the bottleneck of D2D underlaid cellular
networks is the cross-tier interference between D2D links and the cellular
user, not the D2D intra-tier interference. Numerical results show the gains of
the proposed power control algorithms and accuracy of the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6164</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6164</id><created>2013-05-27</created><authors><author><keyname>Aharoni</keyname><forenames>Ron</forenames></author><author><keyname>Charbit</keyname><forenames>Pierre</forenames></author><author><keyname>Howard</keyname><forenames>David</forenames></author></authors><title>On a Generalization of the Ryser-Brualdi-Stein Conjecture</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rainbow matching for (not necessarily distinct) sets F_1,...,F_k of
hypergraph edges is a matching consisting of k edges, one from each F_i. The
aim of the paper is twofold - to put order in the multitude of conjectures that
relate to this concept (some of them first presented here), and to present some
partial results on one of these conjectures, that seems central among them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6175</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6175</id><created>2013-05-27</created><authors><author><keyname>Chen</keyname><forenames>Shangdi</forenames></author><author><keyname>Zhao</keyname><forenames>Dawei</forenames></author></authors><title>New Construction of Authentication Codes with Arbitration from
  Pseudo-Symplectic Geometry over Finite Fields</title><categories>cs.CR</categories><comments>arXiv admin note: text overlap with arXiv:1302.3160 by other authors</comments><journal-ref>Ars Combinatoria, 2010, 97A: 453-465</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new construction of authentication codes with arbitration from
pseudo-symplectic geometry over finite fields is given. The parameters and the
probabilities of deceptions of the codes are also computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6184</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6184</id><created>2013-05-27</created><authors><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LAMA</affiliation></author></authors><title>Full abstraction for fair testing in CCS</title><categories>cs.LO</categories><comments>15 pages, to appear in CALCO '13. To appear Lecture notes in computer
  science (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work with Pous, we defined a semantics for CCS which may both be
viewed as an innocent presheaf semantics and as a concurrent game semantics. It
is here proved that a behavioural equivalence induced by this semantics on CCS
processes is fully abstract for fair testing equivalence. The proof relies on a
new algebraic notion called playground, which represents the 'rule of the
game'. From any playground, two languages, equipped with labelled transition
systems, are derived, as well as a strong, functional bisimulation between
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6187</identifier>
 <datestamp>2013-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6187</id><created>2013-05-27</created><updated>2013-07-23</updated><authors><author><keyname>Prestwich</keyname><forenames>S. D.</forenames></author></authors><title>Improved Branch-and-Bound for Low Autocorrelation Binary Sequences</title><categories>cs.AI</categories><comments>Journal paper in preparation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Low Autocorrelation Binary Sequence problem has applications in
telecommunications, is of theoretical interest to physicists, and has inspired
many optimisation researchers. Metaheuristics for the problem have progressed
greatly in recent years but complete search has not progressed since a
branch-and-bound method of 1996. In this paper we find four ways of improving
branch-and-bound, leading to a tighter relaxation, faster convergence to
optimality, and better empirical scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6190</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6190</id><created>2013-05-27</created><authors><author><keyname>Jozsa</keyname><forenames>Richard</forenames></author><author><keyname>Nest</keyname><forenames>Maarten Van den</forenames></author></authors><title>Classical simulation complexity of extended Clifford circuits</title><categories>quant-ph cs.CC</categories><comments>17 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clifford gates are a winsome class of quantum operations combining
mathematical elegance with physical significance. The Gottesman-Knill theorem
asserts that Clifford computations can be classically efficiently simulated but
this is true only in a suitably restricted setting. Here we consider Clifford
computations with a variety of additional ingredients: (a) strong vs. weak
simulation, (b) inputs being computational basis states vs. general product
states, (c) adaptive vs. non-adaptive choices of gates for circuits involving
intermediate measurements, (d) single line outputs vs. multi-line outputs. We
consider the classical simulation complexity of all combinations of these
ingredients and show that many are not classically efficiently simulatable
(subject to common complexity assumptions such as P not equal to NP). Our
results reveal a surprising proximity of classical to quantum computing power
viz. a class of classically simulatable quantum circuits which yields universal
quantum computation if extended by a purely classical additional ingredient
that does not extend the class of quantum processes occurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6195</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6195</id><created>2013-05-27</created><updated>2013-10-03</updated><authors><author><keyname>Luko&#x165;ka</keyname><forenames>Robert</forenames></author><author><keyname>Maz&#xe1;k</keyname><forenames>J&#xe1;n</forenames></author><author><keyname>Zhu</keyname><forenames>Xuding</forenames></author></authors><title>Maximum 4-degenerate subgraph of a planar graph</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is $k$-degenerate if it can be transformed into an empty graph by
subsequent removals of vertices of degree $k$ or less. We prove that every
connected planar graph with average degree $d \ge 2$ has a 4-degenerate induced
subgraph containing at least $(38-d)/36$ of its vertices. This shows that every
planar graph of order $n$ has a 4-degenerate induced subgraph of order more
than $8/9 \cdot n$. We also consider a local variation of this problem and show
that in every planar graph with at least 7 vertices, deleting a suitable vertex
allows us to subsequently remove at least 6 more vertices of degree four or
less.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6203</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6203</id><created>2013-05-27</created><authors><author><keyname>Dumitru</keyname><forenames>Iulia</forenames></author><author><keyname>Stamatescu</keyname><forenames>Grigore</forenames></author><author><keyname>Fagarasan</keyname><forenames>Ioana</forenames></author><author><keyname>Iliescu</keyname><forenames>Sergiu Stelian</forenames></author></authors><title>Dynamic Management Techniques for Increasing Energy Efficiency within a
  Data Center</title><categories>cs.DC</categories><comments>5 pages, 3 figures</comments><acm-class>C.0</acm-class><journal-ref>Proc. of the 1st UNITE Doctoral Symposium, pp. 129-133, Bucharest,
  Romania, 27-28 June, 2011, PRINTECH, ISSN 2247-6040</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ours days data centers provide the global community an indispensable
service: nearly unlimited access to almost any kind of information we can
imagine by supporting most Internet services such as: Web hosting and
E-commerce services. Because of their capacity and their work, data centers
have various impacts on the environment, but those related with the electricity
use are by far the most important. In this paper, we present several power and
energy management techniques for data centers and we will focus our attention
on techniques that are explicitly tailored to servers and their workloads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6204</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6204</id><created>2013-05-27</created><authors><author><keyname>Kugiumtzis</keyname><forenames>Dimitris</forenames></author></authors><title>Direct coupling information measure from non-uniform embedding</title><categories>physics.data-an cs.IT math.IT nlin.CD stat.ME</categories><comments>28 pages, 13 figures, 5 tables, accepted in Physical Review E</comments><doi>10.1103/PhysRevE.87.062918</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A measure to estimate the direct and directional coupling in multivariate
time series is proposed. The measure is an extension of a recently published
measure of conditional Mutual Information from Mixed Embedding (MIME) for
bivariate time series. In the proposed measure of Partial MIME (PMIME), the
embedding is on all observed variables, and it is optimized in explaining the
response variable. It is shown that PMIME detects correctly direct coupling,
and outperforms the (linear) conditional Granger causality and the partial
transfer entropy. We demonstrate that PMIME does not rely on significance test
and embedding parameters, and the number of observed variables has no effect on
its statistical accuracy, it may only slow the computations. The importance of
these points is shown in simulations and in an application to epileptic
multi-channel scalp EEG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6206</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6206</id><created>2013-05-27</created><authors><author><keyname>Farmer</keyname><forenames>William M.</forenames></author></authors><title>Chiron: A Set Theory with Types, Undefinedness, Quotation, and
  Evaluation</title><categories>math.LO cs.LO</categories><comments>154 pages. Published as SQRL Report No. 38, McMaster University, 2007
  (revised 2012). This research was supported by NSERC</comments><report-no>SQRL Report No. 38, McMaster University, 2007 (revised 2012)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chiron is a derivative of von-Neumann-Bernays-G\&quot;odel (NBG) set theory that
is intended to be a practical, general-purpose logic for mechanizing
mathematics. Unlike traditional set theories such as Zermelo-Fraenkel (ZF) and
NBG, Chiron is equipped with a type system, lambda notation, and definite and
indefinite description. The type system includes a universal type, dependent
types, dependent function types, subtypes, and possibly empty types. Unlike
traditional logics such as first-order logic and simple type theory, Chiron
admits undefined terms that result, for example, from a function applied to an
argument outside its domain or from an improper definite or indefinite
description. The most noteworthy part of Chiron is its facility for reasoning
about the syntax of expressions. Quotation is used to refer to a set called a
construction that represents the syntactic structure of an expression, and
evaluation is used to refer to the value of the expression that a construction
represents. Using quotation and evaluation, syntactic side conditions, schemas,
syntactic transformations used in deduction and computation rules, and other
such things can be directly expressed in Chiron. This paper presents the syntax
and semantics of Chiron, some definitions and simple examples illustrating its
use, a proof system for Chiron, and a notion of an interpretation of one theory
of Chiron in another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6211</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6211</id><created>2013-05-24</created><updated>2013-07-15</updated><authors><author><keyname>Paul</keyname><forenames>Snigdha</forenames></author><author><keyname>Joshi</keyname><forenames>Nisheeth</forenames></author><author><keyname>Mathur</keyname><forenames>Iti</forenames></author></authors><title>Development of a Hindi Lemmatizer</title><categories>cs.CL</categories><comments>International Journal of Computational Linguistics and Natural
  Language Processing, Vol 2, Issue 5, 2013</comments><journal-ref>International Journal of Computational Linguistics and Natural
  Language Processing, Vol 2, Issue 5, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We live in a translingual society, in order to communicate with people from
different parts of the world we need to have an expertise in their respective
languages. Learning all these languages is not at all possible; therefore we
need a mechanism which can do this task for us. Machine translators have
emerged as a tool which can perform this task. In order to develop a machine
translator we need to develop several different rules. The very first module
that comes in machine translation pipeline is morphological analysis. Stemming
and lemmatization comes under morphological analysis. In this paper we have
created a lemmatizer which generates rules for removing the affixes along with
the addition of rules for creating a proper root word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6213</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6213</id><created>2013-05-27</created><authors><author><keyname>Bercher</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LIGM</affiliation></author></authors><title>Some results on a $\chi$-divergence, an~extended~Fisher information
  and~generalized~Cram\'er-Rao inequalities</title><categories>cs.IT math.IT stat.ML</categories><proxy>ccsd</proxy><journal-ref>Geometric Sciences of Information, Paris : France (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modified $\chi^{\beta}$-divergence, give some of its properties,
and show that this leads to the definition of a generalized Fisher information.
We give generalized Cram\'er-Rao inequalities, involving this Fisher
information, an extension of the Fisher information matrix, and arbitrary norms
and power of the estimation error. In the case of a location parameter, we
obtain new characterizations of the generalized $q$-Gaussians, for instance as
the distribution with a given moment that minimizes the generalized Fisher
information. Finally we indicate how the generalized Fisher information can
lead to new uncertainty relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6215</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6215</id><created>2013-05-27</created><authors><author><keyname>Bercher</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LIGM</affiliation></author></authors><title>On some interrelations of generalized $q$-entropies and a generalized
  Fisher information, including a Cram\'er-Rao inequality</title><categories>cs.IT cond-mat.other math.IT stat.ML</categories><proxy>ccsd</proxy><journal-ref>Applied Stochastic Models and Data Analysis, Mataro (Barcelona) :
  Spain (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this communication, we describe some interrelations between generalized
$q$-entropies and a generalized version of Fisher information. In information
theory, the de Bruijn identity links the Fisher information and the derivative
of the entropy. We show that this identity can be extended to generalized
versions of entropy and Fisher information. More precisely, a generalized
Fisher information naturally pops up in the expression of the derivative of the
Tsallis entropy. This generalized Fisher information also appears as a special
case of a generalized Fisher information for estimation problems. Indeed, we
derive here a new Cram\'er-Rao inequality for the estimation of a parameter,
which involves a generalized form of Fisher information. This generalized
Fisher information reduces to the standard Fisher information as a particular
case. In the case of a translation parameter, the general Cram\'er-Rao
inequality leads to an inequality for distributions which is saturated by
generalized $q$-Gaussian distributions. These generalized $q$-Gaussians are
important in several areas of physics and mathematics. They are known to
maximize the $q$-entropies subject to a moment constraint. The Cram\'er-Rao
inequality shows that the generalized $q$-Gaussians also minimize the
generalized Fisher information among distributions with a fixed moment.
Similarly, the generalized $q$-Gaussians also minimize the generalized Fisher
information among distributions with a given $q$-entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6216</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6216</id><created>2013-05-27</created><updated>2013-08-01</updated><authors><author><keyname>Chandrasetty</keyname><forenames>Vikram Arkalgud</forenames></author><author><keyname>Aziz</keyname><forenames>Syed Mahfuzul</forenames></author></authors><title>Resource Efficient LDPC Decoders for Multimedia Communication</title><categories>cs.IT cs.MM math.IT</categories><comments>10 pages, 12 figures, 4 tables, submitted to Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving high image quality is an important aspect in an increasing number
of wireless multimedia applications. These applications require resource
efficient error correction hardware to detect and correct errors introduced by
the communication channel. This paper presents an innovative flexible
architecture for error correction using Low-Density Parity-Check (LDPC) codes.
The proposed partially-parallel decoder architecture utilizes a novel code
construction technique based on multi-level Hierarchical Quasi-Cyclic (HQC)
matrix with innovative layering of random sub-matrices. Simulation of a
high-level MATLAB model shows that the proposed HQC matrices have bit error
rate (BER) performance close to that of unstructured random matrices. The
proposed decoder has been implemented on FPGA. It is very resource efficient
and provides very high throughput compared to other decoders reported to date.
Performance evaluation of the decoder has been carried out by transmitting JPEG
images over an AWGN channel and comparing the quality of the reconstructed
images with those from other decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6228</identifier>
 <datestamp>2014-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6228</id><created>2013-05-27</created><updated>2013-09-04</updated><authors><author><keyname>Barber</keyname><forenames>Michael J.</forenames></author></authors><title>Detecting hierarchical and overlapping network communities using locally
  optimal modularity changes</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>10 pages; 4 tables, 3 figures</comments><journal-ref>European Physical Journal B, 86(385):1-9, 2013</journal-ref><doi>10.1140/epjb/e2013-40645-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agglomerative clustering is a well established strategy for identifying
communities in networks. Communities are successively merged into larger
communities, coarsening a network of actors into a more manageable network of
communities. The order in which merges should occur is not in general clear,
necessitating heuristics for selecting pairs of communities to merge. We
describe a hierarchical clustering algorithm based on a local optimality
property. For each edge in the network, we associate the modularity change for
merging the communities it links. For each community vertex, we call the
preferred edge that edge for which the modularity change is maximal. When an
edge is preferred by both vertices that it links, it appears to be the optimal
choice from the local viewpoint. We use the locally optimal edges to define the
algorithm: simultaneously merge all pairs of communities that are connected by
locally optimal edges that would increase the modularity, redetermining the
locally optimal edges after each step and continuing so long as the modularity
can be further increased. We apply the algorithm to model and empirical
networks, demonstrating that it can efficiently produce high-quality community
solutions. We relate the performance and implementation details to the
structure of the resulting community hierarchies. We additionally consider a
complementary local clustering algorithm, describing how to identify
overlapping communities based on the local optimality condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6229</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6229</id><created>2013-05-27</created><authors><author><keyname>Stamatescu</keyname><forenames>Grigore</forenames></author><author><keyname>Sg&#xe2;rciu</keyname><forenames>Valentin</forenames></author></authors><title>Integration of Wireless Sensor Networks with Virtual Instrumentation in
  a Residential Environment</title><categories>cs.NI</categories><comments>12 pages, 7 figures</comments><acm-class>C.3</acm-class><journal-ref>Scientific Bulletin, Series C: Electrical Engineering and Computer
  Science, Vol. 75, Iss. 2, pp. 41-52, 2013, ISSN 2286-3540</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach to integrate wireless sensor networks (WSN)
with the LabVIEW graphical development environment through a dedicated software
driver. As personal constribution, a system architecture and concept
implementation are described, in the context of a smart house monitoring
scenario. Data acquisition is performed via the deployed wireless sensor
network with focus on three main parameters: temperature, humidity and light.
The data logging, monitoring and control functions are realized through a
virtual instrumentation project. This also enables an easy-to-use user
interface and the accesibility of data through standards-based web server
technologies. The potential of remote monitoring and control through mobile
terminals is opened up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6238</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6238</id><created>2013-05-27</created><authors><author><keyname>Moot</keyname><forenames>Richard</forenames><affiliation>LaBRI</affiliation></author></authors><title>Extended Lambek calculi and first-order linear logic</title><categories>cs.CL cs.LO</categories><comments>Logic and Language, Allemagne (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First-order multiplicative intuitionistic linear logic (MILL1) can be seen as
an extension of the Lambek calculus. In addition to the fragment of MILL1 which
corresponds to the Lambek calculus (of Moot &amp; Piazza 2001), I will show
fragments of MILL1 which generate the multiple context-free languages and which
correspond to the Displacement calculus of Morrilll e.a.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6239</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6239</id><created>2013-05-27</created><authors><author><keyname>Chazal</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Glisse</keyname><forenames>Marc</forenames></author><author><keyname>Labru&#xe8;re</keyname><forenames>Catherine</forenames></author><author><keyname>Michel</keyname><forenames>Bertrand</forenames></author></authors><title>Optimal rates of convergence for persistence diagrams in Topological
  Data Analysis</title><categories>math.ST cs.CG cs.LG math.GT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational topology has recently known an important development toward
data analysis, giving birth to the field of topological data analysis.
Topological persistence, or persistent homology, appears as a fundamental tool
in this field. In this paper, we study topological persistence in general
metric spaces, with a statistical approach. We show that the use of persistent
homology can be naturally considered in general statistical frameworks and
persistence diagrams can be used as statistics with interesting convergence
properties. Some numerical experiments are performed in various contexts to
illustrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6244</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6244</id><created>2013-05-27</created><authors><author><keyname>Wei</keyname><forenames>Zhengchao</forenames></author><author><keyname>Ma</keyname><forenames>Zhi</forenames></author></authors><title>Easily Implemented Rate Compatible Reconciliation Protocol for Quantum
  Key Distribution</title><categories>quant-ph cs.CR</categories><comments>5 pagers, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconciliation is an important step to correct errors in Quantum Key
Distribution (QKD). In QKD, after comparing basis, two legitimate parties
possess two correlative keys which have some differences and they could obtain
identical keys through reconciliation. In this paper, we present a new rate
compatible reconciliation scheme based on Row Combining with Edge Variation
(RCEV) Low Density Parity Check (LDPC) codes which could change code rate
adaptively in noisy channel where error rate may change with time. Our scheme
is easy to implement and could get good efficiency compared to existing
schemes. Meanwhile, due to the inherent structure we use, the new scheme not
only saves memory space remarkably but also simplifies the decoder architecture
and accelerates the decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6249</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6249</id><created>2013-05-27</created><authors><author><keyname>Doroudi</keyname><forenames>Sherwin</forenames><affiliation>Tepper School of Business, Carnegie Mellon University</affiliation></author><author><keyname>Gopalakrishnan</keyname><forenames>Ragavendran</forenames><affiliation>Department of Computing and Mathematical Sciences, California Institute of Technology</affiliation></author></authors><title>A class of equivalent idle-time-order-based routing policies for
  heterogeneous multi-server systems</title><categories>cs.PF math.PR</categories><comments>Ongoing work</comments><msc-class>60K25, 68M20, 90B22, 90B36</msc-class><acm-class>D.4.8; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an M/M/N/K/FCFS system (N&gt;0, K&gt;=N), where the servers operate at
(possibly) heterogeneous service rates. In this situation, the steady state
behavior depends on the routing policy that is used to select which idle server
serves the next job in queue. We define a class of idle-time-order-based
policies (including, for example, Longest Idle Server First (LISF)) and show
that all policies in this class result in the same steady state behavior. In
particular, they are all equivalent to the naive Random routing policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6254</identifier>
 <datestamp>2015-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6254</id><created>2013-05-27</created><authors><author><keyname>Giovanidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author></authors><title>A Stochastic Geometry Framework for Analyzing Pairwise-Cooperative
  Cellular Networks</title><categories>cs.IT math.IT</categories><comments>54 pages, 23 figures</comments><journal-ref>IEEE Trans. on Wireless Communications. vol.14, no.2, pp.794-808,
  Feb. 2015</journal-ref><doi>10.1109/TWC.2014.2360196</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation in cellular networks has been recently suggested as a promising
scheme to improve system performance, especially for cell-edge users. In this
work, we use stochastic geometry to analyze cooperation models where the
positions of Base Stations (BSs) follow a Poisson point process distribution
and where Voronoi cells define the planar areas associated with them. For the
service of each user, either one or two BSs are involved. If two, these
cooperate by exchange of user data and channel related information with
conferencing over some backhaul link. Our framework generally allows variable
levels of channel information at the transmitters. In this paper we investigate
the case of limited channel state information for cooperation (channel phase,
second neighbour interference), but not the fully adaptive case which would
require considerable feedback. The total per-user transmission power is further
split between the two transmitters and a common message is encoded. The
decision for a user to choose service with or without cooperation is directed
by a family of geometric policies depending on its relative position to its two
closest base stations. An exact expression of the network coverage probability
is derived. Numerical evaluation allows one to analyze significant coverage
benefits compared to the non-cooperative case. As a conclusion, cooperation
schemes can improve system performance without exploitation of extra network
resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6256</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6256</id><created>2013-05-27</created><authors><author><keyname>Mryglod</keyname><forenames>O.</forenames></author><author><keyname>Kenna</keyname><forenames>R.</forenames></author><author><keyname>Holovatch</keyname><forenames>Yu.</forenames></author><author><keyname>Berche</keyname><forenames>B.</forenames></author></authors><title>Comparison of a citation-based indicator and peer review for absolute
  and specific measures of research-group excellence</title><categories>cs.DL physics.soc-ph</categories><comments>To be published in &quot;Scientometrics&quot;</comments><journal-ref>Scientometrics 97 (2013) 767-777</journal-ref><doi>10.1007/s11192-013-1058-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many different measures are used to assess academic research excellence and
these are subject to ongoing discussion and debate within the scientometric,
university-management and policy-making communities internationally. One topic
of continued importance is the extent to which citation-based indicators
compare with peer-review-based evaluation. Here we analyse the correlations
between values of a particular citation-based impact indicator and peer-review
scores in several academic disciplines, from natural to social sciences and
humanities. We perform the comparison for research groups rather than for
individuals. We make comparisons on two levels. At an absolute level, we
compare total impact and overall strength of the group as a whole. At a
specific level, we compare academic impact and quality, normalised by the size
of the group. We find very high correlations at the former level for some
disciplines and poor correlations at the latter level for all disciplines. This
means that, although the citation-based scores could help to describe
research-group strength, in particular for the so-called hard sciences, they
should not be used as a proxy for ranking or comparison of research groups.
Moreover, the correlation between peer-evaluated and citation-based scores is
weaker for soft sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6291</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6291</id><created>2013-05-27</created><updated>2016-01-05</updated><authors><author><keyname>Gabbay</keyname><forenames>Murdoch J.</forenames></author></authors><title>Semantics out of context: nominal absolute denotations for first-order
  logic and computation</title><categories>cs.LO math.LO</categories><acm-class>F.4.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Call a semantics for a language with variables absolute when variables map to
fixed entities in the denotation. That is, a semantics is absolute when the
denotation of a variable a is a copy of itself in the denotation. We give a
trio of lattice-based, sets-based, and algebraic absolute semantics to
first-order logic. Possibly open predicates are directly interpreted as lattice
elements / sets / algebra elements, subject to suitable interpretations of the
connectives and quantifiers. In particular, universal quantification &quot;forall
a.phi&quot; is interpreted using a new notion of &quot;fresh-finite&quot; limit and using a
novel dual to substitution.
  The interest of this semantics is partly in the non-trivial and beautiful
technical details, which also offer certain advantages over existing
semantics---but also the fact that such semantics exist at all suggests a new
way of looking at variables and the foundations of logic and computation, which
may be well-suited to the demands of modern computer science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6292</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6292</id><created>2013-05-27</created><updated>2014-01-06</updated><authors><author><keyname>Ranieri</keyname><forenames>Juri</forenames></author><author><keyname>Chebira</keyname><forenames>Amina</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Near-Optimal Sensor Placement for Linear Inverse Problems</title><categories>cs.IT math.IT</categories><comments>13 pages, accepted for publication on IEEE TSP</comments><doi>10.1109/TSP.2014.2299518</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classic problem is the estimation of a set of parameters from measurements
collected by only a few sensors. The number of sensors is often limited by
physical or economical constraints and their placement is of fundamental
importance to obtain accurate estimates. Unfortunately, the selection of the
optimal sensor locations is intrinsically combinatorial and the available
approximation algorithms are not guaranteed to generate good solutions in all
cases of interest. We propose FrameSense, a greedy algorithm for the selection
of optimal sensor locations. The core cost function of the algorithm is the
frame potential, a scalar property of matrices that measures the orthogonality
of its rows. Notably, FrameSense is the first algorithm that is near-optimal in
terms of mean square error, meaning that its solution is always guaranteed to
be close to the optimal one. Moreover, we show with an extensive set of
numerical experiments that FrameSense achieves state-of-the-art performance
while having the lowest computational cost, when compared to other greedy
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6298</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6298</id><created>2013-05-27</created><updated>2014-01-13</updated><authors><author><keyname>D'Alfonso</keyname><forenames>Lisi</forenames></author><author><keyname>Jeronimo</keyname><forenames>Gabriela</forenames></author><author><keyname>Solern&#xf3;</keyname><forenames>Pablo</forenames></author></authors><title>Effective Differential Nullstellensatz for Ordinary DAE Systems with
  Constant Coefficients</title><categories>math.AC cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give upper bounds for the differential Nullstellensatz in the case of
ordinary systems of differential algebraic equations over any field of
constants $K$ of characteristic $0$. Let $\vec{x}$ be a set of $n$ differential
variables, $\vec{f}$ a finite family of differential polynomials in the ring
$K\{\vec{x}\}$ and $f\in K\{\vec{x}\}$ another polynomial which vanishes at
every solution of the differential equation system $\vec{f}=0$ in any
differentially closed field containing $K$. Let $d:=\max\{\deg(\vec{f}),
\deg(f)\}$ and $\epsilon:=\max\{2,{\rm{ord}}(\vec{f}), {\rm{ord}}(f)\}$. We
show that $f^M$ belongs to the algebraic ideal generated by the successive
derivatives of $\vec{f}$ of order at most $L = (n\epsilon
d)^{2^{c(n\epsilon)^3}}$, for a suitable universal constant $c&gt;0$, and
$M=d^{n(\epsilon +L+1)}$. The previously known bounds for $L$ and $M$ are not
elementary recursive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6306</identifier>
 <datestamp>2014-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6306</id><created>2013-05-27</created><updated>2014-02-27</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>The Complexity of Approximately Counting Tree Homomorphisms</title><categories>cs.CC</categories><doi>10.1145/2600917</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two computational problems, parameterised by a fixed tree H.
#HomsTo(H) is the problem of counting homomorphisms from an input graph G to H.
#WHomsTo(H) is the problem of counting weighted homomorphisms to H, given an
input graph G and a weight function for each vertex v of G. Even though H is a
tree, these problems turn out to be sufficiently rich to capture all of the
known approximation behaviour in #P. We give a complete trichotomy for
#WHomsTo(H). If H is a star then #WHomsTo(H) is in FP. If H is not a star but
it does not contain a certain induced subgraph J_3 then #WHomsTo(H) is
equivalent under approximation-preserving (AP) reductions to #BIS, the problem
of counting independent sets in a bipartite graph. This problem is complete for
the class #RHPi_1 under AP-reductions. Finally, if H contains an induced J_3
then #WHomsTo(H) is equivalent under AP-reductions to #SAT, the problem of
counting satisfying assignments to a CNF Boolean formula. Thus, #WHomsTo(H) is
complete for #P under AP-reductions. The results are similar for #HomsTo(H)
except that a rich structure emerges if H contains an induced J_3. We show that
there are trees H for which #HomsTo(H) is #SAT-equivalent (disproving a
plausible conjecture of Kelk). There is an interesting connection between these
homomorphism-counting problems and the problem of approximating the partition
function of the ferromagnetic Potts model. In particular, we show that for a
family of graphs J_q, parameterised by a positive integer q, the problem
#HomsTo(H) is AP-interreducible with the problem of approximating the partition
function of the q-state Potts model. It was not previously known that the Potts
model had a homomorphism-counting interpretation. We use this connection to
obtain some additional upper bounds for the approximation complexity of
#HomsTo(J_q).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6325</identifier>
 <datestamp>2015-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6325</id><created>2013-05-27</created><updated>2013-08-13</updated><authors><author><keyname>Navarro</keyname><forenames>Cristobal A.</forenames></author><author><keyname>Canfora</keyname><forenames>Fabrizio</forenames></author><author><keyname>Kahler</keyname><forenames>Nancy Hitschfeld</forenames></author></authors><title>Multi-core computation of transfer matrices for strip lattices in the
  Potts model</title><categories>physics.comp-ph cond-mat.stat-mech cs.DC</categories><doi>10.1109/HPCC.and.EUC.2013.27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transfer-matrix technique is a convenient way for studying strip lattices
in the Potts model since the compu- tational costs depend just on the periodic
part of the lattice and not on the whole. However, even when the cost is
reduced, the transfer-matrix technique is still an NP-hard problem since the
time T(|V|, |E|) needed to compute the matrix grows ex- ponentially as a
function of the graph width. In this work, we present a parallel
transfer-matrix implementation that scales performance under multi-core
architectures. The construction of the matrix is based on several repetitions
of the deletion- contraction technique, allowing parallelism suitable to
multi-core machines. Our experimental results show that the multi-core
implementation achieves speedups of 3.7X with p = 4 processors and 5.7X with p
= 8. The efficiency of the implementation lies between 60% and 95%, achieving
the best balance of speedup and efficiency at p = 4 processors for actual
multi-core architectures. The algorithm also takes advantage of the lattice
symmetry, making the transfer matrix computation to run up to 2X faster than
its non-symmetric counterpart and use up to a quarter of the original space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6332</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6332</id><created>2013-05-27</created><authors><author><keyname>Erickson</keyname><forenames>Kristin Grace</forenames></author></authors><title>The Story of Telebrain: A multi-performer telematic platform for
  performatization</title><categories>cs.HC cs.ET cs.MM cs.PL</categories><comments>AISB symposium on Music and Unconventional Computing, conference
  proceedings 2013, Exeter, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents Telebrain, a browser-based performatization platform
invented for organizing real-time telematic performances. Performatization is
the human performance of algorithms. When computers and humans performatize
cooperatively, the human-computer interaction (HCI) becomes the location of
computation. Novel modes of machine-human communication are necessary for
organizing performatizations. Telebrain is designed to facilitate machine-human
languages. Capitalizing on the ubiquity and cross-platform compatibility of the
Internet, Telebrain is an open-source web application supporting PerPL
(Performer Programming Language), a human-interpreted configurable language of
multi-media instructions used to program performers. Telebrain facilitates a
variety of performance disciplines such as music, theater, dance, computational
performance, networked scoring (image and audio), prompted improvisation,
real-space multi-player gaming, collaborative transdisciplinary karaoke and
quantum square-dancing. (http://telebrain.org)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6336</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6336</id><created>2013-05-27</created><authors><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author><author><keyname>Sampaio-Neto</keyname><forenames>Raimundo</forenames></author></authors><title>Adaptive Reduced-Rank Processing Using a Projection Operator Based on
  Joint Iterative Optimization of Adaptive Filters For CDMA Interference
  Suppression</title><categories>cs.IT math.IT</categories><comments>4 figures. Published in SSP 2010. arXiv admin note: substantial text
  overlap with arXiv:1205.4390, arXiv:1304.7548</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel adaptive reduced-rank filtering scheme based on
the joint iterative optimization of adaptive filters. The proposed scheme
consists of a joint iterative optimization of a bank of full-rank adaptive
filters that constitutes the projection matrix and an adaptive reduced-rank
filter that operates at the output of the bank of filters. We describe minimum
mean-squared error (MMSE) expressions for the design of the projection matrix
and the reduced-rank filter and simple least-mean squares (LMS) adaptive
algorithms for its computationally efficient implementation. Simulation results
for a CDMA interference suppression application reveals that the proposed
scheme significantly outperforms the state-of-the-art reduced-rank schemes,
while requiring a significantly lower computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6339</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6339</id><created>2013-05-27</created><updated>2013-09-24</updated><authors><author><keyname>Kaur</keyname><forenames>Jasleen</forenames></author><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Universality of scholarly impact metrics</title><categories>cs.DL cs.SI physics.soc-ph</categories><comments>Accepted in Journal of Informetrics</comments><journal-ref>Journal of Informetrics, Volume 7, Issue 4, October 2012, Pages
  924-932, ISSN 1751-1577</journal-ref><doi>10.1016/j.joi.2013.09.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the growing use of impact metrics in the evaluation of scholars,
journals, academic institutions, and even countries, there is a critical need
for means to compare scientific impact across disciplinary boundaries.
Unfortunately, citation-based metrics are strongly biased by diverse field
sizes and publication and citation practices. As a result, we have witnessed an
explosion in the number of newly proposed metrics that claim to be &quot;universal.&quot;
However, there is currently no way to objectively assess whether a normalized
metric can actually compensate for disciplinary bias. We introduce a new method
to assess the universality of any scholarly impact metric, and apply it to
evaluate a number of established metrics. We also define a very simple new
metric hs, which proves to be universal, thus allowing to compare the impact of
scholars across scientific disciplines. These results move us closer to a
formal methodology in the measure of scholarly impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6349</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6349</id><created>2013-05-27</created><updated>2013-09-11</updated><authors><author><keyname>Faber</keyname><forenames>Vance</forenames></author></authors><title>Global communication algorithms for Cayley graphs</title><categories>math.CO cs.DS</categories><comments>25 pages</comments><msc-class>68M10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss several combinatorial problems that arise when one looks at
computational algorithms for highly symmetric networks of processors. More
specifically, we are interested in minimal times associated with four
communication tasks (defined more precisely below): universal broadcast, every
processor has a vector that it wishes to broadcast to all the others; universal
accumulation, every processor wishes to receive the sum of all the vectors
being sent to it by all the other processors; universal exchange, every
processor wishes to exchange a vector with each other processor; and global
summation, every processor wants the sum of the vectors in all the processors
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6350</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6350</id><created>2013-05-27</created><authors><author><keyname>Zhao</keyname><forenames>Dawei</forenames></author><author><keyname>Peng</keyname><forenames>Haipeng</forenames></author><author><keyname>Li</keyname><forenames>Shudong</forenames></author><author><keyname>Yang</keyname><forenames>Yixian</forenames></author></authors><title>An efficient dynamic ID based remote user authentication scheme using
  self-certified public keys for multi-server environment</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, Li et al. analyzed Lee et al.'s multi-server authentication scheme
and proposed a novel smart card and dynamic ID based remote user authentication
scheme for multi-server environments. They claimed that their scheme can resist
several kinds of attacks. However, through careful analysis, we find that Li et
al.'s scheme is vulnerable to stolen smart card and offline dictionary attack,
replay attack, impersonation attack and server spoofing attack. By analyzing
other similar schemes, we find that the certain type of dynamic ID based
multi-server authentication scheme in which only hash functions are used and no
registration center participates in the authentication and session key
agreement phase is hard to provide perfect efficient and secure authentication.
To compensate for these shortcomings, we improve the recently proposed Liao et
al.'s multi-server authentication scheme which is based on pairing and
self-certified public keys, and propose a novel dynamic ID based remote user
authentication scheme for multi-server environments. Liao et al.'s scheme is
found vulnerable to offline dictionary attack and denial of service attack, and
cannot provide user's anonymity and local password verification. However, our
proposed scheme overcomes the shortcomings of Liao et al.'s scheme. Security
and performance analyses show the proposed scheme is secure against various
attacks and has many excellent features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6355</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6355</id><created>2013-05-27</created><updated>2014-03-21</updated><authors><author><keyname>Karimi</keyname><forenames>S.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author></authors><title>On multi-time-step monolithic coupling algorithms for elastodynamics</title><categories>cs.NA math.NA</categories><doi>10.1016/j.jcp.2014.05.034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a way of constructing multi-time-step monolithic coupling methods
for elastodynamics. The governing equations for constrained multiple subdomains
are written in dual Schur form and enforce the continuity of velocities at
system time levels. The resulting equations will be in the form of
differential-algebraic equations. To crystallize the ideas we shall employ
Newmark family of time-stepping schemes. The proposed method can handle
multiple subdomains, and allows different time-steps as well as different time
stepping schemes from the Newmark family in different subdomains. We shall use
the energy method to assess the numerical stability, and quantify the influence
of perturbations under the proposed coupling method. We also discuss the
conditions under which the proposed method will be energy preserving, and the
conditions under which the method will be energy conserving. Several numerical
examples are presented to illustrate the accuracy and stability properties of
the proposed method. We shall also compare the proposed multi-time-step
coupling method with some other similar methods available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6358</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6358</id><created>2013-05-27</created><authors><author><keyname>Yunus</keyname><forenames>Melor Md</forenames></author><author><keyname>Tuan</keyname><forenames>Julian Lau Kiing</forenames></author><author><keyname>Salehi</keyname><forenames>Hadi</forenames></author></authors><title>Using Blogs to Promote Writing Skill in ESL Classroom</title><categories>cs.CY</categories><comments>5 pages</comments><journal-ref>Proceedings of the 4th International Conference on Education and
  Educational Technologies (EET '13), 109-113, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study provides details on the motivational factors for using blogs as an
essential tool to promote students writing skills in ESL classrooms. The study
aims to discuss how using blogs may be integrated into classroom activities to
promote students writing skills as well as polishing their skills. It would
also illustrate the features offered in blogs as well as the motivational
essence that is attached to the blogs. To achieve the aim of the study, a
semi-structured interview protocol was used to collect the required qualitative
data. The findings of the study would serve as an insistent reminder that the
blogs which have been clearly underlined in the curriculum should be
re-orchestrated more effectively again by the teachers of English as a Second
Language (ESL).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6360</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6360</id><created>2013-05-28</created><authors><author><keyname>Yunus</keyname><forenames>Melor Md</forenames></author><author><keyname>Salehi</keyname><forenames>Hadi</forenames></author><author><keyname>John</keyname><forenames>Dexter Sigan Anak</forenames></author></authors><title>Using Visual Aids as a Motivational Tool in Enhancing Students Interest
  in Reading Literary Texts</title><categories>cs.CY</categories><comments>4 Pages</comments><journal-ref>Proceedings of the 4th International Conference on Education and
  Educational Technologies (EET '13), 114-117, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study aims to investigate the teachers perceptions on the use of visual
aids (e.g., animation videos, pictures, films and projectors) as a motivational
tool in enhancing students interest in reading literary texts. To achieve the
aim of the study, the mixed-method approach was used to collect the required
data. Therefore, 52 English teachers from seven national secondary schools in
Kapit, Sarawak, Malaysia were selected. Five of the respondents were also
randomly selected for the interview. The analysis of the data indicated that
the majority of the teachers had positive perceptions of the use of visual
aids. The use of visual aids enable the teachers to engage their students
closely with the literary texts despite of being able to facilitate students of
different English proficiency level in reading the texts with interest. This
aspect is vital as literature helps to generate students creative and critical
thinking skills. Although the teachers had positive attitudes towards the use
of visual aids, the study suggests that it will be more interesting and precise
if it includes students perceptions as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6364</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6364</id><created>2013-05-28</created><authors><author><keyname>Liang</keyname><forenames>Xiao</forenames></author><author><keyname>Zhao</keyname><forenames>Jichang</forenames></author><author><keyname>Dong</keyname><forenames>Li</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Unraveling the origin of exponential law in intra-urban human mobility</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Scientific Reports 3, 2983, 2013</journal-ref><doi>10.1038/srep02983</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast majority of travel takes place within cities. Recently, new data has
become available which allows for the discovery of urban mobility patterns
which differ from established results about long distance travel. Specifically,
the latest evidence increasingly points to exponential trip length
distributions, contrary to the scaling laws observed on larger scales. In this
paper, in order to explore the origin of the exponential law, we propose a new
model which can predict individual flows in urban areas better. Based on the
model, we explain the exponential law of intra-urban mobility as a result of
the exponential decrease in average population density in urban areas. Indeed,
both empirical and analytical results indicate that the trip length and the
population density share the same exponential decaying rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6376</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6376</id><created>2013-05-28</created><authors><author><keyname>Vanderzwet</keyname><forenames>Frank</forenames></author></authors><title>Fractional Pebbling Game Lower Bounds</title><categories>cs.CC cs.DS</categories><comments>Graduate Research Paper for University of Toronto. Completion of
  paper assisted by Professor Stephen Cook and Professor Toniann Pitassi</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractional pebbling is a generalization of black-white pebbling introduced
recently. In this reasearch paper we solve an open problem by proving a tight
lower bound on the pebble weight required to fractionally pebble a balanced
d-ary tree of height h. This bound has close ties with branching programs and
the separation of P from NL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6379</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6379</id><created>2013-05-28</created><authors><author><keyname>Nguyen</keyname><forenames>Minh H-T</forenames></author><author><keyname>Tan</keyname><forenames>Kok Kiong</forenames></author><author><keyname>Liang</keyname><forenames>Wenyu</forenames></author><author><keyname>Teo</keyname><forenames>Chek Sing</forenames></author></authors><title>Robust Precision Positioning Control on Linear Ultrasonic Motor</title><categories>cs.SY</categories><comments>6 pages, 8 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasonic motors used in high-precision mechatronics are characterized by
strong frictional effects, which are among the main problems in precision
motion control. The traditional methods apply model-based nonlinear feedforward
to compensate the friction, thus requiring closed-loop stability and safety
constraint considerations. Implementation of these methods requires complex
designed experiments. This paper introduces a systematic approach using
piecewise affine models to emulate the friction effect of the motor motion. The
well-known model predictive control method is employed to deal with piecewise
affine models. The increased complexity of the model offers a higher tracking
precision on a simpler gain scheduling scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6387</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6387</id><created>2013-05-28</created><updated>2015-11-16</updated><authors><author><keyname>Kappes</keyname><forenames>Joerg Hendrik</forenames></author><author><keyname>Speth</keyname><forenames>Markus</forenames></author><author><keyname>Reinelt</keyname><forenames>Gerhard</forenames></author><author><keyname>Schnoerr</keyname><forenames>Christoph</forenames></author></authors><title>Higher-order Segmentation via Multicuts</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicuts enable to conveniently represent discrete graphical models for
unsupervised and supervised image segmentation, in the case of local energy
functions that exhibit symmetries. The basic Potts model and natural extensions
thereof to higher-order models provide a prominent class of such objectives,
that cover a broad range of segmentation problems relevant to image analysis
and computer vision. We exhibit a way to systematically take into account such
higher-order terms for computational inference. Furthermore, we present results
of a comprehensive and competitive numerical evaluation of a variety of
dedicated cutting-plane algorithms. Our approach enables the globally optimal
evaluation of a significant subset of these models, without compromising
runtime. Polynomially solvable relaxations are studied as well, along with
advanced rounding schemes for post-processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6390</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6390</id><created>2013-05-28</created><authors><author><keyname>Sun</keyname><forenames>Yu-e</forenames></author><author><keyname>Huang</keyname><forenames>He</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Chen</keyname><forenames>Zhili</forenames></author><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Hongli</forenames></author><author><keyname>Huang</keyname><forenames>Liusheng</forenames></author></authors><title>Near-Optimal Truthful Auction Mechanisms in Secondary Spectrum Markets</title><categories>cs.NI cs.DS cs.GT</categories><comments>9 pages, 7 figures</comments><acm-class>C.2.1; D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study spectrum auction problem where each request from
secondary users has spatial, temporal, and spectral features. With the requests
of secondary users and the reserve price of the primary user, our goal is to
design truthful mechanisms that will either maximize the social efficiency or
maximize the revenue of the primary user. As the optimal conflict-free spectrum
allocation problem is NP-hard, in this work, we design near optimal spectrum
allocation mechanisms separately based on the following techniques:
derandomized allocation from integer programming formulation, its linear
programming (LP) relaxation, and the dual of the LP. We theoretically prove
that 1) our near optimal allocation methods are bid monotone, which implys
truthful auction mechanisms; and 2) our near optimal allocation methods can
achieve a social efficiency or a revenue that is at least $1-\frac{1}{e}$ times
of the optimal respectively. At last, we conduct extensive simulations to study
the performances (social efficiency, revenue) of the proposed methods, and the
simulation results corroborate our theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6394</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6394</id><created>2013-05-28</created><authors><author><keyname>Nguyen</keyname><forenames>Minh Hoang-Tuan</forenames></author><author><keyname>Tan</keyname><forenames>Kok Kiong</forenames></author><author><keyname>Huang</keyname><forenames>Sunan</forenames></author></authors><title>Enhanced Predictive Ratio Control of Interacting Systems</title><categories>cs.SY</categories><comments>9 pages, 7 figures, 1 table</comments><journal-ref>Journal of Process Control, Volume 21, Issue 7, August 2011, Pages
  1115 to 1125</journal-ref><doi>10.1016/j.jprocont.2011.04.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ratio control for two interacting processes is proposed with a PID
feedforward design based on model predictive control (MPC) scheme. At each
sampling instant, the MPC control action minimizes a state-dependent
performance index associated with a PID-type state vector, thus yielding a
PID-type control structure. Compared to the standard MPC formulations with
separated single-variable control, such a control action allows one to take
into account the non-uniformity of the two process outputs. After reformulating
the MPC control law as a PID control law, we provide conditions for prediction
horizon and weighting matrices so that the closed-loop control is
asymptotically stable, and show the e?ectiveness of the approach with
simulation and experiment results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6395</identifier>
 <datestamp>2014-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6395</id><created>2013-05-28</created><updated>2014-12-01</updated><authors><author><keyname>Badkobeh</keyname><forenames>Golnaz</forenames></author><author><keyname>Fici</keyname><forenames>Gabriele</forenames></author><author><keyname>Lipt&#xe1;k</keyname><forenames>Zsuzsanna</forenames></author></authors><title>On the Number of Closed Factors in a Word</title><categories>cs.FL math.CO</categories><comments>Accepted to LATA 2015</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A closed word (a.k.a. periodic-like word or complete first return) is a word
whose longest border does not have internal occurrences, or, equivalently,
whose longest repeated prefix is not right special. We investigate the
structure of closed factors of words. We show that a word of length $n$
contains at least $n+1$ distinct closed factors, and characterize those words
having exactly $n+1$ closed factors. Furthermore, we show that a word of length
$n$ can contain $\Theta(n^{2})$ many distinct closed factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6402</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6402</id><created>2013-05-28</created><authors><author><keyname>Nguyen</keyname><forenames>Minh Hoang-Tuan</forenames></author><author><keyname>Tan</keyname><forenames>Kok Kiong</forenames></author></authors><title>From Parametric Model-based Optimization to robust PID Gain Scheduling</title><categories>cs.SY</categories><comments>7 pages, 5 figures, submitted to JPC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In chemical process applications, model predictive control effectively deals
with input and state constraints during transient operations. However,
industrial PID controllers directly manipulates the actuators, so they play the
key role in small perturbation robustness. This paper considers the problem of
augmenting the commonplace PID with the constraint handling and optimization
functionalities of MPC. First, we review the MPC framework, which employs a
linear feedback gain in its unconstrained region. This linear gain can be any
preexisting multiloop PID design, or based on the two stabilizing PI or PID
designs for multivariable systems proposed in the paper. The resulting
controller is a feedforward PID mapping, a straightforward form without the
need of tuning PID to fit an optimal input. The parametrized solution of MPC
under constraints further leverages a familiar PID gain scheduling structure.
Steady state robustness is achieved along with the PID design so that
additional robustness analysis is avoided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6425</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6425</id><created>2013-05-28</created><authors><author><keyname>Cerri</keyname><forenames>Andrea</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Stability of persistence spaces of vector-valued continuous functions</title><categories>math.DS cs.CG</categories><msc-class>Primary 68U05, Secondary 55N05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional persistence modules do not admit a concise representation
analogous to that provided by persistence diagrams for real-valued functions.
However, there is no obstruction for multidimensional persistent Betti numbers
to admit one. Therefore, it is reasonable to look for a generalization of
persistence diagrams concerning those properties that are related only to
persistent Betti numbers. In this paper, the persistence space of a
vector-valued continuous function is introduced to generalize the concept of
persistence diagram in this sense. The main result is its stability under
function perturbations: any change in vector-valued functions implies a not
greater change in the Hausdorff distance between their persistence spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6429</identifier>
 <datestamp>2014-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6429</id><created>2013-05-28</created><updated>2014-11-10</updated><authors><author><keyname>Small</keyname><forenames>Michael</forenames></author><author><keyname>Li</keyname><forenames>Yingying</forenames></author><author><keyname>Stemler</keyname><forenames>Thomas</forenames></author><author><keyname>Judd</keyname><forenames>Kevin</forenames></author></authors><title>Super-star networks: Growing optimal scale-free networks via likelihood</title><categories>nlin.AO cs.SI physics.soc-ph</categories><comments>Draft - extended version of invited talks given in 2013 at Shanghai
  University, Fudan and Aristotle University of Thessaloniki. Lost the battle
  with PRL, now significantly expanded (23 pages, 8 figures, 2 appendices)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preferential attachment --- by which new nodes attach to existing nodes with
probability proportional to the existing nodes' degree --- has become the
standard growth model for scale-free networks, where the asymptotic probability
of a node having degree $k$ is proportional to $k^{-\gamma}$. However, the
motivation for this model is entirely ad hoc. We use exact likelihood arguments
and show that the optimal way to build a scale-free network is to attach most
new links to nodes of low degree. Curiously, this leads to a scale-free
networks with a single dominant hub: a star-like structure we call a super-star
network. Asymptotically, the optimal strategy is to attach each new node to one
of the nodes of degree $k$ with probability proportional to
$\frac{1}{N+\zeta(\gamma)(k+1)^\gamma}$ (in a $N$ node network) --- a stronger
bias toward high degree nodes than exhibited by standard preferential
attachment. Our algorithm generates optimally scale-free networks (the
super-star networks) as well as randomly sampling the space of all scale-free
networks with a given degree exponent $\gamma$. We generate viable realisation
with finite $N$ for $1\ll \gamma&lt;2$ as well as $\gamma&gt;2$. We observe an
apparently discontinuous transition at $\gamma\approx 2$ between so-called
super-star networks and more tree-like realisations. Gradually increasing
$\gamma$ further leads to re-emergence of a super-star hub. To quantify these
structural features we derive a new analytic expression for the expected degree
exponent of a pure preferential attachment process, and introduce alternative
measures of network entropy. Our approach is generic and may also be applied to
an arbitrary degree distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6431</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6431</id><created>2013-05-28</created><updated>2013-12-03</updated><authors><author><keyname>Breuer</keyname><forenames>Peter T.</forenames></author><author><keyname>Bowen</keyname><forenames>Jonathan P.</forenames></author></authors><title>Certifying Machine Code Safe from Hardware Aliasing: RISC is not
  necessarily risky</title><categories>cs.LO cs.SE</categories><comments>First submitted to SEFM 2013 as &quot;Towards Proving RISC Machine Code
  not Risky with respect to Memory Aliasing&quot; (15p+4p Appendix), Resubmitted to
  and accepted for OpenCert 2013, co-located with SEFM 2013 (16p+6p Appendix)</comments><acm-class>D.2.4</acm-class><doi>10.1007/978-3-319-05032-4_27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sometimes machine code turns out to be a better target for verification than
source code. RISC machine code is especially advantaged with respect to source
code in this regard because it has only two instructions that access memory.
That architecture forms the basis here for an inference system that can prove
machine code safe against `hardware aliasing', an effect that occurs in
embedded systems. There are programming memes that ensure code is safe from
hardware aliasing, but we want to certify that a given machine code is provably
safe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6432</identifier>
 <datestamp>2014-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6432</id><created>2013-05-28</created><authors><author><keyname>Ahadi</keyname><forenames>Arash</forenames></author><author><keyname>Dehghan</keyname><forenames>Ali</forenames></author></authors><title>The Complexity of the Proper Orientation Number</title><categories>cs.CC cs.DM cs.DS math.CO</categories><comments>10 pages, 2 figures. Submitted to Information Processing Letters</comments><doi>10.1016/j.ipl.2013.07.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph orientation is a well-studied area of graph theory. A proper
orientation of a graph $G = (V,E)$ is an orientation $D$ of $E(G)$ such that
for every two adjacent vertices $ v $ and $ u $, $ d^{-}_{D}(v) \neq
d^{-}_{D}(u)$ where $d_{D}^{-}(v)$ is the number of edges with head $v$ in $D$.
The proper orientation number of $G$ is defined as $ \overrightarrow{\chi} (G)
=\displaystyle \min_{D\in \Gamma} \displaystyle\max_{v\in V(G)} d^{-}_{D}(v) $
where $\Gamma$ is the set of proper orientations of $G$. We have $ \chi(G)-1
\leq \overrightarrow{\chi} (G)\leq \Delta(G) $. We show that, it is $
\mathbf{NP} $-complete to decide whether $\overrightarrow{\chi}(G)=2$, for a
given planar graph $G$. Also, we prove that there is a polynomial time
algorithm for determining the proper orientation number of 3-regular graphs. In
sharp contrast, we will prove that this problem is $ \mathbf{NP} $-hard for
4-regular graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6441</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6441</id><created>2013-05-28</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Agaev</keyname><forenames>Rafig</forenames></author></authors><title>Matrices of forests, analysis of networks, and ranking problems</title><categories>math.CO cs.CV cs.DM cs.NI</categories><comments>8 pages. This article draws heavily from arXiv:math/0508171.
  Published in Proceedings of the First International Conference on Information
  Technology and Quantitative Management (ITQM 2013). This version contains
  some corrections and additions</comments><msc-class>05C50 05C05 91B10 62J15 90B15 60J10</msc-class><doi>10.1016/j.procs.2013.05.145</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The matrices of spanning rooted forests are studied as a tool for analysing
the structure of networks and measuring their properties. The problems of
revealing the basic bicomponents, measuring vertex proximity, and ranking from
preference relations / sports competitions are considered. It is shown that the
vertex accessibility measure based on spanning forests has a number of
desirable properties. An interpretation for the stochastic matrix of
out-forests in terms of information dissemination is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6451</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6451</id><created>2013-05-28</created><authors><author><keyname>Amor</keyname><forenames>Iheb Ben</forenames><affiliation>LIPADE</affiliation></author><author><keyname>Bougetteya</keyname><forenames>Athman</forenames><affiliation>CSIT</affiliation></author><author><keyname>Ouziri</keyname><forenames>Mourad</forenames><affiliation>LIPADE</affiliation></author><author><keyname>Benbernou</keyname><forenames>Salima</forenames><affiliation>LIPADE</affiliation></author><author><keyname>Nadif</keyname><forenames>Mohamed</forenames><affiliation>LIPADE</affiliation></author></authors><title>Data Leak Aware Crowdsourcing in Social Network</title><categories>cs.SI physics.soc-ph</categories><proxy>ccsd</proxy><journal-ref>Springer 7652 (2012) pp 226-236</journal-ref><doi>10.1007/978-3-642-38333-5_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Harnessing human computation for solving complex problems call spawns the
issue of finding the unknown competitive group of solvers. In this paper, we
propose an approach called Friendlysourcing to build up teams from social
network answering a business call, all the while avoiding partial solution
disclosure to competitive groups. The contributions of this paper include (i) a
clustering based approach for discovering collaborative and competitive team in
social network (ii) a Markov-chain based algorithm for discovering implicit
interactions in the social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6474</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6474</id><created>2013-05-28</created><authors><author><keyname>Wimmer</keyname><forenames>Martin</forenames></author><author><keyname>Cederman</keyname><forenames>Daniel</forenames></author><author><keyname>Tr&#xe4;ff</keyname><forenames>Jesper Larsson</forenames></author><author><keyname>Tsigas</keyname><forenames>Philippas</forenames></author></authors><title>Configurable Strategies for Work-stealing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Work-stealing systems are typically oblivious to the nature of the tasks they
are scheduling. For instance, they do not know or take into account how long a
task will take to execute or how many subtasks it will spawn. Moreover, the
actual task execution order is typically determined by the underlying task
storage data structure, and cannot be changed. There are thus possibilities for
optimizing task parallel executions by providing information on specific tasks
and their preferred execution order to the scheduling system.
  We introduce scheduling strategies to enable applications to dynamically
provide hints to the task-scheduling system on the nature of specific tasks.
Scheduling strategies can be used to independently control both local task
execution order as well as steal order. In contrast to conventional scheduling
policies that are normally global in scope, strategies allow the scheduler to
apply optimizations on individual tasks. This flexibility greatly improves
composability as it allows the scheduler to apply different, specific
scheduling choices for different parts of applications simultaneously. We
present a number of benchmarks that highlight diverse, beneficial effects that
can be achieved with scheduling strategies. Some benchmarks (branch-and-bound,
single-source shortest path) show that prioritization of tasks can reduce the
total amount of work compared to standard work-stealing execution order. For
other benchmarks (triangle strip generation) qualitatively better results can
be achieved in shorter time. Other optimizations, such as dynamic merging of
tasks or stealing of half the work, instead of half the tasks, are also shown
to improve performance. Composability is demonstrated by examples that combine
different strategies, both within the same kernel (prefix sum) as well as when
scheduling multiple kernels (prefix sum and unbalanced tree search).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6489</identifier>
 <datestamp>2013-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6489</id><created>2013-05-28</created><updated>2013-12-06</updated><authors><author><keyname>Zhao</keyname><forenames>Junzhou</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author><author><keyname>Guan</keyname><forenames>Xiaohong</forenames></author><author><keyname>Wang</keyname><forenames>Pinghui</forenames></author></authors><title>Social Sensor Placement in Large Scale Networks: A Graph Sampling
  Perspective</title><categories>cs.SI physics.soc-ph</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor placement for the purpose of detecting/tracking news outbreak and
preventing rumor spreading is a challenging problem in a large scale online
social network (OSN). This problem is a kind of subset selection problem:
choosing a small set of items from a large population so to maximize some
prespecified set function. However, it is known to be NP-complete. Existing
heuristics are very costly especially for modern OSNs which usually contain
hundreds of millions of users. This paper aims to design methods to find
\emph{good solutions} that can well trade off efficiency and accuracy. We first
show that it is possible to obtain a high quality solution with a probabilistic
guarantee from a &quot;{\em candidate set}&quot; of the underlying social network. By
exploring this candidate set, one can increase the efficiency of placing social
sensors. We also present how this candidate set can be obtained using &quot;{\em
graph sampling}&quot;, which has an advantage over previous methods of not requiring
the prior knowledge of the complete network topology. Experiments carried out
on two real datasets demonstrate not only the accuracy and efficiency of our
approach, but also effectiveness in detecting and predicting news outbreak.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6506</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6506</id><created>2013-05-28</created><authors><author><keyname>Hausenblas</keyname><forenames>Michael</forenames></author></authors><title>Notes on Physical &amp; Logical Data Layouts</title><categories>cs.DB</categories><comments>5 pages, 2 figures, 1 table</comments><acm-class>H.2</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this short note I review and discuss fundamental options for physical and
logical data layouts as well as the impact of the choices on data processing. I
should say in advance that these notes offer no new insights, that is,
everything stated here has already been published elsewhere. In fact, it has
been published in so many different places, such as blog posts, in the
literature, etc. that the main contribution is to bring it all together in one
place.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6537</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6537</id><created>2013-05-28</created><authors><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author></authors><title>A Cooperative Coevolutionary Genetic Algorithm for Learning Bayesian
  Network Structures</title><categories>cs.NE cs.AI</categories><doi>10.1145/2001576.2001729</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a cooperative coevolutionary genetic algorithm for learning
Bayesian network structures from fully observable data sets. Since this problem
can be decomposed into two dependent subproblems, that is to find an ordering
of the nodes and an optimal connectivity matrix, our algorithm uses two
subpopulations, each one representing a subtask. We describe the empirical
results obtained with simulations of the Alarm and Insurance networks. We show
that our algorithm outperforms the deterministic algorithm K2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6543</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6543</id><created>2013-05-28</created><authors><author><keyname>Malecha</keyname><forenames>Gregory</forenames></author><author><keyname>Chlipala</keyname><forenames>Adam</forenames></author><author><keyname>Braibant</keyname><forenames>Thomas</forenames></author><author><keyname>Hulin</keyname><forenames>Patrick</forenames></author><author><keyname>Yang</keyname><forenames>Edward Z.</forenames></author></authors><title>MirrorShard: Proof by Computational Reflection with Verified Hints</title><categories>cs.PL cs.LO</categories><msc-class>68N30</msc-class><acm-class>D.2.4; D.3.1; F.3.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a method for building composable and extensible verification
procedures within the Coq proof assistant. Unlike traditional methods that rely
on run-time generation and checking of proofs, we use verified-correct
procedures with Coq soundness proofs. Though they are internalized in Coq's
logic, our provers support sound extension by users with hints over new
domains, enabling automated reasoning about user-defined abstract predicates.
We maintain soundness by developing an architecture for modular packaging,
construction, and composition of hint databases, which had previously only been
implemented in Coq at the level of its dynamically typed, proof-generating
tactic language. Our provers also include rich handling of unification
variables, enabling integration with other tactic-based deduction steps within
Coq. We have implemented our techniques in MirrorShard, an open-source
framework for reflective verification. We demonstrate its applicability by
instantiating it to separation logic in order to reason about imperative
program verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6545</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6545</id><created>2013-05-28</created><updated>2014-04-25</updated><authors><author><keyname>Kalev</keyname><forenames>Amir</forenames></author><author><keyname>Gour</keyname><forenames>Gilad</forenames></author></authors><title>Construction of all general symmetric informationally complete
  measurements</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>8 pages, 1 figure</comments><journal-ref>J. Phys. A: Math. Theor. 47, 335302 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct the set of all general (i.e. not necessarily rank 1) symmetric
informationally complete (SIC) positive operator valued measures (POVMs). In
particular, we show that any orthonormal basis of a real vector space of
dimension d^2-1 corresponds to some general SIC POVM and vice versa. Our
constructed set of all general SIC-POVMs contains weak SIC-POVMs for which each
POVM element can be made arbitrarily close to a multiple times the identity. On
the other hand, it remains open if for all finite dimensions our constructed
family contains a rank 1 SIC-POVM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6555</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6555</id><created>2013-05-28</created><authors><author><keyname>Bender</keyname><forenames>Michael A.</forenames></author><author><keyname>Farach-Colton</keyname><forenames>Martin</forenames></author><author><keyname>Fekete</keyname><forenames>S&#xe1;ndor P.</forenames></author><author><keyname>Fineman</keyname><forenames>Jeremy T.</forenames></author><author><keyname>Gilbert</keyname><forenames>Seth</forenames></author></authors><title>Reallocation Problems in Scheduling</title><categories>cs.DS</categories><comments>9 oages, 1 table; extended abstract version to appear in SPAA 2013</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In traditional on-line problems, such as scheduling, requests arrive over
time, demanding available resources. As each request arrives, some resources
may have to be irrevocably committed to servicing that request. In many
situations, however, it may be possible or even necessary to reallocate
previously allocated resources in order to satisfy a new request. This
reallocation has a cost. This paper shows how to service the requests while
minimizing the reallocation cost. We focus on the classic problem of scheduling
jobs on a multiprocessor system. Each unit-size job has a time window in which
it can be executed. Jobs are dynamically added and removed from the system. We
provide an algorithm that maintains a valid schedule, as long as a sufficiently
feasible schedule exists. The algorithm reschedules only a total number of
O(min{log^* n, log^* Delta}) jobs for each job that is inserted or deleted from
the system, where n is the number of active jobs and Delta is the size of the
largest window.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6568</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6568</id><created>2013-05-28</created><authors><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author><author><keyname>Oliveira</keyname><forenames>Renato</forenames></author></authors><title>Reinforcement Learning for the Soccer Dribbling Task</title><categories>cs.LG cs.RO stat.ML</categories><doi>10.1109/CIG.2011.6031994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a reinforcement learning solution to the \emph{soccer dribbling
task}, a scenario in which a soccer agent has to go from the beginning to the
end of a region keeping possession of the ball, as an adversary attempts to
gain possession. While the adversary uses a stationary policy, the dribbler
learns the best action to take at each decision point. After defining
meaningful variables to represent the state space, and high-level macro-actions
to incorporate domain knowledge, we describe our application of the
reinforcement learning algorithm \emph{Sarsa} with CMAC for function
approximation. Our experiments show that, after the training period, the
dribbler is able to accomplish its task against a strong adversary around 58%
of the time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6569</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6569</id><created>2013-05-28</created><updated>2014-01-07</updated><authors><author><keyname>Aristoff</keyname><forenames>David</forenames></author><author><keyname>Leli&#xe8;vre</keyname><forenames>Tony</forenames></author></authors><title>Mathematical Analysis of Temperature Accelerated Dynamics</title><categories>math-ph cs.CE math.MP</categories><comments>28 pages, 2 figures</comments><msc-class>82C21, 82C80</msc-class><journal-ref>Multiscale Model. Simul., 12(1), 290--317 (2014)</journal-ref><doi>10.1137/130923063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a mathematical framework for temperature accelerated dynamics (TAD),
an algorithm proposed by M.R. S{\o}rensen and A.F. Voter to efficiently
generate metastable stochastic dynamics. Using the notion of quasistationary
distributions, we propose some modifications to TAD. Then considering the
modified algorithm in an idealized setting, we show how TAD can be made
mathematically rigorous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6577</identifier>
 <datestamp>2014-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6577</id><created>2013-05-28</created><updated>2014-09-23</updated><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author></authors><title>Polynomial Bounds for the Grid-Minor Theorem</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key results in Robertson and Seymour's seminal work on graph
minors is the Grid-Minor Theorem. The theorem states that every graph of
treewidth at least $k$ contains a $k' \times k'$ grid as a minor where $k' \geq
f(k)$ for some function $f$. This theorem has found many applications in graph
theory and algorithms. The best current quantitative bound, due to recent work
of Kawarabayashi and Kobayashi, and Leaf and Seymour, shows that
$f(k)=\Omega(\sqrt{\log k/\log \log k})$. In contrast, the best known upper
bound implies that $f(k) =O(\sqrt{k/\log k})$. In this paper we obtain the
first polynomial relationship between treewidth and grid-minor size by showing
that $f(k)=\Omega(k^{\delta})$ for some fixed constant $\delta &gt; 0$, and
describe an algorithm, whose running time is polynomial in $|V(G)|$ and $k$,
that finds such a grid-minor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6581</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6581</id><created>2013-05-28</created><authors><author><keyname>Viallet</keyname><forenames>Maxime</forenames></author><author><keyname>Baraffe</keyname><forenames>Isabelle</forenames></author><author><keyname>Walder</keyname><forenames>Rolf</forenames></author></authors><title>Comparison of different nonlinear solvers for 2D time-implicit stellar
  hydrodynamics</title><categories>astro-ph.SR cs.NA math.NA physics.comp-ph</categories><comments>Accepted for publication in A&amp;A</comments><doi>10.1051/0004-6361/201220725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-implicit schemes are attractive since they allow numerical time steps
that are much larger than those permitted by the Courant-Friedrich-Lewy
criterion characterizing time-explicit methods. This advantage comes, however,
with a cost: the solution of a system of nonlinear equations is required at
each time step. In this work, the nonlinear system results from the
discretization of the hydrodynamical equations with the Crank-Nicholson scheme.
We compare the cost of different methods, based on Newton-Raphson iterations,
to solve this nonlinear system, and benchmark their performances against
time-explicit schemes. Since our general scientific objective is to model
stellar interiors, we use as test cases two realistic models for the convective
envelope of a red giant and a young Sun. Focusing on 2D simulations, we show
that the best performances are obtained with the quasi-Newton method proposed
by Broyden. Another important concern is the accuracy of implicit calculations.
Based on the study of an idealized problem, namely the advection of a single
vortex by a uniform flow, we show that there are two aspects: i) the nonlinear
solver has to be accurate enough to resolve the truncation error of the
numerical discretization, and ii) the time step has be small enough to resolve
the advection of eddies. We show that with these two conditions fulfilled, our
implicit methods exhibit similar accuracy to time-explicit schemes, which have
lower values for the time step and higher computational costs. Finally, we
discuss in the conclusion the applicability of these methods to fully implicit
3D calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6624</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6624</id><created>2013-05-28</created><authors><author><keyname>Kumar</keyname><forenames>Priyanka</forenames></author><author><keyname>Peri</keyname><forenames>Sathya</forenames></author></authors><title>A TimeStamp based Multi-version STM Protocol that satisfies Opacity and
  Multi-Version Permissiveness</title><categories>cs.DC</categories><comments>19 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Transactional Memory Systems (STM) are a promising alternative to
lock based systems for concurrency control in shared memory systems. In
multiversion STM systems, each write on a transaction object produces a new
version of that object. The advantage obtained by storing multiple versions is
that one can ensure that read operations do not fail. Opacity is a commonly
used correctness criterion for STM systems. Multi-Version permissive STM system
never aborts a read-only transaction. Although many multi-version STM systems
have been proposed, to the best of our knowledge none of them have been
formally proved to satisfy opacity. In this paper we present a time-stamp based
multiversion STM system that satisfies opacity and mv-permissiveness. We
formally prove the correctness of the proposed STM system. We also present
garbage collection procedure which deletes unwanted versions of the transaction
objects and formally prove it correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6640</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6640</id><created>2013-05-28</created><authors><author><keyname>Apel</keyname><forenames>Sven</forenames></author><author><keyname>Beyer</keyname><forenames>Dirk</forenames></author><author><keyname>Friedberger</keyname><forenames>Karlheinz</forenames></author><author><keyname>Raimondi</keyname><forenames>Franco</forenames></author><author><keyname>von Rhein</keyname><forenames>Alexander</forenames></author></authors><title>Domain Types: Selecting Abstractions Based on Variable Usage</title><categories>cs.SE cs.PL</categories><comments>13 pages, 9 figures, 2 tables</comments><report-no>MIP-1303</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of software model checking depends on finding an appropriate
abstraction of the subject program. The choice of the abstract domain and the
analysis configuration is currently left to the user, who may not be familiar
with the tradeoffs and performance details of the available abstract domains.
We introduce the concept of domain types, which classify the program variables
into types that are more fine-grained than standard declared types, such as int
or long, in order to guide the selection of an appropriate abstract domain for
a model checker. Our implementation determines the domain type for each
variable in a pre-processing step, based on the variable usage in the program,
and then assigns each variable to an abstract domain. The model-checking
framework that we use supports to specify a separate analysis precision for
each abstract domain, such that we can freely configure the analysis. We
experimentally demonstrate a significant impact of the choice of the abstract
domain per variable. We consider one explicit (hash tables for integer values)
and one symbolic (binary decision diagrams) domain. The experiments are based
on standard verification tasks that are taken from recent competitions on
software verification. Each abstract domain has unique advantages in
representing the state space of variables of a certain domain type. Our
experiments show that software model checkers can be improved with a
domain-type guided combination of abstract domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6646</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6646</id><created>2013-05-28</created><authors><author><keyname>Ross</keyname><forenames>Stephane</forenames></author><author><keyname>Mineiro</keyname><forenames>Paul</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author></authors><title>Normalized Online Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce online learning algorithms which are independent of feature
scales, proving regret bounds dependent on the ratio of scales existent in the
data rather than the absolute scale. This has several useful effects: there is
no need to pre-normalize data, the test-time and test-space complexity are
reduced, and the algorithms are more robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6650</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6650</id><created>2013-05-28</created><authors><author><keyname>Ahmad</keyname><forenames>Sheeraz</forenames></author><author><keyname>Yu</keyname><forenames>Angela J.</forenames></author></authors><title>Active Sensing as Bayes-Optimal Sequential Decision Making</title><categories>cs.AI cs.CV</categories><comments>Scheduled to appear in UAI 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensory inference under conditions of uncertainty is a major problem in both
machine learning and computational neuroscience. An important but poorly
understood aspect of sensory processing is the role of active sensing. Here, we
present a Bayes-optimal inference and control framework for active sensing,
C-DAC (Context-Dependent Active Controller). Unlike previously proposed
algorithms that optimize abstract statistical objectives such as information
maximization (Infomax) [Butko &amp; Movellan, 2010] or one-step look-ahead accuracy
[Najemnik &amp; Geisler, 2005], our active sensing model directly minimizes a
combination of behavioral costs, such as temporal delay, response error, and
effort. We simulate these algorithms on a simple visual search task to
illustrate scenarios in which context-sensitivity is particularly beneficial
and optimization with respect to generic statistical objectives particularly
inadequate. Motivated by the geometric properties of the C-DAC policy, we
present both parametric and non-parametric approximations, which retain
context-sensitivity while significantly reducing computational complexity.
These approximations enable us to investigate the more complex problem
involving peripheral vision, and we notice that the difference between C-DAC
and statistical policies becomes even more evident in this scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6656</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6656</id><created>2013-05-28</created><authors><author><keyname>Cajueiro</keyname><forenames>Daniel O.</forenames></author><author><keyname>Andrade</keyname><forenames>Roberto F. S.</forenames></author></authors><title>Controlling self-organized criticality in complex networks</title><categories>physics.soc-ph cs.SI nlin.AO</categories><journal-ref>The European Physical Journal B, Condensed Matter Physics (Print),
  v. 77, p. 291-296, 2010</journal-ref><doi>10.1140/epjb/e2010-00229-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A control scheme to reduce the size of avalanches of the Bak-Tang-Wiesenfeld
model on complex networks is proposed. Three network types are considered:
those proposed by Erd\H{o}s-Renyi, Goh-Kahng-Kim, and a real network
representing the main connections of the electrical power grid of the western
United States. The control scheme is based on the idea of triggering avalanches
in the highest degree nodes that are near to become critical. We show that this
strategy works in the sense that the dissipation of mass occurs most locally
avoiding larger avalanches. We also compare this strategy with a random
strategy where the nodes are chosen randomly. Although the random control has
some ability to reduce the probability of large avalanches, its performance is
much worse than the one based on the choice of the highest degree nodes.
Finally, we argue that the ability of the proposed control scheme is related to
its ability to reduce the concentration of mass on the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6659</identifier>
 <datestamp>2013-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6659</id><created>2013-05-28</created><updated>2013-11-01</updated><authors><author><keyname>Campbell</keyname><forenames>Trevor</forenames></author><author><keyname>Liu</keyname><forenames>Miao</forenames></author><author><keyname>Kulis</keyname><forenames>Brian</forenames></author><author><keyname>How</keyname><forenames>Jonathan P.</forenames></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames></author></authors><title>Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process
  Mixture</title><categories>cs.LG stat.ML</categories><comments>This paper is from NIPS 2013. Please use the following BibTeX
  citation: @inproceedings{Campbell13_NIPS, Author = {Trevor Campbell and Miao
  Liu and Brian Kulis and Jonathan P. How and Lawrence Carin}, Title = {Dynamic
  Clustering via Asymptotics of the Dependent Dirichlet Process}, Booktitle =
  {Advances in Neural Information Processing Systems (NIPS)}, Year = {2013}}</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel algorithm, based upon the dependent Dirichlet
process mixture model (DDPMM), for clustering batch-sequential data containing
an unknown number of evolving clusters. The algorithm is derived via a
low-variance asymptotic analysis of the Gibbs sampling algorithm for the DDPMM,
and provides a hard clustering with convergence guarantees similar to those of
the k-means algorithm. Empirical results from a synthetic test with moving
Gaussian clusters and a test with real ADS-B aircraft trajectory data
demonstrate that the algorithm requires orders of magnitude less computational
time than contemporary probabilistic and hard clustering algorithms, while
providing higher accuracy on the examined datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6663</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6663</id><created>2013-05-28</created><updated>2013-11-10</updated><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Yao</keyname><forenames>Li</forenames></author><author><keyname>Alain</keyname><forenames>Guillaume</forenames></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames></author></authors><title>Generalized Denoising Auto-Encoders as Generative Models</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown how denoising and contractive autoencoders implicitly
capture the structure of the data-generating density, in the case where the
corruption noise is Gaussian, the reconstruction error is the squared error,
and the data is continuous-valued. This has led to various proposals for
sampling from this implicitly learned density function, using Langevin and
Metropolis-Hastings MCMC. However, it remained unclear how to connect the
training procedure of regularized auto-encoders to the implicit estimation of
the underlying data-generating distribution when the data are discrete, or
using other forms of corruption process and reconstruction errors. Another
issue is the mathematical justification which is only valid in the limit of
small corruption noise. We propose here a different attack on the problem,
which deals with all these issues: arbitrary (but noisy enough) corruption,
arbitrary reconstruction loss (seen as a log-likelihood), handling both
discrete and continuous-valued variables, and removing the bias due to
non-infinitesimal corruption noise (or non-infinitesimal contractive penalty).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6669</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6669</id><created>2013-05-28</created><authors><author><keyname>Erickson</keyname><forenames>Alejandro</forenames></author><author><keyname>Ruskey</keyname><forenames>Frank</forenames></author></authors><title>Domino Tatami Covering is NP-complete</title><categories>cs.CC math.CO</categories><comments>10 pages, accepted at The International Workshop on Combinatorial
  Algorithms (IWOCA) 2013</comments><msc-class>05B40, 05B50, 68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A covering with dominoes of a rectilinear region is called \emph{tatami} if
no four dominoes meet at any point. We describe a reduction from planar 3SAT to
Domino Tatami Covering. As a consequence it is NP-complete to decide whether
there is a perfect matching of a graph that meets every 4-cycle, even if the
graph is restricted to be an induced subgraph of the grid-graph. The gadgets
used in the reduction were discovered with the help of a SAT-solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6693</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6693</id><created>2013-05-29</created><authors><author><keyname>Bereg</keyname><forenames>Sergey</forenames></author><author><keyname>Fabila-Monroy</keyname><forenames>Ruy</forenames></author><author><keyname>Flores-Pe&#xf1;aloza</keyname><forenames>David</forenames></author><author><keyname>Lopez</keyname><forenames>Mario</forenames></author><author><keyname>P&#xe9;rez-Lantero</keyname><forenames>Pablo</forenames></author></authors><title>Drawing the double circle on a grid of minimum size</title><categories>cs.CG math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1926, Jarn\'ik introduced the problem of drawing a convex $n$-gon with
vertices having integer coordinates. He constructed such a drawing in the grid
$[1,c\cdot n^{3/2}]^2$ for some constant $c&gt;0$, and showed that this grid size
is optimal up to a constant factor. We consider the analogous problem for
drawing the double circle, and prove that it can be done within the same grid
size. Moreover, we give an O(n)-time algorithm to construct such a point set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6705</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6705</id><created>2013-05-29</created><authors><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>K. J. Ray</forenames></author></authors><title>On Cost-Effective Incentive Mechanisms in Microtask Crowdsourcing</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While microtask crowdsourcing provides a new way to solve large volumes of
small tasks at a much lower price compared with traditional in-house solutions,
it suffers from quality problems due to the lack of incentives. On the other
hand, providing incentives for microtask crowdsourcing is challenging since
verifying the quality of submitted solutions is so expensive that will negate
the advantage of microtask crowdsourcing. We study cost-effective incentive
mechanisms for microtask crowdsourcing in this paper. In particular, we
consider a model with strategic workers, where the primary objective of a
worker is to maximize his own utility. Based on this model, we analyze two
basic mechanisms widely adopted in existing microtask crowdsourcing
applications and show that, to obtain high quality solutions from workers,
their costs are constrained by some lower bounds. We then propose a
cost-effective mechanism that employs quality-aware worker training as a tool
to stimulate workers to provide high quality solutions. We prove theoretically
that the proposed mechanism, when properly designed, can obtain high quality
solutions with an arbitrarily low cost. Beyond its theoretical guarantees, we
further demonstrate the effectiveness of our proposed mechanisms through a set
of behavioral experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6721</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6721</id><created>2013-05-29</created><authors><author><keyname>Keil</keyname><forenames>Matthias</forenames></author><author><keyname>Thiemann</keyname><forenames>Peter</forenames></author></authors><title>Type-based Dependency Analysis for JavaScript</title><categories>cs.PL</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dependency analysis is a program analysis that determines potential data flow
between program points. While it is not a security analysis per se, it is a
viable basis for investigating data integrity, for ensuring confidentiality,
and for guaranteeing sanitization. A noninterference property can be stated and
proved for the dependency analysis. We have designed and implemented a
dependency analysis for JavaScript. We formalize this analysis as an
abstraction of a tainting semantics. We prove the correctness of the tainting
semantics, the soundness of the abstraction, a noninterference property, and
the termination of the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6738</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6738</id><created>2013-05-29</created><authors><author><keyname>Rappos</keyname><forenames>Efstratios</forenames></author><author><keyname>Robert</keyname><forenames>Stephan</forenames></author></authors><title>Using GPU Simulation to Accurately Fit to the Power-Law Distribution</title><categories>stat.CO cs.DC physics.comp-ph physics.data-an stat.AP</categories><msc-class>62F03, 68W10, 62P10, 62P30, 62P35, 62Q05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a methodology for fitting experimental data to the
discrete power-law distribution and provides the results of a detailed
simulation exercise used to calculate accurate cutoff values used to assess the
fit to a power-law distribution when using the maximum likelihood estimation
for the exponent of the distribution. Using massively parallel programming
computing, we were able to accelerate by a factor of 60 the computational time
required for these calculations across a range of parameters and construct a
series of detailed tables containing the test values to be used in a
Kolmogorov-Smirnov goodness-of-fit test, allowing for an accurate assessment of
the power-law fit from empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6745</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6745</id><created>2013-05-29</created><updated>2013-06-14</updated><authors><author><keyname>Demyanova</keyname><forenames>Yulia</forenames></author><author><keyname>Veith</keyname><forenames>Helmut</forenames></author><author><keyname>Zuleger</keyname><forenames>Florian</forenames></author></authors><title>On the Concept of Variable Roles and its Use in Software Analysis</title><categories>cs.PL cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human written source code in imperative programming languages exhibits
typical patterns for variable use such as flags, loop iterators, counters,
indices, bitvectors etc. Although it is widely understood by practitioners that
these variable roles are important for automated software analysis tools, they
are not systematically studied by the formal methods community, and not well
documented in the research literature. In this paper, we study the notion of
variable roles on the example of basic types (int, float, char) in C. We
propose a classification of the variables in a program by variable roles, and
demonstrate that classical data flow analysis lends itself naturally both as a
specification formalism and an analysis paradigm for this classification
problem. We demonstrate the practical applicability of our method by predicting
membership of source files to the different categories of the software
verification competition SVCOMP 2013.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6757</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6757</id><created>2013-05-29</created><authors><author><keyname>Akiyama</keyname><forenames>Shigeki</forenames></author><author><keyname>Marsault</keyname><forenames>Victor</forenames></author><author><keyname>Sakarovitch</keyname><forenames>Jacques</forenames></author></authors><title>Auto-similarity in rational base number systems</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is a contribution to the study of set of the representations of
integers in a rational base number system. This prefix-closed subset of the
free monoid is naturally represented as a highly non regular tree whose nodes
are the integers and whose subtrees are all distinct. With every node of that
tree is then associated a minimal infinite word. The main result is that a
sequential transducer which computes for all n the minimal word associated with
n+1 from the one associated with n, has essentially the same underlying graph
as the tree itself. These infinite words are then interpreted as
representations of real numbers; the difference between the numbers represented
by these two consecutive minimal words is the called the span of a node of the
tree. The preceding construction allows to characterise the topological closure
of the set of spans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6783</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6783</id><created>2013-05-29</created><authors><author><keyname>Pratas</keyname><forenames>Nuno K.</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author></authors><title>Low-Rate Machine-Type Communication via Wireless Device-to-Device (D2D)
  Links</title><categories>cs.IT cs.NI math.IT</categories><comments>12 Pages, 9 Figures, Submitted to JSAC &quot;Device-to-Device
  Communications in Cellular Networks&quot; on the 20th of May 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless cellular networks feature two emerging technological trends. The
first is the direct Device-to-Device (D2D) communications, which enables direct
links between the wireless devices that reutilize the cellular spectrum and
radio interface. The second is that of Machine-Type Communications (MTC), where
the objective is to attach a large number of low-rate low-power devices, termed
Machine-Type Devices (MTDs) to the cellular network. MTDs pose new challenges
to the cellular network, one if which is that the low transmission power can
lead to outage problems for the cell-edge devices. Another issue imminent to
MTC is the \emph{massive access} that can lead to overload of the radio
interface. In this paper we explore the opportunity opened by D2D links for
supporting MTDs, since it can be desirable to carry the MTC traffic not through
direct links to a Base Station, but through a nearby relay. MTC is modeled as a
fixed-rate traffic with an outage requirement. We propose two network-assisted
D2D schemes that enable the cooperation between MTDs and standard cellular
devices, thereby meeting the MTC outage requirements while maximizing the rate
of the broadband services for the other devices. The proposed schemes apply the
principles Opportunistic Interference Cancellation and the Cognitive Radio's
underlaying. We show through analysis and numerical results the gains of the
proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6789</identifier>
 <datestamp>2014-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6789</id><created>2013-05-29</created><updated>2014-05-14</updated><authors><author><keyname>Tomamichel</keyname><forenames>Marco</forenames></author><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author></authors><title>Second-Order Coding Rates for Channels with State</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Trans. Inf. Theory 60 (8), p. 4427-4448 (2014)</journal-ref><doi>10.1109/TIT.2014.2324555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance limits of state-dependent discrete memoryless
channels with a discrete state available at both the encoder and the decoder.
We establish the epsilon-capacity as well as necessary and sufficient
conditions for the strong converse property for such channels when the sequence
of channel states is not necessarily stationary, memoryless or ergodic. We then
seek a finer characterization of these capacities in terms of second-order
coding rates. The general results are supplemented by several examples
including i.i.d. and Markov states and mixed channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6800</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6800</id><created>2013-05-29</created><authors><author><keyname>Callahan</keyname><forenames>Alison</forenames></author><author><keyname>Dumontier</keyname><forenames>Michel</forenames></author></authors><title>Ovopub: Modular data publication with minimal provenance</title><categories>cs.DL</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growth of the Semantic Web as a medium for creating, consuming,
mashing up and republishing data, our ability to trace any statement(s) back to
their origin is becoming ever more important. Several approaches have now been
proposed to associate statements with provenance, with multiple applications in
data publication, attribution and argumentation. Here, we describe the ovopub,
a modular model for data publication that enables encapsulation, aggregation,
integrity checking, and selective-source query answering. We describe the
ovopub RDF specification, key design patterns and their application in the
publication and referral to data in the life sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6803</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6803</id><created>2013-05-29</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author></authors><title>A representation of context-free grammars with the help of finite
  digraphs</title><categories>cs.FL</categories><comments>4 figures</comments><journal-ref>American Journal of Applied Mathematics. Vol. 1, No. 1, 2013, pp.
  8-11</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For any context-free grammar, we build a transition diagram, that is, a
finite directed graph with labeled arcs, which describes the work of the
grammar. This approach is new, and it is different from previously known graph
models. We define the concept of proper walk in this transition diagram and we
prove that a word belongs to a given context-free language if and only if this
word can be obtained with the help of a proper walk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6817</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6817</id><created>2013-04-25</created><updated>2013-06-21</updated><authors><author><keyname>Jain</keyname><forenames>Ashish</forenames></author><author><keyname>Chaudhari</keyname><forenames>Narendra S.</forenames></author></authors><title>Two Trivial Attacks on A5/1:A GSM Stream Cipher</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author due to final version is
  submitted in journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stream ciphers play an important role in those applications where high
throughput remains critical and resources are very restricted e.g. in Europe
and North America, A5/1 is widely used stream cipher that ensure
confidentiality of conversations in GSM mobile phones. However careful security
analysis of such cipher is very important due to widespread practical
applicability. The basic building blocks used in the design of A5/1 are linear
feedback shift registers (LFSRs). Algebraic attacks are new and very powerful
tool to cryptanalyse LFSRs based stream ciphers even non-linear combiner are
concerned. In this paper we compared previous attacks on A5/1 as well as an
algebraic attack and a new improved guess and determine attack is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6827</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6827</id><created>2013-05-29</created><authors><author><keyname>L&#xe8;bre</keyname><forenames>Marie-Ange</forenames><affiliation>CITI</affiliation></author><author><keyname>Mou&#xeb;l</keyname><forenames>Fr&#xe9;d&#xe9;ric Le</forenames><affiliation>CITI</affiliation></author><author><keyname>M&#xe9;nard</keyname><forenames>Eric</forenames></author></authors><title>Mod\`ele multi-\'echelles pour les services dans les VANET</title><categories>cs.NI</categories><comments>in French</comments><proxy>ccsd</proxy><journal-ref>Journ\'ees Nationales des Communications dans les Transports
  (JNCT) (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service deployment, integration and interactions in VANET are fast expanding.
They are now focusing only on driver security. In the future, with in-car
application deployments, the car will be considered as a user extension - in
the same way as smartphones actually. We propose a multi-level graph model to
challenge this VANET / Application / User integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6829</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6829</id><created>2013-05-29</created><updated>2013-06-11</updated><authors><author><keyname>Kordy</keyname><forenames>Barbara</forenames></author><author><keyname>Kordy</keyname><forenames>Piotr</forenames></author><author><keyname>Mauw</keyname><forenames>Sjouke</forenames></author><author><keyname>Schweitzer</keyname><forenames>Patrick</forenames></author></authors><title>ADTool: Security Analysis with Attack-Defense Trees (Extended Version)</title><categories>cs.CR cs.GT</categories><comments>This is an extended version of the tool demonstration paper accepted
  for publication at the 10th International Conference on Quantitative
  Evaluation of SysTems (QEST 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ADTool is free, open source software assisting graphical modeling and
quantitative analysis of security, using attack-defense trees. The main
features of the ADTool are easy creation, efficient editing, and automated
bottom-up evaluation of security-relevant measures. The tool also supports the
usage of attack trees, protection trees and defense trees, which are all
particular instances of attack-defense trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6836</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6836</id><created>2013-05-28</created><authors><author><keyname>Estrada</keyname><forenames>Ernesto</forenames></author></authors><title>About the Discriminant Power of the Subgraph Centrality and Other
  Centrality Measures About the Discriminant Power of the Subgraph Centrality
  and Other Centrality Measures(Working paper)</title><categories>cs.SI math.CO physics.soc-ph</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discriminant power of centrality indices for the degree, eigenvector,
closeness, betweenness and subgraph centrality is analyzed. It is defined by
the number of graphs for which the standard deviation of the centrality of its
nodes is zero. On the basis of empirical analysis it is concluded that the
subgraph centrality displays better discriminant power than the rest of
centralities. We also propose some new conjectures about the types of graphs
for which the subgraph centrality does not discriminate among nonequivalent
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6857</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6857</id><created>2013-05-29</created><authors><author><keyname>Lages</keyname><forenames>E. N.</forenames></author><author><keyname>Silveira</keyname><forenames>E. S. S.</forenames></author><author><keyname>Cintra</keyname><forenames>D. T.</forenames></author><author><keyname>Frery</keyname><forenames>A. C.</forenames></author></authors><title>An adaptive time integration strategy based on displacement history
  curvature</title><categories>cs.NA math.NA</categories><comments>24 pages, 3 tables, 21 figures</comments><journal-ref>International Journal for Numerical Methods in Engineering 93, 12
  (2013) 1235-1254</journal-ref><doi>10.1002/nme.4421</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work introduces a time-adaptive strategy that uses a refinement
estimator based on the first Frenet curvature. In dynamics, a time-adaptive
strategy is a mechanism that interactively proposes changes to the time step
used in iterative methods of solution. These changes aim to improve the
relation between quality of response and computational cost. The method here
proposed is suitable for a variety of numerical time integration problems,
e.g., in the study of bodies subjected to dynamical loads. The motion equation
in its space-discrete form is used as reference to derive the formulation
presented in this paper. Our method is contrasted with other ones based on
local error estimator and apparent frequencies. We check the performance of our
proposal when employed with the central difference, the explicit
generalized-alpha and the Chung-Lee integration methods. The proposed
refinement estimator demands low computational resources, being easily applied
to several direct integration methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6861</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6861</id><created>2013-05-29</created><authors><author><keyname>K&#xfc;rsch</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Design and Realization of a Scalable Simulator of Magnetic Resonance
  Tomography</title><categories>cs.DC cs.CE q-bio.QM</categories><comments>PhD thesis, RWTH Aachen, Germany, 2003, in German, available at
  http://darwin.bth.rwth-aachen.de/opus3/volltexte/2003/709/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In research activities regarding Magnetic Resonance Imaging in medicine,
simulation tools with a universal approach are rare. Usually, simulators are
developed and used which tend to be restricted to a particular, small range of
applications. This led to the design and implementation of a new simulator
PARSPIN, the subject of this thesis. In medical applications, the Bloch
equation is a well-suited mathematical model of the underlying physics with a
wide scope. In this thesis, it is shown how analytical solutions of the Bloch
equation can be found, which promise substantial execution time advantages over
numerical solution methods. From these analytical solutions of the Bloch
equation, a new formalism for the description and the analysis of complex
imaging experiments is derived, the K-t formalism. It is shown that modern
imaging methods can be better explained by the K-t formalism than by observing
and analysing the magnetization of each spin of a spin ensemble. Various
approaches for a numerical simulation of Magnetic Resonance imaging are
discussed. It is shown that a simulation tool based on the K-t formalism
promises a substantial gain in execution time. Proper spatial discretization
according to the sampling theorem, a topic rarely discussed in literature, is
universally derived from the K-t formalism in this thesis. A spin-based
simulator is an application with high demands to computing facilities even on
modern hardware. In this thesis, two approaches for a parallelized software
architecture are designed, analysed and evaluated with regard to a reduction of
execution time. A number of possible applications in research and education are
demonstrated. For a choice of imaging experiments, results produced both
experimentally and by simulation are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6862</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6862</id><created>2013-05-27</created><updated>2013-10-29</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Zhou</keyname><forenames>Ping</forenames></author></authors><title>Measuring the Knowledge-Based Economy of China in terms of Synergy among
  Technological, Organizational, and Geographic Attributes of Firms</title><categories>cs.CY</categories><comments>accepted for publication in Scientometrics (October, 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the possible synergy among geographic, size, and technological
distributions of firms in the Orbis database, we find the greatest reduction of
uncertainty at the level of the 31 provinces of China, and an additional 18.0%
at the national level. Some of the coastal provinces stand out as expected, but
the metropolitan areas of Beijing and Shanghai are (with Tianjan and Chonqing)
most pronounced at the next-lower administrative level of (339) prefectures,
since these four metropoles are administratively defined at both levels.
Focusing on high- and medium-tech manufacturing, a shift toward Beijing and
Shanghai is indicated, and the synergy is on average enhanced (as expected; but
not for all provinces). Unfortunately, the Orbis data is incomplete since it
was collected for commercial and not for administrative or governmental
purposes. However, we show a methodology that can be used by others who may
have access to higher-quality statistical data for the measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6864</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6864</id><created>2013-05-29</created><authors><author><keyname>Ferner</keyname><forenames>Ulric J.</forenames></author><author><keyname>Wang</keyname><forenames>Tong</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Resolution-aware network coded storage</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that coding can be used in storage area networks
(SANs) to improve various quality of service metrics under normal SAN operating
conditions, without requiring additional storage space. For our analysis, we
develop a model which captures modern characteristics such as constrained I/O
access bandwidth limitations. Using this model, we consider two important
cases: single-resolution (SR) and multi-resolution (MR) systems. For SR
systems, we use blocking probability as the quality of service metric and
propose the network coded storage (NCS) scheme as a way to reduce blocking
probability. The NCS scheme codes across file chunks in time, exploiting file
striping and file duplication. Under our assumptions, we illustrate cases where
SR NCS provides an order of magnitude savings in blocking probability. For MR
systems, we introduce saturation probability as a quality of service metric to
manage multiple user types, and we propose the uncoded resolution- aware
storage (URS) and coded resolution-aware storage (CRS) schemes as ways to
reduce saturation probability. In MR URS, we align our MR layout strategy with
traffic requirements. In MR CRS, we code videos across MR layers. Under our
assumptions, we illustrate that URS can in some cases provide an order of
magnitude gain in saturation probability over classic non-resolution aware
systems. Further, we illustrate that CRS provides additional saturation
probability savings over URS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6866</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6866</id><created>2013-05-29</created><authors><author><keyname>Kamalian</keyname><forenames>R. R.</forenames></author></authors><title>Examples of cyclically-interval non-colorable bipartite graphs</title><categories>math.CO cs.DM</categories><comments>4 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  For an undirected, simple, finite, connected graph $G$, we denote by $V(G)$
and $E(G)$ the sets of its vertices and edges, respectively. A function
$\varphi:E(G)\rightarrow\{1,2,\ldots,t\}$ is called a proper edge $t$-coloring
of a graph $G$ if adjacent edges are colored differently and each of $t$ colors
is used. An arbitrary nonempty subset of consecutive integers is called an
interval. If $\varphi$ is a proper edge $t$-coloring of a graph $G$ and $x\in
V(G)$, then $S_G(x,\varphi)$ denotes the set of colors of edges of $G$ which
are incident with $x$. A proper edge $t$-coloring $\varphi$ of a graph $G$ is
called a cyclically-interval $t$-coloring if for any $x\in V(G)$ at least one
of the following two conditions holds: a) $S_G(x,\varphi)$ is an interval, b)
$\{1,2,\ldots,t\}\setminus S_G(x,\varphi)$ is an interval. For any $t\in
\mathbb{N}$, let $\mathfrak{M}_t$ be the set of graphs for which there exists a
cyclically-interval $t$-coloring, and let
$$\mathfrak{M}\equiv\bigcup_{t\geq1}\mathfrak{M}_t.$$ Examples of bipartite
graphs that do not belong to the class $\mathfrak{M}$ are constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6883</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6883</id><created>2013-05-29</created><authors><author><keyname>Diehl</keyname><forenames>Joscha</forenames></author></authors><title>Rotation invariants of two dimensional curves based on iterated
  integrals</title><categories>cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel class of rotation invariants of two dimensional curves
based on iterated integrals. The invariants we present are in some sense
complete and we describe an algorithm to calculate them, giving explicit
computations up to order six. We present an application to online
(stroke-trajectory based) character recognition. This seems to be the first
time in the literature that the use of iterated integrals of a curve is
proposed for (invariant) feature extraction in machine learning applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6915</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6915</id><created>2013-05-29</created><authors><author><keyname>Beyer</keyname><forenames>Dirk</forenames></author><author><keyname>L&#xf6;we</keyname><forenames>Stefan</forenames></author><author><keyname>Novikov</keyname><forenames>Evgeny</forenames></author><author><keyname>Stahlbauer</keyname><forenames>Andreas</forenames></author><author><keyname>Wendler</keyname><forenames>Philipp</forenames></author></authors><title>Reusing Precisions for Efficient Regression Verification</title><categories>cs.SE cs.PL</categories><comments>14 pages, 2 figures, 6 tables</comments><report-no>MIP-1302</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous testing during development is a well-established technique for
software-quality assurance. Continuous model checking from revision to revision
is not yet established as a standard practice, because the enormous resource
consumption makes its application impractical. Model checkers compute a large
number of verification facts that are necessary for verifying if a given
specification holds. We have identified a category of such intermediate results
that are easy to store and efficient to reuse: abstraction precisions. The
precision of an abstract domain specifies the level of abstraction that the
analysis works on. Precisions are thus a precious result of the verification
effort and it is a waste of resources to throw them away after each
verification run. In particular, precisions are small and thus easy to store;
they are easy to process and have a large impact on resource consumption. We
experimentally show the impact of precision reuse on industrial verification
problems, namely, 59 device drivers with 1119 revisions from the Linux kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6918</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6918</id><created>2013-05-29</created><authors><author><keyname>Spina</keyname><forenames>Thiago V.</forenames></author><author><keyname>Tepper</keyname><forenames>Mariano</forenames></author><author><keyname>Esler</keyname><forenames>Amy</forenames></author><author><keyname>Morellas</keyname><forenames>Vassilios</forenames></author><author><keyname>Papanikolopoulos</keyname><forenames>Nikolaos</forenames></author><author><keyname>Falc&#xe3;o</keyname><forenames>Alexandre X.</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Video Human Segmentation using Fuzzy Object Models and its Application
  to Body Pose Estimation of Toddlers for Behavior Studies</title><categories>cs.CV</categories><comments>arXiv admin note: text overlap with arXiv:1210.7014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video object segmentation is a challenging problem due to the presence of
deformable, connected, and articulated objects, intra- and inter-object
occlusions, object motion, and poor lighting. Some of these challenges call for
object models that can locate a desired object and separate it from its
surrounding background, even when both share similar colors and textures. In
this work, we extend a fuzzy object model, named cloud system model (CSM), to
handle video segmentation, and evaluate it for body pose estimation of toddlers
at risk of autism. CSM has been successfully used to model the parts of the
brain (cerebrum, left and right brain hemispheres, and cerebellum) in order to
automatically locate and separate them from each other, the connected brain
stem, and the background in 3D MR-images. In our case, the objects are
articulated parts (2D projections) of the human body, which can deform, cause
self-occlusions, and move along the video. The proposed CSM extension handles
articulation by connecting the individual clouds, body parts, of the system
using a 2D stickman model. The stickman representation naturally allows us to
extract 2D body pose measures of arm asymmetry patterns during unsupported gait
of toddlers, a possible behavioral marker of autism. The results show that our
method can provide insightful knowledge to assist the specialist's observations
during real in-clinic assessments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6954</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6954</id><created>2013-05-29</created><authors><author><keyname>Hern&#xe1;ndez</keyname><forenames>Eugenio</forenames></author><author><keyname>Vera</keyname><forenames>Daniel</forenames></author></authors><title>Greedy type algorithms for RIP matrices. A study of two selection rules</title><categories>cs.IT math.IT</categories><comments>28 pages, 3 figures</comments><msc-class>41A46, 68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some consequences of the Restricted Isometry Property (RIP) of matrices have
been applied to develop a greedy algorithm called &quot;ROMP&quot; (Regularized
Orthogonal Matching Pursuit) to recover sparse signals and to approximate
non-sparse ones. These consequences were subsequently applied to other greedy
and thresholding algorithms like &quot;SThresh&quot;, &quot;CoSaMP&quot;, &quot;StOMP&quot; and &quot;SWCGP&quot;. In
this paper, we find another consequence of the RIP property and use it to
analyze the approximation to k-sparse signals with Stagewise Weak versions of
Gradient Pursuit (SWGP), Matching Pursuit (SWMP) and Orthogonal Matching
Pursuit (SWOMP). We combine the above mentioned algorithms with another
selection rule similar to the ones that have appeared in the literature showing
that results are obtained with less restrictions in the RIP constant, but we
need a smaller threshold parameter for the coefficients. The results of some
experiments are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6971</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6971</id><created>2013-05-29</created><authors><author><keyname>Loiseau</keyname><forenames>Patrick</forenames></author><author><keyname>Schwartz</keyname><forenames>Galina</forenames></author><author><keyname>Musacchio</keyname><forenames>John</forenames></author><author><keyname>Amin</keyname><forenames>Saurabh</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author></authors><title>Incentive Mechanisms for Internet Congestion Management: Fixed-Budget
  Rebate versus Time-of-Day Pricing</title><categories>cs.NI cs.GT</categories><comments>To appear in IEEE/ACM Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile data traffic has been steadily rising in the past years. This has
generated a significant interest in the deployment of incentive mechanisms to
reduce peak-time congestion. Typically, the design of these mechanisms requires
information about user demand and sensitivity to prices. Such information is
naturally imperfect. In this paper, we propose a \emph{fixed-budget rebate
mechanism} that gives each user a reward proportional to his percentage
contribution to the aggregate reduction in peak time demand. For comparison, we
also study a time-of-day pricing mechanism that gives each user a fixed reward
per unit reduction of his peak-time demand. To evaluate the two mechanisms, we
introduce a game-theoretic model that captures the \emph{public good} nature of
decongestion. For each mechanism, we demonstrate that the socially optimal
level of decongestion is achievable for a specific choice of the mechanism's
parameter. We then investigate how imperfect information about user demand
affects the mechanisms' effectiveness. From our results, the fixed-budget
rebate pricing is more robust when the users' sensitivity to congestion is
&quot;sufficiently&quot; convex. This feature of the fixed-budget rebate mechanism is
attractive for many situations of interest and is driven by its closed-loop
property, i.e., the unit reward decreases as the peak-time demand decreases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6974</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6974</id><created>2013-05-29</created><authors><author><keyname>Tang</keyname><forenames>John</forenames></author><author><keyname>Leontiadis</keyname><forenames>Ilias</forenames></author><author><keyname>Scellato</keyname><forenames>Salvatore</forenames></author><author><keyname>Nicosia</keyname><forenames>Vincenzo</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author><author><keyname>Musolesi</keyname><forenames>Mirco</forenames></author><author><keyname>Latora</keyname><forenames>Vito</forenames></author></authors><title>Applications of Temporal Graph Metrics to Real-World Networks</title><categories>physics.soc-ph cs.SI</categories><comments>25 pages</comments><journal-ref>Chapter in Temporal Networks (Petter Holme and Jari Saram\&quot;aki
  editors). Springer. Berlin, Heidelberg 2013</journal-ref><doi>10.1007/978-3-642-36461-7_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real world networks exhibit rich temporal information: friends are added and
removed over time in online social networks; the seasons dictate the
predator-prey relationship in food webs; and the propagation of a virus depends
on the network of human contacts throughout the day. Recent studies have
demonstrated that static network analysis is perhaps unsuitable in the study of
real world network since static paths ignore time order, which, in turn,
results in static shortest paths overestimating available links and
underestimating their true corresponding lengths. Temporal extensions to
centrality and efficiency metrics based on temporal shortest paths have also
been proposed. Firstly, we analyse the roles of key individuals of a corporate
network ranked according to temporal centrality within the context of a
bankruptcy scandal; secondly, we present how such temporal metrics can be used
to study the robustness of temporal networks in presence of random errors and
intelligent attacks; thirdly, we study containment schemes for mobile phone
malware which can spread via short range radio, similar to biological viruses;
finally, we study how the temporal network structure of human interactions can
be exploited to effectively immunise human populations. Through these
applications we demonstrate that temporal metrics provide a more accurate and
effective analysis of real-world networks compared to their static
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6979</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6979</id><created>2013-05-29</created><authors><author><keyname>Ugander</keyname><forenames>Johan</forenames></author><author><keyname>Karrer</keyname><forenames>Brian</forenames></author><author><keyname>Backstrom</keyname><forenames>Lars</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author></authors><title>Graph cluster randomization: network exposure to multiple universes</title><categories>cs.SI physics.soc-ph stat.ME</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A/B testing is a standard approach for evaluating the effect of online
experiments; the goal is to estimate the `average treatment effect' of a new
feature or condition by exposing a sample of the overall population to it. A
drawback with A/B testing is that it is poorly suited for experiments involving
social interference, when the treatment of individuals spills over to
neighboring individuals along an underlying social network. In this work, we
propose a novel methodology using graph clustering to analyze average treatment
effects under social interference. To begin, we characterize graph-theoretic
conditions under which individuals can be considered to be `network exposed' to
an experiment. We then show how graph cluster randomization admits an efficient
exact algorithm to compute the probabilities for each vertex being network
exposed under several of these exposure conditions. Using these probabilities
as inverse weights, a Horvitz-Thompson estimator can then provide an effect
estimate that is unbiased, provided that the exposure model has been properly
specified.
  Given an estimator that is unbiased, we focus on minimizing the variance.
First, we develop simple sufficient conditions for the variance of the
estimator to be asymptotically small in n, the size of the graph. However, for
general randomization schemes, this variance can be lower bounded by an
exponential function of the degrees of a graph. In contrast, we show that if a
graph satisfies a restricted-growth condition on the growth rate of
neighborhoods, then there exists a natural clustering algorithm, based on
vertex neighborhoods, for which the variance of the estimator can be upper
bounded by a linear function of the degrees. Thus we show that proper cluster
randomization can lead to exponentially lower estimator variance when
experimentally measuring average treatment effects under interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6992</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6992</id><created>2013-05-29</created><authors><author><keyname>Dong</keyname><forenames>Jie</forenames></author><author><keyname>Smith</keyname><forenames>David</forenames></author></authors><title>Coexistence and Interference Mitigation for Wireless Body Area Networks:
  Improvements using On-Body Opportunistic Relaying</title><categories>cs.NI</categories><comments>25 pages, 12 figures. Submitted for possible publication on IEEE
  Transactions on Wireless Communications</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Coexistence, and hence interference mitigation, across multiple wireless body
area networks (WBANs) is an important problem as WBANs become more pervasive.
Here, two-hop relay-assisted cooperative communications using opportunistic
relaying (OR) is proposed for enhancement of coexistence for WBANs. Suitable
time division multiple access (TDMA) schemes are employed for both intra-WBAN
and inter-WBANs access protocols. To emulate actual conditions of WBAN use,
extensive on-body and inter-body &quot;everyday&quot; channel measurements are employed.
In addition, a realistic inter-WBAN channel model is simulated to investigate
the effect of body shadowing and hub location on WBAN performance in enabling
coexistence. When compared with single-link communications, it is found that
opportunistic relaying can provide significant improvement, in terms of
signal-to-interference+noise ratio (SINR), to outage probability and level
crossing rate (LCR) into outages. However, average outage duration (AOD) is not
affected. In addition a lognormal distribution shows a better fit to received
SINR when the channel coherence time is small, and a Nakagami-m distribution is
a more common fit when the channel is more stable. According to the estimated
SINR distributions, theoretical outage probability, LCR and AOD are shown to
match the empirical results well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.6993</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.6993</id><created>2013-05-29</created><authors><author><keyname>Ouyang</keyname><forenames>Yi</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>On The Optimality of Myopic Sensing in Multi-State Channels</title><categories>cs.SY cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the channel sensing problem arising in opportunistic scheduling
over fading channels, cognitive radio networks, and resource constrained
jamming. The communication system consists of N channels. Each channel is
modeled as a multi-state Markov chain (M.C.). At each time instant a user
selects one channel to sense and uses it to transmit information. A reward
depending on the state of the selected channel is obtained for each
transmission. The objective is to design a channel sensing policy that
maximizes the expected total reward collected over a finite or infinite
horizon. This problem can be viewed as an instance of a restless bandit
problem, for which the form of optimal policies is unknown in general. We
discover sets of conditions sufficient to guarantee the optimality of a myopic
sensing policy; we show that under one particular set of conditions the myopic
policy coincides with the Gittins index rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7006</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7006</id><created>2013-05-30</created><authors><author><keyname>Moustafa</keyname><forenames>Walaa Eldin</forenames></author><author><keyname>Kimmig</keyname><forenames>Angelika</forenames></author><author><keyname>Deshpande</keyname><forenames>Amol</forenames></author><author><keyname>Getoor</keyname><forenames>Lise</forenames></author></authors><title>Subgraph Pattern Matching over Uncertain Graphs with Identity Linkage
  Uncertainty</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing need for methods which can capture uncertainties and
answer queries over graph-structured data. Two common types of uncertainty are
uncertainty over the attribute values of nodes and uncertainty over the
existence of edges. In this paper, we combine those with identity uncertainty.
Identity uncertainty represents uncertainty over the mapping from objects
mentioned in the data, or references, to the underlying real-world entities. We
propose the notion of a probabilistic entity graph (PEG), a probabilistic graph
model that defines a distribution over possible graphs at the entity level. The
model takes into account node attribute uncertainty, edge existence
uncertainty, and identity uncertainty, and thus enables us to systematically
reason about all three types of uncertainties in a uniform manner. We introduce
a general framework for constructing a PEG given uncertain data at the
reference level and develop highly efficient algorithms to answer subgraph
pattern matching queries in this setting. Our algorithms are based on two novel
ideas: context-aware path indexing and reduction by join-candidates, which
drastically reduce the query search space. A comprehensive experimental
evaluation shows that our approach outperforms baseline implementations by
orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7014</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7014</id><created>2013-05-30</created><authors><author><keyname>Pavlyshenko</keyname><forenames>Bohdan</forenames></author></authors><title>Tweets Miner for Stock Market Analysis</title><categories>cs.IR cs.CL cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a software package for the data mining of Twitter
microblogs for the purpose of using them for the stock market analysis. The
package is written in R langauge using apropriate R packages. The model of
tweets has been considered. We have also compared stock market charts with
frequent sets of keywords in Twitter microblogs messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7038</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7038</id><created>2013-05-30</created><authors><author><keyname>Desoubeaux</keyname><forenames>Mathieu</forenames></author><author><keyname>Herzet</keyname><forenames>C&#xe9;dric</forenames></author><author><keyname>Puech</keyname><forenames>William</forenames></author><author><keyname>Guelvouit</keyname><forenames>Ga&#xeb;tan Le</forenames></author></authors><title>Enhanced blind decoding of Tardos codes with new map-based functions</title><categories>cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new decoder for probabilistic binary traitor tracing
codes under the marking assumption. It is based on a binary hypothesis testing
rule which integrates a collusion channel relaxation so as to obtain numerical
and simple accusation functions. This decoder is blind as no estimation of the
collusion channel prior to the accusation is required. Experimentations show
that using the proposed decoder gives better performance than the well-known
symmetric version of the Tardos decoder for common attack channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7050</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7050</id><created>2013-05-30</created><authors><author><keyname>Guck</keyname><forenames>Dennis</forenames></author><author><keyname>Hatefi</keyname><forenames>Hassan</forenames></author><author><keyname>Hermanns</keyname><forenames>Holger</forenames></author><author><keyname>Katoen</keyname><forenames>Joost-Pieter</forenames></author><author><keyname>Timmer</keyname><forenames>Mark</forenames></author></authors><title>Modelling, Reduction and Analysis of Markov Automata (extended version)</title><categories>cs.LO cs.DS cs.FL</categories><comments>Technical report accompanying the QEST 2013 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov automata (MA) constitute an expressive continuous-time compositional
modelling formalism. They appear as semantic backbones for engineering
frameworks including dynamic fault trees, Generalised Stochastic Petri Nets,
and AADL. Their expressive power has thus far precluded them from effective
analysis by probabilistic (and statistical) model checkers, stochastic game
solvers, or analysis tools for Petri net-like formalisms. This paper presents
the foundations and underlying algorithms for efficient MA modelling, reduction
using static analysis, and most importantly, quantitative analysis. We also
discuss implementation pragmatics of supporting tools and present several case
studies demonstrating feasibility and usability of MA in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7053</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7053</id><created>2013-05-30</created><authors><author><keyname>Zhang</keyname><forenames>Kaihua</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Lam</keyname><forenames>Kin-Man</forenames></author><author><keyname>Zhang</keyname><forenames>David</forenames></author></authors><title>A Local Active Contour Model for Image Segmentation with Intensity
  Inhomogeneity</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A novel locally statistical active contour model (ACM) for image segmentation
in the presence of intensity inhomogeneity is presented in this paper. The
inhomogeneous objects are modeled as Gaussian distributions of different means
and variances, and a moving window is used to map the original image into
another domain, where the intensity distributions of inhomogeneous objects are
still Gaussian but are better separated. The means of the Gaussian
distributions in the transformed domain can be adaptively estimated by
multiplying a bias field with the original signal within the window. A
statistical energy functional is then defined for each local region, which
combines the bias field, the level set function, and the constant approximating
the true signal of the corresponding object. Experiments on both synthetic and
real images demonstrate the superiority of our proposed algorithm to
state-of-the-art and representative methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7056</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7056</id><created>2013-05-30</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Dienstplanerstellung in Krankenhaeusern mittels genetischer Algorithmen</title><categories>cs.NE</categories><comments>Diplomarbeit, in German, Universitaet Mannheim, 1996</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis investigates the use of problem-specific knowledge to enhance a
genetic algorithm approach to multiple-choice optimisation problems. It shows
that such information can significantly enhance performance, but that the
choice of information and the way it is included are important factors for
success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7057</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7057</id><created>2013-05-30</created><authors><author><keyname>Mokhtar</keyname><forenames>Sahar A.</forenames></author><author><keyname>Elsayad</keyname><forenames>Alaa. M.</forenames></author></authors><title>Predicting the Severity of Breast Masses with Data Mining Methods</title><categories>cs.LG stat.ML</categories><journal-ref>International Journal of Computer Science Issues (IJCSI) March
  2013 Issue (Volume 10, Issue 2)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mammography is the most effective and available tool for breast cancer
screening. However, the low positive predictive value of breast biopsy
resulting from mammogram interpretation leads to approximately 70% unnecessary
biopsies with benign outcomes. Data mining algorithms could be used to help
physicians in their decisions to perform a breast biopsy on a suspicious lesion
seen in a mammogram image or to perform a short term follow-up examination
instead. In this research paper data mining classification algorithms; Decision
Tree (DT), Artificial Neural Network (ANN), and Support Vector Machine (SVM)
are analyzed on mammographic masses data set. The purpose of this study is to
increase the ability of physicians to determine the severity (benign or
malignant) of a mammographic mass lesion from BI-RADS attributes and the
patient,s age. The whole data set is divided for training the models and test
them by the ratio of 70:30% respectively and the performances of classification
algorithms are compared through three statistical measures; sensitivity,
specificity, and classification accuracy. Accuracy of DT, ANN and SVM are
78.12%, 80.56% and 81.25% of test samples respectively. Our analysis shows that
out of these three classification models SVM predicts severity of breast cancer
with least error rate and highest accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7058</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7058</id><created>2013-05-30</created><authors><author><keyname>Ibrahim</keyname><forenames>Nora Y.</forenames></author><author><keyname>Mokhtar</keyname><forenames>Sahar A.</forenames></author><author><keyname>Harb</keyname><forenames>Hany M.</forenames></author></authors><title>Towards an Ontology based integrated Framework for Semantic Web</title><categories>cs.AI</categories><journal-ref>International Journal of Computer Science and Information Security
  (IJCSIS) Vol. 10, No. 9, September 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Ontologies are widely used as a means for solving the information
heterogeneity problems on the web because of their capability to provide
explicit meaning to the information. They become an efficient tool for
knowledge representation in a structured manner. There is always more than one
ontology for the same domain. Furthermore, there is no standard method for
building ontologies, and there are many ontology building tools using different
ontology languages. Because of these reasons, interoperability between the
ontologies is very low. Current ontology tools mostly use functions to build,
edit and inference the ontology. Methods for merging heterogeneous domain
ontologies are not included in most tools. This paper presents ontology merging
methodology for building a single global ontology from heterogeneous eXtensible
Markup Language (XML) data sources to capture and maintain all the knowledge
which XML data sources can contain
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7071</identifier>
 <datestamp>2013-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7071</id><created>2013-05-30</created><authors><author><keyname>Gusenbauer</keyname><forenames>Markus</forenames></author><author><keyname>&#xd6;zelt</keyname><forenames>Harald</forenames></author><author><keyname>Fischbacher</keyname><forenames>Johann</forenames></author><author><keyname>Reichel</keyname><forenames>Franz</forenames></author><author><keyname>Exl</keyname><forenames>Lukas</forenames></author><author><keyname>Bance</keyname><forenames>Simon</forenames></author><author><keyname>Kataeva</keyname><forenames>Nadezhda</forenames></author><author><keyname>Binder</keyname><forenames>Claudia</forenames></author><author><keyname>Br&#xfc;ckl</keyname><forenames>Hubert</forenames></author><author><keyname>Schrefl</keyname><forenames>Thomas</forenames></author></authors><title>Simulation of magnetic active polymers for versatile microfluidic
  devices</title><categories>physics.bio-ph cs.CE physics.comp-ph physics.flu-dyn</categories><journal-ref>EPJ Web of Conferences. Vol. 40. EDP Sciences, 2013</journal-ref><doi>10.1051/epjconf/20134002001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to use a compound of magnetic nanoparticles (20-100 nm) embedded
in a flexible polymer (Polydimethylsiloxane PDMS) to filter circulating tumor
cells (CTCs). The analysis of CTCs is an emerging tool for cancer biology
research and clinical cancer management including the detection, diagnosis and
monitoring of cancer. The combination of experiments and simulations lead to a
versatile microfluidic lab-on-chip device. Simulations are essential to
understand the influence of the embedded nanoparticles in the elastic PDMS when
applying a magnetic gradient field. It combines finite element calculations of
the polymer, magnetic simulations of the embedded nanoparticles and the fluid
dynamic calculations of blood plasma and blood cells. With the use of magnetic
active polymers a wide range of tunable microfluidic structures can be created.
The method can help to increase the yield of needed isolated CTCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7072</identifier>
 <datestamp>2013-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7072</id><created>2013-05-30</created><authors><author><keyname>Gusenbauer</keyname><forenames>Markus</forenames></author><author><keyname>Nguyen</keyname><forenames>Ha</forenames></author><author><keyname>Reichel</keyname><forenames>Franz</forenames></author><author><keyname>Exl</keyname><forenames>Lukas</forenames></author><author><keyname>Bance</keyname><forenames>Simon</forenames></author><author><keyname>Fischbacher</keyname><forenames>Johann</forenames></author><author><keyname>&#xd6;zelt</keyname><forenames>Harald</forenames></author><author><keyname>Kovacs</keyname><forenames>Alexander</forenames></author><author><keyname>Brandl</keyname><forenames>Martin</forenames></author><author><keyname>Schrefl</keyname><forenames>Thomas</forenames></author></authors><title>Guided self-assembly of magnetic beads for biomedical applications</title><categories>physics.bio-ph cs.CE physics.comp-ph physics.flu-dyn</categories><doi>10.1016/j.physb.2013.08.050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Micromagnetic beads are widely used in biomedical applications for cell
separation, drug delivery, and hypothermia cancer treatment. Here we propose to
use self-organized magnetic bead structures which accumulate on fixed magnetic
seeding points to isolate circulating tumor cells. The analysis of circulating
tumor cells is an emerging tool for cancer biology research and clinical cancer
management including the detection, diagnosis and monitoring of cancer.
Microfluidic chips for isolating circulating tumor cells use either affinity,
size or density capturing methods. We combine multiphysics simulation
techniques to understand the microscopic behavior of magnetic beads interacting
with Nickel accumulation points used in lab-on-chip technologies. Our proposed
chip technology offers the possibility to combine affinity and size capturing
with special antibody-coated bead arrangements using a magnetic gradient field
created by Neodymium Iron Boron permanent magnets. The multiscale simulation
environment combines magnetic field computation, fluid dynamics and discrete
particle dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7103</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7103</id><created>2013-05-30</created><authors><author><keyname>Chanak</keyname><forenames>Prasenjit</forenames></author><author><keyname>Samanta</keyname><forenames>Tuhina</forenames></author><author><keyname>Banerjee</keyname><forenames>Indrajit</forenames></author></authors><title>Fault-tolerant multipath routing scheme for energy efficient wireless
  sensor networks</title><categories>cs.NI</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  5, No. 2, April 2013</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The main challenge in wireless sensor network is to improve the fault
tolerance of each node and also provide an energy efficient fast data routing
service. In this paper we propose an energy efficient node fault diagnosis and
recovery for wireless sensor networks referred as fault tolerant multipath
routing scheme for energy efficient wireless sensor network (FTMRS).The FTMRS
is based on multipath data routing scheme. One shortest path is use for main
data routing in FTMRS technique and other two backup paths are used as
alternative path for faulty network and to handle the overloaded traffic on
main channel. Shortest path data routing ensures energy efficient data routing.
The performance analysis of FTMRS shows better results compared to other
popular fault tolerant techniques in wireless sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7111</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7111</id><created>2013-05-30</created><authors><author><keyname>Maguedong-Djoumessi</keyname><forenames>Celestine Periale</forenames></author><author><keyname>Hern&#xe1;ndez-Orallo</keyname><forenames>Jos&#xe9;</forenames></author></authors><title>Test cost and misclassification cost trade-off using reframing</title><categories>cs.LG</categories><comments>Keywords: test cost, misclassification cost, missing values,
  reframing, ROC analysis, operating context, feature configuration, feature
  selection</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many solutions to cost-sensitive classification (and regression) rely on some
or all of the following assumptions: we have complete knowledge about the cost
context at training time, we can easily re-train whenever the cost context
changes, and we have technique-specific methods (such as cost-sensitive
decision trees) that can take advantage of that information. In this paper we
address the problem of selecting models and minimising joint cost (integrating
both misclassification cost and test costs) without any of the above
assumptions. We introduce methods and plots (such as the so-called JROC plots)
that can work with any off-the-shelf predictive technique, including ensembles,
such that we reframe the model to use the appropriate subset of attributes (the
feature configuration) during deployment time. In other words, models are
trained with the available attributes (once and for all) and then deployed by
setting missing values on the attributes that are deemed ineffective for
reducing the joint cost. As the number of feature configuration combinations
grows exponentially with the number of features we introduce quadratic methods
that are able to approximate the optimal configuration and model choices, as
shown by the experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7112</identifier>
 <datestamp>2015-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7112</id><created>2013-05-30</created><updated>2015-11-09</updated><authors><author><keyname>Raymond</keyname><forenames>Jean-Florent</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Low Polynomial Exclusion of Planar Graph Patterns</title><categories>math.CO cs.DM</categories><msc-class>05C83</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The celebrated grid exclusion theorem states that for every $h$-vertex planar
graph $H$, there is a constant $c_{h}$ such that if a graph $G$ does not
contain $H$ as a minor then $G$ has treewidth at most $c_{h}$. We are looking
for patterns of $H$ where this bound can become a low degree polynomial. We
provide such bounds for the following parameterized graphs: the wheel
($c_{h}=O(h)$), the double wheel ($c_{h}=O(h^2\cdot \log^{2} h)$), any graph of
pathwidth at most 2 ($c_{h}=O(h^{2})$), and the yurt graph ($c_{h}=O(h^{4})$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7114</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7114</id><created>2013-05-30</created><updated>2013-09-10</updated><authors><author><keyname>Ahmed</keyname><forenames>Mohamed</forenames></author><author><keyname>Traverso</keyname><forenames>Stefano</forenames></author><author><keyname>Garetto</keyname><forenames>Michele</forenames></author><author><keyname>Giaccone</keyname><forenames>Paolo</forenames></author><author><keyname>Leonardi</keyname><forenames>Emilio</forenames></author><author><keyname>Niccolini</keyname><forenames>Saverio</forenames></author></authors><title>Temporal Locality in Today's Content Caching: Why it Matters and How to
  Model it</title><categories>cs.NI</categories><comments>7 pages, 7 figures, Accepted for publication in ACM Computer
  Communication Review</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dimensioning of caching systems represents a difficult task in the design
of infrastructures for content distribution in the current Internet. This paper
addresses the problem of defining a realistic arrival process for the content
requests generated by users, due its critical importance for both analytical
and simulative evaluations of the performance of caching systems. First, with
the aid of YouTube traces collected inside operational residential networks, we
identify the characteristics of real traffic that need to be considered or can
be safely neglected in order to accurately predict the performance of a cache.
Second, we propose a new parsimonious traffic model, named the Shot Noise Model
(SNM), that enables users to natively capture the dynamics of content
popularity, whilst still being sufficiently simple to be employed effectively
for both analytical and scalable simulative studies of caching systems.
Finally, our results show that the SNM presents a much better solution to
account for the temporal locality observed in real traffic compared to existing
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7117</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7117</id><created>2013-05-30</created><authors><author><keyname>Demetriou</keyname><forenames>Michael A.</forenames></author></authors><title>Adaptation and optimization of synchronization gains in networked
  distributed parameter systems</title><categories>math.OC cs.SY</categories><comments>17 pages, 5 figures</comments><msc-class>93C20, 93C40, 35K90</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is concerned with the design and effects of the synchronization
gains on the synchronization problem for a class of networked distributed
parameter systems. The networked systems, assumed to be described by the same
evolution equation in a Hilbert space, differ in their initial conditions. The
proposed synchronization controllers aim at achieving both the control
objective and the synchronization objective. To enhance the synchronization, as
measured by the norm of the pairwise state difference of the networked systems,
an adaptation of the gains is proposed. An alternative design arrives at
constant gains that are optimized with respect to an appropriate measure of
synchronization. A subsequent formulation casts the control and synchronization
design problem into an optimal control problem for the aggregate systems. An
extensive numerical study examines the various aspects of the optimization and
adaptation of the gains on the control and synchronization of networked 1D
parabolic differential equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7120</identifier>
 <datestamp>2015-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7120</id><created>2013-05-30</created><updated>2015-12-18</updated><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Durand</keyname><forenames>Ir&#xe8;ne</forenames></author></authors><title>Computations by fly-automata beyond monadic second-order logic</title><categories>cs.LO</categories><comments>Accepted for publication in Theoretical Computer Science</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present logically based methods for constructing XP and FPT graph
algorithms, parametrized by tree-width or clique-width. We will use
fly-automata introduced in a previous article. They make possible to check
properties that are not monadic second-order expressible because their states
may include counters, so that their sets of states may be infinite. We equip
these automata with output functions, so that they can compute values
associated with terms or graphs. Rather than new algorithmic results we present
tools for constructing easily certain dynamic programming algorithms by
combining predefined automata for basic functions and properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7121</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7121</id><created>2013-05-30</created><authors><author><keyname>Merc&#xe8;re</keyname><forenames>Guillaume</forenames></author></authors><title>Regression techniques for subspace-based black-box state-space system
  identification: an overview</title><categories>cs.SY</categories><comments>Technical report</comments><report-no>UP_AS_001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As far as the identification of linear time-invariant state-space
representation is concerned, among all of the solutions available in the
literature, the subspace-based state-space model identification techniques have
proved their efficiency in many practical cases since the beginning of the
90's. This paper introduces an overview of these techniques by focusing on
their formulation as a least-squares problem. Apart from an article written by
J. Qin, to the author's knowledge, such a regression formulation is not totally
investigated in the books which can be considered as the references as far as
subspace-based identification is concerned. Thus, in this paper, a specific
attention is payed to the regression-based techniques used to identify systems
working under open-loop as well as closed-loop conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7128</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7128</id><created>2013-05-30</created><authors><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Adaptive Alert Throttling for Intrusion Detection Systems</title><categories>cs.CR</categories><comments>University of Nottingham Computer Science Technical Report 2003.
  arXiv admin note: substantial text overlap with arXiv:0801.4119,
  arXiv:0804.1281</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each time that an intrusion detection system raises an alert it must make
some attempt to communicate the information to an operator. This communication
channel can easily become the target of a denial of service attack because,
like all communication channels, it has a fixed capacity. If this channel can
become overwhelmed with bogus data, an attacker can quickly achieve complete
neutralisation of intrusion detection capability. Although these types of
attack are very hard to stop completely, our aim is to present techniques that
improve alert throughput and capacity to such an extent that the resources
required to successfully mount the attack become prohibitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7130</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7130</id><created>2013-05-30</created><authors><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Memory Implementations - Current Alternatives</title><categories>cs.AI cs.NE</categories><comments>University of Nottingham, 2005</comments><report-no>NOTTCS-TR-2005-4</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory can be defined as the ability to retain and recall information in a
diverse range of forms. It is a vital component of the way in which we as human
beings operate on a day to day basis. Given a particular situation, decisions
are made and actions undertaken in response to that situation based on our
memory of related prior events and experiences. By utilising our memory we can
anticipate the outcome of our chosen actions to avoid unexpected or unwanted
events. In addition, as we subtly alter our actions and recognise altered
outcomes we learn and create new memories, enabling us to improve the
efficiency of our actions over time. However, as this process occurs so
naturally in the subconscious its importance is often overlooked.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7144</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7144</id><created>2013-05-30</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author></authors><title>Immune System Approaches to Intrusion Detection - A Review (ICARIS)</title><categories>cs.CR cs.NE</categories><comments>Proceedings of the 3rd International Conference on Artificial Immune
  Systems (ICARIS), 316-329, 2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of artificial immune systems in intrusion detection is an appealing
concept for two reasons. Firstly, the human immune system provides the human
body with a high level of protection from invading pathogens, in a robust,
self-organised and distributed manner. Secondly, current techniques used in
computer security are not able to cope with the dynamic and increasingly
complex nature of computer systems and their security. It is hoped that
biologically inspired approaches in this area, including the use of
immune-based systems will be able to meet this challenge. Here we collate the
algorithms used, the development of the systems and the outcome of their
implementation. It provides an introduction and review of the key developments
within this field, in addition to making suggestions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7145</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7145</id><created>2013-05-30</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Menachof</keyname><forenames>David</forenames></author><author><keyname>Sherman</keyname><forenames>Galina</forenames></author><author><keyname>Zimmerman</keyname><forenames>Peter</forenames></author></authors><title>Modelling and Analysing Cargo Screening Processes: A Project Outline</title><categories>cs.AI cs.CY</categories><comments>Proceedings of the INFORMS Simulation Society Research Workshop, June
  25-27, 2009, Warwick, UK, 44-47, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficiency of current cargo screening processes at sea and air ports is
unknown as no benchmarks exists against which they could be measured. Some
manufacturer benchmarks exist for individual sensors but we have not found any
benchmarks that take a holistic view of the screening procedures assessing a
combination of sensors and also taking operator variability into account. Just
adding up resources and manpower used is not an effective way for assessing
systems where human decision-making and operator compliance to rules play a
vital role. For such systems more advanced assessment methods need to be used,
taking into account that the cargo screening process is of a dynamic and
stochastic nature. Our project aim is to develop a decision support tool
(cargo-screening system simulator) that will map the right technology and
manpower to the right commodity-threat combination in order to maximize
detection rates. In this paper we present a project outline and highlight the
research challenges we have identified so far. In addition we introduce our
first case study, where we investigate the cargo screening process at the ferry
port in Calais.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7146</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7146</id><created>2013-05-30</created><authors><author><keyname>Coscia</keyname><forenames>Michele</forenames></author><author><keyname>Rossetti</keyname><forenames>Giulio</forenames></author><author><keyname>Pennacchioli</keyname><forenames>Diego</forenames></author><author><keyname>Ceccarelli</keyname><forenames>Damiano</forenames></author><author><keyname>Giannotti</keyname><forenames>Fosca</forenames></author></authors><title>&quot;You Know Because I Know&quot;: a Multidimensional Network Approach to Human
  Resources Problem</title><categories>cs.SI cs.CY cs.DS physics.soc-ph</categories><journal-ref>Advances in Social Network Analysis and Mining (ASONAM) 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding talents, often among the people already hired, is an endemic
challenge for organizations. The social networking revolution, with online
tools like Linkedin, made possible to make explicit and accessible what we
perceived, but not used, for thousands of years: the exact position and ranking
of a person in a network of professional and personal connections. To search
and mine where and how an employee is positioned on a global skill network will
enable organizations to find unpredictable sources of knowledge, innovation and
know-how. This data richness and hidden knowledge demands for a
multidimensional and multiskill approach to the network ranking problem.
Multidimensional networks are networks with multiple kinds of relations. To the
best of our knowledge, no network-based ranking algorithm is able to handle
multidimensional networks and multiple rankings over multiple attributes at the
same time. In this paper we propose such an algorithm, whose aim is to address
the node multi-ranking problem in multidimensional networks. We test our
algorithm over several real world networks, extracted from DBLP and the Enron
email corpus, and we show its usefulness in providing less trivial and more
flexible rankings than the current state of the art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7167</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7167</id><created>2013-05-30</created><updated>2014-04-03</updated><authors><author><keyname>Zaichenkov</keyname><forenames>Pavel</forenames><affiliation>University of Hertfordshire</affiliation><affiliation>Moscow Institute of Physics and Technology</affiliation></author><author><keyname>Gijsbers</keyname><forenames>Bert</forenames><affiliation>Ghent University</affiliation><affiliation>University of Amsterdam</affiliation></author><author><keyname>Grelck</keyname><forenames>Clemens</forenames><affiliation>University of Amsterdam</affiliation></author><author><keyname>Tveretina</keyname><forenames>Olga</forenames><affiliation>University of Hertfordshire</affiliation></author><author><keyname>Shafarenko</keyname><forenames>Alex</forenames><affiliation>University of Hertfordshire</affiliation></author></authors><title>A Case Study in Coordination Programming: Performance Evaluation of
  S-Net vs Intel's Concurrent Collections</title><categories>cs.PL cs.DC</categories><comments>9 pages, 8 figures, 1 table, accepted for PLC 2014 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a programming methodology and runtime performance case study
comparing the declarative data flow coordination language S-Net with Intel's
Concurrent Collections (CnC). As a coordination language S-Net achieves a
near-complete separation of concerns between sequential software components
implemented in a separate algorithmic language and their parallel orchestration
in an asynchronous data flow streaming network. We investigate the merits of
S-Net and CnC with the help of a relevant and non-trivial linear algebra
problem: tiled Cholesky decomposition. We describe two alternative S-Net
implementations of tiled Cholesky factorization and compare them with two CnC
implementations, one with explicit performance tuning and one without, that
have previously been used to illustrate Intel CnC. Our experiments on a 48-core
machine demonstrate that S-Net manages to outperform CnC on this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7169</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7169</id><created>2013-05-30</created><authors><author><keyname>Mankad</keyname><forenames>Shawn</forenames></author><author><keyname>Michailidis</keyname><forenames>George</forenames></author></authors><title>Structural and Functional Discovery in Dynamic Networks with
  Non-negative Matrix Factorization</title><categories>cs.SI physics.soc-ph stat.ML</categories><comments>16 pages, 17 figures</comments><doi>10.1103/PhysRevE.88.042812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time series of graphs are increasingly prevalent in modern data and pose
unique challenges to visual exploration and pattern extraction. This paper
describes the development and application of matrix factorizations for
exploration and time-varying community detection in time-evolving graph
sequences. The matrix factorization model allows the user to home in on and
display interesting, underlying structure and its evolution over time. The
methods are scalable to weighted networks with a large number of time points or
nodes, and can accommodate sudden changes to graph topology. Our techniques are
demonstrated with several dynamic graph series from both synthetic and real
world data, including citation and trade networks. These examples illustrate
how users can steer the techniques and combine them with existing methods to
discover and display meaningful patterns in sizable graphs over many time
points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7181</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7181</id><created>2013-05-30</created><authors><author><keyname>Huang</keyname><forenames>Gang</forenames></author><author><keyname>Jiang</keyname><forenames>Hong</forenames></author><author><keyname>Matthews</keyname><forenames>Kim</forenames></author><author><keyname>Wilford</keyname><forenames>Paul</forenames></author></authors><title>Lensless Imaging by Compressive Sensing</title><categories>cs.CV</categories><comments>Accepted ICIP 2013. 5 Pages, 7 Figures. arXiv admin note: substantial
  text overlap with arXiv:1302.1789</comments><journal-ref>IEEE International Conference on Image Processing, ICIP 2013,
  Paper #2393</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a lensless compressive imaging architecture. The
architecture consists of two components, an aperture assembly and a sensor. No
lens is used. The aperture assembly consists of a two dimensional array of
aperture elements. The transmittance of each aperture element is independently
controllable. The sensor is a single detection element. A compressive sensing
matrix is implemented by adjusting the transmittance of the individual aperture
elements according to the values of the sensing matrix. The proposed
architecture is simple and reliable because no lens is used. The architecture
can be used for capturing images of visible and other spectra such as infrared,
or millimeter waves, in surveillance applications for detecting anomalies or
extracting features such as speed of moving objects. Multiple sensors may be
used with a single aperture assembly to capture multi-view images
simultaneously. A prototype was built by using a LCD panel and a photoelectric
sensor for capturing images of visible spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7182</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7182</id><created>2013-05-30</created><authors><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Average Consensus on Arbitrary Strongly Connected Digraphs with
  Time-Varying Topologies</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have recently proposed a &quot;surplus-based&quot; algorithm which solves the
multi-agent average consensus problem on general strongly connected and static
digraphs. The essence of that algorithm is to employ an additional variable to
keep track of the state changes of each agent, thereby achieving averaging even
though the state sum is not preserved. In this note, we extend this approach to
the more interesting and challenging case of time-varying topologies: An
extended surplus-based averaging algorithm is designed, under which a necessary
and sufficient graphical condition is derived that guarantees state averaging.
The derived condition requires only that the digraphs be arbitrary strongly
connected in a \emph{joint} sense, and does not impose &quot;balanced&quot; or
&quot;symmetric&quot; properties on the network topology, which is therefore more general
than those previously reported in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7185</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7185</id><created>2013-05-30</created><authors><author><keyname>Martin</keyname><forenames>Philippe A.</forenames></author></authors><title>Collaborative ontology sharing and editing</title><categories>cs.AI</categories><comments>12 pages, 2 figures, journal</comments><acm-class>I.2.4</acm-class><journal-ref>IJCSIS 6 (2011) 14-29</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article first lists reasons why - in the long term or when creating a
new knowledge base (KB) for general knowledge sharing purposes -
collaboratively building a well-organized KB does/can provide more
possibilities, with on the whole no more costs, than the mainstream approach
where knowledge creation and re-use involves searching, merging and creating
(semi-)independent (relatively small) ontologies or semi-formal documents. The
article lists elements required to achieve this and describes the main one: a
KB editing protocol that keeps the KB free of automatically/manually detected
inconsistencies while not forcing them to discuss or agree on terminology and
beliefs nor requiring a selection committee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7196</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7196</id><created>2013-05-30</created><authors><author><keyname>Martin</keyname><forenames>Philippe A.</forenames></author></authors><title>For a Semantic Web based Peer-reviewing and Publication of Research
  Results</title><categories>cs.DL cs.AI</categories><comments>6 pages, conference</comments><journal-ref>KGCM (2012) 23-28</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article shows why the diffusion and peer-reviewing of research results
would be more efficient, precise and relevant if all or at least some parts of
the descriptions and peer-reviews of research results took the form of a
fine-grained semantic network, within articles or knowledge bases, as part of
the Semantic Web. This article also shows some ways this can be done and hence
how research journal/proceeding publishers could allow this. So far, the World
Wide Web Consortium (W3C) has not proposed simple notations and cooperation
protocols - similar to those illustrated or referred to in this article - but
it now seems likely that Wikipedia/Wikidata, Google or the W3C will propose
them sooner or later. Then, research journal/proceeding publishers and
researchers may or may not quickly use this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7200</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7200</id><created>2013-05-30</created><authors><author><keyname>Martin</keyname><forenames>Philippe A.</forenames></author></authors><title>Organizing Linked Data Quality Related Methods</title><categories>cs.DL cs.AI cs.IR</categories><comments>7 pages, 10 tables, conference</comments><acm-class>I.2.4</acm-class><journal-ref>IKE (2012) 376-382</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents the top-level of an ontology categorizing and
generalizing best practices and quality criteria or measures for Linked Data.
It permits to compare these techniques and have a synthetic organized view of
what can or should be done for knowledge sharing purposes. This ontology is
part of a general knowledge base that can be accessed and complemented by any
Web user. Thus, it can be seen as a cooperatively built library for the above
cited elements. Since they permit to evaluate information objects and create
better ones, these elements also permit knowledge-based tools and techniques -
as well as knowledge providers - to be evaluated and categorized based on their
input/output information objects. One top-level distinction permitting to
organize this ontology is the one between content, medium and containers of
descriptions. Various structural, ontological, syntactical and lexical
distinctions are then used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7214</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7214</id><created>2013-05-30</created><authors><author><keyname>Xie</keyname><forenames>Jianwei</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Secure Degrees of Freedom of K-User Gaussian Interference Channels: A
  Unified View</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, May 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the exact sum secure degrees of freedom (d.o.f.) of the K-user
Gaussian interference channel. We consider three different secrecy constraints:
1) K-user interference channel with one external eavesdropper (IC-EE), 2)
K-user interference channel with confidential messages (IC-CM), and 3) K-user
interference channel with confidential messages and one external eavesdropper
(IC-CM-EE). We show that for all of these three cases, the exact sum secure
d.o.f. is K(K-1)/(2K-1). We show converses for IC-EE and IC-CM, which imply a
converse for IC-CM-EE. We show achievability for IC-CM-EE, which implies
achievability for IC-EE and IC-CM. We develop the converses by relating the
channel inputs of interfering users to the reliable rates of the interfered
users, and by quantifying the secrecy penalty in terms of the eavesdroppers'
observations. Our achievability uses structured signaling, structured
cooperative jamming, channel prefixing, and asymptotic real interference
alignment. While the traditional interference alignment provides some amount of
secrecy by mixing unintended signals in a smaller sub-space at every receiver,
in order to attain the optimum sum secure d.o.f., we incorporate structured
cooperative jamming into the achievable scheme, and intricately design the
structure of all of the transmitted signals jointly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7250</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7250</id><created>2013-05-30</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>Harnessing Simultaneously the Benefits of UWB and MBWA: A Practical
  Scenario</title><categories>cs.IT cs.NI math.IT</categories><comments>Proc. of the 22nd IEEE Canadian Conference on Electrical and Computer
  Engineering (CCECE'09)</comments><doi>10.1109/CCECE.2009.5090185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UWB has a very large bandwidth in a WPAN network, which is best used for
HD-video applications. Meanwhile, MBWA is a WMAN option optimized for
wireless-IP in a fast moving vehicle. In this paper, we propose a practical
engineering scenario that harnesses simultaneously the distinctive feature of
both UWB and MBWA. However, this in-proximity operation of the technologies
will inevitably cause mutual interference to both systems. In light of this, as
a preliminary phase to coexistence, we have derived, under various
circumstances, the maximum interference power limit that needs to be respected
in order to ensure an acceptable system performance as requested by the new
IEEE 802.20 standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7252</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7252</id><created>2013-05-30</created><authors><author><keyname>Adhikary</keyname><forenames>Ansuman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Joint Spatial Division and Multiplexing: Opportunistic Beamforming and
  User Grouping</title><categories>cs.IT math.IT</categories><comments>37 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint Spatial Division and Multiplexing (JSDM) is a recently proposed scheme
to enable massive MIMO like gains and simplified system operations for
Frequency Division Duplexing (FDD) systems. The key idea lies in partitioning
the users into groups with approximately similar covariances, and use a two
stage downlink beamforming: a pre-beamformer that depends on the channel
covariances and minimizes interference across groups and a multiuser MIMO
precoder for the effective channel after pre-beamforming, to counteract
interference within a group. We first focus on the regime of a fixed number of
antennas and large number of users, and show that opportunistic beamforming
with user selection yields significant gain, and thus, channel correlation may
yield a capacity improvement over the uncorrelated &quot;isotropic&quot; channel result
of Sharif and Hassibi. We prove that in the presence of different correlations
among groups, a block diagonalization approach for the design of
pre-beamformers achieves the optimal sum-rate scaling. Next, we consider the
regime of large number of antennas and users, where user selection does not
provide significant gain. Here, we propose a simplified user grouping algorithm
to cluster users into groups when the number of antennas becomes very large, in
a realistic setting where users are randomly distributed and have different
angles of arrival and angular spreads depending on the propagation environment.
Our subsequent analysis leads to a probabilistic scheduling algorithm, where
users within each group are preselected at random based on probabilities
derived from the large system analysis, depending on the fairness criterion.
This is advantageous since only the selected users are required to feedback
their channel state information (CSIT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7254</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7254</id><created>2013-05-30</created><authors><author><keyname>Ayachi</keyname><forenames>I.</forenames></author><author><keyname>Kammarti</keyname><forenames>R.</forenames></author><author><keyname>Ksouri</keyname><forenames>M.</forenames></author><author><keyname>LACS</keyname><forenames>P. Borne</forenames></author><author><keyname>ENIT</keyname></author><author><keyname>LAGIS</keyname><forenames>Tunis-Belvedere Tunisie</forenames></author><author><keyname>ECL</keyname></author><author><keyname>Ascq</keyname><forenames>Villeneuve d</forenames></author><author><keyname>France</keyname></author></authors><title>Harmony search to solve the container storage problem with different
  container types</title><categories>cs.AI</categories><comments>7 pages</comments><report-no>Volume 48-- No.22, June 2012</report-no><journal-ref>International Journal of Computer Applications, June 2012</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents an adaptation of the harmony search algorithm to solve
the storage allocation problem for inbound and outbound containers. This
problem is studied considering multiple container type (regular, open side,
open top, tank, empty and refrigerated) which lets the situation more
complicated, as various storage constraints appeared. The objective is to find
an optimal container arrangement which respects their departure dates, and
minimize the re-handle operations of containers. The performance of the
proposed approach is verified comparing to the results generated by genetic
algorithm and LIFO algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7265</identifier>
 <datestamp>2015-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7265</id><created>2013-05-30</created><authors><author><keyname>Seyfi</keyname><forenames>Ali</forenames></author></authors><title>A Focused Crawler Combinatory Link and Content Model Based on T-Graph
  Principles</title><categories>cs.IR cs.DL</categories><comments>14 pages, 6 figures</comments><doi>10.1016/j.csi.2015.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two significant tasks of a focused Web crawler are finding relevant
topic-specific documents on the Web and analytically prioritizing them for
later effective and reliable download. For the first task, we propose a
sophisticated custom algorithm to fetch and analyze the most effective HTML
structural elements of the page as well as the topical boundary and anchor text
of each unvisited link, based on which the topical focus of an unvisited page
can be predicted and elicited with a high accuracy. Thus, our novel method
uniquely combines both link-based and content-based approaches. For the second
task, we propose a scoring function of the relevant URLs through the use of
T-Graph (Treasure Graph) to assist in prioritizing the unvisited links that
will later be put into the fetching queue. Our Web search system is called the
Treasure-Crawler. This research paper embodies the architectural design of the
Treasure-Crawler system which satisfies the principle requirements of a focused
Web crawler, and asserts the correctness of the system structure including all
its modules through illustrations and by the test results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7272</identifier>
 <datestamp>2014-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7272</id><created>2013-05-30</created><updated>2014-03-14</updated><authors><author><keyname>Heng</keyname><forenames>Liang</forenames></author><author><keyname>Gao</keyname><forenames>Grace Xingxin</forenames></author></authors><title>Accuracy of Range-Based Cooperative Localization in Wireless Sensor
  Networks: A Lower Bound Analysis</title><categories>cs.NI cs.MA</categories><comments>11 pages, 6 figures, 1 table</comments><acm-class>C.2.1</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Accurate location information is essential for many wireless sensor network
(WSN) applications. A location-aware WSN generally includes two types of nodes:
sensors whose locations to be determined and anchors whose locations are known
a priori. For range-based localization, sensors' locations are deduced from
anchor-to-sensor and sensor-to-sensor range measurements. Localization accuracy
depends on the network parameters such as network connectivity and size. This
paper provides a generalized theory that quantitatively characterizes such
relation between network parameters and localization accuracy. We use the
average degree as a connectivity metric and use geometric dilution of precision
(DOP), equivalent to the Cramer-Rao bound, to quantify localization accuracy.
We prove a novel lower bound on expectation of average geometric DOP
(LB-E-AGDOP) and derives a closed-form formula that relates LB-E-AGDOP to only
three parameters: average anchor degree, average sensor degree, and number of
sensor nodes. The formula shows that localization accuracy is approximately
inversely proportional to the average degree, and a higher ratio of average
anchor degree to average sensor degree yields better localization accuracy.
Furthermore, the paper demonstrates a strong connection between LB-E-AGDOP and
the best achievable accuracy. Finally, we validate the theory via numerical
simulations with three different random graph models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7294</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7294</id><created>2013-05-30</created><authors><author><keyname>Tang</keyname><forenames>Chunming</forenames></author><author><keyname>Qi</keyname><forenames>Yanfeng</forenames></author><author><keyname>Xu</keyname><forenames>Maozhi</forenames></author></authors><title>A Note on Cyclic Codes from APN Functions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclic codes, as linear block error-correcting codes in coding theory, play a
vital role and have wide applications. Ding in \cite{D} constructed a number of
classes of cyclic codes from almost perfect nonlinear (APN) functions and
planar functions over finite fields and presented ten open problems on cyclic
codes from highly nonlinear functions. In this paper, we consider two open
problems involving the inverse APN functions $f(x)=x^{q^m-2}$ and the Dobbertin
APN function $f(x)=x^{2^{4i}+2^{3i}+2^{2i}+2^{i}-1}$. From the calculation of
linear spans and the minimal polynomials of two sequences generated by these
two classes of APN functions, the dimensions of the corresponding cyclic codes
are determined and lower bounds on the minimum weight of these cyclic codes are
presented. Actually, we present a framework for the minimal polynomial and
linear span of the sequence $s^{\infty}$ defined by $s_t=Tr((1+\alpha^t)^e)$,
where $\alpha$ is a primitive element in $GF(q)$. These techniques can also be
applied into other open problems in \cite{D}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7296</identifier>
 <datestamp>2013-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7296</id><created>2013-05-30</created><authors><author><keyname>Judd</keyname><forenames>Kevin</forenames></author><author><keyname>Small</keyname><forenames>Michael</forenames></author><author><keyname>Stemler</keyname><forenames>Thomas</forenames></author></authors><title>What exactly are the properties of scale-free and other networks?</title><categories>nlin.AO cs.SI physics.comp-ph physics.soc-ph</categories><comments>Preprint - submitted, 6 pages, 3 figures</comments><journal-ref>2013 EPL 103 58004</journal-ref><doi>10.1209/0295-5075/103/58004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of scale-free networks has been widely applied across natural and
physical sciences. Many claims are made about the properties of these networks,
even though the concept of scale-free is often vaguely defined. We present
tools and procedures to analyse the statistical properties of networks defined
by arbitrary degree distributions and other constraints. Doing so reveals the
highly likely properties, and some unrecognised richness, of scale-free
networks, and casts doubt on some previously claimed properties being due to a
scale-free characteristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7311</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7311</id><created>2013-05-31</created><authors><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Pan</keyname><forenames>Chunhong</forenames></author><author><keyname>Xiang</keyname><forenames>Shiming</forenames></author><author><keyname>Zhu</keyname><forenames>Feiyun</forenames></author></authors><title>Robust Hyperspectral Unmixing with Correntropy based Metric</title><categories>cs.CV</categories><comments>arXiv admin note: text overlap with arXiv:1202.6294 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral unmixing is one of the crucial steps for many hyperspectral
applications. The problem of hyperspectral unmixing has proven to be a
difficult task in unsupervised work settings where the endmembers and
abundances are both unknown. What is more, this task becomes more challenging
in the case that the spectral bands are degraded with noise. This paper
presents a robust model for unsupervised hyperspectral unmixing. Specifically,
our model is developed with the correntropy based metric where the non-negative
constraints on both endmembers and abundances are imposed to keep physical
significance. In addition, a sparsity prior is explicitly formulated to
constrain the distribution of the abundances of each endmember. To solve our
model, a half-quadratic optimization technique is developed to convert the
original complex optimization problem into an iteratively re-weighted NMF with
sparsity constraints. As a result, the optimization of our model can adaptively
assign small weights to noisy bands and give more emphasis on noise-free bands.
In addition, with sparsity constraints, our model can naturally generate sparse
abundances. Experiments on synthetic and real data demonstrate the
effectiveness of our model in comparison to the related state-of-the-art
unmixing models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7316</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7316</id><created>2013-05-31</created><authors><author><keyname>Nghiem</keyname><forenames>Minh-Quoc</forenames></author><author><keyname>Kristianto</keyname><forenames>Giovanni Yoko</forenames></author><author><keyname>Topic</keyname><forenames>Goran</forenames></author><author><keyname>Aizawa</keyname><forenames>Akiko</forenames></author></authors><title>A hybrid approach for semantic enrichment of MathML mathematical
  expressions</title><categories>cs.DL cs.IR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we present a new approach to the semantic enrichment of
mathematical expression problem. Our approach is a combination of statistical
machine translation and disambiguation which makes use of surrounding text of
the mathematical expressions. We first use Support Vector Machine classifier to
disambiguate mathematical terms using both their presentation form and
surrounding text. We then use the disambiguation result to enhance the semantic
enrichment of a statistical-machine-translation-based system. Experimental
results show that our system archives improvements over prior systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7323</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7323</id><created>2013-05-31</created><updated>2013-06-16</updated><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Anand</keyname><forenames>Kushal</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Gunawan</keyname><forenames>Erry</forenames></author></authors><title>Sub-Stream Fairness and Numerical Correctness in MIMO Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>To be presented at IEEE ISWTA'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal-to-interference plus noise ratio (SINR) and rate fairness in a system
are substantial quality-of-service (QoS) metrics. The acclaimed SINR
maximization (max-SINR) algorithm does not achieve fairness between user's
streams, i.e., sub-stream fairness is not achieved. To this end, we propose a
distributed power control algorithm to render sub-stream fairness in the
system. Sub-stream fairness is a less restrictive design metric than stream
fairness (i.e., fairness between all streams) thus sum-rate degradation is
milder. Algorithmic parameters can significantly differentiate the results of
numerical algorithms. A complete picture for comparison of algorithms can only
be depicted by varying these parameters. For example, a predetermined iteration
number or a negligible increment in the sum-rate can be the stopping criteria
of an algorithm. While the distributed interference alignment (DIA) can
reasonably achieve sub-stream fairness for the later, the imbalance between
sub-streams increases as the preset iteration number decreases. Thus comparison
of max-SINR and DIA with a low preset iteration number can only depict a part
of the picture. We analyze such important parameters and their effects on SINR
and rate metrics to exhibit numerical correctness in executing the benchmarks.
Finally, we propose group filtering schemes that jointly design the streams of
a user in contrast to max-SINR scheme that designs each stream of a user
separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7331</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7331</id><created>2013-05-31</created><updated>2013-06-05</updated><authors><author><keyname>Kumar</keyname><forenames>M. Naresh</forenames></author></authors><title>Alternating Decision trees for early diagnosis of dengue fever</title><categories>cs.LG q-bio.QM stat.AP</categories><comments>13 pages, 5 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dengue fever is a flu-like illness spread by the bite of an infected mosquito
which is fast emerging as a major health problem. Timely and cost effective
diagnosis using clinical and laboratory features would reduce the mortality
rates besides providing better grounds for clinical management and disease
surveillance. We wish to develop a robust and effective decision tree based
approach for predicting dengue disease. Our analysis is based on the clinical
characteristics and laboratory measurements of the diseased individuals. We
have developed and trained an alternating decision tree with boosting and
compared its performance with C4.5 algorithm for dengue disease diagnosis. Of
the 65 patient records a diagnosis establishes that 53 individuals have been
confirmed to have dengue fever. An alternating decision tree based algorithm
was able to differentiate the dengue fever using the clinical and laboratory
data with number of correctly classified instances as 89%, F-measure of 0.86
and receiver operator characteristics (ROC) of 0.826 as compared to C4.5 having
correctly classified instances as 78%,h F-measure of 0.738 and ROC of 0.617
respectively. Alternating decision tree based approach with boosting has been
able to predict dengue fever with a higher degree of accuracy than C4.5 based
decision tree using simple clinical and laboratory features. Further analysis
on larger data sets is required to improve the sensitivity and specificity of
the alternating decision trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7332</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7332</id><created>2013-05-31</created><updated>2013-12-04</updated><authors><author><keyname>Hermanns</keyname><forenames>Holger</forenames></author><author><keyname>Kr&#x10d;&#xe1;l</keyname><forenames>Jan</forenames></author><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author></authors><title>Compositional Verification and Optimization of Interactive Markov Chains</title><categories>cs.LO cs.SY</categories><doi>10.1007/978-3-642-40184-8_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactive Markov chains (IMC) are compositional behavioural models
extending labelled transition systems and continuous-time Markov chains. We
provide a framework and algorithms for compositional verification and
optimization of IMC with respect to time-bounded properties. Firstly, we give a
specification formalism for IMC. Secondly, given a time-bounded property, an
IMC component and the assumption that its unknown environment satisfies a given
specification, we synthesize a scheduler for the component optimizing the
probability that the property is satisfied in any such environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7345</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7345</id><created>2013-05-31</created><updated>2013-09-13</updated><authors><author><keyname>Dylla</keyname><forenames>Frank</forenames></author><author><keyname>Mossakowski</keyname><forenames>Till</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author><author><keyname>Wolter</keyname><forenames>Diedrich</forenames></author></authors><title>Algebraic Properties of Qualitative Spatio-Temporal Calculi</title><categories>cs.AI</categories><comments>COSIT 2013 paper including supplementary material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Qualitative spatial and temporal reasoning is based on so-called qualitative
calculi. Algebraic properties of these calculi have several implications on
reasoning algorithms. But what exactly is a qualitative calculus? And to which
extent do the qualitative calculi proposed meet these demands? The literature
provides various answers to the first question but only few facts about the
second. In this paper we identify the minimal requirements to binary
spatio-temporal calculi and we discuss the relevance of the according axioms
for representation and reasoning. We also analyze existing qualitative calculi
and provide a classification involving different notions of a relation algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7351</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7351</id><created>2013-05-31</created><authors><author><keyname>Adsul</keyname><forenames>Bharat</forenames></author><author><keyname>Machchhar</keyname><forenames>Jinesh</forenames></author><author><keyname>Sohoni</keyname><forenames>Milind</forenames></author></authors><title>Local and Global Analysis of Parametric Solid Sweeps</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a detailed computational framework for modelling the
envelope of the swept volume, that is the boundary of the volume obtained by
sweeping an input solid along a trajectory of rigid motions. Our framework is
adapted to the well-established industry-standard brep format to enable its
implementation in modern CAD systems. This is achieved via a &quot;local analysis&quot;,
which covers parametrization and singularities, as well as a &quot;global theory&quot;
which tackles face-boundaries, self-intersections and trim curves. Central to
the local analysis is the &quot;funnel&quot; which serves as a natural parameter space
for the basic surfaces constituting the sweep. The trimming problem is reduced
to the problem of surface-surface intersections of these basic surfaces. Based
on the complexity of these intersections, we introduce a novel classification
of sweeps as either decomposable or non-decomposable. Further, we construct an
{\em invariant} function $\theta$ on the funnel which efficiently separates
decomposable and non-decomposable sweeps. Through a geometric theorem we also
show intimate connections between $\theta$, local curvatures and the inverse
trajectory used in earlier works as an approach towards trimming. In contrast
to the inverse trajectory approach, $\theta$ is robust and is the key to a
complete structural understanding, and an efficient computation of both, the
singular locus and the trim curves, which are central to a stable
implementation. Several illustrative outputs of a pilot implementation are
included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7360</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7360</id><created>2013-05-31</created><authors><author><keyname>Barras</keyname><forenames>Bruno</forenames></author><author><keyname>Huesca</keyname><forenames>Lourdes del Carmen Gonz&#xe1;lez</forenames></author><author><keyname>Herbelin</keyname><forenames>Hugo</forenames></author><author><keyname>R&#xe9;gis-Gianas</keyname><forenames>Yann</forenames></author><author><keyname>Tassi</keyname><forenames>Enrico</forenames></author><author><keyname>Wenzel</keyname><forenames>Makarius</forenames></author><author><keyname>Wolff</keyname><forenames>Burkhart</forenames></author></authors><title>Pervasive Parallelism in Highly-Trustable Interactive Theorem Proving
  Systems</title><categories>cs.LO</categories><comments>Conferences on Intelligent Computer Mathematics CICM 2013. The final
  publication is available at http://link.springer.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is an overview of the Paral-ITP project, which intents to make the proof
assistants Isabelle and Coq fit for the multicore era.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7376</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7376</id><created>2013-05-31</created><updated>2013-06-08</updated><authors><author><keyname>Raymond</keyname><forenames>Jean-Florent</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Polynomial Gap Extensions of the Erd\H{o}s-P\'osa Theorem</title><categories>cs.DM math.CO</categories><msc-class>05C83</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph $H$, we denote by ${\cal M}(H)$ all graphs that can be
contracted to $H$. The following extension of the Erd\H{o}s-P\'osa Theorem
holds: for every $h$-vertex planar graph $H$, there exists a function $f_{H}$
such that every graph $G$, either contains $k$ disjoint copies of graphs in
${\cal M}(H)$, or contains a set of $f_{H}(k)$ vertices meeting every subgraph
of $G$ that belongs in ${\cal M}(H)$. In this paper we prove that this is the
case for every graph $H$ of pathwidth at most 2 and, in particular, that
$f_{H}(k) = 2^{O(h^2)}\cdot k^{2}\cdot \log k$. As a main ingredient of the
proof of our result, we show that for every graph $H$ on $h$ vertices and
pathwidth at most 2, either $G$ contains $k$ disjoint copies of $H$ as a minor
or the treewidth of $G$ is upper-bounded by $2^{O(h^2)}\cdot k^{2}\cdot \log
k$. We finally prove that the exponential dependence on $h$ in these bounds can
be avoided if $H=K_{2,r}$. In particular, we show that $f_{K_{2,r}}=O(r^2\cdot
k^2)$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7383</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7383</id><created>2013-05-31</created><updated>2013-07-15</updated><authors><author><keyname>Di Pietro</keyname><forenames>Roberto</forenames></author><author><keyname>Lombardi</keyname><forenames>Flavio</forenames></author><author><keyname>Villani</keyname><forenames>Antonio</forenames></author></authors><title>CUDA Leaks: Information Leakage in GPU Architectures</title><categories>cs.CR cs.DC</categories><doi>10.1145/2801153</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphics Processing Units (GPUs) are deployed on most present server,
desktop, and even mobile platforms. Nowadays, a growing number of applications
leverage the high parallelism offered by this architecture to speed-up general
purpose computation. This phenomenon is called GPGPU computing (General Purpose
GPU computing). The aim of this work is to discover and highlight security
issues related to CUDA, the most widespread platform for GPGPU computing. In
particular, we provide details and proofs-of-concept about a novel set of
vulnerabilities CUDA architectures are subject to, that could be exploited to
cause severe information leak. Following (detailed) intuitions rooted on sound
engineering security, we performed several experiments targeting the last two
generations of CUDA devices: Fermi and Kepler. We discovered that these two
families do suffer from information leakage vulnerabilities. In particular,
some vulnerabilities are shared between the two architectures, while others are
idiosyncratic of the Kepler architecture. As a case study, we report the impact
of one of these vulnerabilities on a GPU implementation of the AES encryption
algorithm. We also suggest software patches and alternative approaches to
tackle the presented vulnerabilities. To the best of our knowledge this is the
first work showing that information leakage in CUDA is possible using just
standard CUDA instructions. We expect our work to pave the way for further
research in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7387</identifier>
 <datestamp>2013-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7387</id><created>2013-05-31</created><updated>2013-12-11</updated><authors><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author></authors><title>Geometric Complexity Theory: an introduction for geometers</title><categories>math.AG cs.CC math.RT</categories><comments>40 pages, v2: many small errors fixed thanks to careful readings by
  M. Brion, P. Burgisser and R. Tange, v3: 42 pages, more detail added
  regarding shallow circuits</comments><msc-class>68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is a survey of recent developments in, and a tutorial on, the
approach to P v. NP and related questions called Geometric Complexity Theory
(GCT). It is written to be accessible to graduate students. Numerous open
questions in algebraic geometry and representation theory relevant for GCT are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7393</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7393</id><created>2013-05-31</created><authors><author><keyname>Azim</keyname><forenames>Anwarul</forenames></author></authors><title>Performance of Single User vs. Multiuser Modulation in Wireless
  Multicarrier (MC) Communications</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The main objective of this paper is to compare block transmission system
performance analytically for Code Divisional Multiple Access (CDMA) modulations
in Generalized Multicarrier environment against linear modulation techniques
for both single user and multiuser. The effectivity of GMC-CDMA for multiuser
will also be judged for different Direct Sequence CDMA (DS-CDMA) such as
MC-CDMA, MC-DS-CDMA, MC-SS-CDMA. The analytical comparison will be in terms of
computing probability of bit error for frequency selective and slow flat fading
channels for different modulation techniques. The Bit Error Rate should be a
good indication for of the performance. The tolerance characteristics of
DS-CDMA in frequency-selective channels and MC-CDMA in flat fading channels
will be shown analytically and improved capacity and Bit Error Rate performance
will be derived for Block Spread Multiuser Multicarrier by relying block symbol
spreading and Fast Fourier Transform (FFT) operations. GMC-CDMA should give
guaranteed symbol recovery regardless of channel limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7395</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7395</id><created>2013-05-31</created><updated>2013-11-03</updated><authors><author><keyname>Chakhmakhchyan</keyname><forenames>L.</forenames></author><author><keyname>Shepelyansky</keyname><forenames>D.</forenames></author></authors><title>PageRank model of opinion formation on Ulam networks</title><categories>nlin.CD cs.SI physics.soc-ph</categories><comments>7 pages, 6 figures. Updated version for publication</comments><journal-ref>Phys. Lett. A 377, 3119 (2013)</journal-ref><doi>10.1016/j.physleta.2013.10.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a PageRank model of opinion formation on Ulam networks, generated
by the intermittency map and the typical Chirikov map. The Ulam networks
generated by these maps have certain similarities with such scale-free networks
as the World Wide Web (WWW), showing an algebraic decay of the PageRank
probability. We find that the opinion formation process on Ulam networks have
certain similarities but also distinct features comparing to the WWW. We
attribute these distinctions to internal differences in network structure of
the Ulam and WWW networks. We also analyze the process of opinion formation in
the frame of generalized Sznajd model which protects opinion of small
communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7403</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7403</id><created>2013-05-31</created><authors><author><keyname>Ward</keyname><forenames>Jonathan Stuart</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>Monitoring Large-Scale Cloud Systems with Layered Gossip Protocols</title><categories>cs.DC</categories><comments>Extended Abstract for the ACM International Symposium on
  High-Performance Parallel and Distributed Computing (HPDC 2013) Poster Track</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monitoring is an essential aspect of maintaining and developing computer
systems that increases in difficulty proportional to the size of the system.
The need for robust monitoring tools has become more evident with the advent of
cloud computing. Infrastructure as a Service (IaaS) clouds allow end users to
deploy vast numbers of virtual machines as part of dynamic and transient
architectures. Current monitoring solutions, including many of those in the
open-source domain rely on outdated concepts including manual deployment and
configuration, centralised data collection and adapt poorly to membership
churn.
  In this paper we propose the development of a cloud monitoring suite to
provide scalable and robust lookup, data collection and analysis services for
large-scale cloud systems. In lieu of centrally managed monitoring we propose a
multi-tier architecture using a layered gossip protocol to aggregate monitoring
information and facilitate lookup, information collection and the
identification of redundant capacity. This allows for a resource aware data
collection and storage architecture that operates over the system being
monitored. This in turn enables monitoring to be done in-situ without the need
for significant additional infrastructure to facilitate monitoring services. We
evaluate this approach against alternative monitoring paradigms and demonstrate
how our solution is well adapted to usage in a cloud-computing context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7410</identifier>
 <datestamp>2014-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7410</id><created>2013-05-31</created><updated>2014-08-26</updated><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author><author><keyname>Zhang</keyname><forenames>Daqiang</forenames></author><author><keyname>Zhu</keyname><forenames>Rongbo</forenames></author><author><keyname>Ma</keyname><forenames>Yinxue</forenames></author><author><keyname>Yin</keyname><forenames>Ping</forenames></author><author><keyname>Xie</keyname><forenames>Feng</forenames></author></authors><title>A Review of Automated Formal Verification of Ad Hoc Routing Protocols
  for Wireless Sensor Networks</title><categories>cs.NI cs.LO</categories><comments>12 pages, 1 figure, Journal Article</comments><acm-class>C.2.2; D.2.4</acm-class><journal-ref>Sensor Letters, Volume 11, Number 5, May 2013, pp. 752-764</journal-ref><doi>10.1166/sl.2013.2653</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper surveys how formal verification can be used to prove the
correctness of ad hoc routing protocols, which are fundamental infrastructure
of wireless sensor networks. The existing techniques fall into two classes:
verification on small-scale networks and verification on unbounded networks.
The former one is always fully automatic and easy to use, thanks to the limited
state space generated in verification. However, it cannot prove the correctness
over all cases. The latter one can provide a complete proof based on
abstractions of unbounded network. However, it usually needs user intervention
and expertise in verification. The two kinds of technique are illustrated by
verifications against some key properties such as stability, loop-freedom and
deadlock-freedom. To conclude, they can be used to find faults and prove
correctness, respectively. We believe that they can together aid the
development of correct ad hoc routing protocols and their reliable
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7413</identifier>
 <datestamp>2015-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7413</id><created>2013-05-31</created><updated>2015-09-17</updated><authors><author><keyname>B&#xe9;al</keyname><forenames>Marie-Pierre</forenames></author><author><keyname>Blockelet</keyname><forenames>Michel</forenames></author><author><keyname>Dima</keyname><forenames>C&#x1ce;t&#x1ce;lin</forenames></author></authors><title>Sofic-Dyck shifts</title><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the class of sofic-Dyck shifts which extends the class of
Markov-Dyck shifts introduced by Inoue, Krieger and Matsumoto. Sofic-Dyck
shifts are shifts of sequences whose finite factors form unambiguous
context-free languages. We show that they correspond exactly to the class of
shifts of sequences whose sets of factors are visibly pushdown languages. We
give an expression of the zeta function of a sofic-Dyck shift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7416</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7416</id><created>2013-05-31</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>The Dendritic Cell Algorithm for Intrusion Detection</title><categories>cs.CR cs.NE</categories><comments>Bio-Inspired Communications and Networking, IGI Global, 84-102, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As one of the solutions to intrusion detection problems, Artificial Immune
Systems (AIS) have shown their advantages. Unlike genetic algorithms, there is
no one archetypal AIS, instead there are four major paradigms. Among them, the
Dendritic Cell Algorithm (DCA) has produced promising results in various
applications. The aim of this chapter is to demonstrate the potential for the
DCA as a suitable candidate for intrusion detection problems. We review some of
the commonly used AIS paradigms for intrusion detection problems and
demonstrate the advantages of one particular algorithm, the DCA. In order to
clearly describe the algorithm, the background to its development and a formal
definition are given. In addition, improvements to the original DCA are
presented and their implications are discussed, including previous work done on
an online analysis component with segmentation and ongoing work on automated
data preprocessing. Based on preliminary results, both improvements appear to
be promising for online anomaly-based intrusion detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7422</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7422</id><created>2013-05-31</created><authors><author><keyname>Sherman</keyname><forenames>Galina</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Menachof</keyname><forenames>David</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Evaluating Different Cost-Benefit Analysis Methods for Port Security
  Operations</title><categories>cs.CE</categories><comments>Decision Making in Service Industries: A Practical Approach, 279-302,
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service industries, such as ports, are attentive to their standards, a smooth
service flow and economic viability. Cost benefit analysis has proven itself as
a useful tool to support this type of decision making; it has been used by
businesses and governmental agencies for many years. In this book chapter we
demonstrate different modelling methods that are used for estimating input
factors required for conducting cost benefit analysis based on a single case
study. These methods are: scenario analysis, decision trees, Monte-Carlo
simulation modelling and discrete event simulation modelling. Our aims are, on
the one hand, to guide the analyst through the modelling processes and, on the
other hand, to demonstrate what additional decision support information can be
obtained from applying each of these modelling methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7424</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7424</id><created>2013-05-31</created><authors><author><keyname>Adewunmi</keyname><forenames>Adrian</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Investigating the effectiveness of Variance Reduction Techniques in
  Manufacturing, Call Center and Cross-docking Discrete Event Simulation Models</title><categories>cs.CE</categories><comments>Use Cases of Discrete Event Simulation Appliance and Research.
  Bangsow, Steffen (Ed.). Springer Berlin Heidelberg, 1-24, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variance reduction techniques have been shown by others in the past to be a
useful tool to reduce variance in Simulation studies. However, their
application and success in the past has been mainly domain specific, with
relatively little guidelines as to their general applicability, in particular
for novices in this area. To facilitate their use, this study aims to
investigate the robustness of individual techniques across a set of scenarios
from different domains. Experimental results show that Control Variates is the
only technique which achieves a reduction in variance across all domains.
Furthermore, applied individually, Antithetic Variates and Control Variates
perform particularly well in the Cross-docking scenarios, which was previously
unknown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7429</identifier>
 <datestamp>2014-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7429</id><created>2013-05-31</created><updated>2014-05-20</updated><authors><author><keyname>Canini</keyname><forenames>Marco</forenames></author><author><keyname>Kuznetsov</keyname><forenames>Petr</forenames></author><author><keyname>Levin</keyname><forenames>Dan</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>A Distributed SDN Control Plane for Consistent Policy Updates</title><categories>cs.DC</categories><acm-class>C.2.2; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software-defined networking (SDN) is a novel paradigm that out-sources the
control of packet-forwarding switches to a set of software controllers. The
most fundamental task of these controllers is the correct implementation of the
\emph{network policy}, i.e., the intended network behavior. In essence, such a
policy specifies the rules by which packets must be forwarded across the
network.
  This paper studies a distributed SDN control plane that enables
\emph{concurrent} and \emph{robust} policy implementation. We introduce a
formal model describing the interaction between the data plane and a
distributed control plane (consisting of a collection of fault-prone
controllers). Then we formulate the problem of \emph{consistent} composition of
concurrent network policy updates (short: the \emph{CPC Problem}). To
anticipate scenarios in which some conflicting policy updates must be rejected,
we enable the composition via a natural \emph{transactional} interface with
all-or-nothing semantics.
  We show that the ability of an $f$-resilient distributed control plane to
process concurrent policy updates depends on the tag complexity, i. e., the
number of policy labels (a.k.a. \emph{tags}) available to the controllers, and
describe a CPC protocol with optimal tag complexity $f+2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7430</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7430</id><created>2013-05-31</created><authors><author><keyname>Grindrod</keyname><forenames>Peter</forenames></author><author><keyname>Higham</keyname><forenames>Desmond</forenames></author></authors><title>Dynamical Systems to Monitor Complex Networks in Continuous Time</title><categories>cs.SI math.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many settings it is appropriate to treat the evolution of pairwise
interactions over continuous time. We show that new Katz-style centrality
measures can be derived in this context via solutions to a nonautonomous ODE
driven by the network dynamics. This allows us to identify and track, at any
resolution, the most influential nodes in terms of broadcasting and receiving
information through time dependent links. In addition to the classical notion
of attenuation across edges used in the static Katz centrality measure, the ODE
also allows for attenuation over time, so that real time &quot;running measures&quot; can
be computed. With regard to computational efficiency, we explain why it is
cheaper to track good receivers of information than good broadcasters. We
illustrate the new measures on a large scale voice call network, where key
features are discovered that are not evident from snapshots or aggregates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7432</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7432</id><created>2013-05-31</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan M.</forenames></author></authors><title>Real-world Transfer of Evolved Artificial Immune System Behaviours
  between Small and Large Scale Robotic Platforms</title><categories>cs.NE cs.RO</categories><comments>Evolutionary Intelligence 3 (3), 123-136, 2010. arXiv admin note:
  text overlap with arXiv:1007.0376</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mobile robotics, a solid test for adaptation is the ability of a control
system to function not only in a diverse number of physical environments, but
also on a number of different robotic platforms. This paper demonstrates that a
set of behaviours evolved in simulation on a miniature robot (epuck) can be
transferred to a much larger-scale platform (Pioneer), both in simulation and
in the real world. The chosen architecture uses artificial evolution of epuck
behaviours to obtain a genetic sequence, which is then employed to seed an
idiotypic, artificial immune system (AIS) on the Pioneers. Despite numerous
hardware and software differences between the platforms, navigation and
target-finding experiments show that the evolved behaviours transfer very well
to the larger robot when the idiotypic AIS technique is used. In contrast,
transferability is poor when reinforcement learning alone is used, which
validates the adaptability of the chosen architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7434</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7434</id><created>2013-05-31</created><authors><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Birkin</keyname><forenames>Phil</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Motif Detection Inspired by Immune Memory (JORS)</title><categories>cs.NE</categories><comments>Journal of the Operational Research Society 62 (2), 253-265, 2011.
  arXiv admin note: text overlap with arXiv:1004.3887, arXiv:1002.0432,
  arXiv:1006.1526</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search for patterns or motifs in data represents an area of key interest
to many researchers. In this paper we present the Motif Tracking Algorithm, a
novel immune inspired pattern identification tool that is able to identify
variable length unknown motifs which repeat within time series data. The
algorithm searches from a neutral perspective that is independent of the data
being analysed and the underlying motifs. In this paper we test the flexibility
of the motif tracking algorithm by applying it to the search for patterns in
two industrial data sets. The algorithm is able to identify a population of
meaningful motifs in both cases, and the value of these motifs is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7437</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7437</id><created>2013-05-31</created><authors><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Modelling Electricity Consumption in Office Buildings: An Agent Based
  Approach</title><categories>cs.CE cs.AI</categories><comments>Energy and Buildings 43(10), 2882-2892, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop an agent-based model which integrates four
important elements, i.e. organisational energy management policies/regulations,
energy management technologies, electric appliances and equipment, and human
behaviour, to simulate the electricity consumption in office buildings. Based
on a case study, we use this model to test the effectiveness of different
electricity management strategies, and solve practical office electricity
consumption problems. This paper theoretically contributes to an integration of
the four elements involved in the complex organisational issue of office
electricity consumption, and practically contributes to an application of an
agent-based approach for office building electricity consumption study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7438</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7438</id><created>2013-05-31</created><authors><author><keyname>Qiu</keyname><forenames>Tian</forenames></author><author><keyname>Wang</keyname><forenames>Tian-Tian</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhong</keyname><forenames>Li-Xin</forenames></author><author><keyname>Chen</keyname><forenames>Guang</forenames></author></authors><title>Heterogeneity Involved Network-based Algorithm Leads to Accurate and
  Personalized Recommendations</title><categories>physics.soc-ph cs.IR cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneity of both the source and target objects is taken into account in
a network-based algorithm for the directional resource transformation between
objects. Based on a biased heat conduction recommendation method (BHC) which
considers the heterogeneity of the target object, we propose a heterogeneous
heat conduction algorithm (HHC), by further taking the source object degree as
the weight of diffusion. Tested on three real datasets, the Netflix, RYM and
MovieLens, the HHC algorithm is found to present a better recommendation in
both the accuracy and personalization than two excellent algorithms, i.e., the
original BHC and a hybrid algorithm of heat conduction and mass diffusion
(HHM), while not requiring any other accessorial information or parameter.
Moreover, the HHC even elevates the recommendation accuracy on cold objects,
referring to the so-called cold start problem, for effectively relieving the
recommendation bias on objects with different level of popularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7440</identifier>
 <datestamp>2014-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7440</id><created>2013-05-31</created><updated>2014-05-28</updated><authors><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author><author><keyname>Cellai</keyname><forenames>Davide</forenames></author><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Reed-Tsochas</keyname><forenames>Felix</forenames></author></authors><title>A Simple Generative Model of Collective Online Behaviour</title><categories>physics.soc-ph cs.SI</categories><comments>Updated, with new figures and Supplementary Information</comments><journal-ref>Proc.Natl.Acad.Sci. U.S.A. 111 (2014) 10411-10415</journal-ref><doi>10.1073/pnas.1313895111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human activities increasingly take place in online environments, providing
novel opportunities for relating individual behaviours to population-level
outcomes. In this paper, we introduce a simple generative model for the
collective behaviour of millions of social networking site users who are
deciding between different software applications. Our model incorporates two
distinct components: one is associated with recent decisions of users, and the
other reflects the cumulative popularity of each application. Importantly,
although various combinations of the two mechanisms yield long-time behaviour
that is consistent with data, the only models that reproduce the observed
temporal dynamics are those that strongly emphasize the recent popularity of
applications over their cumulative popularity. This demonstrates---even when
using purely observational data without experimental design---that temporal
data-driven modelling can effectively distinguish between competing microscopic
mechanisms, allowing us to uncover new aspects of collective online behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7445</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7445</id><created>2013-05-31</created><updated>2013-09-04</updated><authors><author><keyname>Sola</keyname><forenames>Luis</forenames></author><author><keyname>Romance</keyname><forenames>Miguel</forenames></author><author><keyname>Criado</keyname><forenames>Regino</forenames></author><author><keyname>Flores</keyname><forenames>Julio</forenames></author><author><keyname>del Amo</keyname><forenames>Alejandro Garcia</forenames></author><author><keyname>Boccaletti</keyname><forenames>Stefano</forenames></author></authors><title>Eigenvector centrality of nodes in multiplex networks</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Chaos 23, 033131 (2013)</journal-ref><doi>10.1063/1.4818544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the concept of eigenvector centrality to multiplex networks, and
introduce several alternative parameters that quantify the importance of nodes
in a multi-layered networked system, including the definition of vectorial-type
centralities. In addition, we rigorously show that, under reasonable
conditions, such centrality measures exist and are unique. Computer experiments
and simulations demonstrate that the proposed measures provide substantially
different results when applied to the same multiplex structure, and highlight
the non-trivial relationships between the different measures of centrality
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7448</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7448</id><created>2013-05-31</created><authors><author><keyname>Fafianie</keyname><forenames>Stefan</forenames></author><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Nederlof</keyname><forenames>Jesper</forenames></author></authors><title>Speeding-up Dynamic Programming with Representative Sets - An
  Experimental Evaluation of Algorithms for Steiner Tree on Tree Decompositions</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic programming on tree decompositions is a frequently used approach to
solve otherwise intractable problems on instances of small treewidth. In recent
work by Bodlaender et al., it was shown that for many connectivity problems,
there exist algorithms that use time, linear in the number of vertices, and
single exponential in the width of the tree decomposition that is used. The
central idea is that it suffices to compute representative sets, and these can
be computed efficiently with help of Gaussian elimination.
  In this paper, we give an experimental evaluation of this technique for the
Steiner Tree problem. A comparison of the classic dynamic programming algorithm
and the improved dynamic programming algorithm that employs the table reduction
shows that the new approach gives significant improvements on the running time
of the algorithm and the size of the tables computed by the dynamic programming
algorithm, and thus that the rank based approach from Bodlaender et al. does
not only give significant theoretical improvements but also is a viable
approach in a practical setting, and showcases the potential of exploiting the
idea of representative sets for speeding up dynamic programming algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7454</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7454</id><created>2013-05-31</created><authors><author><keyname>Feyereisl</keyname><forenames>Jan</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Privileged Information for Data Clustering</title><categories>cs.LG stat.ML</categories><comments>Information Sciences 194, 4-23, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many machine learning algorithms assume that all input samples are
independently and identically distributed from some common distribution on
either the input space X, in the case of unsupervised learning, or the input
and output space X x Y in the case of supervised and semi-supervised learning.
In the last number of years the relaxation of this assumption has been explored
and the importance of incorporation of additional information within machine
learning algorithms became more apparent. Traditionally such fusion of
information was the domain of semi-supervised learning. More recently the
inclusion of knowledge from separate hypothetical spaces has been proposed by
Vapnik as part of the supervised setting. In this work we are interested in
exploring Vapnik's idea of master-class learning and the associated learning
using privileged information, however within the unsupervised setting. Adoption
of the advanced supervised learning paradigm for the unsupervised setting
instigates investigation into the difference between privileged and technical
data. By means of our proposed aRi-MAX method stability of the KMeans algorithm
is improved and identification of the best clustering solution is achieved on
an artificial dataset. Subsequently an information theoretic dot product based
algorithm called P-Dot is proposed. This method has the ability to utilize a
wide variety of clustering techniques, individually or in combination, while
fusing privileged and technical data for improved clustering. Application of
the P-Dot method to the task of digit recognition confirms our findings in a
real-world scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7458</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7458</id><created>2013-05-31</created><authors><author><keyname>Roadknight</keyname><forenames>Chris</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Sherman</keyname><forenames>Galina</forenames></author></authors><title>Validation of a Microsimulation of the Port of Dover</title><categories>cs.CE cs.AI physics.soc-ph</categories><comments>Journal of Computational Science 3 (1-2), 56-66, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modelling and simulating the traffic of heavily used but secure environments
such as seaports and airports is of increasing importance. Errors made when
simulating these environments can have long standing economic, social and
environmental implications. This paper discusses issues and problems that may
arise when designing a simulation strategy. Data for the Port is presented,
methods for lightweight vehicle assessment that can be used to calibrate and
validate simulations are also discussed along with a diagnosis of
overcalibration issues. We show that decisions about where the intelligence
lies in a system has important repercussions for the reliability of system
statistics. Finally, conclusions are drawn about how microsimulations can be
moved forward as a robust planning tool for the 21st century.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7465</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7465</id><created>2013-05-31</created><authors><author><keyname>Liu</keyname><forenames>Yihui</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Feyereisl</keyname><forenames>Jan</forenames></author><author><keyname>Durrant</keyname><forenames>Lindy G.</forenames></author></authors><title>Wavelet feature extraction and genetic algorithm for biomarker detection
  in colorectal cancer data</title><categories>cs.NE cs.CE</categories><journal-ref>Knowledge-Based Systems 37, 502-514, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biomarkers which predict patient's survival can play an important role in
medical diagnosis and treatment. How to select the significant biomarkers from
hundreds of protein markers is a key step in survival analysis. In this paper a
novel method is proposed to detect the prognostic biomarkers of survival in
colorectal cancer patients using wavelet analysis, genetic algorithm, and Bayes
classifier. One dimensional discrete wavelet transform (DWT) is normally used
to reduce the dimensionality of biomedical data. In this study one dimensional
continuous wavelet transform (CWT) was proposed to extract the features of
colorectal cancer data. One dimensional CWT has no ability to reduce
dimensionality of data, but captures the missing features of DWT, and is
complementary part of DWT. Genetic algorithm was performed on extracted wavelet
coefficients to select the optimized features, using Bayes classifier to build
its fitness function. The corresponding protein markers were located based on
the position of optimized features. Kaplan-Meier curve and Cox regression model
were used to evaluate the performance of selected biomarkers. Experiments were
conducted on colorectal cancer dataset and several significant biomarkers were
detected. A new protein biomarker CD46 was found to significantly associate
with survival time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7466</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7466</id><created>2013-05-31</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Linqiang</forenames></author><author><keyname>Zhang</keyname><forenames>Daqiang</forenames></author><author><keyname>Zhang</keyname><forenames>Xue</forenames></author><author><keyname>Gao</keyname><forenames>Ruixia</forenames></author></authors><title>Ada-MAC: An Adaptive MAC Protocol for Real-time and Reliable Health
  Monitoring,</title><categories>cs.NI</categories><comments>IEEE International Conference on Cyber Technology in Automation,
  Control and Intelligent Systems (IEEE CYBER 2012), Bangkok, Thailand, May
  27-31, pp. 203 - 208, 2012</comments><doi>10.1109/CYBER.2012.6392554</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IEEE 802.15.4 is regarded as one of the most suitable communication protocols
for cyber-physical applications of wireless sensor and actuator networks. This
is because this protocol is able to achieve low-power and low-cost transmission
in wireless personal area networks. But most cyber-physical systems (CPSs)
require a degree of real-time and reliability from the underlying communication
protocol. Some of them are stricter than the others. However, IEEE 802.15.4
protocol cannot provide reliability and real-time transmission for
time-critical and delay-sensitive data in cyber-physical applications. To solve
this problem, we propose a new MAC protocol, i.e. the Ada-MAC protocol, which
is based on IEEE 802.15.4 beacon-enabled mode. It can support cyber-physical
applications such as health monitoring, which require stringent real- time and
reliability guarantees. We implement the proposed protocol on the OMNET++
platform and conduct a performance evaluation of the proposed protocol with
comparison against the traditional IEEE 802.15.4 protocol. The results are
presented and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7467</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7467</id><created>2013-05-31</created><authors><author><keyname>Miller</keyname><forenames>Simon</forenames></author><author><keyname>Appleby</keyname><forenames>Susan</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan M.</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Towards a More Systematic Approach to Secure Systems Design and Analysis</title><categories>cs.CR cs.SE</categories><journal-ref>International Journal of Secure Software Engineering 4(1), 11-30,
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of designing secure software systems is fraught with uncertainty, as
data on uncommon attacks is limited, costs are difficult to estimate, and
technology and tools are continually changing. Consequently, experts may
interpret the security risks posed to a system in different ways, leading to
variation in assessment. This paper presents research into measuring the
variability in decision making between security professionals, with the
ultimate goal of improving the quality of security advice given to software
system designers. A set of thirty nine cyber-security experts took part in an
exercise in which they independently assessed a realistic system scenario. This
study quantifies agreement in the opinions of experts, examines methods of
aggregating opinions, and produces an assessment of attacks from ratings of
their components. We show that when aggregated, a coherent consensus view of
security emerges which can be used to inform decisions made during systems
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7471</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7471</id><created>2013-05-31</created><authors><author><keyname>Figueredo</keyname><forenames>Grazziela P.</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Investigating Mathematical Models of Immuno-Interactions with
  Early-Stage Cancer under an Agent-Based Modelling Perspective</title><categories>cs.CE cs.AI</categories><journal-ref>BMC Bioinformatics 14(Suppl 6), S6, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many advances in research regarding immuno-interactions with cancer were
developed with the help of ordinary differential equation (ODE) models. These
models, however, are not effectively capable of representing problems involving
individual localisation, memory and emerging properties, which are common
characteristics of cells and molecules of the immune system. Agent-based
modelling and simulation is an alternative paradigm to ODE models that
overcomes these limitations. In this paper we investigate the potential
contribution of agent-based modelling and simulation when compared to ODE
modelling and simulation. We seek answers to the following questions: Is it
possible to obtain an equivalent agent-based model from the ODE formulation? Do
the outcomes differ? Are there any benefits of using one method compared to the
other? To answer these questions, we have considered three case studies using
established mathematical models of immune interactions with early-stage cancer.
These case studies were re-conceptualised under an agent-based perspective and
the simulation results were then compared with those from the ODE models. Our
results show that it is possible to obtain equivalent agent-based models (i.e.
implementing the same mechanisms); the simulation output of both types of
models however might differ depending on the attributes of the system to be
modelled. In some cases, additional insight from using agent-based modelling
was obtained. Overall, we can confirm that agent-based modelling is a useful
addition to the tool set of immunologists, as it has extra features that allow
for simulations with characteristics that are closer to the biological
phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7476</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7476</id><created>2013-05-31</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Theoretical formulation and analysis of the deterministic dendritic cell
  algorithm</title><categories>cs.NE cs.DS</categories><journal-ref>Biosystems 111 (2), 127-135, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As one of the emerging algorithms in the field of Artificial Immune Systems
(AIS), the Dendritic Cell Algorithm (DCA) has been successfully applied to a
number of challenging real-world problems. However, one criticism is the lack
of a formal definition, which could result in ambiguity for understanding the
algorithm. Moreover, previous investigations have mainly focused on its
empirical aspects. Therefore, it is necessary to provide a formal definition of
the algorithm, as well as to perform runtime analyses to revealits theoretical
aspects. In this paper, we define the deterministic version of the DCA, named
the dDCA, using set theory and mathematical functions. Runtime analyses of the
standard algorithm and the one with additional segmentation are performed. Our
analysis suggests that the standard dDCA has a runtime complexity of O(n2) for
the worst-case scenario, where n is the number of input data instances. The
introduction of segmentation changes the algorithm's worst case runtime
complexity to O(max(nN; nz)), for DC population size N with size of each
segment z. Finally, two runtime variables of the algorithm are formulated based
on the input data, to understand its runtime behaviour as guidelines for
further development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7477</identifier>
 <datestamp>2014-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7477</id><created>2013-05-31</created><updated>2014-10-11</updated><authors><author><keyname>Lee</keyname><forenames>Jason D.</forenames></author><author><keyname>Sun</keyname><forenames>Yuekai</forenames></author><author><keyname>Taylor</keyname><forenames>Jonathan E.</forenames></author></authors><title>On model selection consistency of regularized M-estimators</title><categories>math.ST cs.LG math.OC stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularized M-estimators are used in diverse areas of science and engineering
to fit high-dimensional models with some low-dimensional structure. Usually the
low-dimensional structure is encoded by the presence of the (unknown)
parameters in some low-dimensional model subspace. In such settings, it is
desirable for estimates of the model parameters to be \emph{model selection
consistent}: the estimates also fall in the model subspace. We develop a
general framework for establishing consistency and model selection consistency
of regularized M-estimators and show how it applies to some special cases of
interest in statistical learning. Our analysis identifies two key properties of
regularized M-estimators, referred to as geometric decomposability and
irrepresentability, that ensure the estimators are consistent and model
selection consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7480</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7480</id><created>2013-05-31</created><authors><author><keyname>Chen</keyname><forenames>Duan-Bing</forenames></author><author><keyname>Xiao</keyname><forenames>Rui</forenames></author><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Path diversity improves the identification of influential spreaders</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 6 figures</comments><doi>10.1209/0295-5075/104/68006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying influential spreaders in complex networks is a crucial problem
which relates to wide applications. Many methods based on the global
information such as $k$-shell and PageRank have been applied to rank spreaders.
However, most of related previous works overwhelmingly focus on the number of
paths for propagation, while whether the paths are diverse enough is usually
overlooked. Generally, the spreading ability of a node might not be strong if
its propagation depends on one or two paths while the other paths are dead
ends. In this Letter, we introduced the concept of path diversity and find that
it can largely improve the ranking accuracy. We further propose a local method
combining the information of path number and path diversity to identify
influential nodes in complex networks. This method is shown to outperform many
well-known methods in both undirected and directed networks. Moreover, the
efficiency of our method makes it possible to be applied to very large systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7482</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7482</id><created>2013-05-31</created><authors><author><keyname>Liu</keyname><forenames>Xiyang</forenames></author><author><keyname>Ren</keyname><forenames>Zhongjie</forenames></author><author><keyname>Chang</keyname><forenames>Xiuling</forenames></author><author><keyname>Gao</keyname><forenames>Haichang</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Draw a line on your PDA to authenticate</title><categories>cs.CR</categories><comments>The sixth Symposium on Usable Privacy and Security, SOUPS2010, July
  14-16, Redmond, WA, 7, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The trend toward a highly mobile workforce and the ubiquity of graphical
interfaces (such as the stylus and touch-screen) has enabled the emergence of
graphical authentications in Personal Digital Assistants (PDAs) [1]. However,
most of the current graphical password schemes are vulnerable to
shoulder-surfing [2,3], a known risk where an attacker can capture a password
by direct observation or by recording the authentication session. Several
approaches have been developed to deal with this problem, but they have
significant usability drawbacks, usually in the time and effort to log in,
making them less suitable for authentication [4, 8]. For example, it is
time-consuming for users to log in CHC [4] and there are complex text memory
requirements in scheme proposed by Hong [5]. With respect to the scheme
proposed by Weinshall [6], not only is it intricate to log in, but also the
main claim of resisting shoulder-surfing is proven false [7]. In this paper, we
introduce a new graphical password scheme which provides a good resistance to
shouldersurfing and preserves a desirable usability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7484</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7484</id><created>2013-05-31</created><authors><author><keyname>Majumdar</keyname><forenames>Anirudha</forenames></author><author><keyname>Vasudevan</keyname><forenames>Ram</forenames></author><author><keyname>Tobenkin</keyname><forenames>Mark M.</forenames></author><author><keyname>Tedrake</keyname><forenames>Russ</forenames></author></authors><title>Technical Report: Convex Optimization of Nonlinear Feedback Controllers
  via Occupation Measures</title><categories>cs.RO cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an approach for designing feedback controllers for
polynomial systems that maximize the size of the time-limited backwards
reachable set (BRS). We rely on the notion of occupation measures to pose the
synthesis problem as an infinite dimensional linear program (LP) and provide
finite dimensional approximations of this LP in terms of semidefinite programs
(SDPs). The solution to each SDP yields a polynomial control policy and an
outer approximation of the largest achievable BRS. In contrast to traditional
Lyapunov based approaches which are non-convex and require feasible
initialization, our approach is convex and does not require any form of
initialization. The resulting time-varying controllers and approximated
reachable sets are well-suited for use in a trajectory library or feedback
motion planning algorithm. We demonstrate the efficacy and scalability of our
approach on five nonlinear systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7485</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7485</id><created>2013-05-31</created><authors><author><keyname>Wang</keyname><forenames>Liming</forenames></author><author><keyname>Chang</keyname><forenames>Xiuling</forenames></author><author><keyname>Ren</keyname><forenames>Zhongjie</forenames></author><author><keyname>Gao</keyname><forenames>Haichang</forenames></author><author><keyname>Liu</keyname><forenames>Xiyang</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Against Spyware Using CAPTCHA in Graphical Password Scheme</title><categories>cs.CR</categories><journal-ref>The 24th IEEE International Conference on Advanced Information
  Networking and Applications, Perth, Australia, 760-767, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text-based password schemes have inherent security and usability problems,
leading to the development of graphical password schemes. However, most of
these alternate schemes are vulnerable to spyware attacks. We propose a new
scheme, using CAPTCHA (Completely Automated Public Turing tests to tell
Computers and Humans Apart) that retaining the advantages of graphical password
schemes, while simultaneously raising the cost of adversaries by orders of
magnitude. Furthermore, some primary experiments are conducted and the results
indicate that the usability should be improved in the future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7488</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7488</id><created>2013-05-31</created><authors><author><keyname>Sahito</keyname><forenames>Farhan Hyder</forenames></author><author><keyname>Slany</keyname><forenames>Wolfgang</forenames></author></authors><title>Advanced Personnel Vetting Techniques in Critical Multi-Tennant Hosted
  Computing Environments</title><categories>cs.CR cs.CY</categories><journal-ref>International Journal of Advanced Computer Science and
  Applications (IJACSA). Vol. 4, No.5, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of cloud computing presents a strategic direction for critical
infrastructures and promises to have far-reaching effects on their systems and
networks to deliver better outcomes to the nations at a lower cost. However,
when considering cloud computing, government entities must address a host of
security issues (such as malicious insiders) beyond those of service cost and
flexibility. The scope and objective of this paper is to analyze, evaluate and
investigate the insider threat in cloud security in sensitive infrastructures
as well as to propose two proactive socio-technical solutions for securing
commercial and governmental cloud infrastructures. Firstly, it proposes
actionable framework, techniques and practices in order to ensure that such
disruptions through human threats are infrequent, of minimal duration,
manageable, and cause the least damage possible. Secondly, it aims for extreme
security measures to analyze and evaluate human threats related assessment
methods for employee screening in certain high-risk situations using cognitive
analysis technology, in particular functional magnetic Resonance Imaging
(fMRI). The significance of this research is also to counter human rights and
ethical dilemmas by presenting a set of ethical and professional guidelines.
The main objective of this work is to analyze related risks, identify
countermeasures and present recommendations to develop a security awareness
culture that will allow cloud providers to utilize effectively the benefits of
this advanced techniques without sacrificing system security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.7514</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.7514</id><created>2013-05-31</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Studying new classes of graph metrics</title><categories>math.MG cs.DM math.CO</categories><comments>Prepared for the Proceedings of GSI2013 - Geometric Science of
  Information (August 28-30, 2013, Paris). 9 pages, 1 figure</comments><msc-class>05C12 05C50 05C05 51K05 15A48 15A51</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In data analysis, there is a strong demand for graph metrics that differ from
the classical shortest path and resistance distances. Recently, several new
classes of graph metrics have been proposed. This paper presents some of them
featuring the cutpoint additive distances. These include the path distances,
the reliability distance, the walk distances, and the logarithmic forest
distances among others. We discuss a number of connections between these and
other distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0018</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0018</id><created>2013-05-31</created><authors><author><keyname>Breuer</keyname><forenames>Peter T.</forenames></author><author><keyname>Bowen</keyname><forenames>Jonathan P.</forenames></author></authors><title>An Open Question on the Uniqueness of (Encrypted) Arithmetic</title><categories>cs.CR cs.DM</categories><comments>Withdrawn by authors after acceptance for ICCS 2013 (one of the
  conjectures that appears in the text was disproved by the authors after
  submission); 9 pages</comments><acm-class>E.4; H.1.1; I.4.2; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We ask whether two or more images of arithmetic may inhabit the same space
via different encodings. The answers have significance for a class of processor
design that does all its computation in an encrypted form, without ever
performing any decryption or encryption itself. Against the possibility of
algebraic attacks against the arithmetic in a `crypto-processor' (KPU) we
propose a defence called `ABC encryption' and show how this kind of encryption
makes it impossible for observations of the arithmetic to be used by an
attacker to discover the actual values. We also show how to construct such
encrypted arithmetics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0019</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0019</id><created>2013-05-31</created><authors><author><keyname>Gerlach</keyname><forenames>Jens</forenames></author></authors><title>Recursive Sorting in Lattices</title><categories>cs.DM math.CO</categories><comments>10 pages, 2 tables, 3 figures</comments><msc-class>18B35</msc-class><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The direct application of the definition of sorting in lattices is
impractical because it leads to an algorithm with exponential complexity. In
this paper we present for distributive lattices a recursive formulation to
compute the sort of a sequence. This alternative formulation is inspired by the
identity that underlies Pascal's triangle. It provides quadratic complexity and
is in fact a generalization of insertion sort for lattices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0024</identifier>
 <datestamp>2015-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0024</id><created>2013-05-31</created><authors><author><keyname>Tawfik</keyname><forenames>A.</forenames><affiliation>MTI U., Cairo &amp; Egyptian Ctr. Theor. Phys., Cairo &amp; WLCAPP</affiliation></author></authors><title>Calibrated Fair Measures of Measure: Indices to Quantify an Individual's
  Scientific Research Output</title><categories>cs.DL physics.soc-ph</categories><comments>10 pages, 2 figures with 4 eps graphs</comments><report-no>ECTP-2013-02</report-no><journal-ref>Can. J. Phys. 93, 1-5 (2015)</journal-ref><doi>10.1139/cjp-2014-0412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Are existing ways of measuring scientific quality reflecting disadvantages of
not being part of giant collaborations? How could possible discrimination be
avoided? We propose indices defined for each discipline (subfield) and which
count the plausible contributions added up by collaborators maintaining the
spirit of interdependency. Based on the growing debate about defining potential
biases and detecting unethical behavior, a standardized method to measure
contributions of the astronomical number of coauthors is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0026</identifier>
 <datestamp>2013-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0026</id><created>2013-05-31</created><updated>2013-10-17</updated><authors><author><keyname>Bartoletti</keyname><forenames>Massimo</forenames></author><author><keyname>Cimoli</keyname><forenames>Tiziana</forenames></author><author><keyname>Di Giamberardino</keyname><forenames>Paolo</forenames></author><author><keyname>Zunino</keyname><forenames>Roberto</forenames></author></authors><title>Contract agreements via logic</title><categories>cs.LO</categories><comments>In Proceedings ICE 2013, arXiv:1310.4019</comments><proxy>Selena Clancy</proxy><journal-ref>EPTCS 131, 2013, pp. 5-19</journal-ref><doi>10.4204/EPTCS.131.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We relate two contract models: one based on event structures and game theory,
and the other one based on logic. In particular, we show that the notions of
agreement and winning strategies in the game-theoretic model are related to
that of provability in the logical model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0029</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0029</id><created>2013-05-31</created><authors><author><keyname>Jiang</keyname><forenames>Hong</forenames></author><author><keyname>Wilford</keyname><forenames>Paul</forenames></author></authors><title>A Hierarchical Modulation for Upgrading Digital Broadcast Systems</title><categories>cs.IT math.IT</categories><comments>10 Pages, 8 Figures</comments><journal-ref>IEEE Transactions on Broadcasting, vol. 51, no. 2, 2005, pp.
  223-229</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hierarchical modulation scheme is proposed to upgrade an existing digital
broadcast system, such as satellite TV, or satellite radio, by adding more data
in its transmission. The hierarchical modulation consists of a basic
constellation, which is the same as in the original system, and a secondary
constellation, which carries the additional data for the upgraded system. The
upgraded system with the hierarchical modulation is backward compatible in the
sense that receivers that have been deployed in the original system can
continue receiving data in the basic constellation. New receivers can be
designed to receive data carried in the secondary constellation, as well as
those in the basic constellation. Analysis will be performed to show the
tradeoff between bit rate of the data in secondary constellation and the
penalty to the performance of receiving the basic constellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0034</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0034</id><created>2013-05-31</created><authors><author><keyname>Jiang</keyname><forenames>Hong</forenames></author><author><keyname>Wilford</keyname><forenames>Paul</forenames></author><author><keyname>Wilkus</keyname><forenames>Steve</forenames></author></authors><title>Providing Local Content in a Hybrid Single Frequency Network using
  Hierarchical Modulation</title><categories>cs.IT math.IT</categories><comments>10 Pages, 8 Figures</comments><journal-ref>IEEE Transactions on Broadcasting vol. 56, no. 4, 2010, pp.
  532-540</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hierarchical modulation method is proposed for providing local content in a
hybrid satellite and terrestrial single frequency network such DVB-SH. The
hierarchical modulation is used to transmit both global and local content in
terrestrial transmitters. The global content is transmitted with high priority
layer of the hierarchical modulation, and the local content is modulated with
the low priority layer of the hierarchical modulation. The satellite transmits
global content only. The performance of the hierarchical system for both global
and local content is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0036</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0036</id><created>2013-05-31</created><updated>2014-11-23</updated><authors><author><keyname>Lamperski</keyname><forenames>Andrew</forenames></author><author><keyname>Lessard</keyname><forenames>Laurent</forenames></author></authors><title>Optimal Decentralized State-Feedback Control with Sparsity and Delays</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents the solution to a class of decentralized linear quadratic
state-feedback control problems, in which the plant and controller must satisfy
the same combination of delay and sparsity constraints. Using a novel
decomposition of the noise history, the control problem is split into
independent subproblems that are solved using dynamic programming. The approach
presented herein both unifies and generalizes many existing results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0037</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0037</id><created>2013-05-31</created><authors><author><keyname>Jiang</keyname><forenames>Hong</forenames></author><author><keyname>Wilford</keyname><forenames>Paul</forenames></author></authors><title>Digital predistortion for power amplifiers using separable functions</title><categories>cs.IT math.IT</categories><comments>10 Pages, 12 Figures</comments><journal-ref>IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 58, NO. 8, AUGUST
  2010, pp. 4121- 4130</journal-ref><doi>10.1109/TSP.2010.2049742</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with digital predistortion for linearization of RF
high power amplifiers (HPAs). It has two objectives. First, we establish a
theoretical framework for a generic predistorter system, and show that if a
postdistorter exists, then it is also a predistorter, and therefore, the
predistorter and postdistorter are equivalent. This justifies the indirect
learning methods for a large class of HPAs. Secondly, we establish a systematic
and general structure for a predistorter that is capable of compensating
nonlinearity for a large variety of HPAs. This systematic structure is derived
using approximation by separable functions, and avoids selection of
predistorters based on the assumption of HPA models traditionally done in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0039</identifier>
 <datestamp>2014-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0039</id><created>2013-05-31</created><updated>2014-10-08</updated><authors><author><keyname>Buchet</keyname><forenames>Mickael</forenames></author><author><keyname>Chazal</keyname><forenames>Frederic</forenames></author><author><keyname>Oudot</keyname><forenames>Steve Y.</forenames></author><author><keyname>Sheehy</keyname><forenames>Donald R.</forenames></author></authors><title>Efficient and Robust Persistent Homology for Measures</title><categories>cs.CG</categories><comments>This is the full version of the paper with the same title in
  Proceedings of SODA 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the notion of the distance to a measure from Euclidean space to
probability measures on general metric spaces as a way to do topological data
analysis in a way that is robust to noise and outliers. We then give an
efficient way to approximate the sub-level sets of this function by a union of
metric balls and extend previous results on sparse Rips filtrations to this
setting. This robust and efficient approach to topological data analysis is
illustrated with several examples from an implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0054</identifier>
 <datestamp>2015-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0054</id><created>2013-05-31</created><authors><author><keyname>Seyfi</keyname><forenames>Ali</forenames></author></authors><title>Analysis and Evaluation of the Link and Content Based Focused
  Treasure-Crawler</title><categories>cs.IR cs.DL</categories><comments>13 pages, 12 figures, 7 tables. arXiv admin note: text overlap with
  arXiv:1305.7265</comments><doi>10.1016/j.csi.2015.09.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indexing the Web is becoming a laborious task for search engines as the Web
exponentially grows in size and distribution. Presently, the most effective
known approach to overcome this problem is the use of focused crawlers. A
focused crawler applies a proper algorithm in order to detect the pages on the
Web that relate to its topic of interest. For this purpose we proposed a custom
method that uses specific HTML elements of a page to predict the topical focus
of all the pages that have an unvisited link within the current page. These
recognized on-topic pages have to be sorted later based on their relevance to
the main topic of the crawler for further actual downloads. In the
Treasure-Crawler, we use a hierarchical structure called the T-Graph which is
an exemplary guide to assign appropriate priority score to each unvisited link.
These URLs will later be downloaded based on this priority. This paper outlines
the architectural design and embodies the implementation, test results and
performance evaluation of the Treasure-Crawler system. The Treasure-Crawler is
evaluated in terms of information retrieval criteria such as recall and
precision, both with values close to 0.5. Gaining such outcome asserts the
significance of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0075</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0075</id><created>2013-06-01</created><authors><author><keyname>Pintea</keyname><forenames>Camelia-M.</forenames></author><author><keyname>Pop</keyname><forenames>Petrica C.</forenames></author></authors><title>Sensitive Ants for Denial Jamming Attack on Wireless Sensor Network</title><categories>cs.CR cs.NI</categories><comments>- 4 pages - accepted paper</comments><journal-ref>Advances in Intelligent and Soft Computing 239 (2014) 409-418</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new defence mechanism for different jamming attack on Wireless Sensor
Network (WSN) based on ant system it is introduced. The artificial sensitive
ants react on network attacks in particular based on their sensitivity level.
The information is re-directed from the attacked node to its appropriate
destination node. It is analyzed how are detected and isolated the jamming
attacks with mobile agents in general and in particular with the newly
ant-based sensitive approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0077</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0077</id><created>2013-06-01</created><authors><author><keyname>Cheng</keyname><forenames>Steven</forenames></author><author><keyname>Higham</keyname><forenames>Lisa</forenames></author><author><keyname>Kawash</keyname><forenames>Jalal</forenames></author></authors><title>Partition Consistency: A Case Study in Modeling Systems with Weak Memory
  Consistency and Proving Correctness of their Implementations</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiprocess systems, including grid systems, multiprocessors and multicore
computers, incorporate a variety of specialized hardware and software
mechanisms, which speed computation, but result in complex memory behavior. As
a consequence, the possible outcomes of a concurrent program can be unexpected.
A memory consistency model is a description of the behaviour of such a system.
Abstract memory consistency models aim to capture the concrete implementations
and architectures. Therefore, formal specification of the implementation or
architecture is necessary, and proofs of correspondence between the abstract
and the concrete models are required.
  This paper provides a case study of this process. We specify a new model,
partition consistency, that generalizes many existing consistency models. A
concrete message-passing network model is also specified. Implementations of
partition consistency on this network model are then presented and proved
correct. A middle level of abstraction is utilized to facilitate the proofs.
All three levels of abstraction are specified using the same framework. The
paper aims to illustrate a general methodology and techniques for specifying
memory consistency models and proving the correctness of their implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0089</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0089</id><created>2013-06-01</created><authors><author><keyname>Sinha</keyname><forenames>Amitabha</forenames></author><author><keyname>Sarkar</keyname><forenames>Mitrava</forenames></author><author><keyname>Acharyya</keyname><forenames>Soumojit</forenames></author><author><keyname>Chakraborty</keyname><forenames>Suranjan</forenames></author></authors><title>A Novel Reconfigurable Architecture of a DSP Processor for Efficient
  Mapping of DSP Functions using Field Programmable DSP Arrays</title><categories>cs.AR</categories><comments>8 Pages, 12 Figures, ACM SIGARCH Computer Architecture News. arXiv
  admin note: substantial text overlap with arXiv:1305.3251</comments><msc-class>68R01</msc-class><journal-ref>ACM SIGARCH Computer Architecture News, Volume 41 Issue 2, May
  2013, Pages 1-8</journal-ref><doi>10.1145/2490302.2490304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of modern integrated circuit technologies makes it feasible to
develop cheaper, faster and smaller special purpose signal processing function
circuits. Digital Signal processing functions are generally implemented either
on ASICs with inflexibility, or on FPGAs with bottlenecks of relatively smaller
utilization factor or lower speed compared to ASIC. Field Programmable DSP
Array (FPDA) is the proposed DSP dedicated device, redolent to FPGA, but with
basic fixed common modules (CMs) (like adders, subtractors, multipliers,
scaling units, shifters) instead of CLBs. This paper introduces the development
of reconfigurable system architecture with a focus on FPDA that integrates
different DSP functions like DFT, FFT, DCT, FIR, IIR, and DWT etc. The
switching between DSP functions is occurred by reconfiguring the
interconnection between CMs. Validation of the proposed architecture has been
achieved on Virtex5 FPGA. The architecture provides sufficient amount of
flexibility, parallelism and scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0090</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0090</id><created>2013-06-01</created><authors><author><keyname>Ayachi</keyname><forenames>I.</forenames></author><author><keyname>Kammarti</keyname><forenames>R.</forenames></author><author><keyname>Ksouri</keyname><forenames>M.</forenames></author><author><keyname>Borne</keyname><forenames>P.</forenames></author><author><keyname>de Lille</keyname><forenames>Lagis Ecole Centrale</forenames></author><author><keyname>de Tunis</keyname><forenames>Lacs Ecole Nationale des Ingenieurs</forenames></author></authors><title>Harmony search algorithm for the container storage problem</title><categories>cs.NE</categories><comments>7 pages, 8th International Conference of Modeling and Simulation -
  MOSIM 10 - May 10-12, 2010 - Hammamet - Tunisia. arXiv admin note: text
  overlap with arXiv:1305.7254</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recently a new metaheuristic called harmony search was developed. It mimics
the behaviors of musicians improvising to find the better state harmony. In
this paper, this algorithm is described and applied to solve the container
storage problem in the harbor. The objective of this problem is to determine a
valid containers arrangement, which meets customers delivery deadlines, reduces
the number of container rehandlings and minimizes the ship idle time. In this
paper, an adaptation of the harmony search algorithm to the container storage
problem is detailed and some experimental results are presented and discussed.
The proposed approach was compared to a genetic algorithm previously applied to
the same problem and recorded a good results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0094</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0094</id><created>2013-06-01</created><authors><author><keyname>Huleihel</keyname><forenames>Wasim</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Analysis of Mismatched Estimation Errors Using Gradients of Partition
  Functions</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>58 pages;Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of signal estimation (denoising) from a
statistical-mechanical perspective, in continuation to a recent work on the
analysis of mean-square error (MSE) estimation using a direct relationship
between optimum estimation and certain partition functions. The paper consists
of essentially two parts. In the first part, using the aforementioned
relationship, we derive single-letter expressions of the mismatched MSE of a
codeword (from a randomly selected code), corrupted by a Gaussian vector
channel. In the second part, we provide several examples to demonstrate phase
transitions in the behavior of the MSE. These examples enable us to understand
more deeply and to gather intuition regarding the roles of the real and the
mismatched probability measures in creating these phase transitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0095</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0095</id><created>2013-06-01</created><authors><author><keyname>Potapov</keyname><forenames>Alexey</forenames></author><author><keyname>Rodionov</keyname><forenames>Sergey</forenames></author></authors><title>Universal Induction with Varying Sets of Combinators</title><categories>cs.AI</categories><comments>To appear in the proceedings of AGI 2013, Lecture Notes in Artificial
  Intelligence, Vol. 7999, pp. 88-97, Springer-Verlag, 2013. The final
  publication is available at link.springer.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universal induction is a crucial issue in AGI. Its practical applicability
can be achieved by the choice of the reference machine or representation of
algorithms agreed with the environment. This machine should be updatable for
solving subsequent tasks more efficiently. We study this problem on an example
of combinatory logic as the very simple Turing-complete reference machine,
which enables modifying program representations by introducing different sets
of primitive combinators. Genetic programming system is used to search for
combinator expressions, which are easily decomposed into sub-expressions being
recombined in crossover. Our experiments show that low-complexity induction or
prediction tasks can be solved by the developed system (much more efficiently
than using brute force); useful combinators can be revealed and included into
the representation simplifying more difficult tasks. However, optimal sets of
combinators depend on the specific task, so the reference machine should be
adaptively chosen in coordination with the search engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0103</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0103</id><created>2013-06-01</created><authors><author><keyname>Telgarsky</keyname><forenames>Rastislav</forenames></author></authors><title>Dominant Frequency Extraction</title><categories>cs.NA</categories><comments>12 pages, 5 figures, Matlab code</comments><msc-class>37M10, 62M15, 62P30, 37M05, 65T50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time series are collected and studied extensively for the knowledge about the
data source characteristics such as the trend or the spectral landscape. Some
peaks in the spectral landscape correspond to dominant frequencies. The
approach here is empirical: all time series are discrete and finite. Contents:
Introduction. 1 Examples of periodic phenomena. 2 Algorithms and libraries. 3
Time series analysis. 4 Dominant frequency in ladar data. Conclusion.
References.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0110</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0110</id><created>2013-06-01</created><updated>2013-06-07</updated><authors><author><keyname>Miller</keyname><forenames>Carl A.</forenames></author></authors><title>Evasiveness of Graph Properties and Topological Fixed-Point Theorems</title><categories>math.CO cs.CC math.AT</categories><comments>Book version, 92 pages</comments><msc-class>55-01</msc-class><acm-class>F.2.2; G.2.2</acm-class><journal-ref>Foundations and Trends in Theoretical Computer Science, vol. 7,
  no. 4, pp. 337-415, 2011</journal-ref><doi>10.1561/0400000055</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many graph properties (e.g., connectedness, containing a complete subgraph)
are known to be difficult to check. In a decision-tree model, the cost of an
algorithm is measured by the number of edges in the graph that it queries. R.
Karp conjectured in the early 1970s that all monotone graph properties are
evasive -- that is, any algorithm which computes a monotone graph property must
check all edges in the worst case. This conjecture is unproven, but a lot of
progress has been made. Starting with the work of Kahn, Saks, and Sturtevant in
1984, topological methods have been applied to prove partial results on the
Karp conjecture. This text is a tutorial on these topological methods. I give a
fully self-contained account of the central proofs from the paper of Kahn,
Saks, and Sturtevant, with no prior knowledge of topology assumed. I also
briefly survey some of the more recent results on evasiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0112</identifier>
 <datestamp>2014-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0112</id><created>2013-06-01</created><authors><author><keyname>Colomer-de-Simon</keyname><forenames>Pol</forenames></author><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Beiro</keyname><forenames>Mariano G.</forenames></author><author><keyname>Alvarez-Hamelin</keyname><forenames>J. Ignacio</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author></authors><title>Deciphering the global organization of clustering in real complex
  networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><journal-ref>Sci. Rep. 3, 2517 (2013)</journal-ref><doi>10.1038/srep02517</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We uncover the global organization of clustering in real complex networks. As
it happens with other fundamental properties of networks such as the degree
distribution, we find that real networks are neither completely random nor
ordered with respect to clustering, although they tend to be closer to
maximally random architectures. We reach this conclusion by comparing the
global structure of clustering in real networks with that in maximally random
and in maximally ordered clustered graphs. The former are produced with an
exponential random graph model that maintains correlations among adjacent edges
at the minimum needed to conform with the expected clustering spectrum; the
later with a random model that arranges triangles in cliques inducing highly
ordered structures. To compare the global organization of clustering in real
and model networks, we compute $m$-core landscapes, where the $m$-core is
defined, akin to the $k$-core, as the maximal subgraph with edges participating
at least in $m$ triangles. This property defines a set of nested subgraphs
that, contrarily to $k$-cores, is able to distinguish between hierarchical and
modular architectures. To visualize the $m$-core decomposition we developed the
LaNet-vi 3.0 tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0114</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0114</id><created>2013-06-01</created><updated>2013-10-29</updated><authors><author><keyname>Penner</keyname><forenames>Orion</forenames></author><author><keyname>Pan</keyname><forenames>Raj Kumar</forenames></author><author><keyname>Petersen</keyname><forenames>Alexander M.</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author></authors><title>On the Predictability of Future Impact in Science</title><categories>physics.soc-ph cs.DL</categories><comments>Published version, 8 pages, 5 figures + Appendix</comments><journal-ref>Scientific Reports 3, 3052 (2013)</journal-ref><doi>10.1038/srep03052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correctly assessing a scientist's past research impact and potential for
future impact is key in recruitment decisions and other evaluation processes.
While a candidate's future impact is the main concern for these decisions, most
measures only quantify the impact of previous work. Recently, it has been
argued that linear regression models are capable of predicting a scientist's
future impact. By applying that future impact model to 762 careers drawn from
three disciplines: physics, biology, and mathematics, we identify a number of
subtle, but critical, flaws in current models. Specifically, cumulative
non-decreasing measures like the h-index contain intrinsic autocorrelation,
resulting in significant overestimation of their &quot;predictive power&quot;. Moreover,
the predictive power of these models depend heavily upon scientists' career
age, producing least accurate estimates for young researchers. Our results
place in doubt the suitability of such models, and indicate further
investigation is required before they can be used in recruiting decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0125</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0125</id><created>2013-06-01</created><authors><author><keyname>Whitehill</keyname><forenames>Jacob</forenames></author></authors><title>Understanding ACT-R - an Outsider's Perspective</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ACT-R theory of cognition developed by John Anderson and colleagues
endeavors to explain how humans recall chunks of information and how they solve
problems. ACT-R also serves as a theoretical basis for &quot;cognitive tutors&quot;,
i.e., automatic tutoring systems that help students learn mathematics, computer
programming, and other subjects. The official ACT-R definition is distributed
across a large body of literature spanning many articles and monographs, and
hence it is difficult for an &quot;outsider&quot; to learn the most important aspects of
the theory. This paper aims to provide a tutorial to the core components of the
ACT-R theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0128</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0128</id><created>2013-06-01</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Towards Detection of Bottlenecks in Modular Systems</title><categories>cs.AI cs.SY</categories><comments>12 pp., tables 4, figures 15</comments><msc-class>68T20, 93A13, 90B50</msc-class><acm-class>I.2.8; J.6; K.4.3; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes some basic approaches to detection of bottlenecks in
composite (modular) systems. The following basic system bottlenecks detection
problems are examined: (1) traditional quality management approaches (Pareto
chart based method, multicriteria analysis as selection of Pareto-efficient
points, and/or multicriteria ranking), (2) selection of critical system
elements (critical components/modules, critical component interconnection), (3)
selection of interconnected system components as composite system faults (via
clique-based fusion), (4) critical elements (e.g., nodes) in networks, and (5)
predictive detection of system bottlenecks (detection of system components
based on forecasting of their parameters). Here, heuristic solving schemes are
used. Numerical examples illustrate the approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0139</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0139</id><created>2013-06-01</created><authors><author><keyname>Jassim</keyname><forenames>Firas A.</forenames></author></authors><title>Image Inpainting by Kriging Interpolation Technique</title><categories>cs.CV</categories><comments>6 pages, 9 figures, 1 table</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT),Vol. 3, No. 5, pp.91-96, 2013</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Image inpainting is the art of predicting damaged regions of an image. The
manual way of image inpainting is a time consuming. Therefore, there must be an
automatic digital method for image inpainting that recovers the image from the
damaged regions. In this paper, a novel statistical image inpainting algorithm
based on Kriging interpolation technique was proposed. Kriging technique
automatically fills the damaged region in an image using the information
available from its surrounding regions in such away that it uses the spatial
correlation structure of points inside the k-by-k block. Kriging has the
ability to face the challenge of keeping the structure and texture information
as the size of damaged region heighten. Experimental results showed that,
Kriging has a high PSNR value when recovering a variety of test images from
scratches and text as damaged regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0150</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0150</id><created>2013-06-01</created><authors><author><keyname>Felicetti</keyname><forenames>Luca</forenames></author><author><keyname>Femminella</keyname><forenames>Mauro</forenames></author><author><keyname>Reali</keyname><forenames>Gianluca</forenames></author></authors><title>Simulation of Molecular Signaling in Blood Vessels: Software Design and
  Application to Atherogenesis</title><categories>cs.CE cond-mat.soft q-bio.QM</categories><comments>Submitted for publication to Nano Communication Networks, Elsevier</comments><journal-ref>Nano Communication Networks Vol.4, No.3, September 2013</journal-ref><doi>10.1016/j.nancom.2013.06.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a software platform, named BiNS2, able to simulate
diffusion-based molecular communications with drift inside blood vessels. The
contribution of the paper is twofold. First a detailed description of the
simulator is given, under the software engineering point of view, by
highlighting the innovations and optimizations introduced. Their introduction
into the previous version of the BiNS simulator was needed to provide to
functions for simulating molecular signaling and communication potentials
inside bounded spaces. The second contribution consists of the analysis,
carried out by using BiNS2, of a specific communication process happening
inside blood vessels, the atherogenesis, which is the initial phase of the
formation of atherosclerotic plaques, due to the abnormal signaling between
platelets and endothelium. From a communication point of view, platelets act as
mobile transmitters, endothelial cells are fixed receivers, sticky to the
vessel walls, and the transmitted signal is made of bursts of molecules emitted
by platelets. The simulator allows evaluating the channel latency and the
footprint on the vessel wall of the transmitted signal as a function of the
transmitter distance from the vessels wall, the signal strength, and the
receiver sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0152</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0152</id><created>2013-06-01</created><authors><author><keyname>Culurciello</keyname><forenames>Eugenio</forenames></author><author><keyname>Jin</keyname><forenames>Jonghoon</forenames></author><author><keyname>Dundar</keyname><forenames>Aysegul</forenames></author><author><keyname>Bates</keyname><forenames>Jordan</forenames></author></authors><title>An Analysis of the Connections Between Layers of Deep Neural Networks</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analysis of different techniques for selecting the connection
be- tween layers of deep neural networks. Traditional deep neural networks use
ran- dom connection tables between layers to keep the number of connections
small and tune to different image features. This kind of connection performs
adequately in supervised deep networks because their values are refined during
the training. On the other hand, in unsupervised learning, one cannot rely on
back-propagation techniques to learn the connections between layers. In this
work, we tested four different techniques for connecting the first layer of the
network to the second layer on the CIFAR and SVHN datasets and showed that the
accuracy can be im- proved up to 3% depending on the technique used. We also
showed that learning the connections based on the co-occurrences of the
features does not confer an advantage over a random connection table in small
networks. This work is helpful to improve the efficiency of connections between
the layers of unsupervised deep neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0153</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0153</id><created>2013-06-01</created><authors><author><keyname>Ajtai</keyname><forenames>Miklos</forenames></author></authors><title>Lower Bounds for RAMs and Quantifier Elimination</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are considering RAMs $N_{n}$, with wordlength $n=2^{d}$, whose arithmetic
instructions are the arithmetic operations multiplication and addition modulo
$2^{n}$, the unary function $ \min\lbrace 2^{x}, 2^{n}-1\rbrace$, the binary
functions $\lfloor x/y\rfloor $ (with $\lfloor x/0 \rfloor =0$), $\max(x,y)$,
$\min(x,y)$, and the boolean vector operations $\wedge,\vee,\neg$ defined on
$0,1$ sequences of length $n$. It also has the other RAM instructions. The size
of the memory is restricted only by the address space, that is, it is $2^{n}$
words. The RAMs has a finite instruction set, each instruction is encoded by a
fixed natural number independently of $n$. Therefore a program $P$ can run on
each machine $N_{n}$, if $n=2^{d}$ is sufficiently large. We show that there
exists an $\epsilon&gt;0$ and a program $P$, such that it satisfies the following
two conditions.
  (i) For all sufficiently large $n=2^{d}$, if $P$ running on $N_{n}$ gets an
input consisting of two words $a$ and $b$, then, in constant time, it gives a
$0,1$ output $P_{n}(a,b)$.
  (ii) Suppose that $Q$ is a program such that for each sufficiently large
$n=2^{d}$, if $Q$, running on $N_{n}$, gets a word $a$ of length $n$ as an
input, then it decides whether there exists a word $b$ of length $n$ such that
$P_{n}(a,b)=0$. Then, for infinitely many positive integers $d$, there exists a
word $a$ of length $n=2^{d}$, such that the running time of $Q$ on $N_{n}$ at
input $a$ is at least $\epsilon (\log d)^{\frac{1}{2}} (\log \log d)^{-1}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0155</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0155</id><created>2013-06-01</created><authors><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Dynamic Ad Allocation: Bandits with Budgets</title><categories>cs.LG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an application of multi-armed bandits to internet advertising
(specifically, to dynamic ad allocation in the pay-per-click model, with
uncertainty on the click probabilities). We focus on an important practical
issue that advertisers are constrained in how much money they can spend on
their ad campaigns. This issue has not been considered in the prior work on
bandit-based approaches for ad allocation, to the best of our knowledge.
  We define a simple, stylized model where an algorithm picks one ad to display
in each round, and each ad has a \emph{budget}: the maximal amount of money
that can be spent on this ad. This model admits a natural variant of UCB1, a
well-known algorithm for multi-armed bandits with stochastic rewards. We derive
strong provable guarantees for this algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0158</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0158</id><created>2013-06-01</created><updated>2013-11-11</updated><authors><author><keyname>Weng</keyname><forenames>Lilian</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author><author><keyname>Ahn</keyname><forenames>Yong-Yeol</forenames></author></authors><title>Virality Prediction and Community Structure in Social Networks</title><categories>cs.SI cs.CY physics.data-an physics.soc-ph</categories><comments>15 pages, 5 figures</comments><journal-ref>Scientific Reports 3, 2522 (2013)</journal-ref><doi>10.1038/srep02522</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  How does network structure affect diffusion? Recent studies suggest that the
answer depends on the type of contagion. Complex contagions, unlike infectious
diseases (simple contagions), are affected by social reinforcement and
homophily. Hence, the spread within highly clustered communities is enhanced,
while diffusion across communities is hampered. A common hypothesis is that
memes and behaviors are complex contagions. We show that, while most memes
indeed behave like complex contagions, a few viral memes spread across many
communities, like diseases. We demonstrate that the future popularity of a meme
can be predicted by quantifying its early spreading pattern in terms of
community concentration. The more communities a meme permeates, the more viral
it is. We present a practical method to translate data about community
structure into predictive knowledge about what information will spread widely.
This connection may lead to significant advances in computational social
science, social media analytics, and marketing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0159</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0159</id><created>2013-06-01</created><updated>2013-06-07</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author></authors><title>The Ghost in the Quantum Turing Machine</title><categories>quant-ph cs.GL physics.hist-ph</categories><comments>85 pages (more a short book than a long essay!), 2 figures. To appear
  in &quot;The Once and Future Turing: Computing the World,&quot; a collection edited by
  S. Barry Cooper and Andrew Hodges. And yes, I know Turing is 101 by now. v2:
  Corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In honor of Alan Turing's hundredth birthday, I unwisely set out some
thoughts about one of Turing's obsessions throughout his life, the question of
physics and free will. I focus relatively narrowly on a notion that I call
&quot;Knightian freedom&quot;: a certain kind of in-principle physical unpredictability
that goes beyond probabilistic unpredictability. Other, more metaphysical
aspects of free will I regard as possibly outside the scope of science. I
examine a viewpoint, suggested independently by Carl Hoefer, Cristi Stoica, and
even Turing himself, that tries to find scope for &quot;freedom&quot; in the universe's
boundary conditions rather than in the dynamical laws. Taking this viewpoint
seriously leads to many interesting conceptual problems. I investigate how far
one can go toward solving those problems, and along the way, encounter (among
other things) the No-Cloning Theorem, the measurement problem, decoherence,
chaos, the arrow of time, the holographic principle, Newcomb's paradox,
Boltzmann brains, algorithmic information theory, and the Common Prior
Assumption. I also compare the viewpoint explored here to the more radical
speculations of Roger Penrose. The result of all this is an unusual perspective
on time, quantum mechanics, and causation, of which I myself remain skeptical,
but which has several appealing features. Among other things, it suggests
interesting empirical questions in neuroscience, physics, and cosmology; and
takes a millennia-old philosophical debate into some underexplored territory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0160</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0160</id><created>2013-06-01</created><updated>2015-06-12</updated><authors><author><keyname>Netrapalli</keyname><forenames>Praneeth</forenames></author><author><keyname>Jain</keyname><forenames>Prateek</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Phase Retrieval using Alternating Minimization</title><categories>stat.ML cs.IT cs.LG math.IT</categories><comments>Accepted for publication in IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase retrieval problems involve solving linear equations, but with missing
sign (or phase, for complex numbers) information. More than four decades after
it was first proposed, the seminal error reduction algorithm of (Gerchberg and
Saxton 1972) and (Fienup 1982) is still the popular choice for solving many
variants of this problem. The algorithm is based on alternating minimization;
i.e. it alternates between estimating the missing phase information, and the
candidate solution. Despite its wide usage in practice, no global convergence
guarantees for this algorithm are known. In this paper, we show that a
(resampling) variant of this approach converges geometrically to the solution
of one such problem -- finding a vector $\mathbf{x}$ from
$\mathbf{y},\mathbf{A}$, where $\mathbf{y} =
\left|\mathbf{A}^{\top}\mathbf{x}\right|$ and $|\mathbf{z}|$ denotes a vector
of element-wise magnitudes of $\mathbf{z}$ -- under the assumption that
$\mathbf{A}$ is Gaussian.
  Empirically, we demonstrate that alternating minimization performs similar to
recently proposed convex techniques for this problem (which are based on
&quot;lifting&quot; to a convex matrix problem) in sample complexity and robustness to
noise. However, it is much more efficient and can scale to large problems.
Analytically, for a resampling version of alternating minimization, we show
geometric convergence to the solution, and sample complexity that is off by log
factors from obvious lower bounds. We also establish close to optimal scaling
for the case when the unknown vector is sparse. Our work represents the first
theoretical guarantee for alternating minimization (albeit with resampling) for
any variant of phase retrieval problems in the non-convex setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0162</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0162</id><created>2013-06-01</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>Cellular-Based Statistical Model for Mobile Dispersion</title><categories>cs.IT math.IT</categories><comments>Proc. of the 14th IEEE International Workshop on Computer-Aided
  Modeling, Analysis and Design of Communication Links and Networks (CAMAD'09)</comments><doi>10.1109/CAMAD.2009.5161465</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While analyzing mobile systems we often approximate the actual coverage
surface and assume an ideal cell shape. In a multi-cellular network, because of
its tessellating nature, a hexagon is more preferred than a circular geometry.
Despite this reality, perhaps due to the inherent simplicity, only a model for
circular based random spreading is available. However, if used, this results an
unfair terminal distribution for non-circular contours. Therefore, in this
paper we specifically derived an unbiased node density model for a hexagon. We
then extended the principle and established stochastic ways to handle sectored
cells. Next, based on these mathematical findings, we created a generic
modeling tool that can support a complex network with varying position,
capacity, size, user density, and sectoring capability. Last, simulation was
used to verify the theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0165</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0165</id><created>2013-06-01</created><authors><author><keyname>Zhang</keyname><forenames>Daqiang</forenames></author><author><keyname>Zou</keyname><forenames>Qin</forenames></author><author><keyname>Xiong</keyname><forenames>Haoyi</forenames></author></authors><title>CRUC: Cold-start Recommendations Using Collaborative Filtering in
  Internet of Things</title><categories>cs.IR cs.NI</categories><comments>Elsevier ESEP 2011: 9-10 December 2011, Singapore, Elsevier Energy
  Procedia, http://www.elsevier.com/locate/procedia/, 2011</comments><doi>10.1016/j.egypro.2011.11.497</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things (IoT) aims at interconnecting everyday objects
(including both things and users) and then using this connection information to
provide customized user services. However, IoT does not work in its initial
stages without adequate acquisition of user preferences. This is caused by
cold-start problem that is a situation where only few users are interconnected.
To this end, we propose CRUC scheme - Cold-start Recommendations Using
Collaborative Filtering in IoT, involving formulation, filtering and prediction
steps. Extensive experiments over real cases and simulation have been performed
to evaluate the performance of CRUC scheme. Experimental results show that CRUC
efficiently solves the cold-start problem in IoT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0173</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0173</id><created>2013-06-02</created><authors><author><keyname>Naghizadeh</keyname><forenames>Parinaz</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Perceptions and Truth: A Mechanism Design Approach to Crowd-Sourcing
  Reputation</title><categories>cs.GT</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a distributed multi-user system where individual entities possess
observations or perceptions of one another, while the truth is only known to
themselves, and they might have an interest in withholding or distorting the
truth. We ask the question whether it is possible for the system as a whole to
arrive at the correct perceptions or assessment of all users, referred to as
their reputation, by encouraging or incentivizing the users to participate in a
collective effort without violating private information and self-interest. Two
specific applications, online shopping and network reputation, are provided to
motivate our study and interpret the results. In this paper we investigate this
problem using a mechanism design theoretic approach. We introduce a number of
utility models representing users' strategic behavior, each consisting of one
or both of a truth element and an image element, reflecting the user's desire
to obtain an accurate view of the other and an inflated image of itself. For
each model, we either design a mechanism that achieves the optimal performance
(solution to the corresponding centralized problem), or present individually
rational sub-optimal solutions. In the latter case, we demonstrate that even
when the centralized solution is not achievable, by using a simple
punish-reward mechanism, not only a user has the incentive to participate and
provide information, but also that this information can improve the system
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0178</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0178</id><created>2013-06-02</created><updated>2013-06-04</updated><authors><author><keyname>Bouslimi</keyname><forenames>Riadh</forenames></author><author><keyname>Messaoudi</keyname><forenames>Abir</forenames></author><author><keyname>Akaichi</keyname><forenames>Jalel</forenames></author></authors><title>Using a bag of Words for Automatic Medical Image Annotation with a
  Latent Semantic</title><categories>cs.IR cs.CV</categories><comments>10 pages, 6 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp;
  Applications(IJAIA), Vol 4, No.3 May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper a new approach for the automatic annotation of
medical images, using the approach of &quot;bag-of-words&quot; to represent the visual
content of the medical image combined with text descriptors based approach
tf.idf and reduced by latent semantic to extract the co-occurrence between
terms and visual terms. A medical report is composed of a text describing a
medical image. First, we are interested to index the text and extract all
relevant terms using a thesaurus containing MeSH medical concepts. In a second
phase, the medical image is indexed while recovering areas of interest which
are invariant to change in scale, light and tilt. To annotate a new medical
image, we use the approach of &quot;bagof-words&quot; to recover the feature vector.
Indeed, we use the vector space model to retrieve similar medical image from
the database training. The calculation of the relevance value of an image to
the query image is based on the cosine function. We conclude with an experiment
carried out on five types of radiological imaging to evaluate the performance
of our system of medical annotation. The results showed that our approach works
better with more images from the radiology of the skull.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0182</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0182</id><created>2013-06-02</created><authors><author><keyname>Ahadi</keyname><forenames>Arash</forenames></author><author><keyname>Dehghan</keyname><forenames>Ali</forenames></author></authors><title>The Inapproximability for the (0,1)-additive number</title><categories>math.CO cs.CC</categories><comments>13 pages, 3 figures, Submitted to Discrete Mathematics &amp; Theoretical
  Computer Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An {\it additive labeling} of a graph $G$ is a function $ \ell :V(G)
\o\mathbb{N}$, such that for every two adjacent vertices $ v $ and $ u$ of $ G
$, $ \sum_{w \sim v}\ell(w)\neq \sum_{w \sim u}\ell(w) $ ($ x \sim y $ means
that $ x $ is joined to $y$). An {\it additive number} of $ G $, denoted by
$\eta(G)$, is the minimum number $k $ such that $ G $ has a additive labeling $
\ell :V(G) \to \lbrace 1,...,k\rbrace $. An {\it additive choosability number}
of a graph $G$, denoted by $\eta_{\ell}(G) $, is the smallest number $k $ such
that $G$ has an additive labeling from any assignment of lists of size $k$ to
the vertices of $G$.
  Seamone (2012) \cite{a80} conjectured that for every graph $G$, $\eta(G)=
\eta_{\ell}(G)$. We give a negative answer to this conjecture and we show that
for every $k$ there is a graph $G$ such that $ \eta_{\ell}(G)- \eta(G) \geq k$.
  A {\it $(0,1)$-additive labeling} of a graph $G$ is a function $ \ell :V(G)
\rightarrow\{0,1\}$, such that for every two adjacent vertices $ v $ and $ u$
of $ G $, $ \sum_{w \sim v}\ell(w)\neq \sum_{w \sim u}\ell(w) $.
  A graph may lack any $(0,1)$-additive labeling. We show that it is $
\mathbf{NP} $-complete to decide whether a $(0,1)$-additive labeling exists for
some families of graphs such as planar triangle-free graphs and perfect graphs.
For a graph $G$ with some $(0,1)$-additive labelings, the $(0,1)$-additive
number of $G$ is defined as $ \eta_{1} (G) = \min_{\ell \in \Gamma}\sum_{v\in
V(G)}\ell(v) $ where $\Gamma$ is the set of $(0,1)$-additive labelings of $G$.
We prove that given a planar graph that contains a $(0,1)$-additive labeling,
for all $ \varepsilon &gt;0 $, approximating the $(0,1)$-additive number within $
n^{1-\varepsilon} $ is $ \mathbf{NP} $-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0183</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0183</id><created>2013-06-02</created><authors><author><keyname>Panda</keyname><forenames>Manoj</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Cell-Level Modeling of IEEE 802.11 WLANs</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a scalable \textit{cell-level} analytical model for multi-cell
infrastructure IEEE 802.11 WLANs under a so-called Pairwise Binary Dependence
(PBD) condition. The PBD condition is a geometric property under which the
relative locations of the nodes inside a cell do not matter and the network is
free of \textit{hidden nodes}. For the cases of saturated nodes and
TCP-controlled long-file downloads, we provide accurate predictions of cell
throughputs. Similar to Bonald et al (Sigmetrics, 2008), we model a multi-cell
WLAN under short-file downloads as &quot;a network of processor-sharing queues with
state-dependent service rates.&quot; Whereas the state-dependent service rates
proposed by Bonald et al are based only on the \textit{number} of contending
neighbors, we employ state-dependent service rates that incorporate the the
impact of the overall \textit{topology} of the network. We propose an
\textit{effective service rate approximation} technique and obtain good
approximations for the \textit{mean flow transfer delay} in each cell. For
TCP-controlled downloads where the APs transmit a large fraction of time, we
show that the throughputs predicted under the PBD condition are very good
approximations in two important scenarios where hidden nodes are indeed present
and the PBD condition does not strictly hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0186</identifier>
 <datestamp>2014-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0186</id><created>2013-06-02</created><updated>2014-01-09</updated><authors><author><keyname>Uria</keyname><forenames>Benigno</forenames></author><author><keyname>Murray</keyname><forenames>Iain</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author></authors><title>RNADE: The real-valued neural autoregressive density-estimator</title><categories>stat.ML cs.LG</categories><comments>12 pages, 3 figures, 3 tables, 2 algorithms. Merges the published
  paper and supplementary material into one document</comments><journal-ref>Advances in Neural Information Processing Systems 26:2175-2183,
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce RNADE, a new model for joint density estimation of real-valued
vectors. Our model calculates the density of a datapoint as the product of
one-dimensional conditionals modeled using mixture density networks with shared
parameters. RNADE learns a distributed representation of the data, while having
a tractable expression for the calculation of densities. A tractable likelihood
allows direct comparison with other methods and training by standard
gradient-based optimizers. We compare the performance of RNADE on several
datasets of heterogeneous and perceptual data, finding it outperforms mixture
models in all but one case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0193</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0193</id><created>2013-06-02</created><authors><author><keyname>Amintoosi</keyname><forenames>Haleh</forenames></author><author><keyname>Kanhere</keyname><forenames>Salil S.</forenames></author></authors><title>A Trust-based Recruitment Framework for Multi-hop Social Participatory
  Sensing</title><categories>cs.SI physics.soc-ph</categories><comments>accepted in DCOSS 2013</comments><doi>10.1109/DCOSS.2013.29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of social participatory sensing provides a substrate to benefit from
friendship relations in recruiting a critical mass of participants willing to
attend in a sensing campaign. However, the selection of suitable participants
who are trustable and provide high quality contributions is challenging. In
this paper, we propose a recruitment framework for social participatory
sensing. Our framework leverages multi-hop friendship relations to identify and
select suitable and trustworthy participants among friends or friends of
friends, and finds the most trustable paths to them. The framework also
includes a suggestion component which provides a cluster of suggested friends
along with the path to them, which can be further used for recruitment or
friendship establishment. Simulation results demonstrate the efficacy of our
proposed recruitment framework in terms of selecting a large number of
well-suited participants and providing contributions with high overall trust,
in comparison with one-hop recruitment architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0194</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0194</id><created>2013-06-02</created><authors><author><keyname>Bechmann</keyname><forenames>Matthias</forenames></author><author><keyname>Clark</keyname><forenames>John</forenames></author><author><keyname>Sebald</keyname><forenames>Angelika</forenames></author></authors><title>Genetic algorithms and solid state NMR pulse sequences</title><categories>cs.CE physics.ins-det</categories><journal-ref>Journal of Magnetic Resonance 228, 66 (2013)</journal-ref><doi>10.1016/j.jmr.2012.12.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of genetic algorithms for the optimisation of magic angle spinning
NMR pulse sequences is discussed. The discussion uses as an example the
optimisation of the C7 dipolar recoupling pulse sequence, aiming to achieve
improved efficiency for spin systems characterised by large chemical shielding
anisotropies and/or small dipolar coupling interactions. The optimised pulse
sequence is found to be robust over a wide range of parameters, requires only
minimal a priori knowledge of the spin system for experimental implementations
with buildup rates being solely determined by the magnitude of the dipolar
coupling interaction, but is found to be less broadbanded than the original C7
pulse sequence. The optimised pulse sequence breaks the synchronicity between
r.f. pulses and sample spinning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0195</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0195</id><created>2013-06-02</created><authors><author><keyname>Dewan</keyname><forenames>Prateek</forenames></author><author><keyname>Sachdeva</keyname><forenames>Niharika</forenames></author><author><keyname>Gupta</keyname><forenames>Mayank</forenames></author><author><keyname>Kumaraguru</keyname><forenames>Ponnurangam</forenames></author></authors><title>ChaMAILeon: Exploring the Usability of a Privacy Preserving Email
  Sharing System</title><categories>cs.CY</categories><comments>12 pages without references and appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While passwords, by definition, are meant to be secret, recent trends have
witnessed an increasing number of people sharing their email passwords with
friends, colleagues, and significant others. However, leading websites like
Google advise their users not to share their passwords with anyone, to avoid
security and privacy breaches. To understand users' general password sharing
behavior and practices, we conducted an online survey with 209 Indian
participants and found that 64.35% of the participants felt a need to share
their email passwords. Further, about 77% of the participants said that they
would want to use a system which could provide them access control features, to
maintain their privacy while sharing emails. To address the privacy concerns of
users who need to share emails, we propose ChaMAILeon, a system which enables
users to share their email passwords while maintaining their privacy.
ChaMAILeon allows users to create multiple passwords for their email account.
Each such password corresponds to a different set of access control rules, and
gives a different view of the same email account. We conducted a controlled
experiment with 30 participants to evaluate the usability of the system. Each
participant was required to perform 5 tasks. Each task corresponded to
different access control rules, which the participant was required to set, for
a dummy email account. We found that, with a reasonable number of multiple
attempts, all 30 participants were able to perform all 5 tasks given to them.
The system usability score was found out to be 75.42. Moreover, 56.6% of the
participants said that they would like to use ChaMAILeon frequently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0196</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0196</id><created>2013-06-02</created><authors><author><keyname>Bao</keyname><forenames>Peng</forenames></author><author><keyname>Shen</keyname><forenames>Hua-Wei</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Cheng</keyname><forenames>Xue-Qi</forenames></author></authors><title>Cumulative Effect in Information Diffusion: A Comprehensive Empirical
  Study on Microblogging Network</title><categories>cs.SI physics.soc-ph</categories><doi>10.1371/journal.pone.0076027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cumulative effect in social contagions underlies many studies on the spread
of innovation, behaviors, and influence. However, few large-scale empirical
studies are conducted to validate the existence of cumulative effect in the
information diffusion on social networks. In this paper, using the
population-scale dataset from the largest Chinese microblogging website, we
conduct a comprehensive study on the cumulative effect in information
diffusion. We base our study on the diffusion network of each message, where
nodes are the involved users and links are the following relationships among
them. We find that multiple exposures to the same message indeed increase the
possibility of forwarding it. However, additional exposures cannot further
improve the chance of forwarding when the number of exposures crosses its peak
at two. This finding questions the cumulative effect hypothesis in information
diffusion. Furthermore, to clarify the forwarding preference among users, we
investigate both the structural motif of the diffusion network and the temporal
pattern of information diffusion process among users. The patterns provide
vital insight for understanding the variation of message popularity and explain
the characteristics of diffusion networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0207</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0207</id><created>2013-06-02</created><authors><author><keyname>Iacono</keyname><forenames>John</forenames></author></authors><title>In pursuit of the dynamic optimality conjecture</title><categories>cs.DS</categories><comments>Preliminary version of paper to appear in the Conference on Space
  Efficient Data Structures, Streams and Algorithms to be held in August 2013
  in honor of Ian Munro's 66th birthday</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1985, Sleator and Tarjan introduced the splay tree, a self-adjusting
binary search tree algorithm. Splay trees were conjectured to perform within a
constant factor as any offline rotation-based search tree algorithm on every
sufficiently long sequence---any binary search tree algorithm that has this
property is said to be dynamically optimal. However, currently neither splay
trees nor any other tree algorithm is known to be dynamically optimal. Here we
survey the progress that has been made in the almost thirty years since the
conjecture was first formulated, and present a binary search tree algorithm
that is dynamically optimal if any binary search tree algorithm is dynamically
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0221</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0221</id><created>2013-06-02</created><authors><author><keyname>Alreshoodi</keyname><forenames>Mohammed</forenames></author><author><keyname>Woods</keyname><forenames>John</forenames></author></authors><title>Survey on QoE\QoS Correlation Models For Multimedia Services</title><categories>cs.MM cs.NI</categories><comments>20 pages, International Journal of Distributed and Parallel Systems
  (IJDPS)</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.4, No.3, May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a brief review of some existing correlation models which
attempt to map Quality of Service (QoS) to Quality of Experience (QoE) for
multimedia services. The term QoS refers to deterministic network behaviour, so
that data can be transported with a minimum of packet loss, delay and maximum
bandwidth. QoE is a subjective measure that involves human dimensions; it ties
together user perception, expectations, and experience of the application and
network performance. The Holy Grail of subjective measurement is to predict it
from the objective measurements; in other words predict QoE from a given set of
QoS parameters or vice versa. Whilst there are many quality models for
multimedia, most of them are only partial solutions to predicting QoE from a
given QoS. This contribution analyses a number of previous attempts and
optimisation techniquesthat can reliably compute the weighting coefficients for
the QoS/QoE mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0222</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0222</id><created>2013-06-02</created><authors><author><keyname>Musa</keyname><forenames>Ibrahim Kabiru</forenames></author><author><keyname>Walker</keyname><forenames>Stuart</forenames></author></authors><title>Hybrid Optical and Electrical Network Flows Scheduling in Cloud Data
  Centres</title><categories>cs.NI</categories><comments>17 pages 11 figures, Journal paper</comments><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 5, No 2, April 2013</journal-ref><doi>10.5121/ijcsit.2013.5201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid intra-data centre networks, with optical and electrical capabilities,
are attracting research interest in recent years. This is attributed to the
emergence of new bandwidth greedy applications and novel computing paradigms. A
key decision to make in networks of this type is the selection and placement of
suitable flows for switching in circuit network. Here, we propose an efficient
strategy for flow selection and placement suitable for hybrid Intra-cloud data
centre networks. We further present techniques for investigating bottlenecks in
a packet networks and for the selection of flows to switch in circuit network.
The bottleneck technique is verified on a Software Defined Network (SDN)
testbed. We also implemented the techniques presented here in a scalable
simulation experiment to investigate the impact of flow selection on network
performance. Results obtained from scalable simulation experiment indicate a
considerable improvement on average throughput, lower configuration delay, and
stability of offloaded flows
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0225</identifier>
 <datestamp>2014-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0225</id><created>2013-06-02</created><updated>2014-11-29</updated><authors><author><keyname>Hui</keyname><forenames>Qing</forenames></author><author><keyname>Zhang</keyname><forenames>Haopeng</forenames></author></authors><title>Convergence Analysis and Parallel Computing Implementation for the
  Multiagent Coordination Optimization Algorithm</title><categories>math.OC cs.NE math.DS</categories><comments>51 pages, 34 figures</comments><report-no>CSEL-06-13</report-no><msc-class>49J45, 65Y05, 90C59, 93D99</msc-class><acm-class>G.1.0; G.1.6; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, a novel variation of Particle Swarm Optimization (PSO)
algorithm, called Multiagent Coordination Optimization (MCO), is implemented in
a parallel computing way for practical use by introducing MATLAB built-in
function &quot;parfor&quot; into MCO. Then we rigorously analyze the global convergence
of MCO by means of semistability theory. Besides sharing global optimal
solutions with the PSO algorithm, the MCO algorithm integrates cooperative
swarm behavior of multiple agents into the update formula by sharing velocity
and position information between neighbors to improve its performance.
Numerical evaluation of the parallel MCO algorithm is provided in the report by
running the proposed algorithm on supercomputers in the High Performance
Computing Center at Texas Tech University. In particular, the optimal value and
consuming time are compared with PSO and serial MCO by solving several
benchmark functions in the literature, respectively. Based on the simulation
results, the performance of the parallel MCO is not only superb compared with
PSO for solving many nonlinear, noncovex optimization problems, but also is of
high efficiency by saving the computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0233</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0233</id><created>2013-06-02</created><authors><author><keyname>Grisi-Filho</keyname><forenames>Jos&#xe9; H. H.</forenames></author><author><keyname>Ossada</keyname><forenames>Raul</forenames></author><author><keyname>Ferreira</keyname><forenames>Fernando</forenames></author><author><keyname>Amaku</keyname><forenames>Marcos</forenames></author></authors><title>Scale-Free Networks with the Same Degree Distribution: Different
  Structural Properties</title><categories>cs.SI cond-mat.dis-nn cond-mat.stat-mech math.DS physics.soc-ph</categories><comments>9 pages, 5 figures, 1 table</comments><journal-ref>Physics Research International, Volume 2013, Article ID 234180, 9
  pages (http://www.hindawi.com/journals/phys/2013/234180/)</journal-ref><doi>10.1155/2013/234180</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have analysed some structural properties of scale-free networks with the
same degree distribution. Departing from a degree distribution obtained from
the Barab\'asi-Albert (BA) algorithm, networks were generated using four
additional different algorithms a (Molloy-Reed, Kalisky, and two new models
named A and B) besides the BA algorithm itself. For each network, we have
calculated the following structural measures: average degree of the nearest
neighbours, central point dominance, clustering coefficient, the Pearson
correlation coefficient, and global efficiency. We found that different
networks with the same degree distribution may have distinct structural
properties. In particular, model B generates decentralized networks with a
larger number of components, a smaller giant component size, and a low global
efficiency when compared to the other algorithms, especially compared to the
centralized BA networks that have all vertices in a single component, with a
medium to high global efficiency. The other three models generate networks with
intermediate characteristics between B and BA models. A consequence of this
finding is that the dynamics of different phenomena on these networks may
differ considerably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0237</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0237</id><created>2013-06-02</created><updated>2013-11-18</updated><authors><author><keyname>Deng</keyname><forenames>Houtao</forenames></author></authors><title>Guided Random Forest in the RRF Package</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random Forest (RF) is a powerful supervised learner and has been popularly
used in many applications such as bioinformatics.
  In this work we propose the guided random forest (GRF) for feature selection.
Similar to a feature selection method called guided regularized random forest
(GRRF), GRF is built using the importance scores from an ordinary RF. However,
the trees in GRRF are built sequentially, are highly correlated and do not
allow for parallel computing, while the trees in GRF are built independently
and can be implemented in parallel. Experiments on 10 high-dimensional gene
data sets show that, with a fixed parameter value (without tuning the
parameter), RF applied to features selected by GRF outperforms RF applied to
all features on 9 data sets and 7 of them have significant differences at the
0.05 level. Therefore, both accuracy and interpretability are significantly
improved. GRF selects more features than GRRF, however, leads to better
classification accuracy. Note in this work the guided random forest is guided
by the importance scores from an ordinary random forest, however, it can also
be guided by other methods such as human insights (by specifying $\lambda_i$).
GRF can be used in &quot;RRF&quot; v1.4 (and later versions), a package that also
includes the regularized random forest methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0239</identifier>
 <datestamp>2015-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0239</id><created>2013-06-02</created><updated>2015-02-21</updated><authors><author><keyname>Tang</keyname><forenames>Yichuan</forenames></author></authors><title>Deep Learning using Linear Support Vector Machines</title><categories>cs.LG stat.ML</categories><comments>Contribution to the ICML 2013 Challenges in Representation Learning
  Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, fully-connected and convolutional neural networks have been trained
to achieve state-of-the-art performance on a wide variety of tasks such as
speech recognition, image classification, natural language processing, and
bioinformatics. For classification tasks, most of these &quot;deep learning&quot; models
employ the softmax activation function for prediction and minimize
cross-entropy loss. In this paper, we demonstrate a small but consistent
advantage of replacing the softmax layer with a linear support vector machine.
Learning minimizes a margin-based loss instead of the cross-entropy loss. While
there have been various combinations of neural nets and SVMs in prior art, our
results using L2-SVMs show that by simply replacing softmax with linear SVMs
gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and
the ICML 2013 Representation Learning Workshop's face expression recognition
challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0242</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0242</id><created>2013-06-02</created><updated>2013-06-28</updated><authors><author><keyname>Cilleruelo</keyname><forenames>Javier</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author><author><keyname>Sheffer</keyname><forenames>Adam</forenames></author></authors><title>On lattices, distinct distances, and the Elekes-Sharir framework</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we consider distinct distances determined by points in an
integer lattice. We first consider Erdos's lower bound for the square lattice,
recast in the setup of the so-called Elekes-Sharir framework \cite{ES11,GK11},
and show that, without a major change, this framework \emph{cannot} lead to
Erdos's conjectured lower bound. This shows that the upper bound of Guth and
Katz \cite{GK11} for the related 3-dimensional line-intersection problem is
tight for this instance. The gap between this bound and the actual bound of
Erdos arises from an application of the Cauchy-Schwarz inequality (which is an
integral part of the Elekes-Sharir framework). Our analysis relies on two
number-theoretic results by Ramanujan.
  We also consider distinct distances in rectangular lattices of the form
$\{(i,j) \mid 0\le i\le n^{1-\alpha},\ 0\le j\le n^{\alpha}\}$, for some
$0&lt;\alpha&lt;1/2$, and show that the number of distinct distances in such a
lattice is $\Theta(n)$. In a sense, our proof &quot;bypasses&quot; a deep conjecture in
number theory, posed by Cilleruelo and Granville \cite{CG07}. A positive
resolution of this conjecture would also have implied our bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0257</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0257</id><created>2013-06-02</created><updated>2014-02-02</updated><authors><author><keyname>Frasco</keyname><forenames>Gerald F.</forenames></author><author><keyname>Sun</keyname><forenames>Jie</forenames></author><author><keyname>Rozenfeld</keyname><forenames>Hernan D.</forenames></author><author><keyname>ben-Avraham</keyname><forenames>Daniel</forenames></author></authors><title>Spatially distributed social complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI nlin.AO</categories><comments>9 pages, 6 figures</comments><journal-ref>Phys. Rev. X 4, 011008 (2014)</journal-ref><doi>10.1103/PhysRevX.4.011008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a bare-bones stochastic model that takes into account both the
geographical distribution of people within a country and their complex network
of connections. The model, which is designed to give rise to a scale-free
network of social connections and to visually resemble the geographical spread
seen in satellite pictures of the Earth at night, gives rise to a power-law
distribution for the ranking of cities by population size (but for the largest
cities) and reflects the notion that highly connected individuals tend to live
in highly populated areas. It also yields some interesting insights regarding
Gibrat's law for the rates of city growth (by population size), in partial
support of the findings in a recent analysis of real data [Rozenfeld et al.,
Proc. Natl. Acad. Sci. U.S.A. 105, 18702 (2008)]. The model produces a
nontrivial relation between city population and city population density and a
superlinear relationship between social connectivity and city population, both
of which seem quite in line with real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0258</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0258</id><created>2013-06-02</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Slime mould tactile sensor</title><categories>cs.ET nlin.AO physics.bio-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slime mould P. polycephalum is a single cells visible by unaided eye. The
cells shows a wide spectrum of intelligent behaviour. By interpreting the
behaviour in terms of computation one can make a slime mould based computing
device. The Physarum computers are capable to solve a range of tasks of
computational geometry, optimisation and logic. Physarum computers designed so
far lack of localised inputs. Commonly used inputs --- illumination and
chemo-attractants and -repellents --- usually act on extended domains of the
slime mould's body. Aiming to design massive-parallel tactile inputs for slime
mould computers we analyse a temporal dynamic of P. polycephalum's electrical
response to tactile stimulation. In experimental laboratory studies we discover
how the Physarum responds to application and removal of a local mechanical
pressure with electrical potential impulses and changes in its electrical
potential oscillation patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0260</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0260</id><created>2013-06-02</created><authors><author><keyname>Lu</keyname><forenames>Jie</forenames></author><author><keyname>Tang</keyname><forenames>Choon Yik</forenames></author></authors><title>Distributed Asynchronous Algorithms for Solving Positive Definite Linear
  Equations over Dynamic Networks</title><categories>cs.SY cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops Subset Equalizing (SE), a distributed algorithm for
solving a symmetric positive definite system of linear equations over a network
of agents with arbitrary asynchronous interactions and membership dynamics,
where each agent may join and leave the network at any time, for infinitely
many times, and may lose all its memory upon leaving. To design and analyze SE,
we introduce a time-varying Lyapunov-like function, defined on a state space
with changing dimension, and a generalized concept of network connectivity,
capable of handling such interactions and membership dynamics. Based on them,
we establish the boundedness, asymptotic convergence, and exponential
convergence of SE, along with a bound on its convergence rate. Finally, through
extensive simulation, we demonstrate the effectiveness of SE in a volatile
agent network and show that a special case of SE, termed Groupwise Equalizing,
is significantly more bandwidth/energy efficient than two existing algorithms
in multi-hop wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0264</identifier>
 <datestamp>2014-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0264</id><created>2013-06-02</created><updated>2014-11-25</updated><authors><author><keyname>Dong</keyname><forenames>Wenxiang</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Yang</keyname><forenames>Ying</forenames></author><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author></authors><title>Epidemic-like Proximity-based Traffic Offloading</title><categories>cs.IT cs.SI math.IT</categories><comments>This paper has been withdrawn by the author due to premature and
  incomplete results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular networks are overloaded due to the mobile traffic surge, and mobile
social network (MSNets) carrying information flow can help reduce cellular
traffic load. If geographically-nearby users directly adopt WiFi or Bluetooth
technology (i.e., leveraging proximity-based communication) for information
spreading in MSNets, a portion of mobile traffic can be offloaded from cellular
networks. For many delay-tolerant applications, it is beneficial for traffic
offloading to pick some seed users as information sources, which help further
spread the information to others in an epidemic-like manner using
proximity-based communication. In this paper, we develop a theoretical
framework to study the issue of choosing only k seed users so as to maximize
the mobile traffic offloaded from cellular networks via proximity-based
communication. We introduce a gossip-style social cascade (GSC) model to model
the information diffusion process, which captures the epidemic-like nature of
proximity-based communication and characterizes users' social participation as
well. For static networks as a special-case study and mobile networks, we
establish an equivalent view and a temporal mapping of the information
diffusion process, respectively, leveraging virtual coupon collectors. We
further prove the submodularity in the information diffusion and propose a
greedy algorithm to choose the seed users for proximity-based traffic
offloading, yielding a solution within about 63% of the optimal value to the
traffic offloading maximization (TOM) problem. Experiments are carried out to
study the offloading performance of our approach, illustrating that
proximity-based communication can offload cellular traffic by over 60% with a
small number of seed users and the greedy algorithm significantly outperforms
the heuristic and random algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0271</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0271</id><created>2013-06-02</created><authors><author><keyname>Danilevsky</keyname><forenames>Marina</forenames></author><author><keyname>Wang</keyname><forenames>Chi</forenames></author><author><keyname>Desai</keyname><forenames>Nihit</forenames></author><author><keyname>Guo</keyname><forenames>Jingyi</forenames></author><author><keyname>Han</keyname><forenames>Jiawei</forenames></author></authors><title>KERT: Automatic Extraction and Ranking of Topical Keyphrases from
  Content-Representative Document Titles</title><categories>cs.LG cs.IR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce KERT (Keyphrase Extraction and Ranking by Topic), a framework
for topical keyphrase generation and ranking. By shifting from the
unigram-centric traditional methods of unsupervised keyphrase extraction to a
phrase-centric approach, we are able to directly compare and rank phrases of
different lengths. We construct a topical keyphrase ranking function which
implements the four criteria that represent high quality topical keyphrases
(coverage, purity, phraseness, and completeness). The effectiveness of our
approach is demonstrated on two collections of content-representative titles in
the domains of Computer Science and Physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0281</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0281</id><created>2013-06-02</created><authors><author><keyname>Brakerski</keyname><forenames>Zvika</forenames></author><author><keyname>Langlois</keyname><forenames>Adeline</forenames></author><author><keyname>Peikert</keyname><forenames>Chris</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author><author><keyname>Stehl&#xe9;</keyname><forenames>Damien</forenames></author></authors><title>Classical Hardness of Learning with Errors</title><categories>cs.CC cs.CR</categories><comments>Preliminary version in STOC'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Learning with Errors (LWE) problem is classically at least
as hard as standard worst-case lattice problems, even with polynomial modulus.
Previously this was only known under quantum reductions.
  Our techniques capture the tradeoff between the dimension and the modulus of
LWE instances, leading to a much better understanding of the landscape of the
problem. The proof is inspired by techniques from several recent cryptographic
constructions, most notably fully homomorphic encryption schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0282</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0282</id><created>2013-06-02</created><authors><author><keyname>Rong</keyname><forenames>Junjie</forenames></author><author><keyname>Wen</keyname><forenames>Lihua</forenames></author><author><keyname>Xiao</keyname><forenames>Jinyou</forenames></author></authors><title>An efficient method for evaluating BEM singular integrals on curved
  elements with application in acoustic analysis</title><categories>cs.CE math.NA</categories><comments>19 Pages, 10 figures</comments><journal-ref>Engineering Analysis with Boundary Elements, 2014, 38: 83-93</journal-ref><doi>10.1016/j.enganabound.2013.10.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The polar coordinate transformation (PCT) method has been extensively used to
treat various singular integrals in the boundary element method (BEM). However,
the resultant integrands of the PCT tend to become nearly singular when (1) the
aspect ratio of the element is large or (2) the field point is closed to the
element boundary; thus a large number of quadrature points are needed to
achieve a relatively high accuracy. In this paper, the first problem is
circumvented by using a conformal transformation so that the geometry of the
curved physical element is preserved in the transformed domain. The second
problem is alleviated by using a sigmoidal transformation, which makes the
quadrature points more concentrated around the near singularity.
  By combining the proposed two transformations with the Guiggiani's method in
[M. Guiggiani, \emph{et al}.
  A general algorithm for the numerical solution of hypersingular boundary
integral equations.
  \emph{ASME Journal of Applied Mechanics}, 59(1992), 604-614], one obtains an
efficient and robust numerical method for computing the weakly-, strongly- and
hyper-singular integrals in high-order BEM with curved elements. Numerical
integration results show that, compared with the original PCT, the present
method can reduce the number of quadrature points considerably, for given
accuracy. For further verification, the method is incorporated into a 2-order
Nystr\&quot;om BEM code for solving acoustic Burton-Miller boundary integral
equation. It is shown that the method can retain the convergence rate of the
BEM with much less quadrature points than the existing PCT. The method is
implemented in C language and freely available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0291</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0291</id><created>2013-06-03</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author><author><keyname>Baek</keyname><forenames>Junho</forenames></author></authors><title>Revisiting Circular-Based Random Node Simulation</title><categories>cs.IT math.IT</categories><comments>Proc. of the 9th IEEE International Symposium on Communication and
  Information Technology (ISCIT'09)</comments><doi>10.1109/ISCIT.2009.5341148</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In literature, a stochastic model for spreading nodes in a cellular cell is
available. Despite its existence, the current method does not offer any
versatility in dealing with sectored layers. Of course, this needed
adaptability could be created synthetically through heuristic means. However,
due to selective sampling, such practice dissolves the true randomness sought.
Hence, in this paper, a universal exact scattering model is derived. Also, as
an alternative to exhaustive simulation, a generic close-form path-loss
predictor between a node and a BS is obtained. Further, using these results, an
algorithm based on the superposition principle is proposed. This will ensure
greater emulation flexibility, and attain a heterogeneous spatial density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0308</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0308</id><created>2013-06-03</created><updated>2014-02-12</updated><authors><author><keyname>Hennig</keyname><forenames>Philipp</forenames></author><author><keyname>Hauberg</keyname><forenames>S&#xf8;ren</forenames></author></authors><title>Probabilistic Solutions to Differential Equations and their Application
  to Riemannian Statistics</title><categories>stat.ML cs.LG math.NA</categories><comments>11 page (9 page conference paper, plus supplements)</comments><msc-class>65L05, 65L10, 58D17</msc-class><journal-ref>Proceedings of the 17th International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2014, Reykjavik, Iceland. Journal of
  Machine Learning Research: W&amp;CP volume 33</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a probabilistic numerical method for the solution of both boundary
and initial value problems that returns a joint Gaussian process posterior over
the solution. Such methods have concrete value in the statistics on Riemannian
manifolds, where non-analytic ordinary differential equations are involved in
virtually all computations. The probabilistic formulation permits marginalising
the uncertainty of the numerical solution such that statistics are less
sensitive to inaccuracies. This leads to new Riemannian algorithms for mean
value computations and principal geodesic analysis. Marginalisation also means
results can be less precise than point estimates, enabling a noticeable
speed-up over the state of the art. Our approach is an argument for a wider
point that uncertainty caused by numerical calculations should be tracked
throughout the pipeline of machine learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0312</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0312</id><created>2013-06-03</created><authors><author><keyname>Ganesh</keyname><forenames>S.</forenames></author><author><keyname>Amutha</keyname><forenames>R.</forenames></author></authors><title>Efficient and Secure Routing Protocol for Wireless Sensor Networks
  through SNR based Dynamic Clustering Mechanisms</title><categories>cs.NI</categories><comments>11 Pages, 3 Tables, Accepted for publication in Journal of
  Communications and Networks,ISSN 1976-5541 (Online) ISSN 1229-2370 (Print),
  May 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in Wireless Sensor Network Technology (WSN) have provided the
availability of small and low-cost sensor with capability of sensing various
types of physical and environmental conditions, data processing and wireless
communication. In WSN, the sensor nodes have a limited transmission range, and
their processing and storage capabilities as well as their energy resources are
limited. Triple Umpiring System (TUS) has already been proved its better
performance on Wireless Sensor Networks. Clustering technique provides an
effective way to prolong the lifetime of WSN. In this paper, we modified the Ad
hoc on demand Distance Vector Routing (AODV) by incorporating Signal to Noise
Ratio (SNR) based dynamic clustering. The proposed scheme Efficient and Secure
Routing Protocol for Wireless Sensor Networks through SNR based dynamic
Clustering mechanisms (ESRPSDC) can partition the nodes into clusters and
select the Cluster Head (CH) among the nodes based on the energy and Non
Cluster Head (NCH) nodes join with a specific CH based on SNR Values. Error
recovery has been implemented during Inter cluster routing itself in order to
avoid end-toend error recovery. Security has been achieved by isolating the
malicious nodes using sink based routing pattern analysis. Extensive
investigation studies using Global Mobile Simulator (GloMoSim) showed that this
Hybrid ESRP significantly improves the Energy efficiency and Packet Reception
Rate (PRR) compared to SNR unaware routing algorithms like Low Energy Aware
Adaptive Clustering Hierarchy (LEACH) and Power- Efficient Gathering in Sensor
Information Systems (PEGASIS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0315</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0315</id><created>2013-06-03</created><authors><author><keyname>Dagdelen</keyname><forenames>&#xd6;zg&#xfc;r</forenames></author><author><keyname>Gagliardoni</keyname><forenames>Marc Fischlin Tommaso</forenames></author></authors><title>The Fiat-Shamir Transformation in a Quantum World</title><categories>cs.CR</categories><comments>30 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fiat-Shamir transformation is a famous technique to turn identification
schemes into signature schemes. The derived scheme is provably secure in the
random-oracle model against classical adversaries. Still, the technique has
also been suggested to be used in connection with quantum-immune identification
schemes, in order to get quantum-immune signature schemes. However, a recent
paper by Boneh et al. (Asiacrypt 2011) has raised the issue that results in the
random-oracle model may not be immediately applicable to quantum adversaries,
because such adversaries should be allowed to query the random oracle in
superposition. It has been unclear if the Fiat-Shamir technique is still secure
in this quantum oracle model (QROM).
  Here, we discuss that giving proofs for the Fiat-Shamir transformation in the
QROM is presumably hard. We show that there cannot be black-box extractors, as
long as the underlying quantum-immune identification scheme is secure against
active adversaries and the first message of the prover is independent of its
witness. Most schemes are of this type. We then discuss that for some schemes
one may be able to resurrect the Fiat-Shamir result in the QROM by modifying
the underlying protocol first. We discuss in particular a version of the
Lyubashevsky scheme which is provably secure in the QROM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0322</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0322</id><created>2013-06-03</created><updated>2014-02-22</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author><author><keyname>Soler-Toscano</keyname><forenames>Fernando</forenames></author><author><keyname>Dingle</keyname><forenames>Kamaludin</forenames></author><author><keyname>Louis</keyname><forenames>Ard A.</forenames></author></authors><title>Correlation of Automorphism Group Size and Topological Properties with
  Program-size Complexity Evaluations of Graphs and Complex Networks</title><categories>cs.IT cs.CC cs.CG math.IT q-bio.MN</categories><comments>15 2-column pages, 20 figures. Forthcoming in Physica A: Statistical
  Mechanics and its Applications</comments><doi>10.1016/j.physa.2014.02.060</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that numerical approximations of Kolmogorov complexity (K) applied to
graph adjacency matrices capture some group-theoretic and topological
properties of graphs and empirical networks ranging from metabolic to social
networks. That K and the size of the group of automorphisms of a graph are
correlated opens up interesting connections to problems in computational
geometry, and thus connects several measures and concepts from complexity
science. We show that approximations of K characterise synthetic and natural
networks by their generating mechanisms, assigning lower algorithmic randomness
to complex network models (Watts-Strogatz and Barabasi-Albert networks) and
high Kolmogorov complexity to (random) Erdos-Renyi graphs. We derive these
results via two different Kolmogorov complexity approximation methods applied
to the adjacency matrices of the graphs and networks. The methods used are the
traditional lossless compression approach to Kolmogorov complexity, and a
normalised version of a Block Decomposition Method (BDM) measure, based on
algorithmic probability theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0326</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0326</id><created>2013-06-03</created><authors><author><keyname>Kajdanowicz</keyname><forenames>Tomasz</forenames></author><author><keyname>Kazienko</keyname><forenames>Przemyslaw</forenames></author><author><keyname>Indyk</keyname><forenames>Wojciech</forenames></author></authors><title>Parallel Processing of Large Graphs</title><categories>cs.DC</categories><comments>Preprint submitted to Future Generation Computer Systems</comments><msc-class>65Y05</msc-class><acm-class>D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More and more large data collections are gathered worldwide in various IT
systems. Many of them possess the networked nature and need to be processed and
analysed as graph structures. Due to their size they require very often usage
of parallel paradigm for efficient computation. Three parallel techniques have
been compared in the paper: MapReduce, its map-side join extension and Bulk
Synchronous Parallel (BSP). They are implemented for two different graph
problems: calculation of single source shortest paths (SSSP) and collective
classification of graph nodes by means of relational influence propagation
(RIP). The methods and algorithms are applied to several network datasets
differing in size and structural profile, originating from three domains:
telecommunication, multimedia and microblog. The results revealed that
iterative graph processing with the BSP implementation always and
significantly, even up to 10 times outperforms MapReduce, especially for
algorithms with many iterations and sparse communication. Also MapReduce
extension based on map-side join usually noticeably presents better efficiency,
although not as much as BSP. Nevertheless, MapReduce still remains the good
alternative for enormous networks, whose data structures do not fit in local
memories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0334</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0334</id><created>2013-06-03</created><authors><author><keyname>Zheng</keyname><forenames>Xiaoying</forenames></author><author><keyname>Cho</keyname><forenames>Chunglae</forenames></author><author><keyname>Xia</keyname><forenames>Ye</forenames></author></authors><title>Algorithms and Stability Analysis for Content Distribution over Multiple
  Multicast Trees</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates theoretical issues in applying the universal swarming
technique to efficient content distribution. In a swarming session, a file is
distributed to all the receivers by having all the nodes in the session
exchange file chunks. By universal swarming, not only all the nodes in the
session, but also some nodes outside the session may participate in the chunk
exchange to improve the distribution performance. We present a universal
swarming model where the chunks are distributed along different Steiner trees
rooted at the source and covering all the receivers. We assume chunks arrive
dynamically at the sources and focus on finding stable universal swarming
algorithms. To achieve the throughput region, universal swarming usually
involves a tree-selection subproblem of finding a min-cost Steiner tree, which
is NP-hard. We propose a universal swarming scheme that employs an approximate
tree-selection algorithm. We show that it achieves network stability for a
reduced throughput region, where the reduction ratio is no more than the
approximation ratio of the tree-selection algorithm. We propose a second
universal swarming scheme that employs a randomized tree-selection algorithm.
It achieves the throughput region, but with a weaker stability result. The
proposed schemes and their variants are expected to be useful for
infrastructure-based content distribution networks with massive content and
relatively stable network environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0340</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0340</id><created>2013-06-03</created><authors><author><keyname>Lima</keyname><forenames>F. W. S.</forenames></author></authors><title>Majority-vote model on Opinion-Dependent Networks</title><categories>physics.soc-ph cs.SI</categories><comments>9 figures, accepted for publication in IJMPC</comments><doi>10.1142/S0129183113500666</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a nonequilibrium model with up-down symmetry and a noise parameter
$q$ known as majority-vote model of M.J. Oliveira $1992$ on opinion-dependent
network or Stauffer-Hohnisch-Pittnauer networks. By Monte Carlo simulations and
finite-size scaling relations the critical exponents $\beta/\nu$, $\gamma/\nu$,
and $1/\nu$ and points $q_{c}$ and $U^*$ are obtained. After extensive
simulations, we obtain $\beta/\nu=0.230(3)$, $\gamma/\nu=0.535(2)$, and
$1/\nu=0.475(8)$. The calculated values of the critical noise parameter and
Binder cumulant are $q_{c}=0.166(3)$ and $U^*=0.288(3)$. Within the error bars,
the exponents obey the relation $2\beta/\nu+\gamma/\nu=1$ and the results
presented here demonstrate that the majority-vote model belongs to a different
universality class than the equilibrium Ising model on
Stauffer-Hohnisch-Pittnauer networks, but to the same class as majority-vote
models on some other networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0361</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0361</id><created>2013-06-03</created><authors><author><keyname>Graziotin</keyname><forenames>Daniel</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author></authors><title>An Analysis of issues against the adoption of Dynamic Carpooling</title><categories>cs.CY</categories><comments>10 pages, whitepaper, extracted from B.Sc. thesis &quot;Dycapo: On the
  creation of an open-source Server and a Protocol for Dynamic Carpooling&quot;
  (Daniel Graziotin, 2010)</comments><doi>10.6084/m9.figshare.710636</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Using a private car is a transportation system very common in industrialized
countries. However, it causes different problems such as overuse of oil,
traffic jams causing earth pollution, health problems and an inefficient use of
personal time. One possible solution to these problems is carpooling, i.e.
sharing a trip on a private car of a driver with one or more passengers.
Carpooling would reduce the number of cars on streets hence providing worldwide
environmental, economical and social benefits. The matching of drivers and
passengers can be facilitated by information and communication technologies.
Typically, a driver inserts on a web-site the availability of empty seats on
his/her car for a planned trip and potential passengers can search for trips
and contact the drivers. This process is slow and can be appropriate for long
trips planned days in advance. We call this static carpooling and we note it is
not used frequently by people even if there are already many web-sites offering
this service and in fact the only real open challenge is widespread adoption.
Dynamic carpooling, on the other hand, takes advantage of the recent and
increasing adoption of Internet-connected geo-aware mobile devices for enabling
impromptu trip opportunities. Passengers request trips directly on the street
and can find a suitable ride in just few minutes. Currently there are no
dynamic carpooling systems widely used. Every attempt to create and organize
such systems failed. This paper reviews the state of the art of dynamic
carpooling. It identifies the most important issues against the adoption of
dynamic carpooling systems and the proposed solutions for such issues. It
proposes a first input on solving the problem of mass-adopting dynamic
carpooling systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0369</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0369</id><created>2013-06-03</created><authors><author><keyname>Goyal</keyname><forenames>Arnav</forenames></author><author><keyname>Limbachiya</keyname><forenames>Dixita</forenames></author><author><keyname>Gupta</keyname><forenames>Shikhar Kumar</forenames></author><author><keyname>Joshi</keyname><forenames>Foram</forenames></author><author><keyname>Pritmani</keyname><forenames>Sushant</forenames></author><author><keyname>Sahai</keyname><forenames>Akshita</forenames></author><author><keyname>Gupta</keyname><forenames>Manish K</forenames></author></authors><title>DNA Pen: A Tool for Drawing on a Molecular Canvas</title><categories>cs.ET</categories><comments>Submitted to DNA19. The software is available at
  http://www.guptalab.org/dnapen</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DNA origami is an interdisciplinary area where DNA can be used as a building
block for making useful stuff at nanoscale. This work presents an open source
software DNA pen (based on the recent work of Peng Yin and his group) which can
be used (using free hand and digital molecular canvas) to draw an object at
nanoscale. Software generates error free DNA sequences which can be used in the
wet lab to create the object at the nanoscale. Using DNA pen we have drawn
several objects including the map of India and sanskrit letter &quot;Om&quot; from free
hand molecular canvas and digital letter DNA using digitized molecular canvas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0386</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0386</id><created>2013-06-03</created><updated>2016-02-10</updated><authors><author><keyname>Scherrer</keyname><forenames>Bruno</forenames><affiliation>BIGS</affiliation></author></authors><title>Improved and Generalized Upper Bounds on the Complexity of Policy
  Iteration</title><categories>math.OC cs.AI cs.DM cs.RO</categories><comments>Markov decision processes, Dynamic Programming, Analysis of
  Algorithms, Mathematics of Operations Research, INFORMS, 2016</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a Markov Decision Process (MDP) with $n$ states and a totalnumber $m$
of actions, we study the number of iterations needed byPolicy Iteration (PI)
algorithms to converge to the optimal$\gamma$-discounted policy. We consider
two variations of PI: Howard'sPI that changes the actions in all states with a
positive advantage,and Simplex-PI that only changes the action in the state
with maximaladvantage. We show that Howard's PI terminates after at most
$O\left(\frac{m}{1-\gamma}\log\left(\frac{1}{1-\gamma}\right)\right)$iterations,
improving by a factor $O(\log n)$ a result by Hansen etal., while Simplex-PI
terminates after at most
$O\left(\frac{nm}{1-\gamma}\log\left(\frac{1}{1-\gamma}\right)\right)$iterations,
improving by a factor $O(\log n)$ a result by Ye. Undersome structural
properties of the MDP, we then consider bounds thatare independent of the
discount factor~$\gamma$: quantities ofinterest are bounds $\tau\_t$ and
$\tau\_r$---uniform on all states andpolicies---respectively on the
\emph{expected time spent in transientstates} and \emph{the inverse of the
frequency of visits in recurrentstates} given that the process starts from the
uniform distribution.Indeed, we show that Simplex-PI terminates after at most
$\tilde O\left(n^3 m^2 \tau\_t \tau\_r \right)$ iterations. This extends
arecent result for deterministic MDPs by Post &amp; Ye, in which $\tau\_t\le 1$ and
$\tau\_r \le n$, in particular it shows that Simplex-PI isstrongly polynomial
for a much larger class of MDPs. We explain whysimilar results seem hard to
derive for Howard's PI. Finally, underthe additional (restrictive) assumption
that the state space ispartitioned in two sets, respectively states that are
transient andrecurrent for all policies, we show that both Howard's PI
andSimplex-PI terminate after at most $\tilde
O(m(n^2\tau\_t+n\tau\_r))$iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0388</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0388</id><created>2013-06-03</created><authors><author><keyname>Wellman</keyname><forenames>Michael P.</forenames></author><author><keyname>Kim</keyname><forenames>Tae Hyung</forenames></author><author><keyname>Duong</keyname><forenames>Quang</forenames></author></authors><title>Analyzing Incentives for Protocol Compliance in Complex Domains: A Case
  Study of Introduction-Based Routing</title><categories>cs.GT cs.CR</categories><comments>Presented at the Twelfth Workshop on the Economics of Information
  Security, Washington, DC, June 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal analyses of incentives for compliance with network protocols often
appeal to game-theoretic models and concepts. Applications of game-theoretic
analysis to network security have generally been limited to highly stylized
models, where simplified environments enable tractable study of key strategic
variables. We propose a simulation-based approach to game-theoretic analysis of
protocol compliance, for scenarios with large populations of agents and large
policy spaces. We define a general procedure for systematically exploring a
structured policy space, directed expressly to resolve the qualitative
classification of equilibrium behavior as compliant or non-compliant. The
techniques are illustrated and exercised through an extensive case study
analyzing compliance incentives for introduction-based routing. We find that
the benefits of complying with the protocol are particularly strong for nodes
subject to attack, and the overall compliance level achieved in equilibrium,
while not universal, is sufficient to support the desired security goals of the
protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0393</identifier>
 <datestamp>2013-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0393</id><created>2013-06-03</created><updated>2013-07-02</updated><authors><author><keyname>Wang</keyname><forenames>Yuyi</forenames></author><author><keyname>Ramon</keyname><forenames>Jan</forenames></author><author><keyname>Guo</keyname><forenames>Zheng-Chu</forenames></author></authors><title>Learning from networked examples in a k-partite graph</title><categories>cs.LG stat.ML</categories><comments>The full paper of the CAP2013 version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many machine learning algorithms are based on the assumption that training
examples are drawn independently. However, this assumption does not hold
anymore when learning from a networked sample where two or more training
examples may share common features. We propose an efficient weighting method
for learning from networked examples and show the sample error bound which is
better than previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0400</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0400</id><created>2013-06-03</created><updated>2013-09-30</updated><authors><author><keyname>Brand</keyname><forenames>Michael</forenames></author></authors><title>The RAM equivalent of P vs. RP</title><categories>cs.CC cs.FL</categories><comments>23 pages</comments><msc-class>68Q05, 68Q10, 68Q15</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental open questions in computational complexity is whether
the class of problems solvable by use of stochasticity under the Random
Polynomial time (RP) model is larger than the class of those solvable in
deterministic polynomial time (P). However, this question is only open for
Turing Machines, not for Random Access Machines (RAMs).
  Simon (1981) was able to show that for a sufficiently equipped Random Access
Machine, the ability to switch states nondeterministically does not entail any
computational advantage. However, in the same paper, Simon describes a
different (and arguably more natural) scenario for stochasticity under the RAM
model. According to Simon's proposal, instead of receiving a new random bit at
each execution step, the RAM program is able to execute the pseudofunction
$\textit{RAND}(y)$, which returns a uniformly distributed random integer in the
range $[0,y)$. Whether the ability to allot a random integer in this fashion is
more powerful than the ability to allot a random bit remained an open question
for the last 30 years.
  In this paper, we close Simon's open problem, by fully characterising the
class of languages recognisable in polynomial time by each of the RAMs
regarding which the question was posed. We show that for some of these,
stochasticity entails no advantage, but, more interestingly, we show that for
others it does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0404</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0404</id><created>2013-06-03</created><updated>2013-06-20</updated><authors><author><keyname>He</keyname><forenames>Jun</forenames></author><author><keyname>Zhang</keyname><forenames>Dejiao</forenames></author><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Tao</keyname><forenames>Tao</forenames></author></authors><title>Iterative Grassmannian Optimization for Robust Image Alignment</title><categories>cs.CV math.OC stat.ML</categories><comments>Preprint submitted to the special issue of the Image and Vision
  Computing Journal on the theme &quot;The Best of Face and Gesture 2013&quot;</comments><journal-ref>Image and Vision Computing, 32(10), 800-813, 2014</journal-ref><doi>10.1016/j.imavis.2014.02.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust high-dimensional data processing has witnessed an exciting development
in recent years, as theoretical results have shown that it is possible using
convex programming to optimize data fit to a low-rank component plus a sparse
outlier component. This problem is also known as Robust PCA, and it has found
application in many areas of computer vision. In image and video processing and
face recognition, the opportunity to process massive image databases is
emerging as people upload photo and video data online in unprecedented volumes.
However, data quality and consistency is not controlled in any way, and the
massiveness of the data poses a serious computational challenge. In this paper
we present t-GRASTA, or &quot;Transformed GRASTA (Grassmannian Robust Adaptive
Subspace Tracking Algorithm)&quot;. t-GRASTA iteratively performs incremental
gradient descent constrained to the Grassmann manifold of subspaces in order to
simultaneously estimate a decomposition of a collection of images into a
low-rank subspace, a sparse part of occlusions and foreground objects, and a
transformation such as rotation or translation of the image. We show that
t-GRASTA is 4 $\times$ faster than state-of-the-art algorithms, has half the
memory requirement, and can achieve alignment for face images as well as
jittered camera surveillance images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0406</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0406</id><created>2013-06-03</created><authors><author><keyname>Amir</keyname><forenames>Amihood</forenames></author><author><keyname>Franceschini</keyname><forenames>Gianni</forenames></author><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Kopelowitz</keyname><forenames>Tsvi</forenames></author><author><keyname>Lewenstein</keyname><forenames>Moshe</forenames></author><author><keyname>Lewenstein</keyname><forenames>Noa</forenames></author></authors><title>Managing Unbounded-Length Keys in Comparison-Driven Data Structures with
  Applications to On-Line Indexing</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a general technique for optimally transforming any
dynamic data structure that operates on atomic and indivisible keys by
constant-time comparisons, into a data structure that handles unbounded-length
keys whose comparison cost is not a constant. Examples of these keys are
strings, multi-dimensional points, multiple-precision numbers, multi-key data
(e.g.~records), XML paths, URL addresses, etc. The technique is more general
than what has been done in previous work as no particular exploitation of the
underlying structure of is required. The only requirement is that the insertion
of a key must identify its predecessor or its successor.
  Using the proposed technique, online suffix tree can be constructed in worst
case time $O(\log n)$ per input symbol (as opposed to amortized $O(\log n)$
time per symbol, achieved by previously known algorithms). To our knowledge,
our algorithm is the first that achieves $O(\log n)$ worst case time per input
symbol. Searching for a pattern of length $m$ in the resulting suffix tree
takes $O(\min(m\log |\Sigma|, m + \log n) + tocc)$ time, where $tocc$ is the
number of occurrences of the pattern. The paper also describes more
applications and show how to obtain alternative methods for dealing with suffix
sorting, dynamic lowest common ancestors and order maintenance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0424</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0424</id><created>2013-06-03</created><authors><author><keyname>Brahim</keyname><forenames>Abdelhamid Salah</forenames></author><author><keyname>Tabourier</keyname><forenames>Lionel</forenames></author><author><keyname>Grand</keyname><forenames>B&#xe9;n&#xe9;dicte Le</forenames></author></authors><title>A data-driven analysis to question epidemic models for citation cascades
  on the blogosphere</title><categories>cs.SI physics.soc-ph</categories><comments>18 pages, 9 figures, to be published in ICWSM-13 proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Citation cascades in blog networks are often considered as traces of
information spreading on this social medium. In this work, we question this
point of view using both a structural and semantic analysis of five months
activity of the most representative blogs of the french-speaking
community.Statistical measures reveal that our dataset shares many features
with those that can be found in the literature, suggesting the existence of an
identical underlying process. However, a closer analysis of the post content
indicates that the popular epidemic-like descriptions of cascades are
misleading in this context.A basic model, taking only into account the behavior
of bloggers and their restricted social network, accounts for several important
statistical features of the data.These arguments support the idea that
citations primary goal may not be information spreading on the blogosphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0428</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0428</id><created>2013-06-03</created><authors><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author></authors><title>Sharing a Reward Based on Peer Evaluations</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a problem where a group of agents has to decide how some fixed value
should be shared among them. We are interested in settings where the share that
each agent receives is based on how that agent is evaluated by other members of
the group, where highly regarded agents receive a greater share compared to
agents that are not well regarded. We introduce two mechanisms for determining
agents' shares: the peer-evaluation mechanism, where each agent gives a direct
evaluation for every other member of the group, and the peer-prediction
mechanism, where each agent is asked to report how they believe group members
will evaluate a particular agent. The sharing is based on the provided
information. While both mechanisms are individually rational, the first
mechanism is strategy-proof and budget-balanced, but it can be collusion-prone.
Further, the second mechanism is collusion-resistant and incentive-compatible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0431</identifier>
 <datestamp>2014-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0431</id><created>2013-06-03</created><updated>2014-07-09</updated><authors><author><keyname>Vera</keyname><forenames>Juan C.</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author><author><keyname>Yang</keyname><forenames>Linji</forenames></author></authors><title>Improved Bounds on the Phase Transition for the Hard-Core Model in
  2-Dimensions</title><categories>cs.DM math-ph math.MP math.PR</categories><comments>19 pages, 1 figure. Polished proofs and examples compared to earlier
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the hard-core lattice gas model defined on independent sets weighted by
an activity $\lambda$, we study the critical activity $\lambda_c(\mathbb{Z}^2)$
for the uniqueness/non-uniqueness threshold on the 2-dimensional integer
lattice $\mathbb{Z}^2$. The conjectured value of the critical activity is
approximately $3.796$. Until recently, the best lower bound followed from
algorithmic results of Weitz (2006). Weitz presented an FPTAS for approximating
the partition function for graphs of constant maximum degree $\Delta$ when
$\lambda&lt;\lambda_c(\mathbb{T}_\Delta)$ where $\mathbb{T}_\Delta$ is the
infinite, regular tree of degree $\Delta$. His result established a certain
decay of correlations property called strong spatial mixing (SSM) on
$\mathbb{Z}^2$ by proving that SSM holds on its self-avoiding walk tree
$T_{\mathrm{saw}}^\sigma(\mathbb{Z}^2)$ where $\sigma=(\sigma_v)_{v\in
\mathbb{Z}^2}$ and $\sigma_v$ is an ordering on the neighbors of vertex $v$. As
a consequence he obtained that $\lambda_c(\mathbb{Z}^2)\geq\lambda_c(
\mathbb{T}_4) = 1.675$. Restrepo et al. (2011) improved Weitz's approach for
the particular case of $\mathbb{Z}^2$ and obtained that
$\lambda_c(\mathbb{Z}^2)&gt;2.388$. In this paper, we establish an upper bound for
this approach, by showing that, for all $\sigma$, SSM does not hold on
$T_{\mathrm{saw}}^\sigma(\mathbb{Z}^2)$ when $\lambda&gt;3.4$. We also present a
refinement of the approach of Restrepo et al. which improves the lower bound to
$\lambda_c(\mathbb{Z}^2)&gt;2.48$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0441</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0441</id><created>2013-06-03</created><authors><author><keyname>Elgedawy</keyname><forenames>Islam</forenames></author></authors><title>DCaaS: Data Consistency as a Service for Managing Data Uncertainty on
  the Clouds</title><categories>cs.DC</categories><comments>10 pages, 6 figures, 2 tables</comments><msc-class>68Q85</msc-class><journal-ref>International Journal of Advanced Computer Science and
  Applications(IJACSA), paper 10, pages (59-68), Vol. 4, No.5, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring data correctness over partitioned distributed database systems is a
classical problem. Classical solutions proposed to solve this problem are
mainly adopting locking or blocking techniques. These techniques are not
suitable for cloud environments as they produce terrible response times; due to
the long latency and faultiness of wide area network connections among cloud
datacenters. One way to improve performance is to restrict access of
users-bases to specific datacenters and avoid data sharing between datacenters.
However, conflicts might appear when data is replicated between datacenters;
nevertheless change propagation timeliness is not guaranteed. Such problems
created data uncertainty on cloud environments. Managing data uncertainty is
one of the main obstacles for supporting global distributed transactions on the
clouds. To overcome this problem, this paper proposes an quota-based approach
for managing data uncertainty on the clouds that guarantees global data
correctness without global locking or blocking. To decouple service developers
from the hassles of managing data uncertainty, we propose to use a new platform
service (i.e. Data Consistency as a Service (DCaaS)) to encapsulate the
proposed approach. DCaaS service also ensures SaaS services cloud portability,
as it works as a cloud adapter between SaaS service instances. Experiments show
that proposed approach realized by the DCaaS service provides much better
response time when compared with classical locking and blocking techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0442</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0442</id><created>2013-06-03</created><authors><author><keyname>Kammarti</keyname><forenames>R.</forenames><affiliation>: LACS, Ecole Nationale des Ingenieurs de Tunis, Tunis - Belvedere. TUNISIE</affiliation></author><author><keyname>Ayachi</keyname><forenames>I.</forenames><affiliation>: LAGIS, Ecole Centrale de Lille, Villeneuve dAscq, France</affiliation></author><author><keyname>Ksouri</keyname><forenames>M.</forenames><affiliation>: LACS, Ecole Nationale des Ingenieurs de Tunis, Tunis - Belvedere. TUNISIE</affiliation></author><author><keyname>Borne</keyname><forenames>P.</forenames><affiliation>: LAGIS, Ecole Centrale de Lille, Villeneuve dAscq, France</affiliation></author></authors><title>Evolutionary Approach for the Containers Bin-Packing Problem</title><categories>cs.NE</categories><comments>9 pages</comments><journal-ref>Studies in Informatics and Control, Vol. 18, No. 4/2009, pages
  315-324</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper deals with the resolution of combinatorial optimization problems,
particularly those concerning the maritime transport scheduling. We are
interested in the management platforms in a river port and more specifically in
container organisation operations with a view to minimizing the number of
container rehandlings. Subsequently, we rmeet customers delivery deadlines and
we reduce ship stoppage time In this paper, we propose a genetic algorithm to
solve this problem and we present some experiments and results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0448</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0448</id><created>2013-06-03</created><authors><author><keyname>El-Haweet</keyname><forenames>W.</forenames></author><author><keyname>Elgedawy</keyname><forenames>Islam</forenames></author><author><keyname>El-Salam</keyname><forenames>Ibrahim Abd</forenames></author></authors><title>Adaptive Fixed Priority End-To-End Imprecise Scheduling In Distributed
  Real Time Systems</title><categories>cs.DC</categories><comments>8 pages, 6 tables, conference, In Proceedings of SPECTS 2001</comments><msc-class>68Q85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In end-to-end distributed real time systems, a task may be executed
sequentially on different processors. The end-toend task response time must not
exceed the end-to-end task deadline to consider the task a schedulable task. In
transient over load periods, deadlines may be missed or processors may
saturate. The imprecise computation technique is a way to overcome the
mentioned problems by trading off precision and timeliness. We developed an
imprecise integrated framework for scheduling fixed priority end-to-end tasks
in distributed real time systems by extending an existing integrated framework
for the same problem. We devised a new priority assignment scheme called global
mandatory relevance scheme to meet the concept of imprecise computation. We
devised an algorithm for processor utilization adjustment, this algorithm
decreases the processor load when the processor utilization is greater than
one. Also we extended the schedulability analysis algorithms presented in the
old framework to allow adaptive priority assignment and to meet imprecise
computation concept. Simulation results showed that our new framework is more
dependable and predictable than the existing framework over transient overload
periods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0453</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0453</id><created>2013-06-03</created><authors><author><keyname>Bougrine</keyname><forenames>Hassan</forenames></author></authors><title>Subfield Effects on the Core of Coauthors</title><categories>physics.soc-ph cs.DL</categories><comments>12 figures (can be combined); 37 references; 4 Tables; prepared for
  and submitted to Scientometrics</comments><journal-ref>Scientometrics 98 (2), 1047-1064 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is examined whether the number ($J$) of (joint) publications of a &quot;main
scientist&quot; with her/his coauthors ranked according to rank ($r$) importance,
i.e. $ J \propto 1/r $, as found by Ausloos [1] still holds for subfields, i.e.
when the &quot;main scientist&quot; has worked on different, sometimes overlapping,
subfields. Two cases are studied. It is shown that the law holds for large
subfields. As shown, in an Appendix, is also useful to combine small topics
into large ones for better statistics. It is observed that the sub-cores are
much smaller than the overall coauthor core measure. Nevertheless, the
smallness of the core and sub-cores may imply further considerations for the
evaluation of team research purposes and activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0478</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0478</id><created>2013-05-16</created><authors><author><keyname>Ibrahim</keyname><forenames>Mohamed</forenames></author><author><keyname>Saeed</keyname><forenames>Ahmed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Harras</keyname><forenames>Khaled A.</forenames></author></authors><title>Unconventional TV Detection using Mobile Devices</title><categories>cs.CY</categories><comments>4 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies show that the TV viewing experience is changing giving the
rise of trends like &quot;multi-screen viewing&quot; and &quot;connected viewers&quot;. These
trends describe TV viewers that use mobile devices (e.g. tablets and smart
phones) while watching TV. In this paper, we exploit the context information
available from the ubiquitous mobile devices to detect the presence of TVs and
track the media being viewed. Our approach leverages the array of sensors
available in modern mobile devices, e.g. cameras and microphones, to detect the
location of TV sets, their state (ON or OFF), and the channels they are
currently tuned to. We present the feasibility of the proposed sensing
technique using our implementation on Android phones with different realistic
scenarios. Our results show that in a controlled environment a detection
accuracy of 0.978 F-measure could be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0491</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0491</id><created>2013-05-31</created><authors><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Three-Dimensional Model of Residential Energy Consumer Archetypes for
  Local Energy Policy Design in the UK</title><categories>cs.CY</categories><comments>Energy Policy 47, 102-110, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews major studies in three traditional lines of research in
residential energy consumption in the UK, i.e. economic/infrastructure,
behaviour, and load profiling. Based on the review the paper proposes a
three-dimensional model for archetyping residential energy consumers in the UK
by considering property energy efficiency levels, the greenness of household
behaviour of using energy, and the duration of property daytime occupancy. With
the proposed model, eight archetypes of residential energy consumers in the UK
have been identified. They are: pioneer greens, follower greens, concerned
greens, home stayers, unconscientious wasters, regular wasters, daytime
wasters, and disengaged wasters. Using a case study, these archetypes of
residential energy consumers demonstrate the robustness of the 3-D model in
aiding local energy policy/intervention design in the UK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0493</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0493</id><created>2013-06-03</created><authors><author><keyname>Nicosia</keyname><forenames>Vincenzo</forenames></author><author><keyname>Tang</keyname><forenames>John</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author><author><keyname>Musolesi</keyname><forenames>Mirco</forenames></author><author><keyname>Russo</keyname><forenames>Giovanni</forenames></author><author><keyname>Latora</keyname><forenames>Vito</forenames></author></authors><title>Graph Metrics for Temporal Networks</title><categories>physics.soc-ph cs.SI</categories><comments>26 pages, 5 figures, Chapter in Temporal Networks (Petter Holme and
  Jari Saram\&quot;aki editors). Springer. Berlin, Heidelberg 2013</comments><doi>10.1007/978-3-642-36461-7_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal networks, i.e., networks in which the interactions among a set of
elementary units change over time, can be modelled in terms of time-varying
graphs, which are time-ordered sequences of graphs over a set of nodes. In such
graphs, the concepts of node adjacency and reachability crucially depend on the
exact temporal ordering of the links. Consequently, all the concepts and
metrics proposed and used for the characterisation of static complex networks
have to be redefined or appropriately extended to time-varying graphs, in order
to take into account the effects of time ordering on causality. In this chapter
we discuss how to represent temporal networks and we review the definitions of
walks, paths, connectedness and connected components valid for graphs in which
the links fluctuate over time. We then focus on temporal node-node distance,
and we discuss how to characterise link persistence and the temporal
small-world behaviour in this class of networks. Finally, we discuss the
extension of classic centrality measures, including closeness, betweenness and
spectral centrality, to the case of time-varying graphs, and we review the work
on temporal motifs analysis and the definition of modularity for temporal
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0497</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0497</id><created>2013-05-14</created><authors><author><keyname>Zirkind</keyname><forenames>Givon</forenames></author></authors><title>One Time Pad Password Protection: Using T.E.C. Steganography and Secure
  Password Transmission Protocols</title><categories>cs.CR</categories><comments>Draft for CAESER 2014 submission</comments><msc-class>94A60, 14G50</msc-class><acm-class>D.2.11; E.0; E.3; E.3; E.m; F.2.0; F.2.1; F.2.2; F.2.m; H.0; H.1.0;
  H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A while ago, I developed what I called an encryption method. The most
favorable of reviews did not see a method but a collection of techniques. Be
that as it may, the process used, is described in the paper, Windtalking
Computers. This paper is about the steganographic method described, the
cryptanalysis efforts of that method and; a real world application of that
method as an answer to the increasing problem of password file hacking. The
premise is that the technique is a variant of one time pad, using a novel way
to produce one time pad output for digital input. There is no record in the
literature of such a method being used for encryption at all. Digital
encryption generally treats the letters of the plaintext as a binary number and
does some mathematical computation to produce ciphertext. The idea of inserting
bits with a random generated key is new. Therefore (because a uniquely random
generated key is used), the encryption is cryptanalytically unbreakable and/or
computationally secure and/or information theoretic. An academic version was
made. Challenges for decryption have not produced to-date a decryption.
Advantages and disadvantages of the method are discussed.
  Hackers are constantly penetrating networks and stealing password files.
Which, once in possession of a password file, hackers individually or
collectively with distributed processing over the Internet, decrypt the values
of the hash passwords. Thereby gaining access to systems. This problem has
become sufficiently significant for CAESAR (Competition for Authenticated
Encryption: Security, Applicability, and Robustness) to make calls for papers
for solutions. Herein is one proposed solution. While one time pad presents a
problem being computationally intensive, for the relatively short length of
passwords, the cost of computation may be cost effective for the security
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0502</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0502</id><created>2013-06-03</created><updated>2014-01-22</updated><authors><author><keyname>Rico-Alvarino</keyname><forenames>Alberto</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Learning-Based Adaptive Transmission for Limited Feedback Multiuser
  MIMO-OFDM</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performing link adaptation in a multiantenna and multiuser system is
challenging because of the coupling between precoding, user selection, spatial
mode selection and use of limited feedback about the channel. The problem is
exacerbated by the difficulty of selecting the proper modulation and coding
scheme when using orthogonal frequency division multiplexing (OFDM). This paper
presents a data-driven approach to link adaptation for multiuser multiple input
mulitple output (MIMO) OFDM systems. A machine learning classifier is used to
select the modulation and coding scheme, taking as input the SNR values in the
different subcarriers and spatial streams. A new approximation is developed to
estimate the unknown interuser interference due to the use of limited feedback.
This approximation allows to obtain SNR information at the transmitter with a
minimum communication overhead. A greedy algorithm is used to perform spatial
mode and user selection with affordable complexity, without resorting to an
exhaustive search. The proposed adaptation is studied in the context of the
IEEE 802.11ac standard, and is shown to schedule users and adjust the
transmission parameters to the channel conditions as well as to the rate of the
feedback channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0514</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0514</id><created>2013-06-03</created><updated>2015-02-03</updated><authors><author><keyname>Ollivier</keyname><forenames>Yann</forenames></author></authors><title>Riemannian metrics for neural networks II: recurrent networks and
  learning symbolic data sequences</title><categories>cs.NE cs.LG</categories><comments>4th version: some changes in notation, more experiments</comments><msc-class>68T05, 68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks are powerful models for sequential data, able to
represent complex dependencies in the sequence that simpler models such as
hidden Markov models cannot handle. Yet they are notoriously hard to train.
Here we introduce a training procedure using a gradient ascent in a Riemannian
metric: this produces an algorithm independent from design choices such as the
encoding of parameters and unit activities. This metric gradient ascent is
designed to have an algorithmic cost close to backpropagation through time for
sparsely connected networks. We use this procedure on gated leaky neural
networks (GLNNs), a variant of recurrent neural networks with an architecture
inspired by finite automata and an evolution equation inspired by
continuous-time networks. GLNNs trained with a Riemannian gradient are
demonstrated to effectively capture a variety of structures in synthetic
problems: basic block nesting as in context-free grammars (an important feature
of natural languages, but difficult to learn), intersections of multiple
independent Markov-type relations, or long-distance relationships such as the
distant-XOR problem. This method does not require adjusting the network
structure or initial parameters: the network used is a sparse random graph and
the initialization is identical for all problems considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0519</identifier>
 <datestamp>2014-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0519</id><created>2013-06-03</created><updated>2014-05-27</updated><authors><author><keyname>De Domenico</keyname><forenames>M.</forenames></author><author><keyname>Sole</keyname><forenames>A.</forenames></author><author><keyname>Gomez</keyname><forenames>S.</forenames></author><author><keyname>Arenas</keyname><forenames>A.</forenames></author></authors><title>Random Walks on Multiplex Networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>10 pages, 8 figures, 5 tables, Supplementary material for the paper
  &quot;Navigability of interconnected networks under random failures&quot;
  (http://www.pnas.org/content/early/2014/05/21/1318469111.abstract)</comments><journal-ref>PNAS May 27, 2014</journal-ref><doi>10.1073/pnas.1318469111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiplex networks are receiving increasing interests because they allow to
model relationships between networked agents on several layers simultaneously.
In this supplementary material for the paper &quot;Navigability of interconnected
networks under random failures&quot;, we extend well-known random walks to
multiplexes and we introduce a new type of walk that can exist only in
multiplexes. We derive exact expressions for vertex occupation time and the
coverage. Finally, we show how the efficiency in exploring the multiplex
critically depends on the underlying topology of layers, the weight of their
inter-connections and the strategy adopted to walk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0524</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0524</id><created>2013-05-31</created><authors><author><keyname>Malinina</keyname><forenames>Natalia</forenames></author></authors><title>Special Partial Graphs</title><categories>cs.DM</categories><comments>15 pages, 20 figures</comments><msc-class>05C10, 05C15</msc-class><acm-class>F.2.2; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The attempts to prove the Four Color Problem last for long years. A little
hope arises that the properties of the minimal partial triangulations will be
very useful for the solution of the Four Color Problem. That is why the
material of this paper is devoted to the examination of the specific partial
graphs and their properties. Such graphs will have all the elements of the
planar triangulation, but will have the minimal size. And it will be quite
interesting to found out their properties in order to search in the sequel for
the possibility to prove the Four Color Problem on the base of their
characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0530</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0530</id><created>2013-06-03</created><authors><author><keyname>Minero</keyname><forenames>Paolo</forenames></author><author><keyname>Lim</keyname><forenames>Sung Hoon</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Hybrid Coding: An Interface for Joint Source-Channel Coding and Network
  Communication</title><categories>cs.IT math.IT</categories><comments>42 pages, 10 figures. Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach to joint source-channel coding is presented in the context of
communicating correlated sources over multiple access channels. Similar to the
separation architecture, the joint source-channel coding system architecture in
this approach is modular, whereby the source encoding and channel decoding
operations are decoupled. However, unlike the separation architecture, the same
codeword is used for both source coding and channel coding, which allows the
resulting hybrid coding scheme to achieve the performance of the best known
joint source-channel coding schemes. Applications of the proposed architecture
to relay communication are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0539</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0539</id><created>2013-06-03</created><authors><author><keyname>Scherrer</keyname><forenames>Bruno</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author></authors><title>On the Performance Bounds of some Policy Search Dynamic Programming
  Algorithms</title><categories>cs.AI cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the infinite-horizon discounted optimal control problem
formalized by Markov Decision Processes. We focus on Policy Search algorithms,
that compute an approximately optimal policy by following the standard Policy
Iteration (PI) scheme via an -approximate greedy operator (Kakade and Langford,
2002; Lazaric et al., 2010). We describe existing and a few new performance
bounds for Direct Policy Iteration (DPI) (Lagoudakis and Parr, 2003; Fern et
al., 2006; Lazaric et al., 2010) and Conservative Policy Iteration (CPI)
(Kakade and Langford, 2002). By paying a particular attention to the
concentrability constants involved in such guarantees, we notably argue that
the guarantee of CPI is much better than that of DPI, but this comes at the
cost of a relative--exponential in $\frac{1}{\epsilon}$-- increase of time
complexity. We then describe an algorithm, Non-Stationary Direct Policy
Iteration (NSDPI), that can either be seen as 1) a variation of Policy Search
by Dynamic Programming by Bagnell et al. (2003) to the infinite horizon
situation or 2) a simplified version of the Non-Stationary PI with growing
period of Scherrer and Lesner (2012). We provide an analysis of this algorithm,
that shows in particular that it enjoys the best of both worlds: its
performance guarantee is similar to that of CPI, but within a time complexity
similar to that of DPI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0541</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0541</id><created>2013-05-12</created><authors><author><keyname>Kartoun</keyname><forenames>Uri</forenames></author></authors><title>Identifying Pairs in Simulated Bio-Medical Time-Series</title><categories>cs.LG cs.CE</categories><comments>arXiv admin note: text overlap with arXiv:1303.0073</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a time-series-based classification approach to identify
similarities in pairs of simulated human-generated patterns. An example for a
pattern is a time-series representing a heart rate during a specific
time-range, wherein the time-series is a sequence of data points that represent
the changes in the heart rate values. A bio-medical simulator system was
developed to acquire a collection of 7,871 price patterns of financial
instruments. The financial instruments traded in real-time on three American
stock exchanges, NASDAQ, NYSE, and AMEX, simulate bio-medical measurements. The
system simulates a human in which each price pattern represents one bio-medical
sensor. Data provided during trading hours from the stock exchanges allowed
real-time classification. Classification is based on new machine learning
techniques: self-labeling, which allows the application of supervised learning
methods on unlabeled time-series and similarity ranking, which applied on a
decision tree learning algorithm to classify time-series regardless of type and
quantity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0543</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0543</id><created>2013-06-03</created><updated>2014-10-27</updated><authors><author><keyname>Denil</keyname><forenames>Misha</forenames></author><author><keyname>Shakibi</keyname><forenames>Babak</forenames></author><author><keyname>Dinh</keyname><forenames>Laurent</forenames></author><author><keyname>Ranzato</keyname><forenames>Marc'Aurelio</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Predicting Parameters in Deep Learning</title><categories>cs.LG cs.NE stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that there is significant redundancy in the parameterization
of several deep learning models. Given only a few weight values for each
feature it is possible to accurately predict the remaining values. Moreover, we
show that not only can the parameter values be predicted, but many of them need
not be learned at all. We train several different architectures by learning
only a small number of weights and predicting the rest. In the best case we are
able to predict more than 95% of the weights of a network without any drop in
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0549</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0549</id><created>2013-06-03</created><authors><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Kundu</keyname><forenames>Sandipan</forenames></author><author><keyname>Pados</keyname><forenames>Dimitris A.</forenames></author><author><keyname>Batalama</keyname><forenames>Stella N.</forenames></author></authors><title>Waveform Design for Secure SISO Transmissions and Multicasting</title><categories>cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless physical-layer security is an emerging field of research aiming at
preventing eavesdropping in an open wireless medium. In this paper, we propose
a novel waveform design approach to minimize the likelihood that a message
transmitted between trusted single-antenna nodes is intercepted by an
eavesdropper. In particular, with knowledge first of the eavesdropper's channel
state information (CSI), we find the optimum waveform and transmit energy that
minimize the signal-to-interference-plus-noise ratio (SINR) at the output of
the eavesdropper's maximum-SINR linear filter, while at the same time provide
the intended receiver with a required pre-specified SINR at the output of its
own max-SINR filter. Next, if prior knowledge of the eavesdropper's CSI is
unavailable, we design a waveform that maximizes the amount of energy available
for generating disturbance to eavesdroppers, termed artificial noise (AN),
while the SINR of the intended receiver is maintained at the pre-specified
level. The extensions of the secure waveform design problem to multiple
intended receivers are also investigated and semidefinite relaxation (SDR) -an
approximation technique based on convex optimization- is utilized to solve the
arising NP-hard design problems. Extensive simulation studies confirm our
analytical performance predictions and illustrate the benefits of the designed
waveforms on securing single-input single-output (SISO) transmissions and
multicasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0555</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0555</id><created>2013-06-03</created><updated>2013-06-16</updated><authors><author><keyname>Etemaadi</keyname><forenames>Ramin</forenames></author><author><keyname>Lind</keyname><forenames>Kenneth</forenames></author><author><keyname>Heldal</keyname><forenames>Rogardt</forenames></author><author><keyname>Chaudron</keyname><forenames>Michel R. V.</forenames></author></authors><title>Details of an Automotive Sub-System: Saab Instrument Cluster Module</title><categories>cs.SE</categories><comments>This paper has been withdrawn by the author due to an IP issue</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this technical report is to give the details of a real world
existing sub-system in the automotive industry. It is produced to be used for
reproduction of the same experiment if other researchers are interested in.
Hence, it would be possible to compare the results of our published studies
with the results of similar tools. The data is collected for the purpose of
applying metaheuristic optimization approaches. The case study based on these
data shows that metaheuristic optimization approaches can find efficient
solutions for multiple quality attributes while fulfilling given constraints.
  The case study was conducted at Saab Automobile AB in order to evaluate the
AQOSA framework in an industrial context. AQOSA (Automated Quality-driven
Optimization of Software Architecture) is our architecture optimization
framework that supports multiple quality attributes including response time,
processor utilization, bus utilization, safety and cost.
  To enable validation of the results we selected an existing realization for
the Saab 9-5 Instrument Cluster Module ECU (Electronic Control Unit) and the
surrounding sub-systems. The goal of the case study is to find a better
solution than the current realization while fulfilling the requirements and
constraints. The results of the case study and the details of AQOSA framework
is reported in a paper from the authors in Journal of Systems and Software,
Special Issue on Quality Optimization of Software Architecture and Design
Specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0573</identifier>
 <datestamp>2013-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0573</id><created>2013-06-03</created><authors><author><keyname>Singh</keyname><forenames>Navtej</forenames></author><author><keyname>Browne</keyname><forenames>Lisa-Marie</forenames></author><author><keyname>Butler</keyname><forenames>Ray</forenames></author></authors><title>Parallel Astronomical Data Processing with Python: Recipes for multicore
  machines</title><categories>astro-ph.IM cs.DC</categories><comments>15 pages, 7 figures, 1 table, &quot;for associated test code, see
  http://astro.nuigalway.ie/staff/navtejs&quot;, Accepted for publication in
  Astronomy and Computing</comments><doi>10.1016/j.ascom.2013.04.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High performance computing has been used in various fields of astrophysical
research. But most of it is implemented on massively parallel systems
(supercomputers) or graphical processing unit clusters. With the advent of
multicore processors in the last decade, many serial software codes have been
re-implemented in parallel mode to utilize the full potential of these
processors. In this paper, we propose parallel processing recipes for multicore
machines for astronomical data processing. The target audience are astronomers
who are using Python as their preferred scripting language and who may be using
PyRAF/IRAF for data processing. Three problems of varied complexity were
benchmarked on three different types of multicore processors to demonstrate the
benefits, in terms of execution time, of parallelizing data processing tasks.
The native multiprocessing module available in Python makes it a relatively
trivial task to implement the parallel code. We have also compared the three
multiprocessing approaches - Pool/Map, Process/Queue, and Parallel Python. Our
test codes are freely available and can be downloaded from our website.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0585</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0585</id><created>2013-06-03</created><authors><author><keyname>Li</keyname><forenames>Jing</forenames></author><author><keyname>Xie</keyname><forenames>Kai</forenames></author></authors><title>Iterative Decoding and Turbo Equalization: The Z-Crease Phenomenon</title><categories>cs.IT math.IT nlin.CD</categories><comments>6 pages</comments><journal-ref>46th Annual Conference on Information Sciences and Systems (CISS),
  Princeton, NJ, March 2012</journal-ref><doi>10.1063/1.4756059</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative probabilistic inference, popularly dubbed the soft-iterative
paradigm, has found great use in a wide range of communication applications,
including turbo decoding and turbo equalization. The classic approach of
analyzing the iterative approach inevitably use the statistical and
information-theoretical tools that bear ensemble-average flavors. This paper
consider the per-block error rate performance, and analyzes it using nonlinear
dynamical theory. By modeling the iterative processor as a nonlinear dynamical
system, we report a universal &quot;Z-crease phenomenon:&quot; the zig-zag or up-and-down
fluctuation -- rather than the monotonic decrease -- of the per-block errors,
as the number of iteration increases. Using the turbo decoder as an example, we
also report several interesting motion phenomenons which were not previously
reported, and which appear to correspond well with the notion of &quot;pseudo
codewords&quot; and &quot;stopping/trapping sets.&quot; We further propose a heuristic
stopping criterion to control Z-crease and identify the best iteration. Our
stopping criterion is most useful for controlling the worst-case per-block
errors, and helps to significantly reduce the average-iteration numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0587</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0587</id><created>2013-06-03</created><authors><author><keyname>Li</keyname><forenames>Jing</forenames></author><author><keyname>Xie</keyname><forenames>Kai</forenames></author></authors><title>Analog Turbo Codes: Turning Chaos to Reliability</title><categories>cs.IT math.IT</categories><comments>46th Annual Conference on Computer Sciences and Information Systems
  (CISS 2012), 2012, 5 pages, 5 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog error correction codes, by relaxing the source space and the codeword
space from discrete fields to continuous fields, present a generalization of
digital codes. While linear codes are sufficient for digital codes, they are
not for analog codes, and hence nonlinear mappings must be employed to fully
harness the power of analog codes. This paper demonstrates new ways of building
effective (nonlinear) analog codes from a special class of nonlinear,
fast-diverging functions known as the chaotic functions. It is shown that the
&quot;butterfly effect&quot; of the chaotic functions matches elegantly with the distance
expansion condition required for error correction, and that the useful idea in
digital turbo codes can be exploited to construct efficient turbo-like chaotic
analog codes. Simulations show that the new analog codes can perform on par
with, or better than, their digital counter-parts when transmitting analog
sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0604</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0604</id><created>2013-06-03</created><updated>2013-10-30</updated><authors><author><keyname>Balcan</keyname><forenames>Maria Florina</forenames></author><author><keyname>Ehrlich</keyname><forenames>Steven</forenames></author><author><keyname>Liang</keyname><forenames>Yingyu</forenames></author></authors><title>Distributed k-Means and k-Median Clustering on General Topologies</title><categories>cs.LG cs.DC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides new algorithms for distributed clustering for two popular
center-based objectives, k-median and k-means. These algorithms have provable
guarantees and improve communication complexity over existing approaches.
Following a classic approach in clustering by \cite{har2004coresets}, we reduce
the problem of finding a clustering with low cost to the problem of finding a
coreset of small size. We provide a distributed method for constructing a
global coreset which improves over the previous methods by reducing the
communication complexity, and which works over general communication
topologies. Experimental results on large scale data sets show that this
approach outperforms other coreset-based distributed clustering algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0615</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0615</id><created>2013-06-03</created><authors><author><keyname>Lewenstein</keyname><forenames>Moshe</forenames></author></authors><title>Orthogonal Range Searching for Text Indexing</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text indexing, the problem in which one desires to preprocess a (usually
large) text for future (shorter) queries, has been researched ever since the
su?ffix tree was invented in the early 70's. With textual data continuing to
increase and with changes in the way it is accessed, new data structures and
new algorithmic methods are continuously required. Therefore, text indexing is
of utmost importance and is a very active research domain.
  Orthogonal range searching, classically associated with the computational
geometry community, is one of the tools that has increasingly become important
for various text indexing applications. Initially, in the mid 90's there were a
couple of results recognizing this connection. In the last few years we have
seen an increase in use of this method and are reaching a deeper understanding
of the range searching uses for text indexing.
  In this monograph we survey some of these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0618</identifier>
 <datestamp>2014-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0618</id><created>2013-06-03</created><updated>2014-02-12</updated><authors><author><keyname>Kapelner</keyname><forenames>Adam</forenames></author><author><keyname>Bleich</keyname><forenames>Justin</forenames></author></authors><title>Prediction with Missing Data via Bayesian Additive Regression Trees</title><categories>stat.ML cs.LG</categories><comments>18 pages, 3 figures, 2 tables, 1 algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for incorporating missing data in non-parametric
statistical learning without the need for imputation. We focus on a tree-based
method, Bayesian Additive Regression Trees (BART), enhanced with &quot;Missingness
Incorporated in Attributes,&quot; an approach recently proposed incorporating
missingness into decision trees (Twala, 2008). This procedure takes advantage
of the partitioning mechanisms found in tree-based models. Simulations on
generated models and real data indicate that our proposed method can forecast
well on complicated missing-at-random and not-missing-at-random models as well
as models where missingness itself influences the response. Our procedure has
higher predictive performance and is more stable than competitors in many
cases. We also illustrate BART's abilities to incorporate missingness into
uncertainty intervals and to detect the influence of missingness on the model
fit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0626</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0626</id><created>2013-06-03</created><authors><author><keyname>Jain</keyname><forenames>Prateek</forenames></author><author><keyname>Dhillon</keyname><forenames>Inderjit S.</forenames></author></authors><title>Provable Inductive Matrix Completion</title><categories>cs.LG cs.IT math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a movie recommendation system where apart from the ratings
information, side information such as user's age or movie's genre is also
available. Unlike standard matrix completion, in this setting one should be
able to predict inductively on new users/movies. In this paper, we study the
problem of inductive matrix completion in the exact recovery setting. That is,
we assume that the ratings matrix is generated by applying feature vectors to a
low-rank matrix and the goal is to recover back the underlying matrix.
Furthermore, we generalize the problem to that of low-rank matrix estimation
using rank-1 measurements. We study this generic problem and provide conditions
that the set of measurements should satisfy so that the alternating
minimization method (which otherwise is a non-convex method with no convergence
guarantees) is able to recover back the {\em exact} underlying low-rank matrix.
  In addition to inductive matrix completion, we show that two other low-rank
estimation problems can be studied in our framework: a) general low-rank matrix
sensing using rank-1 measurements, and b) multi-label regression with missing
labels. For both the problems, we provide novel and interesting bounds on the
number of measurements required by alternating minimization to provably
converges to the {\em exact} low-rank matrix. In particular, our analysis for
the general low rank matrix sensing problem significantly improves the required
storage and computational cost than that required by the RIP-based matrix
sensing methods \cite{RechtFP2007}. Finally, we provide empirical validation of
our approach and demonstrate that alternating minimization is able to recover
the true matrix for the above mentioned problems using a small number of
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0627</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0627</id><created>2013-06-03</created><authors><author><keyname>Gerlach</keyname><forenames>Enrico</forenames></author><author><keyname>Eggl</keyname><forenames>Siegfried</forenames></author><author><keyname>Skokos</keyname><forenames>Charalampos</forenames></author><author><keyname>Bodyfelt</keyname><forenames>Joshua D.</forenames></author><author><keyname>Papamikos</keyname><forenames>Georgios</forenames></author></authors><title>High Order Three Part Split Symplectic Integration Schemes</title><categories>nlin.CD cs.NA physics.comp-ph</categories><comments>Submitted for conference proceedings to the 10th HSTAM International
  Congress on Mechanics (http://www.10hstam.tuc.gr/)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symplectic integration methods based on operator splitting are well
established in many branches of science. For Hamiltonian systems which split in
more than two parts, symplectic methods of higher order have been studied in
detail only for a few special cases. In this work, we present and compare
different ways to construct high order symplectic schemes for general
Hamiltonian systems that can be split in three integrable parts. We use these
techniques to numerically solve the equations of motion for a simple toy model,
as well as the disordered discrete nonlinear Schr\&quot;odinger equation. We thereby
compare the efficiency of symplectic and non-symplectic integration methods.
Our results show that the new symplectic schemes are superior to the other
tested methods, with respect to both long term energy conservation and
computational time requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0630</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0630</id><created>2013-06-03</created><authors><author><keyname>Gilmer</keyname><forenames>Justin</forenames></author><author><keyname>Saks</keyname><forenames>Michael</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>Composition limits and separating examples for some Boolean function
  complexity measures</title><categories>cs.CC</categories><comments>Appearing in CCC 2013, 36 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block sensitivity ($bs(f)$), certificate complexity ($C(f)$) and fractional
certificate complexity ($C^*(f)$) are three fundamental combinatorial measures
of complexity of a boolean function $f$. It has long been known that $bs(f)
\leq C^{\ast}(f) \leq C(f) =O(bs(f)^2)$. We provide an infinite family of
examples for which $C(f)$ grows quadratically in $C^{\ast}(f)$ (and also
$bs(f)$) giving optimal separations between these measures. Previously the
biggest separation known was $C(f)=C^{\ast}(f)^{\log_{4.5}5}$. We also give a
family of examples for which $C^{\ast}(f)=\Omega(bs(f)^{3/2})$.
  These examples are obtained by composing boolean functions in various ways.
Here the composition $f \circ g$ of $f$ with $g$ is obtained by substituting
for each variable of $f$ a copy of $g$ on disjoint sets of variables. To
construct and analyse these examples we systematically investigate the
behaviour under function composition of these measures and also the sensitivity
measure $s(f)$. The measures $s(f)$, $C(f)$ and $C^{\ast}(f)$ behave nicely
under composition: they are submultiplicative (where measure $m$ is
submultiplicative if $m(f \circ g) \leq m(f)m(g)$) with equality holding under
some fairly general conditions. The measure $bs(f)$ is qualitatively different:
it is not submultiplicative. This qualitative difference was not noticed in the
previous literature and we correct some errors that appeared in previous
papers. We define the composition limit of a measure $m$ at function $f$,
$m^{\lim}(f)$ to be the limit as $k$ grows of $m(f^{(k)})^{1/k}$, where
$f^{(k)}$ is the iterated composition of $f$ with itself $k$-times. For any
function $f$ we show that $bs^{\lim}(f) = (C^*)^{\lim}(f)$ and characterize
$s^{\lim}(f), (C^*)^{\lim}(f)$, and $C^{\lim}(f)$ in terms of the largest
eigenvalue of a certain set of $2\times 2$ matrices associated with $f$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0646</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0646</id><created>2013-06-03</created><authors><author><keyname>Bhattacherjee</keyname><forenames>Biplab</forenames></author><author><keyname>Manna</keyname><forenames>S. S.</forenames></author><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author></authors><title>Information sharing and sorting in a community</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>6 pages, 7 figures</comments><doi>10.1103/PhysRevE.87.062808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the results of detailed numerical study of a model for the sharing
and sorting of informations in a community consisting of a large number of
agents. The information gathering takes place in a sequence of mutual bipartite
interactions where randomly selected pairs of agents communicate with each
other to enhance their knowledge and sort out the common information. Though
our model is less restricted compared to the well established naming game, yet
the numerical results strongly indicate that the whole set of exponents
characterizing this model are different from those of the naming game and they
assume non-trivial values. Finally it appears that in analogy to the emergence
of clusters in the phenomenon of percolation, one can define clusters of agents
here having the same information. We have studied in detail the growth of the
largest cluster in this article and performed its finite-size scaling analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0649</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0649</id><created>2013-06-04</created><authors><author><keyname>Hatami</keyname><forenames>Hamed</forenames></author><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>Estimating the distance from testable affine-invariant properties</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\cal{P}$ be an affine invariant property of functions $\mathbb{F}_p^n
\to [R]$ for fixed $p$ and $R$. We show that if $\cal{P}$ is locally testable
with a constant number of queries, then one can estimate the distance of a
function $f$ from $\cal{P}$ with a constant number of queries. This was
previously unknown even for simple properties such as cubic polynomials over
$\mathbb{F}_2$.
  Our test is simple: take a restriction of $f$ to a constant dimensional
affine subspace, and measure its distance from $\cal{P}$. We show that by
choosing the dimension large enough, this approximates with high probability
the global distance of $f$ from $\cP$. The analysis combines the approach of
Fischer and Newman [SIAM J. Comp 2007] who established a similar result for
graph properties, with recently developed tools in higher order Fourier
analysis, in particular those developed in Bhattacharyya et al. [STOC 2013].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0662</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0662</id><created>2013-06-04</created><authors><author><keyname>Cassez</keyname><forenames>Franck</forenames></author><author><keyname>Grastien</keyname><forenames>Alban</forenames></author></authors><title>Predictability of Event Occurrences in Timed Systems</title><categories>cs.SY cs.FL cs.LO math.OC</categories><comments>Extended version of FORMATS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of predicting events' occurrences in partially
observable timed systems modelled by timed automata. Our contribution is
many-fold: 1) we give a definition of bounded predictability, namely
k-predictability, that takes into account the minimum delay between the
prediction and the actual event's occurrence; 2) we show that 0-predictability
is equivalent to the original notion of predictability of S. Genc and S.
Lafortune; 3) we provide a necessary and sufficient condition for
k-predictability (which is very similar to k-diagnosability) and give a simple
algorithm to check k-predictability; 4) we address the problem of
predictability of events' occurrences in timed automata and show that the
problem is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0665</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0665</id><created>2013-06-04</created><authors><author><keyname>Eppe</keyname><forenames>Manfred</forenames></author><author><keyname>Bhatt</keyname><forenames>Mehul</forenames></author></authors><title>Narrative based Postdictive Reasoning for Cognitive Robotics</title><categories>cs.AI cs.RO</categories><comments>Commonsense Reasoning Symposium, Ayia Napa, Cyprus, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Making sense of incomplete and conflicting narrative knowledge in the
presence of abnormalities, unobservable processes, and other real world
considerations is a challenge and crucial requirement for cognitive robotics
systems. An added challenge, even when suitably specialised action languages
and reasoning systems exist, is practical integration and application within
large-scale robot control frameworks.
  In the backdrop of an autonomous wheelchair robot control task, we report on
application-driven work to realise postdiction triggered abnormality detection
and re-planning for real-time robot control: (a) Narrative-based knowledge
about the environment is obtained via a larger smart environment framework; and
(b) abnormalities are postdicted from stable-models of an answer-set program
corresponding to the robot's epistemic model. The overall reasoning is
performed in the context of an approximate epistemic action theory based
planner implemented via a translation to answer-set programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0682</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0682</id><created>2013-06-04</created><updated>2013-09-06</updated><authors><author><keyname>Leng</keyname><forenames>Mei</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author><author><keyname>See</keyname><forenames>Chong Meng Samson</forenames></author><author><keyname>Razul</keyname><forenames>Sirajudeen Gulam</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Modified CRB for Location and Velocity Estimation using Signals of
  Opportunity</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of localizing two sensors using signals of
opportunity from beacons with known positions. Beacons and sensors have
asynchronous local clocks or oscillators with unknown clock skews and offsets.
We model clock skews as random, and analyze the biases introduced by clock
asynchronism in the received signals. By deriving the equivalent Fisher
information matrix for the modified Bayesian Cram\'er-Rao lower bound (CRLB) of
sensor position and velocity estimation, we quantify the errors caused by clock
asynchronism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0686</identifier>
 <datestamp>2015-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0686</id><created>2013-06-04</created><updated>2013-06-04</updated><authors><author><keyname>Joulani</keyname><forenames>Pooria</forenames></author><author><keyname>Gy&#xf6;rgy</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Szepesv&#xe1;ri</keyname><forenames>Csaba</forenames></author></authors><title>Online Learning under Delayed Feedback</title><categories>cs.LG cs.AI stat.ML</categories><comments>Extended version of a paper accepted to ICML-2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online learning with delayed feedback has received increasing attention
recently due to its several applications in distributed, web-based learning
problems. In this paper we provide a systematic study of the topic, and analyze
the effect of delay on the regret of online learning algorithms. Somewhat
surprisingly, it turns out that delay increases the regret in a multiplicative
way in adversarial problems, and in an additive way in stochastic problems. We
give meta-algorithms that transform, in a black-box fashion, algorithms
developed for the non-delayed case into ones that can handle the presence of
delays in the feedback loop. Modifications of the well-known UCB algorithm are
also developed for the bandit problem with delayed feedback, with the advantage
over the meta-algorithms that they can be implemented with lower complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0694</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0694</id><created>2013-06-04</created><authors><author><keyname>Ye</keyname><forenames>Tao</forenames></author><author><keyname>Huang</keyname><forenames>Wenqi</forenames></author><author><keyname>Lu</keyname><forenames>Zhipeng</forenames></author></authors><title>Iterated Tabu Search Algorithm for Packing Unequal Circles in a Circle</title><categories>math.OC cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an Iterated Tabu Search algorithm (denoted by ITS-PUCC)
for solving the problem of Packing Unequal Circles in a Circle. The algorithm
exploits the continuous and combinatorial nature of the unequal circles packing
problem. It uses a continuous local optimization method to generate locally
optimal packings. Meanwhile, it builds a neighborhood structure on the set of
local minimum via two appropriate perturbation moves and integrates two
combinatorial optimization methods, Tabu Search and Iterated Local Search, to
systematically search for good local minima. Computational experiments on two
sets of widely-used test instances prove its effectiveness and efficiency. For
the first set of 46 instances coming from the famous circle packing contest and
the second set of 24 instances widely used in the literature, the algorithm is
able to discover respectively 14 and 16 better solutions than the previous
best-known records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0706</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0706</id><created>2013-06-04</created><authors><author><keyname>Ray</keyname><forenames>Nicolas</forenames></author><author><keyname>Sokolov</keyname><forenames>Dmitry</forenames></author></authors><title>Tracing cross-free polylines oriented by a N-symmetry direction field on
  triangulated surfaces</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm for tracing polylines on a triangle mesh such that:
they are aligned with a N-symmetry direction field, and two such polylines
cannot cross or merge. This property is fundamental for mesh segmentation and
is very difficult to enforce with numerical integration of vector fields. We
propose an alternative solution based on &quot;stream-mesh&quot;, a new combinatorial
data structure that defines, for each point of a triangle edge, where the
corresponding polyline leaves the triangle. It makes it possible to trace
polylines by iteratively crossing triangles. Vector field singularities and
polyline/vertex crossing are characterized and consistently handled. The
polylines inherits the cross-free property of the stream-mesh, except inside
triangles where avoiding local overlaps would require higher order polycurves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0710</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0710</id><created>2013-06-04</created><authors><author><keyname>Liu</keyname><forenames>Xiaogang</forenames></author><author><keyname>Luo</keyname><forenames>Yuan</forenames></author><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author></authors><title>On the Optimum Cyclic Subcode Chains of $\mathcal{RM}(2,m)^*$ for
  Increasing Message Length</title><categories>cs.IT math.IT</categories><comments>10pages, 2 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The distance profiles of linear block codes can be employed to design
variational coding scheme for encoding message with variational length and
getting lower decoding error probability by large minimum Hamming distance. %,
e.g. the design of TFCI in CDMA and the researches on the second-order
Reed-Muller code $\mathcal{RM}(2,m)$, etc.
  Considering convenience for encoding, we focus on the distance profiles with
respect to cyclic subcode chains (DPCs) of cyclic codes over $GF(q)$ with
length $n$ such that $\mbox{gcd}(n,q) = 1$. In this paper the optimum DPCs and
the corresponding optimum cyclic subcode chains are investigated on the
punctured second-order Reed-Muller code $\mathcal{RM}(2,m)^*$ for increasing
message length, where two standards on the optimums are studied according to
the rhythm of increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0712</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0712</id><created>2013-06-04</created><authors><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Resource Allocation for Secure Communication in Systems with Wireless
  Information and Power Transfer</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures, and 1 table. Submitted for possible conference
  publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers secure communication in a multiuser multiple-input
single-output (MISO) downlink system with simultaneous wireless information and
power transfer. We study the design of resource allocation algorithms
minimizing the total transmit power for the case when the receivers are able to
harvest energy from the radio frequency. In particular, the algorithm design is
formulated as a non-convex optimization problem which takes into account
artificial noise generation to combat potential eavesdroppers, a minimum
required signal-to-interference-plus-noise ratio (SINR) at the desired
receiver, maximum tolerable SINRs at the potential eavesdroppers, and a minimum
required power delivered to the receivers. We adopt a semidefinite programming
(SDP) relaxation approach to obtain an upper bound solution for the considered
problem. The tightness of the upper bound is revealed by examining a sufficient
condition for the global optimal solution. Inspired by the sufficient
condition, we propose two suboptimal resource allocation schemes enhancing
secure communication and facilitating efficient energy harvesting. Simulation
results demonstrate a close-to-optimal performance achieved by the proposed
suboptimal schemes and significant transmit power savings by optimization of
the artificial noise generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0715</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0715</id><created>2013-06-04</created><authors><author><keyname>Hoffmann</keyname><forenames>Till</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author></authors><title>Random Walks on Stochastic Temporal Networks</title><categories>physics.soc-ph cs.SI</categories><comments>Chapter in Temporal Networks (Petter Holme and Jari Saramaki
  editors). Springer. Berlin, Heidelberg 2013. The book chapter contains minor
  corrections and modifications. This chapter is based on arXiv:1112.3324,
  which contains additional calculations and numerical simulations</comments><doi>10.1007/978-3-642-36461-7_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the study of dynamical processes on networks, there has been intense focus
on network structure -- i.e., the arrangement of edges and their associated
weights -- but the effects of the temporal patterns of edges remains poorly
understood. In this chapter, we develop a mathematical framework for random
walks on temporal networks using an approach that provides a compromise between
abstract but unrealistic models and data-driven but non-mathematical
approaches. To do this, we introduce a stochastic model for temporal networks
in which we summarize the temporal and structural organization of a system
using a matrix of waiting-time distributions. We show that random walks on
stochastic temporal networks can be described exactly by an
integro-differential master equation and derive an analytical expression for
its asymptotic steady state. We also discuss how our work might be useful to
help build centrality measures for temporal networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0727</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0727</id><created>2013-06-04</created><authors><author><keyname>Ebrahim</keyname><forenames>Nader Ale</forenames></author><author><keyname>Farhadi</keyname><forenames>Hadi</forenames></author><author><keyname>Salehi</keyname><forenames>Hadi</forenames></author><author><keyname>Yunus</keyname><forenames>Melor Md</forenames></author><author><keyname>Chadegani</keyname><forenames>Arezoo Aghaei</forenames></author><author><keyname>Farhadi</keyname><forenames>Maryam</forenames></author><author><keyname>Fooladi</keyname><forenames>Masood</forenames></author></authors><title>Does it Matter Which Citation Tool is Used to Compare the h-index of a
  Group of Highly Cited Researchers?</title><categories>cs.DL physics.soc-ph</categories><comments>5 pages, 5 figures and 2 tables</comments><msc-class>97B10</msc-class><acm-class>H.2.2</acm-class><journal-ref>Australian Journal of Basic and Applied Sciences, 7(4), 198-202.
  March 2013</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  h-index retrieved by citation indexes (Scopus, Google scholar, and Web of
Science) is used to measure the scientific performance and the research impact
studies based on the number of publications and citations of a scientist. It
also is easily available and may be used for performance measures of
scientists, and for recruitment decisions. The aim of this study is to
investigate the difference between the outputs and results from these three
citation databases namely Scopus, Google Scholar, and Web of Science based upon
the h-index of a group of highly cited researchers (Nobel Prize winner
scientist). The purposive sampling method was adopted to collect the required
data. The results showed that there is a significant difference in the h-index
between three citation indexes of Scopus, Google scholar, and Web of Science;
the Google scholar h-index was more than the h-index in two other databases. It
was also concluded that there is a significant positive relationship between
h-indices based on Google scholar and Scopus. The citation indexes of Scopus,
Google scholar, and Web of Science may be useful for evaluating h-index of
scientists but they have some limitations as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0729</identifier>
 <datestamp>2015-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0729</id><created>2013-06-04</created><updated>2015-04-15</updated><authors><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Jungers</keyname><forenames>Raphael M.</forenames></author><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author></authors><title>On Primitivity of Sets of Matrices</title><categories>math.CO cs.CC math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonnegative matrix $A$ is called primitive if $A^k$ is positive for some
integer $k&gt;0$. A generalization of this concept to finite sets of matrices is
as follows: a set of matrices $\mathcal M = \{A_1, A_2, \ldots, A_m \}$ is
primitive if $A_{i_1} A_{i_2} \ldots A_{i_k}$ is positive for some indices
$i_1, i_2, ..., i_k$. The concept of primitive sets of matrices comes up in a
number of problems within the study of discrete-time switched systems. In this
paper, we analyze the computational complexity of deciding if a given set of
matrices is primitive and we derive bounds on the length of the shortest
positive product.
  We show that while primitivity is algorithmically decidable, unless $P=NP$ it
is not possible to decide primitivity of a matrix set in polynomial time.
Moreover, we show that the length of the shortest positive sequence can be
superpolynomial in the dimension of the matrices. On the other hand, defining
${\mathcal P}$ to be the set of matrices with no zero rows or columns, we give
a simple combinatorial proof of a previously-known characterization of
primitivity for matrices in ${\mathcal P}$ which can be tested in polynomial
time. This latter observation is related to the well-known 1964 conjecture of
Cerny on synchronizing automata; in fact, any bound on the minimal length of a
synchronizing word for synchronizing automata immediately translates into a
bound on the length of the shortest positive product of a primitive set of
matrices in ${\mathcal P}$. In particular, any primitive set of $n \times n$
matrices in ${\mathcal P}$ has a positive product of length $O(n^3)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0733</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0733</id><created>2013-06-04</created><authors><author><keyname>Kingma</keyname><forenames>Diederik P</forenames></author></authors><title>Fast Gradient-Based Inference with Continuous Latent Variable Models in
  Auxiliary Form</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a technique for increasing the efficiency of gradient-based
inference and learning in Bayesian networks with multiple layers of continuous
latent vari- ables. We show that, in many cases, it is possible to express such
models in an auxiliary form, where continuous latent variables are
conditionally deterministic given their parents and a set of independent
auxiliary variables. Variables of mod- els in this auxiliary form have much
larger Markov blankets, leading to significant speedups in gradient-based
inference, e.g. rapid mixing Hybrid Monte Carlo and efficient gradient-based
optimization. The relative efficiency is confirmed in ex- periments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0741</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0741</id><created>2013-06-04</created><authors><author><keyname>Bene&#x161;</keyname><forenames>Nikola</forenames></author><author><keyname>Delahaye</keyname><forenames>Beno&#xee;t</forenames></author><author><keyname>Fahrenberg</keyname><forenames>Uli</forenames></author><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author><author><keyname>Legay</keyname><forenames>Axel</forenames></author></authors><title>Hennessy-Milner Logic with Greatest Fixed Points as a Complete
  Behavioural Specification Theory</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two fundamentally different approaches to specifying and verifying
properties of systems. The logical approach makes use of specifications given
as formulae of temporal or modal logics and relies on efficient model checking
algorithms; the behavioural approach exploits various equivalence or refinement
checking methods, provided the specifications are given in the same formalism
as implementations.
  In this paper we provide translations between the logical formalism of
Hennessy-Milner logic with greatest fixed points and the behavioural formalism
of disjunctive modal transition systems. We also introduce a new operation of
quotient for the above equivalent formalisms, which is adjoint to structural
composition and allows synthesis of missing specifications from partial
implementations. This is a substantial generalisation of the quotient for
deterministic modal transition systems defined in earlier papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0750</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0750</id><created>2013-06-04</created><authors><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Ali</keyname><forenames>L.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author></authors><title>Evaluating Wireless Proactive Routing Protocols under Mobility and
  Scalability Constraints</title><categories>cs.NI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1304.0154</comments><journal-ref>J. Basic. Appl. Sci. Res., 3(1)1187-12001, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Multi-hop Networks (WMhNs) provide users with the facility to
communicate while moving with whatever the node speed, the node density and the
number of traffic flows they want, without any unwanted delay and/or
disruption. This paper contributes Linear Programming models (LP_models) for
WMhNs. In WMhNs, different routing protocols are used to facilitate users
demand(s). To practically examine the constraints of respective LP_models over
different routing techniques, we select three proactive routing protocols;
Destination Sequence Distance Vector (DSDV), Fish-eye State Routing (FSR) and
Optimized Link State Routing (OLSR). These protocols are simulated in two
important scenarios regarding to user demands; mobilities and different network
flows. To evaluate the performance, we further relate the protocols strategy
effects on respective constraints in selected network scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0751</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0751</id><created>2013-06-04</created><authors><author><keyname>Taghipour</keyname><forenames>Nima</forenames></author><author><keyname>Davis</keyname><forenames>Jesse</forenames></author><author><keyname>Blockeel</keyname><forenames>Hendrik</forenames></author></authors><title>First-Order Decomposition Trees</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lifting attempts to speed up probabilistic inference by exploiting symmetries
in the model. Exact lifted inference methods, like their propositional
counterparts, work by recursively decomposing the model and the problem. In the
propositional case, there exist formal structures, such as decomposition trees
(dtrees), that represent such a decomposition and allow us to determine the
complexity of inference a priori. However, there is currently no equivalent
structure nor analogous complexity results for lifted inference. In this paper,
we introduce FO-dtrees, which upgrade propositional dtrees to the first-order
level. We show how these trees can characterize a lifted inference solution for
a probabilistic logical model (in terms of a sequence of lifted operations),
and make a theoretical analysis of the complexity of lifted inference in terms
of the novel notion of lifted width for the tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0755</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0755</id><created>2013-06-04</created><authors><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Ali</keyname><forenames>L.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author></authors><title>Evaluating Wireless Reactive Routing Protocols with Linear Programming
  Model for Wireless Ad-hoc Networks</title><categories>cs.NI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1304.0153</comments><journal-ref>J. Basic. Appl. Sci. Res., 3(1)1170-1181, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Wireless Ad-hoc Networks, nodes are free to move randomly and organize
themselves arbitrarily, thus topology may change quickly and capriciously. In
Mobile Ad-hoc NETworks, specially Wireless Multi-hop Networks provide users
with facility of quick communication. In Wireless Multi-hop Networks, routing
protocols with energy efficient and delay reduction techniques are needed to
fulfill users demands. In this paper, we present Linear Programming models to
assess and enhance reactive routing protocols. To practically examine
constraints of respective Linear Programming models over reactive protocols, we
select AODV, DSR and DYMO. It is deduced from analytical simulations of Linear
Programming models in MATLAB that quick route repair reduces routing latency
and optimizations of retransmission attempts results efficient energy
utilization. To provide quick repair, we enhance AODV and DSR. To practically
examine the efficiency of enhanced protocols in different scenarios of Wireless
Multi-hop Networks, we conduct simulations using NS-2. From simulation results,
enhanced DSR and AODV achieve efficient output by optimizing routing latencies
and routing load in terms of retransmission attempts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0757</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0757</id><created>2013-06-04</created><authors><author><keyname>Arshad</keyname><forenames>W.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author></authors><title>Modeling and Simulating Network Connectivity in Routing Protocols for
  MANETs and VANETs</title><categories>cs.NI</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(2)1312-1318, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a framework for node distribution with respect to
density, network connectivity and communication time. Using NS2, we evaluate
and compare performance of three routing protocols; Ad-hoc On-demand Distance
Vector (AODV), Dynamic Source Routing (DSR) and Fisheye State Routing (FSR)
both in MANETs (IEEE 802.11) and VANETs (IEEE 802.11p). We further enhanced
these protocols by changing their routing information exchange intervals; MOD
AODV, MOD DSR and MOD FSR. A comprehensive simulation work is performed for the
comparison of these routing protocols for varying motilities and scalabilities
of nodes. As a result, we can say that AODV outperforms DSR and FSR both in
MANETs and VANETs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0760</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0760</id><created>2013-06-04</created><authors><author><keyname>J&#xe9;z&#xe9;quel</keyname><forenames>Jean-Marc</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Combemale</keyname><forenames>Benoit</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Barais</keyname><forenames>Olivier</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Monperrus</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Fouquet</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Mashup of Meta-Languages and its Implementation in the Kermeta Language
  Workbench</title><categories>cs.SE</categories><comments>Published in Software and Systems Modeling (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing use of domain-specific languages (DSL) in industry, DSL
design and implementation goes far beyond an activity for a few experts only
and becomes a challenging task for thousands of software engineers. DSL
implementation indeed requires engineers to care for various concerns, from
abstract syntax, static semantics, behavioral semantics, to extra-functional
issues such as run-time performance. This paper presents an approach that uses
one meta-language per language implementation concern. We show that the usage
and combination of those meta-languages is simple and intuitive enough to
deserve the term &quot;mashup&quot;. We evaluate the approach by completely implementing
the non trivial fUML modeling language, a semantically sound and executable
subset of the Unified Modeling Language (UML).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0761</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0761</id><created>2013-06-04</created><authors><author><keyname>Wasiq</keyname><forenames>S.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author></authors><title>Evaluating and Comparing Probability of Path Loss in DSDV, OLSR and DYMO
  at 802.11 and 802.11p</title><categories>cs.NI</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(2)1327-1334, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present path loss model for VANETs and simulate three
routing protocols; Destination Sequenced Distance Vector (DSDV), Optimized Link
State Routing (OLSR) and Dynamic MANET On-demand (DYMO) to evaluate and compare
their performance using NS-2. The main contribution of this work is enhancement
of existing techniques to achieve high efficiency of the underlying networks.
After extensive simulations in NS-2, we conclude that DSDV best performs with
802.11p while DYMO gives outstanding performance with 802.11.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0762</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0762</id><created>2013-06-04</created><authors><author><keyname>Monperrus</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Mezini</keyname><forenames>Mira</forenames></author></authors><title>Detecting Missing Method Calls as Violations of the Majority Rule</title><categories>cs.SE</categories><proxy>ccsd</proxy><journal-ref>ACM Transactions on Software Engineering and Methodology 22, 1
  (2013) 1-25</journal-ref><doi>10.1145/2430536.2430541</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When using object-oriented frameworks it is easy to overlook certain
important method calls that are required at particular places in code. In this
paper, we provide a comprehensive set of empirical facts on this problem,
starting from traces of missing method calls in a bug repository. We propose a
new system that searches for missing method calls in software based on the
other method calls that are observable. Our key insight is that the voting
theory concept of majority rule holds for method calls: a call is likely to be
missing if there is a majority of similar pieces of code where this call is
present. The evaluation shows that the system predictions go further missing
method calls and often reveal different kinds of code smells (e.g. violations
of API best practices).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0769</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0769</id><created>2013-06-04</created><authors><author><keyname>Rafiee</keyname><forenames>Ashkan</forenames><affiliation>LAMA</affiliation></author><author><keyname>Dutykh</keyname><forenames>Denys</forenames><affiliation>LAMA</affiliation></author><author><keyname>Dias</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>CMLA</affiliation></author></authors><title>Numerical simulation of wave impact on a rigid wall using a two--phase
  compressible SPH method</title><categories>physics.flu-dyn cs.NA physics.comp-ph</categories><comments>18 pages, 11 figures, 33 references. Other author's papers can be
  downloaded at http://www.denys-dutykh.com/</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an SPH method based on the SPH--ALE formulation is used for
modelling two-phase flows with large density ratios and realistic sound speeds.
The SPH scheme is further improved to circumvent the tensile instability that
may occur in the SPH simulations. The two-phase SPH solver is then used to
model a benchmark problem of liquid impact on a rigid wall. The results are
compared with an incompressible Level Set solver. Furthermore, a wave impact on
a rigid wall with a large entrained air pocket is modelled. The SPH simulation
is initialised by the output of a fully non-linear potential flow solver. The
pressure distribution, velocity field and impact pressure are then analysed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0771</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0771</id><created>2013-06-04</created><authors><author><keyname>Boyar</keyname><forenames>Joan</forenames></author><author><keyname>Larsen</keyname><forenames>Kim S.</forenames></author><author><keyname>Maiti</keyname><forenames>Abyayananda</forenames></author></authors><title>The Frequent Items Problem in Online Streaming under Various Performance
  Measures</title><categories>cs.DS</categories><comments>IMADA-preprint-cs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we strengthen the competitive analysis results obtained for a
fundamental online streaming problem, the Frequent Items Problem. Additionally,
we contribute with a more detailed analysis of this problem, using alternative
performance measures, supplementing the insight gained from competitive
analysis. The results also contribute to the general study of performance
measures for online algorithms. It has long been known that competitive
analysis suffers from drawbacks in certain situations, and many alternative
measures have been proposed. However, more systematic comparative studies of
performance measures have been initiated recently, and we continue this work,
using competitive analysis, relative interval analysis, and relative worst
order analysis on the Frequent Items Problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0772</identifier>
 <datestamp>2014-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0772</id><created>2013-06-04</created><updated>2013-07-31</updated><authors><author><keyname>Blaszczyszyn</keyname><forenames>Bartlomiej</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Keeler</keyname><forenames>Holger Paul</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Equivalence and comparison of heterogeneous cellular networks</title><categories>cs.NI cs.IT math.IT math.PR</categories><proxy>ccsd</proxy><doi>10.1109/PIMRCW.2013.6707855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general heterogeneous network in which, besides general
propagation effects (shadowing and/or fading), individual base stations can
have different emitting powers and be subject to different parameters of
Hata-like path-loss models (path-loss exponent and constant) due to, for
example, varying antenna heights. We assume also that the stations may have
varying parameters of, for example, the link layer performance (SINR threshold,
etc). By studying the propagation processes of signals received by the typical
user from all antennas marked by the corresponding antenna parameters, we show
that seemingly different heterogeneous networks based on Poisson point
processes can be equivalent from the point of view a typical user. These
neworks can be replaced with a model where all the previously varying
propagation parameters (including path-loss exponents) are set to constants
while the only trade-off being the introduction of an isotropic base station
density. This allows one to perform analytic comparisons of different network
models via their isotropic representations. In the case of a constant path-loss
exponent, the isotropic representation simplifies to a homogeneous modification
of the constant intensity of the original network, thus generalizing a previous
result showing that the propagation processes only depend on one moment of the
emitted power and propagation effects. We give examples and applications to
motivate these results and highlight an interesting observation regarding
random path-loss exponents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0783</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0783</id><created>2013-06-04</created><updated>2013-11-05</updated><authors><author><keyname>Zsid&#xf3;</keyname><forenames>Julianna</forenames></author></authors><title>Theorem of three circles in Coq</title><categories>cs.LO</categories><comments>27 pages, 5 figures</comments><msc-class>68Q</msc-class><doi>10.1007/s10817-013-9299-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theorem of three circles in real algebraic geometry guarantees the
termination and correctness of an algorithm of isolating real roots of a
univariate polynomial. The main idea of its proof is to consider polynomials
whose roots belong to a certain area of the complex plane delimited by straight
lines. After applying a transformation involving inversion this area is mapped
to an area delimited by circles. We provide a formalisation of this rather
geometric proof in Ssreflect, an extension of the proof assistant Coq,
providing versatile algebraic tools. They allow us to formalise the proof from
an algebraic point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0785</identifier>
 <datestamp>2015-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0785</id><created>2013-06-04</created><updated>2015-08-04</updated><authors><author><keyname>Gregoire</keyname><forenames>Jean</forenames></author><author><keyname>Bonnabel</keyname><forenames>Silv&#xe8;re</forenames></author><author><keyname>de La Fortelle</keyname><forenames>Arnaud</forenames></author></authors><title>Robust multirobot coordination using priority encoded homotopic
  constraints</title><categories>cs.RO</categories><comments>21 pages, in revision for publication in System &amp; Control Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of coordinating multiple robots along fixed geometric
paths. Our contribution is threefold. First we formalize the intuitive concept
of priorities as a binary relation induced by a feasible coordination solution,
without excluding the case of robots following each other on the same geometric
path. Then we prove that two paths in the coordination space are continuously
deformable into each other if and only if they induce the \emph{same priority
graph}, that is, the priority graph uniquely encodes homotopy classes of
coordination solutions. Finally, we give a simple control law allowing to
safely navigate into homotopy classes \emph{under kinodynamic constraints} even
in the presence of unexpected events, such as a sudden robot deceleration
without notice. It appears the freedom within homotopy classes allows to much
deviate from any pre-planned trajectory without ever colliding nor having to
re-plan the assigned priorities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0806</identifier>
 <datestamp>2014-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0806</id><created>2013-06-04</created><authors><author><keyname>Poza</keyname><forenames>Mar\'\ia</forenames></author><author><keyname>Dom\'\inguez</keyname><forenames>C&#xe9;sar</forenames></author><author><keyname>Heras</keyname><forenames>J&#xf3;nathan</forenames></author><author><keyname>Rubio</keyname><forenames>Julio</forenames></author></authors><title>A certified reduction strategy for homological image processing</title><categories>cs.LO math.AT</categories><journal-ref>ACM Transactions on Computational Logic, Volume 15 Issue 3,
  Article No. 23 2014</journal-ref><doi>10.1145/2630789</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of digital images using homological procedures is an outstanding
topic in the area of Computational Algebraic Topology. In this paper, we
describe a certified reduction strategy to deal with digital images, but
preserving their homological properties. We stress both the advantages of our
approach (mainly, the formalisation of the mathematics allowing us to verify
the correctness of algorithms) and some limitations (related to the performance
of the running systems inside proof assistants). The drawbacks are overcome
using techniques that provide an integration of computation and deduction. Our
driving application is a problem in bioinformatics, where the accuracy and
reliability of computations are specially requested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0808</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0808</id><created>2013-06-04</created><authors><author><keyname>Mokryn</keyname><forenames>Osnat</forenames></author><author><keyname>Blattner</keyname><forenames>Marcel</forenames></author><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author></authors><title>The Role of Trends in Evolving Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling complex networks has been the focus of much research for over a
decade. Preferential attachment (PA) is considered a common explanation to the
self organization of evolving networks, suggesting that new nodes prefer to
attach to more popular nodes. The PA model results in broad degree
distributions, found in many networks, but cannot explain other common
properties such as: The growth of nodes arriving late and Clustering (community
structure). Here we show that when the tendency of networks to adhere to trends
is incorporated into the PA model, it can produce networks with such
properties. Namely, in trending networks, newly arriving nodes may become
central at random, forming new clusters. In particular, we show that when the
network is young it is more susceptible to trends, but even older networks may
have trendy new nodes that become central in their structure. Alternatively,
networks can be seen as composed of two parts: static, governed by a power law
degree distribution, and a dynamic part governed by trends, as we show on Wiki
pages. Our results also show that the arrival of trending new nodes not only
creates new clusters, but also has an effect on the relative importance and
centrality of all other nodes in the network. This can explain a variety of
real world networks in economics, social and online networks, and cultural
networks. Products popularity, formed by the network of people's opinions,
exhibit these properties. Some lines of products are increasingly susceptible
to trends and hence to shifts in popularity, while others are less trendy and
hence more stable. We believe that our findings have a big impact on our
understanding of real networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0810</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0810</id><created>2013-06-01</created><authors><author><keyname>Perotti</keyname><forenames>Alan</forenames></author></authors><title>RuleRunner technical report</title><categories>cs.LO cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rule-based run-time monitoring system for finite traces, with FLTL verdict
and quadratic complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0811</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0811</id><created>2013-06-04</created><updated>2013-11-04</updated><authors><author><keyname>Cesa-Bianchi</keyname><forenames>Nicol&#xf2;</forenames></author><author><keyname>Gentile</keyname><forenames>Claudio</forenames></author><author><keyname>Zappella</keyname><forenames>Giovanni</forenames></author></authors><title>A Gang of Bandits</title><categories>cs.LG cs.SI stat.ML</categories><comments>NIPS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-armed bandit problems are receiving a great deal of attention because
they adequately formalize the exploration-exploitation trade-offs arising in
several industrially relevant applications, such as online advertisement and,
more generally, recommendation systems. In many cases, however, these
applications have a strong social component, whose integration in the bandit
algorithm could lead to a dramatic performance increase. For instance, we may
want to serve content to a group of users by taking advantage of an underlying
network of social relationships among them. In this paper, we introduce novel
algorithmic approaches to the solution of such networked bandit problems. More
specifically, we design and analyze a global strategy which allocates a bandit
algorithm to each network node (user) and allows it to &quot;share&quot; signals
(contexts and payoffs) with the neghboring nodes. We then derive two more
scalable variants of this strategy based on different ways of clustering the
graph nodes. We experimentally compare the algorithm and its variants to
state-of-the-art methods for contextual bandits that do not use the relational
information. Our experiments, carried out on synthetic and real-world datasets,
show a marked increase in prediction performance obtained by exploiting the
network structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0813</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0813</id><created>2013-06-04</created><authors><author><keyname>Bontcheva</keyname><forenames>Kalina</forenames></author><author><keyname>Gorrell</keyname><forenames>Genevieve</forenames></author><author><keyname>Wessels</keyname><forenames>Bridgette</forenames></author></authors><title>Social Media and Information Overload: Survey Results</title><categories>cs.SI cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A UK-based online questionnaire investigating aspects of usage of
user-generated media (UGM), such as Facebook, LinkedIn and Twitter, attracted
587 participants. Results show a high degree of engagement with social
networking media such as Facebook, and a significant engagement with other
media such as professional media, microblogs and blogs. Participants who
experience information overload are those who engage less frequently with the
media, rather than those who have fewer posts to read. Professional users show
different behaviours to social users. Microbloggers complain of information
overload to the greatest extent. Two thirds of Twitter-users have felt that
they receive too many posts, and over half of Twitter-users have felt the need
for a tool to filter out the irrelevant posts. Generally speaking, participants
express satisfaction with the media, though a significant minority express a
range of concerns including information overload and privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0814</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0814</id><created>2013-06-04</created><authors><author><keyname>Carapelle</keyname><forenames>Claudia</forenames></author><author><keyname>Kartzow</keyname><forenames>Alexander</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>Satisfiability of CTL* with constraints</title><categories>cs.LO</categories><comments>To appear at Concur 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that satisfiability for CTL* with equality-, order-, and
modulo-constraints over Z is decidable. Previously, decidability was only known
for certain fragments of CTL*, e.g., the existential and positive fragments and
EF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0816</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0816</id><created>2013-06-04</created><authors><author><keyname>Najy</keyname><forenames>Waleed K. A.</forenames></author><author><keyname>Crandall</keyname><forenames>Jacob W.</forenames></author><author><keyname>Zeineldin</keyname><forenames>H. H.</forenames></author></authors><title>A Critical Assessment of Cost-Based Nash Methods for Demand Scheduling
  in Smart Grids</title><categories>cs.GT cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demand-side management (DSM) is becoming an increasingly important component
of the envisioned smart grid. The ability to improve the efficiency of energy
use in the power system by altering demand is widely viewed as being not merely
promising but in fact essential. However, while the advantages of DSM are
clear, arriving at an efficient implementation has so far proven to be less
straightforward. There have recently been many proposals put forth in the
literature to tackle the demand scheduling aspect of DSM. One particular
approach based on a game-theoretic treatment of the day-ahead load-scheduling
problem has recently gained tremendous popularity in the DSM literature. In
this letter, an assessment of this approach is conducted, and its main result
is challenged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0819</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0819</id><created>2013-06-04</created><authors><author><keyname>Foucaud</keyname><forenames>Florent</forenames></author><author><keyname>Perarnau</keyname><forenames>Guillem</forenames></author><author><keyname>Serra</keyname><forenames>Oriol</forenames></author></authors><title>Random subgraphs make identification affordable</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An identifying code of a graph is a dominating set which uniquely determines
all the vertices by their neighborhood within the code. Whereas graphs with
large minimum degree have small domination number, this is not the case for the
identifying code number (the size of a smallest identifying code), which indeed
is not even a monotone parameter with respect to graph inclusion.
  We show that every graph $G$ with $n$ vertices, maximum degree
$\Delta=\omega(1)$ and minimum degree $\delta\geq c\log{\Delta}$, for some
constant $c&gt;0$, contains a large spanning subgraph which admits an identifying
code with size $O\left(\frac{n\log{\Delta}}{\delta}\right)$. In particular, if
$\delta=\Theta(n)$, then $G$ has a dense spanning subgraph with identifying
code $O\left(\log n\right)$, namely, of asymptotically optimal size. The
subgraph we build is created using a probabilistic approach, and we use an
interplay of various random methods to analyze it. Moreover we show that the
result is essentially best possible, both in terms of the number of deleted
edges and the size of the identifying code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0831</identifier>
 <datestamp>2015-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0831</id><created>2013-06-04</created><updated>2015-11-04</updated><authors><author><keyname>Furber</keyname><forenames>Robert</forenames><affiliation>Radboud University, Nijmegen</affiliation></author><author><keyname>Jacobs</keyname><forenames>Bart</forenames><affiliation>Radboud University, Nijmegen</affiliation></author></authors><title>Towards a Categorical Account of Conditional Probability</title><categories>math.CT cs.LO</categories><comments>In Proceedings QPL 2015, arXiv:1511.01181</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 195, 2015, pp. 179-195</journal-ref><doi>10.4204/EPTCS.195.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a categorical account of conditional probability,
covering both the classical and the quantum case. Classical conditional
probabilities are expressed as a certain &quot;triangle-fill-in&quot; condition,
connecting marginal and joint probabilities, in the Kleisli category of the
distribution monad. The conditional probabilities are induced by a map together
with a predicate (the condition). The latter is a predicate in the logic of
effect modules on this Kleisli category.
  This same approach can be transferred to the category of C*-algebras (with
positive unital maps), whose predicate logic is also expressed in terms of
effect modules. Conditional probabilities can again be expressed via a
triangle-fill-in property. In the literature, there are several proposals for
what quantum conditional probability should be, and also there are extra
difficulties not present in the classical case. At this stage, we only describe
quantum systems with classical parametrization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0832</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0832</id><created>2013-06-04</created><authors><author><keyname>Haimovich</keyname><forenames>Hernan</forenames></author><author><keyname>Middleton</keyname><forenames>Richard H.</forenames></author><author><keyname>De Nicolo</keyname><forenames>Lisandro</forenames></author></authors><title>Large-signal stability conditions for semi-quasi-Z-source inverters:
  switched and averaged models</title><categories>cs.SY</categories><comments>Submitted to the IEEE Conf. on Decision and Control, Florence, Italy,
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently introduced semi-quasi-Z-source in- verter can be interpreted as
a DC-DC converter whose input- output voltage gain may take any value between
minus infinity and 1 depending on the applied duty cycle. In order to generate
a sinusoidal voltage waveform at the output of this converter, a time-varying
duty cycle needs to be applied. Application of a time-varying duty cycle that
produces large-signal behavior requires careful consideration of stability
issues. This paper provides stability results for both the large-signal
averaged and the switched models of the semi-quasi-Z-source inverter operating
in continuous conduction mode. We show that if the load is linear and purely
resistive then the boundedness and ultimate boundedness of the state
trajectories is guaranteed provided some reasonable operation conditions are
ensured. These conditions amount to keeping the duty cycle away from the
extreme values 0 or 1 (averaged and switched models), and limiting the maximum
PWM switching period (switched model). The results obtained can be used to give
theoretical justification to the inverter operation strategy recently proposed
by Cao et al. in [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0842</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0842</id><created>2013-06-04</created><updated>2013-06-06</updated><authors><author><keyname>Muandet</keyname><forenames>Krikamol</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author><author><keyname>Sriperumbudur</keyname><forenames>Bharath</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Kernel Mean Estimation and Stein's Effect</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>first draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mean function in reproducing kernel Hilbert space, or a kernel mean, is an
important part of many applications ranging from kernel principal component
analysis to Hilbert-space embedding of distributions. Given finite samples, an
empirical average is the standard estimate for the true kernel mean. We show
that this estimator can be improved via a well-known phenomenon in statistics
called Stein's phenomenon. After consideration, our theoretical analysis
reveals the existence of a wide class of estimators that are better than the
standard. Focusing on a subset of this class, we propose efficient shrinkage
estimators for the kernel mean. Empirical evaluations on several benchmark
applications clearly demonstrate that the proposed estimators outperform the
standard kernel mean estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0846</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0846</id><created>2013-06-04</created><authors><author><keyname>McGilvary</keyname><forenames>Gary A.</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author><author><keyname>Lloyd</keyname><forenames>Ashley</forenames></author><author><keyname>Atkinson</keyname><forenames>Malcolm</forenames></author></authors><title>V-BOINC: The Virtualization of BOINC</title><categories>cs.DC cs.OS</categories><comments>9 pages, Proceedings of the 13th IEEE/ACM International Symposium on
  Cluster, Cloud and Grid Computing (CCGrid 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Berkeley Open Infrastructure for Network Computing (BOINC) is an open
source client-server middleware system created to allow projects with large
computational requirements, usually set in the scientific domain, to utilize a
technically unlimited number of volunteer machines distributed over large
physical distances. However various problems exist deploying applications over
these heterogeneous machines using BOINC: applications must be ported to each
machine architecture type, the project server must be trusted to supply
authentic applications, applications that do not regularly checkpoint may lose
execution progress upon volunteer machine termination and applications that
have dependencies may find it difficult to run under BOINC.
  To solve such problems we introduce virtual BOINC, or V-BOINC, where virtual
machines are used to run computations on volunteer machines. Application
developers can then compile their applications on a single architecture,
checkpointing issues are solved through virtualization API's and many security
concerns are addressed via the virtual machine's sandbox environment. In this
paper we focus on outlining a unique approach on how virtualization can be
introduced into BOINC and demonstrate that V-BOINC offers acceptable
computational performance when compared to regular BOINC. Finally we show that
applications with dependencies can easily run under V-BOINC in turn increasing
the computational potential volunteer computing offers to the general public
and project developers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0865</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0865</id><created>2013-06-04</created><updated>2013-10-23</updated><authors><author><keyname>Kang</keyname><forenames>Jinkyu</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Kang</keyname><forenames>Joonhyuk</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Joint Signal and Channel State Information Compression for the Backhaul
  of Uplink Network MIMO Systems</title><categories>cs.IT math.IT</categories><comments>34 pages, 6 figures. Submitted to IEEE Transactions on Wireless
  Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In network MIMO cellular systems, subsets of base stations (BSs), or remote
radio heads, are connected via backhaul links to central units (CUs) that
perform joint encoding in the downlink and joint decoding in the uplink.
Focusing on the uplink, an effective solution for the communication between BSs
and the corresponding CU on the backhaul links is based on compressing and
forwarding the baseband received signal from each BS. In the presence of
ergodic fading, communicating the channel state information (CSI) from the BSs
to the CU may require a sizable part of the backhaul capacity. In a prior work,
this aspect was studied by assuming a Compress-Forward-Estimate (CFE) approach,
whereby the BSs compress the training signal and CSI estimation takes place at
the CU. In this work, instead, an Estimate-Compress-Forward (ECF) approach is
investigated, whereby the BSs perform CSI estimation and forward a compressed
version of the CSI to the CU. This choice is motivated by the information
theoretic optimality of separate estimation and compression. Various ECF
strategies are proposed that perform either separate or joint compression of
estimated CSI and received signal. Moreover, the proposed strategies are
combined with distributed source coding when considering multiple BSs.
&quot;Semi-coherent&quot; strategies are also proposed that do not convey any CSI or
training information on the backhaul links. Via numerical results, it is shown
that a proper design of ECF strategies based on joint received signal and
estimated CSI compression or of semi-coherent schemes leads to substantial
performance gains compared to more conventional approaches based on
non-coherent transmission or the CFE approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0883</identifier>
 <datestamp>2014-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0883</id><created>2013-06-04</created><updated>2014-05-20</updated><authors><author><keyname>Alekseyev</keyname><forenames>Max A.</forenames></author><author><keyname>Tengely</keyname><forenames>Szabolcs</forenames></author></authors><title>On integral points on biquadratic curves and near-multiples of squares
  in Lucas sequences</title><categories>math.NT cs.DM</categories><msc-class>11Y50, 11D25, 11B39, 14G05</msc-class><journal-ref>Journal of Integer Sequences 17(6), 2014, Article 14.6.6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithmic reduction of the search for integral points on a
curve y^2 = ax^4 + bx^2 + c with nonzero ac(b^2-4ac) to solving a finite number
of Thue equations. While existence of such reduction is anticipated from
arguments of algebraic number theory, our algorithm is elementary and to best
of our knowledge is the first published algorithm of this kind. In combination
with other methods and powered by existing software Thue equations solvers, it
allows one to efficiently compute integral points on biquadratic curves.
  We illustrate this approach with a particular application of finding
near-multiples of squares in Lucas sequences. As an example, we establish that
among Fibonacci numbers only 2 and 34 are of the form 2m^2+2; only 1, 13, and
1597 are of the form m^2-3; and so on.
  As an auxiliary result, we also give an algorithm for solving a Diophantine
equation k^2 = f(m,n)/g(m,n) in integers m,n,k, where f and g are homogeneous
quadratic polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0886</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0886</id><created>2013-06-04</created><authors><author><keyname>Yu</keyname><forenames>Felix X.</forenames></author><author><keyname>Liu</keyname><forenames>Dong</forenames></author><author><keyname>Kumar</keyname><forenames>Sanjiv</forenames></author><author><keyname>Jebara</keyname><forenames>Tony</forenames></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames></author></authors><title>$\propto$SVM for learning with label proportions</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 30th International Conference on
  Machine Learning (ICML 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of learning with label proportions in which the training
data is provided in groups and only the proportion of each class in each group
is known. We propose a new method called proportion-SVM, or $\propto$SVM, which
explicitly models the latent unknown instance labels together with the known
group label proportions in a large-margin framework. Unlike the existing works,
our approach avoids making restrictive assumptions about the data. The
$\propto$SVM model leads to a non-convex integer programming problem. In order
to solve it efficiently, we propose two algorithms: one based on simple
alternating optimization and the other based on a convex relaxation. Extensive
experiments on standard datasets show that $\propto$SVM outperforms the
state-of-the-art, especially for larger group sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0896</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0896</id><created>2013-06-04</created><authors><author><keyname>Abraham</keyname><forenames>Siby</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author><author><keyname>Sanglikar</keyname><forenames>Mukund</forenames></author></authors><title>Finding Numerical Solutions of Diophantine Equations using Ant Colony
  Optimization</title><categories>cs.NE cs.ET</categories><comments>14 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper attempts to find numerical solutions of Diophantine equations, a
challenging problem as there are no general methods to find solutions of such
equations. It uses the metaphor of foraging habits of real ants. The ant colony
optimization based procedure starts with randomly assigned locations to a fixed
number of artificial ants. Depending upon the quality of these positions, ants
deposit pheromone at the nodes. A successor node is selected from the
topological neighborhood of each of the nodes based on this stochastic
pheromone deposit. If an ant bumps into an already encountered node, the
pheromone is updated correspondingly. A suitably defined pheromone evaporation
strategy guarantees that premature convergence does not take place. The
experimental results, which compares with those of other machine intelligence
techniques, validate the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0897</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0897</id><created>2013-06-04</created><authors><author><keyname>Tamas</keyname><forenames>Wani W.</forenames><affiliation>SPE</affiliation></author><author><keyname>Notton</keyname><forenames>Gilles</forenames><affiliation>SPE</affiliation></author><author><keyname>Paoli</keyname><forenames>Christophe</forenames><affiliation>SPE</affiliation></author><author><keyname>Voyant</keyname><forenames>Cyril</forenames><affiliation>SPE, CHD Castellucio</affiliation></author><author><keyname>Nivet</keyname><forenames>Marie Laure</forenames><affiliation>SPE</affiliation></author><author><keyname>Balu</keyname><forenames>Aur&#xe9;lia</forenames><affiliation>SPE</affiliation></author></authors><title>Urban ozone concentration forecasting with artificial neural network in
  Corsica</title><categories>cs.NE</categories><comments>Sustainable Solutions for Energy and Environment. EENVIRO 2013,
  Buchatrest : Romania (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Atmospheric pollutants concentration forecasting is an important issue in air
quality monitoring. Qualitair Corse, the organization responsible for
monitoring air quality in Corsica (France) region, needs to develop a
short-term prediction model to lead its mission of information towards the
public. Various deterministic models exist for meso-scale or local forecasting,
but need powerful large variable sets, a good knowledge of atmospheric
processes, and can be inaccurate because of local climatical or geographical
particularities, as observed in Corsica, a mountainous island located in a
Mediterranean Sea. As a result, we focus in this study on statistical models,
and particularly Artificial Neural Networks (ANN) that have shown good results
in the prediction of ozone concentration at horizon h+1 with data measured
locally. The purpose of this study is to build a predictor to realize
predictions of ozone and PM10 at horizon d+1 in Corsica in order to be able to
anticipate pollution peak formation and to take appropriated prevention
measures. Specific meteorological conditions are known to lead to particular
pollution event in Corsica (e.g. Saharan dust event). Therefore, several ANN
models will be used, for meteorological conditions clustering and for
operational forecasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0918</identifier>
 <datestamp>2014-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0918</id><created>2013-06-04</created><updated>2014-01-23</updated><authors><author><keyname>Wright</keyname><forenames>James R.</forenames></author><author><keyname>Leyton-Brown</keyname><forenames>Kevin</forenames></author></authors><title>Predicting Human Behavior in Unrepeated, Simultaneous-Move Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is common to assume that agents will adopt Nash equilibrium strategies;
however, experimental studies have demonstrated that Nash equilibrium is often
a poor description of human players' behavior in unrepeated normal-form games.
In this paper, we analyze four widely studied models (QRE, Lk, Cognitive
Hierarchy, QLk) that aim to describe actual, rather than idealized, human
behavior in such games. We performed what we believe is the most comprehensive
meta-analysis of these models, leveraging nine different data sets from the
literature recording human play of two-player games. We began by evaluating the
models' generalization or predictive performance, asking how well a model fits
unseen ``test data'' after having had its parameters calibrated based on
separate ``training data''. Surprisingly, we found that (what we dub) the QLk
model of Stahl &amp; Wilson [1994] consistently achieved the best performance.
Motivated by this finding, we describe methods for analyzing the posterior
distributions over a model's parameters. We found that QLk's parameters were
being set to values that were not consistent with their intended economic
interpretations. We thus explored variations of QLk, ultimately identifying a
new model family that has fewer parameters, gives rise to more parsimonious
parameter values, and achieves better predictive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0924</identifier>
 <datestamp>2014-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0924</id><created>2013-06-04</created><authors><author><keyname>Gramatica</keyname><forenames>Ruggero</forenames></author><author><keyname>Di Matteo</keyname><forenames>T.</forenames></author><author><keyname>Giorgetti</keyname><forenames>Stefano</forenames></author><author><keyname>Barbiani</keyname><forenames>Massimo</forenames></author><author><keyname>Bevec</keyname><forenames>Dorian</forenames></author><author><keyname>Aste</keyname><forenames>Tomaso</forenames></author></authors><title>Graph theory enables drug repurposing. How a mathematical model can
  drive the discovery of hidden Mechanisms of Action</title><categories>q-bio.QM cs.CE</categories><comments>8 pages, 7 figures</comments><journal-ref>PLoS ONE 9 (2013) e84912</journal-ref><doi>10.1371/journal.pone.0084912</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduced a methodology to efficiently exploit natural-language expressed
biomedical knowledge for repurposing existing drugs towards diseases for which
they were not initially intended. Leveraging on developments in Computational
Linguistics and Graph Theory, a methodology is defined to build a graph
representation of knowledge, which is automatically analysed to discover hidden
relations between any drug and any disease: these relations are specific paths
among the biomedical entities of the graph, representing possible Modes of
Action for any given pharmacological compound. These paths are ranked according
to their relevance, exploiting a measure induced by a stochastic process
defined on the graph. Here we show, providing real-world examples, how the
method successfully retrieves known pathophysiological Mode of Actions and
finds new ones by meaningfully selecting and aggregating contributions from
known bio-molecular interactions. Applications of this methodology are
presented, and prove the efficacy of the method for selecting drugs as
treatment options for rare diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0926</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0926</id><created>2013-06-04</created><authors><author><keyname>Jeong</keyname><forenames>Seongwook</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>Self-Iterating Soft Equalizer</title><categories>cs.IT math.IT</categories><comments>32 pages, 12 figures. This paper is under review for IEEE
  Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-iterating soft equalizer (SISE) consisting of a few relatively weak
constituent equalizers is shown to provide robust performance even in severe
intersymbol interference (ISI) channels that exhibit deep nulls and valleys
within the signal band. Constituent equalizers are allowed to exchange soft
information in the absence of interleavers based on the method that are
designed to suppress significant correlation among their soft outputs. The
resulting SISE works well as a stand-alone equalizer or as the equalizer
component of a turbo equalization system. The performance advantages over
existing methods are validated with bit-error-rate (BER) simulations and
extrinsic information transfer (EXIT) chart analysis. It is shown that in turbo
equalizer setting the SISE achieves performance closer to the maximum a
posteriori probability equalizer than any other known schemes in very severe
ISI channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0940</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0940</id><created>2013-06-04</created><updated>2013-12-26</updated><authors><author><keyname>Osband</keyname><forenames>Ian</forenames></author><author><keyname>Russo</keyname><forenames>Daniel</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author></authors><title>(More) Efficient Reinforcement Learning via Posterior Sampling</title><categories>stat.ML cs.LG</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most provably-efficient learning algorithms introduce optimism about
poorly-understood states and actions to encourage exploration. We study an
alternative approach for efficient exploration, posterior sampling for
reinforcement learning (PSRL). This algorithm proceeds in repeated episodes of
known duration. At the start of each episode, PSRL updates a prior distribution
over Markov decision processes and takes one sample from this posterior. PSRL
then follows the policy that is optimal for this sample during the episode. The
algorithm is conceptually simple, computationally efficient and allows an agent
to encode prior knowledge in a natural way. We establish an $\tilde{O}(\tau S
\sqrt{AT})$ bound on the expected regret, where $T$ is time, $\tau$ is the
episode length and $S$ and $A$ are the cardinalities of the state and action
spaces. This bound is one of the first for an algorithm not based on optimism,
and close to the state of the art for any reinforcement learning algorithm. We
show through simulation that PSRL significantly outperforms existing algorithms
with similar regret bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0944</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0944</id><created>2013-06-04</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>An Exact Path-Loss Density Model for Mobiles in a Cellular System</title><categories>cs.IT math.IT</categories><comments>Proc. of the 7th ACM International Symposium on Mobility Management
  and Wireless Access (MobiWac'09), held in conjunction with MSWiM'09</comments><doi>10.1145/1641776.1641797</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In trying to emulate the spatial position of wireless nodes for purpose of
analysis, we rely on stochastic simulation. And, it is customary, for mobile
systems, to consider a base-station radiation coverage by an ideal cell shape.
For cellular analysis, a hexagon contour is always preferred mainly because of
its tessellating nature. Despite this fact, largely due to its intrinsic
simplicity, in literature only random dispersion model for a circular shape is
known. However, if considered, this will result an unfair nodes density
specifically at the edges of non-circular contours. As a result, in this paper,
we showed the exact random number generation technique required for nodes
scattering inside a hexagon. Next, motivated from a system channel perspective,
we argued the need for the exhaustive random mobile dropping process, and hence
derived a generic close-form expression for the path-loss distribution density
between a base-station and a mobile. Last, simulation was used to reaffirm the
validity of the theoretical analysis using values from the new IEEE 802.20
standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0946</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0946</id><created>2013-06-04</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>Closed-Form Path-Loss Predictor for Gaussianly Distributed Nodes</title><categories>cs.IT cs.NI math.IT</categories><comments>Proc. of IEEE International Conference on Communications (ICC'10)</comments><doi>10.1109/ICC.2010.5502200</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emulation of wireless nodes spatial position is a practice used by
deployment engineers and network planners to analyze the characteristics of a
network. In particular, nodes geolocation will directly impact factors such as
connectivity, signals fidelity, and service quality. In literature, in addition
to typical homogenous scattering, normal distribution is frequently used to
model mobiles concentration in a cellular system. Moreover, Gaussian dropping
is often considered as an effective placement method for airborne sensor
deployment. Despite the practicality of this model, getting the network channel
loss distribution still relies on exhaustive Monte Carlo simulation. In this
paper, we argue the need for this inefficient approach and hence derived a
generic and exact closed-form expression for the path-loss distribution density
between a base-station and a network of nodes. Simulation was used to reaffirm
the validity of the theoretical analysis using values from the new IEEE 802.20
standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0947</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0947</id><created>2013-06-04</created><authors><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author><author><keyname>Hopkins</keyname><forenames>Michael M.</forenames></author><author><keyname>Hoekman</keyname><forenames>Jarno</forenames></author><author><keyname>Siepel</keyname><forenames>Josh</forenames></author><author><keyname>O'Hare</keyname><forenames>Alice</forenames></author><author><keyname>Perianes-Rodriguez</keyname><forenames>Antonio</forenames></author><author><keyname>Nightingale</keyname><forenames>Paul</forenames></author></authors><title>Big Pharma, little science? A bibliometric perspective on big pharma's
  R&amp;D decline</title><categories>cs.DL physics.soc-ph</categories><doi>10.1016/j.techfore.2012.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a widespread perception that pharmaceutical R&amp;D is facing a
productivity crisis characterised by stagnation in the numbers of new drug
approvals in the face of increasing R&amp;D costs. This study explores
pharmaceutical R&amp;D dynamics by examining the publication activities of all R&amp;D
laboratories of the major European and US pharmaceutical firms during the
period 1995-2009. The empirical findings present an industry in
transformation.In the first place, we observe a decline of the total number of
publications by large firms. Second, we show a relative increase of their
external collaborations suggesting a tendency to outsource, and a
diversification of the disciplinary base, in particular towards computation,
health services and more clinical approaches. Also evident is a more pronounced
decline in publications by both R&amp;D laboratories located in Europe and by firms
with European headquarters. Finally, while publications by Big Pharma in
emerging economies sharply increase, they remain extremely low compared with
those in developed countries. In summary, the trend in this transformation is
one of a gradual decrease in internal research efforts and increasing reliance
on external research. These empirical insights support the view that large
pharmaceutical firms are increasingly becoming networks integrators rather than
the prime locus of drug discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0957</identifier>
 <datestamp>2013-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0957</id><created>2013-06-04</created><updated>2013-11-27</updated><authors><author><keyname>Cuiti&#xf1;o</keyname><forenames>Luis Felipe Tapia</forenames></author><author><keyname>Tironi</keyname><forenames>Andrea Luigi</forenames></author></authors><title>Dual codes of product semi-linear codes</title><categories>cs.IT math.IT math.RA</categories><comments>v1: 37 pages; v2: 31 pages, the presentation of the main topics is
  improved by some minor changes and additional results, and some mistakes and
  typos have been corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbb{F}_q$ be a finite field with $q$ elements and denote by $\theta
: \mathbb{F}_q\to\mathbb{F}_q$ an automorphism of $\mathbb{F}_q$. In this
paper, we deal with linear codes of $\mathbb{F}_q^n$ invariant under a
semi-linear map $T:\mathbb{F}_q^n\to\mathbb{F}_q^n$ for some $n\geq 2$. In
particular, we study three kind of their dual codes, some relations between
them and we focus on codes which are products of module skew codes in the
non-commutative polynomial ring $\mathbb{F}_q[X,\theta]$ as a subcase of linear
codes invariant by a semi-linear map $T$. In this setting we give also an
algorithm for encoding, decoding and detecting errors and we show a method to
construct codes invariant under a fixed $T$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0958</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0958</id><created>2013-06-04</created><authors><author><keyname>Kobayashi</keyname><forenames>Kenichi</forenames><affiliation>Fujitsu Laboratories</affiliation></author><author><keyname>Kamimura</keyname><forenames>Manabu</forenames></author><author><keyname>Yano</keyname><forenames>Keisuke</forenames></author><author><keyname>Kato</keyname><forenames>Koki</forenames></author><author><keyname>Matsuo</keyname><forenames>Akihiko</forenames></author></authors><title>SArF Map: Visualizing Software Architecture from Feature and Layer
  Viewpoints</title><categories>cs.SE</categories><comments>10 pages, 16 figures, 2 tables. This is the accepted version of a
  paper presented at the 21st IEEE International Conference on Program
  Comprehension (ICPC2013), San Francisco, CA, USA, May 2013, pp.43-52</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To facilitate understanding the architecture of a software system, we
developed SArF Map technique that visualizes software architecture from feature
and layer viewpoints using a city metaphor. SArF Map visualizes implicit
software features using our previous study, SArF dependency-based software
clustering algorithm. Since features are high-level abstraction units of
software, a generated map can be directly used for high-level decision making
such as reuse and also for communications between developers and non-developer
stakeholders. In SArF Map, each feature is visualized as a city block, and
classes in the feature are laid out as buildings reflecting their software
layer. Relevance between features is represented as streets. Dependency links
are visualized lucidly. Through open source and industrial case studies, we
show that the architecture of the target systems can be easily overviewed and
that the quality of their packaging designs can be quickly assessed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0963</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0963</id><created>2013-06-04</created><authors><author><keyname>Kim</keyname><forenames>Been</forenames></author><author><keyname>Chacha</keyname><forenames>Caleb M.</forenames></author><author><keyname>Shah</keyname><forenames>Julie</forenames></author></authors><title>Inferring Robot Task Plans from Human Team Meetings: A Generative
  Modeling Approach with Logic-Based Prior</title><categories>cs.AI cs.CL cs.RO stat.ML</categories><comments>Appears in Proceedings of the Twenty-Seventh AAAI Conference on
  Artificial Intelligence (AAAI-13)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We aim to reduce the burden of programming and deploying autonomous systems
to work in concert with people in time-critical domains, such as military field
operations and disaster response. Deployment plans for these operations are
frequently negotiated on-the-fly by teams of human planners. A human operator
then translates the agreed upon plan into machine instructions for the robots.
We present an algorithm that reduces this translation burden by inferring the
final plan from a processed form of the human team's planning conversation. Our
approach combines probabilistic generative modeling with logical plan
validation used to compute a highly structured prior over possible plans. This
hybrid approach enables us to overcome the challenge of performing inference
over the large solution space with only a small amount of noisy data from the
team planning session. We validate the algorithm through human subject
experimentation and show we are able to infer a human team's final plan with
83% accuracy on average. We also describe a robot demonstration in which two
people plan and execute a first-response collaborative task with a PR2 robot.
To the best of our knowledge, this is the first work that integrates a logical
planning technique within a generative model to perform plan inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0968</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0968</id><created>2013-06-04</created><authors><author><keyname>Wang</keyname><forenames>Taotao</forenames></author><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author><author><keyname>Gao</keyname><forenames>Hui</forenames></author><author><keyname>Lu</keyname><forenames>Yueming</forenames></author></authors><title>BER Analysis of Decision-Feedback Multiple Symbol Detection in
  Noncoherent MIMO Ultra-Wideband Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, accepted by IEEE TVT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate noncoherent multiple-input multiple-output
(MIMO) ultra-wideband (UWB) systems where the signal is encoded by differential
space-time block code (DSTBC). DSTBC enables noncoherent MIMO UWB systems to
achieve diversity gain. However, the traditional noncoherent symbol-by-symbol
differential detection (DD) for DSTBC-UWB suffers from performance degradation
compared with the coherent detection. We introduce a noncoherent multiple
symbol detection (MSD) scheme to enhance the performance of DSTBC-UWB system.
Although the MSD scheme can boost the performance more as the observation
window size gets to larger, the complexity of the exhaustive search for MSD
also exponentially increases in terms of the window size. To decrease the
computational complexity, the concept of decision-feedback (DF) is introduced
to MSD for DSTBC-UWB in this paper. The resultant DF-MSD yields reasonable
complexity and also solid performance improvement. We provide the bit error
rate (BER) analysis for the proposed DF-MSD. Both theoretical analysis and
simulation results validate the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0969</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0969</id><created>2013-06-04</created><updated>2013-07-30</updated><authors><author><keyname>Liu</keyname><forenames>Liang</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Chua</keyname><forenames>K. C.</forenames></author></authors><title>Secrecy Wireless Information and Power Transfer with MISO Beamforming</title><categories>cs.IT math.IT</categories><comments>accepted by the IEEE Global Communications Conference 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dual use of radio signals for simultaneous wireless information and power
transfer (SWIPT) has recently drawn significant attention. To meet the
practical requirement that energy receivers (ERs) operate with much higher
received power than information receivers (IRs), ERs need to be deployed closer
to the transmitter than IRs. However, due to the broadcast nature of wireless
channels, one critical issue is that the messages sent to IRs cannot be
eavesdropped by ERs, which possess better channels from the transmitter. In
this paper, we address this new secrecy communication problem in a multiuser
multiple-input single-output (MISO) SWIPT system where a multi-antenna
transmitter sends information and energy simultaneously to one IR and multiple
ERs, each with a single antenna. By optimizing transmit beamforming vectors and
their power allocation, we maximize the weighted sum-energy transferred to ERs
subject to a secrecy rate constraint for the information sent to the IR. We
solve this non-convex problem optimally by reformulating it into a two-stage
problem. First, we fix the signal-to-interference-plus-noise ratio (SINR) at
the IR and obtain the optimal beamforming solution by applying the technique of
semidefinite relaxation (SDR). Then the original problem is solved by a
one-dimension search over the optimal SINR value for the IR. Furthermore, two
suboptimal low-complexity beamforming schemes are proposed, and their
achievable (secrecy) rate-energy (R-E) regions are compared against that by the
optimal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0974</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0974</id><created>2013-06-04</created><authors><author><keyname>Wan</keyname><forenames>Jiuqing</forenames></author><author><keyname>Liu</keyname><forenames>Li</forenames></author></authors><title>Distributed Bayesian inference for consistent labeling of tracked
  objects in non-overlapping camera networks</title><categories>cs.CV</categories><comments>19 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental requirements for visual surveillance using
non-overlapping camera networks is the correct labeling of tracked objects on
each camera in a consistent way,in the sense that the captured tracklets, or
observations in this paper, of the same object at different cameras should be
assigned with the same label. In this paper, we formulate this task as a
Bayesian inference problem and propose a distributed inference framework in
which the posterior distribution of labeling variable corresponding to each
observation, conditioned on all history appearance and spatio-temporal evidence
made in the whole networks, is calculated based solely on local information
processing on each camera and mutual information exchanging between neighboring
cameras. In our framework, the number of objects presenting in the monitored
region, i.e. the sampling space of labeling variables, does not need to be
specified beforehand. Instead, it can be determined automatically on the fly.
In addition, we make no assumption about the appearance distribution of a
single object, but use similarity scores between appearance pairs, given by
advanced object re-identification algorithm, as appearance likelihood for
inference. This feature makes our method very flexible and competitive when
observing condition undergoes large changes across camera views. To cope with
the problem of missing detection, which is critical for distributed inference,
we consider an enlarged neighborhood of each camera during inference and use a
mixture model to describe the higher order spatio-temporal constraints. The
robustness of the algorithm against missing detection is improved at the cost
of slightly increased computation and communication burden at each camera node.
Finally, we demonstrate the effectiveness of our method through experiments on
an indoor Office Building dataset and an outdoor Campus Garden dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0992</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0992</id><created>2013-06-05</created><authors><author><keyname>Ballico</keyname><forenames>Edoardo</forenames></author></authors><title>Any network codes comes from an algebraic curve taking osculating spaces</title><categories>math.AG cs.IT math.IT</categories><comments>preprint version; final version on Design, Codes and Cryptography</comments><msc-class>14H50, 14N05, 94B27</msc-class><doi>10.1007/s10623-013-9841-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we prove that every network code over $\mathbb {F}_q$ may be
realized taking some of the osculating spaces of a smooth projective curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.0996</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.0996</id><created>2013-06-05</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>KamiWaAi - Interactive 3D Sketching with Java Based on Cl(4,1) Conformal
  Model of Euclidean Space</title><categories>cs.CG math.RA</categories><comments>21 pages, 2 figures, 11 tables</comments><journal-ref>Advances in Applied Clifford Algebras, Volume 13, Issue 1 , pp
  11-45 (2003)</journal-ref><doi>10.1007/s00006-003-0004-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the new interactive Java sketching software KamiWaAi,
recently developed at the University of Fukui. Its graphical user interface
enables the user without any knowledge of both mathematics or computer science,
to do full three dimensional &quot;drawings&quot; on the screen. The resulting
constructions can be reshaped interactively by dragging its points over the
screen. The programming approach is new. KamiWaAi implements geometric objects
like points, lines, circles, spheres, etc. directly as software objects (Java
classes) of the same name. These software objects are geometric entities
mathematically defined and manipulated in a conformal geometric algebra,
combining the five dimensions of origin, three space and infinity. Simple
geometric products in this algebra represent geometric unions, intersections,
arbitrary rotations and translations, projections, distance, etc. To ease the
coordinate free and matrix free implementation of this fundamental geometric
product, a new algebraic three level approach is presented. Finally details
about the Java classes of the new GeometricAlgebra software package and their
associated methods are given. KamiWaAi is available for free internet download.
  Key Words: Geometric Algebra, Conformal Geometric Algebra, Geometric Calculus
Software, GeometricAlgebra, Java Package, Interactive 3D Software, Geometric
Objects
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1023</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1023</id><created>2013-06-05</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>Quaternion Fourier Transform on Quaternion Fields and Generalizations</title><categories>math.RA cs.CV math-ph math.MP</categories><comments>21 pages</comments><msc-class>Primary 42A38, Secondary 11R52</msc-class><journal-ref>Advances in Applied Clifford Algebras, olume 17, Issue 3 , pp.
  497-517 (2007)</journal-ref><doi>10.1007/s00006-007-0037-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We treat the quaternionic Fourier transform (QFT) applied to quaternion
fields and investigate QFT properties useful for applications. Different forms
of the QFT lead us to different Plancherel theorems. We relate the QFT
computation for quaternion fields to the QFT of real signals. We research the
general linear ($GL$) transformation behavior of the QFT with matrices,
Clifford geometric algebra and with examples. We finally arrive at wide-ranging
non-commutative multivector FT generalizations of the QFT. Examples given are
new volume-time and spacetime algebra Fourier transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1031</identifier>
 <datestamp>2014-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1031</id><created>2013-06-05</created><updated>2014-04-30</updated><authors><author><keyname>Kotthoff</keyname><forenames>Lars</forenames></author></authors><title>LLAMA: Leveraging Learning to Automatically Manage Algorithms</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithm portfolio and selection approaches have achieved remarkable
improvements over single solvers. However, the implementation of such systems
is often highly customised and specific to the problem domain. This makes it
difficult for researchers to explore different techniques for their specific
problems. We present LLAMA, a modular and extensible toolkit implemented as an
R package that facilitates the exploration of a range of different portfolio
techniques on any problem domain. It implements the algorithm selection
approaches most commonly used in the literature and leverages the extensive
library of machine learning algorithms and techniques in R. We describe the
current capabilities and limitations of the toolkit and illustrate its usage on
a set of example SAT problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1034</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1034</id><created>2013-06-05</created><authors><author><keyname>Bhatt</keyname><forenames>Mehul</forenames></author><author><keyname>Suchan</keyname><forenames>Jakob</forenames></author><author><keyname>Freksa</keyname><forenames>Christian</forenames></author></authors><title>ROTUNDE - A Smart Meeting Cinematography Initiative: Tools, Datasets,
  and Benchmarks for Cognitive Interpretation and Control</title><categories>cs.AI cs.CV cs.HC</categories><comments>Appears in AAAI-2013 Workshop on: Space, Time, and Ambient
  Intelligence (STAMI 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construe smart meeting cinematography with a focus on professional
situations such as meetings and seminars, possibly conducted in a distributed
manner across socio-spatially separated groups. The basic objective in smart
meeting cinematography is to interpret professional interactions involving
people, and automatically produce dynamic recordings of discussions, debates,
presentations etc in the presence of multiple communication modalities. Typical
modalities include gestures (e.g., raising one's hand for a question,
applause), voice and interruption, electronic apparatus (e.g., pressing a
button), movement (e.g., standing-up, moving around) etc. ROTUNDE, an instance
of smart meeting cinematography concept, aims to: (a) develop
functionality-driven benchmarks with respect to the interpretation and control
capabilities of human-cinematographers, real-time video editors, surveillance
personnel, and typical human performance in everyday situations; (b) Develop
general tools for the commonsense cognitive interpretation of dynamic scenes
from the viewpoint of visuo-spatial cognition centred perceptual
narrativisation. Particular emphasis is placed on declarative representations
and interfacing mechanisms that seamlessly integrate within large-scale
cognitive (interaction) systems and companion technologies consisting of
diverse AI sub-components. For instance, the envisaged tools would provide
general capabilities for high-level commonsense reasoning about space, events,
actions, change, and interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1036</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1036</id><created>2013-06-05</created><authors><author><keyname>B&#xf6;nisch</keyname><forenames>Sebastian</forenames></author><author><keyname>Brickenstein</keyname><forenames>Michael</forenames></author><author><keyname>Chrapary</keyname><forenames>Hagen</forenames></author><author><keyname>Greuel</keyname><forenames>Gert-Martin</forenames></author><author><keyname>Sperber</keyname><forenames>Wolfram</forenames></author></authors><title>swMATH - a new information service for mathematical software</title><categories>cs.DL cs.MS</categories><comments>see also: http://www.swmath.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information service for mathematical software is presented. Publications
and software are two closely connected facets of mathematical knowledge. This
relation can be used to identify mathematical software and find relevant
information about it. The approach and the state of the art of the information
service are described here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1057</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1057</id><created>2013-06-05</created><authors><author><keyname>Koliander</keyname><forenames>G&#xfc;nther</forenames></author><author><keyname>Riegler</keyname><forenames>Erwin</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author></authors><title>Generic Correlation Increases Noncoherent MIMO Capacity</title><categories>cs.IT math.IT</categories><comments>To be presented at IEEE Int. Symp. Inf. Theory (ISIT) 2013, Istanbul,
  Turkey</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the high-SNR capacity of MIMO Rayleigh block-fading channels in the
noncoherent setting where neither transmitter nor receiver has a priori channel
state information. We show that when the number of receive antennas is
sufficiently large and the temporal correlation within each block is &quot;generic&quot;
(in the sense used in the interference-alignment literature), the capacity
pre-log is given by T(1-1/N) for T&lt;N, where T denotes the number of transmit
antennas and N denotes the block length. A comparison with the widely used
constant block-fading channel (where the fading is constant within each block)
shows that for a large block length, generic correlation increases the capacity
pre-log by a factor of about four.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1066</identifier>
 <datestamp>2015-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1066</id><created>2013-06-05</created><updated>2015-07-11</updated><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Nelson</keyname><forenames>Blaine</forenames></author><author><keyname>Zhang</keyname><forenames>and Zuhe</forenames></author><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin</forenames></author></authors><title>Differential Privacy in a Bayesian setting through posterior sampling</title><categories>stat.ML cs.LG</categories><comments>27 pages; An earlier version of this article was published in ALT
  2014. This version has corrections and additional results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the robustness and privacy properties of Bayesian inference, under
assumptions on the prior. With no modifications to the Bayesian framework, we
show that a simple posterior sampling algorithm results in uniform utility and
privacy guarantees. In more detail, we generalise the concept of differential
privacy to arbitrary dataset distances, outcome spaces and distribution
families. We then prove bounds on the robustness of the posterior, introduce a
posterior sampling mechanism, show that it is differentially private and
provide finite sample bounds for distinguishability-based privacy under a
strong adversarial model. Finally, we give examples satisfying our assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1068</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1068</id><created>2013-06-05</created><authors><author><keyname>Kaur</keyname><forenames>Rupinder</forenames></author><author><keyname>Sengupta</keyname><forenames>Jyotsna</forenames></author></authors><title>Software Process Models and Analysis on Failure of Software Development
  Projects</title><categories>cs.SE</categories><journal-ref>IJSER, Volume 2, Issue 2, February 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The software process model consists of a set of activities undertaken to
design, develop and maintain software systems. A variety of software process
models have been designed to structure, describe and prescribe the software
development process. The software process models play a very important role in
software development, so it forms the core of the software product. Software
project failure is often devastating to an organization. Schedule slips, buggy
releases and missing features can mean the end of the project or even financial
ruin for a company. Oddly, there is disagreement over what it means for a
project to fail. In this paper, discussion is done on current process models
and analysis on failure of software development, which shows the need of new
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1069</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1069</id><created>2013-06-05</created><authors><author><keyname>Heu&#xdf;ner</keyname><forenames>Alexander</forenames></author><author><keyname>Kartzow</keyname><forenames>Alexander</forenames></author></authors><title>Reachability in Higher-Order-Counters</title><categories>cs.FL</categories><comments>Version with Full Proofs of a paper that appears at MFCS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order counter automata (\HOCS) can be either seen as a restriction of
higher-order pushdown automata (\HOPS) to a unary stack alphabet, or as an
extension of counter automata to higher levels. We distinguish two principal
kinds of \HOCS: those that can test whether the topmost counter value is zero
and those which cannot.
  We show that control-state reachability for level $k$ \HOCS with $0$-test is
complete for \mbox{$(k-2)$}-fold exponential space; leaving out the $0$-test
leads to completeness for \mbox{$(k-2)$}-fold exponential time. Restricting
\HOCS (without $0$-test) to level $2$, we prove that global (forward or
backward) reachability analysis is $\PTIME$-complete. This enhances the known
result for pushdown systems which are subsumed by level $2$ \HOCS without
$0$-test.
  We transfer our results to the formal language setting. Assuming that $\PTIME
\subsetneq \PSPACE \subsetneq \mathbf{EXPTIME}$, we apply proof ideas of
Engelfriet and conclude that the hierarchies of languages of \HOPS and of \HOCS
form strictly interleaving hierarchies. Interestingly, Engelfriet's
constructions also allow to conclude immediately that the hierarchy of
collapsible pushdown languages is strict level-by-level due to the existing
complexity results for reachability on collapsible pushdown graphs. This
answers an open question independently asked by Parys and by Kobayashi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1073</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1073</id><created>2013-06-05</created><authors><author><keyname>Haslhofer</keyname><forenames>Bernhard</forenames></author><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Web Synchronization Simulations using the ResourceSync Framework</title><categories>cs.DL cs.DB</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintenance of multiple, distributed up-to-date copies of collections of
changing Web resources is important in many application contexts and is often
achieved using ad hoc or proprietary synchronization solutions. ResourceSync is
a resource synchronization framework that integrates with the Web architecture
and leverages XML sitemaps. We define a model for the ResourceSync framework as
a basis for understanding its properties. We then describe experiments in which
simulations of a variety of synchronization scenarios illustrate the effects of
model configuration on consistency, latency, and data transfer efficiency.
These results provide insight into which congurations are appropriate for
various application scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1076</identifier>
 <datestamp>2015-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1076</id><created>2013-06-05</created><updated>2015-01-15</updated><authors><author><keyname>Yun</keyname><forenames>Se-Young</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author></authors><title>CSMA using the Bethe Approximation: Scheduling and Utility Maximization</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CSMA (Carrier Sense Multiple Access), which resolves contentions over
wireless networks in a fully distributed fashion, has recently gained a lot of
attentions since it has been proved that appropriate control of CSMA parameters
guarantees optimality in terms of stability (i.e., scheduling) and system- wide
utility (i.e., scheduling and congestion control). Most CSMA-based algorithms
rely on the popular MCMC (Markov Chain Monte Carlo) technique, which enables
one to find optimal CSMA parameters through iterative loops of
`simulation-and-update'. However, such a simulation-based approach often
becomes a major cause of exponentially slow convergence, being poorly adaptive
to flow/topology changes. In this paper, we develop distributed iterative
algorithms which produce approximate solutions with convergence in polynomial
time for both stability and utility maximization problems. In particular, for
the stability problem, the proposed distributed algorithm requires, somewhat
surprisingly, only one iteration among links. Our approach is motivated by the
Bethe approximation (introduced by Yedidia, Freeman and Weiss in 2005) allowing
us to express approximate solutions via a certain non-linear system with
polynomial size. Our polynomial convergence guarantee comes from directly
solving the non-linear system in a distributed manner, rather than multiple
simulation-and-update loops in existing algorithms. We provide numerical
results to show that the algorithm produces highly accurate solutions and
converges much faster than the prior ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1083</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1083</id><created>2013-06-05</created><authors><author><keyname>Baudin</keyname><forenames>Pierre-Yves</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Goodman</keyname><forenames>Danny</forenames><affiliation>INRIA Saclay - Ile de France, CVN</affiliation></author><author><keyname>Kumar</keyname><forenames>Puneet</forenames><affiliation>INRIA Saclay - Ile de France, CVN</affiliation></author><author><keyname>Azzabou</keyname><forenames>Noura</forenames><affiliation>MIRCEN, UPMC</affiliation></author><author><keyname>Carlier</keyname><forenames>Pierre G.</forenames><affiliation>UPMC</affiliation></author><author><keyname>Paragios</keyname><forenames>Nikos</forenames><affiliation>INRIA Saclay - Ile de France, LIGM, ENPC, MAS</affiliation></author><author><keyname>Kumar</keyname><forenames>M. Pawan</forenames><affiliation>INRIA Saclay - Ile de France, CVN</affiliation></author></authors><title>Discriminative Parameter Estimation for Random Walks Segmentation:
  Technical Report</title><categories>cs.CV cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use
probabilistic segmentation methods. By combining contrast terms with prior
terms, it provides accurate segmentations of medical images in a fully
automated manner. However, one of the main drawbacks of using the RW algorithm
is that its parameters have to be hand-tuned. we propose a novel discriminative
learning framework that estimates the parameters using a training dataset. The
main challenge we face is that the training samples are not fully supervised.
Speci cally, they provide a hard segmentation of the images, instead of a
proba-bilistic segmentation. We overcome this challenge by treating the optimal
probabilistic segmentation that is compatible with the given hard segmentation
as a latent variable. This allows us to employ the latent support vector
machine formulation for parameter estimation. We show that our approach signi
cantly outperforms the baseline methods on a challenging dataset consisting of
real clinical 3D MRI volumes of skeletal muscles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1091</identifier>
 <datestamp>2014-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1091</id><created>2013-06-05</created><updated>2014-05-23</updated><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Thibodeau-Laufer</keyname><forenames>&#xc9;ric</forenames></author><author><keyname>Alain</keyname><forenames>Guillaume</forenames></author><author><keyname>Yosinski</keyname><forenames>Jason</forenames></author></authors><title>Deep Generative Stochastic Networks Trainable by Backprop</title><categories>cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1305.0445, Also published
  in ICML'2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel training principle for probabilistic models that is an
alternative to maximum likelihood. The proposed Generative Stochastic Networks
(GSN) framework is based on learning the transition operator of a Markov chain
whose stationary distribution estimates the data distribution. The transition
distribution of the Markov chain is conditional on the previous state,
generally involving a small move, so this conditional distribution has fewer
dominant modes, being unimodal in the limit of small moves. Thus, it is easier
to learn because it is easier to approximate its partition function, more like
learning to perform supervised function approximation, with gradients that can
be obtained by backprop. We provide theorems that generalize recent work on the
probabilistic interpretation of denoising autoencoders and obtain along the way
an interesting justification for dependency networks and generalized
pseudolikelihood, along with a definition of an appropriate joint distribution
and sampling mechanism even when the conditionals are not consistent. GSNs can
be used with missing inputs and can be used to sample subsets of variables
given the rest. We validate these theoretical results with experiments on two
image datasets using an architecture that mimics the Deep Boltzmann Machine
Gibbs sampler but allows training to proceed with simple backprop, without the
need for layerwise pretraining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1097</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1097</id><created>2013-06-05</created><authors><author><keyname>Batenkov</keyname><forenames>Dmitry</forenames></author><author><keyname>Yomdin</keyname><forenames>Yosef</forenames></author></authors><title>Algebraic signal sampling, Gibbs phenomenon and Prony-type systems</title><categories>math.NA cs.IT math.CA math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Systems of Prony type appear in various signal reconstruction problems such
as finite rate of innovation, superresolution and Fourier inversion of
piecewise smooth functions. We propose a novel approach for solving Prony-type
systems, which requires sampling the signal at arithmetic progressions. By
keeping the number of equations small and fixed, we demonstrate that such
&quot;decimation&quot; can lead to practical improvements in the reconstruction accuracy.
As an application, we provide a solution to the so-called Eckhoff's conjecture,
which asked for reconstructing jump positions and magnitudes of a
piecewise-smooth function from its Fourier coefficients with maximal possible
asymptotic accuracy -- thus eliminating the Gibbs phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1101</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1101</id><created>2013-06-05</created><authors><author><keyname>Liu</keyname><forenames>Shuiyin</forenames></author><author><keyname>Hong</keyname><forenames>Yi</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author></authors><title>Practical Secrecy using Artificial Noise</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Communications Letters, 2013, 10 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the use of artificial noise for secure
communications. We propose the notion of practical secrecy as a new design
criterion based on the behavior of the eavesdropper's error probability $P_E$,
as the signal-to-noise ratio goes to infinity. We then show that the practical
secrecy can be guaranteed by the randomly distributed artificial noise with
specified power. We show that it is possible to achieve practical secrecy even
when the eavesdropper can afford more antennas than the transmitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1102</identifier>
 <datestamp>2013-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1102</id><created>2013-06-05</created><updated>2013-07-04</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author></authors><title>Detectability of communities in heterogeneous networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>6 pages, 5 figures, accepted for publication in Physical Review E</comments><journal-ref>Phys. Rev. E 88, 010801(R) (2013)</journal-ref><doi>10.1103/PhysRevE.88.010801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communities are fundamental entities for the characterization of the
structure of real networks. The standard approach to the identification of
communities in networks is based on the optimization of a quality function
known as &quot;modularity&quot;. Although modularity has been at the center of an intense
research activity and many methods for its maximization have been proposed, not
much it is yet known about the necessary conditions that communities need to
satisfy in order to be detectable with modularity maximization methods. Here,
we develop a simple theory to establish these conditions, and we successfully
apply it to various classes of network models. Our main result is that
heterogeneity in the degree distribution helps modularity to correctly recover
the community structure of a network and that, in the realistic case of
scale-free networks with degree exponent $\gamma &lt; 2.5$, modularity is always
able to detect the presence of communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1110</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1110</id><created>2013-06-05</created><updated>2013-09-27</updated><authors><author><keyname>Laciana</keyname><forenames>Carlos E.</forenames></author><author><keyname>Aguirre</keyname><forenames>Nicolas Oteiza</forenames></author></authors><title>An agent based multi-optional model for the diffusion of innovations</title><categories>stat.AP cs.SI physics.soc-ph</categories><comments>This article was accepted for publication at Physica A. Publication
  Reference: PHYSA-13-139R1</comments><doi>10.1016/j.physa.2013.09.046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model for the diffusion of several products competing in a
common market based on the generalization of the Ising model of statiscal
mechanics (Potts model). Using an agent based implementation, we analyze two
problems: (i) a three options case, i.e. to adopt a product A, a product B, or
non-adoption and (ii) a four options case, i.e. the adoption of product A,
product B, both, or none. In the first case we analyze a launching strategy for
one of the two products, which delays its launching with the objective of
competing with improvements. Market shares reached by each product are then
estimated at market saturation. Finally, simulations are carried out with
varying degrees of social network topology, uncertainty, and population
homogeneity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1113</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1113</id><created>2013-05-25</created><updated>2013-10-22</updated><authors><author><keyname>Ganzha</keyname><forenames>Elena I.</forenames></author></authors><title>Intertwining Laplace Transformations of Linear Partial Differential
  Equations</title><categories>math.AP cs.SC</categories><comments>LaTeX, 25 pages v2: minor misprints corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generalization of Laplace transformations to the case of linear
partial differential operators (LPDOs) of arbitrary order in R^n. Practically
all previously proposed differential transformations of LPDOs are particular
cases of this transformation (intertwining Laplace transformation, ILT). We
give a complete algorithm of construction of ILT and describe the classes of
operators in R^n suitable for this transformation.
  Keywords: Integration of linear partial differential equations, Laplace
transformation, differential transformation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1114</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1114</id><created>2013-05-25</created><authors><author><keyname>Shitov</keyname><forenames>Yaroslav</forenames></author></authors><title>On the complexity of Boolean matrix ranks</title><categories>math.CO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a reduction which proves that the fooling set number and the
determinantal rank of a Boolean matrix are NP-hard to compute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1128</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1128</id><created>2013-06-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Arithmetic Algorithms for Hereditarily Binary Natural Numbers</title><categories>cs.DS cs.DM cs.MS</categories><comments>unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study some essential arithmetic properties of a new tree-based number
representation, {\em hereditarily binary numbers}, defined by applying
recursively run-length encoding of bijective base-2 digits.
  Our representation expresses giant numbers like the largest known prime
number and its related perfect number as well as the largest known Woodall,
Cullen, Proth, Sophie Germain and twin primes as trees of small sizes.
  More importantly, our number representation supports novel algorithms that,
in the best case, collapse the complexity of various computations by
super-exponential factors and in the worse case are within a constant factor of
their traditional counterparts.
  As a result, it opens the door to a new world, where arithmetic operations
are limited by the structural complexity of their operands, rather than their
bitsizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1134</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1134</id><created>2013-06-05</created><authors><author><keyname>Ullah</keyname><forenames>M. N.</forenames></author><author><keyname>Mahmood</keyname><forenames>A.</forenames></author><author><keyname>Razzaq</keyname><forenames>S.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author></authors><title>A Survey of Different Residential Energy Consumption Controlling
  Techniques for Autonomous DSM in Future Smart Grid Communications</title><categories>cs.NI</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(3)1207-1214, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a survey of residential load controlling techniques
to implement demand side management in future smart grid. Power generation
sector facing important challenges both in quality and quantity to meet the
increasing requirements of consumers. Energy efficiency, reliability, economics
and integration of new energy resources are important issues to enhance the
stability of power system infrastructure. Optimal energy consumption scheduling
minimizes the energy consumption cost and reduce the peak-to-average ratio
(PAR) as well as peak load demand in peak hours. In this work, we discuss
different energy consumption scheduling schemes that schedule the household
appliances in real-time to achieve minimum energy consumption cost and reduce
peak load curve in peak hours to shape the peak load demand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1137</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1137</id><created>2013-06-05</created><authors><author><keyname>Khan</keyname><forenames>I.</forenames></author><author><keyname>Mahmood</keyname><forenames>A.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Razzaq</keyname><forenames>S.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author></authors><title>Home Energy Management Systems in Future Smart Grids</title><categories>cs.NI</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(3)1224-1231, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a detailed review of various Home Energy Management Schemes
(HEM,s). HEM,s will increase savings, reduce peak demand and Pto Average Ratio
(PAR). Among various applications of smart grid technologies, home energy
management is probably the most important one to be addressed. Various steps
have been taken by utilities for efficient energy consumption.New pricing
schemes like Time of Use (ToU), Real Time Pricing (RTP), Critical Peak Pricing
(CPP), Inclining Block Rates (IBR) etc have been been devised for future smart
grids.Home appliances and/or distributed energy resources coordination (Local
Generation) along with different pricing schemes leads towards efficient energy
consumption. This paper addresses various communication and optimization based
residential energy management schemes and different communication and
networking technologies involved in these schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1138</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1138</id><created>2013-06-03</created><authors><author><keyname>Egri-Nagy</keyname><forenames>Attila</forenames></author><author><keyname>Nehaniv</keyname><forenames>Chrystopher L.</forenames></author></authors><title>Compact Notation for Finite Transformations</title><categories>math.GR cs.FL</categories><comments>7 pages, 4 figures, compact notation implemented in SgpDec
  http://sgpdec.sf.net</comments><msc-class>20M20</msc-class><acm-class>D.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new notation for finite transformations. This compact notation
extends the orbit-cycle notation for permutations and builds upon existing
notations. It gives insight into the structure of transformations and reduces
the length of expressions without increasing the number of types of symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1140</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1140</id><created>2013-06-05</created><authors><author><keyname>Ishfaq</keyname><forenames>Mohammad</forenames></author><author><keyname>Qadri</keyname><forenames>Faran Ahmad</forenames></author><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author></authors><title>Preventive Care Resource Allocation in Developing Countries: Can
  Rational Planning Techniques Help in Allocating Vaccinators in Dera Ismail
  Khan District of Pakistan?</title><categories>cs.CY</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(4)1021-1026, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preventive care service delivery faces immense challenges when it comes to
the level of coverage. Within this context, the case of child immunization is
presented by applying operations management tools. This paper explores the
application of integer programming techniques to support the Expanded Programme
of Immunization (EPI) service in the Dera Ismail Khan District of Pakistan. The
main concern here is equitable service delivery to decentralized localities
based on two criteria: (1) achieving the highest possible level of vaccination
among the target population; and 2) ensuring equality among geographically
scattered populations, especially in rural dwellings. For this purpose two
integer programming models have been applied on the basis of (1) sub-dividing
health district into localities and allocating vaccinators to visit and
vaccinate children within their administrative boundaries, and (2) within the
localized planning system allowing vaccinators to visit and vaccinate children
across the administrative boundaries subject to savings in travel time. Both
models show interesting results in terms of need satisfaction and travel-time
savings with a minimum level of deviation from equity. The solutions provide a
trade-off between alternative organizational tactics, and the argument is made
that rational planning methods applied interactively can contribute to the
delivery of an immunization service that is equitable and cost effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1144</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1144</id><created>2013-06-05</created><authors><author><keyname>Zohaib</keyname><forenames>M.</forenames></author><author><keyname>Pasha</keyname><forenames>M.</forenames></author><author><keyname>Riaz</keyname><forenames>R. A.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author></authors><title>Control Strategies for Mobile Robot With Obstacle Avoidance</title><categories>cs.RO</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(4)1027-1036, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obstacle avoidance is an important task in the field of robotics, since the
goal of autonomous robot is to reach the destination without collision. Several
algorithms have been proposed for obstacle avoidance, having drawbacks and
benefits. In this survey paper, we mainly discussed different algorithms for
robot navigation with obstacle avoidance. We also compared all provided
algorithms and mentioned their characteristics; advantages and disadvantages,
so that we can select final efficient algorithm by fusing discussed algorithms.
Comparison table is provided for justifying the area of interest
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1146</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1146</id><created>2013-06-05</created><authors><author><keyname>Iqbal</keyname><forenames>A.</forenames></author><author><keyname>Akbar</keyname><forenames>M.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Bouk</keyname><forenames>S. H.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author></authors><title>Advanced LEACH: A Static Clustering-based Heteroneous Routing Protocol
  for WSNs</title><categories>cs.NI</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(5)864-872, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensors Networks (WSNs) have a big application in heterogeneous
networks. In this paper, we propose and evaluate Advanced Low-Energy Adaptive
Clustering Hierarchy (Ad-LEACH) which is static clustering based heterogeneous
routing protocol. The complete network field is first divided into static
clusters and then in each cluster separate Ad-LEACH protocol is applied. Our
proposed protocol is inherited from LEACH with a cluster head selection
criteria of Distributed Energy-Efficient Clustering (DEEC). This enables
Ad-LEACH to cope with the heterogeneous nature of nodes. Due to small static
clusters, each node reduces its broadcast message power because it only has to
cover a small area. We perform simulations in MATLAB to check the efficiency of
Ad-LEACH. The Simulation results show that Ad-LEACH outperforms LEACH and DEEC
in energy efficiency as well as throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1148</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1148</id><created>2013-06-05</created><authors><author><keyname>Ahmed</keyname><forenames>S.</forenames></author><author><keyname>Khan</keyname><forenames>I. U.</forenames></author><author><keyname>Rasheed</keyname><forenames>M. B.</forenames></author><author><keyname>Ilahi</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>R. D.</forenames></author><author><keyname>Bouk</keyname><forenames>S. H.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author></authors><title>Comparative Analysis of Routing Protocols for Under Water Wireless
  Sensor Networks</title><categories>cs.NI</categories><journal-ref>J. Basic. Appl. Sci. Res., 3(6)130-147, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underwater Wireless Sensor Networks are significantly different from
terrestrial sensor networks due to peculiar characteristics of low bandwidth,
high latency, limited energy, node float mobility and high error probability.
These features bring many challenges to the network protocol design of UWSNs.
Several routing protocols have been developed in recent years for these
networks. One of the major difficulties in comparison and validation of the
performance of these proposals is the lack of a common standard to model the
acoustic propagation in the harsh underwater environment. In this paper we
analyze the evolution of certain underwater routing protocols like VBF, DBR,
H2-DAB, QELAR etc. in terms of their localization techniques, energy
minimization characteristics and holding time calculations. The design of each
protocol follows certain goals i.e. reduction of energy consumption,
improvement of communication latency, achievement of robustness and scalability
etc. This paper examines the main approaches and challenges in the design and
implementation of underwater sensor networks. The detailed descriptions of the
selected protocols contribute in understanding the direction of the current
research on routing layer in UWSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1149</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1149</id><created>2013-06-05</created><updated>2013-07-07</updated><authors><author><keyname>Ma</keyname><forenames>Will</forenames></author></authors><title>Improvements and Generalizations of Stochastic Knapsack and Multi-Armed
  Bandit Approximation Algorithms: Full Version</title><categories>cs.DS</categories><comments>33 pages, full version of conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multi-armed bandit (MAB) problem features the classical tradeoff between
exploration and exploitation. The input specifies several stochastic arms which
evolve with each pull, and the goal is to maximize the expected reward after a
fixed budget of pulls. The celebrated work of Gittins et al. [GGW89] presumes a
condition on the arms called the martingale assumption. Recently, A. Gupta et
al. obtained an LP-based 1/48-approximation for the problem with the martingale
assumption removed [GKMR11]. We improve the algorithm to a 4/27-approximation,
with simpler analysis. Our algorithm also generalizes to the case of MAB
superprocesses with (stochastic) multi-period actions. This generalization
captures the framework introduced by Guha and Munagala in [GM07a, GM07b], and
yields new results for their budgeted learning problems.
  Also, we obtain a (1/2-eps)-approximation for the variant of MAB where
preemption (playing an arm, switching to another arm, then coming back to the
first arm) is not allowed. This contains the stochastic knapsack problem of
Dean, Goemans, and Vondrak [DGV08] with correlated rewards, where we are given
a knapsack of fixed size, a set of jobs each with a joint distribution for its
size and reward, and the objective is to maximize expected reward before the
knapsack size is exhausted. Our (1/2-eps)-approximation improves the 1/16 and
1/8 approximations of [GKMR11] for correlated stochastic knapsack with
cancellation and no cancellation, respectively, providing the first tight
algorithm for these problems that matches the integrality gap of 2. We sample
probabilities from an exponential-sized dynamic programming solution, whose
existence is guaranteed by an LP projection argument. We hope this technique
can also be applied to other dynamic programming problems which can be
projected down onto a small LP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1153</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1153</id><created>2013-06-05</created><authors><author><keyname>Zhu</keyname><forenames>Andy Diwen</forenames></author><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Wang</keyname><forenames>Sibo</forenames></author><author><keyname>Lin</keyname><forenames>Wenqing</forenames></author></authors><title>Efficient Single-Source Shortest Path and Distance Queries on Large
  Graphs</title><categories>cs.DB cs.DS</categories><comments>To appear in KDD 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates two types of graph queries: {\em single source
distance (SSD)} queries and {\em single source shortest path (SSSP)} queries.
Given a node $v$ in a graph $G$, an SSD query from $v$ asks for the distance
from $v$ to any other node in $G$, while an SSSP query retrieves the shortest
path from $v$ to any other node. These two types of queries are fundamental
building blocks of numerous graph algorithms, and they find important
applications in graph analysis, especially in the computation of graph
measures. Most of the existing solutions for SSD and SSSP queries, however,
require that the input graph fits in the main memory, which renders them
inapplicable for the massive disk-resident graphs commonly used in web and
social applications. The only exceptions are a few techniques that are designed
to be I/O efficient, but they all focus on undirected and/or unweighted graphs,
and they only offer sub-optimal query efficiency.
  To address the deficiency of existing work, this paper presents {\em
Highways-on-Disk (HoD)}, a disk-based index that supports both SSD and SSSP
queries on directed and weighted graphs. The key idea of HoD is to augment the
input graph with a set of auxiliary edges, and exploit them during query
processing to reduce I/O and computation costs. We experimentally evaluate HoD
on both directed and undirected real-world graphs with up to billions of nodes
and edges, and we demonstrate that HoD significantly outperforms alternative
solutions in terms of query efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1154</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1154</id><created>2013-06-05</created><updated>2013-10-21</updated><authors><author><keyname>Cai</keyname><forenames>T. Tony</forenames></author><author><keyname>Zhang</keyname><forenames>Anru</forenames></author></authors><title>Sparse Representation of a Polytope and Recovery of Sparse Signals and
  Low-rank Matrices</title><categories>cs.IT math.IT math.ST stat.ML stat.TH</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers compressed sensing and affine rank minimization in both
noiseless and noisy cases and establishes sharp restricted isometry conditions
for sparse signal and low-rank matrix recovery. The analysis relies on a key
technical tool which represents points in a polytope by convex combinations of
sparse vectors. The technique is elementary while leads to sharp results.
  It is shown that for any given constant $t\ge {4/3}$, in compressed sensing
$\delta_{tk}^A &lt; \sqrt{(t-1)/t}$ guarantees the exact recovery of all $k$
sparse signals in the noiseless case through the constrained $\ell_1$
minimization, and similarly in affine rank minimization
$\delta_{tr}^\mathcal{M}&lt; \sqrt{(t-1)/t}$ ensures the exact reconstruction of
all matrices with rank at most $r$ in the noiseless case via the constrained
nuclear norm minimization. Moreover, for any $\epsilon&gt;0$,
$\delta_{tk}^A&lt;\sqrt{\frac{t-1}{t}}+\epsilon$ is not sufficient to guarantee
the exact recovery of all $k$-sparse signals for large $k$. Similar result also
holds for matrix recovery. In addition, the conditions $\delta_{tk}^A &lt;
\sqrt{(t-1)/t}$ and $\delta_{tr}^\mathcal{M}&lt; \sqrt{(t-1)/t}$ are also shown to
be sufficient respectively for stable recovery of approximately sparse signals
and low-rank matrices in the noisy case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1157</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1157</id><created>2013-06-05</created><updated>2014-08-15</updated><authors><author><keyname>Muralidharan</keyname><forenames>Vijayvaradharaj T.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Linear Network Coding, Linear Index Coding and Representable Discrete
  Polymatroids</title><categories>cs.IT math.IT</categories><comments>23 pages, 13 figures, 4 tables. Some more examples added. arXiv admin
  note: text overlap with arXiv:1301.3003, arXiv:1304.0355</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete polymatroids are the multi-set analogue of matroids. In this paper,
we explore the connections between linear network coding, linear index coding
and representable discrete polymatroids. First, we consider the vector linear
solvability of networks over a field $\mathbb{F}_q.$ We define a discrete
polymatroidal network and show that a vector linear solution exists for a
network if and only if the network is discrete polymatroidal with respect to a
representable discrete polymatroid. An algorithm to construct networks starting
from certain class of discrete polymatroids is provided. Every representation
over $\mathbb{F}_q$ for the discrete polymatroid, results in a vector linear
solution over $\mathbb{F}_q$ for the constructed network. We generalize the
results on the connection between discrete polymatroids and vector linear
solutions to linear fractional network coding solutions in which the message
dimensions need not necessarily be the same and need not be the same as the
edge vector dimension. Next, we consider the index coding problem and show that
a linear solution to an index coding problem exists if and only if there exists
a representable discrete polymatroid satisfying certain conditions which are
determined by the index coding problem considered. El Rouayheb et. al. showed
that the problem of finding a multi-linear representation for a matroid can be
reduced to finding a perfect linear index coding solution for an index coding
problem obtained from that matroid. Multi-linear representation of a matroid
can be viewed as a special case of representation of an appropriate discrete
polymatroid. We generalize the result of El Rouayheb et. al. by showing that
the problem of finding a representation for a discrete polymatroid can be
reduced to finding a perfect linear index coding solution for an index coding
problem obtained from that discrete polymatroid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1158</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1158</id><created>2013-06-05</created><authors><author><keyname>Chintakunta</keyname><forenames>Harish</forenames></author><author><keyname>Krim</keyname><forenames>Hamid</forenames></author></authors><title>Distributed computation of homology using harmonics</title><categories>math.AT cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a distributed algorithm to compute the first homology of a
simplicial complex. Such algorithms are very useful in topological analysis of
sensor networks, such as its coverage properties. We employ spanning trees to
compute a basis for algebraic 1-cycles, and then use harmonics to efficiently
identify the contractible and homologous cycles. The computational complexity
of the algorithm is $O(|P|^\omega)$, where $|P|$ is much smaller than the
number of edges, and $\omega$ is the complexity order of matrix multiplication.
For geometric graphs, we show using simulations that $|P|$ is very close to the
first Betti number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1161</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1161</id><created>2013-06-05</created><updated>2013-11-13</updated><authors><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author><author><keyname>Steinwandt</keyname><forenames>Rainer</forenames></author></authors><title>A quantum circuit to find discrete logarithms on ordinary binary
  elliptic curves in depth O(log^2 n)</title><categories>quant-ph cs.DS cs.ET</categories><comments>13 pages, 5 figures; title change and other minor changes. Accepted
  for publication in Quantum Information and Computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving over an earlier construction by Kaye and Zalka, Maslov et al.
describe an implementation of Shor's algorithm which can solve the discrete
logarithm problem on binary elliptic curves in quadratic depth O(n^2). In this
paper we show that discrete logarithms on such curves can be found with a
quantum circuit of depth O(log^2 n). As technical tools we introduce quantum
circuits for GF(2^n) multiplication in depth O(log n) and for GF(2^n) inversion
in depth O(log^2 n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1167</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1167</id><created>2013-06-05</created><authors><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Gelfand</keyname><forenames>Andrew E.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>A Graphical Transformation for Belief Propagation: Maximum Weight
  Matchings and Odd-Sized Cycles</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Max-product `belief propagation' (BP) is a popular distributed heuristic for
finding the Maximum A Posteriori (MAP) assignment in a joint probability
distribution represented by a Graphical Model (GM). It was recently shown that
BP converges to the correct MAP assignment for a class of loopy GMs with the
following common feature: the Linear Programming (LP) relaxation to the MAP
problem is tight (has no integrality gap). Unfortunately, tightness of the LP
relaxation does not, in general, guarantee convergence and correctness of the
BP algorithm. The failure of BP in such cases motivates reverse engineering a
solution -- namely, given a tight LP, can we design a `good' BP algorithm.
  In this paper, we design a BP algorithm for the Maximum Weight Matching (MWM)
problem over general graphs. We prove that the algorithm converges to the
correct optimum if the respective LP relaxation, which may include inequalities
associated with non-intersecting odd-sized cycles, is tight. The most
significant part of our approach is the introduction of a novel graph
transformation designed to force convergence of BP. Our theoretical result
suggests an efficient BP-based heuristic for the MWM problem, which consists of
making sequential, ``cutting plane'', modifications to the underlying GM. Our
experiments show that this heuristic performs as well as traditional
cutting-plane algorithms using LP solvers on MWM problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1185</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1185</id><created>2013-06-05</created><authors><author><keyname>Bresson</keyname><forenames>Xavier</forenames></author><author><keyname>Laurent</keyname><forenames>Thomas</forenames></author><author><keyname>Uminsky</keyname><forenames>David</forenames></author><author><keyname>von Brecht</keyname><forenames>James H.</forenames></author></authors><title>Multiclass Total Variation Clustering</title><categories>stat.ML cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ideas from the image processing literature have recently motivated a new set
of clustering algorithms that rely on the concept of total variation. While
these algorithms perform well for bi-partitioning tasks, their recursive
extensions yield unimpressive results for multiclass clustering tasks. This
paper presents a general framework for multiclass total variation clustering
that does not rely on recursion. The results greatly outperform previous total
variation algorithms and compare well with state-of-the-art NMF approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1187</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1187</id><created>2013-06-05</created><updated>2013-09-28</updated><authors><author><keyname>Xu</keyname><forenames>Ge</forenames></author><author><keyname>Zhu</keyname><forenames>Shengyu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>Decentralized Data Reduction with Quantization Constraints</title><categories>cs.IT math.IT</categories><comments>Revised manuscript submitted to IEEE Transaction on Signal Processing</comments><doi>10.1109/TSP.2014.2303432</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A guiding principle for data reduction in statistical inference is the
sufficiency principle. This paper extends the classical sufficiency principle
to decentralized inference, i.e., data reduction needs to be achieved in a
decentralized manner. We examine the notions of local and global sufficient
statistics and the relationship between the two for decentralized inference
under different observation models. We then consider the impacts of
quantization on decentralized data reduction which is often needed when
communications among sensors are subject to finite capacity constraints. The
central question we intend to ask is: if each node in a decentralized inference
system has to summarize its data using a finite number of bits, is it still
optimal to implement data reduction using global sufficient statistics prior to
quantization? We show that the answer is negative using a simple example and
proceed to identify conditions under which sufficiency based data reduction
followed by quantization is indeed optimal. They include the well known case
when the data at decentralized nodes are conditionally independent as well as a
class of problems with conditionally dependent observations that admit
conditional independence structure through the introduction of an appropriately
chosen hidden variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1202</identifier>
 <datestamp>2015-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1202</id><created>2013-06-05</created><updated>2013-07-01</updated><authors><author><keyname>Dash</keyname><forenames>Sanjeeb</forenames></author></authors><title>A note on QUBO instances defined on Chimera graphs</title><categories>math.OC cs.DS quant-ph</categories><comments>Version 1 discussed computational results with random QUBO instances.
  McGeoch and Wang made an error in describing the instances they used; they
  did not use random QUBO instances but rather random Ising Model instances
  with fields (mapped to QUBO instances). The current version of the note
  reports on tests with the precise instances used by McGeoch and Wang</comments><msc-class>90C05, 90C11, 90C20, 90C57</msc-class><journal-ref>Optima 98, 2015, 2-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  McGeoch and Wang (2013) recently obtained optimal or near-optimal solutions
to some quadratic unconstrained boolean optimization (QUBO) problem instances
using a 439 qubit D-Wave Two quantum computing system in much less time than
with the IBM ILOG CPLEX mixed-integer quadratic programming (MIQP) solver. The
problems studied by McGeoch and Wang are defined on subgraphs -- with up to 439
nodes -- of Chimera graphs. We observe that after a standard reformulation of
the QUBO problem as a mixed-integer linear program (MILP), the specific
instances used by McGeoch and Wang can be solved to optimality with the CPLEX
MILP solver in much less time than the time reported in McGeoch and Wang for
the CPLEX MIQP solver. However, the solution time is still more than the time
taken by the D-Wave computer in the McGeoch-Wang tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1254</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1254</id><created>2013-06-05</created><authors><author><keyname>Younes</keyname><forenames>Ahmed</forenames></author></authors><title>A Single Universal n-bit Gate for Reversible Circuit Synthesis</title><categories>quant-ph cs.ET</categories><comments>13 pages, 4 tables and 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many universal reversible libraries that contain more than one gate type have
been proposed in the literature. Practical implementation of reversible
circuits is much easier if a single gate type is used in the circuit
construction. This paper proposes a reversible n-bit gate that is universal for
reversible circuits synthesis. The proposed gate is extendable according to the
size of the circuit. The paper shows that the size of the synthesized circuits
using the proposed gate is comparable with the size of the synthesized circuits
using the hybrid reversible libraries for 3-in/out reversible circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1264</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1264</id><created>2013-06-05</created><updated>2015-02-16</updated><authors><author><keyname>Ayday</keyname><forenames>Erman</forenames></author><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Hubaux</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>The Chills and Thrills of Whole Genome Sequencing</title><categories>cs.CR</categories><comments>A slightly different version of this article appears in IEEE Computer
  Magazine, Vol. 48, No. 2, February 2015, under the title &quot;Whole Genome
  Sequencing: Revolutionary Medicine or Privacy Nightmare&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, Whole Genome Sequencing (WGS) evolved from a
futuristic-sounding research project to an increasingly affordable technology
for determining complete genome sequences of complex organisms, including
humans. This prompts a wide range of revolutionary applications, as WGS
promises to improve modern healthcare and provide a better understanding of the
human genome -- in particular, its relation to diseases and response to
treatments. However, this progress raises worrisome privacy and ethical issues,
since, besides uniquely identifying its owner, the genome contains a treasure
trove of highly personal and sensitive information. In this article, after
summarizing recent advances in genomics, we discuss some important privacy
issues associated with human genomic information and identify a number of
particularly relevant research challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1265</identifier>
 <datestamp>2014-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1265</id><created>2013-06-05</created><updated>2014-10-01</updated><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos</forenames></author></authors><title>Sparse Covers for Sums of Indicators</title><categories>stat.CO cs.DS</categories><comments>PTRF, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For all $n, \epsilon &gt;0$, we show that the set of Poisson Binomial
distributions on $n$ variables admits a proper $\epsilon$-cover in total
variation distance of size $n^2+n \cdot (1/\epsilon)^{O(\log^2 (1/\epsilon))}$,
which can also be computed in polynomial time. We discuss the implications of
our construction for approximation algorithms and the computation of
approximate Nash equilibria in anonymous games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1267</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1267</id><created>2013-06-05</created><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Gelfand</keyname><forenames>Andrew</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author></authors><title>Loop Calculus and Bootstrap-Belief Propagation for Perfect Matchings on
  Arbitrary Graphs</title><categories>cond-mat.stat-mech cs.AI math.PR</categories><comments>12 pages, 1 figure</comments><doi>10.1088/1742-6596/473/1/012007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript discusses computation of the Partition Function (PF) and the
Minimum Weight Perfect Matching (MWPM) on arbitrary, non-bipartite graphs. We
present two novel problem formulations - one for computing the PF of a Perfect
Matching (PM) and one for finding MWPMs - that build upon the inter-related
Bethe Free Energy, Belief Propagation (BP), Loop Calculus (LC), Integer Linear
Programming (ILP) and Linear Programming (LP) frameworks. First, we describe an
extension of the LC framework to the PM problem. The resulting formulas, coined
(fractional) Bootstrap-BP, express the PF of the original model via the BFE of
an alternative PM problem. We then study the zero-temperature version of this
Bootstrap-BP formula for approximately solving the MWPM problem. We do so by
leveraging the Bootstrap-BP formula to construct a sequence of MWPM problems,
where each new problem in the sequence is formed by contracting odd-sized
cycles (or blossoms) from the previous problem. This Bootstrap-and-Contract
procedure converges reliably and generates an empirically tight upper bound for
the MWPM. We conclude by discussing the relationship between our iterative
procedure and the famous Blossom Algorithm of Edmonds '65 and demonstrate the
performance of the Bootstrap-and-Contract approach on a variety of weighted PM
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1271</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1271</id><created>2013-06-05</created><authors><author><keyname>Xu</keyname><forenames>Kevin S.</forenames></author></authors><title>Predictability of social interactions</title><categories>cs.SI cs.CY physics.soc-ph stat.AP</categories><comments>Extended abstract selected as the winner of the 2013 International
  Conference on Social Computing, Behavioral-Cultural Modeling, and Prediction
  (SBP) Challenge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to predict social interactions between people has profound
applications including targeted marketing and prediction of information
diffusion and disease propagation. Previous work has shown that the location of
an individual at any given time is highly predictable. This study examines the
predictability of social interactions between people to determine whether
interaction patterns are similarly predictable. I find that the locations and
times of interactions for an individual are highly predictable; however, the
other person the individual interacts with is less predictable. Furthermore, I
show that knowledge of the locations and times of interactions has almost no
effect on the predictability of the other person. Finally I demonstrate that a
simple Markov chain model is able to achieve close to the upper bound in terms
of predicting the next person with whom a given individual will interact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1286</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1286</id><created>2013-06-05</created><updated>2013-09-16</updated><authors><author><keyname>Kaleeswaran</keyname><forenames>Shalini</forenames></author><author><keyname>Tulsian</keyname><forenames>Varun</forenames></author><author><keyname>Kanade</keyname><forenames>Aditya</forenames></author><author><keyname>Orso</keyname><forenames>Alessandro</forenames></author></authors><title>MintHint: Automated Synthesis of Repair Hints</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being able to automatically repair programs is an extremely challenging task.
In this paper, we present MintHint, a novel technique for program repair that
is a departure from most of today's approaches. Instead of trying to fully
automate program repair, which is often an unachievable goal, MintHint performs
statistical correlation analysis to identify expressions that are likely to
occur in the repaired code and generates, using pattern-matching based
synthesis, repair hints from these expressions. Intuitively, these hints
suggest how to rectify a faulty statement and help developers find a complete,
actual repair. MintHint can address a variety of common faults, including
incorrect, spurious, and missing expressions.
  We present a user study that shows that developers' productivity can improve
manyfold with the use of repair hints generated by MintHint -- compared to
having only traditional fault localization information. We also apply MintHint
to several faults of a widely used Unix utility program to further assess the
effectiveness of the approach. Our results show that MintHint performs well
even in situations where (1) the repair space searched does not contain the
exact repair, and (2) the operational specification obtained from the test
cases for repair is incomplete or even imprecise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1288</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1288</id><created>2013-06-05</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>Can Research be Taught?</title><categories>cs.CY</categories><comments>Proc. of the 6th Conference on Canadian Design Engineering Network
  and the Canadian Congress on Engineering Education (CDEN/C2E2'09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The word 'researcher' is loaded and often confusing. It takes years to become
one and to master all of its aspects. In this paper, we investigate whether or
not this process of 'becoming' can be catalyzed through education. The focus
will be on wireless communications, though the same principle could very well
be replicated to other disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1295</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1295</id><created>2013-06-06</created><updated>2014-08-18</updated><authors><author><keyname>Wang</keyname><forenames>Yi</forenames></author></authors><title>MathGR: a tensor and GR computation package to keep it simple</title><categories>cs.MS astro-ph.CO gr-qc hep-th physics.comp-ph</categories><comments>12 pages, 2 figures; v2: version to match updated software</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the MathGR package, written in Mathematica. The package can
manipulate tensor and GR calculations with either abstract or explicit indices,
simplify tensors with permutational symmetries, decompose tensors from abstract
indices to partially or completely explicit indices and convert partial
derivatives into total derivatives. Frequently used GR tensors and a model of
FRW universe with ADM type perturbations are predefined. The package is built
around the philosophy to &quot;keep it simple&quot;, and makes use of latest tensor
technologies of Mathematica.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1298</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1298</id><created>2013-06-06</created><authors><author><keyname>Garcia-Cardona</keyname><forenames>Cristina</forenames></author><author><keyname>Flenner</keyname><forenames>Arjuna</forenames></author><author><keyname>Percus</keyname><forenames>Allon G.</forenames></author></authors><title>Multiclass Semi-Supervised Learning on Graphs using Ginzburg-Landau
  Functional Minimization</title><categories>stat.ML cs.LG math.ST physics.data-an stat.TH</categories><comments>16 pages, to appear in Springer's Lecture Notes in Computer Science
  volume &quot;Pattern Recognition Applications and Methods 2013&quot;, part of series on
  Advances in Intelligent and Soft Computing</comments><acm-class>I.5.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We present a graph-based variational algorithm for classification of
high-dimensional data, generalizing the binary diffuse interface model to the
case of multiple classes. Motivated by total variation techniques, the method
involves minimizing an energy functional made up of three terms. The first two
terms promote a stepwise continuous classification function with sharp
transitions between classes, while preserving symmetry among the class labels.
The third term is a data fidelity term, allowing us to incorporate prior
information into the model in a semi-supervised framework. The performance of
the algorithm on synthetic data, as well as on the COIL and MNIST benchmark
datasets, is competitive with state-of-the-art graph-based multiclass
segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1300</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1300</id><created>2013-06-06</created><authors><author><keyname>Nawaz</keyname><forenames>Waqas</forenames></author><author><keyname>Han</keyname><forenames>Yongkoo</forenames></author><author><keyname>Khan</keyname><forenames>Kifayat-Ullah</forenames></author><author><keyname>Lee</keyname><forenames>Young-Koo</forenames></author></authors><title>Personalized Email Community Detection using Collaborative Similarity
  Measure</title><categories>cs.SI physics.soc-ph</categories><comments>4 pages, 4 Figures, International Conference ICMIA-2013 (Accepted)</comments><journal-ref>ICMIA-2013</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Email service providers have employed many email classification and
prioritization systems over the last decade to improve their services. In order
to assist email services, we propose a personalized email community detection
method to discover the groupings of email users based on their structural and
semantic intimacy. We extract the personalized social graph from a set of
emails by uniquely leveraging each node with communication behavior.
Subsequently, collaborative similarity measure (CSM) based intra-graph
clustering approach detects personalized communities. The empirical analysis
shows effectiveness of the resultant communities in terms of evaluation
measures, i.e. density, entropy and f-measure. Moreover, email strainer,
dynamic group prediction, and fraudulent account detection are suggested as the
potential applications from both the service provider and user's point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1301</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1301</id><created>2013-06-06</created><authors><author><keyname>Singha</keyname><forenames>Joyeeta</forenames></author><author><keyname>Das</keyname><forenames>Karen</forenames></author></authors><title>Recognition of Indian Sign Language in Live Video</title><categories>cs.CV</categories><comments>6 pages, 5 figures</comments><journal-ref>International Journal of Computer Applications 70(19):17-22, May
  2013</journal-ref><doi>10.5120/12174-7306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sign Language Recognition has emerged as one of the important area of
research in Computer Vision. The difficulty faced by the researchers is that
the instances of signs vary with both motion and appearance. Thus, in this
paper a novel approach for recognizing various alphabets of Indian Sign
Language is proposed where continuous video sequences of the signs have been
considered. The proposed system comprises of three stages: Preprocessing stage,
Feature Extraction and Classification. Preprocessing stage includes skin
filtering, histogram matching. Eigen values and Eigen Vectors were considered
for feature extraction stage and finally Eigen value weighted Euclidean
distance is used to recognize the sign. It deals with bare hands, thus allowing
the user to interact with the system in natural way. We have considered 24
different alphabets in the video sequences and attained a success rate of
96.25%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1302</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1302</id><created>2013-06-06</created><authors><author><keyname>Monti</keyname><forenames>Massimo</forenames></author><author><keyname>Imai</keyname><forenames>Pierre</forenames></author><author><keyname>Tschudin</keyname><forenames>Christian</forenames></author></authors><title>Designing Run-Time Environments to Have Predefined Global Dynamics</title><categories>cs.SE cs.NI</categories><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.5, No.3, May 2013 pp. 01-16</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stability and the predictability of a computer network algorithm's
performance are as important as the main functional purpose of networking
software. However, asserting or deriving such properties from the finite state
machine implementations of protocols is hard and, except for singular cases
like TCP, is not done today. In this paper, we propose to design and study
run-time environments for networking protocols which inherently enforce
desirable, predictable global dynamics. To this end we merge two complementary
design approaches: (i) A design-time and bottom up approach that enables us to
engineer algorithms based on an analyzable (reaction) flow model. (ii) A
run-time and top-down approach based on an autonomous stack composition
framework, which switches among implementation alternatives to find optimal
operation configurations. We demonstrate the feasibility of our self-optimizing
system in both simulations and real-world Internet setups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1303</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1303</id><created>2013-06-06</created><authors><author><keyname>Srinivasrao</keyname><forenames>Putti</forenames></author><author><keyname>Rao</keyname><forenames>V. P. C.</forenames></author><author><keyname>Govardhan</keyname><forenames>A.</forenames></author><author><keyname>Mohanty</keyname><forenames>Ambika Prasad</forenames></author></authors><title>Scalable Distributed Job Processing with Dynamic Load Balancing</title><categories>cs.DC</categories><comments>12 pages</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.4, No.3, May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here a cost effective framework for a robust scalable and
distributed job processing system that adapts to the dynamic computing needs
easily with efficient load balancing for heterogeneous systems. The design is
such that each of the components are self contained and do not depend on each
other. Yet, they are still interconnected through an enterprise message bus so
as to ensure safe, secure and reliable communication based on transactional
features to avoid duplication as well as data loss. The load balancing,
fault-tolerance and failover recovery are built into the system through a
mechanism of health check facility and a queue based load balancing. The system
has a centralized repository with central monitors to keep track of the
progress of various job executions as well as status of processors in
real-time. The basic requirement of assigning a priority and processing as per
priority is built into the framework. The most important aspect of the
framework is that it avoids the need for job migration by computing the target
processors based on the current load and the various cost factors. The
framework will have the capability to scale horizontally as well as vertically
to achieve the required performance, thus effectively minimizing the total cost
of ownership.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1304</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1304</id><created>2013-06-06</created><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Lin</keyname><forenames>Zihuai</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Yang</keyname><forenames>Yang</forenames></author></authors><title>Towards a Simple Relationship to Estimate the Capacity of Static and
  Mobile Wireless Networks</title><categories>cs.NI cs.IT cs.SY math.IT</categories><comments>accepted to appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extensive research has been done on studying the capacity of wireless
multi-hop networks. These efforts have led to many sophisticated and customized
analytical studies on the capacity of particular networks. While most of the
analyses are intellectually challenging, they lack universal properties that
can be extended to study the capacity of a different network. In this paper, we
sift through various capacity-impacting parameters and present a simple
relationship that can be used to estimate the capacity of both static and
mobile networks. Specifically, we show that the network capacity is determined
by the average number of simultaneous transmissions, the link capacity and the
average number of transmissions required to deliver a packet to its
destination. Our result is valid for both finite networks and asymptotically
infinite networks. We then use this result to explain and better understand the
insights of some existing results on the capacity of static networks, mobile
networks and hybrid networks and the multicast capacity. The capacity analysis
using the aforementioned relationship often becomes simpler. The relationship
can be used as a powerful tool to estimate the capacity of different networks.
Our work makes important contributions towards developing a generic methodology
for network capacity analysis that is applicable to a variety of different
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1310</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1310</id><created>2013-06-06</created><authors><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Chen</keyname><forenames>Zhi Ning</forenames></author></authors><title>Electromagnetic Lens-focusing Antenna Enabled Massive MIMO</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (MIMO) techniques have been recently
advanced to tremendously improve the performance of wireless networks. However,
the use of very large antenna arrays brings new issues, such as the
significantly increased hardware cost and signal processing cost and
complexity. In order to reap the enormous gain of massive MIMO and yet reduce
its cost to an affordable level, this paper proposes a novel system design by
integrating an electromagnetic (EM) lens with the large antenna array, termed
\emph{electromagnetic lens antenna} (ELA). An ELA has the capability of
focusing the power of any incident plane wave passing through the EM lens to a
small subset of the antenna array, while the location of focal area is
dependent on the angle of arrival (AoA) of the wave. As compared to
conventional antenna arrays without the EM lens, the proposed system can
substantially reduce the number of required radio frequency (RF) chains at the
receiver and hence, the implementation costs. In this paper, we investigate the
proposed system under a simplified single-user uplink transmission setup, by
characterizing the power distribution of the ELA as well as the resulting
channel model. Furthermore, by assuming antenna selection used at the receiver,
we show the throughput gains of the proposed system over conventional antenna
arrays given the same number of selected antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1316</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1316</id><created>2013-06-06</created><authors><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames><affiliation>ULB</affiliation></author><author><keyname>Richard</keyname><forenames>Pascal</forenames><affiliation>LIAS/Ensma and Universit&#xe9; de Poitiers</affiliation></author></authors><title>Partitioned scheduling of multimode multiprocessor real-time systems
  with temporal isolation</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the partitioned scheduling problem of multimode real-time systems
upon identical multiprocessor platforms. During the execution of a multimode
system, the system can change from one mode to another such that the current
task set is replaced with a new one. In this paper, we consider a synchronous
transition protocol in order to take into account mode-independent tasks, i.e.,
tasks of which the execution pattern must not be jeopardized by the mode
changes. We propose two methods for handling mode changes in partitioned
scheduling. The first method is offline/optimal and computes a static
allocation of tasks schedulable and respecting both tasks and transition
deadlines (if any). The second approach is subject to a sufficient condition in
order to ensure online First Fit based allocation to satisfy the timing
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1323</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1323</id><created>2013-06-06</created><authors><author><keyname>Chandrasekhar</keyname><forenames>T.</forenames></author><author><keyname>Thangavel</keyname><forenames>K.</forenames></author><author><keyname>Sathishkumar</keyname><forenames>E. N.</forenames></author></authors><title>Verdict Accuracy of Quick Reduct Algorithm using Clustering and
  Classification Techniques for Gene Expression Data</title><categories>cs.LG cs.CE stat.ML</categories><comments>7 pages, 3 figures</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 1, No 1, January 2012, page no. 357-363</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most gene expression data, the number of training samples is very small
compared to the large number of genes involved in the experiments. However,
among the large amount of genes, only a small fraction is effective for
performing a certain task. Furthermore, a small subset of genes is desirable in
developing gene expression based diagnostic tools for delivering reliable and
understandable results. With the gene selection results, the cost of biological
experiment and decision can be greatly reduced by analyzing only the marker
genes. An important application of gene expression data in functional genomics
is to classify samples according to their gene expression profiles. Feature
selection (FS) is a process which attempts to select more informative features.
It is one of the important steps in knowledge discovery. Conventional
supervised FS methods evaluate various feature subsets using an evaluation
function or metric to select only those features which are related to the
decision classes of the data under consideration. This paper studies a feature
selection method based on rough set theory. Further K-Means, Fuzzy C-Means
(FCM) algorithm have implemented for the reduced feature set without
considering class labels. Then the obtained results are compared with the
original class labels. Back Propagation Network (BPN) has also been used for
classification. Then the performance of K-Means, FCM, and BPN are analyzed
through the confusion matrix. It is found that the BPN is performing well
comparatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1326</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1326</id><created>2013-06-06</created><authors><author><keyname>Parveen</keyname><forenames>A. Nisthana</forenames></author><author><keyname>Inbarani</keyname><forenames>H. Hannah</forenames></author><author><keyname>Sathishkumar</keyname><forenames>E. N.</forenames></author></authors><title>Performance analysis of unsupervised feature selection methods</title><categories>cs.LG</categories><comments>7 pages, Conference Publications</comments><doi>10.1109/ICCCA.2012.6179181</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection (FS) is a process which attempts to select more informative
features. In some cases, too many redundant or irrelevant features may
overpower main features for classification. Feature selection can remedy this
problem and therefore improve the prediction accuracy and reduce the
computational overhead of classification algorithms. The main aim of feature
selection is to determine a minimal feature subset from a problem domain while
retaining a suitably high accuracy in representing the original features. In
this paper, Principal Component Analysis (PCA), Rough PCA, Unsupervised Quick
Reduct (USQR) algorithm and Empirical Distribution Ranking (EDR) approaches are
applied to discover discriminative features that will be the most adequate ones
for classification. Efficiency of the approaches is evaluated using standard
classification metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1332</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1332</id><created>2013-06-06</created><authors><author><keyname>Barbhuiya</keyname><forenames>Ferdous A</forenames></author><author><keyname>Biswas</keyname><forenames>Santosh</forenames></author><author><keyname>Nandi</keyname><forenames>Sukumar</forenames></author></authors><title>An Active Host-Based Intrusion Detection System for ARP-Related Attacks
  and its Verification</title><categories>cs.NI cs.CR</categories><comments>International Journal of Network Security &amp; Its Applications (IJNSA),
  Vol.3, No.3, May 2011</comments><journal-ref>Journal of Information Assurance and Security. ISSN 1554-1010
  Volume 7 (2012) pp. 284-295</journal-ref><doi>10.5121/ijnsa.2011.3311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spoofing with falsified IP-MAC pair is the first step in most of the LAN
based-attacks. Address Resolution Protocol (ARP) is stateless, which is the
main cause that makes spoofing possible. Several network level and host level
mechanisms have been proposed to detect and mitigate ARP spoofing but each of
them has their own drawback. In this paper we propose a Host-based Intrusion
Detection system for LAN attacks, which works without any extra constraint like
static IP-MAC, modifying ARP etc. The proposed scheme is verified under all
possible attack scenarios. The scheme is successfully validated in a test bed
with various attack scenarios and the results show the effectiveness of the
proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1334</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1334</id><created>2013-06-06</created><authors><author><keyname>Chhinkaniwala</keyname><forenames>Hitesh</forenames></author><author><keyname>Garg</keyname><forenames>Sanjay</forenames></author></authors><title>Tuple Value Based Multiplicative Data Perturbation Approach To Preserve
  Privacy In Data Stream Mining</title><categories>cs.DB</categories><comments>International Journal of Data Mining &amp; Knowledge Management Process
  (IJDKP) 9 pages</comments><journal-ref>International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP) Vol.3, No.3, May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Huge volume of data from domain specific applications such as medical,
financial, library, telephone, shopping records and individual are regularly
generated. Sharing of these data is proved to be beneficial for data mining
application. On one hand such data is an important asset to business decision
making by analyzing it. On the other hand data privacy concerns may prevent
data owners from sharing information for data analysis. In order to share data
while preserving privacy, data owner must come up with a solution which
achieves the dual goal of privacy preservation as well as an accuracy of data
mining task - clustering and classification. An efficient and effective
approach has been proposed that aims to protect privacy of sensitive
information and obtaining data clustering with minimum information loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1335</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1335</id><created>2013-06-06</created><authors><author><keyname>Raggad</keyname><forenames>H.</forenames></author><author><keyname>Latrach</keyname><forenames>M.</forenames></author><author><keyname>Gharsallah</keyname><forenames>A.</forenames></author><author><keyname>Razban</keyname><forenames>T.</forenames></author></authors><title>A Compact Dual Band Dielectric Resonator Antenna For Wireless
  Applications</title><categories>cs.OH</categories><comments>IJCNC 2013</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents the design of a dual band rectangular Dielectric
Resonator Antenna (DRA) coupled to narrow slot aperture that is fed by
microstrip line. The fundamental TE111 mode and higher-order TE113 mode are
excited with their resonant frequencies respectively. These frequencies can be
controlled by changing the DRA dimensions. A dielectric resonator with high
permittivity is used to miniaturize the global structure. The proposed antenna
is designed to have dual band operation suitable for both DCS (1710 - 1880 MHz)
and WLAN (2400 - 2484 MHz) applications. The return loss, radiation pattern and
gain of the proposed antenna are evaluated. Reasonable agreement between
simulation and experimental results is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1338</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1338</id><created>2013-06-06</created><authors><author><keyname>Gupta</keyname><forenames>Anuj K.</forenames></author><author><keyname>Sadawarti</keyname><forenames>Harsh</forenames></author><author><keyname>Verma</keyname><forenames>Anil K.</forenames></author></authors><title>Implementation of DYMO routing protocol</title><categories>cs.NI</categories><comments>9 pages, 6 figures, 1 table</comments><doi>10.5121/ijitmc.2013.1205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile ad hoc networks communicate without any fixed infrastructure or ant
centralized domain. All the nodes are free to move randomly within the network
and share information dynamically. To achieve an efficient routing various
protocols have been developed so far which vary in their nature and have their
own salient properties. In this paper, we have discussed one of the latest
protocols i.e. Dynamic Manet on demand (DYMO) routing Protocol, implemented and
analysed its performance with other similar protocols against different
parameters. Finally a comparison has been presented between all of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1340</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1340</id><created>2013-06-06</created><authors><author><keyname>Breitner</keyname><forenames>Joachim</forenames></author><author><keyname>Huffman</keyname><forenames>Brian</forenames></author><author><keyname>Mitchell</keyname><forenames>Neil</forenames></author><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author></authors><title>Certified HLints with Isabelle/HOLCF-Prelude</title><categories>cs.LO</categories><comments>1st International Workshop on Haskell And Rewriting Techniques, HART
  2013, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the HOLCF-Prelude, a formalization of a large part of Haskell's
standard prelude in Isabelle/HOLCF. Applying this formalization to the hints
suggested by HLint allows us to certify them formally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1343</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1343</id><created>2013-06-06</created><authors><author><keyname>Esuli</keyname><forenames>Andrea</forenames></author></authors><title>The User Feedback on SentiWordNet</title><categories>cs.CL cs.IR</categories><report-no>/cnr.isti/2013-TR-015</report-no><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the release of SentiWordNet 3.0 the related Web interface has been
restyled and improved in order to allow users to submit feedback on the
SentiWordNet entries, in the form of the suggestion of alternative triplets of
values for an entry. This paper reports on the release of the user feedback
collected so far and on the plans for the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1345</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1345</id><created>2013-06-06</created><updated>2014-07-08</updated><authors><author><keyname>Bui-Xuan</keyname><forenames>Binh-Minh</forenames></author><author><keyname>Kant&#xe9;</keyname><forenames>Mamadou Moustapha</forenames></author><author><keyname>Limouzy</keyname><forenames>Vincent</forenames></author></authors><title>A Note on Graphs of Linear Rank-Width 1</title><categories>cs.DM cs.DS math.CO</categories><comments>9 pages, 2 figures. Not to be published</comments><msc-class>68R10, 05C75</msc-class><acm-class>F.0; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that a connected graph has linear rank-width 1 if and only if it is
a distance-hereditary graph and its split decomposition tree is a path. An
immediate consequence is that one can decide in linear time whether a graph has
linear rank-width at most 1, and give an obstruction if not. Other immediate
consequences are several characterisations of graphs of linear rank-width 1. In
particular a connected graph has linear rank-width 1 if and only if it is
locally equivalent to a caterpillar if and only if it is a vertex-minor of a
path [O-joung Kwon and Sang-il Oum, Graphs of small rank-width are pivot-minors
of graphs of small tree-width, arxiv:1203.3606] if and only if it does not
contain the co-K_2 graph, the Net graph and the 5-cycle graph as vertex-minors
[Isolde Adler, Arthur M. Farley and Andrzej Proskurowski, Obstructions for
linear rank-width at most 1, arxiv:1106.2533].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1346</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1346</id><created>2013-06-06</created><authors><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Maham</keyname><forenames>Behrouz</forenames></author><author><keyname>Hjorungnes</keyname><forenames>Are</forenames></author></authors><title>Rethinking the Secrecy Outage Formulation: A Secure Transmission Design
  Perspective</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Communications Letters, Vol. 15, No. 3, pp. 302 - 304, March
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter studies information-theoretic security without knowing the
eavesdropper's channel fading state. We present an alternative secrecy outage
formulation to measure the probability that message transmissions fail to
achieve perfect secrecy. Using this formulation, we design two transmission
schemes that satisfy the given security requirement while achieving good
throughput performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1350</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1350</id><created>2013-06-06</created><updated>2013-09-27</updated><authors><author><keyname>Sipola</keyname><forenames>Tuomo</forenames></author><author><keyname>Cong</keyname><forenames>Fengyu</forenames></author><author><keyname>Ristaniemi</keyname><forenames>Tapani</forenames></author><author><keyname>Alluri</keyname><forenames>Vinoo</forenames></author><author><keyname>Toiviainen</keyname><forenames>Petri</forenames></author><author><keyname>Brattico</keyname><forenames>Elvira</forenames></author><author><keyname>Nandi</keyname><forenames>Asoke K.</forenames></author></authors><title>Diffusion map for clustering fMRI spatial maps extracted by independent
  component analysis</title><categories>cs.CE cs.LG stat.ML</categories><comments>6 pages. 8 figures. Copyright (c) 2013 IEEE. Published at 2013 IEEE
  International Workshop on Machine Learning for Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional magnetic resonance imaging (fMRI) produces data about activity
inside the brain, from which spatial maps can be extracted by independent
component analysis (ICA). In datasets, there are n spatial maps that contain p
voxels. The number of voxels is very high compared to the number of analyzed
spatial maps. Clustering of the spatial maps is usually based on correlation
matrices. This usually works well, although such a similarity matrix inherently
can explain only a certain amount of the total variance contained in the
high-dimensional data where n is relatively small but p is large. For
high-dimensional space, it is reasonable to perform dimensionality reduction
before clustering. In this research, we used the recently developed diffusion
map for dimensionality reduction in conjunction with spectral clustering. This
research revealed that the diffusion map based clustering worked as well as the
more traditional methods, and produced more compact clusters when needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1356</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1356</id><created>2013-06-06</created><updated>2014-11-03</updated><authors><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author><author><keyname>Kabanava</keyname><forenames>Maryia</forenames></author></authors><title>Analysis $\ell_1$-recovery with frames and Gaussian measurements</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides novel results for the recovery of signals from
undersampled measurements based on analysis $\ell_1$-minimization, when the
analysis operator is given by a frame. We both provide so-called uniform and
nonuniform recovery guarantees for cosparse (analysis-sparse) signals using
Gaussian random measurement matrices. The nonuniform result relies on a
recovery condition via tangent cones and the uniform recovery guarantee is
based on an analysis version of the null space property. Examining these
conditions for Gaussian random matrices leads to precise bounds on the number
of measurements required for successful recovery. In the special case of
standard sparsity, our result improves a bound due to Rudelson and Vershynin
concerning the exact reconstruction of sparse signals from Gaussian
measurements with respect to the constant and extends it to stability under
passing to approximately sparse signals and to robustness under noise on the
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1358</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1358</id><created>2013-06-06</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>Geometric operations implemented by conformal geometric algebra neural
  nodes</title><categories>cs.CV cs.NE math.RA</categories><comments>6 pages, 2 tables, 10 figures</comments><journal-ref>Proc. SICE Symposium on Systems and Information 2008, 26-28 Nov.
  2008, Himeji, Japan, pp. 357-362 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric algebra is an optimal frame work for calculating with vectors. The
geometric algebra of a space includes elements that represent all the its
subspaces (lines, planes, volumes, ...). Conformal geometric algebra expands
this approach to elementary representations of arbitrary points, point pairs,
lines, circles, planes and spheres. Apart from including curved objects,
conformal geometric algebra has an elegant unified quaternion like
representation for all proper and improper Euclidean transformations, including
reflections at spheres, general screw transformations and scaling. Expanding
the concepts of real and complex neurons we arrive at the new powerful concept
of conformal geometric algebra neurons. These neurons can easily take the above
mentioned geometric objects or sets of these objects as inputs and apply a wide
range of geometric transformations via the geometric algebra valued weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1360</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1360</id><created>2013-06-06</created><authors><author><keyname>Fischer</keyname><forenames>Eldar</forenames></author><author><keyname>Goldhirsh</keyname><forenames>Yonatan</forenames></author><author><keyname>Lachish</keyname><forenames>Oded</forenames></author></authors><title>Some properties are not even partially testable</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a property $P$ and a sub-property $P'$, we say that $P$ is $P'$-partially
testable with $q$ queries if there exists an algorithm that distinguishes, with
high probability, inputs in $P'$ from inputs $\epsilon$-far from $P$ by using
$q$ queries. There are natural properties that require many queries to test,
but can be partitioned into a small number of subsets for which they are
partially testable with very few queries.
  We prove the existence of a property $P$ such that the only subsets $P'$ for
which $P$ is $P'$-partially testable are very small. To prove this we introduce
new techniques for proving property testing lower bounds. In addition to
obtaining some broad-brush criteria for non-testability, this implies a lower
bound on the possibility of PCPPs with a sublinear proof. This also implies
lower bounds on MAPs, a notion newly defined by Gur and Rothblum.
  The new techniques rely on analyzing a proposed partial tester. We show that
the queries performed by a tester must, with high probability, query indexes
where a uniformly random member of the sub-property has low entropy. We then
show how one can aggregate the &quot;entropy loss&quot; to deduce that a random choice in
the sub-property must have low entropy, and therefore the sub-property must be
small.
  We develop two techniques for aggregating the entropy loss. A simpler
technique that applies to non-adaptive testers is based on partitioning the
input bits into high query probability parts and parts where there is an
entropy loss when conditioned on the high probability parts. Against adaptive
testers we develop a technique based on constructing a decision tree. The
root-to-leaf paths in this tree rearrange the input into parts where each
exhibits entropy loss when conditioned on the path prefix. This decision tree
is constructed by combining carefully selected decision trees from those used
by the adaptive testing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1362</identifier>
 <datestamp>2014-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1362</id><created>2013-06-06</created><updated>2014-02-27</updated><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author><author><keyname>Paule</keyname><forenames>Peter</forenames></author><author><keyname>Suslov</keyname><forenames>Sergei K.</forenames></author></authors><title>Relativistic Coulomb Integrals and Zeilberger's Holonomic Systems
  Approach II</title><categories>quant-ph cs.SC math-ph math.MP</categories><journal-ref>In: Algebraic and Algorithmic Aspects of Differential and Integral
  Operators, Lecture Notes in Computer Science 8372, pp. 135-145,
  Springer-Verlag Berlin Heidelberg, 2014. ISBN 978-3-642-54478-1</journal-ref><doi>10.1007/978-3-642-54479-8_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the recurrence relations for relativistic Coulomb integrals
directly from the integral representations with the help of computer algebra
methods. In order to manage the computational complexity of this problem, we
employ holonomic closure properties in a sophisticated way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1365</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1365</id><created>2013-06-06</created><authors><author><keyname>Fedushko</keyname><forenames>Solomia</forenames></author><author><keyname>Peleschyshyn</keyname><forenames>Oksana</forenames></author><author><keyname>Peleschyshyn</keyname><forenames>Andriy</forenames></author><author><keyname>Syerov</keyname><forenames>Yuriy</forenames></author></authors><title>The verification of virtual community members socio-demographic profile</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>9 pages, 4 figures, Advanced Computing: An International Journal
  (ACIJ), Vol.4, No.3, May 2013</comments><msc-class>68N30 (Primary), 90B18 and 90B60 (Secondary)</msc-class><acm-class>B.2.2; D.4.5; F.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This article considers the current problem of investigation and development
of the method of web-members' socio-demographic characteristics' profile
validation based on analysis of socio-demographic characteristics. The
topicality of the paper is determined by the necessity to identify the
web-community member by means of computer-linguistic analysis of their
information track (all information about web-community members, which posted on
the Internet). The formal model of basic socio-demographic characteristics of
virtual communities' member is formed. The algorithm of these characteristics
verification is developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1366</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1366</id><created>2013-06-06</created><authors><author><keyname>Mantaci</keyname><forenames>Sabrina</forenames></author><author><keyname>Restivo</keyname><forenames>Antonio</forenames></author><author><keyname>Rosone</keyname><forenames>Giovanna</forenames></author><author><keyname>Sciortino</keyname><forenames>Marinella</forenames></author></authors><title>Sorting suffixes of a text via its Lyndon Factorization</title><categories>cs.DS</categories><comments>Submitted to the Prague Stringology Conference 2013 (PSC 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of sorting the suffixes of a text plays a fundamental role in
Text Algorithms. They are used for instance in the constructions of the
Burrows-Wheeler transform and the suffix array, widely used in several fields
of Computer Science. For this reason, several recent researches have been
devoted to finding new strategies to obtain effective methods for such a
sorting. In this paper we introduce a new methodology in which an important
role is played by the Lyndon factorization, so that the local suffixes inside
factors detected by this factorization keep their mutual order when extended to
the suffixes of the whole word. This property suggests a versatile technique
that easily can be adapted to different implementative scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1373</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1373</id><created>2013-06-06</created><authors><author><keyname>Modieginyane</keyname><forenames>Kgotlaetsile Mathews</forenames></author><author><keyname>Ncube</keyname><forenames>Zenzo Polite</forenames></author><author><keyname>Gasela</keyname><forenames>Naison</forenames></author></authors><title>CUDA Based Performance Evaluation of the Computational Efficiency of the
  DCT Image Compression Technique on Both the CPU and GPU</title><categories>cs.DC cs.MM</categories><comments>15 Pages, 11 Figures, 4 Tables, Advanced Computing: An International
  Journal (ACIJ), Three Author Pictures (with little Bio for each) at last page</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in computing such as the massively parallel GPUs (Graphical
Processing Units),coupled with the need to store and deliver large quantities
of digital data especially images, has brought a number of challenges for
Computer Scientists, the research community and other stakeholders. These
challenges, such as prohibitively large costs to manipulate the digital data
amongst others, have been the focus of the research community in recent years
and has led to the investigation of image compression techniques that can
achieve excellent results. One such technique is the Discrete Cosine Transform,
which helps separate an image into parts of differing frequencies and has the
advantage of excellent energy-compaction.
  This paper investigates the use of the Compute Unified Device Architecture
(CUDA) programming model to implement the DCT based Cordic based Loeffler
algorithm for efficient image compression. The computational efficiency is
analyzed and evaluated under both the CPU and GPU. The PSNR (Peak Signal to
Noise Ratio) is used to evaluate image reconstruction quality in this paper.
The results are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1392</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1392</id><created>2013-06-06</created><authors><author><keyname>Mirone</keyname><forenames>Alessandro</forenames></author><author><keyname>Gouillart</keyname><forenames>Emmanuelle</forenames></author><author><keyname>Brun</keyname><forenames>Emmanuel</forenames></author><author><keyname>Tafforeau</keyname><forenames>Paul</forenames></author><author><keyname>Kieffer</keyname><forenames>Jerome</forenames></author></authors><title>PyHST2: an hybrid distributed code for high speed tomographic
  reconstruction with iterative reconstruction and a priori knowledge
  capabilities</title><categories>math.NA cs.CV</categories><doi>10.1016/j.nimb.2013.09.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the PyHST2 code which is in service at ESRF for phase-contrast and
absorption tomography. This code has been engineered to sustain the high data
flow typical of the third generation synchrotron facilities (10 terabytes per
experiment) by adopting a distributed and pipelined architecture. The code
implements, beside a default filtered backprojection reconstruction, iterative
reconstruction techniques with a-priori knowledge. These latter are used to
improve the reconstruction quality or in order to reduce the required data
volume and reach a given quality goal. The implemented a-priori knowledge
techniques are based on the total variation penalisation and a new recently
found convex functional which is based on overlapping patches.
  We give details of the different methods and their implementations while the
code is distributed under free license.
  We provide methods for estimating, in the absence of ground-truth data, the
optimal parameters values for a-priori techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1394</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1394</id><created>2013-06-06</created><authors><author><keyname>Ward</keyname><forenames>Jonathan Stuart</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>A Cloud Computing Survey: Developments and Future Trends in
  Infrastructure as a Service Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is a recent paradigm based around the notion of delivery of
resources via a service model over the Internet. Despite being a new paradigm
of computation, cloud computing owes its origins to a number of previous
paradigms. The term cloud computing is well defined and no longer merits
rigorous taxonomies to furnish a definition. Instead this survey paper
considers the past, present and future of cloud computing. As an evolution of
previous paradigms, we consider the predecessors to cloud computing and what
significance they still hold to cloud services. Additionally we examine the
technologies which comprise cloud computing and how the challenges and future
developments of these technologies will influence the field. Finally we examine
the challenges that limit the growth, application and development of cloud
computing and suggest directions required to overcome these challenges in order
to further the success of cloud computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1402</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1402</id><created>2013-06-06</created><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author></authors><title>Threshold Load Balancing in Networks</title><categories>cs.DS cs.GT</categories><comments>20 pages, brief announcement in PODC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study probabilistic protocols for concurrent threshold-based load
balancing in networks. There are n resources or machines represented by nodes
in an undirected graph and m &gt;&gt; n users that try to find an acceptable resource
by moving along the edges of the graph. Users accept a resource if the load is
below a threshold. Such thresholds have an intuitive meaning, e.g., as
deadlines in a machine scheduling scenario, and they allow the design of
protocols under strong locality constraints. When migration is partly
controlled by resources and partly by users, our protocols obtain rapid
convergence to a balanced state, in which all users are satisfied. We show that
convergence is achieved in a number of rounds that is only logarithmic in m and
polynomial in structural properties of the graph. Even when migration is fully
controlled by users, we obtain similar results for convergence to approximately
balanced states. If we slightly adjust the migration probabilities in our
protocol, we can also obtain fast convergence to balanced states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1408</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1408</id><created>2013-06-05</created><authors><author><keyname>Virmani</keyname><forenames>Deepali</forenames></author><author><keyname>Jain</keyname><forenames>Akshay</forenames></author><author><keyname>Khandelwal</keyname><forenames>Ankit</forenames></author><author><keyname>Gupta</keyname><forenames>Divik</forenames></author><author><keyname>Garg</keyname><forenames>Nitin</forenames></author></authors><title>Dynamic Clustering Protocol for Data Forwarding in Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>6 pages. International Journal of Computers &amp; Technology, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy being the very key concern area with sensor networks, so the main
focus lies in developing a mechanism to increase the lifetime of a sensor
network by energy balancing. To achieve energy balancing and maximizing network
lifetime we use an idea of clustering and dividing the whole network into
different clusters. In this paper we propose a dynamic cluster formation method
where clusters are refreshed periodically based on residual energy, distance
and cost. Refreshing clustering minimizes workload of any single node and in
turn enhances the energy conservation. Sleep and wait methodology is applied to
the proposed protocol to enhance the network lifetime by turning the nodes on
and off according to their duties. The node that has some data to be
transmitted is in on state and after forwarding its data to the cluster head it
changes its state to off which saves the energy of entire network. Simulations
have been done using MAT lab. Simulation results prove the betterment of our
proposed method over the existing Leach protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1421</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1421</id><created>2013-06-06</created><authors><author><keyname>Park</keyname><forenames>Juyong</forenames></author><author><keyname>Yook</keyname><forenames>Soon-Hyung</forenames></author></authors><title>Bayesian Inference of Natural Rankings in Incomplete Competition
  Networks</title><categories>physics.soc-ph cs.AI cs.SI physics.data-an</categories><comments>5 pages, 2 figures</comments><journal-ref>Scientific Reports 4, 6212 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Competition between a complex system's constituents and a corresponding
reward mechanism based on it have profound influence on the functioning,
stability, and evolution of the system. But determining the dominance hierarchy
or ranking among the constituent parts from the strongest to the weakest --
essential in determining reward or penalty -- is almost always an ambiguous
task due to the incomplete nature of competition networks. Here we introduce
``Natural Ranking,&quot; a desirably unambiguous ranking method applicable to a
complete (full) competition network, and formulate an analytical model based on
the Bayesian formula inferring the expected mean and error of the natural
ranking of nodes from an incomplete network. We investigate its potential and
uses in solving issues in ranking by applying to a real-world competition
network of economic and social importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1433</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1433</id><created>2013-06-06</created><updated>2013-11-10</updated><authors><author><keyname>Greenberg</keyname><forenames>Spencer</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author></authors><title>Tight Lower Bound on the Probability of a Binomial Exceeding its
  Expectation</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the proof of a tight lower bound on the probability that a binomial
random variable exceeds its expected value. The inequality plays an important
role in a variety of contexts, including the analysis of relative deviation
bounds in learning theory and generalization bounds for unbounded loss
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1436</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1436</id><created>2013-06-06</created><authors><author><keyname>Harn</keyname><forenames>Lein</forenames></author><author><keyname>Lin</keyname><forenames>Changlu</forenames></author></authors><title>An efficient group authentication for group communications</title><categories>cs.CR</categories><comments>8 pages</comments><msc-class>94A62</msc-class><acm-class>D.4.6</acm-class><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.5, No.3, May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group communication implies a many-to-many communication and it goes beyond
both one-to-one communication (i.e., unicast) and one-to-many communication
(i.e., multicast). Unlike most user authentication protocols that authenticate
a single user each time, we propose a new type of authentication, called group
authentication, that authenticates all users in a group at once. The group
authentication protocol is specially designed to support group communications.
There is a group manager who is responsible to manage the group communication.
During registration, each user of a group obtains an unique token from the
group manager. Users present their tokens to determine whether they all belong
to the same group or not. The group authentication protocol allows users to
reuse their tokens without compromising the security of tokens. In addition,
the group authentication can protect the identity of each user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1447</identifier>
 <datestamp>2015-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1447</id><created>2013-06-06</created><updated>2015-03-06</updated><authors><author><keyname>Birget</keyname><forenames>J. C.</forenames></author></authors><title>Semigroups and one-way functions</title><categories>math.GR cs.CC</categories><comments>25 pages. This 3rd version benefitted from referee comments in
  International J. of Algebra and Computation, 2015</comments><msc-class>20M05, 20M17, 68Q17, 68Q15</msc-class><doi>10.1142/S0218196715400019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity classes P and NP through a semigroup fP
(&quot;polynomial-time functions&quot;), consisting of all polynomially balanced
polynomial-time computable partial functions. Then P is not equal to NP iff fP
is a non-regular semigroup. The one-way functions considered here are based on
worst-case complexity (they are not cryptographic); they are the non-regular
elements of fP. We prove various properties of fP, e.g., that it is finitely
generated. We define reductions with respect to which certain universal one-way
functions are fP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1448</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1448</id><created>2013-06-06</created><authors><author><keyname>Khattab</keyname><forenames>Omar</forenames></author><author><keyname>Alani</keyname><forenames>Omar</forenames></author></authors><title>I am 4 vho: new approach to improve seamless vertical hanover in
  heterogeneous wireless networks</title><categories>cs.NI</categories><comments>11 pages, 5 figures,Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two mechanisms have been proposed independently by IEEE and 3GPP; namely,
Media Independent Handover (MIH) and Access Network Discovery and Selection
Function (ANDSF), respectively. These mechanisms enable a seamless Vertical
Handover (VHO) between the different types of technologies (3GPP and non-3GPP),
such as GSM (Global System for Mobile Communication), Wireless Fidelity (Wi-
Fi), Worldwide Interoperability for Microwave Access (WiMAX), Universal Mobile
Telecommunications System (UMTS) and Long Term Evolution (LTE). In this paper,
we overview these mechanisms and show their components, benefits and drawbacks.
Then we present our Imperative Alternative MIH for Vertical Handover (I AM 4
VHO) approach based on the approaches that have been studied in the literature
with better performance (packet loss and latency), less connection failure
(probability of reject sessions), less complexity and more exhaustive for
enhancing VHO heterogeneous wireless networks environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1461</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1461</id><created>2013-06-06</created><updated>2013-06-07</updated><authors><author><keyname>Sturm</keyname><forenames>Bob L.</forenames></author></authors><title>The GTZAN dataset: Its contents, its faults, their effects on
  evaluation, and its future use</title><categories>cs.SD</categories><comments>29 pages, 7 figures, 6 tables, 128 references</comments><doi>10.1080/09298215.2014.894533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The GTZAN dataset appears in at least 100 published works, and is the
most-used public dataset for evaluation in machine listening research for music
genre recognition (MGR). Our recent work, however, shows GTZAN has several
faults (repetitions, mislabelings, and distortions), which challenge the
interpretability of any result derived using it. In this article, we disprove
the claims that all MGR systems are affected in the same ways by these faults,
and that the performances of MGR systems in GTZAN are still meaningfully
comparable since they all face the same faults. We identify and analyze the
contents of GTZAN, and provide a catalog of its faults. We review how GTZAN has
been used in MGR research, and find few indications that its faults have been
known and considered. Finally, we rigorously study the effects of its faults on
evaluating five different MGR systems. The lesson is not to banish GTZAN, but
to use it with consideration of its contents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1462</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1462</id><created>2013-06-06</created><authors><author><keyname>Bansal</keyname><forenames>Kanika</forenames></author><author><keyname>Kumar</keyname><forenames>Rajiv</forenames></author></authors><title>K-Algorithm A Modified Technique for Noise Removal in Handwritten
  Documents</title><categories>cs.CV</categories><journal-ref>International Journal of Information Sciences and Techniques, May
  2013, Volume 3, Number 3</journal-ref><doi>10.5121/ijist.2013.3301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  OCR has been an active research area since last few decades. OCR performs the
recognition of the text in the scanned document image and converts it into
editable form. The OCR process can have several stages like pre-processing,
segmentation, recognition and post processing. The pre-processing stage is a
crucial stage for the success of OCR, which mainly deals with noise removal. In
the present paper, a modified technique for noise removal named as K-Algorithm
has been proposed, which has two stages as filtering and binarization. The
proposed technique shows improvised results in comparison to median filtering
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1467</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1467</id><created>2013-06-06</created><authors><author><keyname>Abualkibash</keyname><forenames>Munther</forenames></author><author><keyname>ElSayed</keyname><forenames>Ahmed</forenames></author><author><keyname>Mahmood</keyname><forenames>Ausif</forenames></author></authors><title>Highly Scalable, Parallel and Distributed AdaBoost Algorithm using Light
  Weight Threads and Web Services on a Network of Multi-Core Machines</title><categories>cs.DC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AdaBoost is an important algorithm in machine learning and is being widely
used in object detection. AdaBoost works by iteratively selecting the best
amongst weak classifiers, and then combines several weak classifiers to obtain
a strong classifier. Even though AdaBoost has proven to be very effective, its
learning execution time can be quite large depending upon the application e.g.,
in face detection, the learning time can be several days. Due to its increasing
use in computer vision applications, the learning time needs to be drastically
reduced so that an adaptive near real time object detection system can be
incorporated. In this paper, we develop a hybrid parallel and distributed
AdaBoost algorithm that exploits the multiple cores in a CPU via light weight
threads, and also uses multiple machines via a web service software
architecture to achieve high scalability. We present a novel hierarchical web
services based distributed architecture and achieve nearly linear speedup up to
the number of processors available to us. In comparison with the previously
published work, which used a single level master-slave parallel and distributed
implementation [1] and only achieved a speedup of 2.66 on four nodes, we
achieve a speedup of 95.1 on 31 workstations each having a quad-core processor,
resulting in a learning time of only 4.8 seconds per feature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1468</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1468</id><created>2013-06-06</created><authors><author><keyname>Steinberg</keyname><forenames>Benjamin</forenames></author></authors><title>Topological dynamics and recognition of languages</title><categories>cs.FL math.CO math.GR</categories><comments>This draft was written in March 2010 and was intended to be the
  beginning of a foundational paper on varieties of not necessarily rational
  languages and varieties of left compact semitopological semigroups, including
  an Eilenberg variety theorem and a Reiterman's theorem. Lacking sufficient
  applications to develop the full theory, I put here what has been worked out</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define compact automata and show that every language has a unique minimal
compact automaton. We also define recognition of languages by compact left
semitopological monoids and construct the analogue of the syntactic monoid in
this context. For rational languages this reduces to the usual theory of finite
automata and finite monoids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1469</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1469</id><created>2013-06-06</created><authors><author><keyname>Amroune</keyname><forenames>Mohamed</forenames></author><author><keyname>Charrel</keyname><forenames>Pierre Jean</forenames></author><author><keyname>Zarour</keyname><forenames>Nacereddine</forenames></author><author><keyname>Inglebert</keyname><forenames>Jean Michel</forenames></author></authors><title>A model driven engineering approach to develop a cooperative information
  system</title><categories>cs.SE</categories><comments>International Journal of Software Engineering &amp; Applications, 2013,
  Aircc Editor. arXiv admin note: substantial text overlap with arXiv:1303.4056</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To reuse one or several existing systems in order to develop a complex system
is a common practice in software engineering. This approach can be justified by
the fact that it is often difficult for a single Information System (IS) to
accomplish all the requested tasks. So, one solution is to combine many
different ISs and make them collaborate in order to realize these tasks. We
proposed an approach named AspeCiS (An Aspect-oriented Approach to Develop a
Cooperative Information System) to develop a Cooperative Information System
from existing ISs by using their artifacts such as existing requirements, and
design. AspeCiS covers the three following phases: (i) discovery and analysis
of Cooperative Requirements, (ii) design of Cooperative Requirements models,
and (iii) preparation of the implementation phase. The main issue of AspeCiS is
the definition of Cooperative Requirements using the Existing Requirements and
Additional Requirements, which should be composed with Aspectual Requirements.
We earlier studied how to elicit the Cooperative Requirements in AspeCiS (phase
of discovery and analysis of Cooperative Requirements in AspeCiS) . We study
here the second phase of AspeCiS (design of Cooperative Requirements models),
by the way of a model weaving process. This process uses so-called AspeCiS
Weaving Metamodel, and it weaves Existing and Additional Requirements models to
realize Cooperative Requirements models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1477</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1477</id><created>2013-06-06</created><authors><author><keyname>Borodin</keyname><forenames>Oleg V.</forenames></author><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Zden&#x11b;k</forenames></author><author><keyname>Kostochka</keyname><forenames>Alexandr V.</forenames></author><author><keyname>Lidick&#xfd;</keyname><forenames>Bernard</forenames></author><author><keyname>Yancey</keyname><forenames>Matthew</forenames></author></authors><title>Planar 4-critical graphs with four triangles</title><categories>math.CO cs.DM</categories><comments>20 pages, 7 figures</comments><msc-class>05C15, 05C10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By the Grunbaum-Aksenov Theorem (extending Grotzsch's Theorem) every planar
graph with at most three triangles is 3-colorable. However, there are
infinitely many planar 4-critical graphs with exactly four triangles. We
describe all such graphs. This answers a question of Erdos from 1990.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1478</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1478</id><created>2013-06-06</created><authors><author><keyname>Rohallah</keyname><forenames>Benaboud</forenames></author><author><keyname>Ramdane</keyname><forenames>Maamri</forenames></author><author><keyname>Zaidi</keyname><forenames>Sahnoun</forenames></author></authors><title>Agents and owl-s based semantic web service discovery with user
  preference support</title><categories>cs.IR cs.SE</categories><comments>19 pages, 10 figures</comments><journal-ref>International Journal of Web &amp; Semantic Technology (IJWesT), April
  2013, Volume 4, Number 2, pp 57-75</journal-ref><doi>10.5121/ijwest.2013.4206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-oriented computing (SOC) is an interdisciplinary paradigm that
revolutionizes the very fabric of distributed software development applications
that adopt service-oriented architectures (SOA) can evolve during their
lifespan and adapt to changing or unpredictable environments more easily. SOA
is built around the concept of Web Services. Although the Web services
constitute a revolution in Word Wide Web, they are always regarded as
non-autonomous entities and can be exploited only after their discovery. With
the help of software agents, Web services are becoming more efficient and more
dynamic. The topic of this paper is the development of an agent based approach
for Web services discovery and selection in witch, OWL-S is used to describe
Web services, QoS and service customer request. We develop an efficient
semantic service matching which takes into account concepts properties to match
concepts in Web service and service customer request descriptions. Our approach
is based on an architecture composed of four layers: Web service and Request
description layer, Functional match layer, QoS computing layer and Reputation
computing layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1486</identifier>
 <datestamp>2014-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1486</id><created>2013-06-06</created><updated>2014-04-30</updated><authors><author><keyname>Reissig</keyname><forenames>Gunther</forenames></author><author><keyname>Hartung</keyname><forenames>Christoph</forenames></author><author><keyname>Svaricek</keyname><forenames>Ferdinand</forenames></author></authors><title>Strong Structural Controllability and Observability of Linear
  Time-Varying Systems</title><categories>math.OC cs.SY math.CO</categories><comments>This work has been accepted for publication in the IEEE Trans.
  Automatic Control. v2: Section IV (observability) added; plus minor
  modifications; accepted version</comments><msc-class>93B05, 93B07, 93C05, 15A03, 05C50</msc-class><doi>10.1109/TAC.2014.2320297</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we consider continuous-time systems x'(t) = A(t) x(t) + B(t)
u(t), y(t) = C(t) x(t) + D(t) u(t), as well as discrete-time systems x(t+1) =
A(t) x(t) + B(t) u(t), y(t) = C(t) x(t) + D(t) u(t) whose coefficient matrices
A, B, C and D are not exactly known. More precisely, all that is known about
the systems is their nonzero pattern, i.e., the locations of the nonzero
entries in the coefficient matrices. We characterize the patterns that
guarantee controllability and observability, respectively, for all choices of
nonzero time functions at the matrix positions defined by the pattern, which
extends a result by Mayeda and Yamada for time-invariant systems. As it turns
out, the conditions on the patterns for time-invariant and for time-varying
discrete-time systems coincide, provided that the underlying time interval is
sufficiently long. In contrast, the conditions for time-varying continuous-time
systems are more restrictive than in the time-invariant case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1490</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1490</id><created>2013-05-30</created><authors><author><keyname>Martin</keyname><forenames>Philippe A.</forenames></author></authors><title>Managing Knowledge to Enhance Learning</title><categories>cs.CY</categories><comments>17 pages, 4 figures, 2 tables, journal</comments><acm-class>I.2.4</acm-class><journal-ref>KM&amp;EL 2 (2009) 103-119</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article first summarizes reasons why current approaches supporting Open
Learning and Distance Education need to be complemented by tools permitting
lecturers, researchers and students to cooperatively organize the semantic
content of Learning related materials (courses, discussions, etc.) into a
fine-grained shared semantic network. This first part of the article also
quickly describes the approach adopted to permit such a collaborative work.
Then, examples of such semantic networks are presented. Finally, an evaluation
of the approach by students is provided and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1491</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1491</id><created>2013-06-02</created><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Tan</keyname><forenames>Colin Keng-Yan</forenames></author></authors><title>Gaussian Process-Based Decentralized Data Fusion and Active Sensing for
  Mobility-on-Demand System</title><categories>cs.RO cs.DC cs.LG cs.MA</categories><comments>Robotics: Science and Systems (RSS 2013), Extended version with
  proofs, 10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobility-on-demand (MoD) systems have recently emerged as a promising
paradigm of one-way vehicle sharing for sustainable personal urban mobility in
densely populated cities. In this paper, we enhance the capability of a MoD
system by deploying robotic shared vehicles that can autonomously cruise the
streets to be hailed by users. A key challenge to managing the MoD system
effectively is that of real-time, fine-grained mobility demand sensing and
prediction. This paper presents a novel decentralized data fusion and active
sensing algorithm for real-time, fine-grained mobility demand sensing and
prediction with a fleet of autonomous robotic vehicles in a MoD system. Our
Gaussian process (GP)-based decentralized data fusion algorithm can achieve a
fine balance between predictive power and time efficiency. We theoretically
guarantee its predictive performance to be equivalent to that of a
sophisticated centralized sparse approximation for the GP model: The
computation of such a sparse approximate GP model can thus be distributed among
the MoD vehicles, hence achieving efficient and scalable demand prediction.
Though our decentralized active sensing strategy is devised to gather the most
informative demand data for demand prediction, it can achieve a dual effect of
fleet rebalancing to service the mobility demands. Empirical evaluation on
real-world mobility demand data shows that our proposed algorithm can achieve a
better balance between predictive accuracy and time efficiency than
state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1511</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1511</id><created>2013-06-06</created><authors><author><keyname>Nguyen</keyname><forenames>Tin Chi</forenames></author><author><keyname>Zhao</keyname><forenames>Zhiyu</forenames></author><author><keyname>Zhu</keyname><forenames>Dongxiao</forenames></author></authors><title>SPATA: A Seeding and Patching Algorithm for Hybrid Transcriptome
  Assembly</title><categories>cs.CE q-bio.GN</categories><comments>The GUI software suite is freely available from
  http://sammate.sourceforge.net; Contact: tin.nguyenchi@wayne.edu,
  dzhu@wayne.edu</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transcriptome assembly from RNA-Seq reads is an active area of bioinformatics
research. The ever-declining cost and the increasing depth of RNA-Seq have
provided unprecedented opportunities to better identify expressed transcripts.
However, the nonlinear transcript structures and the ultra-high throughput of
RNA-Seq reads pose significant algorithmic and computational challenges to the
existing transcriptome assembly approaches, either reference-guided or de novo.
While reference-guided approaches offer good sensitivity, they rely on
alignment results of the splice-aware aligners and are thus unsuitable for
species with incomplete reference genomes. In contrast, de novo approaches do
not depend on the reference genome but face a computational daunting task
derived from the complexity of the graph built for the whole transcriptome. In
response to these challenges, we present a hybrid approach to exploit an
incomplete reference genome without relying on splice-aware aligners. We have
designed a split-and-align procedure to efficiently localize the reads to
individual genomic loci, which is followed by an accurate de novo assembly to
assemble reads falling into each locus. Using extensive simulation data, we
demonstrate a high accuracy and precision in transcriptome reconstruction by
comparing to selected transcriptome assembly tools. Our method is implemented
in assemblySAM, a GUI software freely available at
http://sammate.sourceforge.net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1519</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1519</id><created>2013-06-06</created><authors><author><keyname>Signac</keyname><forenames>Laurent</forenames><affiliation>LAII</affiliation></author></authors><title>Lattice Gas Symmetric Cryptography</title><categories>cs.CR nlin.CG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice gas cellular automata (Lgca) are particular cellular automata that
imitate the behavior of par- ticles moving on a lattice. We used a particular
set of Lgca rules, called hpp, to mix bits in data blocks and obtain a
symmetric cryptographic algorithm. The encryption and decryption keys are the
positions of perturbation sites on the lattice (walls). Basically, this paper
presents an original way to perform cryp- tographic operations, based on
cellular automata. In this paper, we show several characteristics about our
algorithm: typical block size (2^(2n-1) ), key-length (2^n ), number of rounds
(2^(n+1) ). We also evaluate avalanche and strict avalanche properties with
respect to key and plain text. Finally, we highlight the underbellies of our
method and give clues to solve them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1520</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1520</id><created>2013-06-06</created><authors><author><keyname>Scherrer</keyname><forenames>Bruno</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author><author><keyname>Geist</keyname><forenames>Matthieu</forenames></author></authors><title>Policy Search: Any Local Optimum Enjoys a Global Performance Guarantee</title><categories>cs.LG cs.AI cs.RO math.OC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Local Policy Search is a popular reinforcement learning approach for handling
large state spaces. Formally, it searches locally in a paramet erized policy
space in order to maximize the associated value function averaged over some
predefined distribution. It is probably commonly b elieved that the best one
can hope in general from such an approach is to get a local optimum of this
criterion. In this article, we show th e following surprising result:
\emph{any} (approximate) \emph{local optimum} enjoys a \emph{global performance
guarantee}. We compare this g uarantee with the one that is satisfied by Direct
Policy Iteration, an approximate dynamic programming algorithm that does some
form of Poli cy Search: if the approximation error of Local Policy Search may
generally be bigger (because local search requires to consider a space of s
tochastic policies), we argue that the concentrability coefficient that appears
in the performance bound is much nicer. Finally, we discuss several practical
and theoretical consequences of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1547</identifier>
 <datestamp>2013-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1547</id><created>2013-06-06</created><updated>2013-10-08</updated><authors><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>Indyk</keyname><forenames>Piotr</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy L.</forenames></author><author><keyname>Razenshteyn</keyname><forenames>Ilya</forenames></author></authors><title>Beyond Locality-Sensitive Hashing</title><categories>cs.DS cs.CG</categories><comments>17 pages, many corrections, added some intuition for the main
  ingredients, Section 4 has been rewritten completely; to appear at ACM-SIAM
  Symposium on Discrete Algorithms (SODA 2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new data structure for the c-approximate near neighbor problem
(ANN) in the Euclidean space. For n points in R^d, our algorithm achieves
O(n^{\rho} + d log n) query time and O(n^{1 + \rho} + d log n) space, where
\rho &lt;= 7/(8c^2) + O(1 / c^3) + o(1). This is the first improvement over the
result by Andoni and Indyk (FOCS 2006) and the first data structure that
bypasses a locality-sensitive hashing lower bound proved by O'Donnell, Wu and
Zhou (ICS 2011). By a standard reduction we obtain a data structure for the
Hamming space and \ell_1 norm with \rho &lt;= 7/(8c) + O(1/c^{3/2}) + o(1), which
is the first improvement over the result of Indyk and Motwani (STOC 1998).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1553</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1553</id><created>2013-06-06</created><updated>2013-06-25</updated><authors><author><keyname>Rodionov</keyname><forenames>Sergey</forenames></author><author><keyname>Potapov</keyname><forenames>Alexey</forenames></author><author><keyname>Vinogradov</keyname><forenames>Yurii</forenames></author></authors><title>Direct Uncertainty Estimation in Reinforcement Learning</title><categories>cs.AI</categories><comments>AGI-13 Workshop paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal probabilistic approach in reinforcement learning is computationally
infeasible. Its simplification consisting in neglecting difference between true
environment and its model estimated using limited number of observations causes
exploration vs exploitation problem. Uncertainty can be expressed in terms of a
probability distribution over the space of environment models, and this
uncertainty can be propagated to the action-value function via Bellman
iterations, which are computationally insufficiently efficient though. We
consider possibility of directly measuring uncertainty of the action-value
function, and analyze sufficiency of this facilitated approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1556</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1556</id><created>2013-06-06</created><updated>2013-09-11</updated><authors><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author></authors><title>Diversity Polynomials for the Analysis of Temporal Correlations in
  Wireless Networks</title><categories>cs.IT cs.NI math.IT math.PR</categories><comments>Accepted for publication in IEEE Trans. on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interference in wireless networks is temporally correlated, since the
node or user locations are correlated over time and the interfering
transmitters are a subset of these nodes. For a wireless network where
(potential) interferers form a Poisson point process and use ALOHA for channel
access, we calculate the joint success and outage probabilities of n
transmissions over a reference link. The results are based on the diversity
polynomial, which captures the temporal interference correlation. The joint
outage probability is used to determine the diversity gain (as the SIR goes to
infinity), and it turns out that there is no diversity gain in simple
retransmission schemes, even with independent Rayleigh fading over all links.
We also determine the complete joint SIR distribution for two transmissions and
the distribution of the local delay, which is the time until a repeated
transmission over the reference link succeeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1557</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1557</id><created>2013-06-06</created><authors><author><keyname>Potapov</keyname><forenames>Alexey</forenames></author><author><keyname>Rodionov</keyname><forenames>Sergey</forenames></author></authors><title>Extending Universal Intelligence Models with Formal Notion of
  Representation</title><categories>cs.AI</categories><comments>proceedings of AGI 2012, Lecture Notes in Artificial Intelligence,
  Vol. 7716, pp. 242-251, Springer-Verlag, 2012. The final publication is
  available at link.springer.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solomonoff induction is known to be universal, but incomputable. Its
approximations, namely, the Minimum Description (or Message) Length (MDL)
principles, are adopted in practice in the efficient, but non-universal form.
Recent attempts to bridge this gap leaded to development of the
Representational MDL principle that originates from formal decomposition of the
task of induction. In this paper, possible extension of the RMDL principle in
the context of universal intelligence agents is considered, for which
introduction of representations is shown to be an unavoidable meta-heuristic
and a step toward efficient general intelligence. Hierarchical representations
and model optimization with the use of information-theoretic interpretation of
the adaptive resonance are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1572</identifier>
 <datestamp>2015-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1572</id><created>2013-06-06</created><updated>2015-10-01</updated><authors><author><keyname>Farre</keyname><forenames>James</forenames></author><author><keyname>Kleinschmidt</keyname><forenames>Helena</forenames></author><author><keyname>Sidman</keyname><forenames>Jessica</forenames></author><author><keyname>John</keyname><forenames>Audrey Lee-St.</forenames></author><author><keyname>Stark</keyname><forenames>Stephanie</forenames></author><author><keyname>Theran</keyname><forenames>Louis</forenames></author><author><keyname>Yu</keyname><forenames>Xilin</forenames></author></authors><title>Algorithms for detecting dependencies and rigid subsystems for CAD</title><categories>cs.CG math.CO</categories><comments>37 pages, 14 figures (v2 is an expanded version of an AGD'14 abstract
  based on v1)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric constraint systems underly popular Computer Aided Design soft-
ware. Automated approaches for detecting dependencies in a design are critical
for developing robust solvers and providing informative user feedback, and we
provide algorithms for two types of dependencies. First, we give a pebble game
algorithm for detecting generic dependencies. Then, we focus on identifying the
&quot;special positions&quot; of a design in which generically independent constraints
become dependent. We present combinatorial algorithms for identifying subgraphs
associated to factors of a particular polynomial, whose vanishing indicates a
special position and resulting dependency. Further factoring in the Grassmann-
Cayley algebra may allow a geometric interpretation giving conditions (e.g.,
&quot;these two lines being parallel cause a dependency&quot;) determining the special
position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1586</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1586</id><created>2013-06-06</created><updated>2014-05-22</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author></authors><title>Strong converse for the classical capacity of entanglement-breaking and
  Hadamard channels via a sandwiched Renyi relative entropy</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>33 pages; v4: minor changes throughout, accepted for publication in
  Communications in Mathematical Physics</comments><journal-ref>Communications in Mathematical Physics, vol. 331, no. 2, pages
  593-622, October 2014</journal-ref><doi>10.1007/s00220-014-2122-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A strong converse theorem for the classical capacity of a quantum channel
states that the probability of correctly decoding a classical message converges
exponentially fast to zero in the limit of many channel uses if the rate of
communication exceeds the classical capacity of the channel. Along with a
corresponding achievability statement for rates below the capacity, such a
strong converse theorem enhances our understanding of the capacity as a very
sharp dividing line between achievable and unachievable rates of communication.
Here, we show that such a strong converse theorem holds for the classical
capacity of all entanglement-breaking channels and all Hadamard channels (the
complementary channels of the former). These results follow by bounding the
success probability in terms of a &quot;sandwiched&quot; Renyi relative entropy, by
showing that this quantity is subadditive for all entanglement-breaking and
Hadamard channels, and by relating this quantity to the Holevo capacity. Prior
results regarding strong converse theorems for particular covariant channels
emerge as a special case of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1591</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1591</id><created>2013-06-06</created><authors><author><keyname>Ristic</keyname><forenames>Branko</forenames></author><author><keyname>Skvortsov</keyname><forenames>Alex</forenames></author><author><keyname>Walker</keyname><forenames>Andrew</forenames></author></authors><title>Autonomous search for a diffusive source in an unknown environment</title><categories>cs.AI cs.RO q-bio.NC</categories><comments>11 pages, 7 figures</comments><doi>10.3390/e16020789</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents an approach to olfactory search for a diffusive emitting
source of tracer (e.g. aerosol, gas) in an environment with unknown map of
randomly placed and shaped obstacles.
  The measurements of tracer concentration are sporadic, noisy and without
directional information. The search domain is discretised and modelled by a
finite two-dimensional lattice. The links is the lattice represent the
traversable paths for emitted particles and for the searcher. A missing link in
the lattice indicates a blocked paths, due to the walls or obstacles. The
searcher must simultaneously estimate the source parameters, the map of the
search domain and its own location within the map. The solution is formulated
in the sequential Bayesian framework and implemented as a Rao-Blackwellised
particle filter with information-driven motion control. The numerical results
demonstrate the concept and its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1595</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1595</id><created>2013-06-06</created><updated>2015-04-13</updated><authors><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Layered Separators in Minor-Closed Families with Applications</title><categories>math.CO cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph separators are a ubiquitous tool in graph theory and computer science.
However, in some applications, their usefulness is limited by the fact that the
separator can be as large as $\Omega(\sqrt{n})$ in graphs with $n$ vertices.
This is the case for planar graphs, and more generally, for proper minor-closed
families. We study a special type of graph separator, called a layered
separator, which may have linear size in $n$, but has bounded size with respect
to a different measure, called the breadth. We prove that planar graphs and
graphs of bounded Euler genus admit layered separators of bounded breadth. More
generally, we characterise the minor-closed classes that admit layered
separators of bounded breadth as those that exclude a fixed apex graph as a
minor.
  We use layered separators to prove $O(\log n)$ bounds for a number of
problems where $O(\sqrt{n})$ was a long standing previous best bound. This
includes the nonrepetitive chromatic number and queue-number of graphs with
bounded Euler genus. We extend these results to all proper minor-closed
families, with a $O(\log n)$ bound on the nonrepetitive chromatic number, and a
$\log^{O(1)}n$ bound on the queue-number. Only for planar graphs were
$\log^{O(1)}n$ bounds previously known. Our results imply that every graph from
a proper minor-closed class has a 3-dimensional grid drawing with
$n\log^{O(1)}n$ volume, whereas the previous best bound was $O(n^{3/2})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1599</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1599</id><created>2013-06-06</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>New Views of Crystal Symmetry</title><categories>cond-mat.mtrl-sci cs.GR math.RA physics.hist-ph</categories><comments>4 pages, 4 figures</comments><journal-ref>in special issue of The Journal of the Int. Soc. For the
  Interdisciplinary Study of Symmetry: J. Rebielak (ed.), Proc. of Symmetries
  of Forms and Structures, Wroclaw and Cracow, Poland, 14-19 Sep. 2009, pp.
  112-115 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Already Hermann Grassmann's father Justus (1829, 1830) published two works on
the geometrical description of crystals, influenced by the earlier works of
C.S. Weiss (1780-1856) on three main crystal forces governing crystal
formation. In his 1840 essay on the derivation of crystal shapes from the
general law of crystal formation Hermann established the notion of a
three-dimensional vectorial system of forces with rational coefficients, that
represent the interior crystal structure, regulate its formation, its shape and
physical behavior. In the Ausdehnungslehre 1844 (Paragraph 171) he finally
writes: I shall conclude this presentation by one of the most beautiful
applications which can be made of the science treated, i.e. the application to
crystal figures (Scholz, 1996). The geometry of crystals thus certainly
influenced the Ausdehnungslehre. In this paper we see how Grassmann's work
influenced Clifford's creation of geometric algebras, which in turn leads to a
new geometric description of crystal symmetry suitable for modern computer
algebra graphics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1603</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1603</id><created>2013-06-06</created><authors><author><keyname>Ghiass</keyname><forenames>Reza Shoja</forenames></author><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author><author><keyname>Bendada</keyname><forenames>Hakim</forenames></author><author><keyname>Maldague</keyname><forenames>Xavier</forenames></author></authors><title>Infrared face recognition: a literature review</title><categories>cs.CV</categories><comments>International Joint Conference on Neural Networks, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic face recognition (AFR) is an area with immense practical potential
which includes a wide range of commercial and law enforcement applications, and
it continues to be one of the most active research areas of computer vision.
Even after over three decades of intense research, the state-of-the-art in AFR
continues to improve, benefiting from advances in a range of different fields
including image processing, pattern recognition, computer graphics and
physiology. However, systems based on visible spectrum images continue to face
challenges in the presence of illumination, pose and expression changes, as
well as facial disguises, all of which can significantly decrease their
accuracy. Amongst various approaches which have been proposed in an attempt to
overcome these limitations, the use of infrared (IR) imaging has emerged as a
particularly promising research direction. This paper presents a comprehensive
and timely review of the literature on this subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1604</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1604</id><created>2013-06-07</created><authors><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author></authors><title>Design Based Teaching for Science and Engineering Students</title><categories>cs.CY</categories><comments>Proc. of the 5th Conference on Canadian Design Engineering Network
  (CDEN'08)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will explain a successfully proven lecturing method based
entirely on system design. Wireless communications will be used as an example
to explain this new teaching philosophy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1609</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1609</id><created>2013-06-07</created><authors><author><keyname>Ghiass</keyname><forenames>Reza Shoja</forenames></author><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author><author><keyname>Bendada</keyname><forenames>Hakim</forenames></author><author><keyname>Maldague</keyname><forenames>Xavier</forenames></author></authors><title>Vesselness features and the inverse compositional AAM for robust face
  recognition using thermal IR</title><categories>cs.CV</categories><journal-ref>AAAI Conference on Artificial Intelligence, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the course of the last decade, infrared (IR) and particularly thermal IR
imaging based face recognition has emerged as a promising complement to
conventional, visible spectrum based approaches which continue to struggle when
applied in the real world. While inherently insensitive to visible spectrum
illumination changes, IR images introduce specific challenges of their own,
most notably sensitivity to factors which affect facial heat emission patterns,
e.g. emotional state, ambient temperature, and alcohol intake. In addition,
facial expression and pose changes are more difficult to correct in IR images
because they are less rich in high frequency detail which is an important cue
for fitting any deformable model. We describe a novel method which addresses
these challenges. To normalize for pose and facial expression changes we
generate a synthetic frontal image of a face in a canonical, neutral facial
expression from an image of the face in an arbitrary pose and facial
expression. This is achieved by piecewise affine warping which follows active
appearance model (AAM) fitting. This is the first publication which explores
the use of an AAM on thermal IR images; we propose a pre-processing step which
enhances detail in thermal images, making AAM convergence faster and more
accurate. To overcome the problem of thermal IR image sensitivity to the
pattern of facial temperature emissions we describe a representation based on
reliable anatomical features. In contrast to previous approaches, our
representation is not binary; rather, our method accounts for the reliability
of the extracted features. This makes the proposed representation much more
robust both to pose and scale changes. The effectiveness of the proposed
approach is demonstrated on the largest public database of thermal IR images of
faces on which it achieved 100% identification, significantly outperforming
previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1618</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1618</id><created>2013-06-07</created><updated>2013-10-02</updated><authors><author><keyname>Vinsen</keyname><forenames>Kevin</forenames></author><author><keyname>Thilker</keyname><forenames>David</forenames></author></authors><title>A BOINC based, citizen-science project for pixel Spectral Energy
  Distribution fitting of resolved galaxies in multi-wavelength surveys</title><categories>astro-ph.IM astro-ph.GA cs.DC</categories><comments>14 pages, 16 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present our experience from the first year of theSkyNet
Pan-STARRS1 Optical Galaxy Survey (POGS) project. This citizen-scientist driven
research project uses the Berkeley Open Infrastructure for Network Computing
(BOINC) middleware and thousands of Internet-connected computers to measure the
resolved galactic structural properties of ~100,000 low redshift galaxies. We
are combining the spectral coverage of GALEX, Pan-STARRS1, SDSS, and WISE to
generate a value-added, multi-wavelength UV-optical-NIR galaxy atlas for the
nearby Universe. Specifically, we are measuring physical parameters (such as
local stellar mass, star formation rate, and first-order star formation
history) on a resolved pixel-by-pixel basis using spectral energy distribution
(SED) fitting techniques in a distributed computing mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1619</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1619</id><created>2013-06-07</created><authors><author><keyname>Yoon</keyname><forenames>Ji Won</forenames></author></authors><title>Statistical Denoising for single molecule fluorescence microscopic
  images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single molecule fluorescence microscopy is a powerful technique for
uncovering detailed information about biological systems, both in vitro and in
vivo. In such experiments, the inherently low signal to noise ratios mean that
accurate algorithms to separate true signal and background noise are essential
to generate meaningful results. To this end, we have developed a new and robust
method to reduce noise in single molecule fluorescence images by using a
Gaussian Markov Random Field (GMRF) prior in a Bayesian framework. Two
different strategies are proposed to build the prior - an intrinsic GMRF, with
a stationary relationship between pixels and a heterogeneous intrinsic GMRF,
with a differently weighted relationship between pixels classified as molecules
and background. Testing with synthetic and real experimental fluorescence
images demonstrates that the heterogeneous intrinsic GMRF is superior to other
conventional de-noising approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1630</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1630</id><created>2013-06-07</created><authors><author><keyname>Sambhanthan</keyname><forenames>Arunasalam</forenames></author><author><keyname>Good</keyname><forenames>Alice</forenames></author></authors><title>Enhancing Tourism Destination Accessibility in Developing Countries
  through Virtual Worlds</title><categories>cs.HC cs.CY</categories><comments>Journal article corresponding to arXiv:1302.5199</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of destination accessibility is a vital concern in the
sustainable tourism development in the emerging regions due to the increasing
numbers of tourism business growth in the recent times. Tourism is one of the
potential foreign exchange earning sectors, which place sustainability as one
of the main success metrics for benchmarking the overall development of the
industry. On the other hand, there are several destinations, which are
inaccessible to tourists due to several reasons. Underutilization of potential
destinations in both pre purchase and consumption stages is a strategic
disadvantage for emerging countries on leading their tourism industry towards
sustainability. This research embarks on a content analysis of second life
based tourism groups and places. Requirement of a virtual world model to
increase the destination accessibility of tourism products has been outlined.
The model has to be designed with visual and auditory experience to tourists.
The model is expected to enhance the accessibility of destinations for users of
different categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1632</identifier>
 <datestamp>2015-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1632</id><created>2013-06-07</created><updated>2015-01-31</updated><authors><author><keyname>Luo</keyname><forenames>Jie</forenames></author></authors><title>A Generalized Channel Coding Theory for Distributed Communication</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents generalized channel coding theorems for a time-slotted
distributed communication system where a transmitter-receiver pair is
communicating in parallel with other transmitters. Assume that the channel code
of each transmitter is chosen arbitrarily in each time slot. The coding choice
of a transmitter is denoted by a code index parameter, which is known neither
to other transmitters nor to the receiver. Fundamental performance limitation
of the system is characterized using an achievable region defined in the space
of the code index vectors. As the codeword length is taken to infinity, for all
code index vectors inside the region, the receiver will decode the message
reliably, while for all code index vectors outside the region, the receiver
will report a collision reliably. A generalized system error performance
measure is defined as the weighted sum of probabilities of different types of
communication error events. Assume that the receiver chooses an &quot;operation
region&quot; and intends to decode the message if the code index vector is inside
the operation region. Achievable bounds on the tradeoff between the operation
region and the generalize error performance measure are obtained under the
assumption of a finite codeword length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1639</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1639</id><created>2013-06-07</created><authors><author><keyname>Chana</keyname><forenames>Inderveer</forenames></author><author><keyname>Kaur</keyname><forenames>Tarandeep</forenames></author></authors><title>Delivering IT as A Utility- A Systematic Review</title><categories>cs.DC</categories><comments>No. of Pages- 20 No. of Figures- 3 No. of Tables- 11</comments><msc-class>68-02[Survey Article]</msc-class><journal-ref>International Journal in Foundations of Computer Science &amp;
  Technology(IJFCST), Volume 3, No.3, May, 2013</journal-ref><doi>10.5121/ijfcst.2013.3302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Utility Computing has facilitated the creation of new markets that has made
it possible to realize the long held dream of delivering IT as a Utility. Even
though utility computing is in its nascent stage today, the proponents of
utility computing envisage that it will become a commodity business in the
upcoming time and utility service providers will meet all the IT requests of
the companies. This paper takes a cross-sectional view at the emergence of
utility computing along with different requirements needed to realize utility
model. It also surveys the current trends in utility computing highlighting
diverse architecture models aligned towards delivering IT as a utility.
Different resource management systems for proficient allocation of resources
have been listed together with various resource scheduling and pricing
strategies used by them. Further, a review of generic key perspectives closely
related to the concept of delivering IT as a Utility has been taken citing the
contenders for the future enhancements in this technology in the form of Grid
and Cloud Computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1650</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1650</id><created>2013-06-07</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>OPS-QFTs: A new type of quaternion Fourier transforms based on the
  orthogonal planes split with one or two general pure quaternions</title><categories>math.RA cs.CV</categories><comments>4 pages</comments><msc-class>15A66, 42A38</msc-class><journal-ref>Numerical Analysis and and Applied Mathematics ICNAAM 2011:
  International Conference on Numerical Analysis and Applied Mathematics. AIP
  Conference Proceedings, Volume 1389, pp. 280-283 (2011)</journal-ref><doi>10.1063/1.3636721</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explain the orthogonal planes split (OPS) of quaternions based on the
arbitrary choice of one or two linearly independent pure unit quaternions
$f,g$. Next we systematically generalize the quaternionic Fourier transform
(QFT) applied to quaternion fields to conform with the OPS determined by $f,g$,
or by only one pure unit quaternion $f$, comment on their geometric meaning,
and establish inverse transformations.
  Keywords: Clifford geometric algebra, quaternion geometry, quaternion Fourier
transform, inverse Fourier transform, orthogonal planes split
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1651</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1651</id><created>2013-06-07</created><authors><author><keyname>Huang</keyname><forenames>Wenchao</forenames></author><author><keyname>Xiong</keyname><forenames>Yan</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Lin</keyname><forenames>Hao</forenames></author><author><keyname>Mao</keyname><forenames>Xufei</forenames></author><author><keyname>Yang</keyname><forenames>Panlong</forenames></author><author><keyname>Liu</keyname><forenames>Yunhao</forenames></author></authors><title>Accurate Indoor Localization Using Acoustic Direction Finding via Smart
  Phones</title><categories>cs.NI</categories><comments>Under submission</comments><acm-class>C.2.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and implement a novel indoor localization scheme, Swadloon, built
upon an accurate acoustic direction finding. Swadloon leverages sensors of the
smartphone without the requirement of any specialized devices. The scheme
Swadloon does not rely on any fingerprints and is very easy to use: a user only
needs to shake the phone for a short duration before walking and localization.
Our Swadloon design exploits a key observation: the relative shift and velocity
of the phone-shaking movement corresponds to the subtle phase and frequency
shift of the Doppler effects experienced in the received acoustic signal by the
phone. A novel method is designed to derive the direction from the phone to the
acoustic source by combining the velocity calculated from the subtle Doppler
shift with the one from the inertial sensors of the phone. Then a real-time
precise localization and tracking is enabled by using a few anchor speakers
with known locations. Major challenges in implementing Swadloon are to measure
the frequency shift precisely and to estimate the shaking velocity accurately
when the speed of phone-shaking is low and changes arbitrarily. We propose
rigorous methods to address these challenges, then design and deploy Swadloon
in several floors of an indoor building each with area about 2000m^2. Our
extensive experiments show that the mean error of direction finding is around
2.1 degree when the acoustic source is within the range of 32m. For indoor
localization, the 90-percentile errors are under 0.92m, while the maximum error
is 1.73m and the mean is about 0.5m. For real-time tracking, the errors are
within 0.4m for walks of 51m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1653</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1653</id><created>2013-06-07</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>Non-constant bounded holomorphic functions of hyperbolic numbers -
  Candidates for hyperbolic activation functions</title><categories>cs.NE cs.CV math.RA</categories><comments>6 pages, 2 figures</comments><journal-ref>in Y. Kuroe, T. Nitta (eds.), Proceedings of the First SICE
  Symposium on Computational Intelligence [Concentrating on Clifford Neural
  Computing], 30 Sep. 2011, KIT, Kyoto, Japan, catalogue no. 11PG0009, pp. 23 -
  28, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Liouville theorem states that bounded holomorphic complex functions are
necessarily constant. Holomorphic functions fulfill the socalled Cauchy-Riemann
(CR) conditions. The CR conditions mean that a complex $z$-derivative is
independent of the direction. Holomorphic functions are ideal for activation
functions of complex neural networks, but the Liouville theorem makes them
useless. Yet recently the use of hyperbolic numbers, lead to the construction
of hyperbolic number neural networks. We will describe the Cauchy-Riemann
conditions for hyperbolic numbers and show that there exists a new interesting
type of bounded holomorphic functions of hyperbolic numbers, which are not
constant. We give examples of such functions. They therefore substantially
expand the available candidates for holomorphic activation functions for
hyperbolic number neural networks.
  Keywords: Hyperbolic numbers, Liouville theorem, Cauchy-Riemann conditions,
bounded holomorphic functions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1656</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1656</id><created>2013-06-07</created><authors><author><keyname>Hon</keyname><forenames>Wing-Kai</forenames></author><author><keyname>Kloks</keyname><forenames>Ton</forenames></author><author><keyname>Liu</keyname><forenames>Hsiang-Hsuan</forenames></author><author><keyname>Poon</keyname><forenames>Sheung-Hung</forenames></author><author><keyname>Wang</keyname><forenames>Yue-Li</forenames></author></authors><title>Results on independent sets in categorical products of graphs, the
  ultimate categorical independence ratio and the ultimate categorical
  independent domination ratio</title><categories>cs.DM math.CO</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.4237</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there are polynomial-time algorithms to compute maximum
independent sets in the categorical products of two cographs and two
splitgraphs. The ultimate categorical independence ratio of a graph G is
defined as lim_{k --&gt; infty} \alpha(G^k)/n^k. The ultimate categorical
independence ratio is polynomial for cographs, permutation graphs, interval
graphs, graphs of bounded treewidth and splitgraphs. When G is a planar graph
of maximal degree three then alpha(G \times K_4) is NP-complete. We present a
PTAS for the ultimate categorical independence ratio of planar graphs. We
present an O^*(n^{n/3}) exact, exponential algorithm for general graphs. We
prove that the ultimate categorical independent domination ratio for complete
multipartite graphs is zero, except when the graph is complete bipartite with
color classes of equal size (in which case it is 1/2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1662</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1662</id><created>2013-06-07</created><updated>2013-10-14</updated><authors><author><keyname>Ruder</keyname><forenames>Michael A.</forenames></author><author><keyname>Meyer</keyname><forenames>Raimund</forenames></author><author><keyname>Obernosterer</keyname><forenames>Frank</forenames></author><author><keyname>Kalveram</keyname><forenames>Hans</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Gerstacker</keyname><forenames>Wolfgang H.</forenames></author></authors><title>Receiver Concepts and Resource Allocation for OSC Downlink Transmission</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications; Revision 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice services over Adaptive Multi-user channels on One Slot (VAMOS) has been
standardized as an extension to the Global System for Mobile Communications
(GSM). The aim of VAMOS is to increase the capacity of GSM, while maintaining
backward compatibility with the legacy system. To this end, the Orthogonal
Sub-channels (OSC) concept is employed, where two Gaussian minimum-shift keying
(GMSK) signals are transmitted in the same time slot and with the same carrier
frequency. To fully exploit the possible capacity gain of OSC, new receiver
concepts are necessary. In contrast to the base station, where multiple
antennas can be employed, the mobile station is typically equipped with only
one receive antenna. Therefore, the downlink receiver design is a very
challenging task. Different concepts for channel estimation, user separation,
and equalization at the receiver of an OSC downlink transmission are introduced
in this paper. Furthermore, the system capacity must be improved by suitable
downlink power and resource allocation algorithms. Making realistic assumptions
on the information available at the base station, an algorithm for joint power
and radio resource allocation is proposed. Simulation results show the
excellent performance of the proposed channel estimation algorithms,
equalization schemes, and joint radio resource and power allocation algorithms
in realistic VAMOS environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1665</identifier>
 <datestamp>2014-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1665</id><created>2013-06-07</created><authors><author><keyname>Sayin</keyname><forenames>Muhammed O.</forenames></author><author><keyname>Kozat</keyname><forenames>Suleyman S.</forenames></author></authors><title>Single Bit and Reduced Dimension Diffusion Strategies Over Distributed
  Networks</title><categories>cs.SY</categories><comments>Submitted to the IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2013.2273304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce novel diffusion based adaptive estimation strategies for
distributed networks that have significantly less communication load and
achieve comparable performance to the full information exchange configurations.
After local estimates of the desired data is produced in each node, a single
bit of information (or a reduced dimensional data vector) is generated using
certain random projections of the local estimates. This newly generated data is
diffused and then used in neighboring nodes to recover the original full
information. We provide the complete state-space description and the mean
stability analysis of our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1669</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1669</id><created>2013-06-07</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>Quaternionic Fourier-Mellin Transform</title><categories>math.RA cs.CV</categories><comments>11 pages, 9 figures</comments><journal-ref>in T. Sugawa (ed.), Proc. of the The 19th Int. Conf. on Finite or
  Infinite Dim. Complex Analysis and Appl. (ICFIDCAA), 11-15 December 2011,
  Hiroshima, Japan, Tohoku Univ. Press, Sendai (2013), pp. ii, 123-131</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution we generalize the classical Fourier Mellin transform [S.
Dorrode and F. Ghorbel, Robust and efficient Fourier-Mellin transform
approximations for gray-level image reconstruction and complete invariant
description, Computer Vision and Image Understanding, 83(1) (2001), 57-78, DOI
10.1006/cviu.2001.0922.], which transforms functions $f$ representing, e.g., a
gray level image defined over a compact set of $\mathbb{R}^2$. The quaternionic
Fourier Mellin transform (QFMT) applies to functions $f: \mathbb{R}^2
\rightarrow \mathbb{H}$, for which $|f|$ is summable over $\mathbb{R}_+^*
\times \mathbb{S}^1$ under the measure $d\theta \frac{dr}{r}$. $\mathbb{R}_+^*$
is the multiplicative group of positive and non-zero real numbers. We
investigate the properties of the QFMT similar to the investigation of the
quaternionic Fourier Transform (QFT) in [E. Hitzer, Quaternion Fourier
Transform on Quaternion Fields and Generalizations, Advances in Applied
Clifford Algebras, 17(3) (2007), 497-517.; E. Hitzer, Directional Uncertainty
Principle for Quaternion Fourier Transforms, Advances in Applied Clifford
Algebras, 20(2) (2010), 271-284, online since 08 July 2009.].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1676</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1676</id><created>2013-06-07</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>Algebraic foundations of split hypercomplex nonlinear adaptive filtering</title><categories>cs.CV math.RA</categories><comments>14 pages, 1 figure</comments><msc-class>60G35, 15A66</msc-class><journal-ref>Mathematical Methods in the Applied Sciences, Volume 36, Issue 9,
  pages 1042-1055, June 2013</journal-ref><doi>10.1002/mma.2660</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A split hypercomplex learning algorithm for the training of nonlinear finite
impulse response adaptive filters for the processing of hypercomplex signals of
any dimension is proposed. The derivation strictly takes into account the laws
of hypercomplex algebra and hypercomplex calculus, some of which have been
neglected in existing learning approaches (e.g. for quaternions). Already in
the case of quaternions we can predict improvements in performance of
hypercomplex processes. The convergence of the proposed algorithms is
rigorously analyzed.
  Keywords: Quaternionic adaptive filtering, Hypercomplex adaptive filtering,
Nonlinear adaptive filtering, Hypercomplex Multilayer Perceptron, Clifford
geometric algebra
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1677</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1677</id><created>2013-06-07</created><authors><author><keyname>Nikoletseas</keyname><forenames>S.</forenames></author><author><keyname>Panagopoulou</keyname><forenames>P.</forenames></author><author><keyname>Raptopoulos</keyname><forenames>C.</forenames></author><author><keyname>Spirakis</keyname><forenames>P. G.</forenames></author></authors><title>On the Structure of Equilibria in Basic Network Formation</title><categories>cs.GT</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study network connection games where the nodes of a network perform edge
swaps in order to improve their communication costs. For the model proposed by
Alon et al. (2010), in which the selfish cost of a node is the sum of all
shortest path distances to the other nodes, we use the probabilistic method to
provide a new, structural characterization of equilibrium graphs. We show how
to use this characterization in order to prove upper bounds on the diameter of
equilibrium graphs in terms of the size of the largest $k$-vicinity (defined as
the the set of vertices within distance $k$ from a vertex), for any $k \geq 1$
and in terms of the number of edges, thus settling positively a conjecture of
Alon et al. in the cases of graphs of large $k$-vicinity size (including graphs
of large maximum degree) and of graphs which are dense enough.
  Next, we present a new swap-based network creation game, in which selfish
costs depend on the immediate neighborhood of each node; in particular, the
profit of a node is defined as the sum of the degrees of its neighbors. We
prove that, in contrast to the previous model, this network creation game
admits an exact potential, and also that any equilibrium graph contains an
induced star. The existence of the potential function is exploited in order to
show that an equilibrium can be reached in expected polynomial time even in the
case where nodes can only acquire limited knowledge concerning non-neighboring
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1679</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1679</id><created>2013-06-07</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>Clifford Fourier-Mellin transform with two real square roots of -1 in
  Cl(p,q), p+q=2</title><categories>math.RA cs.CV</categories><comments>6 pages, 2 figures</comments><journal-ref>9th International conference on mathematical problems in
  engineering, aerospace and sciences: ICNPAA 2012. AIP Conference Proceedings,
  Volume 1493, pp. 480-485 (2012)</journal-ref><doi>10.1063/1.4765531</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a non-commutative generalization of the complex Fourier-Mellin
transform to Clifford algebra valued signal functions over the domain
$\R^{p,q}$ taking values in Cl(p,q), p+q=2.
  Keywords: algebra, Fourier transforms; Logic, set theory, and algebra,
Fourier analysis, Integral transforms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1689</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1689</id><created>2013-06-07</created><authors><author><keyname>Razniewski</keyname><forenames>Simon</forenames></author><author><keyname>Montali</keyname><forenames>Marco</forenames></author><author><keyname>Nutt</keyname><forenames>Werner</forenames></author></authors><title>Verification of Query Completeness over Processes [Extended Version]</title><categories>cs.DB</categories><comments>Extended version of a paper that was submitted to BPM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data completeness is an essential aspect of data quality, and has in turn a
huge impact on the effective management of companies. For example, statistics
are computed and audits are conducted in companies by implicitly placing the
strong assumption that the analysed data are complete. In this work, we are
interested in studying the problem of completeness of data produced by business
processes, to the aim of automatically assessing whether a given database query
can be answered with complete information in a certain state of the process. We
formalize so-called quality-aware processes that create data in the real world
and store it in the company's information system possibly at a later point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1692</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1692</id><created>2013-06-07</created><authors><author><keyname>Kniesburges</keyname><forenames>Sebastian</forenames></author><author><keyname>Koutsopoulos</keyname><forenames>Andreas</forenames></author><author><keyname>Scheideler</keyname><forenames>Christian</forenames></author></authors><title>A DeterministicWorst-Case Message Complexity Optimal Solution for
  Resource Discovery</title><categories>cs.DC</categories><comments>Full Version of Sirocco 2013 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of resource discovery in distributed systems. In
particular we give an algorithm, such that each node in a network discovers the
address of any other node in the network. We model the knowledge of the nodes
as a virtual overlay network given by a directed graph such that complete
knowledge of all nodes corresponds to a complete graph in the overlay network.
Although there are several solutions for resource discovery, our solution is
the first that achieves worst-case optimal work for each node, i.e. the number
of addresses (O(n)) or bits (O(n log n)) a node receives or sends coincides
with the lower bound, while ensuring only a linear runtime (O(n)) on the number
of rounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1702</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1702</id><created>2013-06-07</created><authors><author><keyname>Khokhryakov</keyname><forenames>Evgenii</forenames></author></authors><title>Stable equilibrium study cascaded one bit sigma-delta modulator</title><categories>cs.OH</categories><comments>Pdf-format Russian version</comments><msc-class>93D99</msc-class><acm-class>K.6.1</acm-class><journal-ref>Voprosi RadioElectronici ISSN 0233-9950 2 (2013) 144-154</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper defines a boundary of stability zone for sigma-delta modulator.
The boundary depends from inner sigma-delta modulator coefficients. For
designing purposes such result could be used to find or compare some
appropriate schemes with each other. It is proved some statements and showed
that boundary could be found theoretically for any order of sigma-delta
modulator, but practically till 5-th order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1704</identifier>
 <datestamp>2014-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1704</id><created>2013-06-07</created><updated>2014-02-25</updated><authors><author><keyname>Karamshuk</keyname><forenames>Dmytro</forenames></author><author><keyname>Noulas</keyname><forenames>Anastasios</forenames></author><author><keyname>Scellato</keyname><forenames>Salvatore</forenames></author><author><keyname>Nicosia</keyname><forenames>Vincenzo</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author></authors><title>Geo-Spotting: Mining Online Location-based Services for Optimal Retail
  Store Placement</title><categories>cs.SI cs.CE physics.soc-ph</categories><comments>Proceedings of the 19th ACM SIGKDD international conference on
  Knowledge discovery and data mining, Chicago, 2013, Pages 793-801</comments><acm-class>H.2.8</acm-class><doi>10.1145/2487575.2487616</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of identifying the optimal location for a new retail store has
been the focus of past research, especially in the field of land economy, due
to its importance in the success of a business. Traditional approaches to the
problem have factored in demographics, revenue and aggregated human flow
statistics from nearby or remote areas. However, the acquisition of relevant
data is usually expensive. With the growth of location-based social networks,
fine grained data describing user mobility and popularity of places has
recently become attainable.
  In this paper we study the predictive power of various machine learning
features on the popularity of retail stores in the city through the use of a
dataset collected from Foursquare in New York. The features we mine are based
on two general signals: geographic, where features are formulated according to
the types and density of nearby places, and user mobility, which includes
transitions between venues or the incoming flow of mobile users from distant
areas. Our evaluation suggests that the best performing features are common
across the three different commercial chains considered in the analysis,
although variations may exist too, as explained by heterogeneities in the way
retail facilities attract users. We also show that performance improves
significantly when combining multiple features in supervised learning
algorithms, suggesting that the retail success of a business may depend on
multiple factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1713</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1713</id><created>2013-06-07</created><authors><author><keyname>J&#xe4;ger</keyname><forenames>Gerold</forenames></author><author><keyname>Peczarski</keyname><forenames>Marcin</forenames></author></authors><title>The Worst Case Number of Questions in Generalized AB Game with and
  without White-peg Answers</title><categories>cs.GT</categories><journal-ref>Discrete Applied Mathematics 184 (2015), pp. 20-31</journal-ref><doi>10.1016/j.dam.2014.10.032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The AB game is a two-player game, where the codemaker has to choose a secret
code and the codebreaker has to guess it in as few questions as possible. It is
a variant of the famous Mastermind game, with the only difference that all pegs
in both, the secret and the questions must have distinct colors. In this work,
we consider the Generalized AB game, where for given arbitrary numbers $p$, $c$
with $p \le c$ the secret code consists of $p$ pegs each having one of $c$
colors and the answer consists only of a number of black and white pegs. There
the number of black pegs equals the number of pegs matching in the
corresponding question and the secret in position and color, and the number of
white pegs equals the additional number of pegs matching in the corresponding
question and the secret only in color. We consider also a variant of the
Generalized AB game, where the information of white pegs is omitted. This
variant is called Generalized Black-peg AB game. Let $\ab(p,c)$ and $\abb(p,c)$
be the worst case number of questions for Generalized AB game and Generalized
Black-peg AB game, respectively. Combining a computer program with theoretical
considerations, we confirm known exact values of $\ab(2,c)$ and $\ab(3,c)$ and
prove tight bounds for $\ab(4,c)$. Furthermore, we present exact values for
$\abb(2,c)$ and $\abb(3,c)$ and tight bounds for $\abb(4,c)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1714</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1714</id><created>2013-06-07</created><authors><author><keyname>Ehrhard</keyname><forenames>Thomas</forenames></author><author><keyname>Jiang</keyname><forenames>Ying</forenames></author></authors><title>CCS for Trees</title><categories>cs.LO</categories><comments>25 pages</comments><acm-class>F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CCS can be considered as a most natural extension of finite state automata in
which interaction is made possible thanks to parallel composition. We propose
here a similar extension for top-down tree automata. We introduce a parallel
composition which is parameterized by a graph at the vertices of which
subprocesses are located. Communication is allowed only between subprocesses
related by an edge in this graph. We define an observational equivalence based
on barbs as well as weak bisimilarity equivalence and prove an adequacy theorem
relating these two notions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1716</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1716</id><created>2013-06-07</created><authors><author><keyname>Petukhov</keyname><forenames>Alexander</forenames></author><author><keyname>Kozlov</keyname><forenames>Inna</forenames></author></authors><title>Fast greedy algorithm for subspace clustering from corrupted and
  incomplete data</title><categories>cs.LG cs.DS math.NA stat.ML</categories><comments>arXiv admin note: substantial text overlap with arXiv:1304.4282</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the Fast Greedy Sparse Subspace Clustering (FGSSC) algorithm
providing an efficient method for clustering data belonging to a few
low-dimensional linear or affine subspaces. The main difference of our
algorithm from predecessors is its ability to work with noisy data having a
high rate of erasures (missed entries with the known coordinates) and errors
(corrupted entries with unknown coordinates). We discuss here how to implement
the fast version of the greedy algorithm with the maximum efficiency whose
greedy strategy is incorporated into iterations of the basic algorithm.
  We provide numerical evidences that, in the subspace clustering capability,
the fast greedy algorithm outperforms not only the existing state-of-the art
SSC algorithm taken by the authors as a basic algorithm but also the recent
GSSC algorithm. At the same time, its computational cost is only slightly
higher than the cost of SSC.
  The numerical evidence of the algorithm significant advantage is presented
for a few synthetic models as well as for the Extended Yale B dataset of facial
images. In particular, the face recognition misclassification rate turned out
to be 6-20 times lower than for the SSC algorithm. We provide also the
numerical evidence that the FGSSC algorithm is able to perform clustering of
corrupted data efficiently even when the sum of subspace dimensions
significantly exceeds the dimension of the ambient space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1723</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1723</id><created>2013-06-07</created><authors><author><keyname>Rakhmawati</keyname><forenames>Nur Aini</forenames></author><author><keyname>Umbrich</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Karnstedt</keyname><forenames>Marcel</forenames></author><author><keyname>Hasnain</keyname><forenames>Ali</forenames></author><author><keyname>Hausenblas</keyname><forenames>Michael</forenames></author></authors><title>Querying over Federated SPARQL Endpoints ---A State of the Art Survey</title><categories>cs.DB cs.DC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The increasing amount of Linked Data and its inherent distributed nature have
attracted significant attention throughout the research community and amongst
practitioners to search data, in the past years. Inspired by research results
from traditional distributed databases, different approaches for managing
federation over SPARQL Endpoints have been introduced. SPARQL is the
standardised query language for RDF, the default data model used in Linked Data
deployments and SPARQL Endpoints are a popular access mechanism provided by
many Linked Open Data (LOD) repositories. In this paper, we initially give an
overview of the federation framework infrastructure and then proceed with a
comparison of existing SPARQL federation frameworks. Finally, we highlight
shortcomings in existing frameworks, which we hope helps spawning new research
directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1730</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1730</id><created>2013-06-07</created><authors><author><keyname>Laxmaiah</keyname><forenames>M.</forenames></author><author><keyname>Govardhan</keyname><forenames>A.</forenames></author></authors><title>A Conceptual Metadata Framework for Spatial Data Warehouse</title><categories>cs.DB</categories><journal-ref>International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP) Vol.3, No.3, May 2013</journal-ref><doi>10.5121/IJDKP.2013.3306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metadata represents the information about data to be stored in Data
Warehouses.It is a mandatory element of Data Warehouse to build an efficient
Data Warehouse.Metadata helps in data integration,lineage,data quality and
populating transformed data into data warehouse.Spatial data warehouses are
based on spatial data mostly collected from Geographical Information
Systems(GIS)and the transactional systems that are specific to an application
or enterprise.Metadata design and deployment is the most critical phase in
building of data warehouse where it is mandatory to bring the spatial
information and data modeling together.In this paper,we present a holistic
metadata framework that drives metadata creation for spatial data warehouse.
Theoretically, the proposed metadata framework improves the efficiency of
accessing of data in response to frequent queries on SDWs.In other words, the
proposed framework decreases the response time of the query and accurate
information is fetched from Data Warehouse including the spatial information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1740</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1740</id><created>2013-06-07</created><authors><author><keyname>Choudhary</keyname><forenames>Pankaj</forenames></author><author><keyname>Aaseri</keyname><forenames>Rajendra</forenames></author><author><keyname>Roberts</keyname><forenames>Nirmal</forenames></author></authors><title>HTTPI Based Web Service Security over SOAP</title><categories>cs.CR cs.NI cs.PF</categories><comments>International Journal of Network Security &amp; Its Applications (IJNSA),
  Vol.5, No.3, May 2013</comments><journal-ref>Choudhary, P., Aaseri, R., Roberts, N., (2013) &quot;HTTPI Based Web
  Service Security over SOAP&quot;, IJNSA, Vol.5, No.3, on pp. 55-66</journal-ref><doi>10.5121/ijnsa.2013.5306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a days, a new family of web applications open applications, are emerging
(e.g., Social Networking, News and Blogging). Generally, these open
applications are non-confidential. The security needs of these applications are
only client/server authentication and data integrity. For securing these open
applications, effectively and efficiently, HTTPI, a new transport protocol is
proposed, which ensures the entire security requirements of open applications.
Benefit of using the HTTPI is that it is economical in use, well-suited for
cache proxies, like HTTP is, and provides security against many Internet
attacks (Server Impersonation and Message Modification) like HTTPS does. In
terms of performance HTTPI is very close to the HTTP, but much better than
HTTPS. A Web service is a method of communication between two ends over the
Internet. These web services are developed over XML and HTTP. Today, most of
the open applications use web services for most of their operations. For
securing these web services, security design based on HTTPI is proposed. Our
work involves securing the web services over SOAP, based on the HTTPI. This
secure web service might be applicable for open applications, where
authentication and integrity is needed, but no confidentiality required. In our
paper, we introduce a web service security model based on HTTPI protocol over
SOAP and develop a preliminary implementation of this model. We also analyze
the performance of our approach through an experiment and show that our
proposed approach provides higher throughput, lower average response time and
lower response size than HTTPS based web service security approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1743</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1743</id><created>2013-06-07</created><authors><author><keyname>Heck</keyname><forenames>Tamara</forenames></author><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author></authors><title>Performing Informetric Analysis on Information Retrieval Test
  Collections: Preliminary Experiments in the Physics Domain</title><categories>cs.IR cs.DL</categories><comments>6 pages, 1 figure, 2 tables, accepted for 14th International Society
  of Scientometrics and Informetrics Conference (ISSI 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combination of informetric analysis and information retrieval allows a
twofold application. (1) While in-formetrics analysis is primarily used to gain
insights into a scientific domain, it can be used to build recommen-dation or
alternative ranking services. They are usually based on methods like
co-occurrence or citation analyses. (2) Information retrieval and its
decades-long tradition of rigorous evaluation using standard document corpora,
predefined topics and relevance judgements can be used as a test bed for
informetric analyses. We show a preliminary experiment on how both domains can
be connected using the iSearch test collection, a standard information
retrieval test collection derived from the open access arXiv.org preprint
server. In this paper the aim is to draw a conclusion about the appropriateness
of iSearch as a test bed for the evaluation of a retrieval or recommendation
system that applies informetric methods to improve retrieval results for the
user. Based on an interview study with physicists, bibliographic coupling and
author-co-citation analysis, important authors for ten different research
questions are identified. The results show that the analysed corpus includes
these authors and their corresponding documents. This study is a first step
towards a combination of retrieval evaluations and the evaluation of
informetric analyses methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1746</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1746</id><created>2013-06-06</created><authors><author><keyname>Naushad</keyname><forenames>Alamgir</forenames></author></authors><title>Condition Driven Adaptive Music Generation for Computer Games</title><categories>cs.HC</categories><doi>10.5120/10652-5416</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The video game industry has grown to a multi-billion dollar, worldwide
industry. The background music tends adaptively in reference to the specific
game content during the game length of the play. Adaptive music should be
further explored by looking at the particular condition in the game; such
condition is driven by generating a specific music in the background which best
fits in with the active game content throughout the length of the gameplay.
This research paper outlines the use of condition driven adaptive music
generation for audio and video to dynamically incorporate adaptively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1751</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1751</id><created>2013-06-07</created><updated>2013-09-24</updated><authors><author><keyname>Chen</keyname><forenames>Jinyuan</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author></authors><title>Toward the Performance vs. Feedback Tradeoff for the Two-User MISO
  Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Trans. Inf. Theory. This paper was presented in part
  at the 50th Annual Allerton Conference 2012, at ITA-UCSD 2013, and at ISIT
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the two-user MISO broadcast channel with imperfect and delayed channel
state information at the transmitter (CSIT), the work explores the tradeoff
between performance on the one hand, and CSIT timeliness and accuracy on the
other hand. The work considers a broad setting where communication takes place
in the presence of a random fading process, and in the presence of a feedback
process that, at any point in time, may provide CSIT estimates - of some
arbitrary accuracy - for any past, current or future channel realization. This
feedback quality may fluctuate in time across all ranges of CSIT accuracy and
timeliness, ranging from perfectly accurate and instantaneously available
estimates, to delayed estimates of minimal accuracy. Under standard
assumptions, the work derives the degrees-of-freedom (DoF) region, which is
tight for a large range of CSIT quality. This derived DoF region concisely
captures the effect of channel correlations, the accuracy of predicted,
current, and delayed-CSIT, and generally captures the effect of the quality of
CSIT offered at any time, about any channel.
  The work also introduces novel schemes which - in the context of imperfect
and delayed CSIT - employ encoding and decoding with a phase-Markov structure.
The results hold for a large class of block and non-block fading channel
models, and they unify and extend many prior attempts to capture the effect of
imperfect and delayed feedback. This generality also allows for consideration
of novel pertinent settings, such as the new periodically evolving feedback
setting, where a gradual accumulation of feedback bits progressively improves
CSIT as time progresses across a finite coherence period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1752</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1752</id><created>2013-06-07</created><authors><author><keyname>Cabitza</keyname><forenames>Federico</forenames></author><author><keyname>Simone</keyname><forenames>Carla</forenames></author></authors><title>Appropriation as neglected practice in communities: presenting a
  framework to enable EUD design for CoPs</title><categories>cs.HC</categories><acm-class>H.5.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Communities present considerable challenges for the design and application of
supportive information technology (IT), especially when these develop in
loosely-integrated, informal and scarcely organized contexts, like it is often
the case of Communities of Practice (CoP). An approach that actively supports
user communities in the process of IT appropriation can help alleviate the
impossibility of the members of these communities to rely on professional
support, and enable even complex forms of tailoring and End-User Development
(EUD). Although this approach has been already explored by an increasing number
of researchers, however there is still a lack of a general framework that could
play a role in the comparison of existing proposals and in the development of
new EUD solutions for CoPs. The paper proposes a conceptual framework and a
related architecture, called Logic of Bricolage, that aims to be a step further
in this direction to enable better EUD-oriented support for digitized
communities. The framework is described and the architecture instantiated in
three concrete EUD environments that specifically regard collaborative
activities in order to show the generality and applicability of the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1758</identifier>
 <datestamp>2014-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1758</id><created>2013-06-07</created><updated>2014-05-27</updated><authors><author><keyname>M&#xe9;ndez-D&#xed;az</keyname><forenames>Isabel</forenames></author><author><keyname>Nasini</keyname><forenames>Graciela</forenames></author><author><keyname>Severin</keyname><forenames>Daniel</forenames></author></authors><title>A DSATUR-based algorithm for the Equitable Coloring Problem</title><categories>cs.DM math.CO</categories><msc-class>05C15, 05A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new exact algorithm for the Equitable Coloring
Problem, a coloring problem where the sizes of two arbitrary color classes
differ in at most one unit. Based on the well known DSatur algorithm for the
classic Coloring Problem, a new pruning criterion arising from equity
constraints is proposed and analyzed. The good performance of the algorithm is
shown through computational experiments over random and benchmark instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1769</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1769</id><created>2013-06-07</created><authors><author><keyname>Anta</keyname><forenames>Antonio Fern&#xe1;ndez</forenames></author><author><keyname>Georgiou</keyname><forenames>Chryssis</forenames></author><author><keyname>Kowalski</keyname><forenames>Dariusz R.</forenames></author><author><keyname>Widmer</keyname><forenames>Joerg</forenames></author><author><keyname>Zavou</keyname><forenames>Elli</forenames></author></authors><title>Measuring the Impact of Adversarial Errors on Packet Scheduling
  Strategies</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the problem of achieving efficient packet
transmission over unreliable links with worst case occurrence of errors. In
such a setup, even an omniscient offline scheduling strategy cannot achieve
stability of the packet queue, nor is it able to use up all the available
bandwidth. Hence, an important first step is to identify an appropriate metric
for measuring the efficiency of scheduling strategies in such a setting. To
this end, we propose a relative throughput metric which corresponds to the long
term competitive ratio of the algorithm with respect to the optimal. We then
explore the impact of the error detection mechanism and feedback delay on our
measure. We compare instantaneous error feedback with deferred error feedback,
that requires a faulty packet to be fully received in order to detect the
error. We propose algorithms for worst-case adversarial and stochastic packet
arrival models, and formally analyze their performance. The relative throughput
achieved by these algorithms is shown to be close to optimal by deriving lower
bounds on the relative throughput of the algorithms and almost matching upper
bounds for any algorithm in the considered settings. Our collection of results
demonstrate the potential of using instantaneous feedback to improve the
performance of communication systems in adverse environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1772</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1772</id><created>2013-06-07</created><authors><author><keyname>Graziotin</keyname><forenames>Daniel</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Wang</keyname><forenames>Xiaofeng</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author></authors><title>Are Happy Developers more Productive? The Correlation of Affective
  States of Software Developers and their self-assessed Productivity</title><categories>cs.SE cs.HC</categories><comments>16 pages, 3 Figure. The final publication is available at
  link.springer.com. Link:
  http://link.springer.com/chapter/10.1007%2F978-3-642-39259-7_7. DOI:
  10.1007/978-3-642-39259-7_7</comments><acm-class>D.2.8; K.6.3; H.1.2</acm-class><journal-ref>Proceedings of the 14th International Conference on
  Product-Focused Software Process Improvement (PROFES 2013), LNCS 7983,
  Springer-Verlag, pp. 50-64, 2013</journal-ref><doi>10.1007/978-3-642-39259-7_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For decades now, it has been claimed that a way to improve software
developers' productivity is to focus on people. Indeed, while human factors
have been recognized in Software Engineering research, few empirical
investigations have attempted to verify the claim. Development tasks are
undertaken through cognitive processing abilities. Affective states - emotions,
moods, and feelings - have an impact on work-related behaviors, cognitive
processing activities, and the productivity of individuals. In this paper, we
report an empirical study on the impact of affective states on software
developers' performance while programming. Two affective states dimensions are
positively correlated with self-assessed productivity. We demonstrate the value
of applying psychometrics in Software Engineering studies and echo a call to
valorize the human, individualized aspects of software developers. We introduce
and validate a measurement instrument and a linear mixed-effects model to study
the correlation of affective states and the productivity of software
developers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1773</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1773</id><created>2013-06-07</created><authors><author><keyname>Graziotin</keyname><forenames>Daniel</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author></authors><title>Making Sense out of a Jungle of JavaScript Frameworks: towards a
  Practitioner-friendly Comparative Analysis</title><categories>cs.SE</categories><comments>5 Pages, 1 Figure. The final publication is available at
  link.springer.com. Link:
  http://link.springer.com/chapter/10.1007/978-3-642-39259-7_28. DOI:
  10.1007/978-3-642-39259-7_28</comments><acm-class>D.3.0; K.6.3</acm-class><journal-ref>Proceedings of the 14th International Conference on
  Product-Focused Software Process Improvement (PROFES 2013), LNCS 7983,
  Springer-Verlag, pp. 334-337, 2013</journal-ref><doi>10.1007/978-3-642-39259-7_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of Web development is entering the HTML5 and CSS3 era and
JavaScript is becoming increasingly influential. A large number of JavaScript
frameworks have been recently promoted. Practitioners applying the latest
technologies need to choose a suitable JavaScript framework (JSF) in order to
abstract the frustrating and complicated coding steps and to provide a
cross-browser compatibility. Apart from benchmark suites and recommendation
from experts, there is little research helping practitioners to select the most
suitable JSF to a given situation. The few proposals employ software metrics on
the JSF, but practitioners are driven by different concerns when choosing a
JSF. As an answer to the critical needs, this paper is a call for action. It
proposes a re-search design towards a comparative analysis framework of JSF,
which merges researcher needs and practitioner needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1822</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1822</id><created>2013-06-07</created><authors><author><keyname>Ghiass</keyname><forenames>Reza Shoja</forenames></author><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author><author><keyname>Bendada</keyname><forenames>Hakim</forenames></author><author><keyname>Maldague</keyname><forenames>Xavier</forenames></author></authors><title>Illumination-invariant face recognition from a single image across
  extreme pose using a dual dimension AAM ensemble in the thermal infrared
  spectrum</title><categories>cs.CV</categories><comments>International Joint Conference on Neural Networks, 2013. arXiv admin
  note: substantial text overlap with arXiv:1306.1609</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the course of the last decade, infrared (IR) and particularly thermal IR
imaging based face recognition has emerged as a promising complement to
conventional, visible spectrum based approaches which continue to struggle when
applied in practice. While inherently insensitive to visible spectrum
illumination changes, IR data introduces specific challenges of its own, most
notably sensitivity to factors which affect facial heat emission patterns, e.g.
emotional state, ambient temperature, and alcohol intake. In addition, facial
expression and pose changes are more difficult to correct in IR images because
they are less rich in high frequency detail which is an important cue for
fitting any deformable model. In this paper we describe a novel method which
addresses these major challenges. Specifically, when comparing two thermal IR
images of faces, we mutually normalize their poses and facial expressions by
using an active appearance model (AAM) to generate synthetic images of the two
faces with a neutral facial expression and in the same view (the average of the
two input views). This is achieved by piecewise affine warping which follows
AAM fitting. A major contribution of our work is the use of an AAM ensemble in
which each AAM is specialized to a particular range of poses and a particular
region of the thermal IR face space. Combined with the contributions from our
previous work which addressed the problem of reliable AAM fitting in the
thermal IR spectrum, and the development of a person-specific representation
robust to transient changes in the pattern of facial temperature emissions, the
proposed ensemble framework accurately matches faces across the full range of
yaw from frontal to profile, even in the presence of scale variation (e.g. due
to the varying distance of a subject from the camera).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1840</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1840</id><created>2013-06-07</created><updated>2013-06-23</updated><authors><author><keyname>Mineiro</keyname><forenames>Paul</forenames></author><author><keyname>Karampatziakis</keyname><forenames>Nikos</forenames></author></authors><title>Loss-Proportional Subsampling for Subsequent ERM</title><categories>cs.LG stat.ML</categories><comments>Appears in the proceedings of the 30th International Conference on
  Machine Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a sampling scheme suitable for reducing a data set prior to
selecting a hypothesis with minimum empirical risk. The sampling only considers
a subset of the ultimate (unknown) hypothesis set, but can nonetheless
guarantee that the final excess risk will compare favorably with utilizing the
entire original data set. We demonstrate the practical benefits of our approach
on a large dataset which we subsample and subsequently fit with boosted trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1849</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1849</id><created>2013-06-07</created><updated>2016-02-23</updated><authors><author><keyname>Lang</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Maudet</keyname><forenames>Nicolas</forenames></author><author><keyname>Polukarov</keyname><forenames>Maria</forenames></author><author><keyname>Cohen-Hadria</keyname><forenames>Alice</forenames></author></authors><title>New Results on Equilibria in Strategic Candidacy</title><categories>cs.GT cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a voting setting where candidates have preferences about the
outcome of the election and are free to join or leave the election. The
corresponding candidacy game, where candidates choose strategically to
participate or not, has been studied %initially by Dutta et al., who showed
that no non-dictatorial voting procedure satisfying unanimity is
candidacy-strategyproof, that is, is such that the joint action where all
candidates enter the election is always a pure strategy Nash equilibrium. Dutta
et al. also showed that for some voting tree procedures, there are candidacy
games with no pure Nash equilibria, and that for the rule that outputs the
sophisticated winner of voting by successive elimination, all games have a pure
Nash equilibrium. No results were known about other voting rules. Here we prove
several such results. For four candidates, the message is, roughly, that most
scoring rules (with the exception of Borda) do not guarantee the existence of a
pure Nash equilibrium but that Condorcet-consistent rules, for an odd number of
voters, do. For five candidates, most rules we study no longer have this
guarantee. Finally, we identify one prominent rule that guarantees the
existence of a pure Nash equilibrium for any number of candidates (and for an
odd number of voters): the Copeland rule. We also show that under mild
assumptions on the voting rule, the existence of strong equilibria cannot be
guaranteed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1850</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1850</id><created>2013-06-07</created><authors><author><keyname>Ismaeel</keyname><forenames>Ayad Ghany</forenames></author><author><keyname>Ablahad</keyname><forenames>Anar Auda</forenames></author></authors><title>Enhancement of a Novel Method for Mutational Disease Prediction using
  Bioinformatics Techniques and Backpropagation Algorithm</title><categories>cs.CE q-bio.QM</categories><comments>5 pages, 8 figures, 1 Table, conference or other essential info</comments><journal-ref>International Journal of Scientific &amp; Engineering Research, Volume
  4, Issue 6, June 2013 pages 1169-1173</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The noval method for mutational disease prediction using bioinformatics tools
and datasets for diagnosis the malignant mutations with powerful Artificial
Neural Network (Backpropagation Network) for classifying these malignant
mutations are related to gene(s) (like BRCA1 and BRCA2) cause a disease (breast
cancer). This noval method did not take in consideration just like adopted for
dealing, analyzing and treat the gene sequences for extracting useful
information from the sequence, also exceeded the environment factors which play
important roles in deciding and calculating some of genes features in order to
view its functional parts and relations to diseases. This paper is proposed an
enhancement of a novel method as a first way for diagnosis and prediction the
disease by mutations considering and introducing multi other features show the
alternations, changes in the environment as well as genes, comparing sequences
to gain information about the structure or function of a query sequence, also
proposing optimal and more accurate system for classification and dealing with
specific disorder using backpropagation with mean square rate 0.000000001.
Index Terms (Homology sequence, GC content and AT content, Bioinformatics,
Backpropagation Network, BLAST, DNA Sequence, Protein Sequence)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1851</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1851</id><created>2013-06-07</created><authors><author><keyname>Nassar</keyname><forenames>Marcel</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author><author><keyname>Evans</keyname><forenames>Brian L.</forenames></author></authors><title>A Factor Graph Approach to Joint OFDM Channel Estimation and Decoding in
  Impulsive Noise Environments</title><categories>cs.IT math.IT stat.ML</categories><comments>13 pages, 9 figures, submitted to IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2013.2295063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel receiver for orthogonal frequency division multiplexing
(OFDM) transmissions in impulsive noise environments. Impulsive noise arises in
many modern wireless and wireline communication systems, such as Wi-Fi and
powerline communications, due to uncoordinated interference that is much
stronger than thermal noise. We first show that the bit-error-rate optimal
receiver jointly estimates the propagation channel coefficients, the noise
impulses, the finite-alphabet symbols, and the unknown bits. We then propose a
near-optimal yet computationally tractable approach to this joint estimation
problem using loopy belief propagation. In particular, we merge the recently
proposed &quot;generalized approximate message passing&quot; (GAMP) algorithm with the
forward-backward algorithm and soft-input soft-output decoding using a &quot;turbo&quot;
approach. Numerical results indicate that the proposed receiver drastically
outperforms existing receivers under impulsive noise and comes within 1 dB of
the matched-filter bound. Meanwhile, with N tones, the proposed
factor-graph-based receiver has only O(N log N) complexity, and it can be
parallelized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1855</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1855</id><created>2013-06-07</created><authors><author><keyname>Musta&#x163;&#x103;</keyname><forenames>Irina</forenames></author><author><keyname>Pergel</keyname><forenames>Martin</forenames></author></authors><title>Unit Grid Intersection Graphs: Recognition and Properties</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been known since 1991 that the problem of recognizing grid
intersection graphs is NP-complete. Here we use a modified argument of the
above result to show that even if we restrict to the class of unit grid
intersection graphs (UGIGs), the recognition remains hard, as well as for all
graph classes contained inbetween. The result holds even when considering only
graphs with arbitrarily large girth. Furthermore, we ask the question of
representing UGIGs on grids of minimal size. We show that the UGIGs that can be
represented in a square of side length 1+epsilon, for a positive epsilon no
greater than 1, are exactly the orthogonal ray graphs, and that there exist
families of trees that need an arbitrarily large grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1857</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1857</id><created>2013-06-07</created><authors><author><keyname>Korenblit</keyname><forenames>Mark</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>Decomposition Lemmas</title><categories>cs.DM math.CO</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define two recursive functions obtained by decomposition of a given
interval into four close parts and prove two lemmas which determine features of
these functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1860</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1860</id><created>2013-06-07</created><authors><author><keyname>Korenblit</keyname><forenames>Mark</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>A Solution of Simultaneous Recurrences</title><categories>cs.DM math.CO</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to the methods of solving simultaneous recurrences.
Specifically, we discuss transformation of matrix recurrences to regular
recurrences and propose a way of solving special matrix recurrences of order
three by their decomposition to matrix recurrences of order two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1861</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1861</id><created>2013-06-07</created><authors><author><keyname>Anta</keyname><forenames>Antonio Fern&#xe1;ndez</forenames></author><author><keyname>Georgiou</keyname><forenames>Chryssis</forenames></author><author><keyname>Kowalski</keyname><forenames>Dariusz R.</forenames></author><author><keyname>Zavou</keyname><forenames>Elli</forenames></author></authors><title>Online Parallel Scheduling of Non-uniform Tasks: Trading Failures for
  Energy</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a system in which tasks of different execution times arrive
continuously and have to be executed by a set of processors that are prone to
crashes and restarts. In this paper we model and study the impact of
parallelism and failures on the competitiveness of such an online system. In a
fault-free environment, a simple Longest-in-System scheduling policy, enhanced
by a redundancy-avoidance mechanism, guarantees optimality in a long-term
execution. In the presence of failures though, scheduling becomes a much more
challenging task. In particular, no parallel deterministic algorithm can be
competitive against an offline optimal solution, even with one single processor
and tasks of only two different execution times. We find that when additional
energy is provided to the system in the form of processor speedup, the
situation changes. Specifically, we identify thresholds on the speedup under
which such competitiveness cannot be achieved by any deterministic algorithm,
and above which competitive algorithms exist. Finally, we propose algorithms
that achieve small bounded competitive ratios when the speedup is over the
threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1870</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1870</id><created>2013-06-07</created><authors><author><keyname>Guimar&#xe3;es</keyname><forenames>Jos&#xe9; de Oliveira</forenames></author></authors><title>The Cyan Language</title><categories>cs.PL</categories><comments>248 pages</comments><acm-class>D.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the manual of Cyan, a prototype-based object-oriented language. Cyan
supports static typing, single inheritance, mixin objects (similar to mixin
classes with mixin inheritance), generic prototypes, and Java-like interfaces.
The language has several innovations: a completely object-oriented exception
system, statically-typed closures, a kind of graphical metaobjects called
codegs, optional dynamic typing, user-defined literal objects (an innovative
way of creating objects), context objects (a generalization of closures), and
grammar methods and message sends (which makes it easy to define Domain
Specific Languages).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1877</identifier>
 <datestamp>2013-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1877</id><created>2013-06-08</created><updated>2013-10-08</updated><authors><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>Communication is bounded by root of rank</title><categories>cs.CC math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that any total boolean function of rank $r$ can be computed by a
deterministic communication protocol of complexity $O(\sqrt{r} \cdot \log(r))$.
Equivalently, any graph whose adjacency matrix has rank $r$ has chromatic
number at most $2^{O(\sqrt{r} \cdot \log(r))}$. This gives a nearly quadratic
improvement in the dependence on the rank over previous results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1881</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1881</id><created>2013-06-08</created><authors><author><keyname>Pintea</keyname><forenames>Camelia-M.</forenames></author></authors><title>Artificial Ant Species on Solving Optimization Problems</title><categories>cs.MA</categories><comments>4 pages, accepted paper</comments><msc-class>90C27, 68T05, 92D50</msc-class><journal-ref>Sci. Stud. Res., Ser. Math. Inform. 23(1) (2013) 121-126</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last years several ant-based techniques were involved to solve
hard and complex optimization problems. The current paper is a short study
about the influence of artificial ant species in solving optimization problems.
There are studied the artificial Pharaoh Ants, Lasius Niger and also artificial
ants with no special specificity used commonly in Ant Colony Optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1888</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1888</id><created>2013-06-08</created><authors><author><keyname>Badidi</keyname><forenames>Elarbi</forenames></author></authors><title>A Framework for Software-as-a-Service Selection and Provisioning</title><categories>cs.DC</categories><comments>12 pages</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.5, No.3, pp. 189-200, May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As cloud computing is increasingly transforming the information technology
landscape, organizations and businesses are exhibiting strong interest in
Software-as-a-Service (SaaS) offerings that can help them increase business
agility and reduce their operational costs. They increasingly demand services
that can meet their functional and non-functional requirements. Given the
plethora and the variety of SaaS offerings, we propose, in this paper, a
framework for SaaS provisioning, which relies on brokered Service Level
agreements (SLAs), between service consumers and SaaS providers. The Cloud
Service Broker (CSB) helps service consumers find the right SaaS providers that
can fulfil their functional and non-functional requirements. The proposed
selection algorithm ranks potential SaaS providers by matching their offerings
against the requirements of the service consumer using an aggregate utility
function. Furthermore, the CSB is in charge of conducting SLA negotiation with
selected SaaS providers, on behalf of service consumers, and performing SLA
compliance monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1889</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1889</id><created>2013-06-08</created><authors><author><keyname>Gupta</keyname><forenames>Aakash</forenames></author><author><keyname>Singla</keyname><forenames>Pradeep</forenames></author><author><keyname>Gupta</keyname><forenames>Jitendra</forenames></author><author><keyname>Maheshwari</keyname><forenames>Nitin</forenames></author></authors><title>An Improved Structure Of Reversible Adder And Subtractor</title><categories>cs.AR</categories><journal-ref>International Journal of Electronics and Computer Science
  Engineering, Vol 2, No. 2, pp712-718, June 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's world everyday a new technology which is faster, smaller and more
complex than its predecessor is being developed. The increased number of
transistors packed onto a chip of a conventional system results in increased
power consumption that is why Reversible logic has drawn attention of
Researchers due to its less heat dissipating characteristics. Reversible logic
can be imposed over applications such as quantum computing, optical computing,
quantum dot cellular automata, low power VLSI circuits, DNA computing. This
paper presents the reversible combinational circuit of adder, subtractor and
parity preserving subtractor. The suggested circuit in this paper are designed
using Feynman, Double Feynman and MUX gates which are better than the existing
one in literature in terms of Quantum cost, Garbage output and Total logical
calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1894</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1894</id><created>2013-06-08</created><authors><author><keyname>Buemi</keyname><forenames>Mar&#xed;a Elena</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Ramos</keyname><forenames>Heitor S.</forenames></author></authors><title>Speckle Reduction with Adaptive Stack Filters</title><categories>cs.CV</categories><comments>Accepted for publication on Pattern Recognition Letters. arXiv admin
  note: substantial text overlap with arXiv:1207.4308</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stack filters are a special case of non-linear filters. They have a good
performance for filtering images with different types of noise while preserving
edges and details. A stack filter decomposes an input image into stacks of
binary images according to a set of thresholds. Each binary image is then
filtered by a Boolean function, which characterizes the filter. Adaptive stack
filters can be computed by training using a prototype (ideal) image and its
corrupted version, leading to optimized filters with respect to a loss
function. In this work we propose the use of training with selected samples for
the estimation of the optimal Boolean function. We study the performance of
adaptive stack filters when they are applied to speckled imagery, in particular
to Synthetic Aperture Radar (SAR) images. This is done by evaluating the
quality of the filtered images through the use of suitable image quality
indexes and by measuring the classification accuracy of the resulting images.
We used SAR images as input, since they are affected by speckle noise that
makes classification a difficult task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1901</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1901</id><created>2013-06-08</created><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Mesnard</keyname><forenames>Fred</forenames></author></authors><title>Eventual Linear Ranking Functions</title><categories>cs.PL</categories><comments>10 pages</comments><acm-class>F.3.1; D.2.4</acm-class><doi>10.1145/2505879.2505884</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Program termination is a hot research topic in program analysis. The last few
years have witnessed the development of termination analyzers for programming
languages such as C and Java with remarkable precision and performance. These
systems are largely based on techniques and tools coming from the field of
declarative constraint programming. In this paper, we first recall an algorithm
based on Farkas' Lemma for discovering linear ranking functions proving
termination of a certain class of loops. Then we propose an extension of this
method for showing the existence of eventual linear ranking functions, i.e.,
linear functions that become ranking functions after a finite unrolling of the
loop. We show correctness and completeness of this algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1906</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1906</id><created>2013-06-08</created><authors><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author></authors><title>Qualified Trust, not Surveillance, is the Basis of a Stable Society</title><categories>physics.soc-ph cs.CY</categories><comments>For related work see http://www.futurict.eu</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peaceful citizens and hard-working taxpayers are under government
surveillance. Confidential communication of journalists is intercepted.
Civilians are killed by drones, without a chance to prove their innocence. How
could it come that far? And what are the alternatives?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1907</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1907</id><created>2013-06-08</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>Analytical Coexistence Benchmark for Assessing the Utmost Interference
  Tolerated by IEEE 802.20</title><categories>cs.IT math.IT</categories><journal-ref>Journal of Information Processing Systems, vol. 7, no. 1, pp.
  43-52, Mar. 2011</journal-ref><doi>10.3745/JIPS.2011.7.1.043</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whether it is crosstalk, harmonics, or in-band operation of wireless
technologies, interference between a reference system and a host of offenders
is virtually unavoidable. In past contributions, a benchmark has been
established and considered for coexistence analysis with a number of
technologies including FWA, UMTS, and WiMAX. However, the previously presented
model does not take into account the mobility factor of the reference node in
addition to a number of interdependent requirements regarding the link
direction, channel state, data rate and system factors; hence limiting its
applicability for the MBWA (IEEE 802.20) standard. Thus, over diverse modes, in
this correspondence we analytically derived the greatest aggregate interference
level tolerated for high-fidelity transmission tailored specifically for the
MBWA standard. Our results, in the form of benchmark indicators, should be of
particular interest to peers analyzing and researching RF coexistence scenarios
with this new protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1913</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1913</id><created>2013-06-08</created><authors><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author><author><keyname>Jeni</keyname><forenames>Laszlo</forenames></author><author><keyname>Szabo</keyname><forenames>Zoltan</forenames></author><author><keyname>Cohn</keyname><forenames>Jeffrey</forenames></author><author><keyname>Kanade</keyname><forenames>Takeo</forenames></author></authors><title>Emotional Expression Classification using Time-Series Kernels</title><categories>cs.CV cs.LG stat.ML</categories><comments>IEEE International Workshop on Analysis and Modeling of Faces and
  Gestures, Portland, Oregon, 28 June 2013 (accepted)</comments><msc-class>37M10, 46E22, 68U10, 65D19, 62H30, 68T10</msc-class><acm-class>G.3; I.2.10; I.4; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of facial expressions, as spatio-temporal processes, can take
advantage of kernel methods if one considers facial landmark positions and
their motion in 3D space. We applied support vector classification with kernels
derived from dynamic time-warping similarity measures. We achieved over 99%
accuracy - measured by area under ROC curve - using only the 'motion pattern'
of the PCA compressed representation of the marker point vector, the so-called
shape parameters. Beyond the classification of full motion patterns, several
expressions were recognized with over 90% accuracy in as few as 5-6 frames from
their onset, about 200 milliseconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1916</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1916</id><created>2013-06-08</created><authors><author><keyname>Singh</keyname><forenames>Kirat Pal</forenames></author><author><keyname>Kumar</keyname><forenames>Dilip</forenames></author></authors><title>Performance Evaluation of Low Power MIPS Crypto Processor based on
  Cryptography Algorithms</title><categories>cs.CR cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and implementation of low power 32-bit
encrypted and decrypted MIPS processor for Data Encryption Standard (DES),
Triple DES, Advanced Encryption Standard (AES) based on MIPS pipeline
architecture. The organization of pipeline stages has been done in such a way
that pipeline can be clocked at high frequency. Encryption and Decryption
blocks of three standard cryptography algorithms on MIPS processor and
dependency among themselves are explained in detail with the help of a block
diagram. Clock gating technique is used to reduce the power consumption in MIPS
crypto processor. This approach results in processor that meets power
consumption and performance specification for security applications. Proposed
Implementation approach concludes higher system performance while reducing
operating power consumption. Testing results shows that the MIPS crypto
processor operates successfully at a working frequency of 218MHz and a
bandwidth of 664Mbits/s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1919</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1919</id><created>2013-06-08</created><authors><author><keyname>Bergstrom</keyname><forenames>Lars</forenames></author><author><keyname>Fluet</keyname><forenames>Matthew</forenames></author><author><keyname>Reppy</keyname><forenames>John</forenames></author><author><keyname>Sandler</keyname><forenames>Nora</forenames></author></authors><title>Practical Inlining of Functions with Free Variables</title><categories>cs.PL</categories><comments>Rejected from ICFP2013</comments><acm-class>D.3.0; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A long-standing practical challenge in the optimization of higher-order
languages is inlining functions with free variables. Inlining code statically
at a function call site is safe if the compiler can guarantee that the free
variables have the same bindings at the inlining point as they do at the point
where the function is bound as a closure (code and free variables). There have
been many attempts to create a heuristic to check this correctness condition,
from Shivers' kCFA-based reflow analysis to Might's Delta-CFA and anodization,
but all of those have performance unsuitable for practical compiler
implementations. In practice, modern language implementations rely on a series
of tricks to capture some common cases (e.g., closures whose free variables are
only top-level identifiers such as +) and rely on hand-inlining by the
programmer for anything more complicated.
  This work provides the first practical, general approach for inlining
functions with free variables. We also provide a proof of correctness, an
evaluation of both the execution time and performance impact of this
optimization, and some tips and tricks for implementing an efficient and
precise control-flow analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1922</identifier>
 <datestamp>2014-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1922</id><created>2013-06-08</created><updated>2014-03-15</updated><authors><author><keyname>Tsiligkaridis</keyname><forenames>Theodoros</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Collaborative 20 Questions for Target Localization</title><categories>cs.IT math.IT</categories><comments>34 pages, accepted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 60, No. 4, pp.
  2233-2252, April 2014</journal-ref><doi>10.1109/TIT.2014.2304455</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of 20 questions with noise for multiple players under
the minimum entropy criterion in the setting of stochastic search, with
application to target localization. Each player yields a noisy response to a
binary query governed by a certain error probability. First, we propose a
sequential policy for constructing questions that queries each player in
sequence and refines the posterior of the target location. Second, we consider
a joint policy that asks all players questions in parallel at each time instant
and characterize the structure of the optimal policy for constructing the
sequence of questions. This generalizes the single player probabilistic
bisection method for stochastic search problems. Third, we prove an equivalence
between the two schemes showing that, despite the fact that the sequential
scheme has access to a more refined filtration, the joint scheme performs just
as well on average. Fourth, we establish convergence rates of the mean-square
error (MSE) and derive error exponents. Lastly, we obtain an extension to the
case of unknown error probabilities. This framework provides a mathematical
model for incorporating a human in the loop for active machine learning
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1926</identifier>
 <datestamp>2015-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1926</id><created>2013-06-08</created><updated>2015-06-10</updated><authors><author><keyname>Engel</keyname><forenames>Konrad</forenames></author><author><keyname>Kalinowski</keyname><forenames>Thomas</forenames></author><author><keyname>Savelsbergh</keyname><forenames>Martin W. P.</forenames></author></authors><title>Incremental Network Design with Minimum Spanning Trees</title><categories>math.CO cs.DM math.OC</categories><comments>10 pages</comments><msc-class>05C85, 90C27, 90C35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an edge-weighted graph $G=(V,E)$ and a set $E_0\subset E$, the
incremental network design problem with minimum spanning trees asks for a
sequence of edges $e'_1,\ldots,e'_r\in E\setminus E_0$ minimizing
$\sum_{t=1}^Tw(X_t)$ where $w(X_t)$ is the weight of a minimum spanning tree
$X_t$ for the subgraph $(V,E_0\cup\{e'_1,\ldots,e'_t\})$ and $T=\lvert
E\setminus E_0\rvert$. We prove that this problem can be solved by a greedy
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1927</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1927</id><created>2013-06-08</created><authors><author><keyname>Kim</keyname><forenames>Been</forenames></author><author><keyname>Rudin</keyname><forenames>Cynthia</forenames></author></authors><title>Learning About Meetings</title><categories>stat.AP cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most people participate in meetings almost every day, multiple times a day.
The study of meetings is important, but also challenging, as it requires an
understanding of social signals and complex interpersonal dynamics. Our aim
this work is to use a data-driven approach to the science of meetings. We
provide tentative evidence that: i) it is possible to automatically detect when
during the meeting a key decision is taking place, from analyzing only the
local dialogue acts, ii) there are common patterns in the way social dialogue
acts are interspersed throughout a meeting, iii) at the time key decisions are
made, the amount of time left in the meeting can be predicted from the amount
of time that has passed, iv) it is often possible to predict whether a proposal
during a meeting will be accepted or rejected based entirely on the language
(the set of persuasive words) used by the speaker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1928</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1928</id><created>2013-06-08</created><authors><author><keyname>Crichlow</keyname><forenames>Joel M.</forenames></author><author><keyname>Hartley</keyname><forenames>Stephen J.</forenames></author><author><keyname>Hosein</keyname><forenames>Michael</forenames></author></authors><title>A Light-Weight Distributed System for the processing of Replicated
  Counter-like Objects</title><categories>cs.DC</categories><comments>15 pages, 5 figures, 8 tables</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.4, No.3, May 2013, 1 -15</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to increase availability in a distributed system some or all of the
data items are replicated and stored at separate sites. This is an issue of key
concern especially since there is such a proliferation of wireless technologies
and mobile users. However, the concurrent processing of transactions at
separate sites can generate inconsistencies in the stored information. We have
built a distributed service that manages updates to widely deployed
counter-like replicas. There are many heavy-weight distributed systems
targeting large information critical applications. Our system is intentionally,
relatively lightweight and useful for the somewhat reduced information critical
applications. The service is built on our distributed concurrency control
scheme which combines optimism and pessimism in the processing of transactions.
The service allows a transaction to be processed immediately (optimistically)
at any individual replica as long as the transaction satisfies a cost bound.
All transactions are also processed in a concurrent pessimistic manner to
ensure mutual consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1945</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1945</id><created>2013-06-08</created><authors><author><keyname>Komuravelli</keyname><forenames>Anvesh</forenames></author><author><keyname>Gurfinkel</keyname><forenames>Arie</forenames></author><author><keyname>Chaki</keyname><forenames>Sagar</forenames></author><author><keyname>Clarke</keyname><forenames>Edmund M.</forenames></author></authors><title>Automatic Abstraction in SMT-Based Unbounded Software Model Checking</title><categories>cs.LO cs.PL</categories><comments>Extended version of a paper in the proceedings of CAV 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software model checkers based on under-approximations and SMT solvers are
very successful at verifying safety (i.e. reachability) properties. They
combine two key ideas -- (a) &quot;concreteness&quot;: a counterexample in an
under-approximation is a counterexample in the original program as well, and
(b) &quot;generalization&quot;: a proof of safety of an under-approximation, produced by
an SMT solver, are generalizable to proofs of safety of the original program.
In this paper, we present a combination of &quot;automatic abstraction&quot; with the
under-approximation-driven framework. We explore two iterative approaches for
obtaining and refining abstractions -- &quot;proof based&quot; and &quot;counterexample based&quot;
-- and show how they can be combined into a unified algorithm. To the best of
our knowledge, this is the first application of Proof-Based Abstraction,
primarily used to verify hardware, to Software Verification. We have
implemented a prototype of the framework using Z3, and evaluate it on many
benchmarks from the Software Verification Competition. We show experimentally
that our combination is quite effective on hard instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1947</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1947</id><created>2013-06-08</created><authors><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>Grune</keyname><forenames>Dick</forenames></author><author><keyname>Hond</keyname><forenames>Brinio</forenames></author><author><keyname>Rutgers</keyname><forenames>Peter</forenames></author></authors><title>Detecting Useless Transitions in Pushdown Automata</title><categories>cs.FL</categories><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pushdown automata may contain transitions that are never used in any
accepting run of the automaton. We present an algorithm for detecting such
useless transitions. A finite automaton that captures the possible stack
content during runs of the pushdown automaton, is first constructed in a
forward procedure to determine which transitions are reachable, and then
employed in a backward procedure to determine which of these transitions can
lead to a final stat
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1953</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1953</id><created>2013-06-08</created><authors><author><keyname>Barabanov</keyname><forenames>Alexander</forenames></author><author><keyname>Markov</keyname><forenames>Alexey</forenames></author><author><keyname>Tsirlov</keyname><forenames>Valentin</forenames></author></authors><title>A Formal Approach To Firewalls Testing Techniques</title><categories>cs.CR cs.SE</categories><comments>Keywords: information security, firewall, security analysis, test
  procedures, conformance evaluation, security certification, performance
  optimization</comments><msc-class>68N30</msc-class><acm-class>C.2.0; G.4; K.7.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional technologies of firewall testing are overlooked. A new formalized
approach is presented. Recommendations on optimization of test procedures are
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1955</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1955</id><created>2013-06-08</created><authors><author><keyname>Barabanov</keyname><forenames>Alexander</forenames></author><author><keyname>Grishin</keyname><forenames>Maxim</forenames></author><author><keyname>Markov</keyname><forenames>Alexey</forenames></author></authors><title>The Formal Metabasis For Conformity Assessment of Information Security
  Software and Hardware</title><categories>cs.CR</categories><comments>Keywords: information security, information protection, information
  security tools, certification, conformity assessment, security testing</comments><msc-class>68N30</msc-class><acm-class>C.2.0; G.4; K.7.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach to the development of security test procedures for information
security controls is presented. The recommendations for optimizing the test
procedure are obtained
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1956</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1956</id><created>2013-06-08</created><authors><author><keyname>Flocchini</keyname><forenames>Paola</forenames></author><author><keyname>Santoro</keyname><forenames>Nicola</forenames></author><author><keyname>Viglietta</keyname><forenames>Giovanni</forenames></author><author><keyname>Yamashita</keyname><forenames>Masafumi</forenames></author></authors><title>Rendezvous of Two Robots with Constant Memory</title><categories>cs.MA cs.CG cs.RO</categories><comments>18 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the impact that persistent memory has on the classical rendezvous
problem of two mobile computational entities, called robots, in the plane. It
is well known that, without additional assumptions, rendezvous is impossible if
the entities are oblivious (i.e., have no persistent memory) even if the system
is semi-synchronous (SSynch). It has been recently shown that rendezvous is
possible even if the system is asynchronous (ASynch) if each robot is endowed
with O(1) bits of persistent memory, can transmit O(1) bits in each cycle, and
can remember (i.e., can persistently store) the last received transmission.
This setting is overly powerful.
  In this paper we weaken that setting in two different ways: (1) by
maintaining the O(1) bits of persistent memory but removing the communication
capabilities; and (2) by maintaining the O(1) transmission capability and the
ability to remember the last received transmission, but removing the ability of
an agent to remember its previous activities. We call the former setting
finite-state (FState) and the latter finite-communication (FComm). Note that,
even though its use is very different, in both settings, the amount of
persistent memory of a robot is constant.
  We investigate the rendezvous problem in these two weaker settings. We model
both settings as a system of robots endowed with visible lights: in FState, a
robot can only see its own light, while in FComm a robot can only see the other
robot's light. We prove, among other things, that finite-state robots can
rendezvous in SSynch, and that finite-communication robots are able to
rendezvous even in ASynch. All proofs are constructive: in each setting, we
present a protocol that allows the two robots to rendezvous in finite time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1957</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1957</id><created>2013-06-08</created><updated>2013-10-01</updated><authors><author><keyname>Soto</keyname><forenames>Mauricio</forenames></author><author><keyname>Thraves</keyname><forenames>Christopher</forenames></author></authors><title>(c-)AND: A new graph model</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this document, we study the scope of the following graph model: each
vertex is assigned to a box in a metric space and to a representative element
that belongs to that box. Two vertices are connected by an edge if and only if
its respective boxes contain the opposite representative element. We focus our
study on the case where boxes (and therefore representative elements)
associated to vertices are spread in the Euclidean line. We give both, a
combinatorial and an intersection characterization of the model. Based on these
characterizations, we determine graph families that contain the model (e. g.,
boxicity 2 graphs) and others that the new model contains (e. g., rooted
directed path). We also study the particular case where each representative
element is the center of its respective box. In this particular case, we
provide constructive representations for interval, block and outerplanar
graphs. Finally, we show that the general and the particular model are not
equivalent by constructing a graph family that separates the two cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1958</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1958</id><created>2013-06-08</created><authors><author><keyname>Markov</keyname><forenames>Alexey</forenames></author></authors><title>Software Testing Models Against Information Security Requirements</title><categories>cs.SE</categories><msc-class>68M15</msc-class><acm-class>C.4; D.2.4; G.3; G.4; D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An overview and classification of software testing models are done.
Recommendations on the choice of models are proposed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1959</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1959</id><created>2013-06-08</created><updated>2013-11-03</updated><authors><author><keyname>Zhao</keyname><forenames>Xin</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author></authors><title>Pattern Recognition and Revealing using Parallel Coordinates Plot</title><categories>cs.GR</categories><comments>8 pages and 6 figures. This paper has been withdrawn by the author
  due to publication</comments><acm-class>I.3.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel coordinates plot (PCP) is an excellent tool for multivariate
visualization and analysis, but it may fail to reveal inherent structures for
datasets with a large number of items. In this paper, we propose a suite of
novel clustering, dimension ordering and visualization techniques based on PCP,
to reveal and highlight hidden structures. First, we propose a continuous
spline based polycurves design to extract and classify different cluster
aspects of the data. Then, we provide an efficient and optimal correlation
based sorting technique to reorder coordinates, as a helpful visualization tool
for data analysis. Various results generated by our framework visually
represent much structure, trend and correlation information to guide the user,
and improve the efficacy of analysis, especially for complex and noisy
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.1967</identifier>
 <datestamp>2013-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.1967</id><created>2013-06-08</created><updated>2013-06-20</updated><authors><author><keyname>Feder</keyname><forenames>Tom&#xe1;s</forenames></author><author><keyname>Hell</keyname><forenames>Pavol</forenames></author><author><keyname>Shklarsky</keyname><forenames>Oren</forenames></author></authors><title>Matrix Partitions of Split Graphs</title><categories>cs.DM math.CO</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix partition problems generalize a number of natural graph partition
problems, and have been studied for several standard graph classes. We prove
that each matrix partition problem has only finitely many minimal obstructions
for split graphs. Previously such a result was only known for the class of
cographs. (In particular, there are matrix partition problems which have
infinitely many minimal chordal obstructions.) We provide (close) upper and
lower bounds on the maximum size of a minimal split obstruction. This shows for
the first time that some matrices have exponential-sized minimal obstructions
of any kind (not necessarily split graphs). We also discuss matrix partitions
for bipartite and co-bipartite graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2003</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2003</id><created>2013-06-09</created><authors><author><keyname>Nascimento</keyname><forenames>Abra&#xe3;o D. C.</forenames></author><author><keyname>Horta</keyname><forenames>Michelle M.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Cintra</keyname><forenames>Renato J.</forenames></author></authors><title>Comparing Edge Detection Methods based on Stochastic Entropies and
  Distances for PolSAR Imagery</title><categories>math.ST cs.CV stat.TH</categories><comments>12 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polarimetric synthetic aperture radar (PolSAR) has achieved a prominent
position as a remote imaging method. However, PolSAR images are contaminated by
speckle noise due to the coherent illumination employed during the data
acquisition. This noise provides a granular aspect to the image, making its
processing and analysis (such as in edge detection) hard tasks. This paper
discusses seven methods for edge detection in multilook PolSAR images. In all
methods, the basic idea consists in detecting transition points in the finest
possible strip of data which spans two regions. The edge is contoured using the
transitions points and a B-spline curve. Four stochastic distances, two
differences of entropies, and the maximum likelihood criterion were used under
the scaled complex Wishart distribution; the first six stem from the h-phi
class of measures. The performance of the discussed detection methods was
quantified and analyzed by the computational time and probability of correct
edge detection, with respect to the number of looks, the backscatter matrix as
a whole, the SPAN, the covariance an the spatial resolution. The detection
procedures were applied to three real PolSAR images. Results provide evidence
that the methods based on the Bhattacharyya distance and the difference of
Shannon entropies outperform the other techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2008</identifier>
 <datestamp>2014-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2008</id><created>2013-06-09</created><updated>2013-10-18</updated><authors><author><keyname>Yang</keyname><forenames>Li</forenames></author><author><keyname>Li</keyname><forenames>Hong-Wei</forenames></author></authors><title>Investigating the linear structure of Boolean functions based on Simon's
  period-finding quantum algorithm</title><categories>quant-ph cs.CR</categories><comments>13 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is believed that there is no e?cient classical algorithm to determine the
linear structure of Boolean function. We investigate an extension of Simon's
period-?nding quantum algorithm, and propose an e?cient quantum algorithm to
determine the linear structure of Boolean function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2009</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2009</id><created>2013-06-09</created><authors><author><keyname>Yun</keyname><forenames>Se-Young</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author></authors><title>CSMA over Time-varying Channels: Optimality, Uniqueness and Limited
  Backoff Rate</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies on MAC scheduling have shown that carrier sense multiple
access (CSMA) algo- rithms can be throughput optimal for arbitrary wireless
network topology. However, these results are highly sensitive to the underlying
assumption on 'static' or 'fixed' system conditions. For example, if channel
conditions are time-varying, it is unclear how each node can adjust its CSMA
parameters, so-called backoff and channel holding times, using its local
channel information for the desired high performance. In this paper, we study
'channel-aware' CSMA (A-CSMA) algorithms in time-varying channels, where they
adjust their parameters as some function of the current channel capacity.
First, we show that the achievable rate region of A-CSMA equals to the maximum
rate region if and only if the function is exponential. Furthermore, given an
exponential function in A-CSMA, we design updating rules for their parameters,
which achieve throughput optimality for an arbitrary wireless network topology.
They are the first CSMA algorithms in the literature which are proved to be
throughput optimal under time-varying channels. Moreover, we also consider the
case when back-off rates of A- CSMA are highly restricted compared to the speed
of channel variations, and characterize the throughput performance of A-CSMA in
terms of the underlying wireless network topology. Our results not only guide a
high-performance design on MAC scheduling under highly time-varying scenarios,
but also provide new insights on the performance of CSMA algorithms in relation
to their backoff rates and the network topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2015</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2015</id><created>2013-06-09</created><authors><author><keyname>Rao</keyname><forenames>Xiongbin</forenames><affiliation>Fellow IEEE</affiliation></author><author><keyname>Ruan</keyname><forenames>Liangzhong</forenames><affiliation>Fellow IEEE</affiliation></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames><affiliation>Fellow IEEE</affiliation></author></authors><title>CSI Feedback Reduction for MIMO Interference Alignment</title><categories>cs.IT math.IT</categories><comments>30 pages, 7 figures, accepted for publication by IEEE transactions on
  signal processing in June, 2013</comments><doi>10.1109/TSP.2013.2269902</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment (IA) is a linear precoding strategy that can achieve
optimal capacity scaling at high SNR in interference networks. Most of the
existing IA designs require full channel state information (CSI) at the
transmitters, which induces a huge CSI signaling cost. Hence it is desirable to
improve the feedback efficiency for IA and in this paper, we propose a novel IA
scheme with a significantly reduced CSI feedback. To quantify the CSI feedback
cost, we introduce a novel metric, namely the feedback dimension. This metric
serves as a first-order measurement of CSI feedback overhead. Due to the
partial CSI feedback constraint, conventional IA schemes can not be applied and
hence, we develop a novel IA precoder / decorrelator design and establish new
IA feasibility conditions. Via dynamic feedback profile design, the proposed IA
scheme can also achieve a flexible tradeoff between the degree of freedom (DoF)
requirements for data streams, the antenna resources and the CSI feedback cost.
We show by analysis and simulations that the proposed scheme achieves
substantial reductions of CSI feedback overhead under the same DoF requirement
in MIMO interference networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2019</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2019</id><created>2013-06-09</created><authors><author><keyname>Petre</keyname><forenames>Ion</forenames><affiliation>&#xc5;bo Akademi University</affiliation></author></authors><title>Proceedings Fourth International Workshop on Computational Models for
  Cell Processes</title><categories>cs.CE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 116, 2013</journal-ref><doi>10.4204/EPTCS.116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fourth international workshop on Computational Models for Cell Processes
(CompMod 2013) took place on June 11, 2013 at the {\AA}bo Akademi University,
Turku, Finland, in conjunction with iFM 2013. The first edition of the workshop
(2008) took place in Turku, Finland, in conjunction with Formal Methods 2008,
the second edition (2009) took place in Eindhoven, the Netherlands, as well in
conjunction with Formal Methods 2009, and the third one took place in Aachen,
Germany, in conjunction with CONCUR 2013. This volume contains the final
versions of all contributions accepted for presentation at the workshop.
  The goal of the CompMod workshop series is to bring together researchers in
Computer Science and Mathematics (both discrete and continuous), interested in
the opportunities and the challenges of Systems Biology. The Program Committee
of CompMod 2013 selected 3 papers for presentation at the workshop. In
addition, we had two invited talks and five informal presentations.
  The scientific program of the workshop spans an interesting mix of approaches
to systems and even synthetic biology, encompassing several different modeling
approaches, ranging from quantitative to qualitative techniques, from
continuous to discrete mathematics, and from deterministic to stochastic
methods. We thank our invited speakers Daniela Besozzi (Universita degli Studi
di Milano, Milano, Italy) and Juho Rousu (Aalto University, Finland) for
accepting our invitation and for presenting some of their recent results at
CompMod 2013.
  The technical contributions address the mathematical modeling of the PDGF
signalling pathway, the canonical labelling of site graphs, rule-based modeling
of polymerization reactions, rule-based modeling as a platform for the analysis
of synthetic self-assembled nano-systems, robustness analysis of stochastic
systems, an algebraic approach to gene assembly in ciliates, and large-scale
text mining of biomedical literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2025</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2025</id><created>2013-06-09</created><authors><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Flexibly-bounded Rationality and Marginalization of Irrationality
  Theories for Decision Making</title><categories>cs.AI</categories><comments>17 pages, submitted to Springer-Verlag. arXiv admin note: substantial
  text overlap with arXiv:1305.6037</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the theory of flexibly-bounded rationality which is an
extension to the theory of bounded rationality is revisited. Rational decision
making involves using information which is almost always imperfect and
incomplete together with some intelligent machine which if it is a human being
is inconsistent to make decisions. In bounded rationality, this decision is
made irrespective of the fact that the information to be used is incomplete and
imperfect and that the human brain is inconsistent and thus this decision that
is to be made is taken within the bounds of these limitations. In the theory of
flexibly-bounded rationality, advanced information analysis is used, the
correlation machine is applied to complete missing information and artificial
intelligence is used to make more consistent decisions. Therefore
flexibly-bounded rationality expands the bounds within which rationality is
exercised. Because human decision making is essentially irrational, this paper
proposes the theory of marginalization of irrationality in decision making to
deal with the problem of satisficing in the presence of irrationality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2035</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2035</id><created>2013-06-09</created><authors><author><keyname>Azizyan</keyname><forenames>Martin</forenames></author><author><keyname>Singh</keyname><forenames>Aarti</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean
  Separation</title><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While several papers have investigated computationally and statistically
efficient methods for learning Gaussian mixtures, precise minimax bounds for
their statistical performance as well as fundamental limits in high-dimensional
settings are not well-understood. In this paper, we provide precise information
theoretic bounds on the clustering accuracy and sample complexity of learning a
mixture of two isotropic Gaussians in high dimensions under small mean
separation. If there is a sparse subset of relevant dimensions that determine
the mean separation, then the sample complexity only depends on the number of
relevant dimensions and mean separation, and can be achieved by a simple
computationally efficient procedure. Our results provide the first step of a
theoretical basis for recent methods that combine feature selection and
clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2037</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2037</id><created>2013-06-09</created><authors><author><keyname>Yazdani</keyname><forenames>Maryam</forenames></author><author><keyname>Zamani</keyname><forenames>Morteza Saheb</forenames></author><author><keyname>Sedighi</keyname><forenames>Mehdi</forenames></author></authors><title>A Quantum Physical Design Flow Using ILP and Graph Drawing</title><categories>quant-ph cs.ET</categories><comments>17 figures, 12 tables, Quantum Information Processing Journal. arXiv
  admin note: text overlap with arXiv:0704.0268 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Implementing large-scale quantum circuits is one of the challenges of quantum
computing. One of the central challenges of accurately modeling the
architecture of these circuits is to schedule a quantum application and
generate the layout while taking into account the cost of communications and
classical resources as well as the maximum exploitable parallelism. In this
paper, we present and evaluate a design flow for arbitrary quantum circuits in
ion trap technology. Our design flow consists of two parts. First, a scheduler
takes a description of a circuit and finds the best order for the execution of
its quantum gates using integer linear programming (ILP) regarding the
classical resources (qubits) and instruction dependencies. Then a layout
generator receives the schedule produced by the scheduler and generates a
layout for this circuit using a graph-drawing algorithm. Our experimental
results show that the proposed flow decreases the average latency of quantum
circuits by about 11% for a set of attempted benchmarks and by about 9% for
another set of benchmarks compared with the best in literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2040</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2040</id><created>2013-06-09</created><updated>2013-08-25</updated><authors><author><keyname>Zattoni</keyname><forenames>Elena</forenames></author><author><keyname>Perdon</keyname><forenames>Anna Maria</forenames></author><author><keyname>Conte</keyname><forenames>Giuseppe</forenames></author></authors><title>A Numerical Example about the Geometric Approach to the Output
  Regulation Problem with Stability for Linear Switching Systems</title><categories>cs.SY math.OC</categories><comments>With respect to version 2, complete citations for reference [1] were
  provided</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note presents a numerical example worked out in order to illustrate the
solution to the output regulation problem with quadratic stability for linear
switching systems derived in [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2043</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2043</id><created>2013-06-09</created><authors><author><keyname>Wei</keyname><forenames>Zhiqing</forenames></author></authors><title>A Raindrop Algorithm for Searching The Global Optimal Solution in
  Non-linear Programming</title><categories>cs.DS</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply the random walk model in designing a raindrop
algorithm to find the global optimal solution of a non-linear programming
problem. The raindrop algorithm does not require the information of the first
or second order derivatives of the object function. Hence it is a direct
method. We investigate the properties of raindrop algorithm. Besides, we apply
the raindrop algorithm to solve a non-linear optimization problem, where the
object function is highly irregular (neither convex nor concave). And the
global optimal solution can be found with small number of iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2053</identifier>
 <datestamp>2014-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2053</id><created>2013-06-09</created><updated>2014-03-05</updated><authors><author><keyname>Alam</keyname><forenames>Md. Jawaherul</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author><author><keyname>Pupyrev</keyname><forenames>Sergey</forenames></author><author><keyname>Toeniskoetter</keyname><forenames>Jakson</forenames></author></authors><title>Happy Edges: Threshold-Coloring of Regular Lattices</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a graph coloring problem motivated by a fun Sudoku-style puzzle.
Given a bipartition of the edges of a graph into {\em near} and {\em far} sets
and an integer threshold $t$, a {\em threshold-coloring} of the graph is an
assignment of integers to the vertices so that endpoints of near edges differ
by $t$ or less, while endpoints of far edges differ by more than $t$. We study
threshold-coloring of tilings of the plane by regular polygons, known as
Archimedean lattices, and their duals, the Laves lattices. We prove that some
are threshold-colorable with constant number of colors for any edge labeling,
some require an unbounded number of colors for specific labelings, and some are
not threshold-colorable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2060</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2060</id><created>2013-06-09</created><updated>2015-07-28</updated><authors><author><keyname>Pudwell</keyname><forenames>Lara</forenames></author><author><keyname>Rowland</keyname><forenames>Eric</forenames></author></authors><title>What's in YOUR wallet?</title><categories>math.HO cs.DM stat.AP</categories><comments>10 pages; final version</comments><msc-class>05A17, 60J10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use Markov chains and numerical linear algebra -- and several CPU hours --
to determine the expected number of coins in a person's possession under
certain conditions. We identify the spending strategy that results in the
minimum possible expected number of coins, and we consider two other strategies
that are more realistic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2068</identifier>
 <datestamp>2015-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2068</id><created>2013-06-09</created><updated>2015-06-03</updated><authors><author><keyname>Lewitzka</keyname><forenames>Steffen</forenames></author></authors><title>A modal logic amalgam of classical and intuitionistic propositional
  logic</title><categories>cs.LO math.LO</categories><comments>18 pages</comments><doi>10.1093/logcom/exv048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A famous result, conjectured by G\&quot;odel in 1932 and proved by McKinsey and
Tarski in 1948, says that $\varphi$ is a theorem of intuitionistic
propositional logic IPC iff its G\&quot;odel-translation $\varphi'$ is a theorem of
modal logic S4. In this paper, we extend an intuitionistic version of modal
logic S1+SP, introduced in our previous paper (S. Lewitzka, Algebraic semantics
for a modal logic close to S1, J. Logic and Comp., doi:10.1093/logcom/exu067)
to a classical modal logic L and prove the following: a propositional formula
$\varphi$ is a theorem of IPC iff $\square\varphi$ is a theorem of L (actually,
we show: $\Phi\vdash_{IPC}\varphi$ iff $\square\Phi\vdash_L\square\varphi$, for
propositional $\Phi,\varphi$). Thus, the map $\varphi\mapsto\square\varphi$ is
an embedding of IPC into L, i.e. L contains a copy of IPC. Moreover, L is a
conservative extension of classical propositional logic CPC. In this sense, L
is an amalgam of CPC and IPC. We show that L is sound and complete w.r.t. a
class of special Heyting algebras with a (non-normal) modal operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2069</identifier>
 <datestamp>2015-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2069</id><created>2013-06-09</created><updated>2015-08-01</updated><authors><author><keyname>Czajka</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Confluence of an extension of Combinatory Logic by Boolean Constants</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show confluence of a conditional term rewriting system CLC, which is an
extension of Combinatory Logic by Boolean constants. This solves problem 15
from the RTA list of open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2079</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2079</id><created>2013-06-09</created><updated>2013-06-18</updated><authors><author><keyname>Fink</keyname><forenames>Martin</forenames></author><author><keyname>Pupyrev</keyname><forenames>Sergey</forenames></author></authors><title>Metro-Line Crossing Minimization: Hardness, Approximations, and
  Tractable Cases</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crossing minimization is one of the central problems in graph drawing.
Recently, there has been an increased interest in the problem of minimizing
crossings between paths in drawings of graphs. This is the metro-line crossing
minimization problem (MLCM): Given an embedded graph and a set L of simple
paths, called lines, order the lines on each edge so that the total number of
crossings is minimized. So far, the complexity of MLCM has been an open
problem. In contrast, the problem variant in which line ends must be placed in
outermost position on their edges (MLCM-P) is known to be NP-hard. Our main
results answer two open questions: (i) We show that MLCM is NP-hard. (ii) We
give an $O(\sqrt{\log |L|})$-approximation algorithm for MLCM-P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2081</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2081</id><created>2013-06-09</created><authors><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Johan</keyname><forenames>Henry</forenames></author></authors><title>3D model retrieval using global and local radial distances</title><categories>cs.GR cs.CV cs.IR</categories><comments>6</comments><journal-ref>The International Workshop on Advanced Image Technology
  (IWAIT2010), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D model retrieval techniques can be classified as histogram-based,
view-based and graph-based approaches. We propose a hybrid shape descriptor
which combines the global and local radial distance features by utilizing the
histogram-based and view-based approaches respectively. We define an
area-weighted global radial distance with respect to the center of the bounding
sphere of the model and encode its distribution into a 2D histogram as the
global radial distance shape descriptor. We then uniformly divide the bounding
cube of a 3D model into a set of small cubes and define their centers as local
centers. Then, we compute the local radial distance of a point based on the
nearest local center. By sparsely sampling a set of views and encoding the
local radial distance feature on the rendered views by color coding, we extract
the local radial distance shape descriptor. Based on these two shape
descriptors, we develop a hybrid radial distance shape descriptor for 3D model
retrieval. Experiment results show that our hybrid shape descriptor outperforms
several typical histogram-based and view-based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2083</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2083</id><created>2013-06-09</created><authors><author><keyname>Pai</keyname><forenames>Mallesh</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author></authors><title>Privacy and Mechanism Design</title><categories>cs.GT cs.CR cs.DS</categories><comments>This survey appears in SIGecom Exchanges 12.1, 2013</comments><acm-class>J.4</acm-class><journal-ref>SIGecom Exchanges 12.1, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a survey of recent work at the intersection of mechanism design
and privacy. The connection is a natural one, but its study has been
jump-started in recent years by the advent of differential privacy, which
provides a rigorous, quantitative way of reasoning about the costs that an
agent might experience because of the loss of his privacy. Here, we survey
several facets of this study, and differential privacy plays a role in more
than one way. Of course, it provides us a basis for modeling agent costs for
privacy, which is essential if we are to attempt mechanism design in a setting
in which agents have preferences for privacy. It also provides a toolkit for
controlling those costs. However, perhaps more surprisingly, it provides a
powerful toolkit for controlling the stability of mechanisms in general, which
yields a set of tools for designing novel mechanisms even in economic settings
completely unrelated to privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2084</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2084</id><created>2013-06-09</created><authors><author><keyname>Nickel</keyname><forenames>Maximilian</forenames></author><author><keyname>Tresp</keyname><forenames>Volker</forenames></author></authors><title>Logistic Tensor Factorization for Multi-Relational Data</title><categories>stat.ML cs.LG</categories><comments>Accepted at ICML 2013 Workshop &quot;Structured Learning: Inferring Graphs
  from Structured and Unstructured Inputs&quot; (SLG 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensor factorizations have become increasingly popular approaches for various
learning tasks on structured data. In this work, we extend the RESCAL tensor
factorization, which has shown state-of-the-art results for multi-relational
learning, to account for the binary nature of adjacency tensors. We study the
improvements that can be gained via this approach on various benchmark datasets
and show that the logistic extension can improve the prediction results
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2086</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2086</id><created>2013-06-09</created><updated>2014-12-29</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author></authors><title>Byzantine Fault Tolerant Distributed Quickest Change Detection</title><categories>math.PR cs.IT cs.SY math.IT math.OC</categories><comments>Final version. To appear in the SIAM Journal on Control and
  Optimization. Keywords: (Non-Bayesian) quickest change detection, Byzantine
  fault tolerance, distributed sensor network, robust optimal stopping in
  continuous and discrete time</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and solve the problem of Byzantine fault tolerant distributed
quickest change detection in both continuous and discrete time setups. In this
problem, multiple sensors sequentially observe random signals from the
environment and send their observations to a control center that will determine
whether there is a change in the statistical behavior of the observations. We
assume that the signals are independent and identically distributed across
sensors. An unknown subset of sensors are compromised and will send arbitrarily
modified and even artificially generated signals to the control center. It is
shown that the performance of the the so-called CUSUM statistic, which is
optimal when all sensors are honest, will be significantly degraded in the
presence of even a single dishonest sensor. In particular, instead of in a
logarithmically the detection delay grows linearly with the average run length
(ARL) to false alarm. To mitigate such a performance degradation, we propose a
fully distributed low complexity detection scheme. We show that the proposed
scheme can recover the log scaling. We also propose a centralized group-wise
scheme that can further reduce the detection delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2091</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2091</id><created>2013-06-09</created><updated>2013-06-14</updated><authors><author><keyname>Schneider</keyname><forenames>Nathan</forenames></author><author><keyname>O'Connor</keyname><forenames>Brendan</forenames></author><author><keyname>Saphra</keyname><forenames>Naomi</forenames></author><author><keyname>Bamman</keyname><forenames>David</forenames></author><author><keyname>Faruqui</keyname><forenames>Manaal</forenames></author><author><keyname>Smith</keyname><forenames>Noah A.</forenames></author><author><keyname>Dyer</keyname><forenames>Chris</forenames></author><author><keyname>Baldridge</keyname><forenames>Jason</forenames></author></authors><title>A framework for (under)specifying dependency syntax without overloading
  annotators</title><categories>cs.CL</categories><comments>This is an expanded version of a paper appearing in Proceedings of
  the 7th Linguistic Annotation Workshop &amp; Interoperability with Discourse,
  Sofia, Bulgaria, August 8-9, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a framework for lightweight dependency syntax annotation. Our
formalism builds upon the typical representation for unlabeled dependencies,
permitting a simple notation and annotation workflow. Moreover, the formalism
encourages annotators to underspecify parts of the syntax if doing so would
streamline the annotation process. We demonstrate the efficacy of this
annotation on three languages and develop algorithms to evaluate and compare
underspecified annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2094</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2094</id><created>2013-06-09</created><authors><author><keyname>Zolfaghar</keyname><forenames>Kiyana</forenames></author><author><keyname>Verbiest</keyname><forenames>Nele</forenames></author><author><keyname>Agarwal</keyname><forenames>Jayshree</forenames></author><author><keyname>Meadem</keyname><forenames>Naren</forenames></author><author><keyname>Chin</keyname><forenames>Si-Chi</forenames></author><author><keyname>Roy</keyname><forenames>Senjuti Basu</forenames></author><author><keyname>Teredesai</keyname><forenames>Ankur</forenames></author><author><keyname>Hazel</keyname><forenames>David</forenames></author><author><keyname>Amoroso</keyname><forenames>Paul</forenames></author><author><keyname>Reed</keyname><forenames>Lester</forenames></author></authors><title>Predicting Risk-of-Readmission for Congestive Heart Failure Patients: A
  Multi-Layer Approach</title><categories>cs.LG stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mitigating risk-of-readmission of Congestive Heart Failure (CHF) patients
within 30 days of discharge is important because such readmissions are not only
expensive but also critical indicator of provider care and quality of
treatment. Accurately predicting the risk-of-readmission may allow hospitals to
identify high-risk patients and eventually improve quality of care by
identifying factors that contribute to such readmissions in many scenarios. In
this paper, we investigate the problem of predicting risk-of-readmission as a
supervised learning problem, using a multi-layer classification approach.
Earlier contributions inadequately attempted to assess a risk value for 30 day
readmission by building a direct predictive model as opposed to our approach.
We first split the problem into various stages, (a) at risk in general (b) risk
within 60 days (c) risk within 30 days, and then build suitable classifiers for
each stage, thereby increasing the ability to accurately predict the risk using
multiple layers of decision. The advantage of our approach is that we can use
different classification models for the subtasks that are more suited for the
respective problems. Moreover, each of the subtasks can be solved using
different features and training data leading to a highly confident diagnosis or
risk compared to a one-shot single layer approach. An experimental evaluation
on actual hospital patient record data from Multicare Health Systems shows that
our model is significantly better at predicting risk-of-readmission of CHF
patients within 30 days after discharge compared to prior attempts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2096</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2096</id><created>2013-06-09</created><authors><author><keyname>Kobayashi</keyname><forenames>Kenichi</forenames><affiliation>Fujitsu Laboratories</affiliation></author><author><keyname>Kamimura</keyname><forenames>Manabu</forenames></author><author><keyname>Kato</keyname><forenames>Koki</forenames></author><author><keyname>Yano</keyname><forenames>Keisuke</forenames></author><author><keyname>Matsuo</keyname><forenames>Akihiko</forenames></author></authors><title>Feature-Gathering Dependency-Based Software Clustering Using Dedication
  and Modularity</title><categories>cs.SE</categories><comments>10 pages, 9 figures, 7 tables. This is the accepted version of a
  paper presented at the 28th IEEE International Conference on Software
  Maintenance (ICSM2012), Riva del Garda, Trento, Italy, Sep 2012, pp.462-471</comments><doi>10.1109/ICSM.2012.6405308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software clustering is one of the important techniques to comprehend software
systems. However, presented techniques to date require human interactions to
refine clustering results. In this paper, we proposed a novel dependency-based
software clustering algorithm, SArF. SArF has two characteristics. First, SArF
eliminates the need of the omnipresent-module-removing step which requires
human interactions. Second, the objective of SArF is to gather relevant
software features or functionalities into a cluster. To achieve them, we
defined the Dedication score to infer the importance of dependencies and
utilized Modularity Maximization to cluster weighted directed graphs. Two case
studies and extensive comparative evaluations using open source and industrial
systems show that SArF could successfully decompose the systems fitting to the
authoritative decompositions from a feature viewpoint without any tailored
setups and that SArF was superior to existing dependency-based software
clustering studies. Besides, the case studies show that there exist measurable
authoritativeness limits and that SArF nearly reached the limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2100</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2100</id><created>2013-06-10</created><authors><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author></authors><title>Discriminative extended canonical correlation analysis for pattern set
  matching</title><categories>cs.CV</categories><comments>Machine Learning, 2013</comments><doi>10.1007/s10994-013-5380-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of matching sets of vectors embedded in
the same input space. We propose an approach which is motivated by canonical
correlation analysis (CCA), a statistical technique which has proven successful
in a wide variety of pattern recognition problems. Like CCA when applied to the
matching of sets, our extended canonical correlation analysis (E-CCA) aims to
extract the most similar modes of variability within two sets. Our first major
contribution is the formulation of a principled framework for robust inference
of such modes from data in the presence of uncertainty associated with noise
and sampling randomness. E-CCA retains the efficiency and closed form
computability of CCA, but unlike it, does not possess free parameters which
cannot be inferred directly from data (inherent data dimensionality, and the
number of canonical correlations used for set similarity computation). Our
second major contribution is to show that in contrast to CCA, E-CCA is readily
adapted to match sets in a discriminative learning scheme which we call
discriminative extended canonical correlation analysis (DE-CCA). Theoretical
contributions of this paper are followed by an empirical evaluation of its
premises on the task of face recognition from sets of rasterized appearance
images. The results demonstrate that our approach, E-CCA, already outperforms
both CCA and its quasi-discriminative counterpart constrained CCA (C-CCA), for
all values of their free parameters. An even greater improvement is achieved
with the discriminative variant, DE-CCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2101</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2101</id><created>2013-06-10</created><authors><author><keyname>Geraci</keyname><forenames>Giovanni</forenames></author><author><keyname>Singh</keyname><forenames>Sarabjot</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Secrecy Rates in the Broadcast Channel with Confidential Messages and
  External Eavesdroppers</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the broadcast channel with confidential messages
and external eavesdroppers (BCCE), where a multi-antenna base station
simultaneously communicates to multiple potentially malicious users, in the
presence of randomly located external eavesdroppers. Using the proposed model,
we study the secrecy rates achievable by regularized channel inversion (RCI)
precoding by performing a large-system analysis that combines tools from
stochastic geometry and random matrix theory. We obtain explicit expressions
for the probability of secrecy outage and an upper bound on the rate loss due
to the presence of external eavesdroppers. We show that both these quantities
scale as $\frac{\lambda_e}{\sqrt{N}}$, where $N$ is the number of transmit
antennas and $\lambda_e$ is the density of external eavesdroppers, irrespective
of their collusion strategy. Furthermore, we derive a practical rule for the
choice of the regularization parameter, which is agnostic of channel state
information and location of eavesdroppers, and yet provides close to optimal
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2102</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2102</id><created>2013-06-10</created><authors><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author></authors><title>Discriminative k-means clustering</title><categories>cs.CV</categories><journal-ref>International Joint Conference on Neural Networks, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-means algorithm is a partitional clustering method. Over 60 years old,
it has been successfully used for a variety of problems. The popularity of
k-means is in large part a consequence of its simplicity and efficiency. In
this paper we are inspired by these appealing properties of k-means in the
development of a clustering algorithm which accepts the notion of &quot;positively&quot;
and &quot;negatively&quot; labelled data. The goal is to discover the cluster structure
of both positive and negative data in a manner which allows for the
discrimination between the two sets. The usefulness of this idea is
demonstrated practically on the problem of face recognition, where the task of
learning the scope of a person's appearance should be done in a manner which
allows this face to be differentiated from others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2104</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2104</id><created>2013-06-10</created><authors><author><keyname>Raz</keyname><forenames>Orit Esther</forenames></author></authors><title>On the zone of the boundary of a convex body</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an arrangement $\A$ of $n$ hyperplanes in $\R^d$ and the zone
$\Z$ in $\A$ of the boundary of an arbitrary convex set in $\R^d$ in such an
arrangement. We show that, whereas the combinatorial complexity of $\Z$ is
known only to be $O&lt;n^{d-1}\log n&gt;$ \cite{APS}, the outer part of the zone has
complexity $O&lt;n^{d-1}&gt;$ (without the logarithmic factor). Whether this bound
also holds for the complexity of the inner part of the zone is still an open
question (even for $d=2$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2108</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2108</id><created>2013-06-10</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIPN</affiliation></author><author><keyname>Jacquot</keyname><forenames>Alice</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchon</keyname><forenames>Philippe</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Mutafchiev</keyname><forenames>Ljuben R.</forenames><affiliation>LIPN</affiliation></author></authors><title>Asymptotic Analysis and Random Sampling of Digitally Convex Polyominoes</title><categories>cs.DM</categories><proxy>ccsd</proxy><journal-ref>Discrete Applied Mathematics (2013) 1-23</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work of Brlek \textit{et al.} gives a characterization of digitally
convex polyominoes using combinatorics on words. From this work, we derive a
combinatorial symbolic description of digitally convex polyominoes and use it
to analyze their limit properties and build a uniform sampler. Experimentally,
our sampler shows a limit shape for large digitally convex polyominoes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2109</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2109</id><created>2013-06-10</created><updated>2013-12-16</updated><authors><author><keyname>Tu</keyname><forenames>Sheng-Yuan</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Distributed Decision-Making over Adaptive Networks</title><categories>cs.IT cs.SY math.IT</categories><comments>42 pages, 11 figures, to appear in IEEE Transactions on Signal
  Processing, 2014</comments><doi>10.1109/TSP.2013.2296271</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In distributed processing, agents generally collect data generated by the
same underlying unknown model (represented by a vector of parameters) and then
solve an estimation or inference task cooperatively. In this paper, we consider
the situation in which the data observed by the agents may have risen from two
different models. Agents do not know beforehand which model accounts for their
data and the data of their neighbors. The objective for the network is for all
agents to reach agreement on which model to track and to estimate this model
cooperatively. In these situations, where agents are subject to data from
unknown different sources, conventional distributed estimation strategies would
lead to biased estimates relative to any of the underlying models. We first
show how to modify existing strategies to guarantee unbiasedness. We then
develop a classification scheme for the agents to identify the models that
generated the data, and propose a procedure by which the entire network can be
made to converge towards the same model through a collaborative decision-making
process. The resulting algorithm is applied to model fish foraging behavior in
the presence of two food sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2114</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2114</id><created>2013-06-10</created><updated>2014-01-28</updated><authors><author><keyname>Meister</keyname><forenames>Daniel</forenames></author><author><keyname>Rotics</keyname><forenames>Udi</forenames></author></authors><title>Minimal forbidden induced subgraphs of graphs of bounded clique-width
  and bounded linear clique-width</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the study of full bubble model graphs of bounded clique-width and bounded
linear clique-width, we determined complete sets of forbidden induced
subgraphs, that are minimal in the class of full bubble model graphs. In this
note, we show that (almost all of) these graphs are minimal in the class of all
graphs. As a corollary, we can give sets of minimal forbidden induced subgraphs
for graphs of bounded clique-width and for graphs of bounded linear
clique-width for arbitrary bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2118</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2118</id><created>2013-06-10</created><authors><author><keyname>Sathishkumar</keyname><forenames>E. N.</forenames></author><author><keyname>Thangavel</keyname><forenames>K.</forenames></author><author><keyname>Chandrasekhar</keyname><forenames>T.</forenames></author></authors><title>A Novel Approach for Single Gene Selection Using Clustering and
  Dimensionality Reduction</title><categories>cs.CE cs.LG</categories><comments>6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1306.1323</comments><journal-ref>International Journal of Scientific &amp; Engineering Research, Volume
  4, Issue 5, May-2013, page no 1540-1545</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the standard rough set-based approach to deal with huge amounts of
numeric attributes versus small amount of available objects. Here, a novel
approach of clustering along with dimensionality reduction; Hybrid Fuzzy C
Means-Quick Reduct (FCMQR) algorithm is proposed for single gene selection.
Gene selection is a process to select genes which are more informative. It is
one of the important steps in knowledge discovery. The problem is that all
genes are not important in gene expression data. Some of the genes may be
redundant, and others may be irrelevant and noisy. In this study, the entire
dataset is divided in proper grouping of similar genes by applying Fuzzy C
Means (FCM) algorithm. A high class discriminated genes has been selected based
on their degree of dependence by applying Quick Reduct algorithm based on Rough
Set Theory to all the resultant clusters. Average Correlation Value (ACV) is
calculated for the high class discriminated genes. The clusters which have the
ACV value a s 1 is determined as significant clusters, whose classification
accuracy will be equal or high when comparing to the accuracy of the entire
dataset. The proposed algorithm is evaluated using WEKA classifiers and
compared. Finally, experimental results related to the leukemia cancer data
confirm that our approach is quite promising, though it surely requires further
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2119</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2119</id><created>2013-06-10</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Paris - Rocquencourt, LIENS</affiliation></author><author><keyname>Moulines</keyname><forenames>Eric</forenames><affiliation>LTCI</affiliation></author></authors><title>Non-strongly-convex smooth stochastic approximation with convergence
  rate O(1/n)</title><categories>cs.LG math.OC stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the stochastic approximation problem where a convex function has
to be minimized, given only the knowledge of unbiased estimates of its
gradients at certain points, a framework which includes machine learning
methods based on the minimization of the empirical risk. We focus on problems
without strong convexity, for which all previously known algorithms achieve a
convergence rate for function values of O(1/n^{1/2}). We consider and analyze
two algorithms that achieve a rate of O(1/n) for classical supervised learning
problems. For least-squares regression, we show that averaged stochastic
gradient descent with constant step-size achieves the desired rate. For
logistic regression, this is achieved by a simple novel stochastic gradient
algorithm that (a) constructs successive local quadratic approximations of the
loss functions, while (b) preserving the same running time complexity as
stochastic gradient descent. For these algorithms, we provide a non-asymptotic
analysis of the generalization error (in expectation, and also in high
probability for least-squares), and run extensive experiments on standard
machine learning benchmarks showing that they often outperform existing
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2124</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2124</id><created>2013-06-10</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author></authors><title>New views of crystal symmetry guided by profound admiration of the
  extraordinary works of Grassmann and Clifford</title><categories>cond-mat.mtrl-sci cs.GR math.RA math.RT</categories><comments>11 pages, 8 figures, 2 tables. arXiv admin note: substantial text
  overlap with arXiv:1306.1599</comments><msc-class>Primary 20H15, Secondary 15A66, 74N05, 76M27, 20F55</msc-class><journal-ref>From Past to Future: Gra{\ss}mann's Work in Context, Gra{\ss}mann
  Bicentennial Conference, September 2009, Springer, Basel, pp. 413 - 422
  (2011)</journal-ref><doi>10.1007/978-3-0346-0405-5_36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how beginning with Justus Grassmann's work, Hermann
Grassmann was influenced in his mathematical thinking by crystallography. H.
Grassmann's Ausdehnungslehre in turn had a decisive influence on W.K. Clifford
in the genesis of geometric algebras. Geometric algebras have been expanded to
conformal geometric algebras, which provide an ideal framework for modern
computer graphics. Within this framework a new visualization of
three-dimensional crystallographic space groups has been created. The complex
beauty of this new visualization is shown by a range of images of a diamond
cell. Mathematical details are given in an appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2141</identifier>
 <datestamp>2015-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2141</id><created>2013-06-10</created><updated>2014-07-04</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Spoletini</keyname><forenames>Paola</forenames></author></authors><title>Bounded Variability of Metric Temporal Logic</title><categories>cs.LO</categories><doi>10.1109/TIME.2014.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work has shown that reasoning with real-time temporal logics is
often simpler when restricted to models with bounded variability---where no
more than v events may occur every V time units, for given v, V. When reasoning
about formulas with intrinsic bounded variability, one can employ the simpler
techniques that rely on bounded variability, without any loss of generality.
What is then the complexity of algorithmically deciding which formulas have
intrinsic bounded variability?
  In this paper, we study the problem with reference to Metric Temporal Logic
(MTL). We prove that deciding bounded variability of MTL formulas is
undecidable over dense-time models, but with a undecidability degree lower than
generic dense-time MTL satisfiability. Over discrete-time models, instead,
deciding MTL bounded variability has the same exponential-space complexity as
satisfiability. To complement these negative results, we also briefly discuss
small fragments of MTL that are more amenable to reasoning about bounded
variability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2157</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2157</id><created>2013-06-10</created><authors><author><keyname>Hitzer</keyname><forenames>Eckhard</forenames></author><author><keyname>Sangwine</keyname><forenames>Stephen J.</forenames></author></authors><title>The Orthogonal 2D Planes Split of Quaternions and Steerable Quaternion
  Fourier Transformations</title><categories>math.RA cs.GR math.CA</categories><comments>25 pages, 5 figures</comments><journal-ref>In E. Hitzer, S. Sangwine (eds.), &quot;Quaternion and Clifford Fourier
  transforms and wavelets&quot;, Trends in Mathematics 27, Birkhauser, Basel, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-sided quaternionic Fourier transformation (QFT) was introduced in
\cite{Ell:1993} for the analysis of 2D linear time-invariant
partial-differential systems. In further theoretical investigations
\cite{10.1007/s00006-007-0037-8, EH:DirUP_QFT} a special split of quaternions
was introduced, then called $\pm$split. In the current \change{chapter} we
analyze this split further, interpret it geometrically as \change{an}
\emph{orthogonal 2D planes split} (OPS), and generalize it to a freely
steerable split of $\H$ into two orthogonal 2D analysis planes. The new general
form of the OPS split allows us to find new geometric interpretations for the
action of the QFT on the signal. The second major result of this work is a
variety of \emph{new steerable forms} of the QFT, their geometric
interpretation, and for each form\change{,} OPS split theorems, which allow
fast and efficient numerical implementation with standard FFT software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2158</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2158</id><created>2013-06-10</created><authors><author><keyname>Hermann</keyname><forenames>Karl Moritz</forenames></author><author><keyname>Grefenstette</keyname><forenames>Edward</forenames></author><author><keyname>Blunsom</keyname><forenames>Phil</forenames></author></authors><title>&quot;Not not bad&quot; is not &quot;bad&quot;: A distributional account of negation</title><categories>cs.CL</categories><comments>9 pages, to appear in Proceedings of the 2013 Workshop on Continuous
  Vector Space Models and their Compositionality</comments><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing empirical success of distributional models of
compositional semantics, it is timely to consider the types of textual logic
that such models are capable of capturing. In this paper, we address
shortcomings in the ability of current models to capture logical operations
such as negation. As a solution we propose a tripartite formulation for a
continuous vector space representation of semantics and subsequently use this
representation to develop a formal compositional notion of negation within such
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2159</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2159</id><created>2013-06-10</created><authors><author><keyname>Kharinov</keyname><forenames>M.</forenames></author></authors><title>Image segmentation by optimal and hierarchical piecewise constant
  approximations</title><categories>cs.CV</categories><comments>4 pages, 5 formulas, 3 figures, 1 table, submitted to the Eleventh
  International Conference on Pattern Recognition and Image Analysis September
  23-28, 2013, Samara, Russia</comments><journal-ref>Proc. of the 11-th. Int. Conf. (PRIA-11-2013), Russia, Samara,
  September 23-28, 2013. Vol. 1, pp. 213-216</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Piecewise constant image approximations of sequential number of segments or
clusters of disconnected pixels are treated. The method of majorizing of
optimal approximation sequence by hierarchical sequence of image approximations
is proposed. A generalization for multidimensional case of color and
multispectral images is foreseen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2160</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2160</id><created>2013-06-10</created><authors><author><keyname>Baraglia</keyname><forenames>Ranieri</forenames></author><author><keyname>Dazzi</keyname><forenames>Patrizio</forenames></author><author><keyname>Mordacchini</keyname><forenames>Matteo</forenames></author><author><keyname>Ricci</keyname><forenames>Laura</forenames></author></authors><title>ATLAAS-P2P: a two layer network solution for easing the resource
  discovery process in unstructured networks</title><categories>cs.NI cs.DC</categories><comments>2 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ATLAAS-P2P is a two-layered P2P architecture for developing systems providing
resource aggregation and approximated discovery in P2P networks. Such systems
allow users to search the desired resources by specifying their requirements in
a flexible and easy way. From the point of view of resource providers, this
system makes available an effective solution supporting providers in being
reached by resource requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2166</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2166</id><created>2013-06-10</created><authors><author><keyname>Knill</keyname><forenames>Oliver</forenames></author></authors><title>The Dirac operator of a graph</title><categories>math.CO cs.DM math.AT</categories><comments>2 figures, 21 pages. These are expanded preparation notes to a talk
  given on June 5, 2013 at the Providence meeting of ILAS</comments><msc-class>05C50, 81Q10, 15A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss some linear algebra related to the Dirac matrix D of a finite
simple graph G=(V,E).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2171</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2171</id><created>2013-06-10</created><authors><author><keyname>Creignou</keyname><forenames>Nadia</forenames></author><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Julian-Steffen</forenames></author><author><keyname>Schmidt</keyname><forenames>Johannes</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>Paradigms for Parameterized Enumeration</title><categories>cs.CC cs.LO</categories><comments>Accepted for MFCS 2013; long version of the paper</comments><msc-class>03D15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the paper is to examine the computational complexity and
algorithmics of enumeration, the task to output all solutions of a given
problem, from the point of view of parameterized complexity. First we define
formally different notions of efficient enumeration in the context of
parameterized complexity. Second we show how different algorithmic paradigms
can be used in order to get parameter-efficient enumeration algorithms in a
number of examples. These paradigms use well-known principles from the design
of parameterized decision as well as enumeration techniques, like for instance
kernelization and self-reducibility. The concept of kernelization, in
particular, leads to a characterization of fixed-parameter tractable
enumeration problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2182</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2182</id><created>2013-06-10</created><updated>2014-05-17</updated><authors><author><keyname>Klav&#xed;k</keyname><forenames>Pavel</forenames></author><author><keyname>Kratochv&#xed;l</keyname><forenames>Jan</forenames></author><author><keyname>Otachi</keyname><forenames>Yota</forenames></author><author><keyname>Saitoh</keyname><forenames>Toshiki</forenames></author><author><keyname>Vysko&#x10d;il</keyname><forenames>Tom&#xe1;&#x161;</forenames></author></authors><title>Extending Partial Representations of Interval Graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interval graphs are intersection graphs of closed intervals of the real-line.
The well-known computational problem, called recognition, asks whether an input
graph $G$ can be represented by closed intervals, i.e., whether $G$ is an
interval graph. There are several linear-time algorithms known for recognizing
interval graphs, the oldest one is by Booth and Lueker [J. Comput. System Sci.,
13 (1976)] based on PQ-trees.
  In this paper, we study a generalization of recognition, called partial
representation extension. The input of this problem consists of a graph $G$
with a partial representation $\cal R'$ fixing the positions of some intervals.
The problem asks whether it is possible to place the remaining interval and
create an interval representation $\cal R$ of the entire graph $G$ extending
$\cal R'$. We generalize the characterization of interval graphs by Fulkerson
and Gross [Pac. J. Math., 15 (1965)] to extendible partial representations.
Using it, we give a linear-time algorithm for partial representation extension
based on a reordering problem of PQ-trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2187</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2187</id><created>2013-06-10</created><authors><author><keyname>Hoffmann</keyname><forenames>Stefan</forenames></author><author><keyname>Wanke</keyname><forenames>Egon</forenames></author></authors><title>Metric Dimension for Gabriel Unit Disk Graphs is NP-Complete</title><categories>cs.CC cs.DS</categories><comments>A brief announcement of this result has been published in the
  proceedings of ALGOSENSORS 2012</comments><msc-class>05C99</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that finding a minimal number of landmark nodes for a unique virtual
addressing by hop-distances in wireless ad-hoc sensor networks is NP-complete
even if the networks are unit disk graphs that contain only Gabriel edges. This
problem is equivalent to Metric Dimension for Gabriel unit disk graphs. The
Gabriel edges of a unit disc graph induce a planar O(\sqrt{n}) distance and an
optimal energy spanner. This is one of the most interesting restrictions of
Metric Dimension in the context of wireless multi-hop networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2217</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2217</id><created>2013-06-10</created><authors><author><keyname>Bonnet</keyname><forenames>Edouard</forenames></author><author><keyname>Escoffier</keyname><forenames>Bruno</forenames></author><author><keyname>Paschos</keyname><forenames>Vangelis Th.</forenames></author><author><keyname>Tourniaire</keyname><forenames>Emeric</forenames></author></authors><title>Multi-parameter complexity analysis for constrained size graph problems:
  using greediness for parameterization</title><categories>cs.CC cs.DS</categories><comments>16 pages, 4 figures</comments><msc-class>68Q25</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the parameterized complexity of a broad class of problems called
&quot;local graph partitioning problems&quot; that includes the classical fixed
cardinality problems as max k-vertex cover, k-densest subgraph, etc. By
developing a technique &quot;greediness-for-parameterization&quot;, we obtain fixed
parameter algorithms with respect to a pair of parameters k, the size of the
solution (but not its value) and \Delta, the maximum degree of the input graph.
In particular, greediness-for-parameterization improves asymptotic running
times for these problems upon random separation (that is a special case of
color coding) and is more intuitive and simple. Then, we show how these results
can be easily extended for getting standard-parameterization results (i.e.,
with parameter the value of the optimal solution) for a well known local graph
partitioning problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2230</identifier>
 <datestamp>2013-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2230</id><created>2013-06-10</created><updated>2013-06-18</updated><authors><author><keyname>Floretta</keyname><forenames>Lucio</forenames></author><author><keyname>Liechti</keyname><forenames>Jonas</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Rios</keyname><forenames>Paolo De Los</forenames></author></authors><title>Stochastic fluctuations and the detectability limit of network
  communities</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.QM</categories><comments>5 pages, 5 figures, correction of typos, improvement of the
  bibliography and of the notation, general compression</comments><journal-ref>Phys. Rev. E 88, 060801 (2013)</journal-ref><doi>10.1103/PhysRevE.88.060801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have analyzed the detectability limits of network communities in the
framework of the popular Girvan and Newman benchmark. By carefully taking into
account the inevitable stochastic fluctuations that affect the construction of
each and every instance of the benchmark, we come to the conclusions that the
native, putative partition of the network is completely lost even before the
in-degree/out-degree ratio becomes equal to the one of a structure-less
Erd\&quot;os-R\'enyi network. We develop a simple iterative scheme, analytically
well described by an infinite branching-process, to provide an estimate of the
true detectability limit. Using various algorithms based on modularity
optimization, we show that all of them behave (semi-quantitatively) in the same
way, with the same functional form of the detectability threshold as a function
of the network parameters. Because the same behavior has also been found by
further modularity-optimization methods and for methods based on different
heuristics implementations, we conclude that indeed a correct definition of the
detectability limit must take into account the stochastic fluctuations of the
network construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2249</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2249</id><created>2013-06-10</created><authors><author><keyname>Cloud</keyname><forenames>Jason</forenames></author><author><keyname>Calmon</keyname><forenames>Flavio du Pin</forenames></author><author><keyname>Zeng</keyname><forenames>Weifei</forenames></author><author><keyname>Pau</keyname><forenames>Giovanni</forenames></author><author><keyname>Zeger</keyname><forenames>Linda</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Multi-Path TCP with Network Coding for Mobile Devices in Heterogeneous
  Networks</title><categories>cs.NI</categories><comments>Accepted to VTC2013-Fall, 5 Pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing mobile devices have the capability to use multiple network
technologies simultaneously to help increase performance; but they rarely, if
at all, effectively use these technologies in parallel. We first present
empirical data to help understand the mobile environment when three
heterogeneous networks are available to the mobile device (i.e., a WiFi
network, WiMax network, and an Iridium satellite network). We then propose a
reliable, multi-path protocol called Multi-Path TCP with Network Coding
(MPTCP/NC) that utilizes each of these networks in parallel. An analytical
model is developed and a mean-field approximation is derived that gives an
estimate of the protocol's achievable throughput. Finally, a comparison between
MPTCP and MPTCP/NC is presented using both the empirical data and mean-field
approximation. Our results show that network coding can provide users in mobile
environments a higher quality of service by enabling the use of multiple
network technologies and the capability to overcome packet losses due to lossy,
wireless network connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2252</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2252</id><created>2013-06-10</created><authors><author><keyname>Salwan</keyname><forenames>Nitish</forenames></author><author><keyname>Singh</keyname><forenames>Sandeep</forenames></author><author><keyname>Arora</keyname><forenames>Suket</forenames></author><author><keyname>Singh</keyname><forenames>Amarpreet</forenames></author></authors><title>An Insight to Covert Channels</title><categories>cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an overview of different concepts regarding covert
channels. It discusses the various classifications and the detailing of various
fields used to manipulate for the covert channel execution.Different evaluation
criterias are presented for measuring the strength of covert channels. The
defenses and prevention schemes for this covert channel will also be discussed.
This paper also discuss about an advanced timing channel i.e.Temperature Based
Covert Channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2254</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2254</id><created>2013-06-10</created><authors><author><keyname>De Luca</keyname><forenames>Alessandro</forenames></author><author><keyname>Fici</keyname><forenames>Gabriele</forenames></author></authors><title>Open and Closed Prefixes of Sturmian Words</title><categories>math.CO cs.DM cs.FL</categories><comments>To appear in WORDS 2013 proceedings</comments><msc-class>68R15</msc-class><journal-ref>Lecture Notes in Computer Science 8079: 132-142 (2013)</journal-ref><doi>10.1007/978-3-642-40579-2_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A word is closed if it contains a proper factor that occurs both as a prefix
and as a suffix but does not have internal occurrences, otherwise it is open.
We deal with the sequence of open and closed prefixes of Sturmian words and
prove that this sequence characterizes every finite or infinite Sturmian word
up to isomorphisms of the alphabet. We then characterize the combinatorial
structure of the sequence of open and closed prefixes of standard Sturmian
words. We prove that every standard Sturmian word, after swapping its first
letter, can be written as an infinite product of squares of reversed standard
words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2257</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2257</id><created>2013-06-10</created><authors><author><keyname>Fister</keyname><forenames>Iztok</forenames></author><author><keyname>Fister</keyname><forenames>Iztok</forenames><suffix>Jr</suffix></author></authors><title>Using the quaternion's representation of individuals in swarm
  intelligence and evolutionary computation</title><categories>cs.NE</categories><comments>Technical Report on Faculty of Electrical Engineering and Computer
  Science, Maribor, Slovenia, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel idea for representation of individuals using
quaternions in swarm intelligence and evolutionary algorithms. Quaternions are
a number system, which extends complex numbers. They are successfully applied
to problems of theoretical physics and to those areas needing fast rotation
calculations. We propose the application of quaternions in optimization, more
precisely, we have been using quaternions for representation of individuals in
Bat algorithm. The preliminary results of our experiments when optimizing a
test-suite consisting of ten standard functions showed that this new algorithm
significantly improved the results of the original Bat algorithm. Moreover, the
obtained results are comparable with other swarm intelligence and evolutionary
algorithms, like the artificial bees colony, and differential evolution. We
believe that this representation could also be successfully applied to other
swarm intelligence and evolutionary algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2258</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2258</id><created>2013-06-10</created><authors><author><keyname>Berlin</keyname><forenames>Konstantin</forenames></author><author><keyname>Gumerov</keyname><forenames>Nail A.</forenames></author><author><keyname>Duraiswami</keyname><forenames>Ramani</forenames></author><author><keyname>Fushman</keyname><forenames>David</forenames></author></authors><title>Performance of a GPU-based Direct Summation Algorithm for Computation of
  Small Angle Scattering Profile</title><categories>q-bio.BM cs.DC physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Small Angle Scattering (SAS) of X-rays or neutrons is an experimental
technique that provides valuable structural information for biological
macromolecules under physiological conditions and with no limitation on the
molecular size. In order to refine molecular structure against experimental SAS
data, ab initio prediction of the scattering profile must be recomputed
hundreds of thousands of times, which involves the computation of the sinc
kernel over all pairs of atoms in a molecule. The quadratic computational
complexity of predicting the SAS profile limits the size of the molecules and
and has been a major impediment for integration of SAS data into structure
refinement protocols. In order to significantly speed up prediction of the SAS
profile we present a general purpose graphical processing unit (GPU) algorithm,
written in OpenCL, for the summation of the sinc kernel (Debye summation) over
all pairs of atoms. This program is an order of magnitude faster than a
parallel CPU algorithm, and faster than an FMM-like approximation method for
certain input domains. We show that our algorithm is currently the fastest
method for performing SAS computation for small and medium size molecules
(around 50000 atoms or less). This algorithm is critical for quick and accurate
SAS profile computation of elongated structures, such as DNA, RNA, and sparsely
spaced pseudo-atom molecules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2260</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2260</id><created>2013-06-10</created><updated>2013-07-08</updated><authors><author><keyname>Vartziotis</keyname><forenames>Dimitris</forenames></author><author><keyname>Himpel</keyname><forenames>Benjamin</forenames></author></authors><title>Efficient and Global Optimization-Based Smoothing Methods for
  Mixed-Volume Meshes</title><categories>cs.CG math.DG math.NA</categories><comments>17 pages, 7 figures; First revision shows that original
  transformation is not very useful, but it provides various potentially useful
  mesh quality measures together with simple geometric element transformations
  optimizing them, with preliminary tests for planar triangular meshes
  confirming the expected behavior</comments><msc-class>65D10, 65N50, 37C10, 53C44</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some methods based on simple regularizing geometric element transformations
have heuristically been shown to give runtime efficient and quality effective
smoothing algorithms for meshes. We describe the mathematical framework and a
systematic approach to global optimization-based versions of such methods for
mixed volume meshes. In particular, we identify efficient smoothing algorithms
for certain algebraic mesh quality measures. We also provide explicit
constructions of potentially useful smoothing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2267</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2267</id><created>2013-06-06</created><authors><author><keyname>Dazzi</keyname><forenames>Patrizio</forenames></author></authors><title>Let's Annotate to Let Our Code Run in Parallel</title><categories>cs.PL cs.DC</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach that exploits Java annotations to provide
meta information needed to automatically transform plain Java programs into
parallel code that can be run on multicore workstation. Programmers just need
to decorate the methods that will eventually be executed in parallel with
standard Java annotations. Annotations are automatically processed at
launch-time and parallel byte code is derived. Once in execution the program
automatically retrieves the information about the executing platform and
evaluates the information specified inside the annotations to transform the
byte-code into a semantically equivalent multithreaded version, depending on
the target architecture features. The results returned by the annotated
methods, when invoked, are futures with a wait-by-necessity semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2268</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2268</id><created>2013-06-07</created><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author><author><keyname>Park</keyname><forenames>Mi-Young</forenames></author></authors><title>Accomplishable Tasks in Knowledge Representation</title><categories>cs.AI cs.CL</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge Representation (KR) is traditionally based on the logic of facts,
expressed in boolean logic. However, facts about an agent can also be seen as a
set of accomplished tasks by the agent. This paper proposes a new approach to
KR: the notion of task logical KR based on Computability Logic. This notion
allows the user to represent both accomplished tasks and accomplishable tasks
by the agent. This notion allows us to build sophisticated KRs about many
interesting agents, which have not been supported by previous logical
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2283</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2283</id><created>2013-06-10</created><authors><author><keyname>Ghilezan</keyname><forenames>Silvia</forenames><affiliation>LIP</affiliation></author><author><keyname>Ivetic</keyname><forenames>Jelena</forenames><affiliation>LIP</affiliation></author><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author><author><keyname>Likavec</keyname><forenames>Silvia</forenames></author></authors><title>A journey through resource control lambda calculi and explicit
  substitution using intersection types (an account)</title><categories>math.LO cs.LO</categories><comments>arXiv admin note: text overlap with arXiv:1112.3455</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we invite the reader to a journey through three lambda calculi
with resource control: the lambda calculus, the sequent lambda calculus, and
the lambda calculus with explicit substitution. All three calculi enable
explicit control of resources due to the presence of weakening and contraction
operators. Along this journey, we propose intersection type assignment systems
for all three resource control calculi. We recognise the need for three kinds
of variables all requiring different kinds of intersection types. Our main
contribution is the characterisation of strong normalisation of reductions in
all three calculi, using the techniques of reducibility, head subject
expansion, a combination of well-orders and suitable embeddings of terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2284</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2284</id><created>2013-06-10</created><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author></authors><title>A simple case of rationality of escalation</title><categories>cs.GT cs.LO</categories><proxy>ccsd</proxy><journal-ref>Dans CALCO 2013 - 5th Conference on Algebra and Coalgebra in
  Computer Science, CALCO 2013, Warsaw : Poland (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Escalation is the fact that in a game (for instance an auction), the agents
play forever. It is not necessary to consider complex examples to establish its
rationality. In particular, the $0,1$-game is an extremely simple infinite game
in which escalation arises naturally and rationally. In some sense, it can be
considered as the paradigm of escalation. Through an example of economic games,
we show the benefit economics can take of coinduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2290</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2290</id><created>2013-06-10</created><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Asymptotically Optimal Sequential Estimation of the Mean Based on
  Inclusion Principle</title><categories>math.ST cs.LG math.PR stat.TH</categories><comments>75 pages, no figures. The main results of this paper appeared in
  Proceeding of SPIE Conferences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large class of problems in sciences and engineering can be formulated as
the general problem of constructing random intervals with pre-specified
coverage probabilities for the mean. Wee propose a general approach for
statistical inference of mean values based on accumulated observational data.
We show that the construction of such random intervals can be accomplished by
comparing the endpoints of random intervals with confidence sequences for the
mean. Asymptotic results are obtained for such sequential methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2291</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2291</id><created>2013-06-10</created><authors><author><keyname>Amato</keyname><forenames>Gianluca</forenames></author><author><keyname>Scozzari</keyname><forenames>Francesca</forenames></author></authors><title>Optimal multi-binding unification for sharing and linearity analysis</title><categories>cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the analysis of logic programs, abstract domains for detecting sharing
properties are widely used. Recently the new domain $\Linp$ has been introduced
to generalize both sharing and linearity information. This domain is endowed
with an optimal abstract operator for single-binding unification. The authors
claim that the repeated application of this operator is also optimal for
multi-binding unification. This is the proof of such a claim.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2295</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2295</id><created>2013-06-10</created><authors><author><keyname>Edera</keyname><forenames>Alejandro</forenames></author><author><keyname>Bromberg</keyname><forenames>Facundo</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Federico</forenames></author></authors><title>Markov random fields factorization with context-specific independences</title><categories>cs.AI cs.LG</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov random fields provide a compact representation of joint probability
distributions by representing its independence properties in an undirected
graph. The well-known Hammersley-Clifford theorem uses these conditional
independences to factorize a Gibbs distribution into a set of factors. However,
an important issue of using a graph to represent independences is that it
cannot encode some types of independence relations, such as the
context-specific independences (CSIs). They are a particular case of
conditional independences that is true only for a certain assignment of its
conditioning set; in contrast to conditional independences that must hold for
all its assignments. This work presents a method for factorizing a Markov
random field according to CSIs present in a distribution, and formally
guarantees that this factorization is correct. This is presented in our main
contribution, the context-specific Hammersley-Clifford theorem, a
generalization to CSIs of the Hammersley-Clifford theorem that applies for
conditional independences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2298</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2298</id><created>2013-06-10</created><updated>2014-02-01</updated><authors><author><keyname>Motallebi</keyname><forenames>Sadegh</forenames></author><author><keyname>Aliakbary</keyname><forenames>Sadegh</forenames></author><author><keyname>Habibi</keyname><forenames>Jafar</forenames></author></authors><title>Generative Model Selection Using a Scalable and Size-Independent Complex
  Network Classifier</title><categories>cs.SI cs.LG physics.soc-ph stat.ML</categories><journal-ref>Chaos 23, 043127 (2013);</journal-ref><doi>10.1063/1.4840235</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real networks exhibit nontrivial topological features such as heavy-tailed
degree distribution, high clustering, and small-worldness. Researchers have
developed several generative models for synthesizing artificial networks that
are structurally similar to real networks. An important research problem is to
identify the generative model that best fits to a target network. In this
paper, we investigate this problem and our goal is to select the model that is
able to generate graphs similar to a given network instance. By the means of
generating synthetic networks with seven outstanding generative models, we have
utilized machine learning methods to develop a decision tree for model
selection. Our proposed method, which is named &quot;Generative Model Selection for
Complex Networks&quot; (GMSCN), outperforms existing methods with respect to
accuracy, scalability and size-independence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2301</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2301</id><created>2013-06-10</created><updated>2013-11-13</updated><authors><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author><author><keyname>Steinwandt</keyname><forenames>Rainer</forenames></author></authors><title>A note on quantum related-key attacks</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>8 pages, 4 figures; added figure of quantum circuit for related-key
  attack against block ciphers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a basic related-key attack against a block cipher, the adversary has
access to encryptions under keys that differ from the target key by bit-flips.
In this short note we show that for a quantum adversary such attacks are quite
powerful: if the secret key is (i) uniquely determined by a small number of
plaintext-ciphertext pairs, (ii) the block cipher can be evaluated efficiently,
and (iii) a superposition of related keys can be queried, then the key can be
extracted efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2305</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2305</id><created>2013-06-10</created><authors><author><keyname>Bouissou</keyname><forenames>Olivier</forenames><affiliation>LMeASI</affiliation></author><author><keyname>Chapoutot</keyname><forenames>Alexandre</forenames><affiliation>U2IS</affiliation></author><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>LMeASI</affiliation></author></authors><title>Computing Flowpipe of Nonlinear Hybrid Systems with Numerical Methods</title><categories>math.OC cs.NA cs.SY math.NA</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern control-command systems often include controllers that perform
nonlinear computations to control a physical system, which can typically be
described by an hybrid automaton containing high-dimensional systems of
nonlinear differential equations. To prove safety of such systems, one must
compute all the reachable sets from a given initial position, which might be
uncertain (its value is not precisely known). On linear hybrid systems,
efficient and precise techniques exist, but they fail to handle nonlinear flows
or jump conditions. In this article, we present a new tool name HySon which
computes the flowpipes of both linear and nonlinear hybrid systems using
guaranteed generalization of classical efficient numerical simulation methods,
including with variable integration step-size. In particular, we present an
algorithm for detecting discrete events based on guaranteed interpolation
polynomials that turns out to be both precise and efficient. Illustrations of
the techniques developed in this article are given on representative examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2347</identifier>
 <datestamp>2015-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2347</id><created>2013-06-10</created><updated>2015-07-12</updated><authors><author><keyname>Sabato</keyname><forenames>Sivan</forenames></author><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author></authors><title>Auditing: Active Learning with Outcome-Dependent Query Costs</title><categories>cs.LG</categories><comments>Corrections in section 5</comments><journal-ref>Neural Information Processing Systems 26 (NIPS), 512-520, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a learning setting in which unlabeled data is free, and the cost
of a label depends on its value, which is not known in advance. We study binary
classification in an extreme case, where the algorithm only pays for negative
labels. Our motivation are applications such as fraud detection, in which
investigating an honest transaction should be avoided if possible. We term the
setting auditing, and consider the auditing complexity of an algorithm: the
number of negative labels the algorithm requires in order to learn a hypothesis
with low relative error. We design auditing algorithms for simple hypothesis
classes (thresholds and rectangles), and show that with these algorithms, the
auditing complexity can be significantly lower than the active label
complexity. We also discuss a general competitive approach for auditing and
possible modifications to the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2356</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2356</id><created>2013-06-10</created><updated>2015-01-02</updated><authors><author><keyname>Pejovic</keyname><forenames>Veljko</forenames></author><author><keyname>Musolesi</keyname><forenames>Mirco</forenames></author></authors><title>Anticipatory Mobile Computing: A Survey of the State of the Art and
  Research Challenges</title><categories>cs.HC cs.NI</categories><comments>29 pages, 5 figures</comments><report-no>School of Computer Science University of Birmingham Technical Report
  CSR-13-02</report-no><journal-ref>ACM Computing Surveys (CSUR). Volume 47 Issue 3, April 2015. ACM
  Press</journal-ref><doi>10.1145/2693843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's mobile phones are far from mere communication devices they were ten
years ago. Equipped with sophisticated sensors and advanced computing hardware,
phones can be used to infer users' location, activity, social setting and more.
As devices become increasingly intelligent, their capabilities evolve beyond
inferring context to predicting it, and then reasoning and acting upon the
predicted context. This article provides an overview of the current state of
the art in mobile sensing and context prediction paving the way for
full-fledged anticipatory mobile computing. We present a survey of phenomena
that mobile phones can infer and predict, and offer a description of machine
learning techniques used for such predictions. We then discuss proactive
decision making and decision delivery via the user-device feedback loop.
Finally, we discuss the challenges and opportunities of anticipatory mobile
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2360</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2360</id><created>2013-06-10</created><authors><author><keyname>Hou</keyname><forenames>I-Hong</forenames></author><author><keyname>Singh</keyname><forenames>Rahul</forenames></author></authors><title>Capacity and Scheduling of Access Points for Multiple Live Video Streams</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of serving multiple live video streams to
several different clients from a single access point over unreliable wireless
links, which is expected to be major a consumer of future wireless capacity.
This problem involves two characteristics. On the streaming side, different
video streams may generate variable-bit-rate traffic with different traffic
patterns. On the network side, the wireless transmissions are unreliable, and
the link qualities differ from client to client. In order to alleviate the
above stochastic aspects of both video streams and link unreliability, each
client typically buffers incoming packets before playing the video. The quality
of the video playback subscribed to by each flow depends, among other factors,
on both the delay of packets as well as their throughput.
  In this paper we characterize precisely the capacity of the wireless video
server in terms of what combination of joint per-packet-delays and throughputs
can be supported for the set of flows, as a function of the buffering delay
introduced at the server.
  We also address how to schedule packets at the access point to satisfy the
joint per-packet-delay-throughput performance measure. We test the designed
policy on the traces of three movies. From our tests, it appears to outperform
other policies by a large margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2361</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2361</id><created>2013-06-10</created><authors><author><keyname>Clarke</keyname><forenames>P.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Joint Transmit Diversity Optimization and Relay Selection for
  Cooperative MIMO Systems using Discrete Stochastic Algorithms</title><categories>cs.IT math.IT</categories><comments>3 figures, IEEE Communications Letters, 2012. arXiv admin note: text
  overlap with arXiv:1301.5912</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a joint discrete stochastic optimization based transmit diversity
selection (TDS) and relay selection (RS) algorithm for decode-and-forward (DF),
cooperative MIMO systems with a non-negligible direct path. TDS and RS are
performed jointly with continuous least squares channel estimation (CE), linear
minimum mean square error (MMSE) receivers are used at all nodes and no
inter-relay communication is required. The performance of the proposed scheme
is evaluated via bit-error rate (BER) comparisons and diversity analysis, and
is shown to converge to the optimum exhaustive solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2362</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2362</id><created>2013-06-10</created><authors><author><keyname>Clarke</keyname><forenames>Patrick</forenames></author><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Bidirectional MMSE Algorithms for Interference Mitigation in CDMA
  Systems over Fast Fading Channels</title><categories>cs.IT math.IT</categories><comments>3 figures, ISWCS, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents adaptive bidirectional minimum mean-square error (MMSE)
parameter estimation algorithms for fast-fading channels. The time correlation
between successive channel gains is exploited to improve the estimation and
tracking capabilities of adaptive algorithms and provide robustness against
time-varying channels. Bidirectional normalized least mean-square (NLMS) and
conjugate gradient (CG) algorithms are devised along with adaptive mixing
parameters that adjust to the time-varying channel correlation properties. An
analysis of the proposed algorithms is provided along with a discussion of
their performance advantages. Simulations for an application to interference
suppression in DS-CDMA systems show the advantages of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2399</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2399</id><created>2013-06-10</created><authors><author><keyname>Lee</keyname><forenames>Junghoon</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author></authors><title>Distributed Detection in Coexisting Large-scale Sensor Networks</title><categories>cs.IT math.IT</categories><comments>20 pages, 5 figures, submitted to IEEE Sensors J</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers signal detection in coexisting wireless sensor networks
(WSNs). We characterize the aggregate signal and interference from a Poisson
random field of nodes and define a binary hypothesis testing problem to detect
a signal in the presence of interference. For the testing problem, we introduce
the maximum likelihood (ML) detector and simpler alternatives. The proposed
mixed-fractional lower order moment (FLOM) detector is computationally simple
and close to the ML performance, and robust to estimation errors in system
parameters. We also derived asymptotic theoretical performances for the
proposed simple detectors. Monte-Carlo simulations are used to supplement our
analytical results and compare the performance of the receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2401</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2401</id><created>2013-06-10</created><updated>2014-08-07</updated><authors><author><keyname>Xu</keyname><forenames>Zhongyuan</forenames></author><author><keyname>Stoller</keyname><forenames>Scott D.</forenames></author></authors><title>Mining Attribute-based Access Control Policies</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attribute-based access control (ABAC) provides a high level of flexibility
that promotes security and information sharing. ABAC policy mining algorithms
have potential to significantly reduce the cost of migration to ABAC, by
partially automating the development of an ABAC policy from an access control
list (ACL) policy or role-based access control (RBAC) policy with accompanying
attribute data. This paper presents an ABAC policy mining algorithm. To the
best of our knowledge, it is the first ABAC policy mining algorithm. Our
algorithm iterates over tuples in the given user-permission relation, uses
selected tuples as seeds for constructing candidate rules, and attempts to
generalize each candidate rule to cover additional tuples in the
user-permission relation by replacing conjuncts in attribute expressions with
constraints. Our algorithm attempts to improve the policy by merging and
simplifying candidate rules, and then it selects the highest-quality candidate
rules for inclusion in the generated policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2404</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2404</id><created>2013-06-10</created><authors><author><keyname>Huang</keyname><forenames>Weidong</forenames></author></authors><title>An Aggregation-Based Overall Quality Measurement for Visualization</title><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Aesthetics are often used to evaluate the quality of graph drawings. However,
the existing aesthetic criteria are useful in judging the extents to which a
drawing conforms to particular drawing rules. They have limitations in
evaluating overall quality. Currently the overall quality of graph drawings is
mainly evaluated based on personal judgments and user studies. Personal
judgments are not reliable, while user studies can be costly to run. Therefore,
there is a need for a direct measure of overall quality. This measure can be
used by visualization designers to quickly compare the quality of drawings at
hand at the design stage and make decisions accordingly. In an attempt to meet
this need, we propose a measure that measures overall quality based on
aggregation of individual aesthetic criteria. We present a user study that
validates this measure and demonstrates its capacity in predicting the
performance of human graph comprehension. The implications of the proposed
measure for future research are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2405</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2405</id><created>2013-06-10</created><authors><author><keyname>Oury</keyname><forenames>Nicolas</forenames><affiliation>School of Informatics, Edinburgh University, Edinburgh, Scotland</affiliation></author><author><keyname>Pedersen</keyname><forenames>Michael</forenames><affiliation>Department of Plant Sciences, Cambridge University, Cambridge, UK</affiliation></author><author><keyname>Petersen</keyname><forenames>Rasmus</forenames><affiliation>Microsoft Research, Cambridge, UK</affiliation></author></authors><title>Canonical Labelling of Site Graphs</title><categories>cs.DM math.CO</categories><comments>In Proceedings CompMod 2013, arXiv:1306.2019</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 116, 2013, pp. 13-28</journal-ref><doi>10.4204/EPTCS.116.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate algorithms for canonical labelling of site graphs, i.e. graphs
in which edges bind vertices on sites with locally unique names. We first show
that the problem of canonical labelling of site graphs reduces to the problem
of canonical labelling of graphs with edge colourings. We then present two
canonical labelling algorithms based on edge enumeration, and a third based on
an extension of Hopcroft's partition refinement algorithm. All run in quadratic
worst case time individually. However, one of the edge enumeration algorithms
runs in sub-quadratic time for graphs with &quot;many&quot; automorphisms, and the
partition refinement algorithm runs in sub-quadratic time for graphs with &quot;few&quot;
bisimulation equivalences. This suite of algorithms was chosen based on the
expectation that graphs fall in one of those two categories. If that is the
case, a combined algorithm runs in sub-quadratic worst case time. Whether this
expectation is reasonable remains an interesting open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2413</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2413</id><created>2013-06-10</created><updated>2013-08-14</updated><authors><author><keyname>Bortolussi</keyname><forenames>Luca</forenames><affiliation>University of Trieste, Italy</affiliation></author><author><keyname>Wiklicky</keyname><forenames>Herbert</forenames><affiliation>Imperial College, London, UK</affiliation></author></authors><title>Proceedings 11th International Workshop on Quantitative Aspects of
  Programming Languages and Systems</title><categories>cs.LO cs.PF</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 117, 2013</journal-ref><doi>10.4204/EPTCS.117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative aspects of computation are important and sometimes essential in
characterising the behavior and determining the properties of systems. They are
related to the use of physical quantities (storage space, time, bandwidth,
etc.) as well as mathematical quantities (e.g. probability and measures for
reliability, security and trust). Such quantities play a central role in
defining both the model of systems (architecture, language design, semantics)
and the methodologies and tools for the analysis and verification of system
properties. The aim of this workshop is to discuss the explicit use of
quantitative information such as time and probabilities either directly in the
model or as a tool for the analysis of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2414</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2414</id><created>2013-06-10</created><authors><author><keyname>Santos</keyname><forenames>Paulo Sergio Medeiros dos</forenames></author><author><keyname>Travassos</keyname><forenames>Guilherme Horta</forenames></author></authors><title>Action Research Can Swing the Balance in Experimental Software
  Engineering</title><categories>cs.SE</categories><comments>77 pages, Advances in Computers (2011)</comments><doi>10.1016/B978-0-12-385510-7.00005-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general, professionals still ignore scientific evidence in place of expert
opinions in most of their decision-making. For this reason, it is still common
to see the adoption of new software technologies in the field without any
scientific basis or well-grounded criteria, but on the opinions of experts.
Experimental Software Engineering is of paramount importance to provide the
foundations to understand the limits and applicability of software
technologies. The need to better observe and understand the practice of
Software Engineering leads us to look for alternative experimental approaches
to support our studies. Different research strategies can be used to explore
different Software Engineering practices. Action Research can be seen as one
alternative to intensify the conducting of important experimental studies with
results of great value while investigating the Software Engineering practices
in depth. In this paper, a discussion on the use of Action Research in Software
Engineering is presented. Aiming at better explaining the application of Action
Research, an experimental study (in vivo) on the investigation of the
subjective decisions of software developers, concerned with the refactoring of
source code to improve source code quality in a distributed software
development context is depicted. In addition, some guidance on how to
accomplish an Action Research study in Software Engineering supplement the
discussions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2422</identifier>
 <datestamp>2014-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2422</id><created>2013-06-11</created><updated>2014-03-21</updated><authors><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Zhang</keyname><forenames>Renyuan</forenames></author><author><keyname>Wonham</keyname><forenames>W. Murray</forenames></author></authors><title>Relative Observability of Discrete-Event Systems and its Supremal
  Sublanguages</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify a new observability concept, called relative observability, in
supervisory control of discrete-event systems under partial observation. A
fixed, ambient language is given, relative to which observability is tested.
Relative observability is stronger than observability, but enjoys the important
property that it is preserved under set union; hence there exists the supremal
relatively observable sublanguage of a given language. Relative observability
is weaker than normality, and thus yields, when combined with controllability,
a generally larger controlled behavior; in particular, no constraint is imposed
that only observable controllable events may be disabled. We design algorithms
which compute the supremal relatively observable (and controllable) sublanguage
of a given language, which is generally larger than the normal counterparts. We
demonstrate the new observability concept and algorithms with a Guideway and an
AGV example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2425</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2425</id><created>2013-06-11</created><authors><author><keyname>Pathak</keyname><forenames>Shantanu</forenames></author><author><keyname>S</keyname><forenames>Ranjani</forenames></author></authors><title>Ber Performance Analysis of WiMAX PHY Layer under different channel
  conditions</title><categories>cs.NI cs.PF</categories><comments>19 pages, 12 figures</comments><journal-ref>International Journal of Information Sciences and Techniques
  (IJIST) Vol.3, No.3, May 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives an introduction on the IEEE 802.16 standard WIMAX or
Worldwide Interoperability for Microwave Access. The different parts give
details on the architectural specifications of WiMAX networks and also on the
working principle of WiMAX networks including its services provided. It also
provides brief descriptions on its salient features of this technology and how
it benefits the networking industry. A brief outline of the basic building
blocks or equipment of WiMAX architecture is also provided. This paper also
evaluates the simulation performance of IEEE 802.16 OFDM PHY layer. The
Stanford University Interim (SUI) channel model under varying parameters is
selected for the wireless channel in the simulation. The performance
measurements and analysis was done in simulation developed in MATLAB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2434</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2434</id><created>2013-06-11</created><authors><author><keyname>Fyhn</keyname><forenames>Karsten</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Jensen</keyname><forenames>S&#xf8;ren Holdt</forenames></author></authors><title>Compressive Time Delay Estimation Using Interpolation</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, technical report supporting 1 page submission for
  GlobalSIP 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time delay estimation has long been an active area of research. In this work,
we show that compressive sensing with interpolation may be used to achieve good
estimation precision while lowering the sampling frequency. We propose an
Interpolating Band-Excluded Orthogonal Matching Pursuit algorithm that uses one
of two interpolation functions to estimate the time delay parameter. The
numerical results show that interpolation improves estimation precision and
that compressive sensing provides an elegant tradeoff that may lower the
required sampling frequency while still attaining a desired estimation
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2437</identifier>
 <datestamp>2013-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2437</id><created>2013-06-11</created><updated>2013-07-11</updated><authors><author><keyname>Babichenko</keyname><forenames>Yakov</forenames></author><author><keyname>Barman</keyname><forenames>Siddharth</forenames></author></authors><title>Query Complexity of Correlated Equilibrium</title><categories>cs.GT</categories><comments>Added references</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study lower bounds on the query complexity of determining correlated
equilibrium. In particular, we consider a query model in which an n-player game
is specified via a black box that returns players' utilities at pure action
profiles. In this model we establish that in order to compute a correlated
equilibrium any deterministic algorithm must query the black box an exponential
(in n) number of times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2453</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2453</id><created>2013-06-11</created><authors><author><keyname>Saha</keyname><forenames>Dibakar</forenames></author><author><keyname>Das</keyname><forenames>Nabanita</forenames></author></authors><title>A Fast Fault Tolerant Partitioning Algorithm for Wireless Sensor
  Networks</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, given a random uniform distribution of sensor nodes on a 2-D
plane, a fast self-organized distributed algorithm is proposed to find the
maximum number of partitions of the nodes such that each partition is connected
and covers the area to be monitored. Each connected partition remains active in
a round robin fashion to cover the query region individually. In case of a node
failure, the proposed distributed fault recovery algorithm reconstructs the
affected partition locally utilizing the available free nodes. Simulation
studies show significant improvement in performance compared to the earlier
works in terms of computation time, the diameter of each partition, message
overhead and network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2459</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2459</id><created>2013-06-11</created><authors><author><keyname>Choudhury</keyname><forenames>Sutanay</forenames></author><author><keyname>Holder</keyname><forenames>Lawrence</forenames></author><author><keyname>Chin</keyname><forenames>George</forenames></author><author><keyname>Feo</keyname><forenames>John</forenames></author></authors><title>Fast Search for Dynamic Multi-Relational Graphs</title><categories>cs.DB</categories><comments>SIGMOD Workshop on Dynamic Networks Management and Mining (DyNetMM),
  2013</comments><acm-class>H.2.4</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Acting on time-critical events by processing ever growing social media or
news streams is a major technical challenge. Many of these data sources can be
modeled as multi-relational graphs. Continuous queries or techniques to search
for rare events that typically arise in monitoring applications have been
studied extensively for relational databases. This work is dedicated to answer
the question that emerges naturally: how can we efficiently execute a
continuous query on a dynamic graph? This paper presents an exact subgraph
search algorithm that exploits the temporal characteristics of representative
queries for online news or social media monitoring. The algorithm is based on a
novel data structure called the Subgraph Join Tree (SJ-Tree) that leverages the
structural and semantic characteristics of the underlying multi-relational
graph. The paper concludes with extensive experimentation on several real-world
datasets that demonstrates the validity of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2460</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2460</id><created>2013-06-11</created><authors><author><keyname>Choudhury</keyname><forenames>Sutanay</forenames></author><author><keyname>Holder</keyname><forenames>Lawrence</forenames></author><author><keyname>Chin</keyname><forenames>George</forenames></author><author><keyname>Ray</keyname><forenames>Abhik</forenames></author><author><keyname>Beus</keyname><forenames>Sherman</forenames></author><author><keyname>Feo</keyname><forenames>John</forenames></author></authors><title>StreamWorks - A system for Dynamic Graph Search</title><categories>cs.DB</categories><comments>SIGMOD 2013: International Conference on Management of Data</comments><acm-class>H.2.4</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Acting on time-critical events by processing ever growing social media, news
or cyber data streams is a major technical challenge. Many of these data
sources can be modeled as multi-relational graphs. Mining and searching for
subgraph patterns in a continuous setting requires an efficient approach to
incremental graph search. The goal of our work is to enable real-time search
capabilities for graph databases. This demonstration will present a dynamic
graph query system that leverages the structural and semantic characteristics
of the underlying multi-relational graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2465</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2465</id><created>2013-06-11</created><updated>2014-02-10</updated><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author><author><keyname>Reichman</keyname><forenames>Daniel</forenames></author></authors><title>Contagious Sets in Expanders</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following activation process in undirected graphs: a vertex
is active either if it belongs to a set of initially activated vertices or if
at some point it has at least $r$ active neighbors, where $r&gt;1$ is the
activation threshold.
  A \emph{contagious set} is a set whose activation results with the entire
graph being active. Given a graph $G$, let $m(G,r)$ be the minimal size of a
contagious set. Computing $m(G,r)$ is NP-hard.
  It is known that for every $d$-regular or nearly $d$-regular graph on $n$
vertices, $m(G,r) \le O(\frac{nr}{d})$. We consider such graphs that
additionally have expansion properties, parameterized by the spectral gap
and/or the girth of the graphs.
  The general flavor of our results is that sufficiently strong expansion
(e.g., $\lambda(G)=O(\sqrt{d})$, or girth $\Omega(\log \log d)$) implies that
$m(G,2) \le O(\frac{n}{d^2})$ (and more generally, $m(G,r) \le
O(\frac{n}{d^{r/(r-1)}})$). Significantly weaker expansion properties suffice
in order to imply that $m(G,2)\le O(\frac{n \log d}{d^2})$. For example, we
show this for graphs of girth at least~7, and for graphs with
$\lambda(G)&lt;(1-\epsilon)d$, provided the graph has no 4-cycles. Nearly
$d$-regular expander graphs can be obtained by considering the binomial random
graph $G(n,p)$ with $p \simeq \frac{d}{n}$ and $d &gt; \log n$. For such graphs we
prove that $\Omega(\frac{n}{d^2 \log d}) \le m(G,2) \le O(\frac{n\log\log
d}{d^2\log d})$ almost surely.
  Our results are algorithmic, entailing simple and efficient algorithms for
selecting contagious sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2476</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2476</id><created>2013-06-11</created><authors><author><keyname>Nguyen</keyname><forenames>Viet Hung</forenames></author><author><keyname>Massacci</keyname><forenames>Fabio</forenames></author></authors><title>A Systematically Empirical Evaluation of Vulnerability Discovery Models:
  a Study on Browsers' Vulnerabilities</title><categories>cs.CR</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A precise vulnerability discovery model (VDM) will provide a useful insight
to assess software security, and could be a good prediction instrument for both
software vendors and users to understand security trends and plan ahead
patching schedule accordingly. Thus far, several models have been proposed and
validated. Yet, no systematically independent validation by somebody other than
the author exists. Furthermore, there are a number of issues that might bias
previous studies in the field. In this work, we fill in the gap by introducing
an empirical methodology that systematically evaluates the performance of a VDM
in two aspects: quality and predictability. We further apply this methodology
to assess existing VDMs. The results show that some models should be rejected
outright, while some others might be adequate to capture the discovery process
of vulnerabilities. We also consider different usage scenarios of VDMs and find
that the simplest linear model is the most appropriate choice in terms of both
quality and predictability when browsers are young. Otherwise, logistics-based
models are better choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2477</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2477</id><created>2013-06-11</created><authors><author><keyname>Grispos</keyname><forenames>George</forenames></author><author><keyname>Glisson</keyname><forenames>William Bradley</forenames></author><author><keyname>Storer</keyname><forenames>Tim</forenames></author></authors><title>Cloud Security Challenges: Investigating Policies, Standards, and
  Guidelines in a Fortune 500 Organization</title><categories>cs.CR cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is quickly becoming pervasive in today's globally integrated
networks. The cloud offers organizations opportunities to potentially deploy
software and data solutions that are accessible through numerous mechanisms, in
a multitude of settings, at a reduced cost with increased reliability and
scalability. The increasingly pervasive and ubiquitous nature of the cloud
creates an environment that is potentially conducive to security risks. While
previous discussions have focused on security and privacy issues in the cloud
from the end-users perspective, minimal empirical research has been conducted
from the perspective of a corporate environment case study. This paper presents
the results of an initial case study identifying real-world information
security documentation issues for a Global Fortune 500 organization, should the
organization decide to implement cloud computing services in the future. The
paper demonstrates the importance of auditing policies, standards and
guidelines applicable to cloud computing environments along with highlighting
potential corporate concerns. The results from this case study has revealed
that from the 1123 'relevant' statements found in the organization's security
documentation, 175 statements were considered to be 'inadequate' for cloud
computing. Furthermore, the paper provides a foundation for future analysis and
research regarding implementation concerns for corporate cloud computing
applications and services
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2483</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2483</id><created>2013-06-11</created><updated>2014-07-07</updated><authors><author><keyname>Giaquinta</keyname><forenames>Emanuele</forenames></author><author><keyname>Fredriksson</keyname><forenames>Kimmo</forenames></author><author><keyname>Grabowski</keyname><forenames>Szymon</forenames></author><author><keyname>Tomescu</keyname><forenames>Alexandru I.</forenames></author><author><keyname>Ukkonen</keyname><forenames>Esko</forenames></author></authors><title>Motif matching using gapped patterns</title><categories>cs.DS</categories><doi>10.1016/j.tcs.2014.06.032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new algorithms for the problem of multiple string matching of
gapped patterns, where a gapped pattern is a sequence of strings such that
there is a gap of fixed length between each two consecutive strings. The
problem has applications in the discovery of transcription factor binding sites
in DNA sequences when using generalized versions of the Position Weight Matrix
model to describe transcription factor specificities. In these models a motif
can be matched as a set of gapped patterns with unit-length keywords. The
existing algorithms for matching a set of gapped patterns are worst-case
efficient but not practical, or vice versa, in this particular case. The novel
algorithms that we present are based on dynamic programming and
bit-parallelism, and lie in a middle-ground among the existing algorithms. In
fact, their time complexity is close to the best existing bound and, yet, they
are also practical. We also provide experimental results which show that the
presented algorithms are fast in practice, and preferable if all the strings in
the patterns have unit-length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2484</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2484</id><created>2013-06-11</created><updated>2013-12-04</updated><authors><author><keyname>Sule</keyname><forenames>Virendra</forenames></author></authors><title>Generalization of Boole-Shannon expansion, consistency of Boolean
  equations and elimination by orthonormal expansion</title><categories>cs.CC</categories><comments>16 pages, revised December 5, 2013</comments><msc-class>03G05, 06E30, 94C10</msc-class><acm-class>I.1.2; F.2.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well known Boole-Shannon expansion of Boolean functions in several
variables (with co-efficients in a Boolean algebra $B$) is also known in more
general form in terms of expansion in a set $\Phi$ of orthonormal functions.
However, unlike the one variable step of this expansion an analogous
elimination theorem and consistency is not well known. This article proves such
an elimination theorem for a special class of Boolean functions denoted
$B(\Phi)$. When the orthonormal set $\Phi$ is of polynomial size in number $n$
of variables, the consistency of a Boolean equation $f=0$ can be determined in
polynomial number of $B$-operations. A characterization of $B(\Phi)$ is also
shown and an elimination based procedure for computing consistency of Boolean
equations is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2487</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2487</id><created>2013-06-11</created><authors><author><keyname>Kulakowski</keyname><forenames>Krzysztof</forenames></author><author><keyname>Gronek</keyname><forenames>Piotr</forenames></author><author><keyname>Dydejczyk</keyname><forenames>Antoni</forenames></author></authors><title>How many parameters to model states of mind ?</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, no figures; Proceedings 27th European Conference on
  Modelling and Simulation ECMS Webjorn Rekdalsbakken, Robin T. Bye, Houxiang
  Zhang (Editors), 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A series of examples of computational models is provided, where the model aim
is to interpret numerical results in terms of internal states of agents minds.
Two opposite strategies or research can be distinguished in the literature.
First is to reproduce the richness and complexity of real world as faithfully
as possible, second is to apply simple assumptions and check the results in
depth. As a rule, the results of the latter method agree only qualitatively
with some stylized facts. The price we pay for more detailed predictions within
the former method is that consequences of the rich set of underlying
assumptions remain unchecked. Here we argue that for computational reasons,
complex models with many parameters are less suitable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2491</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2491</id><created>2013-06-11</created><updated>2014-03-25</updated><authors><author><keyname>Summers</keyname><forenames>Tyler H.</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>Optimal Sensor and Actuator Placement in Complex Dynamical Networks</title><categories>math.OC cs.SY</categories><comments>6 pages, 3 figures; to appear at the 2014 IFAC World Congress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controllability and observability have long been recognized as fundamental
structural properties of dynamical systems, but have recently seen renewed
interest in the context of large, complex networks of dynamical systems. A
basic problem is sensor and actuator placement: choose a subset from a finite
set of possible placements to optimize some real-valued controllability and
observability metrics of the network. Surprisingly little is known about the
structure of such combinatorial optimization problems. In this paper, we show
that an important class of metrics based on the controllability and
observability Gramians has a strong structural property that allows efficient
global optimization: the mapping from possible placements to the trace of the
associated Gramian is a modular set function. We illustrate the results via
placement of power electronic actuators in a model of the European power grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2498</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2498</id><created>2013-06-11</created><updated>2013-06-18</updated><authors><author><keyname>Ba&#xef;ou</keyname><forenames>Mourad</forenames></author><author><keyname>Beaudou</keyname><forenames>Laurent</forenames></author><author><keyname>Li</keyname><forenames>Zhentao</forenames></author><author><keyname>Limouzy</keyname><forenames>Vincent</forenames></author></authors><title>On a class of intersection graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed graph D = (V,A) we define its intersection graph I(D) =
(A,E) to be the graph having A as a node-set and two nodes of I(D) are adjacent
if their corresponding arcs share a common node that is the tail of at least
one of these arcs. We call these graphs facility location graphs since they
arise from the classical uncapacitated facility location problem. In this paper
we show that facility location graphs are hard to recognize and they are easy
to recognize when the graph is triangle-free. We also determine the complexity
of the vertex coloring, the stable set and the facility location problems on
that class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2499</identifier>
 <datestamp>2013-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2499</id><created>2013-06-11</created><updated>2013-06-19</updated><authors><author><keyname>Abderrahim</keyname><forenames>Mohammed Alaeddine</forenames></author><author><keyname>Abderrahim</keyname><forenames>Mohammed El Amine</forenames></author><author><keyname>Chikh</keyname><forenames>Mohammed Amine</forenames></author></authors><title>Using Arabic Wordnet for semantic indexation in information retrieval
  system</title><categories>cs.IR cs.CL</categories><comments>6 pages,2 figures,7 tables</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 1, No 2, January 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of arabic Information Retrieval Systems (IRS) guided by arabic
ontology and to enable those systems to better respond to user requirements,
this paper aims to representing documents and queries by the best concepts
extracted from Arabic Wordnet. Identified concepts belonging to Arabic WordNet
synsets are extracted from documents and queries, and those having a single
sense are expanded. The expanded query is then used by the IRS to retrieve the
relevant documents searched. Our experiments are based primarily on a medium
size corpus of arabic text. The results obtained shown us that there are a
global improvement in the performance of the arabic IRS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2502</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2502</id><created>2013-06-11</created><authors><author><keyname>Singh</keyname><forenames>Sukhpal</forenames></author><author><keyname>Singh</keyname><forenames>Harinder</forenames></author></authors><title>Case Study Based Software Engineering Project Development: State of Art</title><categories>cs.SE</categories><comments>15 Pages including 17 figures, 12 tables, Published by IJSRCSAMS</comments><report-no>ijsrcsamsv2i3p31</report-no><msc-class>68N30</msc-class><acm-class>D.2.13</acm-class><journal-ref>International Journal of Scientific Research in Computer Science
  Applications and Management Studies, Volume 2, Issue 3, May 2013</journal-ref><doi>10.5120/7834-1132</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This research paper designates the importance and usage of the case study
approach effectively to educating and training software designers and software
engineers both in academic and industry. Subsequently an account of the use of
case studies based on software engineering in the education of professionals,
there is a conversation of issues in training software designers and how a case
teaching method can be used to state these issues. The paper describes a
software project titled Online Tower Plotting System (OTPS) to develop a
complete and comprehensive case study, along with supporting educational
material. The case study is aimed to demonstrate a variety of software areas,
modules and courses: from bachelor through masters, doctorates and even for
ongoing professional development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2533</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2533</id><created>2013-06-11</created><updated>2013-06-26</updated><authors><author><keyname>Vepakomma</keyname><forenames>Praneeth</forenames></author><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author></authors><title>DISCOMAX: A Proximity-Preserving Distance Correlation Maximization
  Algorithm</title><categories>cs.LG stat.ML</categories><comments>14 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a regression setting we propose algorithms that reduce the dimensionality
of the features while simultaneously maximizing a statistical measure of
dependence known as distance correlation between the low-dimensional features
and a response variable. This helps in solving the prediction problem with a
low-dimensional set of features. Our setting is different from subset-selection
algorithms where the problem is to choose the best subset of features for
regression. Instead, we attempt to generate a new set of low-dimensional
features as in a feature-learning setting. We attempt to keep our proposed
approach as model-free and our algorithm does not assume the application of any
specific regression model in conjunction with the low-dimensional features that
it learns. The algorithm is iterative and is fomulated as a combination of the
majorization-minimization and concave-convex optimization procedures. We also
present spectral radius based convergence results for the proposed iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2537</identifier>
 <datestamp>2013-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2537</id><created>2013-06-11</created><updated>2013-06-19</updated><authors><author><keyname>Miranda</keyname><forenames>Pedro J.</forenames></author><author><keyname>Baptista</keyname><forenames>Murilo S.</forenames></author><author><keyname>Pinto</keyname><forenames>Sandro E. de S.</forenames></author></authors><title>Analysis of communities in a mythological social network</title><categories>physics.soc-ph cs.SI nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intriguing nature of classical Homeric narratives has always fascinated
the occidental culture contributing to philosophy, history, mythology and
straight forwardly to literature. However what would be so intriguing about
Homer's narratives' At a first gaze we shall recognize the very literal appeal
and aesthetic pleasure presented on every page across Homer's chants in Odyssey
and rhapsodies in Iliad. Secondly we may perceive a biased aspect of its
stories contents, varying from real-historical to fictional-mythological. To
encompass this glance, there are some new archeological finding that supports
historicity of some events described within Iliad, and consequently to Odyssey.
Considering these observations and using complex network theory concepts, we
managed to built and analyze a social network gathered across the classical
epic, Odyssey of Homer. Longing for further understanding, topological
quantities were collected in order to classify its social network qualitatively
into real or fictional. It turns out that most of the found properties belong
to real social networks besides assortativity and giant component's size. In
order to test the network's possibilities to be real, we removed some
mythological members that could imprint a fictional aspect on the network.
Carrying on this maneuver the modified social network resulted on assortative
mixing and reduction of the giant component, as expected for real social
networks. Overall we observe that Odyssey might be an amalgam of fictional
elements plus real based human relations, which corroborates other author's
findings for Iliad and archeological evidences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2547</identifier>
 <datestamp>2014-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2547</id><created>2013-06-11</created><updated>2014-07-10</updated><authors><author><keyname>Gottlieb</keyname><forenames>Lee-Ad</forenames></author><author><keyname>Kontorovich</keyname><forenames>Aryeh</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author></authors><title>Efficient Classification for Metric Data</title><categories>cs.LG cs.DS stat.ML</categories><comments>This is the full version of an extended abstract that appeared in
  Proceedings of the 23rd COLT, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in large-margin classification of data residing in general
metric spaces (rather than Hilbert spaces) enable classification under various
natural metrics, such as string edit and earthmover distance. A general
framework developed for this purpose by von Luxburg and Bousquet [JMLR, 2004]
left open the questions of computational efficiency and of providing direct
bounds on generalization error.
  We design a new algorithm for classification in general metric spaces, whose
runtime and accuracy depend on the doubling dimension of the data points, and
can thus achieve superior classification performance in many common scenarios.
The algorithmic core of our approach is an approximate (rather than exact)
solution to the classical problems of Lipschitz extension and of Nearest
Neighbor Search. The algorithm's generalization performance is guaranteed via
the fat-shattering dimension of Lipschitz classifiers, and we present
experimental evidence of its superiority to some common kernel methods. As a
by-product, we offer a new perspective on the nearest neighbor classifier,
which yields significantly sharper risk asymptotics than the classic analysis
of Cover and Hart [IEEE Trans. Info. Theory, 1967].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2548</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2548</id><created>2013-06-11</created><authors><author><keyname>Singh</keyname><forenames>Shubh Narayan</forenames></author><author><keyname>Krishna</keyname><forenames>K. V.</forenames></author></authors><title>The Holonomy Decomposition of Circular Semi-Flower Automata</title><categories>cs.FL</categories><msc-class>68Q70, 20M35, 54H15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Eilenberg's holonomy decomposition is useful to ascertain the structural
properties of automata. Using this method, Egri-Nagy and Nehaniv characterized
the absence of certain types of cycles in automata. In the direction of
studying the structure of automata with cycles, this work focuses on a special
class of semi-flower automata and establish the holonomy decompositions of
certain circular semi-flower automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2550</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2550</id><created>2013-06-11</created><updated>2013-08-01</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Amjad</keyname><forenames>Rana Ali</forenames></author></authors><title>Fixed-to-Variable Length Resolution Coding for Target Distributions</title><categories>cs.IT math.IT</categories><comments>Essentially the ITW 2013 final version. Compared to v1, minor typos
  were corrected and Fig. 1 with an example variable length encoder was added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of random bits required to approximate a target distribution in
terms of un-normalized informational divergence is considered. It is shown that
for a variable-to-variable length encoder, this number is lower bounded by the
entropy of the target distribution. A fixed-to-variable length encoder is
constructed using M-type quantization and Tunstall coding. It is shown that the
encoder achieves in the limit an un-normalized informational divergence of zero
with the number of random bits per generated symbol equal to the entropy of the
target distribution. Numerical results show that the proposed encoder
significantly outperforms the optimal block-to-block encoder in the finite
length regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2552</identifier>
 <datestamp>2014-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2552</id><created>2013-06-11</created><updated>2014-03-26</updated><authors><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames></author><author><keyname>Pucci</keyname><forenames>Geppino</forenames></author><author><keyname>Silvestri</keyname><forenames>Francesco</forenames></author><author><keyname>Vandin</keyname><forenames>Fabio</forenames></author></authors><title>Space-Efficient Parallel Algorithms for Combinatorial Search Problems</title><categories>cs.DS cs.DC</categories><comments>Extended version of the paper in the Proc. of 38th International
  Symposium on Mathematical Foundations of Computer Science (MFCS)</comments><acm-class>F.2.2</acm-class><doi>10.4230/LIPIcs.STACS.2014.627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present space-efficient parallel strategies for two fundamental
combinatorial search problems, namely, backtrack search and branch-and-bound,
both involving the visit of an $n$-node tree of height $h$ under the assumption
that a node can be accessed only through its father or its children. For both
problems we propose efficient algorithms that run on a $p$-processor
distributed-memory machine. For backtrack search, we give a deterministic
algorithm running in $O(n/p+h\log p)$ time, and a Las Vegas algorithm requiring
optimal $O(n/p+h)$ time, with high probability. Building on the backtrack
search algorithm, we also derive a Las Vegas algorithm for branch-and-bound
which runs in $O((n/p+h\log p \log n)h\log^2 n)$ time, with high probability. A
remarkable feature of our algorithms is the use of only constant space per
processor, which constitutes a significant improvement upon previous algorithms
whose space requirements per processor depend on the (possibly huge) tree to be
explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2554</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2554</id><created>2013-06-11</created><authors><author><keyname>Combes</keyname><forenames>Richard</forenames></author><author><keyname>Bouloumi</keyname><forenames>Ilham El</forenames></author><author><keyname>Senecal</keyname><forenames>Stephane</forenames></author><author><keyname>Altman</keyname><forenames>Zwi</forenames></author></authors><title>The association problem in wireless networks: a Policy Gradient
  Reinforcement Learning approach</title><categories>cs.NI cs.IT cs.LG math.IT</categories><comments>Working version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to develop a self-optimized association
algorithm based on PGRL (Policy Gradient Reinforcement Learning), which is both
scalable, stable and robust. The term robust means that performance degradation
in the learning phase should be forbidden or limited to predefined thresholds.
The algorithm is model-free (as opposed to Value Iteration) and robust (as
opposed to Q-Learning). The association problem is modeled as a Markov Decision
Process (MDP). The policy space is parameterized. The parameterized family of
policies is then used as expert knowledge for the PGRL. The PGRL converges
towards a local optimum and the average cost decreases monotonically during the
learning process. The properties of the solution make it a good candidate for
practical implementation. Furthermore, the robustness property allows to use
the PGRL algorithm in an &quot;always-on&quot; learning mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2556</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2556</id><created>2013-06-10</created><authors><author><keyname>Singla</keyname><forenames>Pradeep</forenames></author><author><keyname>Gupta</keyname><forenames>Aakash</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Ashutosh</forenames></author><author><keyname>Basia</keyname><forenames>Pulkit</forenames></author></authors><title>An Optimized Design of Reversible Sequential Digital Circuits</title><categories>cs.OH</categories><comments>Proceedings of NCECST-2013, Bareily</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the today's era, reversible logics are the promising technology for the
designing of low power digital logic system having major application in the
field of nanotechnology, quantum computation, DNA and other low power digital
circuits. Reversible logics provide zero power dissipation (Ideally) in the
digital operations. There are numbers of circuit designed by the reversible
logics and sequential circuits have their own importance in the digital
systems. In this paper authors provides a optimized approach and optimized
design for the sequential circuit (counter as an example) by using the MUX gate
(a reversible gate) which provides the better results against the previous
designs discussed in the literature. The proposed design has lower quantum
cost, garbage output, constant input and total number of logical calculations
performing by the design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2557</identifier>
 <datestamp>2014-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2557</id><created>2013-06-11</created><updated>2014-06-18</updated><authors><author><keyname>Prashanth</keyname><forenames>L. A.</forenames></author><author><keyname>Korda</keyname><forenames>Nathaniel</forenames></author><author><keyname>Munos</keyname><forenames>R&#xe9;mi</forenames></author></authors><title>Fast LSTD using stochastic approximation: Finite time analysis and
  application to traffic control</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a stochastic approximation based method with randomisation of
samples for policy evaluation using the least squares temporal difference
(LSTD) algorithm. Our method results in an $O(d)$ improvement in complexity in
comparison to regular LSTD, where $d$ is the dimension of the data. We provide
convergence rate results for our proposed method, both in high probability and
in expectation. Moreover, we also establish that using our scheme in place of
LSTD does not impact the rate of convergence of the approximate value function
to the true value function. This result coupled with the low complexity of our
method makes it attractive for implementation in big data settings, where $d$
is large. Further, we also analyse a similar low-complexity alternative for
least squares regression and provide finite-time bounds there. We demonstrate
the practicality of our method for LSTD empirically by combining it with the
LSPI algorithm in a traffic signal control application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2558</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2558</id><created>2013-06-11</created><authors><author><keyname>Cohen</keyname><forenames>William W.</forenames></author><author><keyname>Redlawsk</keyname><forenames>David P.</forenames></author><author><keyname>Pierce</keyname><forenames>Douglas</forenames></author></authors><title>The Effect of Biased Communications On Both Trusting and Suspicious
  Voters</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent studies of political decision-making, apparently anomalous behavior
has been observed on the part of voters, in which negative information about a
candidate strengthens, rather than weakens, a prior positive opinion about the
candidate. This behavior appears to run counter to rational models of decision
making, and it is sometimes interpreted as evidence of non-rational &quot;motivated
reasoning&quot;. We consider scenarios in which this effect arises in a model of
rational decision making which includes the possibility of deceptive
information. In particular, we will consider a model in which there are two
classes of voters, which we will call trusting voters and suspicious voters,
and two types of information sources, which we will call unbiased sources and
biased sources. In our model, new data about a candidate can be efficiently
incorporated by a trusting voter, and anomalous updates are impossible;
however, anomalous updates can be made by suspicious voters, if the information
source mistakenly plans for an audience of trusting voters, and if the partisan
goals of the information source are known by the suspicious voter to be
&quot;opposite&quot; to his own. Our model is based on a formalism introduced by the
artificial intelligence community called &quot;multi-agent influence diagrams&quot;,
which generalize Bayesian networks to settings involving multiple agents with
distinct goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2564</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2564</id><created>2013-06-11</created><updated>2013-07-19</updated><authors><author><keyname>Hooley</keyname><forenames>Sean</forenames></author><author><keyname>Sweeney</keyname><forenames>Latanya</forenames></author></authors><title>Survey of Publicly Available State Health Databases</title><categories>cs.CY</categories><report-no>Data Privacy Lab White Paper 1075-1</report-no><acm-class>K.5; K.5.2; K.6.5; K.4.1; H.2.7; H.2.0; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We surveyed every state and the District of Columbia to see what patient
specific information states release on hospital visits and how much potentially
identifiable information is released in those records. Thirty-three states
release hospital discharge data in some form, with varying levels of
demographic information and hospital stay details such as hospital name,
admission and discharge dates, diagnoses, doctors who attended to the patient,
payer, and cost of the stay. We compared the level of demographic and other
data to federal standards set by the Health Information Portability and
Accountability Act or HIPAA), which states do not have to adhere to for this
type of data. We found that states varied widely in whether their data was
HIPAA equivalent; while 13 were equivalent (or stricter) with demographic
fields only 3 of the 33 states that released data did so in a form that was
HIPAA equivalent across all fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2578</identifier>
 <datestamp>2014-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2578</id><created>2013-06-11</created><updated>2014-03-04</updated><authors><author><keyname>Cao</keyname><forenames>Yixin</forenames></author></authors><title>A note on small cuts for a terminal</title><categories>cs.DS</categories><comments>Results already known (http://dx.doi.org/10.1016/j.ic.2012.10.016)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph $G = (V,E)$ and a terminal $s\in V$, a cut $X$ for $s$ is a
vertex set that contains $s$. We look for a cut that is small in two senses,
i.e., there are no more than $k$ vertices in $X$ and no more than $t$ edges
leaving $X$. Answering a question asked by Fomin et al. (arXiv:1304.6189), we
show the problem is fixed-parameter tractable parameterized by either $k$ or
$t$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2581</identifier>
 <datestamp>2014-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2581</id><created>2013-06-11</created><updated>2014-01-29</updated><authors><author><keyname>Kofidis</keyname><forenames>Eleftherios</forenames></author></authors><title>Preamble-based Channel Estimation in FBMC/OQAM Systems: A Time-Domain
  Approach</title><categories>cs.IT math.IT stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filter bank-based multicarrier (FBMC) systems based on offset QAM (FBMC/OQAM)
have recently attracted increased interest in several applications due to their
enhanced flexibility, higher spectral efficiency, and better spectral
containment compared to conventional OFDM. They suffer, however, from an
inter-carrier/inter-symbol interference that complicates signal processing
tasks such as channel estimation. Most of the methods reported thus far rely on
the assumption of (almost) flat subchannels to more easily tackle this problem,
addressing it in a way similar to OFDM. However, this assumption may be often
quite inaccurate, due to the high freq. selectivity of the channel and/or the
small number of subcarriers employed to cope with frequency dispersion in fast
fading. In such cases, severe error floors are exhibited at medium to high SNR
values, which cancel the advantage of FBMC over OFDM. Moreover, the existing
methods provide estimates of the subchannel responses, most commonly in the
frequency domain. The goal of this paper is to revisit this problem through an
alternative formulation that focuses on the estimation of the channel impulse
response itself and makes no assumption on the degree of frequency selectivity
of the subchannels. The possible gains in estimation performance offered by
such an approach are investigated through the design of optimal (in the MSE
sense) preambles, of both the full and sparse types, and of the smallest
possible duration of only one pilot FBMC symbol. Existing designs for flat
subchannels are then shown to result as special cases. Longer preambles,
consisting of two consecutive pilot FBMC symbols, are also analyzed. The
simulation results demonstrate significant improvements from the proposed
approach for both mildly and highly frequency selective channels. Most notably,
no error floors appear anymore over a quite wide range of SNR values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2588</identifier>
 <datestamp>2014-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2588</id><created>2013-06-10</created><updated>2014-07-11</updated><authors><author><keyname>Van Mieghem</keyname><forenames>Piet</forenames></author><author><keyname>Omic</keyname><forenames>Jasmina</forenames></author></authors><title>In-homogeneous Virus Spread in Networks</title><categories>math.OC cs.NI</categories><comments>on http://www.nas.ewi.tudelft.nl/people/Piet/TUDelftReports.html</comments><report-no>Delft University of Technology, report2008081</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our $N$-intertwined model (now called NIMFA) for virus spread in any network
with $N$ nodes is extended to a full heterogeneous setting. The metastable
steady-state nodal infection probabilities are specified in terms of a
generalized Laplacian, that possesses analogous properties as the classical
Laplacian in graph theory. The critical threshold that separates global network
infection from global network health is characterized via an $N$ dimensional
vector that makes the largest eigenvalue of a modified adjacency matrix equal
to unity. Finally, the steady-state infection probability of node $i$ is convex
in the own curing rate $\delta_{i}$, but concave in the curing rates
$\delta_{j}$ of the other nodes $1\leq j\neq i\leq N$ in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2593</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2593</id><created>2013-06-11</created><authors><author><keyname>Tsiang</keyname><forenames>Elaine</forenames></author></authors><title>A 10-dimensional Phonetic-prosodic Space and its Stochastic Structure (A
  framework for probabilistic modeling of spoken languages and their phonology)</title><categories>cs.SD cs.CL</categories><comments>6 pages, 10 tables</comments><report-no>MIMC001</report-no><acm-class>I.2.7</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We formulate a phonetic-prosodic space based on attributes as perceptual
observables, rather than articulatory specifications. We propose an alphabet as
markers in the phonetic subspace, aiming for a resolution sufficient to support
recognition of all spoken languages. The prosodic subspace is made up of
directly measurable physical variables. With the proposed alphabet, traditional
diphthongs naturally generalize to a broader class of language-neutral
phonotactic constraints, indicating a correlation structure similar to that of
the traditional sonority-based syllable. We define a stochastic structure on
the phone strings based on this diphthongal constraint, and show how a specific
spoken language can be defined as a specific set of probability distributions
of this stochastic structure. Furthermore, phonological variations within a
spoken language can be modeled as varying probability distributions restricted
to the phonetic subspace, conditioned on different values in the prosodic
subspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2595</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2595</id><created>2013-06-11</created><updated>2015-12-08</updated><authors><author><keyname>&#xc7;akmak</keyname><forenames>Burak</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Fleury</keyname><forenames>Bernard H.</forenames></author></authors><title>Capacity Scaling in MIMO Systems with General Unitarily Invariant Random
  Matrices</title><categories>cs.IT math.IT</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the capacity scaling of MIMO systems with respect to the
system dimensions. To that end we quantify how the mutual information varies
when the numbers of antennas (at either the receiver or transmitter side) is
altered. For a system comprising $R$ receive and $T$ transmit antennas with
$T&lt;R$, we find the following: By removing as many receive antennas as to obtain
a square system, the maximum resulting loss of mutual information over all SNRs
depends only on $R$,$T$ and the left eigenbasis of the (initial) channel
matrix, but not on its singular values. Assuming the left eigenbasis to be Haar
distributed, the ergodic rate loss can be easily quantified in terms of the
digamma function. In particular, the rate loss normalized by $R$ converges to
the binary entropy function evaluated at the fixed ratio $\phi=T/R$ as the
system dimensions tend to infinity. We also quantify how the mutual information
as a function of the system dimensions deviates from the traditionally assumed
linear growth versus the minimum of the system dimensions at high SNR. Finally,
we derive new formulas in terms of the S-transform which fundamentally relate
the mutual information to its affine approximation at high SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2597</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2597</id><created>2013-06-09</created><authors><author><keyname>Qin</keyname><forenames>Tao</forenames></author><author><keyname>Liu</keyname><forenames>Tie-Yan</forenames></author></authors><title>Introducing LETOR 4.0 Datasets</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LETOR is a package of benchmark data sets for research on LEarning TO Rank,
which contains standard features, relevance judgments, data partitioning,
evaluation tools, and several baselines. Version 1.0 was released in April
2007. Version 2.0 was released in Dec. 2007. Version 3.0 was released in Dec.
2008. This version, 4.0, was released in July 2009. Very different from
previous versions (V3.0 is an update based on V2.0 and V2.0 is an update based
on V1.0), LETOR4.0 is a totally new release. It uses the Gov2 web page
collection (~25M pages) and two query sets from Million Query track of TREC
2007 and TREC 2008. We call the two query sets MQ2007 and MQ2008 for short.
There are about 1700 queries in MQ2007 with labeled documents and about 800
queries in MQ2008 with labeled documents. If you have any questions or
suggestions about the datasets, please kindly email us (letor@microsoft.com).
Our goal is to make the dataset reliable and useful for the community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2599</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2599</id><created>2013-06-11</created><authors><author><keyname>Singha</keyname><forenames>Joyeeta</forenames></author><author><keyname>Das</keyname><forenames>Karen</forenames></author></authors><title>Hand Gesture Recognition Based on Karhunen-Loeve Transform</title><categories>cs.CV</categories><comments>7 pages,9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have proposed a system based on K-L Transform to recognize
different hand gestures. The system consists of five steps: skin filtering,
palm cropping, edge detection, feature extraction, and classification. Firstly
the hand is detected using skin filtering and palm cropping was performed to
extract out only the palm portion of the hand. The extracted image was then
processed using the Canny Edge Detection technique to extract the outline
images of palm. After palm extraction, the features of hand were extracted
using K-L Transform technique and finally the input gesture was recognized
using proper classifier. In our system, we have tested for 10 different hand
gestures, and recognizing rate obtained was 96%. Hence we propose an easy
approach to recognize different hand gestures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2604</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2604</id><created>2013-06-11</created><authors><author><keyname>Mi&#x15b;kiewicz</keyname><forenames>Janusz</forenames></author></authors><title>Effects of Publications in Proceedings on the Measure of the Core Size
  of Coauthors</title><categories>cs.DL physics.soc-ph</categories><comments>The paper was inspired by the work: M. Ausloos. A scientometrics law
  about co-authors and their ranking. The co-author core. Scientometrics (in
  press); arXiv:1207.1614 (2012)</comments><doi>10.1016/j.physa.2013.06.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coauthors (CA) of a &quot;lead investigator&quot; (LI) can receive a rank (r) according
to their &quot;importance&quot; in having published joint publications with the LI. It is
commonly accepted, without any proof, that publications in peer review journals
and e.g. conference proceedings do not have the same &quot;value&quot; in a CV. Same for
papers contributed to encyclopedia and book chapters. It is here examined
whether the relationship between the number (J) of publications of some
scientist with her/his coauthors, ranked according to their decreasing
importance, i.e. $ J \propto 1/r^{\alpha} $, as found by Ausloos, still holds
if the overall publication list is broken into such specific types of
publications. Several authors, with different careers, but mainly having worked
in the field of statistical mechanics, are studied here to sort out answers to
the questions. The exponent $\alpha$ turns out to be weakly scientist
dependent, only if the maximum value of J and r is large and is $\sim +1$ then.
The $m_A$ core value, i.e. the core number of CAs, for proceedings only is
about half of the total one, i.e. when all publications are counted.
Contributions to the numerical values from both encyclopedia and book chapters
are marginal. The role of a time span on $m_A$ is also examined in two cases in
relation to career activity considerations. It can considered that the findings
serve as a contrasting point of view on how to quantify an individual
(publication) career as recently done by Petersen et al., here emphasizing the
collaboration size and evolution, rather than a citation count, moreover
specifying the type of publication. Through the various $m_A$'s one can
distinguish different behavior patterns of a scientist publication with CAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2607</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2607</id><created>2013-06-11</created><updated>2014-04-07</updated><authors><author><keyname>Stein</keyname><forenames>Manuel</forenames></author><author><keyname>Mezghani</keyname><forenames>Amine</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>A Lower Bound for the Fisher Information Measure</title><categories>cs.IT math.IT</categories><comments>4 pages, submitted to IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2014.2316008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem how to approximately determine the absolute value of the Fisher
information measure for a general parametric probabilistic system is
considered. Having available the first and second moment of the system output
in a parametric form, it is shown that the information measure can be bounded
from below through a replacement of the original system by a Gaussian system
with equivalent moments. The presented technique is applied to a system of
practical importance and the potential quality of the bound is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2624</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2624</id><created>2013-06-11</created><authors><author><keyname>Su&#xe1;rez</keyname><forenames>Yasel Garc&#xe9;s</forenames></author><author><keyname>Torres</keyname><forenames>Esley</forenames></author><author><keyname>Pereira</keyname><forenames>Osvaldo</forenames></author><author><keyname>P&#xe9;rez</keyname><forenames>Claudia</forenames></author><author><keyname>Rogr&#xed;guez</keyname><forenames>Roberto</forenames></author></authors><title>Stopping Criterion for the Mean Shift Iterative Algorithm</title><categories>cs.CV math.RA</categories><comments>Have 8 pages. Is the first version of the more general paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image segmentation is a critical step in computer vision tasks constituting
an essential issue for pattern recognition and visual interpretation. In this
paper, we propose a new stopping criterion for the mean shift iterative
algorithm by using images defined in Zn ring, with the goal of reaching a
better segmentation. We carried out also a study on the weak and strong of
equivalence classes between two images. An analysis on the convergence with
this new stopping criterion is carried out too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2663</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2663</id><created>2013-06-11</created><authors><author><keyname>Zhong</keyname><forenames>Guoqiang</forenames></author><author><keyname>Cheriet</keyname><forenames>Mohamed</forenames></author></authors><title>Large Margin Low Rank Tensor Analysis</title><categories>cs.LG cs.NA</categories><comments>30 pages</comments><msc-class>57-04</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Other than vector representations, the direct objects of human cognition are
generally high-order tensors, such as 2D images and 3D textures. From this
fact, two interesting questions naturally arise: How does the human brain
represent these tensor perceptions in a &quot;manifold&quot; way, and how can they be
recognized on the &quot;manifold&quot;? In this paper, we present a supervised model to
learn the intrinsic structure of the tensors embedded in a high dimensional
Euclidean space. With the fixed point continuation procedures, our model
automatically and jointly discovers the optimal dimensionality and the
representations of the low dimensional embeddings. This makes it an effective
simulation of the cognitive process of human brain. Furthermore, the
generalization of our model based on similarity between the learned low
dimensional embeddings can be viewed as counterpart of recognition of human
brain. Experiments on applications for object recognition and face recognition
demonstrate the superiority of our proposed model over state-of-the-art
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2665</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2665</id><created>2013-06-11</created><updated>2013-08-09</updated><authors><author><keyname>Cho</keyname><forenames>Myung</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author></authors><title>Precisely Verifying the Null Space Conditions in Compressed Sensing: A
  Sandwiching Algorithm</title><categories>cs.IT cs.LG cs.SY math.IT math.OC stat.ML</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose new efficient algorithms to verify the null space
condition in compressed sensing (CS). Given an $(n-m) \times n$ ($m&gt;0$) CS
matrix $A$ and a positive $k$, we are interested in computing $\displaystyle
\alpha_k = \max_{\{z: Az=0,z\neq 0\}}\max_{\{K: |K|\leq k\}}$ ${\|z_K
\|_{1}}{\|z\|_{1}}$, where $K$ represents subsets of $\{1,2,...,n\}$, and $|K|$
is the cardinality of $K$. In particular, we are interested in finding the
maximum $k$ such that $\alpha_k &lt; {1}{2}$. However, computing $\alpha_k$ is
known to be extremely challenging. In this paper, we first propose a series of
new polynomial-time algorithms to compute upper bounds on $\alpha_k$. Based on
these new polynomial-time algorithms, we further design a new sandwiching
algorithm, to compute the \emph{exact} $\alpha_k$ with greatly reduced
complexity. When needed, this new sandwiching algorithm also achieves a smooth
tradeoff between computational complexity and result accuracy. Empirical
results show the performance improvements of our algorithm over existing known
methods; and our algorithm outputs precise values of $\alpha_k$, with much
lower complexity than exhaustive search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2672</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2672</id><created>2013-06-11</created><updated>2014-09-20</updated><authors><author><keyname>Mishra</keyname><forenames>B.</forenames></author><author><keyname>Sepulchre</keyname><forenames>R.</forenames></author></authors><title>R3MC: A Riemannian three-factor algorithm for low-rank matrix completion</title><categories>math.OC cs.LG</categories><comments>Accepted for publication in the proceedings of the 53rd IEEE
  Conference on Decision and Control, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exploit the versatile framework of Riemannian optimization on quotient
manifolds to develop R3MC, a nonlinear conjugate-gradient method for low-rank
matrix completion. The underlying search space of fixed-rank matrices is
endowed with a novel Riemannian metric that is tailored to the least-squares
cost. Numerical comparisons suggest that R3MC robustly outperforms
state-of-the-art algorithms across different problem instances, especially
those that combine scarcely sampled and ill-conditioned data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2675</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2675</id><created>2013-06-11</created><authors><author><keyname>Yanofsky</keyname><forenames>Noson S.</forenames></author></authors><title>Kolmogorov Complexity of Categories</title><categories>math.CT cs.IT cs.LO cs.PL math.IT math.LO</categories><comments>16 pages</comments><msc-class>68Q30, 18A05</msc-class><acm-class>F.1.3</acm-class><journal-ref>An version of this is published in &quot;Computation, Logic, Games, and
  Quantum Foundations - The Many Facets of Samson Abramsky: Essays Dedicted to
  Samson Abramsky on the Occasion of His 60th Birthday&quot; Springer LNCS 7860.
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kolmogorov complexity theory is used to tell what the algorithmic
informational content of a string is. It is defined as the length of the
shortest program that describes the string. We present a programming language
that can be used to describe categories, functors, and natural transformations.
With this in hand, we define the informational content of these categorical
structures as the shortest program that describes such structures. Some basic
consequences of our definition are presented including the fact that equivalent
categories have equal Kolmogorov complexity. We also prove different theorems
about what can and cannot be described by our programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2685</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2685</id><created>2013-06-11</created><updated>2013-11-14</updated><authors><author><keyname>Kalaitzis</keyname><forenames>Alfredo</forenames></author><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author></authors><title>Flexible sampling of discrete data correlations without the marginal
  distributions</title><categories>stat.ML cs.LG stat.CO</categories><comments>An overhauled version of the experimental section moved to the main
  paper. Old experimental section moved to supplementary material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning the joint dependence of discrete variables is a fundamental problem
in machine learning, with many applications including prediction, clustering
and dimensionality reduction. More recently, the framework of copula modeling
has gained popularity due to its modular parametrization of joint
distributions. Among other properties, copulas provide a recipe for combining
flexible models for univariate marginal distributions with parametric families
suitable for potentially high dimensional dependence structures. More
radically, the extended rank likelihood approach of Hoff (2007) bypasses
learning marginal models completely when such information is ancillary to the
learning task at hand as in, e.g., standard dimensionality reduction problems
or copula parameter estimation. The main idea is to represent data by their
observable rank statistics, ignoring any other information from the marginals.
Inference is typically done in a Bayesian framework with Gaussian copulas, and
it is complicated by the fact this implies sampling within a space where the
number of constraints increases quadratically with the number of data points.
The result is slow mixing when using off-the-shelf Gibbs sampling. We present
an efficient algorithm based on recent advances on constrained Hamiltonian
Markov chain Monte Carlo that is simple to implement and does not require
paying for a quadratic cost in sample size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2691</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2691</id><created>2013-06-11</created><authors><author><keyname>Gazeau</keyname><forenames>Ivan</forenames><affiliation>INRIA</affiliation></author><author><keyname>Miller</keyname><forenames>Dale</forenames><affiliation>INRIA</affiliation></author><author><keyname>Palamidessi</keyname><forenames>Catuscia</forenames><affiliation>INRIA</affiliation></author></authors><title>Preserving differential privacy under finite-precision semantics</title><categories>cs.DB</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><acm-class>H.2.8</acm-class><journal-ref>EPTCS 117, 2013, pp. 1-18</journal-ref><doi>10.4204/EPTCS.117.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The approximation introduced by finite-precision representation of continuous
data can induce arbitrarily large information leaks even when the computation
using exact semantics is secure. Such leakage can thus undermine design efforts
aimed at protecting sensitive information. We focus here on differential
privacy, an approach to privacy that emerged from the area of statistical
databases and is now widely applied also in other domains. In this approach,
privacy is protected by the addition of noise to a true (private) value. To
date, this approach to privacy has been proved correct only in the ideal case
in which computations are made using an idealized, infinite-precision
semantics. In this paper, we analyze the situation at the implementation level,
where the semantics is necessarily finite-precision, i.e. the representation of
real numbers and the operations on them, are rounded according to some level of
precision. We show that in general there are violations of the differential
privacy property, and we study the conditions under which we can still
guarantee a limited (but, arguably, totally acceptable) variant of the
property, under only a minor degradation of the privacy level. Finally, we
illustrate our results on two cases of noise-generating distributions: the
standard Laplacian mechanism commonly used in differential privacy, and a
bivariate version of the Laplacian recently introduced in the setting of
privacy-aware geolocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2692</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2692</id><created>2013-06-11</created><authors><author><keyname>Tranquilli</keyname><forenames>Paolo</forenames><affiliation>DISI -- Universit&#xe0; di Bologna Alma Mater</affiliation></author></authors><title>Indexed Labels for Loop Iteration Dependent Costs</title><categories>cs.PL</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 117, 2013, pp. 19-33</journal-ref><doi>10.4204/EPTCS.117.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension to the labelling approach, a technique for lifting
resource consumption information from compiled to source code. This approach,
which is at the core of the annotating compiler from a large fragment of C to
8051 assembly of the CerCo project, looses preciseness when differences arise
as to the cost of the same portion of code, whether due to code transformation
such as loop optimisations or advanced architecture features (e.g. cache). We
propose to address this weakness by formally indexing cost labels with the
iterations of the containing loops they occur in. These indexes can be
transformed during the compilation, and when lifted back to source code they
produce dependent costs.
  The proposed changes have been implemented in CerCo's untrusted prototype
compiler from a large fragment of C to 8051 assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2693</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2693</id><created>2013-06-11</created><authors><author><keyname>Ngo</keyname><forenames>Tri Minh</forenames><affiliation>University of Twente</affiliation></author><author><keyname>Huisman</keyname><forenames>Marieke</forenames><affiliation>University of Twente</affiliation></author></authors><title>Quantitative Security Analysis for Multi-threaded Programs</title><categories>cs.CR</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 117, 2013, pp. 34-48</journal-ref><doi>10.4204/EPTCS.117.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative theories of information flow give us an approach to relax the
absolute confidentiality properties that are difficult to satisfy for many
practical programs. The classical information-theoretic approaches for
sequential programs, where the program is modeled as a communication channel
with only input and output, and the measure of leakage is based on the notions
of initial uncertainty and remaining uncertainty after observing the final
outcomes, are not suitable to multi-threaded programs. Besides, the
information-theoretic approaches have been also shown to conflict with each
other when comparing programs. Reasoning about the exposed information flow of
multi-threaded programs is more complicated, since the outcomes of such
programs depend on the scheduler policy, and the leakages in intermediate
states also contribute to the overall leakage of the program.
  This paper proposes a novel model of quantitative analysis for multi-threaded
programs that also takes into account the effect of observables in intermediate
states along the trace. We define a notion of the leakage of a program trace.
Given the fact that the execution of a multi-threaded program is typically
described by a set of traces, the leakage of a program under a specific
scheduler is computed as the expected value of the leakages of all possible
traces. Examples are given to compare our approach with the existing
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2694</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2694</id><created>2013-06-11</created><authors><author><keyname>Schuppan</keyname><forenames>Viktor</forenames></author></authors><title>Enhancing Unsatisfiable Cores for LTL with Information on Temporal
  Relevance</title><categories>cs.LO cs.SE</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><acm-class>F.4.1; F.3.1; D.2.4; B5.2; I.2.4</acm-class><journal-ref>EPTCS 117, 2013, pp. 49-65</journal-ref><doi>10.4204/EPTCS.117.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LTL is frequently used to express specifications in many domains such as
embedded systems or business processes. Witnesses can help to understand why an
LTL specification is satisfiable, and a number of approaches exist to make
understanding a witness easier. In the case of unsatisfiable specifications
unsatisfiable cores (UCs), i.e., parts of an unsatisfiable formula that are
themselves unsatisfiable, are a well established means for debugging. However,
little work has been done to help understanding a UC of an unsatisfiable LTL
formula. In this paper we suggest to enhance a UC of an unsatisfiable LTL
formula with additional information about the time points at which the
subformulas of the UC are relevant for unsatisfiability. For example, in &quot;(G p)
and (X not p)&quot; the first occurrence of &quot;p&quot; is really only &quot;relevant&quot; for
unsatisfiability at time point 1 (time starts at time point 0). We present a
method to extract such information from the resolution graph of a temporal
resolution proof of unsatisfiability of an LTL formula. We implement our method
in TRP++, and we experimentally evaluate it. Source code of our tool is
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2695</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2695</id><created>2013-06-11</created><authors><author><keyname>Han</keyname><forenames>Tingting</forenames></author><author><keyname>Krause</keyname><forenames>Christian</forenames></author><author><keyname>Kwiatkowska</keyname><forenames>Marta</forenames></author><author><keyname>Giese</keyname><forenames>Holger</forenames></author></authors><title>Modal Specifications for Probabilistic Timed Systems</title><categories>cs.LO cs.FL</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 117, 2013, pp. 66-80</journal-ref><doi>10.4204/EPTCS.117.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modal automata are a classic formal model for component-based systems that
comes equipped with a rich specification theory supporting abstraction,
refinement and compositional reasoning. In recent years, quantitative variants
of modal automata were introduced for specifying and reasoning about
component-based designs for embedded and mobile systems. These respectively
generalize modal specification theories for timed and probabilistic systems. In
this paper, we define a modal specification language for combined probabilistic
timed systems, called abstract probabilistic timed automata, which generalizes
existing formalisms. We introduce appropriate syntactic and semantic refinement
notions and discuss consistency of our specification language, also with
respect to time-divergence. We identify a subclass of our models for which we
define the fundamental operations for abstraction, conjunction and parallel
composition, and show several compositionality results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2696</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2696</id><created>2013-06-11</created><authors><author><keyname>Bernardo</keyname><forenames>Marco</forenames><affiliation>University of Urbino, Italy</affiliation></author><author><keyname>De Nicola</keyname><forenames>Rocco</forenames><affiliation>IMT Lucca, Italy</affiliation></author><author><keyname>Loreti</keyname><forenames>Michele</forenames><affiliation>University of Firenze, Italy</affiliation></author></authors><title>The Spectrum of Strong Behavioral Equivalences for Nondeterministic and
  Probabilistic Processes</title><categories>cs.LO</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 117, 2013, pp. 81-96</journal-ref><doi>10.4204/EPTCS.117.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a spectrum of trace-based, testing, and bisimulation equivalences
for nondeterministic and probabilistic processes whose activities are all
observable. For every equivalence under study, we examine the discriminating
power of three variants stemming from three approaches that differ for the way
probabilities of events are compared when nondeterministic choices are resolved
via deterministic schedulers. We show that the first approach - which compares
two resolutions relatively to the probability distributions of all considered
events - results in a fragment of the spectrum compatible with the spectrum of
behavioral equivalences for fully probabilistic processes. In contrast, the
second approach - which compares the probabilities of the events of a
resolution with the probabilities of the same events in possibly different
resolutions - gives rise to another fragment composed of coarser equivalences
that exhibits several analogies with the spectrum of behavioral equivalences
for fully nondeterministic processes. Finally, the third approach - which only
compares the extremal probabilities of each event stemming from the different
resolutions - yields even coarser equivalences that, however, give rise to a
hierarchy similar to that stemming from the second approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2697</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2697</id><created>2013-06-11</created><authors><author><keyname>McIver</keyname><forenames>Annabelle</forenames><affiliation>Macquarie University</affiliation></author><author><keyname>Rabehaja</keyname><forenames>Tahiry</forenames><affiliation>Macquarie University and University of Sheffield</affiliation></author><author><keyname>Struth</keyname><forenames>Georg</forenames><affiliation>University of Sheffield</affiliation></author></authors><title>Probabilistic Concurrent Kleene Algebra</title><categories>cs.LO</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 117, 2013, pp. 97-115</journal-ref><doi>10.4204/EPTCS.117.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an extension of concurrent Kleene algebras to account for
probabilistic properties. The algebra yields a unified framework containing
nondeterminism, concurrency and probability and is sound with respect to the
set of probabilistic automata modulo probabilistic simulation. We use the
resulting algebra to generalise the algebraic formulation of a variant of
Jones' rely/guarantee calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2700</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2700</id><created>2013-06-11</created><updated>2014-07-30</updated><authors><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent</forenames></author></authors><title>Hierarchical Interference Mitigation for Massive MIMO Cellular Networks</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Trans. Signal Processing, July. 2014</comments><doi>10.1109/TSP.2014.2340814</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hierarchical interference mitigation scheme for massive MIMO
cellular networks. The MIMO precoder at each base station (BS) is partitioned
into an inner precoder and an outer precoder. The inner precoder controls the
intra-cell interference and is adaptive to local channel state information
(CSI) at each BS (CSIT). The outer precoder controls the inter-cell
interference and is adaptive to channel statistics. Such hierarchical precoding
structure reduces the number of pilot symbols required for CSI estimation in
massive MIMO downlink and is robust to the backhaul latency. We study joint
optimization of the outer precoders, the user selection, and the power
allocation to maximize a general concave utility which has no closed-form
expression. We first apply random matrix theory to obtain an approximated
problem with closed-form objective. We show that the solution of the
approximated problem is asymptotically optimal with respect to the original
problem as the number of antennas per BS grows large. Then using the hidden
convexity of the problem, we propose an iterative algorithm to find the optimal
solution for the approximated problem. We also obtain a low complexity
algorithm with provable convergence. Simulations show that the proposed design
has significant gain over various state-of-the-art baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2701</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2701</id><created>2013-06-11</created><updated>2013-11-07</updated><authors><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent</forenames></author></authors><title>Cache-Enabled Opportunistic Cooperative MIMO for Video Streaming in
  Wireless Systems</title><categories>cs.IT cs.MM math.IT</categories><comments>14 pages, accepted by IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a cache-enabled opportunistic cooperative MIMO (CoMP) framework
for wireless video streaming. By caching a portion of the video files at the
relays (RS) using a novel MDS-coded random cache scheme, the base station (BS)
and RSs opportunistically employ CoMP to achieve spatial multiplexing gain
without expensive payload backhaul. We study a two timescale joint optimization
of power and cache control to support real-time video streaming. The cache
control is to create more CoMP opportunities and is adaptive to the long-term
popularity of the video files. The power control is to guarantee the QoS
requirements and is adaptive to the channel state information (CSI), the cache
state at the RS and the queue state information (QSI) at the users. The joint
problem is decomposed into an inner power control problem and an outer cache
control problem. We first derive a closed-form power control policy from an
approximated Bellman equation. Based on this, we transform the outer problem
into a convex stochastic optimization problem and propose a stochastic
subgradient algorithm to solve it. Finally, the proposed solution is shown to
be asymptotically optimal for high SNR and small timeslot duration. Its
superior performance over various baselines is verified by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2725</identifier>
 <datestamp>2014-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2725</id><created>2013-06-12</created><updated>2014-01-07</updated><authors><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author><author><keyname>Shi</keyname><forenames>Qingqi</forenames></author></authors><title>Solvability of Cubic Graphs - From Four Color Theorem to NP-Complete</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similar to Euclidean geometry, graph theory is a science that studies figures
that consist of points and lines. The core of Euclidean geometry is the
parallel postulate, which provides the basis of the geometric invariant that
the sum of the angles in every triangle equals $\pi$ and Cramer's rule for
solving simultaneous linear equations. Since the counterpart of parallel
postulate in graph theory is not known, which could be the reason that two
similar problems in graph theory, namely the four color theorem (a topological
invariant) and the solvability of NP-complete problems (discrete simultaneous
equations), remain open to date. In this paper, based on the complex coloring
of cubic graphs, we propose the reducibility postulate of the Petersen
configuration to fill this gap. Comparing edge coloring with a system of linear
equations, we found that the postulate of reducibility in graph theory and the
parallel postulate in Euclidean geometry share some common characteristics of
the plane. First, they both provide solvability conditions on two equations in
the plane. Second, the two basic invariants of the plane, namely the chromatic
index of bridgeless cubic plane graphs and the sum of the angles in every
triangle, can be respectively deduced from them in a straightforward manner.
This reducibility postulation has been verified by more than one hundred
thousand instances of Peterson configurations generated by computer. Despite
that, we still don't have a logical proof of this assertion. Similar to that of
the parallel postulate, we tend to think that describing these natural laws by
even more elementary properties of the plane is inconceivable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2727</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2727</id><created>2013-06-12</created><authors><author><keyname>Guha</keyname><forenames>Tanaya</forenames></author><author><keyname>Nezhadarya</keyname><forenames>Ehsan</forenames></author><author><keyname>Ward</keyname><forenames>Rabab K</forenames></author></authors><title>Sparse Representation-based Image Quality Assessment</title><categories>cs.CV cs.MM</categories><comments>10 pages, 3 figures, 3 tables, submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A successful approach to image quality assessment involves comparing the
structural information between a distorted and its reference image. However,
extracting structural information that is perceptually important to our visual
system is a challenging task. This paper addresses this issue by employing a
sparse representation-based approach and proposes a new metric called the
\emph{sparse representation-based quality} (SPARQ) \emph{index}. The proposed
method learns the inherent structures of the reference image as a set of basis
vectors, such that any structure in the image can be represented by a linear
combination of only a few of those basis vectors. This sparse strategy is
employed because it is known to generate basis vectors that are qualitatively
similar to the receptive field of the simple cells present in the mammalian
primary visual cortex. The visual quality of the distorted image is estimated
by comparing the structures of the reference and the distorted images in terms
of the learnt basis vectors resembling cortical cells. Our approach is
evaluated on six publicly available subject-rated image quality assessment
datasets. The proposed SPARQ index consistently exhibits high correlation with
the subjective ratings on all datasets and performs better or at par with the
state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2733</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2733</id><created>2013-06-12</created><updated>2013-10-06</updated><authors><author><keyname>Fan</keyname><forenames>Xuhui</forenames></author><author><keyname>Cao</keyname><forenames>Longbing</forenames></author><author><keyname>Da Xu</keyname><forenames>Richard Yi</forenames></author></authors><title>Copula Mixed-Membership Stochastic Blockmodel for Intra-Subgroup
  Correlations</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \emph{Mixed-Membership Stochastic Blockmodel (MMSB)} is a popular
framework for modeling social network relationships. It can fully exploit each
individual node's participation (or membership) in a social structure. Despite
its powerful representations, this model makes an assumption that the
distributions of relational membership indicators between two nodes are
independent. Under many social network settings, however, it is possible that
certain known subgroups of people may have high or low correlations in terms of
their membership categories towards each other, and such prior information
should be incorporated into the model. To this end, we introduce a \emph{Copula
Mixed-Membership Stochastic Blockmodel (cMMSB)} where an individual Copula
function is employed to jointly model the membership pairs of those nodes
within the subgroup of interest. The model enables the use of various Copula
functions to suit the scenario, while maintaining the membership's marginal
distribution, as needed, for modeling membership indicators with other nodes
outside of the subgroup of interest. We describe the proposed model and its
inference algorithm in detail for both the finite and infinite cases. In the
experiment section, we compare our algorithms with other popular models in
terms of link prediction, using both synthetic and real world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2735</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2735</id><created>2013-06-12</created><authors><author><keyname>Tukmanov</keyname><forenames>Anvar</forenames></author><author><keyname>Boussakta</keyname><forenames>Said</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Jamalipour</keyname><forenames>Abbas</forenames></author></authors><title>On the Impact of Relay-side Channel State Information on Opportunistic
  Relaying</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, to appear at International Conference on
  Communications (ICC) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, outage performance of network topology-aware distributed
opportunistic relay selection strategies is studied with focus on the impact of
different levels of channel state information (CSI) available at relays.
Specifically, two scenarios with (a) exact instantaneous and (b) only
statistical CSI are compared with explicit account for both small-scale
Rayleigh fading and path loss due to random inter-node distances. Analytical
results, matching closely to simulations, suggest that although similar
diversity order can be achieved in both cases, the lack of precise CSI to
support relay selection translates into significant increase in the power
required to achieve the same level of QoS. In addition, when only statistical
CSI is available, achieving the same diversity order is associated with a clear
performance degradation at low SNR due to splitting of system resources between
multiple relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2743</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2743</id><created>2013-06-12</created><authors><author><keyname>Poss</keyname><forenames>Raphael</forenames></author><author><keyname>Verstraaten</keyname><forenames>Merijn</forenames></author><author><keyname>Penczek</keyname><forenames>Frank</forenames></author><author><keyname>Grelck</keyname><forenames>Clemens</forenames></author><author><keyname>Kirner</keyname><forenames>Raimund</forenames></author><author><keyname>Shafarenko</keyname><forenames>Alex</forenames></author></authors><title>S+Net: extending functional coordination with extra-functional semantics</title><categories>cs.PL cs.DC</categories><comments>34 pages, 11 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report introduces S+Net, a compositional coordination language
for streaming networks with extra-functional semantics. Compositionality
simplifies the specification of complex parallel and distributed applications;
extra-functional semantics allow the application designer to reason about and
control resource usage, performance and fault handling. The key feature of
S+Net is that functional and extra-functional semantics are defined
orthogonally from each other. S+Net can be seen as a simultaneous
simplification and extension of the existing coordination language S-Net, that
gives control of extra-functional behavior to the S-Net programmer. S+Net can
also be seen as a transitional research step between S-Net and AstraKahn,
another coordination language currently being designed at the University of
Hertfordshire. In contrast with AstraKahn which constitutes a re-design from
the ground up, S+Net preserves the basic operational semantics of S-Net and
thus provides an incremental introduction of extra-functional control in an
existing language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2759</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2759</id><created>2013-06-12</created><authors><author><keyname>Xie</keyname><forenames>Jingjing</forenames></author><author><keyname>Xu</keyname><forenames>Bing</forenames></author><author><keyname>Chuang</keyname><forenames>Zhang</forenames></author></authors><title>Horizontal and Vertical Ensemble with Deep Representation for
  Classification</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Representation learning, especially which by using deep learning, has been
widely applied in classification. However, how to use limited size of labeled
data to achieve good classification performance with deep neural network, and
how can the learned features further improve classification remain indefinite.
In this paper, we propose Horizontal Voting Vertical Voting and Horizontal
Stacked Ensemble methods to improve the classification performance of deep
neural networks. In the ICML 2013 Black Box Challenge, via using these methods
independently, Bing Xu achieved 3rd in public leaderboard, and 7th in private
leaderboard; Jingjing Xie achieved 4th in public leaderboard, and 5th in
private leaderboard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2795</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2795</id><created>2013-06-12</created><authors><author><keyname>Pinheiro</keyname><forenames>Pedro H. O.</forenames></author><author><keyname>Collobert</keyname><forenames>Ronan</forenames></author></authors><title>Recurrent Convolutional Neural Networks for Scene Parsing</title><categories>cs.CV</categories><report-no>Idiap-RR-22-2013</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene parsing is a technique that consist on giving a label to all pixels in
an image according to the class they belong to. To ensure a good visual
coherence and a high class accuracy, it is essential for a scene parser to
capture image long range dependencies. In a feed-forward architecture, this can
be simply achieved by considering a sufficiently large input context patch,
around each pixel to be labeled. We propose an approach consisting of a
recurrent convolutional neural network which allows us to consider a large
input context, while limiting the capacity of the model. Contrary to most
standard approaches, our method does not rely on any segmentation methods, nor
any task-specific features. The system is trained in an end-to-end manner over
raw pixels, and models complex spatial dependencies with low inference cost. As
the context size increases with the built-in recurrence, the system identifies
and corrects its own errors. Our approach yields state-of-the-art performance
on both the Stanford Background Dataset and the SIFT Flow Dataset, while
remaining very fast at test time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2801</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2801</id><created>2013-06-12</created><updated>2013-08-18</updated><authors><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author></authors><title>Understanding Dropout: Training Multi-Layer Perceptrons with Auxiliary
  Independent Stochastic Neurons</title><categories>cs.NE cs.LG stat.ML</categories><comments>ICONIP 2013: Special Session in Deep Learning (v4)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a simple, general method of adding auxiliary stochastic
neurons to a multi-layer perceptron is proposed. It is shown that the proposed
method is a generalization of recently successful methods of dropout (Hinton et
al., 2012), explicit noise injection (Vincent et al., 2010; Bishop, 1995) and
semantic hashing (Salakhutdinov &amp; Hinton, 2009). Under the proposed framework,
an extension of dropout which allows using separate dropping probabilities for
different hidden neurons, or layers, is found to be available. The use of
different dropping probabilities for hidden layers separately is empirically
investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2806</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2806</id><created>2013-06-12</created><authors><author><keyname>Abdulla</keyname><forenames>Parosh Aziz</forenames></author><author><keyname>Mayr</keyname><forenames>Richard</forenames></author><author><keyname>Sangnier</keyname><forenames>Arnaud</forenames></author><author><keyname>Sproston</keyname><forenames>Jeremy</forenames></author></authors><title>Solving Parity Games on Integer Vectors</title><categories>cs.LO cs.GT</categories><comments>30 pages</comments><report-no>EDI-INF-RR-1417</report-no><msc-class>68Q60</msc-class><acm-class>D.2.2; D.2.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider parity games on infinite graphs where configurations are
represented by control-states and integer vectors. This framework subsumes two
classic game problems: parity games on vector addition systems with states
(vass) and multidimensional energy parity games. We show that the
multidimensional energy parity game problem is inter-reducible with a subclass
of single-sided parity games on vass where just one player can modify the
integer counters and the opponent can only change control-states. Our main
result is that the minimal elements of the upward-closed winning set of these
single-sided parity games on vass are computable. This implies that the Pareto
frontier of the minimal initial credit needed to win multidimensional energy
parity games is also computable, solving an open question from the literature.
Moreover, our main result implies the decidability of weak simulation
preorder/equivalence between finite-state systems and vass, and the
decidability of model checking vass with a large fragment of the modal
mu-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2815</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2815</id><created>2013-06-12</created><authors><author><keyname>Kejlberg-Rasmussen</keyname><forenames>Casper</forenames></author><author><keyname>Tao</keyname><forenames>Yufei</forenames></author><author><keyname>Tsakalidis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Tsichlas</keyname><forenames>Kostas</forenames></author><author><keyname>Yoon</keyname><forenames>Jeonghun</forenames></author></authors><title>I/O-Efficient Planar Range Skyline and Attrition Priority Queues</title><categories>cs.DS</categories><comments>Appeared at PODS 2013, New York, 19 pages, 10 figures. arXiv admin
  note: text overlap with arXiv:1208.4511, arXiv:1207.2341</comments><acm-class>F.2.2; H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the planar range skyline reporting problem, we store a set P of n 2D
points in a structure such that, given a query rectangle Q = [a_1, a_2] x [b_1,
b_2], the maxima (a.k.a. skyline) of P \cap Q can be reported efficiently. The
query is 3-sided if an edge of Q is grounded, giving rise to two variants:
top-open (b_2 = \infty) and left-open (a_1 = -\infty) queries.
  All our results are in external memory under the O(n/B) space budget, for
both the static and dynamic settings:
  * For static P, we give structures that answer top-open queries in O(log_B n
+ k/B), O(loglog_B U + k/B), and O(1 + k/B) I/Os when the universe is R^2, a U
x U grid, and a rank space grid [O(n)]^2, respectively (where k is the number
of reported points). The query complexity is optimal in all cases.
  * We show that the left-open case is harder, such that any linear-size
structure must incur \Omega((n/B)^e + k/B) I/Os for a query. We show that this
case is as difficult as the general 4-sided queries, for which we give a static
structure with the optimal query cost O((n/B)^e + k/B).
  * We give a dynamic structure that supports top-open queries in O(log_2B^e
(n/B) + k/B^1-e) I/Os, and updates in O(log_2B^e (n/B)) I/Os, for any e
satisfying 0 \le e \le 1. This leads to a dynamic structure for 4-sided queries
with optimal query cost O((n/B)^e + k/B), and amortized update cost O(log
(n/B)).
  As a contribution of independent interest, we propose an I/O-efficient
version of the fundamental structure priority queue with attrition (PQA). Our
PQA supports FindMin, DeleteMin, and InsertAndAttrite all in O(1) worst case
I/Os, and O(1/B) amortized I/Os per operation.
  We also add the new CatenateAndAttrite operation that catenates two PQAs in
O(1) worst case and O(1/B) amortized I/Os. This operation is a non-trivial
extension to the classic PQA of Sundar, even in internal memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2827</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2827</id><created>2013-06-12</created><authors><author><keyname>Meulemans</keyname><forenames>Wouter</forenames></author></authors><title>Map Matching with Simplicity Constraints</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a map matching problem, the task of finding in an embedded graph a
path that has low distance to a given curve in R^2. The Fr\'echet distance is a
common measure for this problem. Efficient methods exist to compute the best
path according to this measure. However, these methods cannot guarantee that
the result is simple (i.e. it does not intersect itself) even if the given
curve is simple. In this paper, we prove that it is in fact NP-complete to
determine the existence a simple cycle in a planar straight-line embedding of a
graph that has at most a given Fr\'echet distance to a given simple closed
curve. We also consider the implications of our proof on some variants of the
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2833</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2833</id><created>2013-06-12</created><authors><author><keyname>Di Pietro</keyname><forenames>Roberto</forenames></author><author><keyname>Mancini</keyname><forenames>Luigi V.</forenames></author><author><keyname>Villani</keyname><forenames>Antonio</forenames></author><author><keyname>Vitali</keyname><forenames>Domenico</forenames></author></authors><title>Mapping the File Systems Genome: rationales, technique, results and
  applications</title><categories>cs.CR</categories><comments>16 pages, 5 image</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides evidence of a feature of Hard-Disk Drives (HDDs), that we
call File System Genome. Such a feature is originated by the areas where (on
the HDD) the file blocks are placed by the operating system during the
installation procedure. It appears from our study that the File System Genome
is a distinctive and unique feature of each indi- vidual HDD. In particular,
our extensive set of experiments shows that the installation of the same
operating system on two identical hardware configurations generates two
different File System Genomes. Further, the application of sound information
theory tools, such as min entropy, show that the differences between two File
System Genome are considerably relevant. The results provided in this paper
constitute the scientific basis for a number of applications in various fields
of information technology, such as forensic identification and security.
Finally, this work also paves the way for the application of the highlighted
technique to other classes of mass-storage devices (e.g. SSDs, Flash memories).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2838</identifier>
 <datestamp>2015-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2838</id><created>2013-06-12</created><authors><author><keyname>Aerts</keyname><forenames>Diederik</forenames></author><author><keyname>Broekaert</keyname><forenames>Jan</forenames></author><author><keyname>Sozzo</keyname><forenames>Sandro</forenames></author><author><keyname>Veloz</keyname><forenames>Tomas</forenames></author></authors><title>The Quantum Challenge in Concept Theory and Natural Language Processing</title><categories>cs.CL cs.IR quant-ph</categories><comments>5 pages</comments><journal-ref>Proceedings of the 25th International Conference on System
  Research, Informatics &amp; Cybernetics (pp. 13-17). Ed.. E. G. Lasker, IIAS,
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mathematical formalism of quantum theory has been successfully used in
human cognition to model decision processes and to deliver representations of
human knowledge. As such, quantum cognition inspired tools have improved
technologies for Natural Language Processing and Information Retrieval. In this
paper, we overview the quantum cognition approach developed in our Brussels
team during the last two decades, specifically our identification of quantum
structures in human concepts and language, and the modeling of data from
psychological and corpus-text-based experiments. We discuss our
quantum-theoretic framework for concepts and their conjunctions/disjunctions in
a Fock-Hilbert space structure, adequately modeling a large amount of data
collected on concept combinations. Inspired by this modeling, we put forward
elements for a quantum contextual and meaning-based approach to information
technologies in which 'entities of meaning' are inversely reconstructed from
texts, which are considered as traces of these entities' states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2843</identifier>
 <datestamp>2015-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2843</id><created>2013-06-11</created><updated>2013-06-23</updated><authors><author><keyname>Simeonov</keyname><forenames>Plamen L.</forenames></author></authors><title>On Some Recent Insights in Integral Biomathics</title><categories>cs.CE</categories><comments>24 pages, 0 figures. In Journal Progress in Biophysics and Molecular
  Biology, 2013</comments><journal-ref>Progress in Biophysics and Molecular Biology, Vol. 113, Issues 1,
  2013, pp. 216-228</journal-ref><doi>10.1016/j.pbiomolbio.2013.06.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper summarizes the results in Integral Biomathics obtained to this
moment and provides an outlook for future research in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2859</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2859</id><created>2013-06-11</created><authors><author><keyname>Lenssen</keyname><forenames>Nathan</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author></authors><title>On the Mathematics of Music: From Chords to Fourier Analysis</title><categories>math.HO cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematics is a far reaching discipline and its tools appear in many
applications. In this paper we discuss its role in music and signal processing
by revisiting the use of mathematics in algorithms that can extract chord
information from recorded music. We begin with a light introduction to the
theory of music and motivate the use of Fourier analysis in audio processing.
We introduce the discrete and continuous Fourier transforms and investigate
their use in extracting important information from audio data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2861</identifier>
 <datestamp>2013-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2861</id><created>2013-06-12</created><updated>2013-12-17</updated><authors><author><keyname>Frigola</keyname><forenames>Roger</forenames></author><author><keyname>Lindsten</keyname><forenames>Fredrik</forenames></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas B.</forenames></author><author><keyname>Rasmussen</keyname><forenames>Carl E.</forenames></author></authors><title>Bayesian Inference and Learning in Gaussian Process State-Space Models
  with Particle MCMC</title><categories>stat.ML cs.LG cs.SY</categories><journal-ref>Published in NIPS 2013, Advances in Neural Information Processing
  Systems 26, pp. 3156--3164</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  State-space models are successfully used in many areas of science,
engineering and economics to model time series and dynamical systems. We
present a fully Bayesian approach to inference \emph{and learning} (i.e. state
estimation and system identification) in nonlinear nonparametric state-space
models. We place a Gaussian process prior over the state transition dynamics,
resulting in a flexible model able to capture complex dynamical phenomena. To
enable efficient inference, we marginalize over the transition dynamics
function and infer directly the joint smoothing distribution using specially
tailored Particle Markov Chain Monte Carlo samplers. Once a sample from the
smoothing distribution is computed, the state transition predictive
distribution can be formulated analytically. Our approach preserves the full
nonparametric expressivity of the model and can make use of sparse Gaussian
processes to greatly reduce computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2862</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2862</id><created>2013-06-12</created><authors><author><keyname>Delgado</keyname><forenames>M.</forenames></author><author><keyname>Farr&#xe1;n</keyname><forenames>J. I.</forenames></author><author><keyname>Garc&#xed;a-S&#xe1;nchez</keyname><forenames>P. A.</forenames></author><author><keyname>Llena</keyname><forenames>D.</forenames></author></authors><title>On the weight hierarchy of codes coming from semigroups with two
  generators</title><categories>math.CO cs.IT math.IT math.NT</categories><comments>20 pages, 14 figures</comments><msc-class>11T71, 20M14, 11Y55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The weight hierarchy of one-point algebraic geometry codes can be estimated
by means of the generalized order bounds, which are described in terms of a
certain Weierstrass semigroup. The asymptotical behaviour of such bounds for r
&gt; 1 differs from that of the classical Feng-Rao distance (r=1) by the so-called
Feng-Rao numbers. This paper is addressed to compute the Feng-Rao numbers for
numerical semigroups of embedding dimension two (with two generators),
obtaining a closed simple formula for the general case by using numerical
semigroup techniques. These involve the computation of the Ap\'ery set with
respect to an integer of the semigroups under consideration. The formula
obtained is applied to lower-bounding the generalized Hamming weights,
improving the bound given by Kirfel and Pellikaan in terms of the classical
Feng-Rao distance. We also compare our bound with a modification of the
Griesmer bound, improving this one in many cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2863</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2863</id><created>2013-06-12</created><authors><author><keyname>Sun</keyname><forenames>Jun</forenames></author><author><keyname>Wu</keyname><forenames>Xiaojun</forenames></author><author><keyname>Palade</keyname><forenames>Vasile</forenames></author><author><keyname>Fang</keyname><forenames>Wei</forenames></author><author><keyname>Shi</keyname><forenames>Yuhui</forenames></author></authors><title>Random Drift Particle Swarm Optimization</title><categories>cs.AI cs.NE math.OC</categories><comments>The paper is the work in progress on particle swarm optimization. It
  has 41 pages and 7 figures</comments><msc-class>68T20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random drift particle swarm optimization (RDPSO) algorithm, inspired by
the free electron model in metal conductors placed in an external electric
field, is presented, systematically analyzed and empirically studied in this
paper. The free electron model considers that electrons have both a thermal and
a drift motion in a conductor that is placed in an external electric field. The
motivation of the RDPSO algorithm is described first, and the velocity equation
of the particle is designed by simulating the thermal motion as well as the
drift motion of the electrons, both of which lead the electrons to a location
with minimum potential energy in the external electric field. Then, a
comprehensive analysis of the algorithm is made, in order to provide a deep
insight into how the RDPSO algorithm works. It involves a theoretical analysis
and the simulation of the stochastic dynamical behavior of a single particle in
the RDPSO algorithm. The search behavior of the algorithm itself is also
investigated in detail, by analyzing the interaction between the particles.
Some variants of the RDPSO algorithm are proposed by incorporating different
random velocity components with different neighborhood topologies. Finally,
empirical studies on the RDPSO algorithm are performed by using a set of
benchmark functions from the CEC2005 benchmark suite. Based on the theoretical
analysis of the particle's behavior, two methods of controlling the algorithmic
parameters are employed, followed by an experimental analysis on how to select
the parameter values, in order to obtain a good overall performance of the
RDPSO algorithm and its variants in real-world applications. A further
performance comparison between the RDPSO algorithms and other variants of PSO
is made to prove the efficiency of the RDPSO algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2864</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2864</id><created>2013-06-12</created><authors><author><keyname>Moreira</keyname><forenames>Catarina</forenames></author><author><keyname>Wichert</keyname><forenames>Andreas</forenames></author></authors><title>Finding Academic Experts on a MultiSensor Approach using Shannon's
  Entropy</title><categories>cs.AI cs.IR</categories><journal-ref>Journal of Expert Systems with Applications, 2013, volume 40,
  issue 14</journal-ref><doi>10.1016/j.eswa.2013.04.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expert finding is an information retrieval task concerned with the search for
the most knowledgeable people, in some topic, with basis on documents
describing peoples activities. The task involves taking a user query as input
and returning a list of people sorted by their level of expertise regarding the
user query. This paper introduces a novel approach for combining multiple
estimators of expertise based on a multisensor data fusion framework together
with the Dempster-Shafer theory of evidence and Shannon's entropy. More
specifically, we defined three sensors which detect heterogeneous information
derived from the textual contents, from the graph structure of the citation
patterns for the community of experts, and from profile information about the
academic experts. Given the evidences collected, each sensor may define
different candidates as experts and consequently do not agree in a final
ranking decision. To deal with these conflicts, we applied the Dempster-Shafer
theory of evidence combined with Shannon's Entropy formula to fuse this
information and come up with a more accurate and reliable final ranking list.
Experiments made over two datasets of academic publications from the Computer
Science domain attest for the adequacy of the proposed approach over the
traditional state of the art approaches. We also made experiments against
representative supervised state of the art algorithms. Results revealed that
the proposed method achieved a similar performance when compared to these
supervised techniques, confirming the capabilities of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2866</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2866</id><created>2013-06-12</created><updated>2013-12-27</updated><authors><author><keyname>Wang</keyname><forenames>Shenghui</forenames></author><author><keyname>Isaac</keyname><forenames>Antoine</forenames></author><author><keyname>Charles</keyname><forenames>Valentine</forenames></author><author><keyname>Koopman</keyname><forenames>Rob</forenames></author><author><keyname>Agoropoulou</keyname><forenames>Anthi</forenames></author><author><keyname>van der Werf</keyname><forenames>Titia</forenames></author></authors><title>Hierarchical structuring of Cultural Heritage objects within large
  aggregations</title><categories>cs.DL</categories><comments>The paper has been published in the proceedings of the TPDL
  conference, see http://tpdl2013.info. For the final version see
  http://link.springer.com/chapter/10.1007%2F978-3-642-40501-3_25</comments><doi>10.1007/978-3-642-40501-3_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Huge amounts of cultural content have been digitised and are available
through digital libraries and aggregators like Europeana.eu. However, it is not
easy for a user to have an overall picture of what is available nor to find
related objects. We propose a method for hier- archically structuring cultural
objects at different similarity levels. We describe a fast, scalable clustering
algorithm with an automated field selection method for finding semantic
clusters. We report a qualitative evaluation on the cluster categories based on
records from the UK and a quantitative one on the results from the complete
Europeana dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2869</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2869</id><created>2013-06-12</created><updated>2013-12-27</updated><authors><author><keyname>Charles</keyname><forenames>Valentine</forenames></author><author><keyname>Isaac</keyname><forenames>Antoine</forenames></author><author><keyname>Fernie</keyname><forenames>Kate</forenames></author><author><keyname>Dallas</keyname><forenames>Costis</forenames></author><author><keyname>Gavrilis</keyname><forenames>Dimitris</forenames></author><author><keyname>Angelis</keyname><forenames>Stavros</forenames></author></authors><title>Achieving interoperability between the CARARE schema for monuments and
  sites and the Europeana Data Model</title><categories>cs.DL</categories><comments>The final version of this paper is openly published in the
  proceedings of the Dublin Core 2013 conference, see
  http://dcevents.dublincore.org/IntConf/dc-2013/paper/view/171</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mapping between different data models in a data aggregation context always
presents significant interoperability challenges. In this paper, we describe
the challenges faced and solutions developed when mapping the CARARE schema
designed for archaeological and architectural monuments and sites to the
Europeana Data Model (EDM), a model based on Linked Data principles, for the
purpose of integrating more than two million metadata records from national
monument collections and databases across Europe into the Europeana digital
library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2878</identifier>
 <datestamp>2015-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2878</id><created>2013-06-12</created><updated>2015-08-09</updated><authors><author><keyname>Perlaza</keyname><forenames>Samir M.</forenames></author><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Perfect Output Feedback in the Two-User Decentralized Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>Revised version (Aug. 2015)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the $\eta$-Nash equilibrium ($\eta$-NE) region of the two-user
Gaussian interference channel (IC) with perfect output feedback is approximated
to within $1$ bit/s/Hz and $\eta$ arbitrarily close to $1$ bit/s/Hz. The
relevance of the $\eta$-NE region is that it provides the set of rate-pairs
that are achievable and stable in the IC when both transmitter-receiver pairs
autonomously tune their own transmit-receive configurations seeking an
$\eta$-optimal individual transmission rate. Therefore, any rate tuple outside
the $\eta$-NE region is not stable as there always exists one link able to
increase by at least $\eta$ bits/s/Hz its own transmission rate by updating its
own transmit-receive configuration. The main insights that arise from this work
are: $(i)$ The $\eta$-NE region achieved with feedback is larger than or equal
to the $\eta$-NE region without feedback. More importantly, for each rate pair
achievable at an $\eta$-NE without feedback, there exists at least one rate
pair achievable at an $\eta$-NE with feedback that is weakly Pareto superior.
$(ii)$ There always exists an $\eta$-NE transmit-receive configuration that
achieves a rate pair that is at most $1$ bit/s/Hz per user away from the outer
bound of the capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2882</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2882</id><created>2013-06-12</created><authors><author><keyname>Gao</keyname><forenames>Haichang</forenames></author><author><keyname>Ren</keyname><forenames>Zhongjie</forenames></author><author><keyname>Chang</keyname><forenames>Xiuling</forenames></author><author><keyname>Liu</keyname><forenames>Xiyang</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A New Graphical Password Scheme Resistant to Shoulder-Surfing</title><categories>cs.CR</categories><comments>Proceedings of the International Conference on CyberWorlds, 20-22
  October 2010, Singapore, 194-199, 2010. arXiv admin note: text overlap with
  arXiv:1305.7482</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shoulder-surfing is a known risk where an attacker can capture a password by
direct observation or by recording the authentication session. Due to the
visual interface, this problem has become exacerbated in graphical passwords.
There have been some graphical schemes resistant or immune to shoulder-surfing,
but they have significant usability drawbacks, usually in the time and effort
to log in. In this paper, we propose and evaluate a new shoulder-surfing
resistant scheme which has a desirable usability for PDAs. Our inspiration
comes from the drawing input method in DAS and the association mnemonics in
Story for sequence retrieval. The new scheme requires users to draw a curve
across their password images orderly rather than click directly on them. The
drawing input trick along with the complementary measures, such as erasing the
drawing trace, displaying degraded images, and starting and ending with
randomly designated images provide a good resistance to shouldersurfing. A
preliminary user study showed that users were able to enter their passwords
accurately and to remember them over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2885</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2885</id><created>2013-06-12</created><authors><author><keyname>Gao</keyname><forenames>Haichang</forenames></author><author><keyname>Liu</keyname><forenames>Honggang</forenames></author><author><keyname>Yao</keyname><forenames>Dan</forenames></author><author><keyname>Liu</keyname><forenames>Xiyang</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>An audio CAPTCHA to distinguish humans from computers</title><categories>cs.CR cs.CY</categories><comments>Third International Symposium on Electronic Commerce and Security,
  ISECS2010, 265-269, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CAPTCHAs are employed as a security measure to differentiate human users from
bots. A new sound-based CAPTCHA is proposed in this paper, which exploits the
gaps between human voice and synthetic voice rather than relays on the auditory
perception of human. The user is required to read out a given sentence, which
is selected randomly from a specified book. The generated audio file will be
analyzed automatically to judge whether the user is a human or not. In this
paper, the design of the new CAPTCHA, the analysis of the audio files, and the
choice of the audio frame window function are described in detail. And also,
some experiments are conducted to fix the critical threshold and the
coefficients of three indicators to ensure the security. The proposed audio
CAPTCHA is proved accessible to users. The user study has shown that the human
success rate reaches approximately 97% and the pass rate of attack software
using Microsoft SDK 5.1 is only 4%. The experiments also indicated that it
could be solved by most human users in less than 14 seconds and the average
time is only 7.8 seconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2898</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2898</id><created>2013-06-12</created><authors><author><keyname>Figueredo</keyname><forenames>Grazziela P.</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Defining a Simulation Strategy for Cancer Immunocompetence</title><categories>cs.CE q-bio.TO</categories><comments>Proceedings of the 9th International Conference on Artificial Immune
  Systems (ICARIS 2010), 4-17, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although there are various types of cancer treatments, none of these
currently take into account the effect of ageing of the immune system and hence
altered responses to cancer. Recent studies have shown that in vitro
stimulation of T cells can help in the treatment of patients. There are many
factors that have to be considered when simulating an organism's
immunocompetence. Our particular interest lies in the study of loss of
immunocompetence with age. We are trying to answer questions such as: Given a
certain age of a patient, how fit is their immune system to fight cancer? Would
an immune boost improve the effectiveness of a cancer treatment given the
patient's immune phenotype and age? We believe that understanding the processes
of immune system ageing and degradation through computer simulation may help in
answering these questions. Specifically, we have decided to look at the change
in numbers of naive T cells with age, as they play a important role in
responses to cancer and anti-tumour vaccination. In this work we present an
agent-based simulation model to understand the interactions which influence the
naive T cell populations over time. Our agent model is based on existing
mathematical system dynamic model, but in comparisons offers better scope for
customisation and detailed analysis. We believe that the results obtained can
in future help with the modelling of T cell populations inside tumours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2906</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2906</id><created>2013-06-12</created><authors><author><keyname>Zergat</keyname><forenames>Kawthar Yasmine</forenames></author><author><keyname>Amrouche</keyname><forenames>Abderrahmane</forenames></author></authors><title>Robust Support Vector Machines for Speaker Verification Task</title><categories>cs.LG cs.SD stat.ML</categories><comments>5 pages,5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important step in speaker verification is extracting features that best
characterize the speaker voice. This paper investigates a front-end processing
that aims at improving the performance of speaker verification based on the
SVMs classifier, in text independent mode. This approach combines features
based on conventional Mel-cepstral Coefficients (MFCCs) and Line Spectral
Frequencies (LSFs) to constitute robust multivariate feature vectors. To reduce
the high dimensionality required for training these feature vectors, we use a
dimension reduction method called principal component analysis (PCA). In order
to evaluate the robustness of these systems, different noisy environments have
been used. The obtained results using TIMIT database showed that, using the
paradigm that combines these spectral cues leads to a significant improvement
in verification accuracy, especially with PCA reduction for low signal-to-noise
ratio noisy environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2918</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2918</id><created>2013-06-12</created><authors><author><keyname>Bravo</keyname><forenames>Mario</forenames><affiliation>ISCI</affiliation></author><author><keyname>Faure</keyname><forenames>Mathieu</forenames><affiliation>AMSE</affiliation></author></authors><title>Reinforcement learning with restrictions on the action set</title><categories>cs.GT cs.LG math.PR</categories><comments>28 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a 2-player normal-form game repeated over time. We introduce an
adaptive learning procedure, where the players only observe their own realized
payoff at each stage. We assume that agents do not know their own payoff
function, and have no information on the other player. Furthermore, we assume
that they have restrictions on their own action set such that, at each stage,
their choice is limited to a subset of their action set. We prove that the
empirical distributions of play converge to the set of Nash equilibria for
zero-sum and potential games, and games where one player has two actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2931</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2931</id><created>2013-06-12</created><authors><author><keyname>Goyal</keyname><forenames>Prachi</forenames></author><author><keyname>Kamat</keyname><forenames>Vikram</forenames></author><author><keyname>Misra</keyname><forenames>Neeldhara</forenames></author></authors><title>On the Parameterized Complexity of the Maximum Edge Coloring Problem</title><categories>cs.DS cs.DM</categories><comments>18 pages, 2 figures, accepted at MFCS 2013. arXiv admin note: text
  overlap with arXiv:1009.0806 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the parameterized complexity of the following edge coloring
problem motivated by the problem of channel assignment in wireless networks.
For an integer q&gt;1 and a graph G, the goal is to find a coloring of the edges
of G with the maximum number of colors such that every vertex of the graph sees
at most q colors. This problem is NP-hard for q&gt;1, and has been well-studied
from the point of view of approximation. Our main focus is the case when q=2,
which is already theoretically intricate and practically relevant. We show
fixed-parameter tractable algorithms for both the standard and the dual
parameter, and for the latter problem, the result is based on a linear vertex
kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2932</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2932</id><created>2013-06-12</created><updated>2013-06-28</updated><authors><author><keyname>Ghosh</keyname><forenames>Shamik</forenames></author></authors><title>On certain classes of graceful lobsters</title><categories>math.CO cs.DM</categories><comments>23 pages, 15 figures</comments><msc-class>05C78</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph G=(V,E) with m edges is graceful if it has a distinct vertex labeling
f, a map from V into the set{0,1,2,3,...,m} which induces a distinct edge
labeling |f(u)-f(v)| for edges uv in E. The famous Ringel-Kotzig conjecture
(1964) is that all trees are graceful. The base of a tree T is obtained from T
by deleting its one-degree vertices. A caterpillar is a tree whose base is a
path and a lobster is a tree whose base is a caterpillar. Paths and
caterpillars are known to be graceful. Next it was conjectured by Bermond
(1979) that all lobsters are graceful. In this paper we describe various
methods of joining graceful graphs and \alpha-labeled graphs using the
adjacency matrix characterization that initiated by Bloom (1979) and others. We
apply these results to obtain some classes of graceful lobsters and indicate
how to obtain some others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2935</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2935</id><created>2013-06-12</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Slimy hairs: Hair sensors made with slime mould</title><categories>cs.ET physics.bio-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slime mould Physarum polycephalum is a large single cell visible by unaided
eye. We design a slime mould implementation of a tactile hair, where the slime
mould responds to repeated deflection of hair by an immediate high-amplitude
spike and a prolonged increase in amplitude and width of its oscillation
impulses. We demonstrate that signal-to-noise ratio of the Physarum tactile
hair sensor averages near six for the immediate response and two for the
prolonged response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2967</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2967</id><created>2013-06-12</created><updated>2013-10-28</updated><authors><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author><author><keyname>Sadeghi</keyname><forenames>Mostafa</forenames></author></authors><title>Optimization of Clustering for Clustering-based Image Denoising</title><categories>cs.CV</categories><comments>The paper have some problems that is needed to be re-written. it has
  been withdrawn</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, the problem of de-noising of an image contaminated with
additive white Gaussian noise (AWGN) is studied. This subject has been
continued to be an open problem in signal processing for more than 50 years. In
the present paper, we suggest a method based on global clustering of image
constructing blocks. Noting that the type of clustering plays an important role
in clustering-based de-noising methods, we address two questions about the
clustering. First, which parts of data should be considered for clustering?
Second, what data clustering method is suitable for de-noising? Clustering is
exploited to learn an over complete dictionary. By obtaining sparse
decomposition of the noisy image blocks in terms of the dictionary atoms, the
de-noised version is achieved. Experimental results show that our dictionary
learning framework outperforms traditional dictionary learning methods such as
K-SVD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2972</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2972</id><created>2013-06-12</created><authors><author><keyname>Bent</keyname><forenames>Russell</forenames><affiliation>LANL</affiliation></author><author><keyname>Bienstock</keyname><forenames>Daniel</forenames><affiliation>Columbia U</affiliation></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames><affiliation>LANL</affiliation></author></authors><title>Synchronization-Aware and Algorithm-Efficient Chance Constrained Optimal
  Power Flow</title><categories>math.OC cs.SY physics.soc-ph</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most common control decisions faced by power system operators is
the question of how to dispatch generation to meet demand for power. This is a
complex optimization problem that includes many nonlinear, non convex
constraints as well as inherent uncertainties about future demand for power and
available generation. In this paper we develop convex formulations to
appropriately model crucial classes of nonlinearities and stochastic effects.
We focus on solving a nonlinear optimal power flow (OPF) problem that includes
loss of synchrony constraints and models wind-farm caused fluctuations. In
particular, we develop (a) a convex formulation of the deterministic
phase-difference nonlinear Optimum Power Flow (OPF) problem; and (b) a
probabilistic chance constrained OPF for angular stability, thermal overloads
and generation limits that is computationally tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2978</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2978</id><created>2013-06-12</created><authors><author><keyname>Koch</keyname><forenames>Alexander</forenames></author><author><keyname>Krug</keyname><forenames>Marcus</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author></authors><title>Graphs with Plane Outside-Obstacle Representations</title><categories>cs.CG cs.DM cs.DS</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An \emph{obstacle representation} of a graph consists of a set of polygonal
obstacles and a distinct point for each vertex such that two points see each
other if and only if the corresponding vertices are adjacent. Obstacle
representations are a recent generalization of classical polygon--vertex
visibility graphs, for which the characterization and recognition problems are
long-standing open questions.
  In this paper, we study \emph{plane outside-obstacle representations}, where
all obstacles lie in the unbounded face of the representation and no two
visibility segments cross. We give a combinatorial characterization of the
biconnected graphs that admit such a representation. Based on this
characterization, we present a simple linear-time recognition algorithm for
these graphs. As a side result, we show that the plane vertex--polygon
visibility graphs are exactly the maximal outerplanar graphs and that every
chordal outerplanar graph has an outside-obstacle representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2979</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2979</id><created>2013-06-12</created><updated>2014-07-21</updated><authors><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Bhojanapalli</keyname><forenames>Srinadh</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Ward</keyname><forenames>Rachel</forenames></author></authors><title>Completing Any Low-rank Matrix, Provably</title><categories>stat.ML cs.IT cs.LG math.IT</categories><comments>Added a new necessary condition(Theorem 6) and a result on completion
  of row coherent matrices(Corollary 4). Partial results appeared in the
  International Conference on Machine Learning 2014, under the title 'Coherent
  Matrix Completion'. (34 pages, 4 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix completion, i.e., the exact and provable recovery of a low-rank matrix
from a small subset of its elements, is currently only known to be possible if
the matrix satisfies a restrictive structural constraint---known as {\em
incoherence}---on its row and column spaces. In these cases, the subset of
elements is sampled uniformly at random.
  In this paper, we show that {\em any} rank-$ r $ $ n$-by-$ n $ matrix can be
exactly recovered from as few as $O(nr \log^2 n)$ randomly chosen elements,
provided this random choice is made according to a {\em specific biased
distribution}: the probability of any element being sampled should be
proportional to the sum of the leverage scores of the corresponding row, and
column. Perhaps equally important, we show that this specific form of sampling
is nearly necessary, in a natural precise sense; this implies that other
perhaps more intuitive sampling schemes fail.
  We further establish three ways to use the above result for the setting when
leverage scores are not known \textit{a priori}: (a) a sampling strategy for
the case when only one of the row or column spaces are incoherent, (b) a
two-phase sampling procedure for general matrices that first samples to
estimate leverage scores followed by sampling for exact recovery, and (c) an
analysis showing the advantages of weighted nuclear/trace-norm minimization
over the vanilla un-weighted formulation for the case of non-uniform sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2988</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2988</id><created>2013-06-12</created><updated>2013-08-22</updated><authors><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Tripathi</keyname><forenames>Pushkar</forenames></author></authors><title>Matching with our Eyes Closed</title><categories>cs.DS cs.GT</categories><comments>This paper has been withdrawn by the authors. The result claiming a
  factor 0.56 algorithm is invalid because of a crucial bug in Claim 2 which
  was brought to our attention by Matthias Poloczek, Frans Schalekamp, and Anke
  van Zuylen</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by an application in kidney exchange, we study the following
query-commit problem: we are given the set of vertices of a non-bipartite graph
G. The set of edges in this graph are not known ahead of time. We can query any
pair of vertices to determine if they are adjacent. If the queried edge exists,
we are committed to match the two endpoints. Our objective is to maximize the
size of the matching.
  This restriction in the amount of information available to the algorithm
constraints us to implement myopic, greedy-like algorithms. A simple
deterministic greedy algorithm achieves a factor 1/2 which is tight for
deterministic algorithms. An important open question in this direction is to
give a randomized greedy algorithm that has a significantly better
approximation factor. This question was first asked almost 20 years ago by Dyer
and Frieze [9] where they showed that a natural randomized strategy of picking
edges uniformly at random doesn't help and has an approximation factor of 1/2 +
o(1). They left it as an open question to devise a better randomized greedy
algorithm. In subsequent work, Aronson, Dyer, Frieze, and Suen [2] gave a
different randomized greedy algorithm and showed that it attains a factor 0.5 +
epsilon where epsilon is 0.0000025.
  In this paper we propose and analyze a new randomized greedy algorithm for
finding a large matching in a general graph and use it to solve the query
commit problem mentioned above. We show that our algorithm attains a factor of
at least 0.56, a significant improvement over 0.50000025. We also show that no
randomized algorithm can have an approximation factor better than 0.7916 for
the query commit problem. For another large and interesting class of randomized
algorithms that we call vertex-iterative algorithms, we show that no
vertex-iterative algorithm can have an approximation factor better than 0.75.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.2999</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.2999</id><created>2013-06-12</created><authors><author><keyname>Fan</keyname><forenames>Xuhui</forenames></author><author><keyname>Cao</keyname><forenames>Longbing</forenames></author><author><keyname>Da Xu</keyname><forenames>Richard Yi</forenames></author></authors><title>Dynamic Infinite Mixed-Membership Stochastic Blockmodel</title><categories>cs.SI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directional and pairwise measurements are often used to model
inter-relationships in a social network setting. The Mixed-Membership
Stochastic Blockmodel (MMSB) was a seminal work in this area, and many of its
capabilities were extended since then. In this paper, we propose the
\emph{Dynamic Infinite Mixed-Membership stochastic blockModel (DIM3)}, a
generalised framework that extends the existing work to a potentially infinite
number of communities and mixture memberships for each of the network's nodes.
This model is in a dynamic setting, where additional model parameters are
introduced to reflect the degree of persistence between one's memberships at
consecutive times. Accordingly, two effective posterior sampling strategies and
their results are presented using both synthetic and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3000</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3000</id><created>2013-06-12</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Pszona</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>Cole's Parametric Search Technique Made Practical</title><categories>cs.DS cs.CG</categories><comments>12 pages, 4 figures. To appear at the 25th Canadian Conference on
  Computational Geometry (CCCG 2013)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parametric search has been widely used in geometric algorithms. Cole's
improvement provides a way of saving a logarithmic factor in the running time
over what is achievable using the standard method. Unfortunately, this
improvement comes at the expense of making an already complicated algorithm
even more complex; hence, this technique has been mostly of theoretical
interest. In this paper, we provide an algorithm engineering framework that
allows for the same asymptotic complexity to be achieved probabilistically in a
way that is both simple and practical (i.e., suitable for actual
implementation). The main idea of our approach is to show that a variant of
quicksort, known as boxsort, can be used to drive comparisons, instead of using
a sorting network, like the complicated AKS network, or an EREW parallel
sorting algorithm, like the fairly intricate parallel mergesort algorithm. This
results in a randomized optimization algorithm with a running time matching
that of using Cole's method, with high probability, while also being practical.
We show how this results in practical implementations of some geometric
algorithms utilizing parametric searching and provide experimental results that
prove practicality of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3002</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3002</id><created>2013-06-12</created><authors><author><keyname>Fan</keyname><forenames>Xuhui</forenames></author><author><keyname>Cao</keyname><forenames>Longbing</forenames></author></authors><title>A Convergence Theorem for the Graph Shift-type Algorithms</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph Shift (GS) algorithms are recently focused as a promising approach for
discovering dense subgraphs in noisy data. However, there are no theoretical
foundations for proving the convergence of the GS Algorithm. In this paper, we
propose a generic theoretical framework consisting of three key GS components:
simplex of generated sequence set, monotonic and continuous objective function
and closed mapping. We prove that GS algorithms with such components can be
transformed to fit the Zangwill's convergence theorem, and the sequence set
generated by the GS procedures always terminates at a local maximum, or at
worst, contains a subsequence which converges to a local maximum of the
similarity measure function. The framework is verified by expanding it to other
GS-type algorithms and experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3003</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3003</id><created>2013-06-12</created><authors><author><keyname>Fan</keyname><forenames>Xuhui</forenames></author><author><keyname>Zeng</keyname><forenames>Yiling</forenames></author><author><keyname>Cao</keyname><forenames>Longbing</forenames></author></authors><title>Non-parametric Power-law Data Clustering</title><categories>cs.LG cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has always been a great challenge for clustering algorithms to
automatically determine the cluster numbers according to the distribution of
datasets. Several approaches have been proposed to address this issue,
including the recent promising work which incorporate Bayesian Nonparametrics
into the $k$-means clustering procedure. This approach shows simplicity in
implementation and solidity in theory, while it also provides a feasible way to
inference in large scale datasets. However, several problems remains unsolved
in this pioneering work, including the power-law data applicability, mechanism
to merge centers to avoid the over-fitting problem, clustering order problem,
e.t.c.. To address these issues, the Pitman-Yor Process based k-means (namely
\emph{pyp-means}) is proposed in this paper. Taking advantage of the Pitman-Yor
Process, \emph{pyp-means} treats clusters differently by dynamically and
adaptively changing the threshold to guarantee the generation of power-law
clustering results. Also, one center agglomeration procedure is integrated into
the implementation to be able to merge small but close clusters and then
adaptively determine the cluster number. With more discussion on the clustering
order, the convergence proof, complexity analysis and extension to spectral
clustering, our approach is compared with traditional clustering algorithm and
variational inference methods. The advantages and properties of pyp-means are
validated by experiments on both synthetic datasets and real world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3004</identifier>
 <datestamp>2013-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3004</id><created>2013-06-12</created><updated>2013-06-19</updated><authors><author><keyname>Reingold</keyname><forenames>Omer</forenames></author><author><keyname>Steinke</keyname><forenames>Thomas</forenames></author><author><keyname>Vadhan</keyname><forenames>Salil</forenames></author></authors><title>Pseudorandomness for Regular Branching Programs via Fourier Analysis</title><categories>cs.CC</categories><comments>RANDOM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an explicit pseudorandom generator for oblivious, read-once,
permutation branching programs of constant width that can read their input bits
in any order. The seed length is $O(\log^2 n)$, where $n$ is the length of the
branching program. The previous best seed length known for this model was
$n^{1/2+o(1)}$, which follows as a special case of a generator due to
Impagliazzo, Meka, and Zuckerman (FOCS 2012) (which gives a seed length of
$s^{1/2+o(1)}$ for arbitrary branching programs of size $s$). Our techniques
also give seed length $n^{1/2+o(1)}$ for general oblivious, read-once branching
programs of width $2^{n^{o(1)}}$, which is incomparable to the results of
Impagliazzo et al.Our pseudorandom generator is similar to the one used by
Gopalan et al. (FOCS 2012) for read-once CNFs, but the analysis is quite
different; ours is based on Fourier analysis of branching programs. In
particular, we show that an oblivious, read-once, regular branching program of
width $w$ has Fourier mass at most $(2w^2)^k$ at level $k$, independent of the
length of the program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3007</identifier>
 <datestamp>2013-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3007</id><created>2013-06-12</created><updated>2013-11-13</updated><authors><author><keyname>Ichinose</keyname><forenames>Genki</forenames></author><author><keyname>Tenguishi</keyname><forenames>Yuto</forenames></author><author><keyname>Tanizawa</keyname><forenames>Toshihiro</forenames></author></authors><title>Robustness of cooperation on scale-free networks under continuous
  topological change</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>6 pages, 5 figures</comments><journal-ref>Physical Review E 88, 052808 (2013)</journal-ref><doi>10.1103/PhysRevE.88.052808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we numerically investigate the robustness of cooperation
clusters in prisoner's dilemma played on scale-free networks, where the network
topologies change by continuous removal and addition of nodes. Each removal and
addition can be either random or intentional. We therefore have four different
strategies in changing network topology: random removal and random addition
(RR), random removal and preferential addition (RP), targeted removal and
random addition (TR), and targeted removal and preferential addition (TP). We
find that cooperation clusters are most fragile against TR, while they are most
robust against RP, even for large values of the temptation coefficient for
defection. The effect of the degree mixing pattern of the network is not the
primary factor for the robustness of cooperation under continuous change in
network topology, which is quite different from the cases observed in static
networks. Cooperation clusters become more robust as the number of links of
hubs occupied by cooperators increase. Our results might infer the fact that a
huge variety of individuals is needed for maintaining global cooperation in
social networks in the real world where each node representing an individual is
constantly removed and added.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3011</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3011</id><created>2013-06-12</created><updated>2014-08-15</updated><authors><author><keyname>Patel</keyname><forenames>Utkarsh R.</forenames></author><author><keyname>Gustavsen</keyname><forenames>Bjorn</forenames></author><author><keyname>Triverio</keyname><forenames>Piero</forenames></author></authors><title>Proximity-Aware Calculation of Cable Series Impedance for Systems of
  Solid and Hollow Conductors</title><categories>cs.CE</categories><comments>Update: This paper has been accepted for publication in the IEEE
  Transactions on Power Delivery. DOI: 10.1109/TPWRD.2014.2330994</comments><doi>10.1109/TPWRD.2014.2330994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wide-band cable models for the prediction of electromagnetic transients in
power systems require the accurate calculation of the cable series impedance as
function of frequency. A surface current approach was recently proposed for
systems of round solid conductors, with inclusion of skin and proximity
effects. In this paper we extend the approach to include tubular conductors,
allowing to model realistic cables with tubular sheaths, armors and pipes. We
also include the effect of a lossy ground. A noteworthy feature of the proposed
technique is the accurate prediction of proximity effects, which can be of
major importance in three-phase, pipe type, and closely-packed single-core
cables. The new approach is highly efficient compared to finite elements. In
the case of a cross-bonded cable system featuring three phase conductors and
three screens, the proposed technique computes the required 120 frequency
samples in only six seconds of CPU time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3018</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3018</id><created>2013-06-13</created><authors><author><keyname>Ramos</keyname><forenames>Vitorino</forenames></author><author><keyname>Rodrigues</keyname><forenames>David M. S.</forenames></author><author><keyname>Lou&#xe7;&#xe3;</keyname><forenames>Jorge</forenames></author></authors><title>Second Order Swarm Intelligence</title><categories>cs.NE</categories><comments>10 pages, 5 figures, accepted to International Conference on Hybrid
  Artificial Intelligence Systems (HAIS 2013), Lecture Notes in Artificial
  Intelligence, LNAI Springer Series</comments><msc-class>68T05</msc-class><acm-class>I.2; F.1.1; I.2.11; I.2.8; G.1.6; C.2.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An artificial Ant Colony System (ACS) algorithm to solve general-purpose
combinatorial Optimization Problems (COP) that extends previous AC models [21]
by the inclusion of a negative pheromone, is here described. Several Travelling
Salesman Problem (TSP) were used as benchmark. We show that by using two
different sets of pheromones, a second-order co-evolved compromise between
positive and negative feedbacks achieves better results than single positive
feedback systems. The algorithm was tested against known NP-complete
combinatorial Optimization Problems, running on symmetrical TSP's. We show that
the new algorithm compares favourably against these benchmarks, accordingly to
recent biological findings by Robinson [26,27], and Gruter [28] where &quot;No
entry&quot; signals and negative feedback allows a colony to quickly reallocate the
majority of its foragers to superior food patches. This is the first time an
extended ACS algorithm is implemented with these successful characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3030</identifier>
 <datestamp>2014-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3030</id><created>2013-06-13</created><updated>2014-05-23</updated><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames></author><author><keyname>Engels</keyname><forenames>Christian</forenames></author><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author><author><keyname>Rao</keyname><forenames>B. V. Raghavendra</forenames></author></authors><title>Random Shortest Paths: Non-Euclidean Instances for Metric Optimization
  Problems</title><categories>cs.DS</categories><comments>To appear in Algorithmica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic analysis for metric optimization problems has mostly been
conducted on random Euclidean instances, but little is known about metric
instances drawn from distributions other than the Euclidean. This motivates our
study of random metric instances for optimization problems obtained as follows:
Every edge of a complete graph gets a weight drawn independently at random. The
distance between two nodes is then the length of a shortest path (with respect
to the weights drawn) that connects these nodes.
  We prove structural properties of the random shortest path metrics generated
in this way. Our main structural contribution is the construction of a good
clustering. Then we apply these findings to analyze the approximation ratios of
heuristics for matching, the traveling salesman problem (TSP), and the k-median
problem, as well as the running-time of the 2-opt heuristic for the TSP. The
bounds that we obtain are considerably better than the respective worst-case
bounds. This suggests that random shortest path metrics are easy instances,
similar to random Euclidean instances, albeit for completely different
structural reasons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3032</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3032</id><created>2013-06-13</created><authors><author><keyname>Kurihara</keyname><forenames>Kazutaka</forenames></author><author><keyname>Takasu</keyname><forenames>Masakazu</forenames></author><author><keyname>Sasao</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Seki</keyname><forenames>Hal</forenames></author><author><keyname>Narabu</keyname><forenames>Takayuki</forenames></author><author><keyname>Yamamoto</keyname><forenames>Mitsuo</forenames></author><author><keyname>Iida</keyname><forenames>Satoshi</forenames></author><author><keyname>Yamamoto</keyname><forenames>Hiroyuki</forenames></author></authors><title>A Face-like Structure Detection on Planet and Satellite Surfaces using
  Image Processing</title><categories>cs.CV</categories><comments>4 pages</comments><journal-ref>ACE 2013, LNCS 8253, Springer, pp. 564-567, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates that face-like structures are everywhere, and can be
de-tected automatically even with computers. Huge amount of satellite images of
the Earth, the Moon, the Mars are explored and many interesting face-like
structure are detected. Throughout this fact, we believe that science and
technologies can alert people not to easily become an occultist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3036</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3036</id><created>2013-06-13</created><authors><author><keyname>Afshar</keyname><forenames>Saeed</forenames></author><author><keyname>Cohen</keyname><forenames>Gregory</forenames></author><author><keyname>Wang</keyname><forenames>Runchun</forenames></author><author><keyname>van Schaik</keyname><forenames>Andre</forenames></author><author><keyname>Tapson</keyname><forenames>Jonathan</forenames></author><author><keyname>Lehmann</keyname><forenames>Torsten</forenames></author><author><keyname>Hamilton</keyname><forenames>Tara Julia</forenames></author></authors><title>The Ripple Pond: Enabling Spiking Networks to See</title><categories>cs.NE q-bio.NC</categories><comments>Submitted to Frontiers in Neuromorphic Engineering (June 12, 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the biologically inspired Ripple Pond Network (RPN),
a simply connected spiking neural network that, operating together with
recently proposed PolyChronous Networks (PCN), enables rapid, unsupervised,
scale and rotation invariant object recognition using efficient spatio-temporal
spike coding. The RPN has been developed as a hardware solution linking
previously implemented neuromorphic vision and memory structures capable of
delivering end-to-end high-speed, low-power and low-resolution recognition for
mobile and autonomous applications where slow, highly sophisticated and power
hungry signal processing solutions are ineffective. Key aspects in the proposed
approach include utilising the spatial properties of physically embedded neural
networks and propagating waves of activity therein for information processing,
using dimensional collapse of imagery information into amenable temporal
patterns and the use of asynchronous frames for information binding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3050</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3050</id><created>2013-06-13</created><updated>2013-08-13</updated><authors><author><keyname>L&#xfc;ttgen</keyname><forenames>Gerald</forenames><affiliation>Uni. Bamberg</affiliation></author><author><keyname>Vogler</keyname><forenames>Walter</forenames><affiliation>Uni. Augsburg</affiliation></author></authors><title>Modal Interface Automata</title><categories>cs.LO cs.FL cs.SE</categories><comments>28 pages</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (August 14,
  2013) lmcs:1136</journal-ref><doi>10.2168/LMCS-9(3:4)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  De Alfaro and Henzinger's Interface Automata (IA) and Nyman et al.'s recent
combination IOMTS of IA and Larsen's Modal Transition Systems (MTS) are
established frameworks for specifying interfaces of system components. However,
neither IA nor IOMTS consider conjunction that is needed in practice when a
component shall satisfy multiple interfaces, while Larsen's MTS-conjunction is
not closed and Bene\v{s} et al.'s conjunction on disjunctive MTS does not treat
internal transitions. In addition, IOMTS-parallel composition exhibits a
compositionality defect. This article defines conjunction (and also
disjunction) on IA and disjunctive MTS and proves the operators to be
'correct', i.e., the greatest lower bounds (least upper bounds) wrt. IA- and
resp. MTS-refinement. As its main contribution, a novel interface theory called
Modal Interface Automata (MIA) is introduced: MIA is a rich subset of IOMTS
featuring explicit output-must-transitions while input-transitions are always
allowed implicitly, is equipped with compositional parallel, conjunction and
disjunction operators, and allows a simpler embedding of IA than Nyman's. Thus,
it fixes the shortcomings of related work, without restricting designers to
deterministic interfaces as Raclet et al.'s modal interface theory does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3054</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3054</id><created>2013-06-13</created><authors><author><keyname>Gao</keyname><forenames>Haichang</forenames></author><author><keyname>Ren</keyname><forenames>Zhongjie</forenames></author><author><keyname>Chang</keyname><forenames>Xiuling</forenames></author><author><keyname>Liu</keyname><forenames>Xiyang</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>The effect of baroque music on the PassPoints graphical password</title><categories>cs.CR cs.CY cs.HC</categories><comments>ACM International Conference on Image and Video Retrieval, 129-134,
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical passwords have been demonstrated to be the possible alternatives to
traditional alphanumeric passwords. However, they still tend to follow
predictable patterns that are easier to attack. The crux of the problem is
users' memory limitations. Users are the weakest link in password
authentication mechanism. It shows that baroque music has positive effects on
human memorizing and learning. We introduce baroque music to the PassPoints
graphical password scheme and conduct a laboratory study in this paper. Results
shown that there is no statistic difference between the music group and the
control group without music in short-term recall experiments, both had high
recall success rates. But in long-term recall, the music group performed
significantly better. We also found that the music group tended to set
significantly more complicated passwords, which are usually more resistant to
dictionary and other guess attacks. But compared with the control group, the
music group took more time to log in both in short-term and long-term tests.
Besides, it appears that background music does not work in terms of hotspots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3055</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3055</id><created>2013-06-13</created><authors><author><keyname>Gao</keyname><forenames>Haichang</forenames></author><author><keyname>Chang</keyname><forenames>Xiuling</forenames></author><author><keyname>Ren</keyname><forenames>Zhongjie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Wang</keyname><forenames>Liming</forenames></author></authors><title>Can background baroque music help to improve the memorability of
  graphical passwords?</title><categories>cs.CR cs.CY cs.HC</categories><comments>Proceedings of the International Conference on Image Analysis and
  Recognition, ICIAR2010, Povoa de Varzim, Portugal, 378-387, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical passwords have been proposed as an alternative to alphanumeric
passwords with their advantages in usability and security. However, they still
tend to follow predictable patterns that are easier for attackers to exploit,
probably due to users' memory limitations. Various literatures show that
baroque music has positive effects on human learning and memorizing. To
alleviate users' memory burden, we investigate the novel idea of introducing
baroque music to graphical password schemes (specifically DAS, PassPoints and
Story) and conduct a laboratory study to see whether it is helpful. In a ten
minutes short-term recall, we found that participants in all conditions had
high recall success rates that were not statistically different from each
other. After one week, the music group coped PassPoints passwords significantly
better than the group without music. But there was no statistical difference
between two groups in recalling DAS passwords or Story passwords. Further more,
we found that the music group tended to set significantly more complicated
PassPoints passwords but less complicated DAS passwords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3056</identifier>
 <datestamp>2015-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3056</id><created>2013-06-13</created><updated>2015-01-27</updated><authors><author><keyname>Zeume</keyname><forenames>Thomas</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author></authors><title>On the quantifier-free dynamic complexity of Reachability</title><categories>cs.LO</categories><journal-ref>Thomas Zeume, Thomas Schwentick, On the quantifier-free dynamic
  complexity of Reachability, Information and Computation, Volume 240, February
  2015, Pages 108-129, ISSN 0890-5401,
  http://dx.doi.org/10.1016/j.ic.2014.09.011</journal-ref><doi>10.1016/j.ic.2014.09.011.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic complexity of the reachability query is studied in the dynamic
complexity framework of Patnaik and Immerman, restricted to quantifier-free
update formulas.
  It is shown that, with this restriction, the reachability query cannot be
dynamically maintained, neither with binary auxiliary relations nor with unary
auxiliary functions, and that ternary auxiliary relations are more powerful
with respect to graph queries than binary auxiliary relations.
  Further inexpressibility results are given for the reachability query in a
different setting as well as for a syntactical restriction of quantifier-free
update formulas. Moreover inexpressibility results for some other queries are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3058</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3058</id><created>2013-06-13</created><authors><author><keyname>Paris</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Doh</keyname><forenames>Yann</forenames></author><author><keyname>Glotin</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Halkias</keyname><forenames>Xanadu</forenames></author><author><keyname>Razik</keyname><forenames>Joseph</forenames></author></authors><title>Physeter catodon localization by sparse coding</title><categories>cs.LG cs.CE stat.ML</categories><comments>6 pages, 6 figures, workshop ICML4B in ICML 2013 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a spermwhale' localization architecture using jointly a
bag-of-features (BoF) approach and machine learning framework. BoF methods are
known, especially in computer vision, to produce from a collection of local
features a global representation invariant to principal signal transformations.
Our idea is to regress supervisely from these local features two rough
estimates of the distance and azimuth thanks to some datasets where both
acoustic events and ground-truth position are now available. Furthermore, these
estimates can feed a particle filter system in order to obtain a precise
spermwhale' position even in mono-hydrophone configuration. Anti-collision
system and whale watching are considered applications of this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3059</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3059</id><created>2013-06-13</created><updated>2013-06-27</updated><authors><author><keyname>Mennicke</keyname><forenames>Roy</forenames><affiliation>Ilmenau University of Technology</affiliation></author></authors><title>Propositional Dynamic Logic with Converse and Repeat for Message-Passing
  Systems</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 2 (June 28,
  2013) lmcs:855</journal-ref><doi>10.2168/LMCS-9(2:12)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The model checking problem for propositional dynamic logic (PDL) over message
sequence charts (MSCs) and communicating finite state machines (CFMs) asks,
given a channel bound $B$, a PDL formula $\varphi$ and a CFM $\mathcal{C}$,
whether every existentially $B$-bounded MSC $M$ accepted by $\mathcal{C}$
satisfies $\varphi$. Recently, it was shown that this problem is
PSPACE-complete.
  In the present work, we consider CRPDL over MSCs which is PDL equipped with
the operators converse and repeat. The former enables one to walk back and
forth within an MSC using a single path expression whereas the latter allows to
express that a path expression can be repeated infinitely often. To solve the
model checking problem for this logic, we define message sequence chart
automata (MSCAs) which are multi-way alternating parity automata walking on
MSCs. By exploiting a new concept called concatenation states, we are able to
inductively construct, for every CRPDL formula $\varphi$, an MSCA precisely
accepting the set of models of $\varphi$. As a result, we obtain that the model
checking problem for CRPDL and CFMs is still in PSPACE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3062</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3062</id><created>2013-06-13</created><authors><author><keyname>England</keyname><forenames>Matthew</forenames></author></authors><title>An implementation of CAD in Maple utilising problem formulation,
  equational constraints and truth-table invariance</title><categories>cs.SC</categories><comments>12 pages; University of Bath, Dept. Computer Science Technical Report
  Series, 2013-02, 2013</comments><msc-class>68W30</msc-class><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cylindrical algebraic decomposition (CAD) is an important tool for the
investigation of semi-algebraic sets, with applications within algebraic
geometry and beyond. We recently reported on a new implementation of CAD in
Maple which implemented the original algorithm of Collins and the subsequent
improvement to projection by McCallum. Our implementation was in contrast to
Maple's in-built CAD command, based on a quite separate theory. Although
initially developed as an investigative tool to compare the algorithms, we
found and reported that our code offered functionality not currently available
in any other existing implementations. One particularly important piece of
functionality is the ability to produce order-invariant CADs. This has allowed
us to extend the implementation to produce CADs invariant with respect to
either equational constraints (ECCADs) or the truth-tables of sequences of
formulae (TTICADs). This new functionality is contained in the second release
of our code, along with commands to consider problem formulation which can be a
major factor in the tractability of a CAD. In the report we describe the new
functionality and some theoretical discoveries it prompted. We describe how the
CADs produced using equational constraints are able to take advantage of not
just improved projection but also improvements in the lifting phase. We also
present an extension to the original TTICAD algorithm which increases both the
applicability of TTICAD and its relative benefit over other algorithms. The
code and an introductory Maple worksheet / pdf demonstrating the full
functionality of the package are freely available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3083</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3083</id><created>2013-06-13</created><authors><author><keyname>Noyel</keyname><forenames>M&#xe9;lanie</forenames><affiliation>CRAN</affiliation></author><author><keyname>Thomas</keyname><forenames>Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Charpentier</keyname><forenames>Patrick</forenames><affiliation>CRAN</affiliation></author><author><keyname>Thomas</keyname><forenames>Andr&#xe9;</forenames><affiliation>CRAN</affiliation></author><author><keyname>Beaupretre</keyname><forenames>Bruno</forenames></author></authors><title>Improving production process performance thanks to neuronal analysis</title><categories>cs.SE</categories><proxy>ccsd</proxy><journal-ref>11th IFAC Workshop on Intelligent Manufacturing System IMS'13, Sao
  Paulo : Brazil (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product quality level is become a key factor for companies' competitiveness.
A lot of time and money are required to ensure and guaranty it. Besides,
motivated by the need of traceability, collecting production data is now
commonplace in most companies. Our paper aims to show that we can ensure the
required quality thanks to an &quot;on-line quality approch&quot; and proposes a neural
network based process to determine the optimal setting for production machines.
We will illustrate this with the Acta-Mobilier case, which is a high quality
lacquerer company.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3084</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3084</id><created>2013-06-13</created><authors><author><keyname>Hernandez</keyname><forenames>Jorge</forenames><affiliation>CMM</affiliation></author><author><keyname>Marcotegui</keyname><forenames>Beatriz</forenames><affiliation>CMM</affiliation></author></authors><title>Segmentation et Interpr\'etation de Nuages de Points pour la
  Mod\'elisation d'Environnements Urbains</title><categories>cs.CV</categories><proxy>ccsd</proxy><journal-ref>Revue fran\c{c}aise de photogrammetrie et de t\'el\'edection 191
  (2008) 28-35</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dans cet article, nous pr\'esentons une m\'ethode pour la d\'etection et la
classification d'artefacts au niveau du sol, comme phase de filtrage
pr\'ealable \`a la mod\'elisation d'environnements urbains. La m\'ethode de
d\'etection est r\'ealis\'ee sur l'image profondeur, une projection de nuage de
points sur un plan image o\`u la valeur du pixel correspond \`a la distance du
point au plan. En faisant l'hypoth\`ese que les artefacts sont situ\'es au sol,
ils sont d\'etect\'es par une transformation de chapeau haut de forme par
remplissage de trous sur l'image de profondeur. Les composantes connexes ainsi
obtenues, sont ensuite caract\'eris\'ees et une analyse des variables est
utilis\'ee pour la s\'election des caract\'eristiques les plus discriminantes.
Les composantes connexes sont donc classifi\'ees en quatre cat\'egories
(lampadaires, pi\'etons, voitures et &quot;Reste&quot;) \`a l'aide d'un algorithme
d'apprentissage supervis\'e. La m\'ethode a \'et\'e test\'ee sur des nuages de
points de la ville de Paris, en montrant de bons r\'esultats de d\'etection et
de classification dans l'ensemble de donn\'ees.---In this article, we present a
method for detection and classification of artifacts at the street level, in
order to filter cloud point, facilitating the urban modeling process. Our
approach exploits 3D information by using range image, a projection of 3D
points onto an image plane where the pixel intensity is a function of the
measured distance between 3D points and the plane. By assuming that the
artifacts are on the ground, they are detected using a Top-Hat of the hole
filling algorithm of range images. Then, several features are extracted from
the detected connected components and a stepwise forward variable/model
selection by using the Wilk's Lambda criterion is performed. Afterward, CCs are
classified in four categories (lampposts, pedestrians, cars and others) by
using a supervised machine learning method. The proposed method was tested on
cloud points of Paris, and have shown satisfactory results on the whole
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3088</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3088</id><created>2013-06-13</created><authors><author><keyname>H&#xe4;gglund</keyname><forenames>Jonas</forenames></author><author><keyname>Markstr\om</keyname><forenames>Klas</forenames></author></authors><title>Shortest cycle covers and cycle double covers with large 2-regular
  subgraphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that many snarks have shortest cycle covers of length
$\frac{4}{3}m+c$ for a constant $c$, where $m$ is the number of edges in the
graph, in agreement with the conjecture that all snarks have shortest cycle
covers of length $\frac{4}{3}m+o(m)$.
  In particular we prove that graphs with perfect matching index at most 4 have
cycle covers of length $\frac{4}{3}m$ and satisfy the $(1,2)$-covering
conjecture of Zhang, and that graphs with large circumference have cycle covers
of length close to $\frac{4}{3}m$. We also prove some results for graphs with
low oddness and discuss the connection with Jaeger's Petersen colouring
conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3091</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3091</id><created>2013-06-13</created><updated>2014-12-15</updated><authors><author><keyname>Markstr&#xf6;m</keyname><forenames>Klas</forenames></author></authors><title>The straight line complexity of small factorials and primorials</title><categories>cs.CC cs.DM math.NT</categories><comments>V4: Published version. Reformatted to journal format. Minor typos
  corrected. v3: Updated acknowledgments, improved some of the lower bounds
  after recomputing all data with a new program, corrected two incorrect lower
  bounds due a damaged datafile from the original 10 year old computation. V2:
  Corrected typos and a mistake in table 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we determine the straight-line complexity of $n!$ for $n\leq
22$ and give bounds for the complexities up to $n=46$. In the same way we
determine the straight-line complexity of the product of the first primes up to
$p=31$ and gives bounds for $p\leq 43$.
  Our results are based on an exhaustive computer search of the short length
straight-line programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3093</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3093</id><created>2013-06-13</created><updated>2013-09-30</updated><authors><author><keyname>Morsi</keyname><forenames>Rania</forenames></author><author><keyname>Michalopoulos</keyname><forenames>Diomidis S.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Multi-user Scheduling Schemes for Simultaneous Wireless Information and
  Power Transfer</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures. Submitted for possible conference publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the downlink multi-user scheduling problem for a
time-slotted system with simultaneous wireless information and power transfer.
In particular, in each time slot, a single user is scheduled to receive
information, while the remaining users opportunistically harvest the ambient
radio frequency (RF) energy. We devise novel scheduling schemes in which the
tradeoff between the users' ergodic capacities and their average amount of
harvested energy can be controlled. To this end, we modify two fair scheduling
schemes used in information-only transfer systems. First, proportionally fair
maximum normalized signal-to-noise ratio (N-SNR) scheduling is modified by
scheduling the user having the jth ascendingly ordered (rather than the
maximum) N-SNR. We refer to this scheme as order-based N-SNR scheduling.
Second, conventional equal-throughput (ET) fair scheduling is modified by
scheduling the user having the minimum moving average throughput among the set
of users whose N-SNR orders fall into a certain set of allowed orders Sa
(rather than the set of all users). We refer to this scheme as order-based ET
scheduling. The feasibility conditions required for the users to achieve ET
with this scheme are also derived. We show that the smaller the selection order
j for the order-based N-SNR scheme, and the lower the orders in Sa for the
order-based ET scheme, the higher the average amount of energy harvested by the
users at the expense of a reduction in their ergodic capacities. We analyze the
performance of the considered scheduling schemes for independent and
non-identically distributed (i.n.d.) Ricean fading channels, and provide
closed-form results for the special case of i.n.d. Rayleigh fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3108</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3108</id><created>2013-06-13</created><updated>2013-08-29</updated><authors><author><keyname>Guo</keyname><forenames>Zheng-Chu</forenames></author><author><keyname>Ying</keyname><forenames>Yiming</forenames></author></authors><title>Guaranteed Classification via Regularized Similarity Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning an appropriate (dis)similarity function from the available data is a
central problem in machine learning, since the success of many machine learning
algorithms critically depends on the choice of a similarity function to compare
examples. Despite many approaches for similarity metric learning have been
proposed, there is little theoretical study on the links between similarity
met- ric learning and the classification performance of the result classifier.
In this paper, we propose a regularized similarity learning formulation
associated with general matrix-norms, and establish their generalization
bounds. We show that the generalization error of the resulting linear separator
can be bounded by the derived generalization bound of similarity learning. This
shows that a good gen- eralization of the learnt similarity function guarantees
a good classification of the resulting linear classifier. Our results extend
and improve those obtained by Bellet at al. [3]. Due to the techniques
dependent on the notion of uniform stability [6], the bound obtained there
holds true only for the Frobenius matrix- norm regularization. Our techniques
using the Rademacher complexity [5] and its related Khinchin-type inequality
enable us to establish bounds for regularized similarity learning formulations
associated with general matrix-norms including sparse L 1 -norm and mixed
(2,1)-norm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3109</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3109</id><created>2013-06-13</created><updated>2013-11-08</updated><authors><author><keyname>Yavits</keyname><forenames>Leonid</forenames></author><author><keyname>Morad</keyname><forenames>Amir</forenames></author><author><keyname>Ginosar</keyname><forenames>Ran</forenames></author></authors><title>Computer Architecture with Associative Processor Replacing Last Level
  Cache and SIMD Accelerator</title><categories>cs.AR</categories><comments>This paper has been withdrawn by the author due to a crucial error in
  equation 10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a novel computer architecture where a last level cache
and a SIMD accelerator are replaced by an Associative Processor. Associative
Processor combines data storage and data processing and provides parallel
computational capabilities and data memory at the same time. An analytic
performance model of the new computer architecture is introduced. Comparative
analysis supported by simulation shows that this novel architecture may
outperform a conventional architecture comprising a SIMD coprocessor and a
shared last level cache while consuming less power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3111</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3111</id><created>2013-06-13</created><authors><author><keyname>Jasper</keyname><forenames>John</forenames></author><author><keyname>Mixon</keyname><forenames>Dustin G.</forenames></author><author><keyname>Fickus</keyname><forenames>Matthew</forenames></author></authors><title>Kirkman Equiangular Tight Frames and Codes</title><categories>cs.IT math.IT</categories><msc-class>42C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An equiangular tight frame (ETF) is a set of unit vectors in a Euclidean
space whose coherence is as small as possible, equaling the Welch bound. Also
known as Welch-bound-equality sequences, such frames arise in various
applications, such as waveform design and compressed sensing. At the moment,
there are only two known flexible methods for constructing ETFs: harmonic ETFs
are formed by carefully extracting rows from a discrete Fourier transform;
Steiner ETFs arise from a tensor-like combination of a combinatorial design and
a regular simplex. These two classes seem very different: the vectors in
harmonic ETFs have constant amplitude, whereas Steiner ETFs are extremely
sparse. We show that they are actually intimately connected: a large class of
Steiner ETFs can be unitarily transformed into constant-amplitude frames,
dubbed Kirkman ETFs. Moreover, we show that an important class of harmonic ETFs
is a subset of an important class of Kirkman ETFs. This connection informs the
discussion of both types of frames: some Steiner ETFs can be transformed into
constant-amplitude waveforms making them more useful in waveform design; some
harmonic ETFs have low spark, making them less desirable for compressed
sensing. We conclude by showing that real-valued constant-amplitude ETFs are
equivalent to binary codes that achieve the Grey-Rankin bound, and then
construct such codes using Kirkman ETFs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3113</identifier>
 <datestamp>2014-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3113</id><created>2013-06-13</created><updated>2014-01-20</updated><authors><author><keyname>Da</keyname><forenames>Fang</forenames></author><author><keyname>Batty</keyname><forenames>Christopher</forenames></author><author><keyname>Grinspun</keyname><forenames>Eitan</forenames></author></authors><title>Multimaterial Front Tracking</title><categories>cs.GR</categories><comments>The paper has been drastically revised and submitted to a journal
  that requires author anonymity; while this cannot be achieved under arXiv.org
  policy, we have nevertheless decided to withdraw the paper to reflect our
  attempt to satisfy anonymity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first triangle mesh-based technique for tracking the evolution
of general three-dimensional multimaterial interfaces undergoing complex
topology changes induced by deformations and collisions. Our core
representation is a non-manifold triangle surface mesh with material labels
assigned to each half-face to distinguish volumetric regions. We advect the
vertices of the mesh in a Lagrangian manner, and employ a complete set of
collision-safe mesh improvement and topological operations that track and
update material labels. In particular, we develop a unified, collision-safe
strategy for handling complex topological operations acting on evolving triple-
and higher-valence junctions, and a flexible method to merge colliding
multimaterial meshes. We demonstrate our approach with a number of challenging
geometric flows, including passive advection, normal flow, and mean curvature
flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3119</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3119</id><created>2013-06-13</created><authors><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Pashkovich</keyname><forenames>Kanstantsin</forenames></author></authors><title>Uncapacitated Flow-based Extended Formulations</title><categories>math.OC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An extended formulation of a polytope is a linear description of this
polytope using extra variables besides the variables in which the polytope is
defined. The interest of extended formulations is due to the fact that many
interesting polytopes have extended formulations with a lot fewer inequalities
than any linear description in the original space. This motivates the
development of methods for, on the one hand, constructing extended formulations
and, on the other hand, proving lower bounds on the sizes of extended
formulations.
  Network flows are a central paradigm in discrete optimization, and are widely
used to design extended formulations. We prove exponential lower bounds on the
sizes of uncapacitated flow-based extended formulations of several polytopes,
such as the (bipartite and non-bipartite) perfect matching polytope and TSP
polytope. We also give new examples of flow-based extended formulations, e.g.,
for 0/1-polytopes defined from regular languages. Finally, we state a few open
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3123</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3123</id><created>2013-06-13</created><updated>2013-07-25</updated><authors><author><keyname>Holub</keyname><forenames>&#x160;t&#x11b;p&#xe1;n</forenames></author></authors><title>Words with unbounded periodicity complexity</title><categories>cs.FL math.CO</categories><comments>some references adjusted</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If an infinite non-periodic word is uniformly recurrent or is of bounded
repetition, then the limit of its periodicity complexity is infinity. Moreover,
there are uniformly recurrent words with the periodicity complexity arbitrarily
high at infinitely many positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3127</identifier>
 <datestamp>2013-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3127</id><created>2013-06-13</created><updated>2013-07-04</updated><authors><author><keyname>Griffin</keyname><forenames>Christopher</forenames></author><author><keyname>Kesidis</keyname><forenames>George</forenames></author></authors><title>Behavior in a Shared Resource Game with Cooperative, Greedy, and
  Vigilante Players</title><categories>cs.GT</categories><comments>6 pages, 7 figures -- Version 3 title and abstract update</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We study a problem of trust in a distributed system in which a common
resource is shared by multiple parties. In such naturally information-limited
settings, parties abide by a behavioral protocol that leads to fair sharing of
the resource. However, greedy players may defect from a cooperative protocol
and achieve a greater than fair share of resources, often without significant
adverse consequences to themselves. In this paper, we study the role of a few
vigilante players who also defect from a cooperative resource-sharing protocol
but only in response to perceived greedy behavior. For a simple model of
engagement, we demonstrate surprisingly complex dynamics among greedy and
vigilante players. We show that the best response function for the
greedy-player under our formulation has a jump discontinuity, which leads to
conditions under which there is no Nash equilibrium. To study this property, we
formulate an exact representation for the greedy player best response function
in the case when there is one greedy player, one vigilante player and $N-2$
cooperative players. We use this formulation to show conditions under which a
Nash equilibrium exists. We also illustrate that in the case when there is no
Nash equilibrium, then the discrete dynamic system generated from fictitious
play will not converge, but will oscillate indefinitely as a result of the jump
discontinuity. The case of multiple vigilante and greedy players is studied
numerically. Finally, we explore the relationship between fictitious play and
the better response dynamics (gradient descent) and illustrate that this
dynamical system can have a fixed point even when the discrete dynamical system
arising from fictitious play does not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3133</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3133</id><created>2013-06-13</created><updated>2013-06-14</updated><authors><author><keyname>Larsen</keyname><forenames>Jakob Eg</forenames></author><author><keyname>Sapiezynski</keyname><forenames>Piotr</forenames></author><author><keyname>Stopczynski</keyname><forenames>Arkadiusz</forenames></author><author><keyname>Moerup</keyname><forenames>Morten</forenames></author><author><keyname>Theodorsen</keyname><forenames>Rasmus</forenames></author></authors><title>Crowds, Bluetooth, and Rock-n-Roll. Understanding Music Festival
  Participant Behavior</title><categories>stat.AP cs.HC</categories><comments>Presented at Sunbelt 2013 in Hamburg on May, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a study of sensing and analyzing an offline social
network of participants at a large-scale music festival (8 days, 130,000+
participants). We place 33 fixed-location Bluetooth scanners in strategic spots
around the festival area to discover Bluetooth-enabled mobile phones carried by
the participants, and thus collect spatio-temporal traces of their mobility and
interactions. We subsequently analyze the data on two levels. On the micro
level, we run a community detection algorithm to reveal a variety of groups the
festival participants form. On the macro level, we employ an Infinite
Relational Model (IRM) in order to recover the structure of the social network
related to participants' music preferences. The obtained structure in the form
of clusters of concerts and participants is then interpreted using
meta-information about music genres, band origins, stages, and dates of
performances. We show that most of the concerts clusters can be described by
one or more of the meta-features, effectively revealing preferences of
participants (e.g. a cluster of US bands) and discuss the significance of the
findings and the potential and limitations of the used method. Finally, we
discuss the possibility of employing the described method and techniques for
creating user-oriented applications and extending the sensing capabilities
during large-scale events by introducing user involvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3134</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3134</id><created>2013-06-13</created><updated>2015-04-20</updated><authors><author><keyname>Eger</keyname><forenames>Steffen</forenames></author></authors><title>Opinion dynamics and wisdom under in-group bias and out-group
  discrimination</title><categories>cs.MA cs.SI nlin.AO</categories><comments>36 pages; title change and major rework</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a DeGroot-like opinion dynamics model in which agents may oppose
other agents. As an underlying motivation, in our setup, agents want to adjust
their opinions to match those of the agents they follow (their `in-group',
friends, or those they trust) and, in addition, they want to adjust their
opinions to match the `inverse' of those of the agents they oppose (their
`out-group', enemies, or those they distrust). Our paradigm can account for
both long-run consensus as well as bi- and multi-polarization and persistent
disagreement in connected societies. Outcomes depend upon network
(`multigraph') structure and the choice of deviation function modeling the mode
of opposition between agents. We also consider social influence (who are the
opinion leaders in the network?) as well as the question of wisdom in our
na\&quot;ive learning paradigm, finding that wisdom is difficult to attain when
there exist sufficiently strong negative relations between agents.
Psychologically and socio-economically, we interpret opposition as arising from
group identity structure (out-group discrimination) or, more particularly, from
rebels/anti-conformists; countercultures; rejection of the norms and values of
disliked others, as `negative referents'; or, simply, distrust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3142</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3142</id><created>2013-06-13</created><updated>2014-01-27</updated><authors><author><keyname>M&#xfc;ller-Lennert</keyname><forenames>Martin</forenames></author><author><keyname>Dupuis</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Szehr</keyname><forenames>Oleg</forenames></author><author><keyname>Fehr</keyname><forenames>Serge</forenames></author><author><keyname>Tomamichel</keyname><forenames>Marco</forenames></author></authors><title>On quantum Renyi entropies: a new generalization and some properties</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>v1: contains several conjectures; v2: conjectures are resolved - see
  also arXiv:1306.5358 and arXiv:1306.5920; v3: published version</comments><journal-ref>J. Math. Phys. 54, 122203 (2013)</journal-ref><doi>10.1063/1.4838856</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Renyi entropies constitute a family of information measures that
generalizes the well-known Shannon entropy, inheriting many of its properties.
They appear in the form of unconditional and conditional entropies, relative
entropies or mutual information, and have found many applications in
information theory and beyond. Various generalizations of Renyi entropies to
the quantum setting have been proposed, most notably Petz's quasi-entropies and
Renner's conditional min-, max- and collision entropy. Here, we argue that
previous quantum extensions are incompatible and thus unsatisfactory.
  We propose a new quantum generalization of the family of Renyi entropies that
contains the von Neumann entropy, min-entropy, collision entropy and the
max-entropy as special cases, thus encompassing most quantum entropies in use
today. We show several natural properties for this definition, including
data-processing inequalities, a duality relation, and an entropic uncertainty
relation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3160</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3160</id><created>2013-06-13</created><authors><author><keyname>Griffin</keyname><forenames>Christopher</forenames></author><author><keyname>Kesidis</keyname><forenames>George</forenames></author><author><keyname>Antoniadis</keyname><forenames>Panayotis</forenames></author><author><keyname>Fdida</keyname><forenames>Serge</forenames></author></authors><title>Modeling and Control of Rare Segments in BitTorrent with Epidemic
  Dynamics</title><categories>cs.NI</categories><comments>18 pages, 6 figures, A shorter version of this paper that did not
  include the N-segment lumped model was presented in May 2011 at IEEE ICC,
  Kyoto</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Despite its existing incentives for leecher cooperation, BitTorrent file
sharing fundamentally relies on the presence of seeder peers. Seeder peers
essentially operate outside the BitTorrent incentives, with two caveats: slow
downlinks lead to increased numbers of &quot;temporary&quot; seeders (who left their
console, but will terminate their seeder role when they return), and the
copyright liability boon that file segmentation offers for permanent seeders.
Using a simple epidemic model for a two-segment BitTorrent swarm, we focus on
the BitTorrent rule to disseminate the (locally) rarest segments first. With
our model, we show that the rarest-segment first rule minimizes transition time
to seeder (complete file acquisition) and equalizes the segment populations in
steady-state. We discuss how alternative dissemination rules may {\em
beneficially increase} file acquisition times causing leechers to remain in the
system longer (particularly as temporary seeders). The result is that leechers
are further enticed to cooperate. This eliminates the threat of extinction of
rare segments which is prevented by the needed presence of permanent seeders.
Our model allows us to study the corresponding trade-offs between performance
improvement, load on permanent seeders, and content availability, which we
leave for future work. Finally, interpreting the two-segment model as one
involving a rare segment and a &quot;lumped&quot; segment representing the rest, we study
a model that jointly considers control of rare segments and different uplinks
causing &quot;choking,&quot; where high-uplink peers will not engage in certain
transactions with low-uplink peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3161</identifier>
 <datestamp>2014-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3161</id><created>2013-06-13</created><updated>2014-03-02</updated><authors><author><keyname>Lapin</keyname><forenames>Maksim</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author><author><keyname>Schiele</keyname><forenames>Bernt</forenames></author></authors><title>Learning Using Privileged Information: SVM+ and Weighted SVM</title><categories>stat.ML cs.LG</categories><comments>18 pages, 8 figures; integrated reviewer comments, improved
  typesetting</comments><journal-ref>Neural Networks 53C (2014), pp. 95-108</journal-ref><doi>10.1016/j.neunet.2014.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prior knowledge can be used to improve predictive performance of learning
algorithms or reduce the amount of data required for training. The same goal is
pursued within the learning using privileged information paradigm which was
recently introduced by Vapnik et al. and is aimed at utilizing additional
information available only at training time -- a framework implemented by SVM+.
We relate the privileged information to importance weighting and show that the
prior knowledge expressible with privileged features can also be encoded by
weights associated with every training example. We show that a weighted SVM can
always replicate an SVM+ solution, while the converse is not true and we
construct a counterexample highlighting the limitations of SVM+. Finally, we
touch on the problem of choosing weights for weighted SVMs when privileged
features are not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3162</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3162</id><created>2013-06-13</created><updated>2014-02-10</updated><authors><author><keyname>Konda</keyname><forenames>Kishore Reddy</forenames></author><author><keyname>Memisevic</keyname><forenames>Roland</forenames></author><author><keyname>Michalski</keyname><forenames>Vincent</forenames></author></authors><title>Learning to encode motion using spatio-temporal synchrony</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of learning to extract motion from videos. To this end,
we show that the detection of spatial transformations can be viewed as the
detection of synchrony between the image sequence and a sequence of features
undergoing the motion we wish to detect. We show that learning about synchrony
is possible using very fast, local learning rules, by introducing
multiplicative &quot;gating&quot; interactions between hidden units across frames. This
makes it possible to achieve competitive performance in a wide variety of
motion estimation tasks, using a small fraction of the time required to learn
features, and to outperform hand-crafted spatio-temporal features by a large
margin. We also show how learning about synchrony can be viewed as performing
greedy parameter estimation in the well-known motion energy model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3171</identifier>
 <datestamp>2014-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3171</id><created>2013-06-13</created><updated>2014-04-01</updated><authors><author><keyname>Javanmard</keyname><forenames>Adel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Confidence Intervals and Hypothesis Testing for High-Dimensional
  Regression</title><categories>stat.ME cs.IT cs.LG math.IT</categories><comments>40 pages, 4 pdf figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fitting high-dimensional statistical models often requires the use of
non-linear parameter estimation procedures. As a consequence, it is generally
impossible to obtain an exact characterization of the probability distribution
of the parameter estimates. This in turn implies that it is extremely
challenging to quantify the \emph{uncertainty} associated with a certain
parameter estimate. Concretely, no commonly accepted procedure exists for
computing classical measures of uncertainty and statistical significance as
confidence intervals or $p$-values for these models.
  We consider here high-dimensional linear regression problem, and propose an
efficient algorithm for constructing confidence intervals and $p$-values. The
resulting confidence intervals have nearly optimal size. When testing for the
null hypothesis that a certain parameter is vanishing, our method has nearly
optimal power.
  Our approach is based on constructing a `de-biased' version of regularized
M-estimators. The new construction improves over recent work in the field in
that it does not assume a special structure on the design matrix. We test our
method on synthetic data and a high-throughput genomic data set about
riboflavin production rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3172</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3172</id><created>2013-06-13</created><authors><author><keyname>Li</keyname><forenames>Tiancheng</forenames></author><author><keyname>Sun</keyname><forenames>Shudong</forenames></author><author><keyname>Sattar</keyname><forenames>Tariq Pervez</forenames></author></authors><title>Adapting sample size in particle filters through KLD-resampling</title><categories>stat.AP cs.RO</categories><comments>short letter of 2 pages, a Finishing Touch of appling KLD measure for
  sample size adaption for particle filters. In Electronics Letters 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter provides an adaptive resampling method. It determines the number
of particles to resample so that the Kullback-Leibler distance (KLD) between
distribution of particles before resampling and after resampling does not
exceed a pre-specified error bound. The basis of the method is the same as
Fox's KLD-sampling but implemented differently. The KLD-sampling assumes that
samples are coming from the true posterior distribution and ignores any
mismatch between the true and the proposal distribution. In contrast, we
incorporate the KLD measure into the resampling in which the distribution of
interest is just the posterior distribution. That is to say, for sample size
adjustment, it is more theoretically rigorous and practically flexible to
measure the fit of the distribution represented by weighted particles based on
KLD during resampling than in sampling. Simulations of target tracking
demonstrate the efficiency of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3177</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3177</id><created>2013-06-13</created><authors><author><keyname>Siris</keyname><forenames>Vasilios A.</forenames></author><author><keyname>Kalyvas</keyname><forenames>Dimitrios</forenames></author></authors><title>Enhancing Mobile Data Offloading with Mobility Prediction and
  Prefetching</title><categories>cs.NI</categories><comments>Proc. of 7th ACM MOBICOM Workshop on Mobility in the Evolving
  Internet Architecture (MobiArch 2012). 6 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present procedures that exploit mobility prediction and prefetching to
enhance offloading of traffic from mobile networks to WiFi hotspots, for both
delay tolerant and delay sensitive traffic. We evaluate the procedures in terms
of the percentage of offloaded traffic, the data transfer delay, and the cache
size used for prefetching. The evaluation considers empirical measurements and
shows how various parameters influence the performance of the procedures, and
their robustness to time and throughput estimation errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3181</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3181</id><created>2013-06-13</created><authors><author><keyname>Cao</keyname><forenames>Yixin</forenames></author></authors><title>An Efficient Branching Algorithm for Interval Completion</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the \emph{{interval completion}} problem, which asks for the
insertion of a set of at most $k$ edges to make a graph of $n$ vertices into an
interval graph. We focus on chordal graphs with no small obstructions, where
every remaining obstruction is known to have a shallow property. From such a
shallow obstruction we single out a subset 6 or 7 vertices, called the frame,
and 5 missed edges in the subgraph induced by the frame. We show that if none
of these edges is inserted, then the frame cannot be altered at all, and the
whole obstruction is also fixed, by and large, in the sense that their related
positions in an interval representation of the objective interval graph have a
specific pattern. We propose a simple bounded search process, which effectively
transforms a given graph to a graph with the structural property that all
obstructions are shallow and have fixed frames. Then we fill in polynomial time
all obstructions that have been previously left in indecision. These efforts
together deliver a simple parameterized algorithm of time $6^k\cdot n^{O(1)}$
for the problem, significantly improving the only known parameterized algorithm
of time $k^{2k}\cdot n^{O(1)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3198</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3198</id><created>2013-06-13</created><authors><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>Mance</keyname><forenames>Felix</forenames></author><author><keyname>Rabe</keyname><forenames>Florian</forenames></author></authors><title>A Universal Machine for Biform Theory Graphs</title><categories>cs.LO cs.MS</categories><comments>Conferences on Intelligent Computer Mathematics, CICM 2013 The final
  publication is available at http://link.springer.com/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Broadly speaking, there are two kinds of semantics-aware assistant systems
for mathematics: proof assistants express the semantic in logic and emphasize
deduction, and computer algebra systems express the semantics in programming
languages and emphasize computation. Combining the complementary strengths of
both approaches while mending their complementary weaknesses has been an
important goal of the mechanized mathematics community for some time. We pick
up on the idea of biform theories and interpret it in the MMTt/OMDoc framework
which introduced the foundations-as-theories approach, and can thus represent
both logics and programming languages as theories. This yields a formal,
modular framework of biform theory graphs which mixes specifications and
implementations sharing the module system and typing information. We present
automated knowledge management work flows that interface to existing
specification/programming tools and enable an OpenMath Machine, that
operationalizes biform theories, evaluating expressions by exhaustively
applying the implementations of the respective operators. We evaluate the new
biform framework by adding implementations to the OpenMath standard content
dictionaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3199</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3199</id><created>2013-06-13</created><authors><author><keyname>Rabe</keyname><forenames>Florian</forenames></author></authors><title>The MMT API: A Generic MKM System</title><categories>cs.LO</categories><comments>Conferences on Intelligent Computer Mathematics (CICM) 2013 The final
  publication is available at http://link.springer.com/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MMT language has been developed as a scalable representation and
interchange language for formal mathematical knowledge. It permits natural
representations of the syntax and semantics of virtually all declarative
languages while making MMT-based MKM services easy to implement. It is
foundationally unconstrained and can be instantiated with specific formal
languages.
  The MMT API implements the MMT language along with multiple backends for
persistent storage and frontends for machine and user access. Moreover, it
implements a wide variety of MMT-based knowledge management services. The API
and all services are generic and can be applied to any language represented in
MMT. A plugin interface permits injecting syntactic and semantic idiosyncrasies
of individual formal languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3200</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3200</id><created>2013-06-13</created><authors><author><keyname>Kliuchnikov</keyname><forenames>Vadym</forenames></author></authors><title>Synthesis of unitaries with Clifford+T circuits</title><categories>quant-ph cs.ET</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new method for approximating an arbitrary $n$ qubit unitary
with precision $\varepsilon$ using a Clifford and T circuit with
$O(4^{n}n(\log(1/\varepsilon)+n))$ gates. The method is based on rounding off a
unitary to a unitary over the ring $\mathbb{Z}[i,1/\sqrt{2}]$ and employing
exact synthesis. We also show that any $n$ qubit unitary over the ring
$\mathbb{Z}[i,1/\sqrt{2}]$ with entries of the form
$(a+b\sqrt{2}+ic+id\sqrt{2})/2^{k}$ can be exactly synthesized using
$O(4^{n}nk)$ Clifford and T gates using two ancillary qubits. This new exact
synthesis algorithm is an improvement over the best known exact synthesis
method by B. Giles and P. Selinger requiring $O(3^{2^{n}}nk)$ elementary gates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3203</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3203</id><created>2013-06-13</created><updated>2014-07-07</updated><authors><author><keyname>Wang</keyname><forenames>Huahua</forenames></author><author><keyname>Banerjee</keyname><forenames>Arindam</forenames></author></authors><title>Bregman Alternating Direction Method of Multipliers</title><categories>math.OC cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mirror descent algorithm (MDA) generalizes gradient descent by using a
Bregman divergence to replace squared Euclidean distance. In this paper, we
similarly generalize the alternating direction method of multipliers (ADMM) to
Bregman ADMM (BADMM), which allows the choice of different Bregman divergences
to exploit the structure of problems. BADMM provides a unified framework for
ADMM and its variants, including generalized ADMM, inexact ADMM and Bethe ADMM.
  We establish the global convergence and the $O(1/T)$ iteration complexity for
BADMM. In some cases, BADMM can be faster than ADMM by a factor of
$O(n/\log(n))$. In solving the linear program of mass transportation problem,
BADMM leads to massive parallelism and can easily run on GPU. BADMM is several
times faster than highly optimized commercial software Gurobi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3212</identifier>
 <datestamp>2013-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3212</id><created>2013-06-13</created><authors><author><keyname>Hsieh</keyname><forenames>Cho-Jui</forenames></author><author><keyname>Sustik</keyname><forenames>Matyas A.</forenames></author><author><keyname>Dhillon</keyname><forenames>Inderjit S.</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author></authors><title>Sparse Inverse Covariance Matrix Estimation Using Quadratic
  Approximation</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The L1-regularized Gaussian maximum likelihood estimator (MLE) has been shown
to have strong statistical guarantees in recovering a sparse inverse covariance
matrix, or alternatively the underlying graph structure of a Gaussian Markov
Random Field, from very limited samples. We propose a novel algorithm for
solving the resulting optimization problem which is a regularized
log-determinant program. In contrast to recent state-of-the-art methods that
largely use first order gradient information, our algorithm is based on
Newton's method and employs a quadratic approximation, but with some
modifications that leverage the structure of the sparse Gaussian MLE problem.
We show that our method is superlinearly convergent, and present experimental
results using synthetic and real-world application data that demonstrate the
considerable improvements in performance of our method when compared to other
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3252</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3252</id><created>2013-06-13</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author><author><keyname>Ahmed-Ali</keyname><forenames>Tarek</forenames></author><author><keyname>Lamnabhi-Lagarrigue</keyname><forenames>Francoise</forenames></author></authors><title>Global Stabilization of Nonlinear Delay Systems With a Compact Absorbing
  Set</title><categories>math.OC cs.SY</categories><comments>27 pages, to be submitted to the International Journal of Robust and
  Nonlinear Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predictor-based stabilization results are provided for nonlinear systems with
input delays and a compact absorbing set. The control scheme consists of an
inter-sample predictor, a global observer, an approximate predictor, and a
nominal controller for the delay-free case. The control scheme is applicable
even to the case where the measurement is sampled and possibly delayed. The
closed-loop system is shown to have the properties of global asymptotic
stability and exponential convergence in the disturbance-free case, robustness
with respect to perturbations of the sampling schedule, and robustness with
respect to measurement errors. In contrast to existing predictor feedback laws,
the proposed control scheme utilizes an approximate predictor of a dynamic type
which is expressed by a system described by Integral Delay Equations.
Additional results are provided for systems that can be transformed to systems
with a compact absorbing set by means of a preliminary predictor feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3257</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3257</id><created>2013-06-13</created><authors><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Kopecki</keyname><forenames>Steffen</forenames></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author></authors><title>3-color Bounded Patterned Self-assembly</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patterned self-assembly tile set synthesis PATS is the problem of finding a
minimal tile set which uniquely self-assembles into a given pattern. Czeizler
and Popa proved the NP-completeness of PATS and Seki showed that the PATS
problem is already NP-complete for patterns with 60 colors. In search for the
minimal number of colors such that PATS remains NP-complete, we introduce
multiple bound PATS (mbPATS) where we allow bounds for the numbers of tile
types of each color. We show that mbPATS is NP-complete for patterns with just
three colors and, as a byproduct of this result, we also obtain a novel proof
for the NP-completeness of PATS which is more concise than the previous proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3260</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3260</id><created>2013-06-13</created><updated>2013-06-18</updated><authors><author><keyname>Buckheister</keyname><forenames>P.</forenames></author><author><keyname>Zetzsche</keyname><forenames>Georg</forenames></author></authors><title>Semilinearity and Context-Freeness of Languages Accepted by Valence
  Automata</title><categories>cs.FL math.GR</categories><comments>Long version of a paper accepted for MFCS 2013. Corrected typos and
  improved readability, results unchanged</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Valence automata are a generalization of various models of automata with
storage. Here, each edge carries, in addition to an input word, an element of a
monoid. A computation is considered valid if multiplying the monoid elements on
the visited edges yields the identity element. By choosing suitable monoids, a
variety of automata models can be obtained as special valence automata.
  This work is concerned with the accepting power of valence automata.
Specifically, we ask for which monoids valence automata can accept only
context-free languages or only languages with semilinear Parikh image,
respectively.
  First, we present a characterization of those graph products (of monoids) for
which valence automata accept only context-free languages. Second, we provide a
necessary and sufficient condition for a graph product of copies of the
bicyclic monoid and the integers to yield only languages with semilinear Parikh
image when used as a storage mechanism in valence automata. Third, we show that
all languages accepted by valence automata over torsion groups have a
semilinear Parikh image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3261</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3261</id><created>2013-06-13</created><authors><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author><author><keyname>Sugimoto</keyname><forenames>Cassidy R.</forenames></author><author><keyname>Macaluso</keyname><forenames>Benoit</forenames></author><author><keyname>Milojevic</keyname><forenames>Stasa</forenames></author><author><keyname>Cronin</keyname><forenames>Blaise</forenames></author><author><keyname>Thelwall</keyname><forenames>Mike</forenames></author></authors><title>arXiv e-prints and the journal of record: An analysis of roles and
  relationships</title><categories>cs.DL</categories><comments>29 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its creation in 1991, arXiv has become central to the diffusion of
research in a number of fields. Combining data from the entirety of arXiv and
the Web of Science (WoS), this paper investigates (a) the proportion of papers
across all disciplines that are on arXiv and the proportion of arXiv papers
that are in the WoS, (b) elapsed time between arXiv submission and journal
publication, and (c) the aging characteristics and scientific impact of arXiv
e-prints and their published version. It shows that the proportion of WoS
papers found on arXiv varies across the specialties of physics and mathematics,
and that only a few specialties make extensive use of the repository. Elapsed
time between arXiv submission and journal publication has shortened but remains
longer in mathematics than in physics. In physics, mathematics, as well as in
astronomy and astrophysics, arXiv versions are cited more promptly and decay
faster than WoS papers. The arXiv versions of papers - both published and
unpublished - have lower citation rates than published papers, although there
is almost no difference in the impact of the arXiv versions of both published
and unpublished papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3284</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3284</id><created>2013-06-13</created><updated>2015-01-17</updated><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author></authors><title>All-Distances Sketches, Revisited: HIP Estimators for Massive Graphs
  Analysis</title><categories>cs.DS cs.SI</categories><comments>16 pages, 3 figures, extended version of a PODS 2014 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph datasets with billions of edges, such as social and Web graphs, are
prevalent, and scalable computation is critical. All-distances sketches (ADS)
[Cohen 1997], are a powerful tool for scalable approximation of statistics.
  The sketch is a small size sample of the distance relation of a node which
emphasizes closer nodes. Sketches for all nodes are computed using a nearly
linear computation and estimators are applied to sketches of nodes to estimate
their properties.
  We provide, for the first time, a unified exposition of ADS algorithms and
applications. We present the Historic Inverse Probability (HIP) estimators
which are applied to the ADS of a node to estimate a large natural class of
statistics. For the important special cases of neighborhood cardinalities (the
number of nodes within some query distance) and closeness centralities, HIP
estimators have at most half the variance of previous estimators and we show
that this is essentially optimal. Moreover, HIP obtains a polynomial
improvement for more general statistics and the estimators are simple,
flexible, unbiased, and elegant.
  For approximate distinct counting on data streams, HIP outperforms the
original estimators for the HyperLogLog MinHash sketches (Flajolet et al.
2007), obtaining significantly improved estimation quality for this
state-of-the-art practical algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3293</identifier>
 <datestamp>2014-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3293</id><created>2013-06-14</created><updated>2014-01-08</updated><authors><author><keyname>Wang</keyname><forenames>Dashun</forenames></author><author><keyname>Song</keyname><forenames>Chaoming</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>Albert-L&#xe1;szl&#xf3;</forenames></author></authors><title>Quantifying Long-Term Scientific Impact</title><categories>cs.DL cs.SI physics.soc-ph</categories><journal-ref>Science 4 October 2013: Vol. 342 no. 6154 pp. 127-132</journal-ref><doi>10.1126/science.1237825</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of predictability of citation-based measures frequently used to
gauge impact, from impact factors to short-term citations, raises a fundamental
question: Is there long-term predictability in citation patterns? Here, we
derive a mechanistic model for the citation dynamics of individual papers,
allowing us to collapse the citation histories of papers from different
journals and disciplines into a single curve, indicating that all papers tend
to follow the same universal temporal pattern. The observed patterns not only
help us uncover basic mechanisms that govern scientific impact but also offer
reliable measures of influence that may have potential policy implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3294</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3294</id><created>2013-06-14</created><authors><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Boyer</keyname><forenames>Kim L.</forenames></author></authors><title>Feature Learning by Multidimensional Scaling and its Applications in
  Object Recognition</title><categories>cs.CV</categories><comments>To appear in SIBGRAPI 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the MDS feature learning framework, in which multidimensional
scaling (MDS) is applied on high-level pairwise image distances to learn
fixed-length vector representations of images. The aspects of the images that
are captured by the learned features, which we call MDS features, completely
depend on what kind of image distance measurement is employed. With properly
selected semantics-sensitive image distances, the MDS features provide rich
semantic information about the images that is not captured by other feature
extraction techniques. In our work, we introduce the iterated
Levenberg-Marquardt algorithm for solving MDS, and study the MDS feature
learning with IMage Euclidean Distance (IMED) and Spatial Pyramid Matching
(SPM) distance. We present experiments on both synthetic data and real images
--- the publicly accessible UIUC car image dataset. The MDS features based on
SPM distance achieve exceptional performance for the car recognition task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3295</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3295</id><created>2013-06-14</created><authors><author><keyname>Hall</keyname><forenames>Mary</forenames></author><author><keyname>Kirby</keyname><forenames>Robert M.</forenames></author><author><keyname>Li</keyname><forenames>Feifei</forenames></author><author><keyname>Meyer</keyname><forenames>Miriah</forenames></author><author><keyname>Pascucci</keyname><forenames>Valerio</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Ricci</keyname><forenames>Rob</forenames></author><author><keyname>Van der Merwe</keyname><forenames>Jacobus</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Rethinking Abstractions for Big Data: Why, Where, How, and What</title><categories>cs.GL cs.DC</categories><comments>8 pages, 1 figure</comments><report-no>UUCS-13-002</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Big data refers to large and complex data sets that, under existing
approaches, exceed the capacity and capability of current compute platforms,
systems software, analytical tools and human understanding. Numerous lessons on
the scalability of big data can already be found in asymptotic analysis of
algorithms and from the high-performance computing (HPC) and applications
communities. However, scale is only one aspect of current big data trends;
fundamentally, current and emerging problems in big data are a result of
unprecedented complexity--in the structure of the data and how to analyze it,
in dealing with unreliability and redundancy, in addressing the human factors
of comprehending complex data sets, in formulating meaningful analyses, and in
managing the dense, power-hungry data centers that house big data.
  The computer science solution to complexity is finding the right
abstractions, those that hide as much triviality as possible while revealing
the essence of the problem that is being addressed. The &quot;big data challenge&quot;
has disrupted computer science by stressing to the very limits the familiar
abstractions which define the relevant subfields in data analysis, data
management and the underlying parallel systems. As a result, not enough of
these challenges are revealed by isolating abstractions in a traditional
software stack or standard algorithmic and analytical techniques, and attempts
to address complexity either oversimplify or require low-level management of
details. The authors believe that the abstractions for big data need to be
rethought, and this reorganization needs to evolve and be sustained through
continued cross-disciplinary collaboration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3297</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3297</id><created>2013-06-14</created><authors><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author></authors><title>Matching objects across the textured-smooth continuum</title><categories>cs.CV</categories><comments>Australasian Conference on Robotics and Automation, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of 3D object recognition is of immense practical importance, with
the last decade witnessing a number of breakthroughs in the state of the art.
Most of the previous work has focused on the matching of textured objects using
local appearance descriptors extracted around salient image points. The
recently proposed bag of boundaries method was the first to address directly
the problem of matching smooth objects using boundary features. However, no
previous work has attempted to achieve a holistic treatment of the problem by
jointly using textural and shape features which is what we describe herein. Due
to the complementarity of the two modalities, we fuse the corresponding
matching scores and learn their relative weighting in a data specific manner by
optimizing discriminative performance on synthetically distorted data. For the
textural description of an object we adopt a representation in the form of a
histogram of SIFT based visual words. Similarly the apparent shape of an object
is represented by a histogram of discretized features capturing local shape. On
a large public database of a diverse set of objects, the proposed method is
shown to outperform significantly both purely textural and purely shape based
approaches for matching across viewpoint variation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3302</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3302</id><created>2013-06-14</created><authors><author><keyname>Yavits</keyname><forenames>Leonid</forenames></author><author><keyname>Morad</keyname><forenames>Amir</forenames></author><author><keyname>Ginosar</keyname><forenames>Ran</forenames></author></authors><title>The Effect of Communication and Synchronization on Amdahl Law in
  Multicore Systems</title><categories>cs.AR cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work analyses the effects of sequential-to-parallel synchronization and
inter-core communication on multicore performance, speedup and scaling. A
modification of Amdahl law is formulated, to reflect the finding that parallel
speedup is lower than originally predicted, due to these effects. In
applications with high inter-core communication requirements, the workload
should be executed on a small number of cores, and applications of high
sequential-to-parallel synchronization requirements may better be executed by
the sequential core, even when f, the Amdahl fraction of parallelization, is
very close to 1. To improve the scalability and performance speedup of a
multicore, it is as important to address the synchronization and connectivity
intensities of parallel algorithms as their parallelization factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3309</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3309</id><created>2013-06-14</created><updated>2013-07-17</updated><authors><author><keyname>Jacobs</keyname><forenames>Henry</forenames></author></authors><title>Symmetries in LDDMM with higher order momentum distributions</title><categories>math.DS cs.CV</categories><comments>12 pages, accepted to the 4th MICCAI workshop on Mathematical
  Foundations of Computational Anatomy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In some implementations of the Large Deformation Diffeomorphic Metric Mapping
formulation for image registration we consider the motion of particles which
locally translate image data. We then lift the motion of the particles to
obtain a motion on the entire image. However, it is certainly possible to
consider particles which do more than translate, and this is what will be
described in this paper. As the unreduced Lagrangian associated to EPDiff
possesses $\Diff(M)$ symmetry, it must also exhibit $G \subset \Diff(M)$
symmetry, for any Lie subgroup. In this paper we will describe a tower of Lie
groups $G^{(0)} \subseteq G^{(1)} \subseteq G^{(2)} \subseteq...$ which
correspond to preserving $k$-th order jet-data. The reduced configuration
spaces $Q^{(k)} := \Diff(M) / G^{(k)}$ will be finite-dimensional (in
particular, $Q^{(0)}$ is the configuration manifold for $N$ particles in $M$).
We will observe that $G^{(k)}$ is a normal subgroup of $G^{(0)}$ and so the
quotient $G^{(0)} / G^{(k)}$ is itself a (finite dimensional) Lie group which
acts on $Q^{(k)}$. This makes $Q^{(k)}$ a principle bundle over $Q^{(0)}$ and
the reduced geodesic equations on $Q^{(k)}$ will possess $G^{(0)} /
G^{(k)}$-symmetry. Noether's theorem implies the existence of conserved momenta
for the reduced system on $T^{\ast}Q^{(k)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3317</identifier>
 <datestamp>2015-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3317</id><created>2013-06-14</created><updated>2015-08-18</updated><authors><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author></authors><title>Sparse Auto-Regressive: Robust Estimation of AR Parameters</title><categories>cs.AI</categories><comments>4 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper I present a new approach for regression of time series using
their own samples. This is a celebrated problem known as Auto-Regression.
Dealing with outlier or missed samples in a time series makes the problem of
estimation difficult, so it should be robust against them. Moreover for coding
purposes I will show that it is desired the residual of auto-regression be
sparse. To these aims, I first assume a multivariate Gaussian prior on the
residual and then obtain the estimation. Two simple simulations have been done
on spectrum estimation and speech coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3323</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3323</id><created>2013-06-14</created><authors><author><keyname>Fan</keyname><forenames>Zhong</forenames></author><author><keyname>Haines</keyname><forenames>Russell J.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Parag</forenames></author></authors><title>M2M Communications for E-Health and Smart Grid: An Industry and Standard
  Perspective</title><categories>cs.CY cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An overview of several standardization activities for machine-to-machine
(M2M) communications is presented, analyzing some of the enabling technologies
and applications of M2M in industry sectors such as Smart Grid and e-Health.
This summary and overview of the ongoing work in M2M from the industrial and
standardization perspective complements the prevalent academic perspective of
such publications to date in this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3331</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3331</id><created>2013-06-14</created><authors><author><keyname>Asif</keyname><forenames>M. Salman</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author></authors><title>Sparse Recovery of Streaming Signals Using L1-Homotopy</title><categories>cs.IT math.IT math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the existing methods for sparse signal recovery assume a static
system: the unknown signal is a finite-length vector for which a fixed set of
linear measurements and a sparse representation basis are available and an
L1-norm minimization program is solved for the reconstruction. However, the
same representation and reconstruction framework is not readily applicable in a
streaming system: the unknown signal changes over time, and it is measured and
reconstructed sequentially over small time intervals.
  In this paper, we discuss two such streaming systems and a homotopy-based
algorithm for quickly solving the associated L1-norm minimization programs: 1)
Recovery of a smooth, time-varying signal for which, instead of using block
transforms, we use lapped orthogonal transforms for sparse representation. 2)
Recovery of a sparse, time-varying signal that follows a linear dynamic model.
For both the systems, we iteratively process measurements over a sliding
interval and estimate sparse coefficients by solving a weighted L1-norm
minimization program. Instead of solving a new L1 program from scratch at every
iteration, we use an available signal estimate as a starting point in a
homotopy formulation. Starting with a warm-start vector, our homotopy algorithm
updates the solution in a small number of computationally inexpensive steps as
the system changes. The homotopy algorithm presented in this paper is highly
versatile as it can update the solution for the L1 problem in a number of
dynamical settings. We demonstrate with numerical experiments that our proposed
streaming recovery framework outperforms the methods that represent and
reconstruct a signal as independent, disjoint blocks, in terms of quality of
reconstruction, and that our proposed homotopy-based updating scheme
outperforms current state-of-the-art solvers in terms of the computation time
and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3343</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3343</id><created>2013-06-14</created><updated>2014-02-12</updated><authors><author><keyname>Pan</keyname><forenames>Zheng</forenames></author><author><keyname>Zhang</keyname><forenames>Changshui</forenames></author></authors><title>Relaxed Sparse Eigenvalue Conditions for Sparse Estimation via
  Non-convex Regularized Regression</title><categories>cs.LG cs.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-convex regularizers usually improve the performance of sparse estimation
in practice. To prove this fact, we study the conditions of sparse estimations
for the sharp concave regularizers which are a general family of non-convex
regularizers including many existing regularizers. For the global solutions of
the regularized regression, our sparse eigenvalue based conditions are weaker
than that of L1-regularization for parameter estimation and sparseness
estimation. For the approximate global and approximate stationary (AGAS)
solutions, almost the same conditions are also enough. We show that the desired
AGAS solutions can be obtained by coordinate descent (CD) based methods.
Finally, we perform some experiments to show the performance of CD methods on
giving AGAS solutions and the degree of weakness of the estimation conditions
required by the sharp concave regularizers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3375</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3375</id><created>2013-06-14</created><authors><author><keyname>Poss</keyname><forenames>Raphael 'kena'</forenames></author></authors><title>The essence of component-based design and coordination</title><categories>cs.SE cs.PL</categories><comments>8 pages, 2 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is there a characteristic of coordination languages that makes them
qualitatively different from general programming languages and deserves special
academic attention? This report proposes a nuanced answer in three parts. The
first part highlights that coordination languages are the means by which
composite software applications can be specified using components that are only
available separately, or later in time, via standard interfacing mechanisms.
The second part highlights that most currently used languages provide
mechanisms to use externally provided components, and thus exhibit some
elements of coordination. However not all do, and the availability of an
external interface thus forms an objective and qualitative criterion that
distinguishes coordination. The third part argues that despite the qualitative
difference, the segregation of academic attention away from general language
design and implementation has non-obvious cost trade-offs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3378</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3378</id><created>2013-06-14</created><authors><author><keyname>Amelina</keyname><forenames>Natalia</forenames></author><author><keyname>Fradkov</keyname><forenames>Alexander</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author><author><keyname>Vergados</keyname><forenames>Dimitrios J.</forenames></author></authors><title>Approximate Consensus Multi-Agent Control Under Stochastic Environment
  with Application to Load Balancing</title><categories>cs.SY</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to the approximate consensus problem for networks of
nonlinear agents with switching topology, noisy and delayed measurements. In
contrast to the existing stochastic approximation-based control algorithms
(protocols), a local voting protocol with nonvanishing step size is proposed.
Nonvanishing (e.g., constant) step size protocols give the opportunity to
achieve better convergence rate (by choosing proper step sizes) in coping with
time-varying loads and agent states. The price to pay is replacement of the
mean square convergence with an approximate one. To analyze dynamics of the
closed loop system, the so-called method of averaged models is used. It allows
to reduce analysis complexity of the closed loop system. In this paper the
upper bounds for mean square distance between the initial system and its
approximate averaged model are proposed. The proposed upper bounds are used to
obtain conditions for approximate consensus achievement.
  The method is applied to the load balancing problem in stochastic dynamic
networks with incomplete information about the current states of agents and
with changing set of communication links. The load balancing problem is
formulated as consensus problem in noisy model with switched topology. The
conditions to achieve the optimal level of load balancing (in the sense that if
no new task arrives, all agents will finish at the same time) are obtained.
  The performance of the system is evaluated analytically and by simulation. It
is shown that the performance of the adaptive multi-agent strategy with the
redistribution of tasks among &quot;connected&quot; neighbors is significantly better
than the performance without redistribution. The obtained results are important
for control of production networks, multiprocessor, sensor or multicomputer
networks, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3390</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3390</id><created>2013-06-14</created><updated>2013-12-16</updated><authors><author><keyname>Bank</keyname><forenames>Bernd</forenames></author><author><keyname>Giusti</keyname><forenames>Marc</forenames></author><author><keyname>Heintz</keyname><forenames>Joos</forenames></author><author><keyname>Lecerf</keyname><forenames>Gr&#xe9;goire</forenames></author><author><keyname>Matera</keyname><forenames>Guillermo</forenames></author><author><keyname>Solern&#xf3;</keyname><forenames>Pablo</forenames></author></authors><title>Degeneracy loci and polynomial equation solving</title><categories>math.AG cs.SC</categories><comments>24 pages, accepted for publication in Found. Comput. Math</comments><msc-class>14Q20 (Primary) 14M10, 14M12, 14P05, 68W30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let V be a smooth equidimensional quasi-affine variety of dimension r over
the complex numbers $C$ and let $F$ be a $(p\times s)$-matrix of coordinate
functions of $C[V]$, where $s\ge p+r$. The pair $(V,F)$ determines a vector
bundle $E$ of rank $s-p$ over $W:=\{x\in V:\mathrm{rk} F(x)=p\}$. We associate
with $(V,F)$ a descending chain of degeneracy loci of E (the generic polar
varieties of $V$ represent a typical example of this situation).
  The maximal degree of these degeneracy loci constitutes the essential
ingredient for the uniform, bounded error probabilistic pseudo-polynomial time
algorithm which we are going to design and which solves a series of
computational elimination problems that can be formulated in this framework. We
describe applications to polynomial equation solving over the reals and to the
computation of a generic fiber of a dominant endomorphism of an affine space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3391</identifier>
 <datestamp>2014-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3391</id><created>2013-06-14</created><updated>2014-07-01</updated><authors><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Wright</keyname><forenames>Stephen J.</forenames></author></authors><title>Local Convergence of an Algorithm for Subspace Identification from
  Partial Data</title><categories>cs.NA math.NA</categories><comments>29 pages. 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GROUSE (Grassmannian Rank-One Update Subspace Estimation) is an iterative
algorithm for identifying a linear subspace of R^n from data consisting of
partial observations of random vectors from that subspace. This paper examines
local convergence properties of GROUSE, under assumptions on the randomness of
the observed vectors, the randomness of the subset of elements observed at each
iteration, and incoherence of the subspace with the coordinate directions.
Convergence at an expected linear rate is demonstrated under certain
assumptions. The case in which the full random vector is revealed at each
iteration allows for much simpler analysis, and is also described. GROUSE is
related to incremental SVD methods and to gradient projection algorithms in
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3398</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3398</id><created>2013-06-14</created><updated>2013-10-11</updated><authors><author><keyname>Traag</keyname><forenames>V. A.</forenames></author><author><keyname>Krings</keyname><forenames>G.</forenames></author><author><keyname>Van Dooren</keyname><forenames>P.</forenames></author></authors><title>Significant Scales in Community Structure</title><categories>physics.soc-ph cs.DM cs.SI</categories><comments>To appear in Scientific Reports</comments><journal-ref>Scientific Reports 3, 2930 (2013)</journal-ref><doi>10.1038/srep02930</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many complex networks show signs of modular structure, uncovered by community
detection. Although many methods succeed in revealing various partitions, it
remains difficult to detect at what scale some partition is significant. This
problem shows foremost in multi-resolution methods. We here introduce an
efficient method for scanning for resolutions in one such method. Additionally,
we introduce the notion of &quot;significance&quot; of a partition, based on subgraph
probabilities. Significance is independent of the exact method used, so could
also be applied in other methods, and can be interpreted as the gain in
encoding a graph by making use of a partition. Using significance, we can
determine &quot;good&quot; resolution parameters, which we demonstrate on benchmark
networks. Moreover, optimizing significance itself also shows excellent
performance. We demonstrate our method on voting data from the European
Parliament. Our analysis suggests the European Parliament has become
increasingly ideologically divided and that nationality plays no role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3409</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3409</id><created>2013-06-14</created><authors><author><keyname>B&#xfc;hler</keyname><forenames>Thomas</forenames></author><author><keyname>Rangapuram</keyname><forenames>Syama Sundar</forenames></author><author><keyname>Setzer</keyname><forenames>Simon</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author></authors><title>Constrained fractional set programs and their application in local
  clustering and community detection</title><categories>stat.ML cs.LG math.OC</categories><comments>Long version of paper accepted at ICML 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The (constrained) minimization of a ratio of set functions is a problem
frequently occurring in clustering and community detection. As these
optimization problems are typically NP-hard, one uses convex or spectral
relaxations in practice. While these relaxations can be solved globally
optimally, they are often too loose and thus lead to results far away from the
optimum. In this paper we show that every constrained minimization problem of a
ratio of non-negative set functions allows a tight relaxation into an
unconstrained continuous optimization problem. This result leads to a flexible
framework for solving constrained problems in network analysis. While a
globally optimal solution for the resulting non-convex problem cannot be
guaranteed, we outperform the loose convex or spectral relaxations by a large
margin on constrained local clustering problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3414</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3414</id><created>2013-06-14</created><updated>2014-04-02</updated><authors><author><keyname>Gale</keyname><forenames>Ella</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Costello</keyname><forenames>Ben de Lacy</forenames></author></authors><title>Slime Mould Memristors</title><categories>cs.ET cond-mat.other physics.bio-ph</categories><comments>14 pages, 6 figures</comments><msc-class>92Cxx, 68Uxx, 92Fxx, 94Cxx</msc-class><acm-class>B.6.1; C.1.3; C.1.m; J.3; J.2</acm-class><doi>10.1007/s12668-014-0156-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In laboratory experiments we demonstrate that protoplasmic tubes of acellular
slime mould \emph{Physarum polycephalum} show current versus voltage profiles
consistent with memristive systems and that the effect is due to the living
protoplasm of the mould. This complements previous findings on memristive
properties of other living systems (human skin and blood) and contributes to
development of self-growing bio-electronic circuits. Distinctive asymmetric
$V$-$I$ curves which were occasionally observed when the internal current is on
the same order as the driven current, are well-modelled by the concept of
active memristors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3415</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3415</id><created>2013-06-14</created><authors><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author></authors><title>Live-wire 3D medical images segmentation</title><categories>cs.CV</categories><comments>University of Oxford B.A. Thesis, 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report describes the design, implementation, evaluation and original
enhancements to the Live-Wire method for 2D and 3D image segmentation.
Live-Wire 2D employs a semi-automatic paradigm; the user is asked to select a
few boundary points of the object to segment, to steer the process in the right
direction, while the result is displayed in real time. In our implementation
segmentation is extended to three dimensions by performing this process on a
slice-by-slice basis. User's time and involvement is further reduced by
allowing him to specify object contours in planes orthogonal to the slices. If
these planes are chosen strategically, Live-Wire 3D can perform 2D segmentation
in the plane of each slice automatically. This report also proposes two
improvements to the original method, path heating and a new graph edge feature
function based on variance of path properties along the boundary. We show that
these improvements lead up to a 33% reduction in interaction with the user, and
improved delineation in presence of strong interfering edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3418</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3418</id><created>2013-06-14</created><authors><author><keyname>Manuel</keyname><forenames>Amaldev</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author><author><keyname>Zeume</keyname><forenames>Thomas</forenames></author></authors><title>A Short Note on Two-Variable Logic with a Linear Order Successor and a
  Preorder Successor</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The finite satisfiability problem of two-variable logic extended by a linear
order successor and a preorder successor is shown to be undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3422</identifier>
 <datestamp>2014-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3422</id><created>2013-06-14</created><authors><author><keyname>Krause</keyname><forenames>Sebastian M.</forenames></author><author><keyname>Peixoto</keyname><forenames>Tiago P.</forenames></author><author><keyname>Bornholdt</keyname><forenames>Stefan</forenames></author></authors><title>Spontaneous centralization of control in a network of company ownerships</title><categories>physics.soc-ph cs.SI q-fin.GN</categories><comments>5 Pages, 7 figures</comments><journal-ref>PLoS ONE 8(12): e80303 (2013)</journal-ref><doi>10.1371/journal.pone.0080303</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce a model for the adaptive evolution of a network of company
ownerships. In a recent work it has been shown that the empirical global
network of corporate control is marked by a central, tightly connected &quot;core&quot;
made of a small number of large companies which control a significant part of
the global economy. Here we show how a simple, adaptive &quot;rich get richer&quot;
dynamics can account for this characteristic, which incorporates the increased
buying power of more influential companies, and in turn results in even higher
control. We conclude that this kind of centralized structure can emerge without
it being an explicit goal of these companies, or as a result of a
well-organized strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3426</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3426</id><created>2013-06-14</created><authors><author><keyname>Burgain</keyname><forenames>Pierrick</forenames></author><author><keyname>Kim</keyname><forenames>Sang Hyun</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Valuating Surface Surveillance Technology for Collaborative
  Multiple-Spot Control of Airport Departure Operations</title><categories>cs.OH</categories><comments>Submitted to IEEE Transactions on Intelligent Transportation Systems.
  arXiv admin note: substantial text overlap with arXiv:1102.2673</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Airport departure operations are a source of airline delays and passenger
frustration. Excessive surface traffic is a cause of increased controller and
pilot workload. It is also a source of increased emissions and delays, and does
not yield improved runway throughput. Leveraging the extensive past research on
airport departure management, this paper explores the environmental and safety
benefits that improved surveillance technologies can bring in the context of
gate- or spot-release strategies. The paper shows that improved surveillance
technologies can yield 4% to 6% reduction of aircraft on taxiway, and therefore
emissions, in addition to the savings currently observed by implementing
threshold starategies under evaluation at Boston Logan Airport and other busy
airports during congested periods. These calculated benefits contrast sharply
with our previous work, which relied on simplified airport ramp areas with a
single departure spot, and where fewer environmental and economic benefits of
advanced surface surveillance systems could be established. Our work is
illustrated by its application to New-York LaGuardia and Seattle Tacoma
airports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3429</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3429</id><created>2013-06-14</created><authors><author><keyname>Kim</keyname><forenames>Sang Hyun</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Impact of Gate Assignment on Gate-Holding Departure Control Strategies</title><categories>cs.OH</categories><comments>Submitted to IEEE Transactions on Intelligent Transportation Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gate holding reduces congestion by reducing the number of aircraft present on
the airport surface at any time, while not starving the runway. Because some
departing flights are held at gates, there is a possibility that arriving
flights cannot access the gates and have to wait until the gates are cleared.
This is called a gate conflict. Robust gate assignment is an assignment that
minimizes gate conflicts by assigning gates to aircraft to maximize the time
gap between two consecutive flights at the same gate; it makes gate assignment
robust, but passengers may walk longer to transfer flights. In order to
simulate the airport departure process, a queuing model is introduced. The
model is calibrated and validated with actual data from New York La Guardia
Airport (LGA) and a U.S. hub airport. Then, the model simulates the airport
departure process with the current gate assignment and a robust gate assignment
to assess the impact of gate assignment on gate-holding departure control. The
results show that the robust gate assignment reduces the number of gate
conflicts caused by gate holding compared to the current gate assignment.
Therefore, robust gate assignment can be combined with gate-holding departure
control to improve operations at congested airports with limited gate
resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3432</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3432</id><created>2013-06-14</created><updated>2015-05-26</updated><authors><author><keyname>Kamalapurkar</keyname><forenames>Rushikesh</forenames></author><author><keyname>Rosenfeld</keyname><forenames>Joel A.</forenames></author><author><keyname>Klotz</keyname><forenames>Justin</forenames></author><author><keyname>Downey</keyname><forenames>Ryan J.</forenames></author><author><keyname>Dixon</keyname><forenames>Warren E.</forenames></author></authors><title>Supporting Lemmas for RISE-based Control Methods</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of continuous controllers termed Robust Integral of the Signum of the
Error (RISE) have been published over the last decade as a means to yield
asymptotic convergence of the tracking error for classes of nonlinear systems
that are subject to exogenous disturbances and/or modeling uncertainties. The
development of this class of controllers relies on a property related to the
integral of the signum of an error signal. A proof for this property is not
available in previous literature. The stability of some RISE controllers is
analyzed using differential inclusions. Such results rely on the hypothesis
that a set of points is Lebesgue negligible. This paper states and proves two
lemmas related to the properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3440</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3440</id><created>2013-06-14</created><authors><author><keyname>de Paula</keyname><forenames>Amanda</forenames></author><author><keyname>Panazio</keyname><forenames>Cristiano</forenames></author></authors><title>Comparison of OFDM and SC-DFE Capacities Without Channel Knowledge at
  the Transmitter</title><categories>cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter provides a capacity analysis between OFDM and the ideal SC-DFE
when no channel knowledge is available at the transmitter. Through some
algebraic manipulation of the OFDM and SC-DFE capacities and using the
concavity property of the manipulated capacity function and Jensen's
inequality, we are able to prove that the SC-DFE capacity is always superior to
that of an OFDM scheme for 4- and 16-QAM for any given channel. For
higher-order modulations, however, the results indicate that OFDM may only
surpass the ideal SC-DFE capacity by a small amount in some specific scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3452</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3452</id><created>2013-06-14</created><updated>2014-09-17</updated><authors><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Stein</keyname><forenames>Yannik</forenames></author></authors><title>Algorithms for Tolerant Tverberg Partitions</title><categories>cs.CG</categories><comments>13 pages, 5 figures</comments><journal-ref>International Journal of Computational Geometry and Applications
  (IJCGA), 24(4), 2014, pp. 261-273</journal-ref><doi>10.1142/S0218195914600073</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a $d$-dimensional $n$-point set. A partition $T$ of $P$ is called
a Tverberg partition if the convex hulls of all sets in $T$ intersect in at
least one point. We say $T$ is $t$-tolerant if it remains a Tverberg partition
after deleting any $t$ points from $P$. Sober\'{o}n and Strausz proved that
there is always a $t$-tolerant Tverberg partition with $\lceil n / (d+1)(t+1)
\rceil$ sets. However, so far no nontrivial algorithms for computing or
approximating such partitions have been presented.
  For $d \leq 2$, we show that the Sober\'{o}n-Strausz bound can be improved,
and we show how the corresponding partitions can be found in polynomial time.
For $d \geq 3$, we give the first polynomial-time approximation algorithm by
presenting a reduction to the Tverberg problem with no tolerance. Finally, we
show that it is coNP-complete to determine whether a given Tverberg partition
is t-tolerant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3456</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3456</id><created>2013-06-14</created><authors><author><keyname>Cheng</keyname><forenames>Chih-Hong</forenames></author><author><keyname>Shankar</keyname><forenames>Natarajan</forenames></author><author><keyname>Ruess</keyname><forenames>Harald</forenames></author><author><keyname>Bensalem</keyname><forenames>Saddek</forenames></author></authors><title>EFSMT: A Logical Framework for Cyber-Physical Systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of cyber-physical systems is challenging in that it includes the
analysis and synthesis of distributed and embedded real-time systems for
controlling, often in a nonlinear way, the environment. We address this
challenge with EFSMT, the exists-forall quantified first-order fragment of
propositional combinations over constraints (including nonlinear arithmetic),
as the logical framework and foundation for analyzing and synthesizing
cyber-physical systems. We demonstrate the expressiveness of EFSMT by reducing
a number of pivotal verification and synthesis problems to EFSMT. Exemplary
problems in this paper include synthesis for robust control via BIBO stability,
Lyapunov coefficient finding for nonlinear control systems, distributed
priority synthesis for orchestrating system components, and synthesis for
hybrid control systems. We are also proposing an algorithm for solving EFSMT
problems based on the interplay between two SMT solvers for respectively
solving universally and existentially quantified problems. This algorithms
builds on commonly used techniques in modern SMT solvers, and generalizes them
to quantifier reasoning by counterexample-guided constraint strengthening. The
EFSMT solver uses Bernstein polynomials for solving nonlinear arithmetic
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3474</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3474</id><created>2013-06-14</created><authors><author><keyname>Wang</keyname><forenames>Yijun</forenames></author></authors><title>Classifying Single-Trial EEG during Motor Imagery with a Small Training
  Set</title><categories>cs.LG cs.HC stat.ML</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Before the operation of a motor imagery based brain-computer interface (BCI)
adopting machine learning techniques, a cumbersome training procedure is
unavoidable. The development of a practical BCI posed the challenge of
classifying single-trial EEG with a small training set. In this letter, we
addressed this problem by employing a series of signal processing and machine
learning approaches to alleviate overfitting and obtained test accuracy similar
to training accuracy on the datasets from BCI Competition III and our own
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3476</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3476</id><created>2013-06-14</created><authors><author><keyname>Bergstra</keyname><forenames>James</forenames></author><author><keyname>Cox</keyname><forenames>David D.</forenames></author></authors><title>Hyperparameter Optimization and Boosting for Classifying Facial
  Expressions: How good can a &quot;Null&quot; Model be?</title><categories>cs.CV cs.LG stat.ML</categories><comments>Presented at the Workshop on Representation and Learning, ICML 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the goals of the ICML workshop on representation and learning is to
establish benchmark scores for a new data set of labeled facial expressions.
This paper presents the performance of a &quot;Null&quot; model consisting of
convolutions with random weights, PCA, pooling, normalization, and a linear
readout. Our approach focused on hyperparameter optimization rather than novel
model components. On the Facial Expression Recognition Challenge held by the
Kaggle website, our hyperparameter optimization approach achieved a score of
60% accuracy on the test data. This paper also introduces a new ensemble
construction variant that combines hyperparameter optimization with the
construction of ensembles. This algorithm constructed an ensemble of four
models that scored 65.5% accuracy. These scores rank 12th and 5th respectively
among the 56 challenge participants. It is worth noting that our approach was
developed prior to the release of the data set, and applied without
modification; our strong competition performance suggests that the TPE
hyperparameter optimization algorithm and domain expertise encoded in our Null
model can generalize to new image classification data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3478</identifier>
 <datestamp>2014-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3478</id><created>2013-06-14</created><updated>2014-10-22</updated><authors><author><keyname>Abdukhalikov</keyname><forenames>Kanat</forenames></author></authors><title>Symplectic spreads, planar functions and mutually unbiased bases</title><categories>math.CO cs.IT math.IT</categories><comments>20 pages</comments><msc-class>05B25, 51A40, 51E15, 12K10, 20B25, 17B20, 05B20</msc-class><doi>10.1007/s10801-014-0565-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give explicit descriptions of complete sets of mutually
unbiased bases (MUBs) and orthogonal decompositions of special Lie algebras
$sl_n(\mathbb{C})$ obtained from commutative and symplectic semifields, and
from some other non-semifield symplectic spreads. Relations between various
constructions are also studied. We show that the automorphism group of a
complete set of MUBs is isomorphic to the automorphism group of the
corresponding orthogonal decomposition of the Lie algebra $sl_n(\mathbb{C})$.
In the case of symplectic spreads this automorphism group is determined by the
automorphism group of the spread. By using the new notion of pseudo-planar
functions over fields of characteristic two we give new explicit constructions
of complete sets of MUBs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3480</identifier>
 <datestamp>2013-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3480</id><created>2013-06-14</created><updated>2013-07-24</updated><authors><author><keyname>Lee</keyname><forenames>Orlando</forenames></author><author><keyname>Rey</keyname><forenames>Mario Leston</forenames></author></authors><title>A Faster Algorithm for Packing Branchings in Digraphs</title><categories>cs.DM math.CO</categories><comments>We are fixing a flaw in the proof</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding an integral packing of branchings in a
capacitated digraph with root-set demands. Schrijver described an algorithm
that returns a packing with at most m+n^3+r branchings that makes at most
m(m+n^3+r) calls to an oracle that basically computes a minimum cut, where n is
the number of vertices, m is the number of arcs and r is the number of
root-sets of the input digraph. In this work we provide an algorithm, inspired
on ideas of Schrijver and on an paper of Gabow and Manu, that returns a packing
with at most m+r-1 branchings and makes at most 2n+m+r-1 oracle calls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3481</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3481</id><created>2013-06-14</created><authors><author><keyname>Kent</keyname><forenames>Brian R.</forenames></author></authors><title>Visualizing Astronomical Data with Blender</title><categories>astro-ph.IM cs.GR</categories><comments>39 pages, 18 figures. Accepted for publication in the Publications of
  the Astronomical Society of the Pacific (PASP). A high resolution copy and
  figures are available at
  http://www.cv.nrao.edu/~bkent/computing/kentPASP.html along with a companion
  video, tutorials, and examples</comments><doi>10.1086/671412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Astronomical data take on a multitude of forms -- catalogs, data cubes,
images, and simulations. The availability of software for rendering
high-quality three-dimensional graphics lends itself to the paradigm of
exploring the incredible parameter space afforded by the astronomical sciences.
The software program Blender gives astronomers a useful tool for displaying
data in a manner used by three-dimensional (3D) graphics specialists and
animators. The interface to this popular software package is introduced with
attention to features of interest in astronomy. An overview of the steps for
generating models, textures, animations, camera work, and renders is outlined.
An introduction is presented on the methodology for producing animations and
graphics with a variety of astronomical data. Examples from sub-fields of
astronomy with different kinds of data are shown with resources provided to
members of the astronomical community. An example video showcasing the outlined
principles and features is provided along with scripts and files for sample
visualizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3482</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3482</id><created>2013-06-14</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Simons</keyname><forenames>Joseph A.</forenames></author></authors><title>Set-Difference Range Queries</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the problem of performing set-difference range queries, where
answers to queries are set-theoretic symmetric differences between sets of
items in two geometric ranges. We describe a general framework for answering
such queries based on a novel use of data-streaming sketches we call signed
symmetric-difference sketches. We show that such sketches can be realized using
invertible Bloom filters (IBFs), which can be composed, differenced, and
searched so as to solve set-difference range queries in a wide range of
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3484</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3484</id><created>2013-06-14</created><authors><author><keyname>Gong</keyname><forenames>Xun</forenames></author><author><keyname>Kiyavash</keyname><forenames>Negar</forenames></author><author><keyname>Venkitasubramaniam</keyname><forenames>Parv</forenames></author></authors><title>An Information Theoretic Study of Timing Side Channels in Two-user
  Schedulers</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timing side channels in two-user schedulers are studied. When two users share
a scheduler, one user may learn the other user's behavior from patterns of
service timings. We measure the information leakage of the resulting timing
side channel in schedulers serving a legitimate user and a malicious attacker,
using a privacy metric defined as the Shannon equivocation of the user's job
density. We show that the commonly used first-come-first-serve (FCFS) scheduler
provides no privacy as the attacker is able to to learn the user's job pattern
completely. Furthermore, we introduce an scheduling policy,
accumulate-and-serve scheduler, which services jobs from the user and attacker
in batches after buffering them. The information leakage in this scheduler is
mitigated at the price of service delays, and the maximum privacy is achievable
when large delays are added.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3492</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3492</id><created>2013-06-14</created><authors><author><keyname>Singh</keyname><forenames>Shubh Narayan</forenames></author><author><keyname>Krishna</keyname><forenames>K. V.</forenames></author></authors><title>Syntactic Complexity of Circular Semi-Flower Automata</title><categories>cs.FL</categories><msc-class>68Q70, 68Q45, 20M35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the syntactic complexity of certain types of finitely
generated submonoids of a free monoid. In fact, we consider those submonoids
which are accepted by circular semi-flower automata (CSFA). Here, we show that
the syntactic complexity of CSFA with at most one `branch point going in' (bpi)
is linear. Further, we prove that the syntactic complexity of $n$-state CSFA
with two bpis over a binary alphabet is $2n(n+1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3507</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3507</id><created>2013-06-14</created><authors><author><keyname>Champarnaud</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Ouardi</keyname><forenames>Faissal</forenames></author><author><keyname>Ziadi</keyname><forenames>Djelloul</forenames></author></authors><title>Extended to Multi-Tilde-Bar Regular Expressions and Efficient Finite
  Automata Constructions</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several algorithms have been designed to convert a regular expression into an
equivalent finite automaton. One of the most popular constructions, due to
Glushkov and to McNaughton and Yamada, is based on the computation of the Null,
First, Last and Follow sets (called Glushkov functions) associated with a
linearized version of the expression. Recently Mignot considered a family of
extended expressions called Extended to multi-tilde-bar Regular Expressions
(EmtbREs) and he showed that, under some restrictions, Glushkov functions can
be defined for an EmtbRE. In this paper we present an algorithm which
efficiently computes the Glushkov functions of an unrestricted EmtbRE. Our
approach is based on a recursive definition of the language associated with an
EmtbRE which enlightens the fact that the worst case time complexity of the
conversion of an EmtbRE into an automaton is related to the worst case time
complexity of the computation of the Null function. Finally we show how to
extend the ZPC-structure to EmtbREs, which allows us to apply to this family of
extended expressions the efficient constructions based on this structure (in
particular the construction of the c-continuation automaton, the position
automaton, the follow automaton and the equation automaton).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3513</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3513</id><created>2013-06-14</created><updated>2013-07-01</updated><authors><author><keyname>Liu</keyname><forenames>Yuhang</forenames></author><author><keyname>Wang</keyname><forenames>Zizhuo</forenames></author></authors><title>A Simple Policy for Multiple Queues with Size-Independent Service Times</title><categories>math.OC cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a service system with two Poisson arrival queues. A server
chooses which queue to serve at each moment. Once a queue is served, all the
customers will be served within a fixed amount of time. This model is useful in
studying airport shuttling or certain online computing systems. We propose a
simple yet optimal state-independent policy for this problem which is not only
easy to implement, but also performs very well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3517</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3517</id><created>2013-06-14</created><authors><author><keyname>Gliwa</keyname><forenames>Bogdan</forenames></author><author><keyname>Br&#xf3;dka</keyname><forenames>Piotr</forenames></author><author><keyname>Zygmunt</keyname><forenames>Anna</forenames></author><author><keyname>Saganowski</keyname><forenames>Stanis&#x142;aw</forenames></author><author><keyname>Kazienko</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Ko&#x17a;lak</keyname><forenames>Jaros&#x142;aw</forenames></author></authors><title>Different Approaches to Community Evolution Prediction in Blogosphere</title><categories>cs.SI physics.soc-ph</categories><comments>SNAA2013 at ASONAM2013 IEEE Computer Society</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the future direction of community evolution is a problem with high
theoretical and practical significance. It allows to determine which
characteristics describing communities have importance from the point of view
of their future behaviour. Knowledge about the probable future career of the
community aids in the decision concerning investing in contact with members of
a given community and carrying out actions to achieve a key position in it. It
also allows to determine effective ways of forming opinions or to protect group
participants against such activities. In the paper, a new approach to group
identification and prediction of future events is presented together with the
comparison to existing method. Performed experiments prove a high quality of
prediction results. Comparison to previous studies shows that using many
measures to describe the group profile, and in consequence as a classifier
input, can improve predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3524</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3524</id><created>2013-06-14</created><authors><author><keyname>Rajendran</keyname><forenames>Karthikeyan</forenames></author><author><keyname>Kevrekidis</keyname><forenames>Ioannis G.</forenames></author></authors><title>Analysis of data in the form of graphs</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>15 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the problem of extending data mining approaches to cases in which
data points arise in the form of individual graphs. Being able to find the
intrinsic low-dimensionality in ensembles of graphs can be useful in a variety
of modeling contexts, especially when coarse-graining the detailed graph
information is of interest. One of the main challenges in mining graph data is
the definition of a suitable pairwise similarity metric in the space of graphs.
We explore two practical solutions to solving this problem: one based on
finding subgraph densities, and one using spectral information. The approach is
illustrated on three test data sets (ensembles of graphs); two of these are
obtained from standard graph generating algorithms, while the graphs in the
third example are sampled as dynamic snapshots from an evolving network
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3525</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3525</id><created>2013-06-14</created><updated>2013-07-17</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author></authors><title>Approximation Algorithms for Bayesian Multi-Armed Bandit Problems</title><categories>cs.DS cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1011.1161</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider several finite-horizon Bayesian multi-armed bandit
problems with side constraints which are computationally intractable (NP-Hard)
and for which no optimal (or near optimal) algorithms are known to exist with
sub-exponential running time. All of these problems violate the standard
exchange property, which assumes that the reward from the play of an arm is not
contingent upon when the arm is played. Not only are index policies suboptimal
in these contexts, there has been little analysis of such policies in these
problem settings. We show that if we consider near-optimal policies, in the
sense of approximation algorithms, then there exists (near) index policies.
Conceptually, if we can find policies that satisfy an approximate version of
the exchange property, namely, that the reward from the play of an arm depends
on when the arm is played to within a constant factor, then we have an avenue
towards solving these problems. However such an approximate version of the
idling bandit property does not hold on a per-play basis and are shown to hold
in a global sense. Clearly, such a property is not necessarily true of
arbitrary single arm policies and finding such single arm policies is
nontrivial. We show that by restricting the state spaces of arms we can find
single arm policies and that these single arm policies can be combined into
global (near) index policies where the approximate version of the exchange
property is true in expectation. The number of different bandit problems that
can be addressed by this technique already demonstrate its wide applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3529</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3529</id><created>2013-06-14</created><authors><author><keyname>Raymond</keyname><forenames>Alexandre J.</forenames></author><author><keyname>Gross</keyname><forenames>Warren J.</forenames></author></authors><title>Scalable Successive-Cancellation Hardware Decoder for Polar Codes</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2014.2347262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes, discovered by Ar{\i}kan, are the first error-correcting codes
with an explicit construction to provably achieve channel capacity,
asymptotically. However, their error-correction performance at finite lengths
tends to be lower than existing capacity-approaching schemes. Using the
successive-cancellation algorithm, polar decoders can be designed for very long
codes, with low hardware complexity, leveraging the regular structure of such
codes. We present an architecture and an implementation of a scalable hardware
decoder based on this algorithm. This design is shown to scale to code lengths
of up to N = 2^20 on an Altera Stratix IV FPGA, limited almost exclusively by
the amount of available SRAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3532</identifier>
 <datestamp>2015-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3532</id><created>2013-06-14</created><updated>2015-02-06</updated><authors><author><keyname>Janson</keyname><forenames>Lucas</forenames></author><author><keyname>Schmerling</keyname><forenames>Edward</forenames></author><author><keyname>Clark</keyname><forenames>Ashley</forenames></author><author><keyname>Pavone</keyname><forenames>Marco</forenames></author></authors><title>Fast Marching Tree: a Fast Marching Sampling-Based Method for Optimal
  Motion Planning in Many Dimensions</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel probabilistic sampling-based motion planning
algorithm called the Fast Marching Tree algorithm (FMT*). The algorithm is
specifically aimed at solving complex motion planning problems in
high-dimensional configuration spaces. This algorithm is proven to be
asymptotically optimal and is shown to converge to an optimal solution faster
than its state-of-the-art counterparts, chiefly PRM* and RRT*. The FMT*
algorithm performs a &quot;lazy&quot; dynamic programming recursion on a predetermined
number of probabilistically-drawn samples to grow a tree of paths, which moves
steadily outward in cost-to-arrive space. As a departure from previous analysis
approaches that are based on the notion of almost sure convergence, the FMT*
algorithm is analyzed under the notion of convergence in probability: the extra
mathematical flexibility of this approach allows for convergence rate
bounds--the first in the field of optimal sampling-based motion planning.
Specifically, for a certain selection of tuning parameters and configuration
spaces, we obtain a convergence rate bound of order $O(n^{-1/d+\rho})$, where
$n$ is the number of sampled points, $d$ is the dimension of the configuration
space, and $\rho$ is an arbitrarily small constant. We go on to demonstrate
asymptotic optimality for a number of variations on FMT*, namely when the
configuration space is sampled non-uniformly, when the cost is not arc length,
and when connections are made based on the number of nearest neighbors instead
of a fixed connection radius. Numerical experiments over a range of dimensions
and obstacle configurations confirm our theoretical and heuristic arguments by
showing that FMT*, for a given execution time, returns substantially better
solutions than either PRM* or RRT*, especially in high-dimensional
configuration spaces and in scenarios where collision-checking is expensive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3534</identifier>
 <datestamp>2014-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3534</id><created>2013-06-14</created><updated>2014-12-04</updated><authors><author><keyname>Vulimiri</keyname><forenames>Ashish</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Gorge</keyname><forenames>Sri Varsha</forenames></author><author><keyname>Liu</keyname><forenames>Zitian</forenames></author><author><keyname>Shenker</keyname><forenames>Scott</forenames></author></authors><title>A cost-benefit analysis of low latency via added utilization</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several recently proposed techniques achieve latency reduction by trading it
off for some amount of additional bandwidth usage. But how would one quantify
whether the tradeoff is actually beneficial in a given system? We develop an
economic cost vs. benefit analysis for answering this question. We use the
analysis to derive a benchmark for wide-area client-server applications, and
demonstrate how it can be applied to reason about a particular latency saving
technique --- redundant DNS requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3538</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3538</id><created>2013-06-14</created><authors><author><keyname>Okamoto</keyname><forenames>Yoshio</forenames></author><author><keyname>Tatsu</keyname><forenames>Yuichi</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>Exact and fixed-parameter algorithms for metro-line crossing
  minimization problems</title><categories>cs.DS</categories><comments>19 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A metro-line crossing minimization problem is to draw multiple lines on an
underlying graph that models stations and rail tracks so that the number of
crossings of lines becomes minimum. It has several variations by adding
restrictions on how lines are drawn. Among those, there is one with a
restriction that line terminals have to be drawn at a verge of a station, and
it is known to be NP-hard even when underlying graphs are paths. This paper
studies the problem in this setting, and propose new exact algorithms. We first
show that a problem to decide if lines can be drawn without crossings is solved
in polynomial time, and propose a fast exponential algorithm to solve a
crossing minimization problem. We then propose a fixed-parameter algorithm with
respect to the multiplicity of lines, which implies that the problem is FPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3542</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3542</id><created>2013-06-14</created><updated>2013-06-24</updated><authors><author><keyname>Anwar</keyname><forenames>Saadat</forenames></author><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Inoue</keyname><forenames>Katsumi</forenames></author></authors><title>Encoding Petri Nets in Answer Set Programming for Simulation Based
  Reasoning</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of our long term research goals is to develop systems to answer realistic
questions (e.g., some mentioned in textbooks) about biological pathways that a
biologist may ask. To answer such questions we need formalisms that can model
pathways, simulate their execution, model intervention to those pathways, and
compare simulations under different circumstances. We found Petri Nets to be
the starting point of a suitable formalism for the modeling and simulation
needs. However, we need to make extensions to the Petri Net model and also
reason with multiple simulation runs and parallel state evolutions. Towards
that end Answer Set Programming (ASP) implementation of Petri Nets would allow
us to do both. In this paper we show how ASP can be used to encode basic Petri
Nets in an intuitive manner. We then show how we can modify this encoding to
model several Petri Net extensions by making small changes. We then highlight
some of the reasoning capabilities that we will use to accomplish our ultimate
research goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3543</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3543</id><created>2013-06-14</created><updated>2013-06-18</updated><authors><author><keyname>Burns</keyname><forenames>Randal</forenames></author><author><keyname>Roncal</keyname><forenames>William Gray</forenames></author><author><keyname>Kleissas</keyname><forenames>Dean</forenames></author><author><keyname>Lillaney</keyname><forenames>Kunal</forenames></author><author><keyname>Manavalan</keyname><forenames>Priya</forenames></author><author><keyname>Perlman</keyname><forenames>Eric</forenames></author><author><keyname>Berger</keyname><forenames>Daniel R.</forenames></author><author><keyname>Bock</keyname><forenames>Davi D.</forenames></author><author><keyname>Chung</keyname><forenames>Kwanghun</forenames></author><author><keyname>Grosenick</keyname><forenames>Logan</forenames></author><author><keyname>Kasthuri</keyname><forenames>Narayanan</forenames></author><author><keyname>Weiler</keyname><forenames>Nicholas C.</forenames></author><author><keyname>Deisseroth</keyname><forenames>Karl</forenames></author><author><keyname>Kazhdan</keyname><forenames>Michael</forenames></author><author><keyname>Lichtman</keyname><forenames>Jeff</forenames></author><author><keyname>Reid</keyname><forenames>R. Clay</forenames></author><author><keyname>Smith</keyname><forenames>Stephen J.</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author><author><keyname>Vogelstein</keyname><forenames>Joshua T.</forenames></author><author><keyname>Vogelstein</keyname><forenames>R. Jacob</forenames></author></authors><title>The Open Connectome Project Data Cluster: Scalable Analysis and Vision
  for High-Throughput Neuroscience</title><categories>cs.DC cs.CE q-bio.NC</categories><comments>11 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a scalable database cluster for the spatial analysis and
annotation of high-throughput brain imaging data, initially for 3-d electron
microscopy image stacks, but for time-series and multi-channel data as well.
The system was designed primarily for workloads that build connectomes---neural
connectivity maps of the brain---using the parallel execution of computer
vision algorithms on high-performance compute clusters. These services and
open-science data sets are publicly available at http://openconnecto.me.
  The system design inherits much from NoSQL scale-out and data-intensive
computing architectures. We distribute data to cluster nodes by partitioning a
spatial index. We direct I/O to different systems---reads to parallel disk
arrays and writes to solid-state storage---to avoid I/O interference and
maximize throughput. All programming interfaces are RESTful Web services, which
are simple and stateless, improving scalability and usability. We include a
performance evaluation of the production system, highlighting the effectiveness
of spatial data organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3546</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3546</id><created>2013-06-14</created><authors><author><keyname>Spencer</keyname><forenames>Jason</forenames></author></authors><title>Cellular Automata in Cryptographic Random Generators</title><categories>cs.CR</categories><comments>113 pgs, 67 pgs of Content, 6 figures, 9 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic schemes using one-dimensional, three-neighbor cellular automata
as a primitive have been put forth since at least 1985. Early results showed
good statistical pseudorandomness, and the simplicity of their construction
made them a natural candidate for use in cryptographic applications. Since
those early days of cellular automata, research in the field of cryptography
has developed a set of tools which allow designers to prove a particular scheme
to be as hard as solving an instance of a well- studied problem, suggesting a
level of security for the scheme. However, little or no literature is available
on whether these cellular automata can be proved secure under even generous
assumptions. In fact, much of the literature falls short of providing complete,
testable schemes to allow such an analysis.
  In this thesis, we first examine the suitability of cellular automata as a
primitive for building cryptographic primitives. In this effort, we focus on
pseudorandom bit generation and noninvertibility, the behavioral heart of
cryptography. In particular, we focus on cyclic linear and non-linear au-
tomata in some of the common configurations to be found in the literature. We
examine known attacks against these constructions and, in some cases, improve
the results.
  Finding little evidence of provable security, we then examine whether the
desirable properties of cellular automata (i.e. highly parallel, simple
construction) can be maintained as the automata are enhanced to provide a
foundation for such proofs. This investigation leads us to a new construction
of a finite state cellular automaton (FSCA) which is NP-Hard to invert.
Finally, we introduce the Chasm pseudorandom generator family built on this
construction and provide some initial experimental results using the NIST test
suite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3548</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3548</id><created>2013-06-15</created><updated>2013-06-24</updated><authors><author><keyname>Anwar</keyname><forenames>Saadat</forenames></author><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Inoue</keyname><forenames>Katsumi</forenames></author></authors><title>Encoding Higher Level Extensions of Petri Nets in Answer Set Programming</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Answering realistic questions about biological systems and pathways similar
to the ones used by text books to test understanding of students about
biological systems is one of our long term research goals. Often these
questions require simulation based reasoning. To answer such questions, we need
formalisms to build pathway models, add extensions, simulate, and reason with
them. We chose Petri Nets and Answer Set Programming (ASP) as suitable
formalisms, since Petri Net models are similar to biological pathway diagrams;
and ASP provides easy extension and strong reasoning abilities. We found that
certain aspects of biological pathways, such as locations and substance types,
cannot be represented succinctly using regular Petri Nets. As a result, we need
higher level constructs like colored tokens. In this paper, we show how Petri
Nets with colored tokens can be encoded in ASP in an intuitive manner, how
additional Petri Net extensions can be added by making small code changes, and
how this work furthers our long term research goals. Our approach can be
adapted to other domains with similar modeling needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3551</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3551</id><created>2013-06-15</created><authors><author><keyname>Zillich</keyname><forenames>Michael</forenames></author><author><keyname>Bennewitz</keyname><forenames>Maren</forenames></author><author><keyname>Fox</keyname><forenames>Maria</forenames></author><author><keyname>Piater</keyname><forenames>Justus</forenames></author><author><keyname>Pangercic</keyname><forenames>Dejan</forenames></author></authors><title>Proceedings of the 2nd Workshop on Robots in Clutter: Preparing robots
  for the real world (Berlin, 2013)</title><categories>cs.RO</categories><acm-class>I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume represents the proceedings of the 2nd Workshop on Robots in
Clutter: Preparing robots for the real world, held June 27, 2013, at the
Robotics: Science and Systems conference in Berlin, Germany.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3558</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3558</id><created>2013-06-15</created><authors><author><keyname>Angiulli</keyname><forenames>Fabrizio</forenames></author><author><keyname>Fassetti</keyname><forenames>Fabio</forenames></author><author><keyname>Palopoli</keyname><forenames>Luigi</forenames></author><author><keyname>Manco</keyname><forenames>Giuseppe</forenames></author></authors><title>Outlying Property Detection with Numerical Attributes</title><categories>cs.LG cs.DB stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The outlying property detection problem is the problem of discovering the
properties distinguishing a given object, known in advance to be an outlier in
a database, from the other database objects. In this paper, we analyze the
problem within a context where numerical attributes are taken into account,
which represents a relevant case left open in the literature. We introduce a
measure to quantify the degree the outlierness of an object, which is
associated with the relative likelihood of the value, compared to the to the
relative likelihood of other objects in the database. As a major contribution,
we present an efficient algorithm to compute the outlierness relative to
significant subsets of the data. The latter subsets are characterized in a
&quot;rule-based&quot; fashion, and hence the basis for the underlying explanation of the
outlierness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3560</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3560</id><created>2013-06-15</created><authors><author><keyname>Fanello</keyname><forenames>Sean Ryan</forenames></author><author><keyname>Ciliberto</keyname><forenames>Carlo</forenames></author><author><keyname>Santoro</keyname><forenames>Matteo</forenames></author><author><keyname>Natale</keyname><forenames>Lorenzo</forenames></author><author><keyname>Metta</keyname><forenames>Giorgio</forenames></author><author><keyname>Rosasco</keyname><forenames>Lorenzo</forenames></author><author><keyname>Odone</keyname><forenames>Francesca</forenames></author></authors><title>iCub World: Friendly Robots Help Building Good Vision Data-Sets</title><categories>cs.CV</categories><comments>CVPR2013 Workshop: Ground Truth - What is a good dataset?. Portland,
  USA (June 28, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present and start analyzing the iCub World data-set, an
object recognition data-set, we acquired using a Human-Robot Interaction (HRI)
scheme and the iCub humanoid robot platform. Our set up allows for rapid
acquisition and annotation of data with corresponding ground truth. While more
constrained in its scopes -- the iCub world is essentially a robotics research
lab -- we demonstrate how the proposed data-set poses challenges to current
recognition systems. The iCubWorld data-set is publicly available. The data-set
can be downloaded from: http://www.iit.it/en/projects/data-sets.html.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3566</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3566</id><created>2013-06-15</created><authors><author><keyname>Kociumaka</keyname><forenames>Tomasz</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author></authors><title>Faster deterministic Feedback Vertex Set</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two new deterministic algorithms for the Feedback Vertex Set
problem parameterized by the solution size. We begin with a simple algorithm,
which runs in O*((2 + \phi)^k) time, where \phi &lt; 1.619 is the golden ratio. It
already surpasses the previously fastest O*((1+2sqrt(2))^k)-time deterministic
algorithm due to Cao et al. [SWAT 2010]. In our developments we follow the
approach of Cao et al., however, thanks to a new reduction rule, we obtain not
only better dependency on the parameter in the running time, but also a
solution with simple analysis and only a single branching rule. Then, we
present a modification of the algorithm which, using a more involved set of
branching rules, achieves O*(3.592^k) running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3576</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3576</id><created>2013-06-15</created><updated>2013-09-23</updated><authors><author><keyname>Halu</keyname><forenames>Arda</forenames></author><author><keyname>Mondragon</keyname><forenames>Raul J.</forenames></author><author><keyname>Panzarasa</keyname><forenames>Pietro</forenames></author><author><keyname>Bianconi</keyname><forenames>Ginestra</forenames></author></authors><title>Multiplex PageRank</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>(16 pages, 6 figures)</comments><journal-ref>PLoS ONE 8(10): e78293 (2013)</journal-ref><doi>10.1371/journal.pone.0078293</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many complex systems can be described as multiplex networks in which the same
nodes can interact with one another in different layers, thus forming a set of
interacting and co-evolving networks. Examples of such multiplex systems are
social networks where people are involved in different types of relationships
and interact through various forms of communication media. The ranking of nodes
in multiplex networks is one of the most pressing and challenging tasks that
research on complex networks is currently facing. When pairs of nodes can be
connected through multiple links and in multiple layers, the ranking of nodes
should necessarily reflect the importance of nodes in one layer as well as
their importance in other interdependent layers. In this paper, we draw on the
idea of biased random walks to define the Multiplex PageRank centrality measure
in which the effects of the interplay between networks on the centrality of
nodes are directly taken into account. In particular, depending on the
intensity of the interaction between layers, we define the Additive,
Multiplicative, Combined, and Neutral versions of Multiplex PageRank, and show
how each version reflects the extent to which the importance of a node in one
layer affects the importance the node can gain in another layer. We discuss
these measures and apply them to an online multiplex social network. Findings
indicate that taking the multiplex nature of the network into account helps
uncover the emergence of rankings of nodes that differ from the rankings
obtained from one single layer. Results provide support in favor of the
salience of multiplex centrality measures, like Multiplex PageRank, for
assessing the prominence of nodes embedded in multiple interacting networks,
and for shedding a new light on structural properties that would otherwise
remain undetected if each of the interacting networks were analyzed in
isolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3584</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3584</id><created>2013-06-15</created><authors><author><keyname>Kalchbrenner</keyname><forenames>Nal</forenames></author><author><keyname>Blunsom</keyname><forenames>Phil</forenames></author></authors><title>Recurrent Convolutional Neural Networks for Discourse Compositionality</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The compositionality of meaning extends beyond the single sentence. Just as
words combine to form the meaning of sentences, so do sentences combine to form
the meaning of paragraphs, dialogues and general discourse. We introduce both a
sentence model and a discourse model corresponding to the two levels of
compositionality. The sentence model adopts convolution as the central
operation for composing semantic vectors and is based on a novel hierarchical
convolutional neural network. The discourse model extends the sentence model
and is based on a recurrent neural network that is conditioned in a novel way
both on the current sentence and on the current speaker. The discourse model is
able to capture both the sequentiality of sentences and the interaction between
different speakers. Without feature engineering or pretraining and with simple
greedy decoding, the discourse model coupled to the sentence model obtains
state of the art performance on a dialogue act classification experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3601</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3601</id><created>2013-06-15</created><authors><author><keyname>Nguyen</keyname><forenames>Huy L.</forenames></author></authors><title>Approximate Nearest Neighbor Search in $\ell_p$</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new locality sensitive hashing (LSH) algorithm for
$c$-approximate nearest neighbor search in $\ell_p$ with $1&lt;p&lt;2$. For a
database of $n$ points in $\ell_p$, we achieve $O(dn^{\rho})$ query time and
$O(dn+n^{1+\rho})$ space, where $\rho \le O((\ln c)^2/c^p)$. This improves upon
the previous best upper bound $\rho\le 1/c$ by Datar et al. (SOCG 2004), and is
close to the lower bound $\rho \ge 1/c^p$ by O'Donnell, Wu and Zhou (ITCS
2011). The proof is a simple generalization of the LSH scheme for $\ell_2$ by
Andoni and Indyk (FOCS 2006).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3602</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3602</id><created>2013-06-15</created><authors><author><keyname>Chen</keyname><forenames>Shenshi</forenames></author><author><keyname>Chen</keyname><forenames>Zhixiang</forenames></author></authors><title>Faster Deterministic Algorithms for Packing, Matching and $t$-Dominating
  Set Problems</title><categories>cs.DS</categories><comments>ISAAC13 Submission. arXiv admin note: substantial text overlap with
  arXiv:1303.0478</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we devise three deterministic algorithms for solving the
$m$-set $k$-packing, $m$-dimensional $k$-matching, and $t$-dominating set
problems in time $O^*(5.44^{mk})$, $O^*(5.44^{(m-1)k})$ and $O^*(5.44^{t})$,
respectively. Although recently there has been remarkable progress on
randomized solutions to those problems, our bounds make good improvements on
the best known bounds for deterministic solutions to those problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3604</identifier>
 <datestamp>2014-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3604</id><created>2013-06-15</created><updated>2014-05-07</updated><authors><author><keyname>Zhang</keyname><forenames>Tian-Xian</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>OFDM Synthetic Aperture Radar Imaging with Sufficient Cyclic Prefix</title><categories>cs.IT math.IT</categories><comments>This version has been accepted by IEEE Transactions on Geoscience and
  Remote Sensing. IEEE Transactions on Geoscience and Remote Sensing 2014</comments><doi>10.1109/TGRS.2014.2322813</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The existing linear frequency modulated (LFM) (or step frequency) and random
noise synthetic aperture radar (SAR) systems may correspond to the frequency
hopping (FH) and direct sequence (DS) spread spectrum systems in the past
second and third generation wireless communications. Similar to the current and
future wireless communications generations, in this paper, we propose OFDM SAR
imaging, where a sufficient cyclic prefix (CP) is added to each OFDM pulse. The
sufficient CP insertion converts an inter-symbol interference (ISI) channel
from multipaths into multiple ISI-free subchannels as the key in a wireless
communications system, and analogously, it provides an inter-range-cell
interference (IRCI) free (high range resolution) SAR image in a SAR system. The
sufficient CP insertion along with our newly proposed SAR imaging algorithm
particularly for the OFDM signals also differentiates this paper from all the
existing studies in the literature on OFDM radar signal processing. Simulation
results are presented to illustrate the high range resolution performance of
our proposed CP based OFDM SAR imaging algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3609</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3609</id><created>2013-06-15</created><authors><author><keyname>Ma</keyname><forenames>Zongming</forenames></author><author><keyname>Wu</keyname><forenames>Yihong</forenames></author></authors><title>Volume Ratio, Sparsity, and Minimaxity under Unitarily Invariant Norms</title><categories>math.ST cs.IT math.IT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current paper presents a novel machinery for studying non-asymptotic
minimax estimation of high-dimensional matrices, which yields tight minimax
rates for a large collection of loss functions in a variety of problems.
  Based on the convex geometry of finite-dimensional Banach spaces, we first
develop a volume ratio approach for determining minimax estimation rates of
unconstrained normal mean matrices under all squared unitarily invariant norm
losses. In addition, we establish the minimax rates for estimating mean
matrices with submatrix sparsity, where the sparsity constraint introduces an
additional term in the rate whose dependence on the norm differs completely
from the rate of the unconstrained problem. Moreover, the approach is
applicable to the matrix completion problem under the low-rank constraint.
  The new method also extends beyond the normal mean model. In particular, it
yields tight rates in covariance matrix estimation and Poisson rate matrix
estimation problems for all unitarily invariant norms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3610</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3610</id><created>2013-06-15</created><authors><author><keyname>Schlegel</keyname><forenames>Christian</forenames></author><author><keyname>Burnashev</keyname><forenames>Marat</forenames></author></authors><title>Thresholds of Spatially Coupled Systems via Lyapunov's Method</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The threshold, or saturation phenomenon of spatially coupled systems is
revisited in the light of Lyapunov's theory of dynamical systems. It is shown
that an application of Lyapunov's direct method can be used to quantitatively
describe the threshold phenomenon, prove convergence, and compute threshold
values. This provides a general proof methodology for the various systems
recently studied. Examples of spatially coupled systems are given and their
thresholds are computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3612</identifier>
 <datestamp>2014-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3612</id><created>2013-06-15</created><updated>2013-06-20</updated><authors><author><keyname>Garcia</keyname><forenames>David</forenames></author><author><keyname>Zanetti</keyname><forenames>Marcelo Serrano</forenames></author><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author></authors><title>The Role of Emotions in Contributors Activity: A Case Study on the
  GENTOO Community</title><categories>cs.SE physics.soc-ph</categories><comments>submitted to the International Conference on Social Computing and Its
  Applications</comments><acm-class>D.2.8; D.2.9; K.4.3; K.6.1; K.8.3</acm-class><doi>10.1109/CGC.2013.71</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the relation between the emotions and the activity of contributors
in the Open Source Software project Gentoo. Our case study builds on extensive
data sets from the project's bug tracking platform Bugzilla, to quantify the
activity of contributors, and its mail archives, to quantify the emotions of
contributors by means of sentiment analysis. The Gentoo project is known for a
period of centralization within its bug triaging community. This was followed
by considerable changes in community organization and performance after the
sudden retirement of the central contributor. We analyse how this event
correlates with the negative emotions, both in bilateral email discussions with
the central contributor, and at the level of the whole community of
contributors. We then extend our study to consider the activity patterns on
Gentoo contributors in general. We find that contributors are more likely to
become inactive when they express strong positive or negative emotions in the
bug tracker, or when they deviate from the expected value of emotions in the
mailing list. We use these insights to develop a Bayesian classifier that
detects the risk of contributors leaving the project. Our analysis opens new
perspectives for measuring online contributor motivation by means of sentiment
analysis and for real-time predictions of contributor turnover in Open Source
Software projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3618</identifier>
 <datestamp>2015-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3618</id><created>2013-06-15</created><updated>2015-01-20</updated><authors><author><keyname>G&#xfc;l</keyname><forenames>G&#xf6;khan</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author></authors><title>Minimax Decentralized Detection for Bayesian Uncertainty</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimax decentralized detection is studied under two scenarios: with and
without a fusion center when the source of uncertainty is the Bayesian prior.
When there is no fusion center, the constraints in system design are
determined. Both for a single decision maker and multiple decision makers, the
maximum loss in detection performance due to robust decision making is
obtained. In the presence of a fusion center, the maximum achievable detection
performance is derived and is compared to that of a without fusion center
network. The results are finally generalized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3622</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3622</id><created>2013-06-15</created><authors><author><keyname>Zhou</keyname><forenames>Mingxin</forenames></author><author><keyname>Zhang</keyname><forenames>Leiming</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>A Differential Feedback Scheme Exploiting the Temporal and Spectral
  Correlation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel state information (CSI) provided by limited feedback channel can be
utilized to increase the system throughput. However, in multiple input multiple
output (MIMO) systems, the signaling overhead realizing this CSI feedback can
be quite large, while the capacity of the uplink feedback channel is typically
limited. Hence, it is crucial to reduce the amount of feedback bits. Prior work
on limited feedback compression commonly adopted the block fading channel model
where only temporal or spectral correlation in wireless channel is considered.
In this paper, we propose a differential feedback scheme with full use of the
temporal and spectral correlations to reduce the feedback load. Then, the
minimal differential feedback rate over MIMO doubly selective fading channel is
investigated. Finally, the analysis is verified by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3624</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3624</id><created>2013-06-16</created><authors><author><keyname>Lu</keyname><forenames>Shilin</forenames></author><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Strazdins</keyname><forenames>Peter</forenames></author></authors><title>Reporting an Experience on Design and Implementation of e-Health Systems
  on Azure Cloud</title><categories>cs.CY cs.DC</categories><comments>Submitted to third IEEE International Conference on Cloud and Green
  Computing (CGC 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic Health (e-Health) technology has brought the world with
significant transformation from traditional paper-based medical practice to
Information and Communication Technologies (ICT)-based systems for automatic
management (storage, processing, and archiving) of information. Traditionally
e-Health systems have been designed to operate within stovepipes on dedicated
networks, physical computers, and locally managed software platforms that make
it susceptible to many serious limitations including: 1) lack of on-demand
scalability during critical situations; 2) high administrative overheads and
costs; and 3) in-efficient resource utilization and energy consumption due to
lack of automation. In this paper, we present an approach to migrate the ICT
systems in the e-Health sector from traditional in-house Client/Server (C/S)
architecture to the virtualised cloud computing environment. To this end, we
developed two cloud-based e-Health applications (Medical Practice Management
System and Telemedicine Practice System) for demonstrating how cloud services
can be leveraged for developing and deploying such applications. The Windows
Azure cloud computing platform is selected as an example public cloud platform
for our study. We conducted several performance evaluation experiments to
understand the Quality Service (QoS) tradeoffs of our applications under
variable workload on Azure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3647</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3647</id><created>2013-06-16</created><authors><author><keyname>Siris</keyname><forenames>Vasilios A.</forenames></author><author><keyname>Anagnostopoulou</keyname><forenames>Maria</forenames></author></authors><title>Performance and Energy Efficiency of Mobile Data Offloading with
  Mobility Prediction and Prefetching</title><categories>cs.NI</categories><comments>Proc. IEEE Workshop on Convergence among Heterogeneous Wireless
  Systems in Future Internet (CONWIRE), held in conjunction with IEEE WoWMoM,
  June 2013. arXiv admin note: substantial text overlap with arXiv:1306.3177</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a detailed evaluation of procedures that exploit mobility
prediction and prefetching to enhance offloading of traffic from mobile
networks to WiFi hotspots, for both delay tolerant and delay sensitive traffic.
We consider empirical measurements and evaluate the percentage of offloaded
traffic, data transfer delay, and energy consumption of the proposed
procedures. Our results illustrate how various factors such as mobile, WiFi and
hotspot backhaul throughput, data size, number of hotspots, along with time and
throughput estimation errors, influence the performance and energy efficiency
of mobile data offloading enhanced with mobility prediction and prefetching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3649</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3649</id><created>2013-06-16</created><updated>2014-05-08</updated><authors><author><keyname>Cohen</keyname><forenames>David</forenames></author><author><keyname>Crampton</keyname><forenames>Jason</forenames></author><author><keyname>Gagarin</keyname><forenames>Andrei</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author></authors><title>Iterative Plan Construction for the Workflow Satisfiability Problem</title><categories>cs.DS</categories><journal-ref>Journal of Artificial Intelligence Research 51 (2014), pp.555-577</journal-ref><doi>10.1613/jair.4435</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \emph{Workflow Satisfiability Problem (WSP)} is a problem of practical
interest that arises whenever tasks need to be performed by authorized users,
subject to constraints defined by business rules. We are required to decide
whether there exists a \emph{plan} -- an assignment of tasks to authorized
users -- such that all constraints are satisfied. Several bespoke algorithms
have been constructed for solving the WSP, optimised to deal with constraints
(business rules) of particular types.
  It is natural to see the WSP as a subclass of the {\em Constraint
Satisfaction Problem (CSP)} in which the variables are tasks and the domain is
the set of users. What makes the WSP distinctive as a CSP is that we can assume
that the number of tasks is very small compared to the number of users. This is
in sharp contrast with traditional CSP models where the domain is small and the
number of variables is very large. As such, it is appropriate to ask for which
constraint languages the WSP is fixed-parameter tractable (FPT), parameterized
by the number of tasks. We have identified a new FPT constraint language,
user-independent constraint, that includes many of the constraints of interest
in business processing systems. We are also able to prove that the union of FPT
languages remains FPT if they satisfy a simple compatibility condition.
  In this paper we present our generic algorithm, in which plans are grouped
into equivalence classes, each class being associated with a \emph{pattern}. We
demonstrate that our generic algorithm has running time $O^*(2^{k\log k})$,
where $k$ is the number of tasks, for the language of user-independent
constraints. We also show that there is no algorithm of running time
$O^*(2^{o(k\log k)})$ for user-independent constraints unless the Exponential
Time Hypothesis fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3664</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3664</id><created>2013-06-16</created><authors><author><keyname>Chien</keyname><forenames>Chia-Hung</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author><author><keyname>Kuo</keyname><forenames>Sy-Yen</forenames></author></authors><title>Fault-tolerant Operations for Universal Blind Quantum Computation</title><categories>quant-ph cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind quantum computation is an appealing use of quantum information
technology because it can conceal both the client's data and the algorithm
itself from the server. However, problems need to be solved in the practical
use of blind quantum computation and fault-tolerance is a major challenge. On
an example circuit, the computational cost measured in T gates executed by the
client is 97 times more than performing the original computation directly,
without using the server, even before applying error correction. (The client
still benefits due to drastically reduced memory requirements.) Broadbent et
al. proposed running error correction over blind computation, but our first
protocol applies one layer of Steane's [[7,1,3]] code underneath instead. This
protocol has better fault tolerance, but still results in a substantial
overhead. We propose another protocol to reduce the client's computational load
by transferring the qubit preparation to the server. For each logical qubit
used in the computation, the client is only required to receive eight logical
qubits via teleportation then buffer two logical qubits before returning one.
This protocol also protects the client's fault-tolerant preparation of logical
qubits from a side-channel attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3677</identifier>
 <datestamp>2013-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3677</id><created>2013-06-16</created><authors><author><keyname>Mantri</keyname><forenames>Atul</forenames></author><author><keyname>Perez-Delgado</keyname><forenames>Carlos A.</forenames></author><author><keyname>Fitzsimons</keyname><forenames>Joseph F.</forenames></author></authors><title>Optimal Blind Quantum Computation</title><categories>quant-ph cs.CC</categories><journal-ref>Phys. Rev. Lett. 111, 230502 (2013)</journal-ref><doi>10.1103/PhysRevLett.111.230502</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind quantum computation allows a client with limited quantum capabilities
to interact with a remote quantum computer to perform an arbitrary quantum
computation, while keeping the description of that computation hidden from the
remote quantum computer. While a number of protocols have been proposed in
recent years, little is currently understood about the resources necessary to
accomplish the task. Here we present general techniques for upper and lower
bounding the quantum communication necessary to perform blind quantum
computation, and use these techniques to establish a concrete bounds for common
choices of the client's quantum capabilities. Our results show that the UBQC
protocol of Broadbent, Fitzsimons and Kashefi [1], comes within a factor of 8/3
of optimal when the client is restricted to preparing single qubits. However,
we describe a generalization of this protocol which requires exponentially less
quantum communication when the client has a more sophisticated device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3679</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3679</id><created>2013-06-16</created><authors><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Das</keyname><forenames>Shantanu</forenames></author></authors><title>Fractional Order Fuzzy Control of Nuclear Reactor Power with
  Thermal-Hydraulic Effects in the Presence of Random Network Induced Delay and
  Sensor Noise having Long Range Dependence</title><categories>math.OC cs.SY</categories><comments>33 pages, 19 figures</comments><journal-ref>Energy Conversion and Management, Volume 68, Pages 200-218, April
  2013</journal-ref><doi>10.1016/j.enconman.2013.01.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear state space modeling of a nuclear reactor has been done for the
purpose of controlling its global power in load following mode. The nonlinear
state space model has been linearized at different percentage of reactor powers
and a novel fractional order (FO) fuzzy proportional integral derivative (PID)
controller is designed using real coded Genetic Algorithm (GA) to control the
reactor power level at various operating conditions. The effectiveness of using
the fuzzy FOPID controller over conventional fuzzy PID controllers has been
shown with numerical simulations. The controllers tuned with the highest power
models are shown to work well at other operating conditions as well; over the
lowest power model based design and hence are robust with respect to the
changes in nuclear reactor operating power levels. This paper also analyzes the
degradation of nuclear reactor power signal due to network induced random
delays in shared communication network and due to sensor noise while being
fed-back to the Reactor Regulating System (RRS). The effect of long range
dependence (LRD) which is a practical consideration for the stochastic
processes like network induced delay and sensor noise has been tackled by
optimum tuning of FO fuzzy PID controllers using GA, while also taking the
operating point shift into consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3680</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3680</id><created>2013-06-16</created><authors><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Halder</keyname><forenames>Kaushik</forenames></author><author><keyname>Das</keyname><forenames>Shantanu</forenames></author><author><keyname>Gupta</keyname><forenames>Amitava</forenames></author></authors><title>Optimum Weight Selection Based LQR Formulation for the Design of
  Fractional Order PI{\lambda}D{\mu} Controllers to Handle a Class of
  Fractional Order Systems</title><categories>math.OC cs.SY</categories><comments>6 pages, 5 figures</comments><journal-ref>Computer Communication and Informatics (ICCCI), 2013 International
  Conference on, Coimbatore, Jan. 2013</journal-ref><doi>10.1109/ICCCI.2013.6466137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A weighted summation of Integral of Time Multiplied Absolute Error (ITAE) and
Integral of Squared Controller Output (ISCO) minimization based time domain
optimal tuning of fractional-order (FO) PID or PI{\lambda}D{\mu} controller is
proposed in this paper with a Linear Quadratic Regulator (LQR) based technique
that minimizes the change in trajectories of the state variables and the
control signal. A class of fractional order systems having single non-integer
order element which show highly sluggish and oscillatory open loop responses
have been tuned with an LQR based FOPID controller. The proposed controller
design methodology is compared with the existing time domain optimal tuning
techniques with respect to change in the trajectory of state variables,
tracking performance for change in set-point, magnitude of control signal and
also the capability of load disturbance suppression. A real coded genetic
algorithm (GA) has been used for the optimal choice of weighting matrices while
designing the quadratic regulator by minimizing the time domain integral
performance index. Credible simulation studies have been presented to justify
the proposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3682</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3682</id><created>2013-06-16</created><authors><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author></authors><title>Frequency Domain Design of Fractional Order PID Controller for AVR
  System Using Chaotic Multi-objective Optimization</title><categories>math.OC cs.SY</categories><comments>26 pages, 9 figures</comments><journal-ref>International Journal of Electrical Power &amp; Energy Systems, Volume
  51, Pages 106-118, October 2013</journal-ref><doi>10.1016/j.ijepes.2013.02.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fractional order (FO) PID or FOPID controller is designed for an Automatic
Voltage Regulator (AVR) system with the consideration of contradictory
performance objectives. An improved evolutionary Non-dominated Sorting Genetic
Algorithm (NSGA-II), augmented with a chaotic Henon map is used for the
multi-objective optimization based design procedure. The Henon map as the
random number generator outperforms the original NSGA-II algorithm and its
Logistic map assisted version for obtaining a better design trade-off with an
FOPID controller. The Pareto fronts showing the trade-offs between the
different design objectives have also been shown for both the FOPID controller
and the conventional PID controller to enunciate the relative merits and
demerits of each. The design is done in frequency domain and hence stability
and robustness of the design is automatically guaranteed unlike the other time
domain optimization based controller design methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3683</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3683</id><created>2013-06-16</created><authors><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Das</keyname><forenames>Shantanu</forenames></author></authors><title>Performance Comparison of Optimal Fractional Order Hybrid Fuzzy PID
  Controllers for Handling Oscillatory Fractional Order Processes with Dead
  Time</title><categories>math.OC cs.SY</categories><comments>31 pages, 20 figures</comments><journal-ref>ISA Transactions, Volume 52, Issue 4, Pages 550-566, July 2013</journal-ref><doi>10.1016/j.isatra.2013.03.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy logic based PID controllers have been studied in this paper,
considering several combinations of hybrid controllers by grouping the
proportional, integral and derivative actions with fuzzy inferencing in
different forms. Fractional order (FO) rate of error signal and FO integral of
control signal have been used in the design of a family of decomposed hybrid FO
fuzzy PID controllers. The input and output scaling factors (SF) along with the
integro-differential operators are tuned with real coded genetic algorithm (GA)
to produce optimum closed loop performance by simultaneous consideration of the
control loop error index and the control signal. Three different classes of
fractional order oscillatory processes with various levels of relative
dominance between time constant and time delay have been used to test the
comparative merits of the proposed family of hybrid fractional order fuzzy PID
controllers. Performance comparison of the different FO fuzzy PID controller
structures has been done in terms of optimal set-point tracking, load
disturbance rejection and minimal variation of manipulated variable or smaller
actuator requirement etc. In addition, multi-objective Non-dominated Sorting
Genetic Algorithm (NSGA-II) has been used to study the Pareto optimal
trade-offs between the set point tracking and control signal, and the set point
tracking and load disturbance performance for each of the controller structure
to handle the three different types of processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3684</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3684</id><created>2013-06-16</created><authors><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author></authors><title>Design of Hybrid Regrouping PSO-GA based Sub-optimal Networked Control
  System with Random Packet Losses</title><categories>math.OC cs.SY</categories><comments>27 pages, 7 figures</comments><journal-ref>Memetic Computing, Volume 5, Issue 2, pp 141-153, June 2013</journal-ref><doi>10.1007/s12293-013-0107-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new approach has been presented to design sub-optimal state
feedback regulators over Networked Control Systems (NCS) with random packet
losses. The optimal regulator gains, producing guaranteed stability are
designed with the nominal discrete time model of a plant using Lyapunov
technique which produces a few set of Bilinear Matrix Inequalities (BMIs). In
order to reduce the computational complexity of the BMIs, a Genetic Algorithm
(GA) based approach coupled with the standard interior point methods for LMIs
has been adopted. A Regrouping Particle Swarm Optimization (RegPSO) based
method is then employed to optimally choose the weighting matrices for the
state feedback regulator design that gets passed through the GA based stability
checking criteria i.e. the BMIs. This hybrid optimization methodology put
forward in this paper not only reduces the computational difficulty of the
feasibility checking condition for optimum stabilizing gain selection but also
minimizes other time domain performance criteria like expected value of the
set-point tracking error with optimum weight selection based LQR design for the
nominal system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3685</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3685</id><created>2013-06-16</created><authors><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author><author><keyname>Mukherjee</keyname><forenames>Sumit</forenames></author><author><keyname>Das</keyname><forenames>Shantanu</forenames></author><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Gupta</keyname><forenames>Amitava</forenames></author></authors><title>Continuous Order Identification of PHWR Models Under Step-back for the
  Design of Hyper-damped Power Tracking Controller with Enhanced Reactor Safety</title><categories>math.OC cs.SY</categories><comments>37 pages, 18 figures</comments><journal-ref>Nuclear Engineering and Design, Volume 257, Pages 109-127, April
  2013</journal-ref><doi>10.1016/j.nucengdes.2013.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, discrete time higher integer order linear transfer function
models have been identified first for a 500 MWe Pressurized Heavy Water Reactor
(PHWR) which has highly nonlinear dynamical nature. Linear discrete time models
of the nonlinear nuclear reactor have been identified around eight different
operating points (power reduction or step-back conditions) with least square
estimator (LSE) and its four variants. From the synthetic frequency domain data
of these identified discrete time models, fractional order (FO) models with
sampled continuous order distribution are identified for the nuclear reactor.
This enables design of continuous order Proportional-Integral-Derivative (PID)
like compensators in the complex w-plane for global power tracking at a wide
range of operating conditions. Modeling of the PHWR is attempted with various
levels of discrete commensurate-orders and the achievable accuracies are also
elucidated along with the hidden issues, regarding modeling and controller
design. Credible simulation studies are presented to show the effectiveness of
the proposed reactor modeling and power level controller design. The controller
pushes the reactor poles in higher Riemann sheets and thus makes the closed
loop system hyper-damped which ensures safer reactor operation at varying
dc-gain while making the power tracking temporal response slightly sluggish;
but ensuring greater safety margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3692</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3692</id><created>2013-06-16</created><updated>2013-06-28</updated><authors><author><keyname>S&#xe1;nchez-Mart&#xed;nez</keyname><forenames>Felipe</forenames></author><author><keyname>Mart&#xed;nez-Sempere</keyname><forenames>Isabel</forenames></author><author><keyname>Ivars-Ribes</keyname><forenames>Xavier</forenames></author><author><keyname>Carrasco</keyname><forenames>Rafael C.</forenames></author></authors><title>An open diachronic corpus of historical Spanish: annotation criteria and
  automatic modernisation of spelling</title><categories>cs.CL cs.DL</categories><comments>The part of this paper describing the IMPACT-es corpus has been
  accepted for publication in the journal Language Resources and Evaluation
  (http://link.springer.com/article/10.1007/s10579-013-9239-y)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The IMPACT-es diachronic corpus of historical Spanish compiles over one
hundred books --containing approximately 8 million words-- in addition to a
complementary lexicon which links more than 10 thousand lemmas with
attestations of the different variants found in the documents. This textual
corpus and the accompanying lexicon have been released under an open license
(Creative Commons by-nc-sa) in order to permit their intensive exploitation in
linguistic research. Approximately 7% of the words in the corpus (a selection
aimed at enhancing the coverage of the most frequent word forms) have been
annotated with their lemma, part of speech, and modern equivalent. This paper
describes the annotation criteria followed and the standards, based on the Text
Encoding Initiative recommendations, used to the represent the texts in digital
form. As an illustration of the possible synergies between diachronic textual
resources and linguistic research, we describe the application of statistical
machine translation techniques to infer probabilistic context-sensitive rules
for the automatic modernisation of spelling. The automatic modernisation with
this type of statistical methods leads to very low character error rates when
the output is compared with the supervised modern version of the text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3693</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3693</id><created>2013-06-16</created><updated>2013-06-22</updated><authors><author><keyname>Shayovitz</keyname><forenames>Shachar</forenames></author><author><keyname>Rapaheli</keyname><forenames>Dan</forenames></author></authors><title>Message Passing Algorithms for Phase Noise Tracking Using Tikhonov
  Mixtures</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE transactions on communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new low complexity iterative algorithm for decoding data
transmitted over strong phase noise channels is presented. The algorithm is
based on the Sum &amp; Product Algorithm (SPA) with phase noise messages modeled as
Tikhonov mixtures. Since mixture based Bayesian inference such as SPA, creates
an exponential increase in mixture order for consecutive messages, mixture
reduction is necessary. We propose a low complexity mixture reduction algorithm
which finds a reduced order mixture whose dissimilarity metric is
mathematically proven to be upper bounded by a given threshold. As part of the
mixture reduction, a new method for optimal clustering provides the closest
circular distribution, in Kullback Leibler sense, to any circular mixture. We
further show a method for limiting the number of tracked components and further
complexity reduction approaches. We show simulation results and complexity
analysis for the proposed algorithm and show better performance than other
state of the art low complexity algorithms. We show that the Tikhonov mixture
approximation of SPA messages is equivalent to the tracking of multiple phase
trajectories, or also can be looked as smart multiple phase locked loops (PLL).
When the number of components is limited to one the result is similar to a
smart PLL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3707</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3707</id><created>2013-06-16</created><authors><author><keyname>Vulimiri</keyname><forenames>Ashish</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Mittal</keyname><forenames>Radhika</forenames></author><author><keyname>Sherry</keyname><forenames>Justine</forenames></author><author><keyname>Ratnasamy</keyname><forenames>Sylvia</forenames></author><author><keyname>Shenker</keyname><forenames>Scott</forenames></author></authors><title>Low latency via redundancy</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low latency is critical for interactive networked applications. But while we
know how to scale systems to increase capacity, reducing latency --- especially
the tail of the latency distribution --- can be much more difficult. In this
paper, we argue that the use of redundancy is an effective way to convert extra
capacity into reduced latency. By initiating redundant operations across
diverse resources and using the first result which completes, redundancy
improves a system's latency even under exceptional conditions. We study the
tradeoff with added system utilization, characterizing the situations in which
replicating all tasks reduces mean latency. We then demonstrate empirically
that replicating all operations can result in significant mean and tail latency
reduction in real-world systems including DNS queries, database servers, and
packet forwarding within networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3710</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3710</id><created>2013-06-16</created><authors><author><keyname>Chen</keyname><forenames>Jinyuan</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author></authors><title>Symmetric Two-User MIMO BC and IC with Evolving Feedback</title><categories>cs.IT math.IT</categories><comments>This paper will be presented in part at SPAWC13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extending recent findings on the two-user MISO broadcast channel (BC) with
imperfect and delayed channel state information at the transmitter (CSIT), the
work here explores the performance of the two user MIMO BC and the two user
MIMO interference channel (MIMO IC), in the presence of feedback with evolving
quality and timeliness. Under standard assumptions, and in the presence of M
antennas per transmitter and N antennas per receiver, the work derives the DoF
region, which is optimal for a large regime of sufficiently good (but
potentially imperfect) delayed CSIT. This region concisely captures the effect
of having predicted, current and delayed-CSIT, as well as concisely captures
the effect of the quality of CSIT offered at any time, about any channel. In
addition to the progress towards describing the limits of using such imperfect
and delayed feedback in MIMO settings, the work offers different insights that
include the fact that, an increasing number of receive antennas can allow for
reduced quality feedback, as well as that no CSIT is needed for the direct
links in the IC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3714</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3714</id><created>2013-06-16</created><authors><author><keyname>Kikuchi</keyname><forenames>Akihito</forenames></author></authors><title>An approach to first principles electronic structure calculation by
  symbolic-numeric computation</title><categories>physics.comp-ph cs.SC</categories><comments>Soon available at
  http://www.qscience.com/doi/pdf/10.5339/connect.2013.14. arXiv admin note:
  substantial text overlap with arXiv:1209.5127</comments><journal-ref>QScience Connect: Vol. 2013, 14</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is an introduction to a new approach to first principles
electronic structure calculation. The starting point is the
Hartree-Fock-Roothaan equation, in which molecular integrals are approximated
by polynomials by way of Taylor expansion with respect to atomic coordinates
and other variables. It leads to a set of polynomial equations whose solutions
are eigenstate, which is designated as algebraic molecular orbital equation.
Symbolic computation, especially, Gr\&quot;obner bases theory, enables us to rewrite
the polynomial equations into more trimmed and tractable forms with identical
roots, from which we can unravel the relationship between physical parameters
(wave function, atomic coordinates, and others) and numerically evaluate them
one by one in order. Furthermore, this method is a unified way to solve the
electronic structure calculation, the optimization of physical parameters, and
the inverse problem as a forward problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3717</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3717</id><created>2013-06-16</created><authors><author><keyname>Chen</keyname><forenames>Xiaoming</forenames></author><author><keyname>Yin</keyname><forenames>Rui</forenames></author></authors><title>Performance Analysis for Physical Layer Security in Multi-Antenna
  Downlink Networks with Limited CSI Feedback</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures. In IEEE Wireless Communications Letters, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel state information (CSI) at the transmitter is of importance to the
performance of physical layer security based on multi-antenna networks.
Specifically, CSI is not only beneficial to improve the capacity of the
legitimate channel, but also can be used to degrade the performance of the
eavesdropper channel. Thus, the secrecy rate increases accordingly. This letter
focuses on the quantitative analysis of the ergodic secrecy sum-rate in terms
of feedback amount of the CSI from the legitimate users in multiuser
multi-antenna downlink networks. Furthermore, the asymptotic characteristics of
the ergodic secrecy sum-rate in two extreme cases is investigated in some
detail. Finally, our theoretical claims are confirmed by the numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3721</identifier>
 <datestamp>2013-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3721</id><created>2013-06-16</created><updated>2013-07-10</updated><authors><author><keyname>Wang</keyname><forenames>Huahua</forenames></author><author><keyname>Banerjee</keyname><forenames>Arindam</forenames></author></authors><title>Online Alternating Direction Method (longer version)</title><categories>cs.LG math.OC</categories><comments>Longer version of arXiv:1206.6448</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online optimization has emerged as powerful tool in large scale optimization.
In this pa- per, we introduce efficient online optimization algorithms based on
the alternating direction method (ADM), which can solve online convex
optimization under linear constraints where the objective could be non-smooth.
We introduce new proof techniques for ADM in the batch setting, which yields a
O(1/T) convergence rate for ADM and forms the basis for regret anal- ysis in
the online setting. We consider two scenarios in the online setting, based on
whether an additional Bregman divergence is needed or not. In both settings, we
establish regret bounds for both the objective function as well as constraints
violation for general and strongly convex functions. We also consider inexact
ADM updates where certain terms are linearized to yield efficient updates and
show the stochastic convergence rates. In addition, we briefly discuss that
online ADM can be used as projection- free online learning algorithm in some
scenarios. Preliminary results are presented to illustrate the performance of
the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3726</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3726</id><created>2013-06-16</created><updated>2013-09-16</updated><authors><author><keyname>Case</keyname><forenames>John</forenames><affiliation>University of Delaware</affiliation></author><author><keyname>Jain</keyname><forenames>Sanjay</forenames><affiliation>National University of Singapore</affiliation></author><author><keyname>Stephan</keyname><forenames>Frank</forenames><affiliation>National University of Singapore</affiliation></author><author><keyname>Stephan</keyname><forenames>Frank</forenames><affiliation>National University of Singapore</affiliation></author></authors><title>Automatic functions, linear time and learning</title><categories>cs.FL</categories><comments>A preliminary version was presented at the conference CiE 2012
  (Computability in Europe)</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  17, 2013) lmcs:734</journal-ref><doi>10.2168/LMCS-9(3:19)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work determines the exact nature of {\em linear time computable}
notions which characterise automatic functions (those whose graphs are
recognised by a finite automaton). The paper also determines which type of
linear time notions permit full learnability for learning in the limit of
automatic classes (families of languages which are uniformly recognised by a
finite automaton). In particular it is shown that a function is automatic iff
there is a one-tape Turing machine with a left end which computes the function
in linear time where the input before the computation and the output after the
computation both start at the left end. It is known that learners realised as
automatic update functions are restrictive for learning. In the present work it
is shown that one can overcome the problem by providing work tapes additional
to a resource-bounded base tape while keeping the update-time to be linear in
the length of the largest datum seen so far. In this model, one additional such
work tape provides additional learning power over the automatic learner model
and two additional work tapes give full learning power. Furthermore, one can
also consider additional queues or additional stacks in place of additional
work tapes and for these devices, one queue or two stacks are sufficient for
full learning power while one stack is insufficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3727</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3727</id><created>2013-06-16</created><authors><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Ye</keyname><forenames>Deshi</forenames></author><author><keyname>Zhang</keyname><forenames>Guochuan</forenames></author></authors><title>A note on scheduling with low rank processing times</title><categories>cs.CC cs.DS</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the classical minimum makespan scheduling problem, where the
processing time of job $j$ on machine $i$ is $p_{ij}$, and the matrix
$P=(p_{ij})_{m\times n}$ is of a low rank. It is proved in (Bhaskara et al.,
SODA 2013) that rank 7 scheduling is NP-hard to approximate to a factor of
$3/2-\epsilon$, and rank 4 scheduling is APX-hard (NP-hard to approximate
within a factor of $1.03-\epsilon$). We improve this result by showing that
rank 4 scheduling is already NP-hard to approximate within a factor of
$3/2-\epsilon$, and meanwhile rank 3 scheduling is APX-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3729</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3729</id><created>2013-06-16</created><authors><author><keyname>Chaganty</keyname><forenames>Arun Tejasvi</forenames></author><author><keyname>Liang</keyname><forenames>Percy</forenames></author></authors><title>Spectral Experts for Estimating Mixtures of Linear Regressions</title><categories>cs.LG stat.ML</categories><comments>Accepted at ICML 2013. Includes supplementary material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discriminative latent-variable models are typically learned using EM or
gradient-based optimization, which suffer from local optima. In this paper, we
develop a new computationally efficient and provably consistent estimator for a
mixture of linear regressions, a simple instance of a discriminative
latent-variable model. Our approach relies on a low-rank linear regression to
recover a symmetric tensor, which can be factorized into the parameters using a
tensor power method. We prove rates of convergence for our estimator and
provide an empirical evaluation illustrating its strengths relative to local
optimization (EM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3738</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3738</id><created>2013-06-17</created><authors><author><keyname>Li</keyname><forenames>Menghui</forenames></author><author><keyname>Zou</keyname><forenames>Hailin</forenames></author><author><keyname>Guan</keyname><forenames>Shuguang</forenames></author><author><keyname>Gong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Li</keyname><forenames>Kun</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Lai</keyname><forenames>Choy-Heng</forenames></author></authors><title>A coevolving model based on preferential triadic closure for social
  media networks</title><categories>cs.SI nlin.AO physics.soc-ph</categories><comments>11 pages, 5 figures, 3 tables</comments><journal-ref>Scientific Reports 3, 2512 (2013)</journal-ref><doi>10.1038/srep02512</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamical origin of complex networks, i.e., the underlying principles
governing network evolution, is a crucial issue in network study. In this
paper, by carrying out analysis to the temporal data of Flickr and
Epinions--two typical social media networks, we found that the dynamical
pattern in neighborhood, especially the formation of triadic links, plays a
dominant role in the evolution of networks. We thus proposed a coevolving
dynamical model for such networks, in which the evolution is only driven by the
local dynamics--the preferential triadic closure. Numerical experiments
verified that the model can reproduce global properties which are qualitatively
consistent with the empirical observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3739</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3739</id><created>2013-06-17</created><updated>2013-06-18</updated><authors><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Khandekar</keyname><forenames>Rohit</forenames></author><author><keyname>Khani</keyname><forenames>M. Reza</forenames></author><author><keyname>Kortsarz</keyname><forenames>Guy</forenames></author></authors><title>Approximation Algorithms for Movement Repairmen</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the {\em Movement Repairmen (MR)} problem we are given a metric space $(V,
d)$ along with a set $R$ of $k$ repairmen $r_1, r_2, ..., r_k$ with their start
depots $s_1, s_2, ..., s_k \in V$ and speeds $v_1, v_2, ..., v_k \geq 0$
respectively and a set $C$ of $m$ clients $c_1, c_2, ..., c_m$ having start
locations $s'_1, s'_2, ..., s'_m \in V$ and speeds $v'_1, v'_2, ..., v'_m \geq
0$ respectively. If $t$ is the earliest time a client $c_j$ is collocated with
any repairman (say, $r_i$) at a node $u$, we say that the client is served by
$r_i$ at $u$ and that its latency is $t$. The objective in the (\smr{}) problem
is to plan the movements for all repairmen and clients to minimize the sum
(average) of the clients latencies. The motivation for this problem comes, for
example, from Amazon Locker Delivery \cite{amazon} and USPS gopost
\cite{gopost}. We give the first $O(\log n)$-approximation algorithm for the
\smr{} problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3760</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3760</id><created>2013-06-17</created><authors><author><keyname>Nguyen</keyname><forenames>Trung Duc</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>A Space-Efficient Design for Reversible Floating Point Adder in Quantum
  Computing</title><categories>quant-ph cs.ET</categories><comments>11 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic has applications in low-power computing and quantum
computing. However, there are few existing designs for reversible
floating-point adders and none suitable for quantum computation. In this paper
we propose a space-efficient reversible floating-point adder, suitable for
binary quantum computation, improving the design of Nachtigal et al. Our work
focuses on improving the reversible designs of the alignment unit and the
normalization unit, which are the most expensive parts. By changing a few
elements of the existing algorithm, including the circuit designs of the RLZC
(reversible leading zero counter) and converter, we have reduced the cost about
68%. We also propose fault-tolerant designs for the circuits. The KQ for our
fault-tolerant design is almost sixty times as expensive as for a 32-bit
fixed-point addition. We note that the floating-point representation makes
in-place, truly reversible arithmetic impossible, requiring us to retain both
inputs, which limits the sustainability of its use for quantum computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3764</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3764</id><created>2013-06-17</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Bounding ground state energy of Hopfield models</title><categories>math.OC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we look at a class of random optimization problems that arise
in the forms typically known as Hopfield models. We view two scenarios which we
term as the positive Hopfield form and the negative Hopfield form. For both of
these scenarios we define the binary optimization problems that essentially
emulate what would typically be known as the ground state energy of these
models. We then present a simple mechanism that can be used to create a set of
theoretical rigorous bounds for these energies. In addition to purely
theoretical bounds, we also present a couple of fast optimization algorithms
that can also be used to provide solid (albeit a bit weaker) algorithmic bounds
for the ground state energies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3766</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3766</id><created>2013-06-17</created><authors><author><keyname>Raviv</keyname><forenames>Netanel</forenames></author></authors><title>Truth Table Minimization of Computational Models</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complexity theory offers a variety of concise computational models for
computing boolean functions - branching programs, circuits, decision trees and
ordered binary decision diagrams to name a few. A natural question that arises
in this context with respect to any such model is this:
  Given a function f:{0,1}^n \to {0,1}, can we compute the optimal complexity
of computing f in the computational model in question? (according to some
desirable measure).
  A critical issue regarding this question is how exactly is f given, since a
more elaborate description of f allows the algorithm to use more computational
resources. Among the possible representations are black-box access to f (such
as in computational learning theory), a representation of f in the desired
computational model or a representation of f in some other model. One might
conjecture that if f is given as its complete truth table (i.e., a list of f's
values on each of its 2^n possible inputs), the most elaborate description
conceivable, then any computational model can be efficiently computed, since
the algorithm computing it can run poly(2^n) time. Several recent studies show
that this is far from the truth - some models have efficient and simple
algorithms that yield the desired result, others are believed to be hard, and
for some models this problem remains open.
  In this thesis we will discuss the computational complexity of this question
regarding several common types of computational models. We shall present
several new hardness results and efficient algorithms, as well as new proofs
and extensions for known theorems, for variants of decision trees, formulas and
branching programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3767</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3767</id><created>2013-06-17</created><updated>2013-06-18</updated><authors><author><keyname>Harper</keyname><forenames>Simon</forenames></author><author><keyname>Chen</keyname><forenames>Tianyi</forenames></author><author><keyname>Yesilada</keyname><forenames>Yeliz</forenames></author></authors><title>Controlled Experimentation in Naturalistic Mobile Settings</title><categories>cs.HC</categories><comments>12 pages, 3 tables</comments><acm-class>H.1.2; C.5.3; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performing controlled user experiments on small devices in naturalistic
mobile settings has always proved to be a difficult undertaking for many Human
Factors researchers. Difficulties exist, not least, because mimicking natural
small device usage suffers from a lack of unobtrusive data to guide
experimental design, and then validate that the experiment is proceeding
naturally.Here we use observational data to derive a set of protocols and a
simple checklist of validations which can be built into the design of any
controlled experiment focused on the user interface of a small device. These,
have been used within a series of experimental designs to measure the utility
and application of experimental software. The key-point is the validation
checks -- based on the observed behaviour of 400 mobile users -- to ratify that
a controlled experiment is being perceived as natural by the user. While the
design of the experimental route which the user follows is a major factor in
the experimental setup, without check validations based on unobtrusive observed
data there can be no certainty that an experiment designed to be natural is
actually progressing as the design implies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3769</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3769</id><created>2013-06-17</created><authors><author><keyname>Gurtner</keyname><forenames>G&#xe9;rald</forenames></author><author><keyname>Vitali</keyname><forenames>Stefania</forenames></author><author><keyname>Cipolla</keyname><forenames>Marco</forenames></author><author><keyname>Lillo</keyname><forenames>Fabrizio</forenames></author><author><keyname>Mantegna</keyname><forenames>Rosario Nunzio</forenames></author><author><keyname>Miccich&#xe8;</keyname><forenames>Salvatore</forenames></author><author><keyname>Pozzi</keyname><forenames>Simone</forenames></author></authors><title>Multi-scale analysis of the European airspace using network community
  detection</title><categories>physics.soc-ph cs.SI</categories><comments>22 pages, 14 figures</comments><journal-ref>PLoS ONE 9(5): e94414 (2014)</journal-ref><doi>10.1371/journal.pone.0094414</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the European airspace can be represented as a multi-scale
traffic network whose nodes are airports, sectors, or navigation points and
links are defined and weighted according to the traffic of flights between the
nodes. By using a unique database of the air traffic in the European airspace,
we investigate the architecture of these networks with a special emphasis on
their community structure. We propose that unsupervised network community
detection algorithms can be used to monitor the current use of the airspaces
and improve it by guiding the design of new ones. Specifically, we compare the
performance of three community detection algorithms, also by using a null model
which takes into account the spatial distance between nodes, and we discuss
their ability to find communities that could be used to define new control
units of the airspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3770</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3770</id><created>2013-06-17</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Lifting $\ell_1$-optimization strong and sectional thresholds</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we revisit under-determined linear systems of equations with
sparse solutions. As is well known, these systems are among core mathematical
problems of a very popular compressed sensing field. The popularity of the
field as well as a substantial academic interest in linear systems with sparse
solutions are in a significant part due to seminal results
\cite{CRT,DonohoPol}. Namely, working in a statistical scenario,
\cite{CRT,DonohoPol} provided substantial mathematical progress in
characterizing relation between the dimensions of the systems and the sparsity
of unknown vectors recoverable through a particular polynomial technique called
$\ell_1$-minimization. In our own series of work
\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} we also provided a
collection of mathematical results related to these problems. While, Donoho's
work \cite{DonohoPol,DonohoUnsigned} established (and our own work
\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed) the typical or
the so-called \emph{weak threshold} behavior of $\ell_1$-minimization many
important questions remain unanswered. Among the most important ones are those
that relate to non-typical or the so-called \emph{strong threshold} behavior.
These questions are usually combinatorial in nature and known techniques come
up short of providing the exact answers. In this paper we provide a powerful
mechanism that that can be used to attack the &quot;tough&quot; scenario, i.e. the
\emph{strong threshold} (and its a similar form called \emph{sectional
threshold}) of $\ell_1$-minimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3771</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3771</id><created>2013-06-17</created><updated>2013-08-13</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The revised SNIP indicator of Elsevier's Scopus</title><categories>cs.DL</categories><comments>Letter to the Editor of the Journal of Informetrics (2013; in press)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modified SNIP indicator of Elsevier, as recently explained by Waltman et
al. (2013) in this journal, solves some of the problems which Leydesdorff &amp;
Opthof (2010 and 2011) indicated in relation to the original SNIP indicator
(Moed, 2010 and 2011). The use of an arithmetic average, however, remains
unfortunate in the case of scientometric distributions because these can be
extremely skewed (Seglen, 1992 and 1997). The new indicator cannot (or hardly)
be reproduced independently when used for evaluation purposes, and remains in
this sense opaque from the perspective of evaluated units and scholars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3772</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3772</id><created>2013-06-17</created><authors><author><keyname>Cohen</keyname><forenames>Sarel</forenames></author><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Hershcovitch</keyname><forenames>Moshik</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author></authors><title>Minimal Indices for Successor Search</title><categories>cs.DS</categories><comments>28 pages, full version, extended abstract submitted to MFCS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new successor data structure which improves upon the index size of
the P\v{a}tra\c{s}cu-Thorup data structures, reducing the index size from $O(n
w^{4/5})$ bits to $O(n \log w)$ bits, with optimal probe complexity.
Alternatively, our new data structure can be viewed as matching the space
complexity of the (probe-suboptimal) $z$-fast trie of Belazzougui et al. Thus,
we get the best of both approaches with respect to both probe count and index
size. The penalty we pay is an extra $O(\log w)$ inter-register operations. Our
data structure can also be used to solve the weak prefix search problem, the
index size of $O(n \log w)$ bits is known to be optimal for any such data
structure.
  The technical contributions include highly efficient single word indices,
with out-degree $w/\log w$ (compared to the $w^{1/5}$ out-degree of fusion tree
based indices). To construct such high efficiency single word indices we device
highly efficient bit selectors which, we believe, are of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3774</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3774</id><created>2013-06-17</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Under-determined linear systems and $\ell_q$-optimization thresholds</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies of under-determined linear systems of equations with sparse
solutions showed a great practical and theoretical efficiency of a particular
technique called $\ell_1$-optimization. Seminal works \cite{CRT,DOnoho06CS}
rigorously confirmed it for the first time. Namely, \cite{CRT,DOnoho06CS}
showed, in a statistical context, that $\ell_1$ technique can recover sparse
solutions of under-determined systems even when the sparsity is linearly
proportional to the dimension of the system. A followup \cite{DonohoPol} then
precisely characterized such a linearity through a geometric approach and a
series of work\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed
statements of \cite{DonohoPol} through a purely probabilistic approach. A
theoretically interesting alternative to $\ell_1$ is a more general version
called $\ell_q$ (with an essentially arbitrary $q$). While $\ell_1$ is
typically considered as a first available convex relaxation of sparsity norm
$\ell_0$, $\ell_q,0\leq q\leq 1$, albeit non-convex, should technically be a
tighter relaxation of $\ell_0$. Even though developing polynomial (or close to
be polynomial) algorithms for non-convex problems is still in its initial
phases one may wonder what would be the limits of an $\ell_q,0\leq q\leq 1$,
relaxation even if at some point one can develop algorithms that could handle
its non-convexity. A collection of answers to this and a few realted questions
is precisely what we present in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3777</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3777</id><created>2013-06-17</created><updated>2014-03-17</updated><authors><author><keyname>Salo</keyname><forenames>Ville</forenames></author><author><keyname>T&#xf6;rm&#xe4;</keyname><forenames>Ilkka</forenames></author></authors><title>Block Maps between Primitive Uniform and Pisot Substitutions</title><categories>math.DS cs.FL</categories><comments>21 pages. Minor corrections to grammar and some proofs. To appear in
  Ergodic Theory and Dynamical Systems after editorial input by Cambridge
  University Press. Copyright held by Cambridge University Press</comments><doi>10.1017/etds.2014.29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we prove that for all pairs of primitive Pisot or uniform
substitutions with the same dominating eigenvalue, there exists a finite set of
block maps such that every block map between the corresponding subshifts is an
element of this set, up to a shift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3778</identifier>
 <datestamp>2015-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3778</id><created>2013-06-17</created><updated>2015-07-16</updated><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Upper-bounding $\ell_1$-optimization sectional thresholds</title><categories>cs.IT math.IT math.OC</categories><comments>acknowledgement footnote added arXiv admin note: text overlap with
  arXiv:1303.7289</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we look at a particular problem related to under-determined
linear systems of equations with sparse solutions. $\ell_1$-minimization is a
fairly successful polynomial technique that can in certain statistical
scenarios find sparse enough solutions of such systems. Barriers of $\ell_1$
performance are typically referred to as its thresholds. Depending if one is
interested in a typical or worst case behavior one then distinguishes between
the \emph{weak} thresholds that relate to a typical behavior on one side and
the \emph{sectional} and \emph{strong} thresholds that relate to the worst case
behavior on the other side. Starting with seminal works
\cite{CRT,DonohoPol,DOnoho06CS} a substantial progress has been achieved in
theoretical characterization of $\ell_1$-minimization statistical thresholds.
More precisely, \cite{CRT,DOnoho06CS} presented for the first time linear lower
bounds on all of these thresholds. Donoho's work \cite{DonohoPol} (and our own
\cite{StojnicCSetam09,StojnicUpper10}) went a bit further and essentially
settled the $\ell_1$'s \emph{weak} thresholds. At the same time they also
provided fairly good lower bounds on the values on the \emph{sectional} and
\emph{strong} thresholds. In this paper, we revisit the \emph{sectional}
thresholds and present a simple mechanism that can be used to create solid
upper bounds as well. The method we present relies on a seemingly simple but
substantial progress we made in studying Hopfield models in
\cite{StojnicHopBnds10}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3779</identifier>
 <datestamp>2015-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3779</id><created>2013-06-17</created><updated>2015-07-16</updated><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Bounds on restricted isometry constants of random matrices</title><categories>math.OC cs.IT math.IT math.PR</categories><comments>acknowledgement footnote added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we look at isometry properties of random matrices. During the
last decade these properties gained a lot attention in a field called
compressed sensing in first place due to their initial use in \cite{CRT,CT}.
Namely, in \cite{CRT,CT} these quantities were used as a critical tool in
providing a rigorous analysis of $\ell_1$ optimization's ability to solve an
under-determined system of linear equations with sparse solutions. In such a
framework a particular type of isometry, called restricted isometry, plays a
key role. One then typically introduces a couple of quantities, called upper
and lower restricted isometry constants to characterize the isometry properties
of random matrices. Those constants are then usually viewed as mathematical
objects of interest and their a precise characterization is desirable. The
first estimates of these quantities within compressed sensing were given in
\cite{CRT,CT}. As the need for precisely estimating them grew further a finer
improvements of these initial estimates were obtained in e.g.
\cite{BCTsharp09,BT10}. These are typically obtained through a combination of
union-bounding strategy and powerful tail estimates of extreme eigenvalues of
Wishart (Gaussian) matrices (see, e.g. \cite{Edelman88}). In this paper we
attempt to circumvent such an approach and provide an alternative way to obtain
similar estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3783</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3783</id><created>2013-06-17</created><authors><author><keyname>Smiraglia</keyname><forenames>Richard</forenames></author><author><keyname>Scharnhorst</keyname><forenames>Andrea</forenames></author><author><keyname>Salah</keyname><forenames>Almila Akdag</forenames></author><author><keyname>Gao</keyname><forenames>Cheng</forenames></author></authors><title>UDC in Action</title><categories>cs.DL physics.soc-ph</categories><comments>Accepted for the UDCC seminar 2013</comments><acm-class>H.3.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The UDC (Universal Decimal Classification) is not only a classification
language with a long history; it also presents a complex cognitive system
worthy of the attention of complexity theory. The elements of the UDC: classes,
auxiliaries, and operations are combined into symbolic strings, which in
essence represent a complex networks of concepts. This network forms a backbone
of ordering of knowledge and at the same time allows expression of different
perspectives on various products of human knowledge production. In this paper
we look at UDC strings derived from the holdings of libraries. In particular we
analyse the subject headings of holdings of the university library in Leuven,
and an extraction of UDC numbers from the OCLC WorldCat. Comparing those sets
with the Master Reference File, we look into the length of strings, the
occurrence of different auxiliary signs, and the resulting connections between
UDC classes. We apply methods and representations from complexity theory.
Mapping out basic statistics on UDC classes as used in libraries from a point
of view of complexity theory bears different benefits. Deploying its structure
could serve as an overview and basic information for users among the nature and
focus of specific collections. A closer view into combined UDC numbers reveals
the complex nature of the UDC as an example for a knowledge ordering system,
which deserves future exploration from a complexity theoretical perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3786</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3786</id><created>2013-06-17</created><updated>2013-07-24</updated><authors><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Torrieri</keyname><forenames>Don</forenames></author></authors><title>Analysis of Multi-Cell Downlink Cooperation with a Constrained Spatial
  Model</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, IEEE Global Telecommun. Conf. (GLOBECOM), 2013,
  to appear. arXiv admin note: text overlap with arXiv:1210.3667</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-cell cooperation (MCC) mitigates intercell interference and improves
throughput at the cell edge. This paper considers a cooperative downlink,
whereby cell-edge mobiles are served by multiple cooperative base stations. The
cooperating base stations transmit identical signals over paths with
non-identical path losses, and the receiving mobile performs diversity
combining. The analysis in this paper is driven by a new expression for the
conditional outage probability when signals arriving over different paths are
combined in the presence of noise and interference, where the conditioning is
with respect to the network topology and shadowing. The channel model accounts
for path loss, shadowing, and Nakagami fading, and the Nakagami fading
parameters do not need to be identical for all paths. To study performance over
a wide class of network topologies, a random spatial model is adopted, and
performance is found by statistically characterizing the rates provided on the
downlinks. To model realistic networks, the model requires a minimum separation
among base stations. Having adopted a realistic model and an accurate analysis,
the paper proceeds to determine performance under several resource-allocation
policies and provides insight regarding how the cell edge should be defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3791</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3791</id><created>2013-06-17</created><updated>2013-07-17</updated><authors><author><keyname>Sharma</keyname><forenames>Naresh</forenames></author></authors><title>A gambling interpretation of some quantum information-theoretic
  quantities</title><categories>quant-ph cs.IT math.IT</categories><comments>Corrected typos and changed abstract a bit</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that repeated gambling over the outcomes of independent and
identically distributed (i.i.d.) random variables gives rise to alternate
operational meaning of entropies in the classical case in terms of the doubling
rates. We give a quantum extension of this approach for gambling over the
measurement outcomes of tensor product states. Under certain parameters of the
gambling setup, one can give operational meaning of von Neumann entropies. We
discuss two variants of gambling when a helper is available and it is shown
that the difference in their doubling rates is the quantum discord. Lastly, a
quantum extension of Kelly's gambling setup in the classical case gives a
doubling rate that is upper bounded by the Holevo information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3797</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3797</id><created>2013-06-17</created><authors><author><keyname>Ferrari</keyname><forenames>Luca</forenames></author></authors><title>Greedy algorithms and poset matroids</title><categories>math.CO cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the matroid-theoretic approach to greedy algorithms to the
setting of poset matroids, in the sense of Barnabei, Nicoletti and Pezzoli
(1998) [BNP]. We illustrate our result by providing a generalization of Kruskal
algorithm (which finds a minimum spanning subtree of a weighted graph) to
abstract simplicial complexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3801</identifier>
 <datestamp>2015-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3801</id><created>2013-06-17</created><updated>2015-07-16</updated><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Towards a better compressed sensing</title><categories>cs.IT math.IT math.OC</categories><comments>acknowledgement footnote added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we look at a well known linear inverse problem that is one of
the mathematical cornerstones of the compressed sensing field. In seminal works
\cite{CRT,DOnoho06CS} $\ell_1$ optimization and its success when used for
recovering sparse solutions of linear inverse problems was considered.
Moreover, \cite{CRT,DOnoho06CS} established for the first time in a statistical
context that an unknown vector of linear sparsity can be recovered as a known
existing solution of an under-determined linear system through $\ell_1$
optimization. In \cite{DonohoPol,DonohoUnsigned} (and later in
\cite{StojnicCSetam09,StojnicUpper10}) the precise values of the linear
proportionality were established as well. While the typical $\ell_1$
optimization behavior has been essentially settled through the work of
\cite{DonohoPol,DonohoUnsigned,StojnicCSetam09,StojnicUpper10}, we in this
paper look at possible upgrades of $\ell_1$ optimization. Namely, we look at a
couple of algorithms that turn out to be capable of recovering a substantially
higher sparsity than the $\ell_1$. However, these algorithms assume a bit of
&quot;feedback&quot; to be able to work at full strength. This in turn then translates
the original problem of improving upon $\ell_1$ to designing algorithms that
would be able to provide output needed to feed the $\ell_1$ upgrades considered
in this papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3808</identifier>
 <datestamp>2014-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3808</id><created>2013-06-17</created><updated>2014-05-22</updated><authors><author><keyname>Nicosia</keyname><forenames>Vincenzo</forenames></author><author><keyname>De Domenico</keyname><forenames>Manlio</forenames></author><author><keyname>Latora</keyname><forenames>Vito</forenames></author></authors><title>Characteristic exponents of complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 5 figures, 1 table</comments><journal-ref>EPL 106, 58005 (2014)</journal-ref><doi>10.1209/0295-5075/106/58005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel way to characterize the structure of complex networks by
studying the statistical properties of the trajectories of random walks over
them. We consider time series corresponding to different properties of the
nodes visited by the walkers. We show that the analysis of the fluctuations of
these time series allows to define a set of characteristic exponents which
capture the local and global organization of a network. This approach provides
a way of solving two classical problems in network science, namely the
systematic classification of networks, and the identification of the salient
properties of growing networks. The results contribute to the construction of a
unifying framework for the investigation of the structure and dynamics of
complex systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3819</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3819</id><created>2013-06-17</created><updated>2014-11-15</updated><authors><author><keyname>Wild</keyname><forenames>Sebastian</forenames></author><author><keyname>Nebel</keyname><forenames>Markus E.</forenames></author><author><keyname>Mahmoud</keyname><forenames>Hosam</forenames></author></authors><title>Analysis of Quickselect under Yaroslavskiy's Dual-Pivoting Algorithm</title><categories>cs.DS math.PR</categories><comments>full version with appendices; otherwise identical to Algorithmica
  version</comments><msc-class>60C05 (Primary), 68P10 (Secondary), 68P20</msc-class><doi>10.1007/s00453-014-9953-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is excitement within the algorithms community about a new partitioning
method introduced by Yaroslavskiy. This algorithm renders Quicksort slightly
faster than the case when it runs under classic partitioning methods. We show
that this improved performance in Quicksort is not sustained in Quickselect; a
variant of Quicksort for finding order statistics. We investigate the number of
comparisons made by Quickselect to find a key with a randomly selected rank
under Yaroslavskiy's algorithm. This grand averaging is a smoothing operator
over all individual distributions for specific fixed order statistics. We give
the exact grand average. The grand distribution of the number of comparison
(when suitably scaled) is given as the fixed-point solution of a distributional
equation of a contraction in the Zolotarev metric space. Our investigation
shows that Quickselect under older partitioning methods slightly outperforms
Quickselect under Yaroslavskiy's algorithm, for an order statistic of a random
rank. Similar results are obtained for extremal order statistics, where again
we find the exact average, and the distribution for the number of comparisons
(when suitably scaled). Both limiting distributions are of perpetuities (a sum
of products of independent mixed continuous random variables).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3828</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3828</id><created>2013-06-17</created><authors><author><keyname>Zhang</keyname><forenames>Haichao</forenames></author><author><keyname>Wipf</keyname><forenames>David</forenames></author></authors><title>Non-Uniform Blind Deblurring with a Spatially-Adaptive Sparse Prior</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typical blur from camera shake often deviates from the standard uniform
convolutional script, in part because of problematic rotations which create
greater blurring away from some unknown center point. Consequently, successful
blind deconvolution requires the estimation of a spatially-varying or
non-uniform blur operator. Using ideas from Bayesian inference and convex
analysis, this paper derives a non-uniform blind deblurring algorithm with
several desirable, yet previously-unexplored attributes. The underlying
objective function includes a spatially adaptive penalty which couples the
latent sharp image, non-uniform blur operator, and noise level together. This
coupling allows the penalty to automatically adjust its shape based on the
estimated degree of local blur and image structure such that regions with large
blur or few prominent edges are discounted. Remaining regions with modest blur
and revealing edges therefore dominate the overall estimation process without
explicitly incorporating structure-selection heuristics. The algorithm can be
implemented using a majorization-minimization strategy that is virtually
parameter free. Detailed theoretical analysis and empirical validation on real
images serve to validate the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3830</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3830</id><created>2013-06-17</created><updated>2013-07-23</updated><authors><author><keyname>Livan</keyname><forenames>Giacomo</forenames></author><author><keyname>Marsili</keyname><forenames>Matteo</forenames></author></authors><title>What do leaders know?</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 3 figures</comments><journal-ref>Entropy, 15(8), 3031-3044 (2013)</journal-ref><doi>10.3390/e15083031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability of a society to make the right decisions on relevant matters
relies on its capability to properly aggregate the noisy information spread
across the individuals it is made of. In this paper we study the information
aggregation performance of a stylized model of a society whose most influential
individuals - the leaders - are highly connected among themselves and
uninformed. Agents update their state of knowledge in a Bayesian manner by
listening to their neighbors. We find analytical and numerical evidence of a
transition, as a function of the noise level in the information initially
available to agents, from a regime where information is correctly aggregated to
one where the population reaches consensus on the wrong outcome with finite
probability. Furthermore, information aggregation depends in a non-trivial
manner on the relative size of the clique of leaders, with the limit of a
vanishingly small clique being singular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3833</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3833</id><created>2013-06-17</created><updated>2014-02-12</updated><authors><author><keyname>Pierre</keyname><forenames>Hyvernat</forenames><affiliation>Universit&#xe9; de Savoie</affiliation></author></authors><title>The Size-Change Termination Principle for Constructor Based Languages</title><categories>cs.LO cs.PL</categories><comments>24 pages + appendix</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 1 (February
  13, 2014) lmcs:1003</journal-ref><doi>10.2168/LMCS-10(1:11)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an automatic termination checker for a generic
first-order call-by-value language in ML style. We use the fact that value are
built from variants and tuples to keep some information about how arguments of
recursive call evolve during evaluation. The result is a criterion for
termination extending the size-change termination principle of Lee, Jones and
Ben-Amram that can detect size changes inside subvalues of arguments. Moreover
the corresponding algorithm is easy to implement, making it a good candidate
for experimentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3839</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3839</id><created>2013-06-17</created><authors><author><keyname>Archambault</keyname><forenames>Daniel</forenames></author><author><keyname>Greene</keyname><forenames>Derek</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>TwitterCrowds: Techniques for Exploring Topic and Sentiment in
  Microblogging Data</title><categories>cs.SI physics.soc-ph</categories><comments>19 pages, colour figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysts and social scientists in the humanities and industry require
techniques to help visualize large quantities of microblogging data. Methods
for the automated analysis of large scale social media data (on the order of
tens of millions of tweets) are widely available, but few visualization
techniques exist to support interactive exploration of the results. In this
paper, we present extended descriptions of ThemeCrowds and SentireCrowds, two
tag-based visualization techniques for this data. We subsequently introduce a
new list equivalent for both of these techniques and present a number of case
studies showing them in operation. Finally, we present a formal user study to
evaluate the effectiveness of these list interface equivalents when comparing
them to ThemeCrowds and SentireCrowds. We find that discovering topics
associated with areas of strong positive or negative sentiment is faster when
using a list interface. In terms of user preference, multilevel tag clouds were
found to be more enjoyable to use. Despite both interfaces being usable for all
tested tasks, we have evidence to support that list interfaces can be more
efficient for tasks when an appropriate ordering is known beforehand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3855</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3855</id><created>2013-06-17</created><updated>2013-11-11</updated><authors><author><keyname>Mishkin</keyname><forenames>Dmytro</forenames></author><author><keyname>Perdoch</keyname><forenames>Michal</forenames></author><author><keyname>Matas</keyname><forenames>Jiri</forenames></author></authors><title>Two-View Matching with View Synthesis Revisited</title><categories>cs.CV</categories><comments>25 pages, 14 figures</comments><report-no>CTU--CMP--2013--15</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wide-baseline matching focussing on problems with extreme viewpoint change is
considered. We introduce the use of view synthesis with affine-covariant
detectors to solve such problems and show that matching with the Hessian-Affine
or MSER detectors outperforms the state-of-the-art ASIFT.
  To minimise the loss of speed caused by view synthesis, we propose the
Matching On Demand with view Synthesis algorithm (MODS) that uses progressively
more synthesized images and more (time-consuming) detectors until reliable
estimation of geometry is possible. We show experimentally that the MODS
algorithm solves problems beyond the state-of-the-art and yet is comparable in
speed to standard wide-baseline matchers on simpler problems.
  Minor contributions include an improved method for tentative correspondence
selection, applicable both with and without view synthesis and a view synthesis
setup greatly improving MSER robustness to blur and scale change that increase
its running time by 10% only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3856</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3856</id><created>2013-06-17</created><authors><author><keyname>R&#xf6;nnqvist</keyname><forenames>Samuel</forenames></author><author><keyname>Sarlin</keyname><forenames>Peter</forenames></author></authors><title>From Text to Bank Interrelation Maps</title><categories>q-fin.RM cs.SI physics.soc-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the wake of the ongoing global financial crisis, interdependencies among
banks have come into focus in trying to assess systemic risk. To date, such
analysis has largely been based on numerical data. By contrast, this study
attempts to gain further insight into bank interconnections by tapping into
financial discussion. Co-mentions of bank names are turned into a network,
which can be visualized and analyzed quantitatively, in order to illustrate
characteristics of individual banks and the network as a whole. The approach
allows for the study of temporal dynamics of the network, to highlight changing
patterns of discussion that reflect real-world events, the current financial
crisis in particular. For instance, it depicts how connections from distressed
banks to other banks and supervisory authorities have emerged and faded over
time, as well as how global shifts in network structure coincide with severe
crisis episodes. The usage of textual data holds an additional advantage in the
possibility of gaining a more qualitative understanding of an observed
interrelation, through its context. We illustrate our approach using a case
study on Finnish banks and financial institutions. The data set comprises 3.9M
posts from online, financial and business-related discussion, during the years
2004 to 2012. Future research includes analyzing European news articles with a
broader perspective, and a focus on improving semantic description of
relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3857</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3857</id><created>2013-06-17</created><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Giannopoulou</keyname><forenames>Archontia C.</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Computing Tree-depth Faster Than $2^{n}$</title><categories>cs.DS math.CO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A connected graph has tree-depth at most $k$ if it is a subgraph of the
closure of a rooted tree whose height is at most $k$. We give an algorithm
which for a given $n$-vertex graph $G$, in time $\mathcal{O}(1.9602^n)$
computes the tree-depth of $G$. Our algorithm is based on combinatorial results
revealing the structure of minimal rooted trees whose closures contain $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3860</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3860</id><created>2013-06-17</created><authors><author><keyname>Sarlin</keyname><forenames>Peter</forenames></author><author><keyname>R&#xf6;nnqvist</keyname><forenames>Samuel</forenames></author></authors><title>Cluster coloring of the Self-Organizing Map: An information
  visualization perspective</title><categories>cs.LG cs.HC</categories><comments>Forthcoming in Proceedings of 17th International Conference
  Information Visualisation (2013)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper takes an information visualization perspective to visual
representations in the general SOM paradigm. This involves viewing SOM-based
visualizations through the eyes of Bertin's and Tufte's theories on data
graphics. The regular grid shape of the Self-Organizing Map (SOM), while being
a virtue for linking visualizations to it, restricts representation of cluster
structures. From the viewpoint of information visualization, this paper
provides a general, yet simple, solution to projection-based coloring of the
SOM that reveals structures. First, the proposed color space is easy to
construct and customize to the purpose of use, while aiming at being
perceptually correct and informative through two separable dimensions. Second,
the coloring method is not dependent on any specific method of projection, but
is rather modular to fit any objective function suitable for the task at hand.
The cluster coloring is illustrated on two datasets: the iris data, and welfare
and poverty indicators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3874</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3874</id><created>2013-06-17</created><updated>2014-09-01</updated><authors><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author></authors><title>Classifying and Visualizing Motion Capture Sequences using Deep Neural
  Networks</title><categories>cs.CV</categories><comments>VISAPP 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The gesture recognition using motion capture data and depth sensors has
recently drawn more attention in vision recognition. Currently most systems
only classify dataset with a couple of dozens different actions. Moreover,
feature extraction from the data is often computational complex. In this paper,
we propose a novel system to recognize the actions from skeleton data with
simple, but effective, features using deep neural networks. Features are
extracted for each frame based on the relative positions of joints (PO),
temporal differences (TD), and normalized trajectories of motion (NT). Given
these features a hybrid multi-layer perceptron is trained, which simultaneously
classifies and reconstructs input data. We use deep autoencoder to visualize
learnt features, and the experiments show that deep neural networks can capture
more discriminative information than, for instance, principal component
analysis can. We test our system on a public database with 65 classes and more
than 2,000 motion sequences. We obtain an accuracy above 95% which is, to our
knowledge, the state of the art result for such a large dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3875</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3875</id><created>2013-06-14</created><authors><author><keyname>Li</keyname><forenames>Tiancheng</forenames></author><author><keyname>Sattar</keyname><forenames>Tariq P.</forenames></author><author><keyname>Han</keyname><forenames>Qing</forenames></author><author><keyname>Sun</keyname><forenames>Shudong</forenames></author></authors><title>Roughening Methods to Prevent Sample Impoverishment in the Particle PHD
  Filter</title><categories>cs.OH</categories><comments>16th International Conference on Information Fusion(FUSION2013), 9-12
  July 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mahler's PHD (Probability Hypothesis Density) filter and its particle
implementation (as called the particle PHD filter) have gained popularity to
solve general MTT (Multi-target Tracking) problems. However, the resampling
procedure used in the particle PHD filter can cause sample impoverishment. To
rejuvenate the diversity of particles, two easy-to-implement roughening
approaches are presented to enhance the particle PHD filter. One termed as
&quot;separate-roughening&quot; is inspired by Gordon's roughening procedure that is
applied on the resampled particles. Another termed as &quot;direct-roughening&quot; is
implemented by increasing the simulation noise of the state propagation of
particles. Four proposals are presented to customize the roughening approach.
Simulations are presented showing that the roughening approach can benefit the
particle PHD filter, especially when the sample size is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3877</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3877</id><created>2013-06-17</created><authors><author><keyname>Boral</keyname><forenames>Anudhyan</forenames></author><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Kociumaka</keyname><forenames>Tomasz</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author></authors><title>Fast branching algorithm for Cluster Vertex Deletion</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the family of clustering problems, we are given a set of objects (vertices
of the graph), together with some observed pairwise similarities (edges). The
goal is to identify clusters of similar objects by slightly modifying the graph
to obtain a cluster graph (disjoint union of cliques). Hueffner et al. [Theory
Comput. Syst. 2010] initiated the parameterized study of Cluster Vertex
Deletion, where the allowed modification is vertex deletion, and presented an
elegant O(2^k * k^9 + n * m)-time fixed-parameter algorithm, parameterized by
the solution size. In our work, we pick up this line of research and present an
O(1.9102^k * (n + m))-time branching algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3882</identifier>
 <datestamp>2013-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3882</id><created>2013-06-14</created><updated>2013-11-06</updated><authors><author><keyname>Schrammel</keyname><forenames>Peter</forenames></author><author><keyname>Melham</keyname><forenames>Tom</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author></authors><title>Chaining Test Cases for Reactive System Testing (extended version)</title><categories>cs.SE cs.SY</categories><comments>extended version of paper published at ICTSS'13</comments><acm-class>D.2.4; D.2.5; F.3.1; F.2.2; C.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing of synchronous reactive systems is challenging because long input
sequences are often needed to drive them into a state at which a desired
feature can be tested. This is particularly problematic in on-target testing,
where a system is tested in its real-life application environment and the time
required for resetting is high. This paper presents an approach to discovering
a test case chain---a single software execution that covers a group of test
goals and minimises overall test execution time. Our technique targets the
scenario in which test goals for the requirements are given as safety
properties. We give conditions for the existence and minimality of a single
test case chain and minimise the number of test chains if a single test chain
is infeasible. We report experimental results with a prototype tool for C code
generated from Simulink models and compare it to state-of-the-art test suite
generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3884</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3884</id><created>2013-06-17</created><authors><author><keyname>Slota</keyname><forenames>Martin</forenames></author><author><keyname>Leite</keyname><forenames>Jo&#xe3;o</forenames></author></authors><title>The Rise and Fall of Semantic Rule Updates Based on SE-Models</title><categories>cs.AI</categories><comments>38 pages, to appear in Theory and Practice of Logic Programming
  (TPLP)</comments><acm-class>D.1.6; I.2.3; I.2.4</acm-class><doi>10.1017/S1471068413000100</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programs under the stable model semantics, or answer-set programs,
provide an expressive rule-based knowledge representation framework, featuring
a formal, declarative and well-understood semantics. However, handling the
evolution of rule bases is still a largely open problem. The AGM framework for
belief change was shown to give inappropriate results when directly applied to
logic programs under a non-monotonic semantics such as the stable models. The
approaches to address this issue, developed so far, proposed update semantics
based on manipulating the syntactic structure of programs and rules.
  More recently, AGM revision has been successfully applied to a significantly
more expressive semantic characterisation of logic programs based on SE-models.
This is an important step, as it changes the focus from the evolution of a
syntactic representation of a rule base to the evolution of its semantic
content.
  In this paper, we borrow results from the area of belief update to tackle the
problem of updating (instead of revising) answer-set programs. We prove a
representation theorem which makes it possible to constructively define any
operator satisfying a set of postulates derived from Katsuno and Mendelzon's
postulates for belief update. We define a specific operator based on this
theorem, examine its computational complexity and compare the behaviour of this
operator with syntactic rule update semantics from the literature. Perhaps
surprisingly, we uncover a serious drawback of all rule update operators based
on Katsuno and Mendelzon's approach to update and on SE-models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3888</identifier>
 <datestamp>2015-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3888</id><created>2013-06-13</created><updated>2015-01-07</updated><authors><author><keyname>Wolff</keyname><forenames>J. Gerard</forenames></author></authors><title>The SP theory of intelligence: an overview</title><categories>cs.AI</categories><comments>arXiv admin note: text overlap with arXiv:cs/0401009,
  arXiv:1303.2071, arXiv:cs/0307010, arXiv:1212.0229, arXiv:1303.2013</comments><journal-ref>J G Wolff, Information, 4 (3), 283-341, 2013</journal-ref><doi>10.3390/info4030283</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is an overview of the &quot;SP theory of intelligence&quot;. The theory
aims to simplify and integrate concepts across artificial intelligence,
mainstream computing and human perception and cognition, with information
compression as a unifying theme. It is conceived as a brain-like system that
receives 'New' information and stores some or all of it in compressed form as
'Old' information. It is realised in the form of a computer model -- a first
version of the SP machine. The concept of &quot;multiple alignment&quot; is a powerful
central idea. Using heuristic techniques, the system builds multiple alignments
that are 'good' in terms of information compression. For each multiple
alignment, probabilities may be calculated. These provide the basis for
calculating the probabilities of inferences. The system learns new structures
from partial matches between patterns. Using heuristic techniques, the system
searches for sets of structures that are 'good' in terms of information
compression. These are normally ones that people judge to be 'natural', in
accordance with the 'DONSVIC' principle -- the discovery of natural structures
via information compression. The SP theory may be applied in several areas
including 'computing', aspects of mathematics and logic, representation of
knowledge, natural language processing, pattern recognition, several kinds of
reasoning, information storage and retrieval, planning and problem solving,
information compression, neuroscience, and human perception and cognition.
Examples include the parsing and production of language including discontinuous
dependencies in syntax, pattern recognition at multiple levels of abstraction
and its integration with part-whole relations, nonmonotonic reasoning and
reasoning with default values, reasoning in Bayesian networks including
'explaining away', causal diagnosis, and the solving of a geometric analogy
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3890</identifier>
 <datestamp>2014-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3890</id><created>2013-06-13</created><updated>2014-03-31</updated><authors><author><keyname>Wolff</keyname><forenames>J. Gerard</forenames></author></authors><title>Big data and the SP theory of intelligence</title><categories>cs.AI</categories><comments>Accepted for publication in IEEE Access</comments><journal-ref>J G Wolff, IEEE Access, 2, 301-315, 2014</journal-ref><doi>10.1109/ACCESS.2014.2315297</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is about how the &quot;SP theory of intelligence&quot; and its realisation
in the &quot;SP machine&quot; may, with advantage, be applied to the management and
analysis of big data. The SP system -- introduced in the article and fully
described elsewhere -- may help to overcome the problem of variety in big data:
it has potential as &quot;a universal framework for the representation and
processing of diverse kinds of knowledge&quot; (UFK), helping to reduce the
diversity of formalisms and formats for knowledge and the different ways in
which they are processed. It has strengths in the unsupervised learning or
discovery of structure in data, in pattern recognition, in the parsing and
production of natural language, in several kinds of reasoning, and more. It
lends itself to the analysis of streaming data, helping to overcome the problem
of velocity in big data. Central in the workings of the system is lossless
compression of information: making big data smaller and reducing problems of
storage and management. There is potential for substantial economies in the
transmission of data, for big cuts in the use of energy in computing, for
faster processing, and for smaller and lighter computers. The system provides a
handle on the problem of veracity in big data, with potential to assist in the
management of errors and uncertainties in data. It lends itself to the
visualisation of knowledge structures and inferential processes. A
high-parallel, open-source version of the SP machine would provide a means for
researchers everywhere to explore what can be done with the system and to
create new versions of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3895</identifier>
 <datestamp>2014-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3895</id><created>2013-06-17</created><updated>2014-05-09</updated><authors><author><keyname>Nie</keyname><forenames>Jiazhong</forenames></author><author><keyname>Kotlowski</keyname><forenames>Wojciech</forenames></author><author><keyname>Warmuth</keyname><forenames>Manfred K.</forenames></author></authors><title>On-line PCA with Optimal Regrets</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We carefully investigate the on-line version of PCA, where in each trial a
learning algorithm plays a k-dimensional subspace, and suffers the compression
loss on the next instance when projected into the chosen subspace. In this
setting, we analyze two popular on-line algorithms, Gradient Descent (GD) and
Exponentiated Gradient (EG). We show that both algorithms are essentially
optimal in the worst-case. This comes as a surprise, since EG is known to
perform sub-optimally when the instances are sparse. This different behavior of
EG for PCA is mainly related to the non-negativity of the loss in this case,
which makes the PCA setting qualitatively different from other settings studied
in the literature. Furthermore, we show that when considering regret bounds as
function of a loss budget, EG remains optimal and strictly outperforms GD.
Next, we study the extension of the PCA setting, in which the Nature is allowed
to play with dense instances, which are positive matrices with bounded largest
eigenvalue. Again we can show that EG is optimal and strictly better than GD in
this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3896</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3896</id><created>2013-06-17</created><updated>2013-07-09</updated><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Maturo</keyname><forenames>Nicola</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author></authors><title>Improving the efficiency of the LDPC code-based McEliece cryptosystem
  through irregular codes</title><categories>cs.IT cs.CR math.IT</categories><comments>6 pages, 3 figures, presented at ISCC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the framework of the McEliece cryptosystem based on LDPC codes,
which is a promising post-quantum alternative to classical public key
cryptosystems. The use of LDPC codes in this context allows to achieve good
security levels with very compact keys, which is an important advantage over
the classical McEliece cryptosystem based on Goppa codes. However, only regular
LDPC codes have been considered up to now, while some further improvement can
be achieved by using irregular LDPC codes, which are known to achieve better
error correction performance than regular LDPC codes. This is shown in this
paper, for the first time at our knowledge. The possible use of irregular
transformation matrices is also investigated, which further increases the
efficiency of the system, especially in regard to the public key size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3899</identifier>
 <datestamp>2013-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3899</id><created>2013-06-17</created><updated>2013-10-31</updated><authors><author><keyname>Ducoat</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author></authors><title>Generalized rank weights : a duality statement</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><msc-class>94B05, 94A45, 94B65, 94B60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider linear codes over some fixed finite field extension over an
arbitrary finite field. Gabidulin introduced rank metric codes, by endowing
linear codes over the extension field with a rank weight over the base field
and studied their basic properties in analogy with linear codes and the
classical Hamming distance. Inspired by the characterization of wiretap II
codes in terms of generalized Hamming weights by Wei, Kurihara et al. defined
some generalized rank weights and showed their relevance for secure network
coding. In this paper, we derive a statement for generalized rank weights of
the dual code, completely analogous to Wei's one for generalized Hamming
weights and we characterize the equality case of the r-generalized Singleton
bound for the generalized rank weights, in terms of the rank weight of the dual
code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3903</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3903</id><created>2013-06-17</created><updated>2013-07-15</updated><authors><author><keyname>Bhakta</keyname><forenames>Ishita</forenames></author><author><keyname>Chakraborty</keyname><forenames>Sandip</forenames></author><author><keyname>Mitra</keyname><forenames>Barsha</forenames></author><author><keyname>Sanyal</keyname><forenames>Debarshi Kumar</forenames></author><author><keyname>Chattopadhyay</keyname><forenames>Samiran</forenames></author><author><keyname>Chattopadhyay</keyname><forenames>Matangini</forenames></author></authors><title>Designing an Efficient Delay Sensitive Routing Metric for IEEE 802.16
  Mesh Networks</title><categories>cs.NI</categories><comments>This paper has been presented at the International Conference on
  Wireless and Optical Communications, May 2011, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality of Service provisioning is one of the major design goals of IEEE
802.16 mesh networks. In order to provide quality delivery of delay sensitive
services such as voice, video etc., it is required to route such traffic over a
minimum delay path. In this paper we propose a routing metric for delay
sensitive services in IEEE 802.16 mesh networks. We design a new cross layer
routing metric, namely Expected Scheduler Delay (ESD), based on HoldOff
exponent and the current load at each node of the network. This proposed metric
takes into account the expected theoretical end-to-end delay of routing paths
as well as network congestion to find the best suited path. We propose an
efficient distributed scheme to calculate ESD and route the packets using
source routing mechanism based on ESD. The simulation results demonstrate that
our metric achieves reduced delay compared to a standard scheme used in IEEE
802.16 mesh, that takes hop count to find the path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3905</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3905</id><created>2013-06-17</created><authors><author><keyname>Audiffren</keyname><forenames>Julien</forenames><affiliation>LIF</affiliation></author><author><keyname>Kadri</keyname><forenames>Hachem</forenames><affiliation>LIF</affiliation></author></authors><title>Stability of Multi-Task Kernel Regression Algorithms</title><categories>cs.LG stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the stability properties of nonlinear multi-task regression in
reproducing Hilbert spaces with operator-valued kernels. Such kernels, a.k.a.
multi-task kernels, are appropriate for learning prob- lems with nonscalar
outputs like multi-task learning and structured out- put prediction. We show
that multi-task kernel regression algorithms are uniformly stable in the
general case of infinite-dimensional output spaces. We then derive under mild
assumption on the kernel generaliza- tion bounds of such algorithms, and we
show their consistency even with non Hilbert-Schmidt operator-valued kernels .
We demonstrate how to apply the results to various multi-task kernel regression
methods such as vector-valued SVR and functional ridge regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3906</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3906</id><created>2013-06-17</created><authors><author><keyname>Ardekani</keyname><forenames>Masoud Saeida</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Sutra</keyname><forenames>Pierre</forenames><affiliation>IIUN</affiliation></author><author><keyname>Pregui&#xe7;a</keyname><forenames>Nuno</forenames><affiliation>CITI</affiliation></author><author><keyname>Shapiro</keyname><forenames>Marc</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author></authors><title>Non-Monotonic Snapshot Isolation</title><categories>cs.DC</categories><proxy>ccsd</proxy><report-no>RR-7805</report-no><journal-ref>N&amp;deg; RR-7805 (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many distributed applications require transactions. However, transactional
protocols that require strong synchronization are costly in large scale
environments. Two properties help with scalability of a transactional system:
genuine partial replication (GPR), which leverages the intrinsic parallelism of
a workload, and snapshot isolation (SI), which decreases the need for
synchronization. We show that, under standard assumptions (data store accesses
are not known in advance, and transactions may access arbitrary objects in the
data store), it is impossible to have both SI and GPR. To circumvent this
impossibility, we propose a weaker consistency criterion, called Non-monotonic
Snapshot Isolation (NMSI). NMSI retains the most important properties of SI,
i.e., read-only transactions always commit, and two write-conflicting updates
do not both commit. We present a GPR protocol that ensures NMSI, and has lower
message cost (i.e., it contacts fewer replicas and/or commits faster) than
previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3909</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3909</id><created>2013-06-17</created><authors><author><keyname>Chen</keyname><forenames>Xujin</forenames></author><author><keyname>Du</keyname><forenames>Donglei</forenames></author><author><keyname>Zuluaga</keyname><forenames>Luis F.</forenames></author></authors><title>Copula-based Randomized Mechanisms for Truthful Scheduling on Two
  Unrelated Machines</title><categories>cs.GT</categories><comments>22 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a Copula-based generic randomized truthful mechanism for scheduling
on two unrelated machines with approximation ratio within $[1.5852, 1.58606]$,
offering an improved upper bound for the two-machine case. Moreover, we provide
an upper bound 1.5067711 for the two-machine two-task case, which is almost
tight in view of the lower bound of 1.506 for the scale-free truthful
mechanisms [4]. Of independent interest is the explicit incorporation of the
concept of Copula in the design and analysis of the proposed approximation
algorithm. We hope that techniques like this one will also prove useful in
solving other problems in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3914</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3914</id><created>2013-06-17</created><updated>2014-04-25</updated><authors><author><keyname>Bernad&#xf3;</keyname><forenames>Laura</forenames></author><author><keyname>Zemen</keyname><forenames>Thomas</forenames></author><author><keyname>Tufvesson</keyname><forenames>Fredrik</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author><author><keyname>Mecklenbr&#xe4;uker</keyname><forenames>Christoph F.</forenames></author></authors><title>Time- and Frequency-Varying $K$-Factor of Non-Stationary Vehicular
  Channels for Safety Relevant Scenarios</title><categories>cs.NI</categories><comments>26 pages, 12 figures, submitted to IEEE Transactions on Intelligent
  Transportation Systems for possible publication</comments><journal-ref>IEEE Transactions on Intelligent Transportation Systems, vol. 16,
  no. 2, April 2015</journal-ref><doi>10.1109/TITS.2014.2349364</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular communication channels are characterized by a non-stationary time-
and frequency-selective fading process due to fast changes in the environment.
We characterize the distribution of the envelope of the first delay bin in
vehicle-to-vehicle channels by means of its Rician $K$-factor. We analyze the
time-frequency variability of this channel parameter using vehicular channel
measurements at 5.6 GHz with a bandwidth of 240 MHz for safety-relevant
scenarios in intelligent transportation systems (ITS). This data enables a
frequency-variability analysis from an IEEE 802.11p system point of view, which
uses 10 MHz channels. We show that the small-scale fading of the envelope of
the first delay bin is Ricean distributed with a varying $K$-factor. The later
delay bins are Rayleigh distributed. We demonstrate that the $K$-factor cannot
be assumed to be constant in time and frequency. The causes of these variations
are the frequency-varying antenna radiation patterns as well as the
time-varying number of active scatterers, and the effects of vegetation. We
also present a simple but accurate bi-modal Gaussian mixture model, that allows
to capture the $K$-factor variability in time for safety-relevant ITS
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3917</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3917</id><created>2013-06-17</created><authors><author><keyname>Jamieson</keyname><forenames>Kevin</forenames></author><author><keyname>Malloy</keyname><forenames>Matthew</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author><author><keyname>Bubeck</keyname><forenames>Sebastien</forenames></author></authors><title>On Finding the Largest Mean Among Many</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling from distributions to find the one with the largest mean arises in a
broad range of applications, and it can be mathematically modeled as a
multi-armed bandit problem in which each distribution is associated with an
arm. This paper studies the sample complexity of identifying the best arm
(largest mean) in a multi-armed bandit problem. Motivated by large-scale
applications, we are especially interested in identifying situations where the
total number of samples that are necessary and sufficient to find the best arm
scale linearly with the number of arms. We present a single-parameter
multi-armed bandit model that spans the range from linear to superlinear sample
complexity. We also give a new algorithm for best arm identification, called
PRISM, with linear sample complexity for a wide range of mean distributions.
The algorithm, like most exploration procedures for multi-armed bandits, is
adaptive in the sense that the next arms to sample are selected based on
previous samples. We compare the sample complexity of adaptive procedures with
simpler non-adaptive procedures using new lower bounds. For many problem
instances, the increased sample complexity required by non-adaptive procedures
is a polynomial factor of the number of arms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3920</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3920</id><created>2013-06-17</created><authors><author><keyname>Silva</keyname><forenames>Thiago C.</forenames></author><author><keyname>Amancio</keyname><forenames>Diego R.</forenames></author></authors><title>Discriminating word senses with tourist walks in complex networks</title><categories>cs.CL cs.SI physics.soc-ph</categories><journal-ref>Eur. Phys. J. B, 86 7 (2013) 297</journal-ref><doi>10.1140/epjb/e2013-40025-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patterns of topological arrangement are widely used for both animal and human
brains in the learning process. Nevertheless, automatic learning techniques
frequently overlook these patterns. In this paper, we apply a learning
technique based on the structural organization of the data in the attribute
space to the problem of discriminating the senses of 10 polysemous words. Using
two types of characterization of meanings, namely semantical and topological
approaches, we have observed significative accuracy rates in identifying the
suitable meanings in both techniques. Most importantly, we have found that the
characterization based on the deterministic tourist walk improves the
disambiguation process when one compares with the discrimination achieved with
traditional complex networks measurements such as assortativity and clustering
coefficient. To our knowledge, this is the first time that such deterministic
walk has been applied to such a kind of problem. Therefore, our finding
suggests that the tourist walk characterization may be useful in other related
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3946</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3946</id><created>2013-06-17</created><updated>2013-09-12</updated><authors><author><keyname>Jiang</keyname><forenames>Hong</forenames></author><author><keyname>Huang</keyname><forenames>Gang</forenames></author><author><keyname>Wilford</keyname><forenames>Paul</forenames></author></authors><title>Multi-view in Lensless Compressive Imaging</title><categories>cs.IT cs.CV math.IT</categories><comments>Accepted for presentation at PCS 2013 as Paper #1021; 4 pages, 4
  figures. arXiv admin note: text overlap with arXiv:1302.1789</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-view images are acquired by a lensless compressive imaging
architecture, which consists of an aperture assembly and multiple sensors. The
aperture assembly consists of a two dimensional array of aperture elements
whose transmittance can be individually controlled to implement a compressive
sensing matrix. For each transmittance pattern of the aperture assembly, each
of the sensors takes a measurement. The measurement vectors from the multiple
sensors represent multi-view images of the same scene. We present theoretical
framework for multi-view reconstruction and experimental results for enhancing
quality of image using multi-view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3953</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3953</id><created>2013-06-17</created><authors><author><keyname>Talpur</keyname><forenames>Mir Sajjad Hussain</forenames></author></authors><title>The Appliance Pervasive of Internet of Things in Healthcare Systems</title><categories>cs.SY</categories><comments>6 Pages, 2 figures, 1 table, IJCSI Journal</comments><journal-ref>Published in IJCSI Journal, Volume 10, Issue 1, No 1, January 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In fact, information systems are the foundation of new productivity sources,
medical organizational forms, and erection of a global economy. IoT based
healthcare systems play a significant role in ICT and have contribution in
growth of medical information systems, which are underpinning of recent medical
and economic development strategies. However, to take advantages of IoT, it is
essential that medical enterprises and community should trust the IoT systems
in terms of performance, security, privacy, reliability and
return-on-investment, which are open challenges of current IoT systems. For
heightening of healthcare system; tracking, tracing and monitoring of patients
and medical objects are more essential. But due to the inadequate healthcare
situation, medical environment, medical technologies and the unique
requirements of some healthcare applications, the obtainable tools cannot meet
them accurately. The tracking, tracing and monitoring of patients and
healthcare actors activities in healthcare system are challenging research
directions for IoT researchers. State-of-the-art IoT based healthcare system
should be developed which ensure the safety of patients and other healthcare
activities. With this manuscript, we elaborate the essential role of IoT in
healthcare systems; immense prospects of Internet of things in healthcare
systems; extensive aspect of the use of IoT is dissimilar among different
healthcare components and finally the participation of IoT between the useful
research and present realistic applications. IoT and few other modern
technologies are still in underpinning stage; mainly in the healthcare system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3954</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3954</id><created>2013-06-17</created><authors><author><keyname>Ferrer</keyname><forenames>Maria V.</forenames></author><author><keyname>Hernandez</keyname><forenames>Salvador</forenames></author><author><keyname>Shakhmatov</keyname><forenames>Dmitri</forenames></author></authors><title>Subgroups of direct products closely approximated by direct sums</title><categories>math.GN cs.IT math.GR math.IT</categories><msc-class>Primary: 22C05, Secondary: 22D35, 54D30, 54D65, 54E35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $I$ be an infinite set, $\{G_i:i\in I\}$ be a family of (topological)
groups and $G=\prod_{i\in I} G_i$ be its direct product. For $J\subseteq I$,
$p_{J}: G\to \prod_{j\in J} G_j$ denotes the projection. We say that a subgroup
$H$ of $G$ is: (i) \emph{uniformly controllable} in $G$ provided that for every
finite set $J\subseteq I$ there exists a finite set $K\subseteq I$ such that
$p_{J}(H)=p_{J}(H\cap\bigoplus_{i\in K} G_i)$; (ii) \emph{controllable} in $G$
provided that $p_{J}(H)=p_{J}(H\cap\bigoplus_{i\in I} G_i)$ for every finite
set $J\subseteq I$; (iii) \emph{weakly controllable} in $G$ if $H\cap
\bigoplus_{i\in I} G_i$ is dense in $H$, when $G$ is equipped with the
Tychonoff product topology. One easily proves that (i)$\to$(ii)$\to$(iii). We
thoroughly investigate the question as to when these two arrows can be
reversed. We prove that the first arrow can be reversed when $H$ is compact,
but the second arrow cannot be reversed even when $H$ is compact. Both arrows
can be reversed if all groups $G_i$ are finite. When $G_i=A$ for all $i\in I$,
where $A$ is an abelian group, we show that the first arrow can be reversed for
{\em all} subgroups $H$ of $G$ if and only if $A$ is finitely generated.
Connections with coding theory are highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3955</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3955</id><created>2013-06-17</created><authors><author><keyname>Amine</keyname><forenames>Abderrahim Mohammed El</forenames></author><author><keyname>Said</keyname><forenames>Benameur</forenames></author><author><keyname>Alaeddine</keyname><forenames>Abderrahim Mohammed</forenames></author></authors><title>The Number of Terms and Documents for Pseudo-Relevant Feedback for
  Ad-hoc Information Retrieval</title><categories>cs.IR</categories><comments>7 pages</comments><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 1, No 1, January 2013; pp 661-667; ISSN 1694-0784</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Information Retrieval System (IRS), the Automatic Relevance Feedback (ARF)
is a query reformulation technique that modifies the initial one without the
user intervention. It is applied mainly through the addition of terms coming
from the external resources such as the ontologies and or the results of the
current research. In this context we are mainly interested in the local
analysis technique for the ARF in ad-hoc IRS on Arabic documents. In this
article, we have examined the impact of the variation of the two parameters
implied in this technique, that is to say, the number of the documents
{\guillemotleft}D{\guillemotright} and the number of terms
{\guillemotleft}T{\guillemotright}, on an Arabic IRS performance. The
experimentation, carried out on an Arabic corpus text, enables us to deduce
that there are queries which are not easily improvable with the query
reformulation. In addition, the success of the ARF is due mainly to the
selection of a sufficient number of documents D and to the extraction of a very
reduced set of relevant terms T for retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3959</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3959</id><created>2013-06-17</created><authors><author><keyname>Adel</keyname><forenames>Alti</forenames></author><author><keyname>Phillipe</keyname><forenames>Roose</forenames></author></authors><title>A New Approach for Quality Management in Pervasive Computing
  Environments</title><categories>cs.SE</categories><comments>10 pages, 10 Figures, Oral Presentation in ECSA 2010</comments><acm-class>H.5.1; D.2</acm-class><journal-ref>International Journal of Computer Science Issues 10, 1 (2013) 1-10</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper provides an extension of MDA called Context-aware Quality Model
Driven Architecture (CQ-MDA) which can be used for quality control in pervasive
computing environments. The proposed CQ-MDA approach based on
ContextualArchRQMM (Contextual ARCHitecture Quality Requirement MetaModel),
being an extension to the MDA, allows for considering quality and
resources-awareness while conducting the design process. The contributions of
this paper are a meta-model for architecture quality control of context-aware
applications and a model driven approach to separate architecture concerns from
context and quality concerns and to configure reconfigurable software
architectures of distributed systems. To demonstrate the utility of our
approach, we use a videoconference system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1306.3975</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1306.3975</id><created>2013-06-17</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Lifting/lowering Hopfield models ground state energies</title><categories>math.OC cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1306.3764</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our recent work \cite{StojnicHopBnds10} we looked at a class of random
optimization problems that arise in the forms typically known as Hopfield
models. We viewed two scenarios which we termed as the positive Hopfield form
and the negative Hopfield form. For both of these scenarios we defined the
binary optimization problems whose optimal values essentially emulate what
would typically be known as the ground state energy of these models. We then
presented a simple mechanisms that can be used to create a set of theoretical
rigorous bounds for these energies. In this paper we create a way more powerful
set of mechanisms that can substantially improve the simple bounds given in
\cite{StojnicHopBnds10}. In fact, the mechanisms we create in this paper are
the first set of results that show that convexity type of bounds can be
substantially improved in this type of combinatorial problems.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="46000" completeListSize="102538">1122234|47001</resumptionToken>
</ListRecords>
</OAI-PMH>
