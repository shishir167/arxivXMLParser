<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:44:28Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|14001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1183</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1183</id><created>2010-06-07</created><updated>2010-06-11</updated><authors><author><keyname>Majumder</keyname><forenames>Koushik</forenames><affiliation>West Bengal University of Technology, India</affiliation></author><author><keyname>Sarkar</keyname><forenames>Subir Kumar</forenames><affiliation>Jadavpur University, India</affiliation></author></authors><title>Hybrid Scenario Based Performance Analysis of DSDV and DSR</title><categories>cs.NI</categories><comments>15 Pages</comments><proxy>Secretary Aircc Journal</proxy><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 56-70</journal-ref><doi>10.5121/ijcsit.2010.2305</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The area of mobile ad hoc networking has received considerable attention of
the research community in recent years. These networks have gained immense
popularity primarily due to their infrastructure-less mode of operation which
makes them a suitable candidate for deployment in emergency scenarios like
relief operation, battlefield etc., where either the pre-existing
infrastructure is totally damaged or it is not possible to establish a new
infrastructure quickly. However, MANETs are constrained due to the limited
transmission range of the mobile nodes which reduces the total coverage area.
Sometimes the infrastructure-less ad hoc network may be combined with a fixed
network to form a hybrid network which can cover a wider area with the
advantage of having less fixed infrastructure. In such a combined network, for
transferring data, we need base stations which act as gateways between the
wired and wireless domains. Due to the hybrid nature of these networks, routing
is considered a challenging task. Several routing protocols have been proposed
and tested under various traffic conditions. However, the simulations of such
routing protocols usually do not consider the hybrid network scenario. In this
work we have carried out a systematic performance study of the two prominent
routing protocols: Destination Sequenced Distance Vector Routing (DSDV) and
Dynamic Source Routing (DSR) protocols in the hybrid networking environment. We
have analyzed the performance differentials on the basis of three metrics -
packet delivery fraction, average end-to-end delay and normalized routing load
under varying pause time with different number of sources using NS2 based
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1184</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1184</id><created>2010-06-07</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author><author><keyname>Kostyuk</keyname><forenames>Nataliya</forenames></author><author><keyname>Isokpehi</keyname><forenames>Raphael</forenames></author><author><keyname>Cohly</keyname><forenames>Hari</forenames></author></authors><title>An Algorithm to Self-Extract Secondary Keywords and Their Combinations
  Based on Abstracts Collected using Primary Keywords from Online Digital
  Libraries</title><categories>cs.IR</categories><comments>9 Pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 93-101</journal-ref><doi>10.5121/ijcsit.2010.2307</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The high-level contribution of this paper is the development and
implementation of an algorithm to selfextract secondary keywords and their
combinations (combo words) based on abstracts collected using standard primary
keywords for research areas from reputed online digital libraries like IEEE
Explore, PubMed Central and etc. Given a collection of N abstracts, we
arbitrarily select M abstracts (M&lt;&lt; N; M/N as low as 0.15) and parse each of
the M abstracts, word by word. Upon the first-time appearance of a word, we
query the user for classifying the word into an Accept-List or non-Accept-List.
The effectiveness of the training approach is evaluated by measuring the
percentage of words for which the user is queried for classification when the
algorithm parses through the words of each of the M abstracts. We observed that
as M grows larger, the percentage of words for which the user is queried for
classification reduces drastically. After the list of acceptable words is built
by parsing the M abstracts, we now parse all the N abstracts, word by word, and
count the frequency of appearance of each of the words in Accept-List in these
N abstracts. We also construct a Combo-Accept-List comprising of all possible
combinations of the single keywords in Accept-List and parse all the N
abstracts, two successive words (combo word) at a time, and count the frequency
of appearance of each of the combo words in the Combo-Accept-List in these N
abstracts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1186</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1186</id><created>2010-06-07</created><authors><author><keyname>Nag</keyname><forenames>A.</forenames><affiliation>Academy of Technology - Hoogly, India and</affiliation></author><author><keyname>Biswas</keyname><forenames>S.</forenames><affiliation>University of Kalyani, India</affiliation></author><author><keyname>Sarkar</keyname><forenames>D.</forenames><affiliation>University of Kalyani, India</affiliation></author><author><keyname>Sarkar</keyname><forenames>P. P.</forenames><affiliation>University of Kalyani, India</affiliation></author></authors><title>A novel technique for image steganography based on Block-DCT and Huffman
  Encoding</title><categories>cs.MM</categories><comments>10 pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 103-112</journal-ref><doi>10.5121/ijcsit.2010.2308</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Image steganography is the art of hiding information into a cover image. This
paper presents a novel technique for Image steganography based on Block-DCT,
where DCT is used to transform original image (cover image) blocks from spatial
domain to frequency domain. Firstly a gray level image of size M x N is divided
into no joint 8 x 8 blocks and a two dimensional Discrete Cosine Transform (2-d
DCT) is performed on each of the P = MN / 64 blocks. Then Huffman encoding is
also performed on the secret messages/images before embedding and each bit of
Huffman code of secret message/image is embedded in the frequency domain by
altering the least significant bit of each of the DCT coefficients of cover
image blocks. The experimental results show that the algorithm has a high
capacity and a good invisibility. Moreover PSNR of cover image with stego-image
shows the better results in comparison with other existing steganography
approaches. Furthermore, satisfactory security is maintained since the secret
message/image cannot be extracted without knowing decoding rules and Huffman
table.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1187</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1187</id><created>2010-06-07</created><authors><author><keyname>Sheela</keyname><forenames>S. V.</forenames><affiliation>B. M. S. College of Engineering - Bangalore, India</affiliation></author><author><keyname>Radhika</keyname><forenames>K. R.</forenames><affiliation>B. M. S. College of Engineering - Bangalore, India</affiliation></author></authors><title>Biometric Authentication using Nonparametric Methods</title><categories>cs.CV</categories><comments>20 pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 114-133</journal-ref><doi>10.5121/ijcsit.2010.2309</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The physiological and behavioral trait is employed to develop biometric
authentication systems. The proposed work deals with the authentication of iris
and signature based on minimum variance criteria. The iris patterns are
preprocessed based on area of the connected components. The segmented image
used for authentication consists of the region with large variations in the
gray level values. The image region is split into quadtree components. The
components with minimum variance are determined from the training samples. Hu
moments are applied on the components. The summation of moment values
corresponding to minimum variance components are provided as input vector to
k-means and fuzzy kmeans classifiers. The best performance was obtained for MMU
database consisting of 45 subjects. The number of subjects with zero False
Rejection Rate [FRR] was 44 and number of subjects with zero False Acceptance
Rate [FAR] was 45. This paper addresses the computational load reduction in
off-line signature verification based on minimal features using k-means, fuzzy
k-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and
FAR of 10% was achieved using k-nn classifier. The signature is a biometric,
where variations in a genuine case, is a natural expectation. In the genuine
signature, certain parts of signature vary from one instance to another. The
system aims to provide simple, fast and robust system using less number of
features when compared to state of art works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1190</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1190</id><created>2010-06-07</created><updated>2010-06-09</updated><authors><author><keyname>H</keyname><forenames>Spits Warnars H. L.</forenames></author></authors><title>Game Information System</title><categories>cs.AI</categories><comments>14 pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 135-148</journal-ref><doi>10.5121/ijcsit.2010.2310</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this Information system age many organizations consider information system
as their weapon to compete or gain competitive advantage or give the best
services for non profit organizations. Game Information System as combining
Information System and game is breakthrough to achieve organizations'
performance. The Game Information System will run the Information System with
game and how game can be implemented to run the Information System. Game is not
only for fun and entertainment, but will be a challenge to combine fun and
entertainment with Information System. The Challenge to run the information
system with entertainment, deliver the entertainment with information system
all at once. Game information system can be implemented in many sectors as like
the information system itself but in difference's view. A view of game which
people can joy and happy and do their transaction as a fun things.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1191</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1191</id><created>2010-06-07</created><authors><author><keyname>Gazali</keyname><forenames>Yaser Miaji Osman</forenames></author><author><keyname>Hassan</keyname><forenames>Suhaidi</forenames></author></authors><title>Survey on the Event Orderings Semantics Used for Distributed System</title><categories>cs.DC</categories><comments>9 pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 150-158</journal-ref><doi>10.5121/ijcsit.2010.2311</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Event ordering in distributed system (DS) is disputable and proactive subject
in DS particularly with the emergence of multimedia synchronization. According
to the literature, different type of event ordering is used for different DS
mode such as asynchronous or synchronous. Recently, there are several novel
implementation of these types introduced to fulfill the demand for establishing
a certain order according to a specific criterion in DS with lighter
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1192</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1192</id><created>2010-06-07</created><authors><author><keyname>Naskar</keyname><forenames>Ruchira</forenames></author><author><keyname>Sengupta</keyname><forenames>Indranil</forenames></author></authors><title>Secret Sharing and Proactive Renewal of Shares in Hierarchical Groups</title><categories>cs.CR</categories><comments>20 Pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 160-179</journal-ref><doi>10.5121/ijcsit.2010.2312</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Secret sharing in user hierarchy represents a challenging area for research.
Although a lot of work has already been done in this direc- tion, this paper
presents a novel approach to share a secret among a hierarchy of users while
overcoming the limitations of the already exist- ing mechanisms. Our work is
based on traditional (k +1; n)-threshold secret sharing, which is secure as
long as an adversary can compromise not more than k secret shares. But in real
life it is often feasible for an adversary to obtain more than k shares over a
long period of time. So, in our work we also present a way to overcome this
vulnerability, while implementing our hierarchical secret sharing scheme. The
use of Elliptic Curve Cryptography makes the computations easier and faster in
our work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1193</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1193</id><created>2010-06-07</created><authors><author><keyname>Rajeswari</keyname><forenames>P. Raja</forenames><affiliation>Acharya Nagarjuna University, India</affiliation></author><author><keyname>Apparo</keyname><forenames>Allam</forenames><affiliation>Jawaharlal Nehru Technological University, India and</affiliation></author><author><keyname>Kumar</keyname><forenames>V. K.</forenames><affiliation>S.V.H. College Of Engineering, India</affiliation></author></authors><title>Genbit Compress Tool(GBC): A Java-Based Tool to Compress DNA Sequences
  and Compute Compression Ratio(bits/base) of Genomes</title><categories>cs.MS</categories><comments>11 pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 181-191</journal-ref><doi>10.5121/ijcsit.2010.2313</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present a Compression Tool, &quot;GenBit Compress&quot;, for genetic sequences based
on our new proposed &quot;GenBit Compress Algorithm&quot;. Our Tool achieves the best
compression ratios for Entire Genome (DNA sequences) . Significantly better
compression results show that GenBit compress algorithm is the best among the
remaining Genome compression algorithms for non-repetitive DNA sequences in
Genomes. The standard Compression algorithms such as gzip or compress cannot
compress DNA sequences but only expand them in size. In this paper we consider
the problem of DNA compression. It is well known that one of the main features
of DNA Sequences is that they contain substrings which are duplicated except
for a few random Mutations. For this reason most DNA compressors work by
searching and encoding approximate repeats. We depart from this strategy by
searching and encoding only exact repeats. our proposed algorithm achieves the
best compression ratio for DNA sequences for larger genome. As long as 8 lakh
characters can be given as input While achieving the best compression ratios
for DNA sequences, our new GenBit Compress program significantly improves the
running time of all previous DNA compressors. Assigning binary bits for
fragments of DNA sequence is also a unique concept introduced in this program
for the first time in DNA compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1198</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1198</id><created>2010-06-07</created><authors><author><keyname>Headayetullah</keyname><forenames>Md.</forenames><affiliation>SOAU - Bhubaneswar, India</affiliation></author><author><keyname>Pradhan</keyname><forenames>G. K.</forenames><affiliation>SOAU - Bhubaneswar, India</affiliation></author></authors><title>Interoperability, Trust Based Information Sharing Protocol and Security:
  Digital Government Key Issues</title><categories>cs.CR</categories><comments>20 pages</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 72-91</journal-ref><doi>10.5121/ijcsit.2010.2306</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Improved interoperability between public and private organizations is of key
significance to make digital government newest triumphant. Digital Government
interoperability, information sharing protocol and security are measured the
key issue for achieving a refined stage of digital government. Flawless
interoperability is essential to share the information between diverse and
merely dispersed organisations in several network environments by using
computer based tools. Digital government must ensure security for its
information systems, including computers and networks for providing better
service to the citizens. Governments around the world are increasingly
revolving to information sharing and integration for solving problems in
programs and policy areas. Evils of global worry such as syndrome discovery and
manage, terror campaign, immigration and border control, prohibited drug
trafficking, and more demand information sharing, harmonization and cooperation
amid government agencies within a country and across national borders. A number
of daunting challenges survive to the progress of an efficient information
sharing protocol. A secure and trusted information-sharing protocol is required
to enable users to interact and share information easily and perfectly across
many diverse networks and databases globally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1210</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1210</id><created>2010-06-07</created><authors><author><keyname>Nir</keyname><forenames>Vincent Le</forenames></author><author><keyname>Moonen</keyname><forenames>Marc</forenames></author><author><keyname>Verlinden</keyname><forenames>Jan</forenames></author><author><keyname>Guenach</keyname><forenames>Mamoun</forenames></author></authors><title>Full vectoring optimal power allocation in xDSL channels under per-modem
  power constraints and spectral mask constraints</title><categories>cs.IT math.IT</categories><comments>8 pages, 6 figures</comments><journal-ref>IEEE Transactions on Communications, Vol. 57, No. 1, pp. 194-202,
  January 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In xDSL systems, crosstalk can be separated into two categories, namely
in-domain crosstalk and out-of-domain crosstalk. In-domain crosstalk is also
refered to as self crosstalk. Out-of-domain crosstalk is crosstalk originating
from outside the multi-pair system and is also denoted as external noise (alien
crosstalk, radio frequency interference,...). While self crosstalk in itself
can easily be canceled by a linear detector like the ZF detector, the presence
of external noise requires a more advanced processing. Coordination between
transmitters and receivers enables the self crosstalk and the external noise to
be mitigated using MIMO signal processing, usually by means of a whitening
filter and SVD. In this paper, we investigate the problem of finding the
optimal power allocation in MIMO xDSL systems in the presence of self crosstalk
and external noise. Optimal Tx/Rx structures and power allocation algorithms
will be devised under practical limitations from xDSL systems, namely per-modem
total power constraints and/or spectral mask constraints, leading to a
generalized SVD-based transmission. Simulation results are given for bonded
VDSL2 systems with external noise coming from ADSL2+ or VDSL2 disturbing lines,
along with a comparison between algorithms with one-sided signal coordination
either only at the transmit side or the receive side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1213</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1213</id><created>2010-06-07</created><authors><author><keyname>Nir</keyname><forenames>Vincent Le</forenames></author><author><keyname>Moonen</keyname><forenames>Marc</forenames></author><author><keyname>Verlinden</keyname><forenames>Jan</forenames></author><author><keyname>Guenach</keyname><forenames>Mamoun</forenames></author></authors><title>Optimal power allocation for downstream xDSL with per-modem total power
  constraints : Broadcast Channel Optimal Spectrum Balancing (BC-OSB)</title><categories>cs.IT math.IT</categories><comments>8 pages, 4 figures</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 57, No. 2, pp.
  690-697, February 2009</journal-ref><doi>10.1109/TSP.2008.2007925</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the duality between Multiple Input Multiple Output (MIMO) Multiple
Access Channels (MAC) and MIMO Broadcast Channels (BC) has been established
under a total power constraint. The same set of rates for MAC can be achieved
in BC exploiting the MAC-BC duality formulas while preserving the total power
constraint. In this paper, we describe the BC optimal power allo- cation
applying this duality in a downstream x-Digital Subscriber Lines (xDSL) context
under a total power constraint for all modems over all tones. Then, a new
algorithm called BC-Optimal Spectrum Balancing (BC-OSB) is devised for a more
realistic power allocation under per-modem total power constraints. The
capacity region of the primal BC problem under per-modem total power
constraints is found by the dual optimization problem for the BC under
per-modem total power constraints which can be rewritten as a dual optimization
problem in the MAC by means of a precoder matrix based on the Lagrange
multipliers. We show that the duality gap between the two problems is zero. The
multi-user power allocation problem has been solved for interference channels
and MAC using the OSB algorithm. In this paper we solve the problem of
multi-user power allocation for the BC case using the OSB algorithm as well and
we derive a computational efficient algorithm that will be referred to as
BC-OSB. Simulation results are provided for two VDSL2 scenarios: the first one
with Differential-Mode (DM) transmission only and the second one with both DM
and Phantom- Mode (PM) transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1222</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1222</id><created>2010-06-07</created><authors><author><keyname>Hull&#xe1;r</keyname><forenames>B&#xe9;la</forenames></author><author><keyname>Laki</keyname><forenames>S&#xe1;ndor</forenames></author><author><keyname>St&#xe9;ger</keyname><forenames>J&#xf3;zsef</forenames></author><author><keyname>Csabai</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>Vattay</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>SONoMA: A Service Oriented Network Measurement Architecture</title><categories>cs.NI cs.DC</categories><comments>Technical Report</comments><report-no>TR-ELTE-CNL-2010/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To characterize the structure, dynamics and operational state of the Internet
it requires distributed measurements. Although in the last decades several
systems capable to do this have been created, the easy access of these
infrastructures and orchestration of complex measurements is not solved. We
propose a system architecture that combines the flexibility of mature network
measurement infrastructures such as PlanetLab or ETOMIC with the general
accessibility and popularity of public services like Web based bandwidth
measurement or traceroute servers. To realize these requirements we developed a
multi-layer architecture based on Web Services and the basic principles of SOA,
which is a very popular paradigm in distributed business application
development. Our approach opens the door to perform complex network
measurements, handles heterogeneous measurement devices, automatically stores
the results in a public database and protects against malicious users as well.
To demonstrate our concept we developed a public prototype system, called
SONoMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1231</identifier>
 <datestamp>2013-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1231</id><created>2010-06-07</created><updated>2013-10-10</updated><authors><author><keyname>Fountoulakis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Panagiotou</keyname><forenames>Konstantinos</forenames></author><author><keyname>Steger</keyname><forenames>Angelika</forenames></author></authors><title>On the Insertion Time of Cuckoo Hashing</title><categories>cs.DS</categories><comments>27 pages, final version accepted by the SIAM Journal on Computing</comments><acm-class>E.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cuckoo hashing is an efficient technique for creating large hash tables with
high space utilization and guaranteed constant access times. There, each item
can be placed in a location given by any one out of k different hash functions.
In this paper we investigate further the random walk heuristic for inserting in
an online fashion new items into the hash table. Provided that k &gt; 2 and that
the number of items in the table is below (but arbitrarily close) to the
theoretically achievable load threshold, we show a polylogarithmic bound for
the maximum insertion time that holds with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1243</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1243</id><created>2010-06-07</created><authors><author><keyname>Amrit</keyname><forenames>Chintan</forenames></author><author><keyname>van Hillegersberg</keyname><forenames>Jos</forenames></author></authors><title>Detecting Coordination Problems in Collaborative Software Development
  Environments</title><categories>cs.SE cs.HC</categories><journal-ref>Information Systems Management, vol. 25, no. 1, pp. 57 - 70, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software development is rarely an individual effort and generally involves
teams of developers collaborating to generate good reliable code. Among the
software code there exist technical dependencies that arise from software
components using services from other components. The different ways of
assigning the design, development, and testing of these software modules to
people can cause various coordination problems among them. We claim that the
collaboration of the developers, designers and testers must be related to and
governed by the technical task structure. These collaboration practices are
handled in what we call Socio-Technical Patterns. The TESNA project (Technical
Social Network Analysis) we report on in this paper addresses this issue. We
propose a method and a tool that a project manager can use in order to detect
the socio-technical coordination problems. We test the method and tool in a
case study of a small and innovative software product company.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1244</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1244</id><created>2010-06-07</created><authors><author><keyname>Amrit</keyname><forenames>Chintan</forenames></author><author><keyname>van Hillegersberg</keyname><forenames>Jos</forenames></author></authors><title>Exploring the Impact of Socio-Technical Core-Periphery Structures in
  Open Source Software Development</title><categories>cs.SE</categories><journal-ref>Journal of Information Technology, Volume 25, Issue 2, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we apply the social network concept of core-periphery structure
to the sociotechnical structure of a software development team. We propose a
socio-technical pattern that can be used to locate emerging coordination
problems in Open Source projects. With the help of our tool and method called
TESNA, we demonstrate a method to monitor the socio-technical core-periphery
movement in Open Source projects. We then study the impact of different
core-periphery movements on Open Source projects. We conclude that a steady
core-periphery shift towards the core is beneficial to the project, whereas
shifts away from the core are clearly not good. Furthermore, oscillatory shifts
towards and away from the core can be considered as an indication of the
instability of the project. Such an analysis can provide developers with a good
insight into the health of an Open Source project. Researchers can gain from
the pattern theory, and from the method we use to study the core-periphery
movements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1249</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1249</id><created>2010-06-07</created><authors><author><keyname>F&#xfa;ster-Sabater</keyname><forenames>Amparo</forenames></author></authors><title>Correction to &quot;Generalized Self-Shrinking Generator&quot;</title><categories>cs.DM</categories><comments>3 pages, 0 figures</comments><msc-class>94A60, 11T71, 14G50</msc-class><acm-class>E.3; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, it is given a correction to Theorem 4 in Y. Hu, and
G. Xiao, &quot;Generalized Self-Shrinking Generator,&quot; IEEE Transactions on
Information Theory, vol. 50, No. 4, pp. 714-719, April 2004.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1260</identifier>
 <datestamp>2011-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1260</id><created>2010-06-07</created><updated>2011-01-05</updated><authors><author><keyname>Isella</keyname><forenames>Lorenzo</forenames></author><author><keyname>Stehl&#xe9;</keyname><forenames>Juliette</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Pinton</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Broeck</keyname><forenames>Wouter Van den</forenames></author></authors><title>What's in a crowd? Analysis of face-to-face behavioral networks</title><categories>physics.soc-ph cs.HC nlin.AO q-bio.OT</categories><journal-ref>J. Theor. Biol. 271 (2011) 166-180</journal-ref><doi>10.1016/j.jtbi.2010.11.033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability of new data sources on human mobility is opening new avenues
for investigating the interplay of social networks, human mobility and
dynamical processes such as epidemic spreading. Here we analyze data on the
time-resolved face-to-face proximity of individuals in large-scale real-world
scenarios. We compare two settings with very different properties, a scientific
conference and a long-running museum exhibition. We track the behavioral
networks of face-to-face proximity, and characterize them from both a static
and a dynamic point of view, exposing important differences as well as striking
similarities. We use our data to investigate the dynamics of a
susceptible-infected model for epidemic spreading that unfolds on the dynamical
networks of human proximity. The spreading patterns are markedly different for
the conference and the museum case, and they are strongly impacted by the
causal structure of the network data. A deeper study of the spreading paths
shows that the mere knowledge of static aggregated networks would lead to
erroneous conclusions about the transmission paths on the dynamical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1265</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1265</id><created>2010-06-07</created><updated>2011-02-06</updated><authors><author><keyname>B&#xe9;al</keyname><forenames>Marie-Pierre</forenames></author><author><keyname>Berstel</keyname><forenames>Jean</forenames></author><author><keyname>Eilers</keyname><forenames>S&#xf8;ren</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author></authors><title>Symbolic dynamics</title><categories>cs.FL cs.DM math.DS</categories><comments>This text is part of a &quot;Handbook on Automata&quot; edited by Jean-Eric
  Pin, to be published by European Mathematical Society</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter presents some of the links between automata theory and symbolic
dynamics. The emphasis is on two particular points. The first one is the
interplay between some particular classes of automata, such as local automata
and results on embeddings of shifts of finite type. The second one is the
connection between syntactic semigroups and the classification of sofic shifts
up to conjugacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1273</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1273</id><created>2010-06-07</created><authors><author><keyname>Tompkins</keyname><forenames>C. Robinson</forenames></author></authors><title>The Morphisms With Unstackable Image Words</title><categories>cs.FL</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an attempt to classify all of the overlap-free morphisms constructively
using the Latin-square morphism, we came across an interesting counterexample,
the Leech square-free morphism. We generalize the combinatorial properties of
the Leech square-free morphism to gain insights on a larger class of both
overlap-free morphisms and square-free morphisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1282</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1282</id><created>2010-06-01</created><updated>2012-02-17</updated><authors><author><keyname>Zhao</keyname><forenames>Jun</forenames></author><author><keyname>Mansfield</keyname><forenames>Elizabeth</forenames></author></authors><title>Discrete Variational Calculus for B-spline Approximated Curves</title><categories>cs.NA cs.CG math.NA</categories><comments>14 pages, 19 figures, prepare for LMS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study variational problems for curves approximated by B-spline curves. We
show that, one can obtain discrete Euler-Lagrange equations, for the data
describing the approximated curves. Our main application is to the curve
completion problem in 2D and 3D. In this case, the aim is to find various
aesthetically pleasing solutions as opposed to a solution of a physical
problem. The Lagrangians of interest are invariant under the special Euclidean
group action for which B-spline approximated curves are well suited. Smooth
Lagrangians with special Euclidean symmetries involve curvature, torsion, and
arc length. Expressions in these, in the original coordinates, are highly
complex. We show that, by contrast, relatively simple discrete Lagrangians
offer excellent results for the curve completion problem. The methods we
develop for the discrete curve completion problem are general and can be used
to solve other discrete variational problems for B-spline curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1288</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1288</id><created>2010-06-07</created><updated>2011-01-31</updated><authors><author><keyname>Meyer</keyname><forenames>Gilles</forenames></author><author><keyname>Bonnabel</keyname><forenames>Silvere</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author></authors><title>Regression on fixed-rank positive semidefinite matrices: a Riemannian
  approach</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper addresses the problem of learning a regression model parameterized
by a fixed-rank positive semidefinite matrix. The focus is on the nonlinear
nature of the search space and on scalability to high-dimensional problems. The
mathematical developments rely on the theory of gradient descent algorithms
adapted to the Riemannian geometry that underlies the set of fixed-rank
positive semidefinite matrices. In contrast with previous contributions in the
literature, no restrictions are imposed on the range space of the learned
matrix. The resulting algorithms maintain a linear complexity in the problem
size and enjoy important invariance properties. We apply the proposed
algorithms to the problem of learning a distance function parameterized by a
positive semidefinite matrix. Good performance is observed on classical
benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1296</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1296</id><created>2010-06-07</created><authors><author><keyname>Ascasibar</keyname><forenames>Yago</forenames><affiliation>UAM, Spain</affiliation></author></authors><title>Estimating multidimensional probability fields using the Field Estimator
  for Arbitrary Spaces (FiEstAS) with applications to astrophysics</title><categories>astro-ph.IM cs.NA</categories><comments>15 pages, 4 figures, accepted in Comp. Phys. Comm</comments><journal-ref>Computer Physics Communications, Volume 181, Issue 8, August 2010,
  Pages 1438-1443</journal-ref><doi>10.1016/j.cpc.2010.04.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Field Estimator for Arbitrary Spaces (FiEstAS) computes the continuous
probability density field underlying a given discrete data sample in multiple,
non-commensurate dimensions. The algorithm works by constructing a
metric-independent tessellation of the data space based on a recursive binary
splitting. Individual, data-driven bandwidths are assigned to each point,
scaled so that a constant &quot;mass&quot; M0 is enclosed. Kernel density estimation may
then be performed for different kernel shapes, and a combination of balloon and
sample point estimators is proposed as a compromise between resolution and
variance. A bias correction is evaluated for the particular (yet common) case
where the density is computed exactly at the locations of the data points
rather than at an uncorrelated set of locations. By default, the algorithm
combines a top-hat kernel with M0=2.0 with the balloon estimator and applies
the corresponding bias correction. These settings are shown to yield reasonable
results for a simple test case, a two-dimensional ring, that illustrates the
performance for oblique distributions, as well as for a six-dimensional
Hernquist sphere, a fairly realistic model of the dynamical structure of
stellar bulges in galaxies and dark matter haloes in cosmological N-body
simulations. Results for different parameter settings are discussed in order to
provide a guideline to select an optimal configuration in other cases. Source
code is available upon request.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1300</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1300</id><created>2010-06-07</created><updated>2010-12-31</updated><authors><author><keyname>Fox</keyname><forenames>Jacob</forenames></author></authors><title>A new proof of the graph removal lemma</title><categories>math.CO cs.DM</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let H be a fixed graph with h vertices. The graph removal lemma states that
every graph on n vertices with o(n^h) copies of H can be made H-free by
removing o(n^2) edges. We give a new proof which avoids Szemer\'edi's
regularity lemma and gives a better bound. This approach also works to give
improved bounds for the directed and multicolored analogues of the graph
removal lemma. This answers questions of Alon and Gowers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1307</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1307</id><created>2010-06-07</created><authors><author><keyname>Mohanty</keyname><forenames>Sraban Kumar</forenames></author></authors><title>I/O Efficient Algorithms for Matrix Computations</title><categories>cs.DS cs.NA math.NA</categories><msc-class>15A23, 11Y16, 65Y20, 68Q25, 68W40, 68W05</msc-class><acm-class>F.2.1; G.1.0; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse some QR decomposition algorithms, and show that the I/O complexity
of the tile based algorithm is asymptotically the same as that of matrix
multiplication. This algorithm, we show, performs the best when the tile size
is chosen so that exactly one tile fits in the main memory. We propose a
constant factor improvement, as well as a new recursive cache oblivious
algorithm with the same asymptotic I/O complexity. We design Hessenberg,
tridiagonal, and bidiagonal reductions that use banded intermediate forms, and
perform only asymptotically optimal numbers of I/Os; these are the first I/O
optimal algorithms for these problems. In particular, we show that known slab
based algorithms for two sided reductions all have suboptimal asymptotic I/O
performances, even though they have been reported to do better than the
traditional algorithms on the basis of empirical evidence.
  We propose new tile based variants of multishift QR and QZ algorithms that
under certain conditions on the number of shifts, have better seek and I/O
complexities than all known variants.
  We show that techniques like rescheduling of computational steps, appropriate
choosing of the blocking parameters and incorporating of more matrix-matrix
operations, can be used to improve the I/O and seek complexities of matrix
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1309</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1309</id><created>2010-06-07</created><authors><author><keyname>Joshi</keyname><forenames>S. M.</forenames></author><author><keyname>Sanyal</keyname><forenames>S.</forenames></author><author><keyname>Banerjee</keyname><forenames>S.</forenames></author><author><keyname>Srikumar</keyname><forenames>S.</forenames></author></authors><title>Using Grid Files for a Relational Database Management System</title><categories>cs.DB</categories><comments>26 Pages, 5 Figures, 2 tables, This Paper was referred to in the
  seminal Paper by J. Nievergelt, H. Hinterberger,K.C. Sevcik, The Grid File:
  An Adaptable, Symmetric Multikey File Structure ACM Transactions on Database
  Systems (TODS), Volume 9, Issue 1, March, 1984. Pages: 38-71, ISSN:
  0362-5915, as [Reference 12]</comments><report-no>Technical Report No. 11 Technical Report No. 11 Technical Report No
  11, TIFR, INDIA</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes our experience with using Grid files as the main storage
organization for a relational database management system. We primarily focus on
the following two aspects. (i) Strategies for implementing grid files
efficiently. (ii) Methods for efficiency evaluating queries posed to a database
organized using grid files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1315</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1315</id><created>2010-06-07</created><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>Counting dependent and independent strings</title><categories>cs.CC</categories><doi>10.1007/978-3-642-15155-2_60</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper gives estimations for the sizes of the the following sets: (1) the
set of strings that have a given dependency with a fixed string, (2) the set of
strings that are pairwise \alpha independent, (3) the set of strings that are
mutually \alpha independent. The relevant definitions are as follows: C(x) is
the Kolmogorov complexity of the string x. A string y has \alpha -dependency
with a string x if C(y) - C(y|x) \geq \alpha. A set of strings {x_1, \ldots,
x_t} is pairwise \alpha-independent if for all i different from j, C(x_i) -
C(x_i | x_j) \leq \alpha. A tuple of strings (x_1, \ldots, x_t) is mutually
\alpha-independent if C(x_{\pi(1)} \ldots x_{\pi(t)}) \geq C(x_1) + \ldots +
C(x_t) - \alpha, for every permutation \pi of [t].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1328</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1328</id><created>2010-06-07</created><authors><author><keyname>Huang</keyname><forenames>Jonathan</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames></author></authors><title>Uncovering the Riffled Independence Structure of Rankings</title><categories>cs.LG cs.AI stat.AP stat.ML</categories><comments>65 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Representing distributions over permutations can be a daunting task due to
the fact that the number of permutations of $n$ objects scales factorially in
$n$. One recent way that has been used to reduce storage complexity has been to
exploit probabilistic independence, but as we argue, full independence
assumptions impose strong sparsity constraints on distributions and are
unsuitable for modeling rankings. We identify a novel class of independence
structures, called \emph{riffled independence}, encompassing a more expressive
family of distributions while retaining many of the properties necessary for
performing efficient inference and reducing sample complexity. In riffled
independence, one draws two permutations independently, then performs the
\emph{riffle shuffle}, common in card games, to combine the two permutations to
form a single permutation. Within the context of ranking, riffled independence
corresponds to ranking disjoint sets of objects independently, then
interleaving those rankings. In this paper, we provide a formal introduction to
riffled independence and present algorithms for using riffled independence
within Fourier-theoretic frameworks which have been explored by a number of
recent papers. Additionally, we propose an automated method for discovering
sets of items which are riffle independent from a training set of rankings. We
show that our clustering-like algorithms can be used to discover meaningful
latent coalitions from real preference ranking datasets and to learn the
structure of hierarchically decomposable models based on riffled independence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1343</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1343</id><created>2010-06-07</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Ganz</keyname><forenames>Adam</forenames></author></authors><title>Segmentation and Nodal Points in Narrative: Study of Multiple Variations
  of a Ballad</title><categories>cs.CL stat.ML</categories><comments>27 pp., 13 figures. Submitted</comments><acm-class>H.3.1; H.3.2; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lady Maisry ballads afford us a framework within which to segment a
storyline into its major components. Segments and as a consequence nodal points
are discussed for nine different variants of the Lady Maisry story of a (young)
woman being burnt to death by her family, on account of her becoming pregnant
by a foreign personage. We motivate the importance of nodal points in textual
and literary analysis. We show too how the openings of the nine variants can be
analyzed comparatively, and also the conclusions of the ballads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1345</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1345</id><created>2010-06-07</created><authors><author><keyname>Cholvi</keyname><forenames>Vicent</forenames></author><author><keyname>Kowalski</keyname><forenames>Dariusz R.</forenames></author></authors><title>Bounds on Stability and Latency in Wireless Communication</title><categories>cs.NI</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study stability and latency of routing in wireless networks
where it is assumed that no collision will occur. Our approach is inspired by
the adversarial queuing theory, which is amended in order to model wireless
communication. More precisely, there is an adversary that specifies
transmission rates of wireless links and injects data in such a way that an
average number of data injected in a single round and routed through a single
wireless link is at most $r$, for a given $r\in (0,1)$. We also assume that the
additional &quot;burst&quot; of data injected during any time interval and scheduled via
a single link is bounded by a given parameter $b$.
  Under this scenario, we show that the nodes following so called {\em
work-conserving} scheduling policies, not necessarily the same, are guaranteed
stability (i.e., bounded queues) and reasonably small data latency (i.e.,
bounded time on data delivery), for injection rates $r&lt;1/d$, where $d$ is the
maximum length of a routing path. Furthermore, we also show that such a bound
is asymptotically optimal on $d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1346</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1346</id><created>2010-06-07</created><updated>2011-03-04</updated><authors><author><keyname>Sprechmann</keyname><forenames>Pablo</forenames></author><author><keyname>Ram&#xed;rez</keyname><forenames>Ignacio</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina</forenames></author></authors><title>C-HiLasso: A Collaborative Hierarchical Sparse Modeling Framework</title><categories>stat.ML cs.CV</categories><doi>10.1109/TSP.2011.2157912</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse modeling is a powerful framework for data analysis and processing.
Traditionally, encoding in this framework is performed by solving an
L1-regularized linear regression problem, commonly referred to as Lasso or
Basis Pursuit. In this work we combine the sparsity-inducing property of the
Lasso model at the individual feature level, with the block-sparsity property
of the Group Lasso model, where sparse groups of features are jointly encoded,
obtaining a sparsity pattern hierarchically structured. This results in the
Hierarchical Lasso (HiLasso), which shows important practical modeling
advantages. We then extend this approach to the collaborative case, where a set
of simultaneously coded signals share the same sparsity pattern at the higher
(group) level, but not necessarily at the lower (inside the group) level,
obtaining the collaborative HiLasso model (C-HiLasso). Such signals then share
the same active groups, or classes, but not necessarily the same active set.
This model is very well suited for applications such as source identification
and separation. An efficient optimization procedure, which guarantees
convergence to the global optimum, is developed for these new models. The
underlying presentation of the new framework and optimization approach is
complemented with experimental examples and theoretical results regarding
recovery guarantees for the proposed models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1377</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1377</id><created>2010-06-07</created><authors><author><keyname>Gong</keyname><forenames>Xiaowen</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Tellambura</keyname><forenames>Chintha</forenames></author></authors><title>Joint Bandwidth and Power Allocation with Admission Control in Wireless
  Multi-User Networks With and Without Relaying</title><categories>cs.IT math.IT</categories><comments>30 pages, 5 figures, submitted to IEEE Trans. Signal Processing in
  June 2010</comments><journal-ref>X. Gong, S.A. Vorobyov, and C. Tellambura, &quot;Joint bandwidth and
  power allocation with admission control in wireless multi-user networks with
  and without relaying,&quot; IEEE Trans. Signal Processing, vol. 59, no. 4, pp.
  1801-1813, Apr. 2011</journal-ref><doi>10.1109/TSP.2010.2104146</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equal allocation of bandwidth and/or power may not be efficient for wireless
multi-user networks with limited bandwidth and power resources. Joint bandwidth
and power allocation strategies for wireless multi-user networks with and
without relaying are proposed in this paper for (i) the maximization of the sum
capacity of all users; (ii) the maximization of the worst user capacity; and
(iii) the minimization of the total power consumption of all users. It is shown
that the proposed allocation problems are convex and, therefore, can be solved
efficiently. Moreover, the admission control based joint bandwidth and power
allocation is considered. A suboptimal greedy search algorithm is developed to
solve the admission control problem efficiently. The conditions under which the
greedy search is optimal are derived and shown to be mild. The performance
improvements offered by the proposed joint bandwidth and power allocation are
demonstrated by simulations. The advantages of the suboptimal greedy search
algorithm for admission control are also shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1380</identifier>
 <datestamp>2013-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1380</id><created>2010-06-07</created><authors><author><keyname>Chen</keyname><forenames>Zengmao</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Wang</keyname><forenames>Cheng-Xiang</forenames></author><author><keyname>Thompson</keyname><forenames>John</forenames></author></authors><title>Pareto Region Characterization for Rate Control in Multi-User Systems
  and Nash Bargaining</title><categories>cs.GT cs.IT math.IT</categories><comments>31 pages, 9 figures, submitted to IEEE Trans. Automatic Control in
  Dec. 2009</comments><journal-ref>Z. Chen, S.A. Vorobyov, C.-X. Wang, and J. Thompson, &quot;Pareto
  region characterization for rate control in MIMO interference systems and
  Nash bargaining,&quot; IEEE Trans. Automatic Control, vol. 57, no. 12, pp.
  3203-3208, Dec. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of rate control in multi-user multiple-input multiple-output
(MIMO) interference systems is formulated as a multicriteria optimization (MCO)
problem. The Pareto rate region of the MCO problem is characterized. It is
shown that for the convexity of the Pareto rate region it is sufficient that
the interference-plus-noise covariance matrices (INCMs) of multiple users with
conflicting objectives approach identity matrix. The latter can be achieved by
using either orthogonal signaling, time-sharing, or interference cancellation
strategies. In the case of high interference, the interference cancellation is
preferable in order to increase the Pareto boundary and guarantee the convexity
of the Pareto rate region. The Nash bargaining (NB) is applied to transform the
MCO problem into a single-objective one. The characteristics of the NB over
MIMO interference systems such as the uniqueness, existence of the NB solution,
and feasibility of the NB set are investigated. When the NB solution exists,
the sufficient condition for the corresponding single-objective problem to have
a unique solution is that the INCMs of users approach identity matrix. A simple
multi-stage interference cancellation scheme, which leads to a larger convex
Pareto rate region and, correspondingly, a unique NB solution with larger user
rates compared to the orthogonal and time-sharing signaling schemes, is
proposed. The convexity of the rate region, effectiveness of the proposed
interference cancellation technique, and existence of the NB solution for MIMO
interference systems are examined by means of numerical studies. The fairness
of the NB solution is also demonstrated. Finally, the special cases of
multi-input single-output (MISO) and single-input single-output (SISO)
interference systems are also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1382</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1382</id><created>2010-06-07</created><authors><author><keyname>Fozunbal</keyname><forenames>Majid</forenames></author></authors><title>On Regret of Parametric Mismatch in Minimum Mean Square Error Estimation</title><categories>cs.IT math.IT</categories><comments>5 Pages, 2 figures, International Symposium on Information Theory
  (ISIT), June 2010</comments><report-no>HPL-2010-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the effect of parametric mismatch in minimum mean square
error (MMSE) estimation. In particular, we consider the problem of estimating
the input signal from the output of an additive white Gaussian channel whose
gain is fixed, but unknown. The input distribution is known, and the estimation
process consists of two algorithms. First, a channel estimator blindly
estimates the channel gain using past observations. Second, a mismatched MMSE
estimator, optimized for the estimated channel gain, estimates the input
signal. We analyze the regret, i.e., the additional mean square error, that is
raised in this process. We derive upper-bounds on both absolute and relative
regrets. Bounds are expressed in terms of the Fisher information. We also study
regret for unbiased, efficient channel estimators, and derive a simple
trade-off between Fisher information and relative regret. This trade-off shows
that the product of a certain function of relative regret and Fisher
information equals the signal-to-noise ratio, independent of the input
distribution. The trade-off relation implies that higher Fisher information
results to smaller expected relative regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1383</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1383</id><created>2010-06-07</created><updated>2010-11-10</updated><authors><author><keyname>Talari</keyname><forenames>Ali</forenames></author><author><keyname>Shahrasbi</keyname><forenames>Behzad</forenames></author><author><keyname>Rahnavard</keyname><forenames>Nazanin</forenames></author></authors><title>Efficient Symbol Sorting for High Intermediate Recovery Rate of LT Codes</title><categories>cs.IT math.IT</categories><comments>2010 IEEE International Symposium on Information Theory (ISIT 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LT codes are modern and efficient rateless forward error correction (FEC)
codes with close to channel capacity performance. Nevertheless, in intermediate
range where the number of received encoded symbols is less than the number of
source symbols, LT codes have very low recovery rates.
  In this paper, we propose a novel algorithm which significantly increases the
intermediate recovery rate of LT codes, while it preserves the codes' close to
channel capacity performance. To increase the intermediate recovery rate, our
proposed algorithm rearranges the transmission order of the encoded symbols
exploiting their structure, their transmission history, and an estimate of the
channel's erasure rate. We implement our algorithm for conventional LT codes,
and numerically evaluate its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1401</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1401</id><created>2010-06-07</created><updated>2010-07-20</updated><authors><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Shi</keyname><forenames>Weisong</forenames></author><author><keyname>Gong</keyname><forenames>Shimin</forenames></author><author><keyname>Zang</keyname><forenames>Xiutao</forenames></author></authors><title>PhoenixCloud: Provisioning Resources for Heterogeneous Workloads in
  Cloud Computing</title><categories>cs.DC</categories><comments>18 pages. This is an extended version of our CCA 08 paper(The First
  Workshop of Cloud Computing and its Application, CCA08, Chicago, 2008): J.
  Zhan L. Wang, B. Tu, Y. Li, P. Wang, W. Zhou, D. Meng. 2008. Phoenix Cloud:
  Consolidating Different Computing Loads on Shared Cluster System for Large
  Organization. The modified version can be found on
  http://arxiv.org/abs/0906.1346</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As more and more service providers choose Cloud platforms, which is provided
by third party resource providers, resource providers needs to provision
resources for heterogeneous workloads in different Cloud scenarios. Taking into
account the dramatic differences of heterogeneous workloads, can we
coordinately provision resources for heterogeneous workloads in Cloud
computing? In this paper we focus on this important issue, which is
investigated by few previous work. Our contributions are threefold: (1) we
respectively propose a coordinated resource provisioning solution for
heterogeneous workloads in two typical Cloud scenarios: first, a large
organization operates a private Cloud for two heterogeneous workloads; second,
a large organization or two service providers running heterogeneous workloads
revert to a public Cloud; (2) we build an agile system PhoenixCloud that
enables a resource provider to create coordinated runtime environments on
demand for heterogeneous workloads when they are consolidated on a Cloud site;
and (3) A comprehensive evaluation has been performed in experiments. For two
typical heterogeneous workload traces: parallel batch jobs and Web services,
our experiments show that: a) in a private Cloud scenario, when the throughput
is almost same like that of a dedicated cluster system, our solution decreases
the configuration size of a cluster by about 40%; b) in a public Cloud
scenario, our solution decreases not only the total resource consumption, but
also the peak resource consumption maximally to 31% with respect to that of EC2
+RightScale solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1402</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1402</id><created>2010-06-07</created><authors><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Zielonka</keyname><forenames>Wies&#x142;aw</forenames><affiliation>Liafa</affiliation></author></authors><title>Blackwell-Optimal Strategies in Priority Mean-Payoff Games</title><categories>cs.GT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 7-21</journal-ref><doi>10.4204/EPTCS.25.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine perfect information stochastic mean-payoff games - a class of
games containing as special sub-classes the usual mean-payoff games and parity
games. We show that deterministic memoryless strategies that are optimal for
discounted games with state-dependent discount factors close to 1 are optimal
for priority mean-payoff games establishing a strong link between these two
classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1403</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1403</id><created>2010-06-07</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames><affiliation>IST Austria</affiliation></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames><affiliation>UCLA</affiliation></author></authors><title>Discounting in Games across Time Scales</title><categories>cs.LO cs.GT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 22-29</journal-ref><doi>10.4204/EPTCS.25.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two-level discounted games played by two players on a
perfect-information stochastic game graph. The upper level game is a discounted
game and the lower level game is an undiscounted reachability game. Two-level
games model hierarchical and sequential decision making under uncertainty
across different time scales. We show the existence of pure memoryless optimal
strategies for both players and an ordered field property for such games. We
show that if there is only one player (Markov decision processes), then the
values can be computed in polynomial time. It follows that whether the value of
a player is equal to a given rational constant in two-level discounted games
can be decided in NP intersected coNP. We also give an alternate strategy
improvement algorithm to compute the value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1404</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1404</id><created>2010-06-07</created><authors><author><keyname>Cristau</keyname><forenames>Julien</forenames><affiliation>LIAFA, CNRS &amp; Universit&#xe9; Paris 7</affiliation></author><author><keyname>David</keyname><forenames>Claire</forenames><affiliation>LFCS, University of Edinburgh</affiliation></author><author><keyname>Horn</keyname><forenames>Florian</forenames><affiliation>LIAFA, CNRS &amp; Universit&#xe9; Paris 7</affiliation></author></authors><title>How do we remember the past in randomised strategies?</title><categories>cs.GT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 30-39</journal-ref><doi>10.4204/EPTCS.25.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph games of infinite length are a natural model for open reactive
processes: one player represents the controller, trying to ensure a given
specification, and the other represents a hostile environment. The evolution of
the system depends on the decisions of both players, supplemented by chance.
  In this work, we focus on the notion of randomised strategy. More
specifically, we show that three natural definitions may lead to very different
results: in the most general cases, an almost-surely winning situation may
become almost-surely losing if the player is only allowed to use a weaker
notion of strategy. In more reasonable settings, translations exist, but they
require infinite memory, even in simple cases. Finally, some traditional
problems becomes undecidable for the strongest type of strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1405</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1405</id><created>2010-06-07</created><authors><author><keyname>Brim</keyname><forenames>Lubo&#x161;</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Chaloupka</keyname><forenames>Jakub</forenames><affiliation>Masaryk University</affiliation></author></authors><title>Using Strategy Improvement to Stay Alive</title><categories>cs.GT cs.DS</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 40-54</journal-ref><doi>10.4204/EPTCS.25.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a novel algorithm for solving Mean-Payoff Games (MPGs). Besides
solving an MPG in the usual sense, our algorithm computes more information
about the game, information that is important with respect to applications. The
weights of the edges of an MPG can be thought of as a gained/consumed energy --
depending on the sign. For each vertex, our algorithm computes the minimum
amount of initial energy that is sufficient for player Max to ensure that in a
play starting from the vertex, the energy level never goes below zero. Our
algorithm is not the first algorithm that computes the minimum sufficient
initial energies, but according to our experimental study it is the fastest
algorithm that computes them. The reason is that it utilizes the strategy
improvement technique which is very efficient in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1406</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1406</id><created>2010-06-07</created><authors><author><keyname>D'Agostino</keyname><forenames>Giovanna</forenames><affiliation>University of Udine, Italy</affiliation></author><author><keyname>Lenzi</keyname><forenames>Giacomo</forenames><affiliation>University of Salerno, Italy</affiliation></author></authors><title>On Modal {\mu}-Calculus over Finite Graphs with Bounded Strongly
  Connected Components</title><categories>cs.LO cs.FL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 55-71</journal-ref><doi>10.4204/EPTCS.25.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every positive integer k we consider the class SCCk of all finite graphs
whose strongly connected components have size at most k. We show that for every
k, the Modal mu-Calculus fixpoint hierarchy on SCCk collapses to the level
Delta2, but not to Comp(Sigma1,Pi1) (compositions of formulas of level Sigma1
and Pi1). This contrasts with the class of all graphs, where
Delta2=Comp(Sigma1,Pi1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1407</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1407</id><created>2010-06-07</created><authors><author><keyname>Bresolin</keyname><forenames>Davide</forenames><affiliation>University of Verona, Verona, Italy</affiliation></author><author><keyname>Sala</keyname><forenames>Pietro</forenames><affiliation>University of Verona, Verona, Italy</affiliation></author><author><keyname>Sciavicco</keyname><forenames>Guido</forenames><affiliation>University of Murcia, Murcia, Spain</affiliation></author></authors><title>Begin, After, and Later: a Maximal Decidable Interval Temporal Logic</title><categories>cs.LO cs.AI</categories><proxy>EPTCS</proxy><acm-class>F.4.1;F4.3;</acm-class><journal-ref>EPTCS 25, 2010, pp. 72-88</journal-ref><doi>10.4204/EPTCS.25.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interval temporal logics (ITLs) are logics for reasoning about temporal
statements expressed over intervals, i.e., periods of time. The most famous ITL
studied so far is Halpern and Shoham's HS, which is the logic of the thirteen
Allen's interval relations. Unfortunately, HS and most of its fragments have an
undecidable satisfiability problem. This discouraged the research in this area
until recently, when a number non-trivial decidable ITLs have been discovered.
  This paper is a contribution towards the complete classification of all
different fragments of HS. We consider different combinations of the interval
relations Begins, After, Later and their inverses Abar, Bbar, and Lbar. We know
from previous works that the combination ABBbarAbar is decidable only when
finite domains are considered (and undecidable elsewhere), and that ABBbar is
decidable over the natural numbers. We extend these results by showing that
decidability of ABBar can be further extended to capture the language
ABBbarLbar, which lays in between ABBar and ABBbarAbar, and that turns out to
be maximal w.r.t decidability over strongly discrete linear orders (e.g. finite
orders, the naturals, the integers). We also prove that the proposed decision
procedure is optimal with respect to the complexity class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1408</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1408</id><created>2010-06-07</created><authors><author><keyname>Morgenstern</keyname><forenames>Andreas</forenames><affiliation>University Kaiserslautern</affiliation></author><author><keyname>Schneider</keyname><forenames>Klaus</forenames><affiliation>University Kaiserslautern</affiliation></author></authors><title>Exploiting the Temporal Logic Hierarchy and the Non-Confluence Property
  for Efficient LTL Synthesis</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 89-102</journal-ref><doi>10.4204/EPTCS.25.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classic approaches to synthesize a reactive system from a linear temporal
logic (LTL) specification first translate the given LTL formula to an
equivalent omega-automaton and then compute a winning strategy for the
corresponding omega-regular game. To this end, the obtained omega-automata have
to be (pseudo)-determinized where typically a variant of Safra's
determinization procedure is used. In this paper, we show that this
determinization step can be significantly improved for tool implementations by
replacing Safra's determinization by simpler determinization procedures. In
particular, we exploit (1) the temporal logic hierarchy that corresponds to the
well-known automata hierarchy consisting of safety, liveness, Buechi, and
co-Buechi automata as well as their boolean closures, (2) the non-confluence
property of omega-automata that result from certain translations of LTL
formulas, and (3) symbolic implementations of determinization procedures for
the Rabin-Scott and the Miyano-Hayashi breakpoint construction. In particular,
we present convincing experimental results that demonstrate the practical
applicability of our new synthesis procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1409</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1409</id><created>2010-06-07</created><authors><author><keyname>Friedmann</keyname><forenames>Oliver</forenames><affiliation>University of Munich</affiliation></author><author><keyname>Lange</keyname><forenames>Martin</forenames><affiliation>University of Kassel</affiliation></author></authors><title>Local Strategy Improvement for Parity Game Solving</title><categories>cs.GT cs.CC cs.DS cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 118-131</journal-ref><doi>10.4204/EPTCS.25.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of solving a parity game is at the core of many problems in model
checking, satisfiability checking and program synthesis. Some of the best
algorithms for solving parity game are strategy improvement algorithms. These
are global in nature since they require the entire parity game to be present at
the beginning. This is a distinct disadvantage because in many applications one
only needs to know which winning region a particular node belongs to, and a
witnessing winning strategy may cover only a fractional part of the entire game
graph.
  We present a local strategy improvement algorithm which explores the game
graph on-the-fly whilst performing the improvement steps. We also compare it
empirically with existing global strategy improvement algorithms and the
currently only other local algorithm for solving parity games. It turns out
that local strategy improvement can outperform these others by several orders
of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1410</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1410</id><created>2010-06-07</created><authors><author><keyname>Fearnley</keyname><forenames>John</forenames><affiliation>University of Warwick</affiliation></author><author><keyname>Zimmermann</keyname><forenames>Martin</forenames><affiliation>RWTH Aachen University</affiliation></author></authors><title>Playing Muller Games in a Hurry</title><categories>cs.GT cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 146-161</journal-ref><doi>10.4204/EPTCS.25.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the following question: can plays in a Muller game be
stopped after a finite number of moves and a winner be declared. A criterion to
do this is sound if Player 0 wins an infinite-duration Muller game if and only
if she wins the finite-duration version. A sound criterion is presented that
stops a play after at most 3^n moves, where n is the size of the arena. This
improves the bound (n!+1)^n obtained by McNaughton and the bound n!+1 derived
from a reduction to parity games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1411</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1411</id><created>2010-06-07</created><authors><author><keyname>Fial&#xed;k</keyname><forenames>Ivan</forenames></author></authors><title>Unitary Noise and the Mermin-GHZ Game</title><categories>quant-ph cs.CC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 188-198</journal-ref><doi>10.4204/EPTCS.25.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication complexity is an area of classical computer science which
studies how much communication is necessary to solve various distributed
computational problems. Quantum information processing can be used to reduce
the amount of communication required to carry out some distributed problems. We
speak of pseudo-telepathy when it is able to completely eliminate the need for
communication. Since it is generally very hard to perfectly implement a quantum
winning strategy for a pseudo-telepathy game, quantum players are almost
certain to make errors even though they use a winning strategy. After
introducing a model for pseudo-telepathy games, we investigate the impact of
erroneously performed unitary transformations on the quantum winning strategy
for the Mermin-GHZ game. The question of how strong the unitary noise can be so
that quantum players would still be better than classical ones is also dealt
with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1412</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1412</id><created>2010-06-07</created><authors><author><keyname>Bernardo</keyname><forenames>Marco</forenames><affiliation>University of Urbino</affiliation></author></authors><title>On the Expressiveness of Markovian Process Calculi with Durational and
  Durationless Actions</title><categories>cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.4.3</acm-class><journal-ref>EPTCS 25, 2010, pp. 199-213</journal-ref><doi>10.4204/EPTCS.25.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several Markovian process calculi have been proposed in the literature, which
differ from each other for various aspects. With regard to the action
representation, we distinguish between integrated-time Markovian process
calculi, in which every action has an exponentially distributed duration
associated with it, and orthogonal-time Markovian process calculi, in which
action execution is separated from time passing. Similar to deterministically
timed process calculi, we show that these two options are not irreconcilable by
exhibiting three mappings from an integrated-time Markovian process calculus to
an orthogonal-time Markovian process calculus that preserve the behavioral
equivalence of process terms under different interpretations of action
execution: eagerness, laziness, and maximal progress. The mappings are limited
to classes of process terms of the integrated-time Markovian process calculus
with restrictions on parallel composition and do not involve the full
capability of the orthogonal-time Markovian process calculus of expressing
nondeterministic choices, thus elucidating the only two important differences
between the two calculi: their synchronization disciplines and their ways of
solving choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1413</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1413</id><created>2010-06-07</created><authors><author><keyname>Ancona</keyname><forenames>Davide</forenames><affiliation>DISI - University of Genova</affiliation></author><author><keyname>Lagorio</keyname><forenames>Giovanni</forenames><affiliation>DISI - University of Genova</affiliation></author></authors><title>Coinductive subtyping for abstract compilation of object-oriented
  languages into Horn formulas</title><categories>cs.PL cs.LO</categories><proxy>EPTCS</proxy><acm-class>D.3.1;F.3.2</acm-class><journal-ref>EPTCS 25, 2010, pp. 214-230</journal-ref><doi>10.4204/EPTCS.25.20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent work we have shown how it is possible to define very precise type
systems for object-oriented languages by abstractly compiling a program into a
Horn formula f. Then type inference amounts to resolving a certain goal w.r.t.
the coinductive (that is, the greatest) Herbrand model of f.
  Type systems defined in this way are idealized, since in the most interesting
instantiations both the terms of the coinductive Herbrand universe and goal
derivations cannot be finitely represented. However, sound and quite expressive
approximations can be implemented by considering only regular terms and
derivations. In doing so, it is essential to introduce a proper subtyping
relation formalizing the notion of approximation between types.
  In this paper we study a subtyping relation on coinductive terms built on
union and object type constructors. We define an interpretation of types as set
of values induced by a quite intuitive relation of membership of values to
types, and prove that the definition of subtyping is sound w.r.t. subset
inclusion between type interpretations. The proof of soundness has allowed us
to simplify the notion of contractive derivation and to discover that the
previously given definition of subtyping did not cover all possible
representations of the empty type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1414</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1414</id><created>2010-06-07</created><authors><author><keyname>Dima</keyname><forenames>C&#x103;t&#x103;lin</forenames><affiliation>LACL, Universit&#xe9; Paris-Est Cr&#xe9;teil</affiliation></author><author><keyname>Enea</keyname><forenames>Constantin</forenames><affiliation>LIAFA, CNRS UMR 7089, Universit&#xe9; Paris Diderot - Paris 7</affiliation></author><author><keyname>Guelev</keyname><forenames>Dimitar</forenames><affiliation>Section of Logic, Institute of Mathematics and Informatics, Bulgarian Academy of Sciences</affiliation></author></authors><title>Model-Checking an Alternating-time Temporal Logic with Knowledge,
  Imperfect Information, Perfect Recall and Communicating Coalitions</title><categories>cs.LO cs.MA</categories><proxy>EPTCS</proxy><acm-class>D.2.4</acm-class><journal-ref>EPTCS 25, 2010, pp. 103-117</journal-ref><doi>10.4204/EPTCS.25.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a variant of ATL with distributed knowledge operators based on a
synchronous and perfect recall semantics. The coalition modalities in this
logic are based on partial observation of the full history, and incorporate a
form of cooperation between members of the coalition in which agents issue
their actions based on the distributed knowledge, for that coalition, of the
system history. We show that model-checking is decidable for this logic. The
technique utilizes two variants of games with imperfect information and
partially observable objectives, as well as a subset construction for
identifying states whose histories are indistinguishable to the considered
coalition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1415</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1415</id><created>2010-06-07</created><authors><author><keyname>Fridman</keyname><forenames>Wladimir</forenames><affiliation>RWTH Aachen University</affiliation></author></authors><title>Formats of Winning Strategies for Six Types of Pushdown Games</title><categories>cs.GT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 132-145</journal-ref><doi>10.4204/EPTCS.25.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The solution of parity games over pushdown graphs (Walukiewicz '96) was the
first step towards an effective theory of infinite-state games. It was shown
that winning strategies for pushdown games can be implemented again as pushdown
automata. We continue this study and investigate the connection between game
presentations and winning strategies in altogether six cases of game arenas,
among them realtime pushdown systems, visibly pushdown systems, and counter
systems. In four cases we show by a uniform proof method that we obtain
strategies implementable by the same type of pushdown machine as given in the
game arena. We prove that for the two remaining cases this correspondence
fails. In the conclusion we address the question of an abstract criterion that
explains the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1416</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1416</id><created>2010-06-07</created><authors><author><keyname>Appold</keyname><forenames>Christian</forenames></author></authors><title>Efficient Symmetry Reduction and the Use of State Symmetries for
  Symbolic Model Checking</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 173-187</journal-ref><doi>10.4204/EPTCS.25.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One technique to reduce the state-space explosion problem in temporal logic
model checking is symmetry reduction. The combination of symmetry reduction and
symbolic model checking by using BDDs suffered a long time from the
prohibitively large BDD for the orbit relation. Dynamic symmetry reduction
calculates representatives of equivalence classes of states dynamically and
thus avoids the construction of the orbit relation. In this paper, we present a
new efficient model checking algorithm based on dynamic symmetry reduction. Our
experiments show that the algorithm is very fast and allows the verification of
larger systems. We additionally implemented the use of state symmetries for
symbolic symmetry reduction. To our knowledge we are the first who investigated
state symmetries in combination with BDD based symbolic model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1419</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1419</id><created>2010-06-07</created><authors><author><keyname>Abbott</keyname><forenames>Alastair A.</forenames><affiliation>UoA</affiliation></author><author><keyname>Calude</keyname><forenames>Cristian S.</forenames><affiliation>UoA</affiliation></author></authors><title>Understanding the Quantum Computational Speed-up via De-quantisation</title><categories>quant-ph cs.CC</categories><proxy>EPTCS</proxy><acm-class>F.1.2</acm-class><journal-ref>EPTCS 26, 2010, pp. 1-12</journal-ref><doi>10.4204/EPTCS.26.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While it seems possible that quantum computers may allow for algorithms
offering a computational speed-up over classical algorithms for some problems,
the issue is poorly understood. We explore this computational speed-up by
investigating the ability to de-quantise quantum algorithms into classical
simulations of the algorithms which are as efficient in both time and space as
the original quantum algorithms.
  The process of de-quantisation helps formulate conditions to determine if a
quantum algorithm provides a real speed-up over classical algorithms. These
conditions can be used to develop new quantum algorithms more effectively (by
avoiding features that could allow the algorithm to be efficiently classically
simulated), as well as providing the potential to create new classical
algorithms (by using features which have proved valuable for quantum
algorithms).
  Results on many different methods of de-quantisations are presented, as well
as a general formal definition of de-quantisation. De-quantisations employing
higher-dimensional classical bits, as well as those using matrix-simulations,
put emphasis on entanglement in quantum algorithms; a key result is that any
algorithm in which the entanglement is bounded is de-quantisable. These methods
are contrasted with the stabiliser formalism de-quantisations due to the
Gottesman-Knill Theorem, as well as those which take advantage of the topology
of the circuit for a quantum algorithm.
  The benefits of the different methods are contrasted, and the importance of a
range of techniques is emphasised. We further discuss some features of quantum
algorithms which current de-quantisation methods do not cover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1420</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1420</id><created>2010-06-07</created><authors><author><keyname>Anders</keyname><forenames>Janet</forenames></author><author><keyname>Shabbir</keyname><forenames>Saroosh</forenames></author><author><keyname>Hilt</keyname><forenames>Stefanie</forenames></author><author><keyname>Lutz</keyname><forenames>Eric</forenames></author></authors><title>Landauer's principle in the quantum domain</title><categories>quant-ph cs.IT math.IT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 13-18</journal-ref><doi>10.4204/EPTCS.26.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent papers discussing thermodynamic processes in strongly coupled quantum
systems claim a violation of Landauer's principle and imply a violation of the
second law of thermodynamics. If true, this would have powerful consequences.
Perpetuum mobiles could be build as long as the operating temperature is
brought close to zero. It would also have serious consequences on thermodynamic
derivations of information theoretic results, such as the Holevo bound. Here we
argue why these claims are erroneous. Correlations occurring in the strongly
coupled, quantum domain require a rethink of how entropy, heat and work are
calculated. It is shown that a consistent treatment solves the paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1422</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1422</id><created>2010-06-07</created><authors><author><keyname>Bayat</keyname><forenames>Abolfazl</forenames><affiliation>Department of Physics and Astronomy, University College London, Gower St., London WC1E 6BT, UK</affiliation></author><author><keyname>Sodano</keyname><forenames>Pasquale</forenames><affiliation>Dipartimento di Fisica e Sezione I.N.F.N., Universit&#xe0; di Perugia, Via A. Pascoli, Perugia, 06123, Italy</affiliation></author><author><keyname>Bose</keyname><forenames>Sougato</forenames><affiliation>Department of Physics and Astronomy, University College London, Gower St., London WC1E 6BT, UK</affiliation></author></authors><title>Engineering Long Range Distance Independent Entanglement through Kondo
  Impurities in Spin Chains</title><categories>quant-ph cs.IT math.IT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 33-46</journal-ref><doi>10.4204/EPTCS.26.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the entanglement properties of the Kondo spin chain when it is
prepared in its ground state as well as its dynamics following a single bond
quench. We show that a true measure of entanglement such as negativity enables
to characterize the unique features of the gapless Kondo regime. We determine
the spatial extent of the Kondo screening cloud and propose an ansatz for the
ground state in the Kondo regime accessible to this spin chain; we also
demonstrate that the impurity spin is indeed maximally entangled with the Kondo
cloud. We exploit these features of the entanglement in the gapless Kondo
regime to show that a single local quench at one end of a Kondo spin chain may
always induce a fast and long lived oscillatory dynamics, which establishes a
high quality entanglement between the individual spins at the opposite ends of
the chain. This entanglement is a footprint of the presence of the Kondo cloud
and may be engineered so as to attain - even for very large chains- a constant
high value independent of the length; in addition, it is thermally robust. To
better evidence the remarkable peculiarities of the Kondo regime, we carry a
parallel analysis of the entanglement properties of the Kondo spin chain model
in the gapped dimerised regime where these remarkable features are absent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1423</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1423</id><created>2010-06-07</created><authors><author><keyname>Floess</keyname><forenames>Dominik F.</forenames></author><author><keyname>Andersson</keyname><forenames>Erika</forenames></author><author><keyname>Hillery</keyname><forenames>Mark</forenames></author></authors><title>Quantum algorithms for testing Boolean functions</title><categories>quant-ph cs.CC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 101-108</journal-ref><doi>10.4204/EPTCS.26.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss quantum algorithms, based on the Bernstein-Vazirani algorithm, for
finding which variables a Boolean function depends on. There are 2^n possible
linear Boolean functions of n variables; given a linear Boolean function, the
Bernstein-Vazirani quantum algorithm can deterministically identify which one
of these Boolean functions we are given using just one single function query.
The same quantum algorithm can also be used to learn which input variables
other types of Boolean functions depend on, with a success probability that
depends on the form of the Boolean function that is tested, but does not depend
on the total number of input variables. We also outline a procedure to futher
amplify the success probability, based on another quantum algorithm, the Grover
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1424</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1424</id><created>2010-06-07</created><authors><author><keyname>Markham</keyname><forenames>Damian</forenames></author><author><keyname>Anders</keyname><forenames>Janet</forenames></author><author><keyname>Hajdu&#x161;ek</keyname><forenames>Michal</forenames></author><author><keyname>Vedral</keyname><forenames>Vlatko</forenames></author></authors><title>Measurement Based Quantum Computation on Fractal Lattices</title><categories>quant-ph cs.DC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 109-115</journal-ref><doi>10.4204/EPTCS.26.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we extend on work which establishes an analology between
one-way quantum computation and thermodynamics to see how the former can be
performed on fractal lattices. We find fractals lattices of arbitrary dimension
greater than one which do all act as good resources for one-way quantum
computation, and sets of fractal lattices with dimension greater than one all
of which do not. The difference is put down to other topological factors such
as ramification and connectivity. This work adds confidence to the analogy and
highlights new features to what we require for universal resources for one-way
quantum computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1426</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1426</id><created>2010-06-07</created><authors><author><keyname>Soeda</keyname><forenames>Akihito</forenames></author><author><keyname>Murao</keyname><forenames>Mio</forenames></author></authors><title>Classification of delocalization power of global unitary operations in
  terms of LOCC one-piece relocalization</title><categories>quant-ph cs.IT math.IT</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 117-126</journal-ref><doi>10.4204/EPTCS.26.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study how two pieces of localized quantum information can be delocalized
across a composite Hilbert space when a global unitary operation is applied. We
classify the delocalization power of global unitary operations on quantum
information by investigating the possibility of relocalizing one piece of the
quantum information without using any global quantum resource. We show that
one-piece relocalization is possible if and only if the global unitary
operation is local unitary equivalent of a controlled-unitary operation. The
delocalization power turns out to reveal different aspect of the non-local
properties of global unitary operations characterized by their entangling
power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1428</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1428</id><created>2010-06-07</created><authors><author><keyname>Bartha</keyname><forenames>Mikl&#xf3;s</forenames><affiliation>Memorial University of Newfoundland</affiliation></author></authors><title>Turing Automata and Graph Machines</title><categories>cs.FL cs.DM</categories><proxy>EPTCS</proxy><acm-class>F.1.1;G.2.2</acm-class><journal-ref>EPTCS 26, 2010, pp. 19-31</journal-ref><doi>10.4204/EPTCS.26.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indexed monoidal algebras are introduced as an equivalent structure for
self-dual compact closed categories, and a coherence theorem is proved for the
category of such algebras. Turing automata and Turing graph machines are
defined by generalizing the classical Turing machine concept, so that the
collection of such machines becomes an indexed monoidal algebra. On the analogy
of the von Neumann data-flow computer architecture, Turing graph machines are
proposed as potentially reversible low-level universal computational devices,
and a truly reversible molecular size hardware model is presented as an
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1429</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1429</id><created>2010-06-07</created><authors><author><keyname>Cheney</keyname><forenames>James</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>Causality and the Semantics of Provenance</title><categories>cs.LO cs.DB</categories><proxy>EPTCS</proxy><acm-class>D.3.1, F.3.2</acm-class><journal-ref>EPTCS 26, 2010, pp. 63-74</journal-ref><doi>10.4204/EPTCS.26.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Provenance, or information about the sources, derivation, custody or history
of data, has been studied recently in a number of contexts, including
databases, scientific workflows and the Semantic Web. Many provenance
mechanisms have been developed, motivated by informal notions such as
influence, dependence, explanation and causality. However, there has been
little study of whether these mechanisms formally satisfy appropriate policies
or even how to formalize relevant motivating concepts such as causality. We
contend that mathematical models of these concepts are needed to justify and
compare provenance techniques. In this paper we review a theory of causality
based on structural models that has been developed in artificial intelligence,
and describe work in progress on using causality to give a semantics to
provenance graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1430</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1430</id><created>2010-06-07</created><authors><author><keyname>Danos</keyname><forenames>Vincent</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Oury</keyname><forenames>Nicolas</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>Equilibrium and Termination</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 75-84</journal-ref><doi>10.4204/EPTCS.26.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a reduction of the termination problem for a Turing machine (in
the simplified form of the Post correspondence problem) to the problem of
determining whether a continuous-time Markov chain presented as a set of Kappa
graph-rewriting rules has an equilibrium. It follows that the problem of
whether a computable CTMC is dissipative (ie does not have an equilibrium) is
undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1431</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1431</id><created>2010-06-07</created><authors><author><keyname>Dunjko</keyname><forenames>Vedran</forenames></author><author><keyname>Kashefi</keyname><forenames>Elham</forenames></author></authors><title>Algebraic characterisation of one-way patterns</title><categories>cs.DS</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 85-100</journal-ref><doi>10.4204/EPTCS.26.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a complete structural characterisation of the map the positive branch
of a one-way pattern implements. We start with the representation of the
positive branch in terms of the phase map decomposition, which is then further
analysed to obtain the primary structure of the matrix M, representing the
phase map decomposition in the computational basis. Using this approach we
obtain some preliminary results on the connection between the columns structure
of a given unitary and the angles of measurements in a pattern that implements
it. We believe this work is a step forward towards a full characterisation of
those unitaries with an efficient one-way model implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1432</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1432</id><created>2010-06-07</created><authors><author><keyname>Spitters</keyname><forenames>Bas</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>The space of measurement outcomes as a spectrum for non-commutative
  algebras</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 127-133</journal-ref><doi>10.4204/EPTCS.26.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bohrification defines a locale of hidden variables internal in a topos. We
find that externally this is the space of partial measurement outcomes. By
considering the double negation sheafification, we obtain the space of
measurement outcomes which coincides with the spectrum for commutative
C*-algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1433</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1433</id><created>2010-06-07</created><authors><author><keyname>Valiron</keyname><forenames>Beno&#xee;t</forenames></author></authors><title>Semantics of a Typed Algebraic Lambda-Calculus</title><categories>cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.3.2; F.4.1</acm-class><journal-ref>EPTCS 26, 2010, pp. 147-158</journal-ref><doi>10.4204/EPTCS.26.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic lambda-calculi have been studied in various ways, but their
semantics remain mostly untouched. In this paper we propose a semantic analysis
of a general simply-typed lambda-calculus endowed with a structure of vector
space. We sketch the relation with two established vectorial lambda-calculi.
Then we study the problems arising from the addition of a fixed point
combinator and how to modify the equational theory to solve them. We sketch an
algebraic vectorial PCF and its possible denotational interpretations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1434</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1434</id><created>2010-06-07</created><authors><author><keyname>Younger</keyname><forenames>A. Steven</forenames><affiliation>Missouri State University</affiliation></author><author><keyname>Redd</keyname><forenames>Emmett</forenames><affiliation>Missouri State University</affiliation></author></authors><title>Computing by Means of Physics-Based Optical Neural Networks</title><categories>cs.NE cs.AI</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 159-167</journal-ref><doi>10.4204/EPTCS.26.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report recent research on computing with biology-based neural network
models by means of physics-based opto-electronic hardware. New technology
provides opportunities for very-high-speed computation and uncovers problems
obstructing the wide-spread use of this new capability. The Computation
Modeling community may be able to offer solutions to these cross-boundary
research problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1435</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1435</id><created>2010-06-07</created><authors><author><keyname>Peng</keyname><forenames>Li</forenames></author><author><keyname>Fabregas</keyname><forenames>Albert Guillen i</forenames></author></authors><title>Distortion Outage Probability in MIMO Block-Fading Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, Accepted, 2010 IEEE International Symposium on
  Information Theory (ISIT 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study analogue source transmission over MIMO block-fading channels with
receiver-only channel state information. Unlike previous work which considers
the end-to-end expected distortion as a figure of merit, we study the
distortion outage probability. We first consider the well known transmitter
informed bound, which yields a benchmark lower bound to the distortion outage
probability of any coding scheme. We next compare the results with
source-channel separation. The key difference from the expected distortion
approach is that if the channel code rate is chosen appropriately,
source-channel separation can not only achieve the same diversity exponent, but
also the same distortion outage probability as the transmitter informed lower
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1441</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1441</id><created>2010-06-07</created><authors><author><keyname>Cooper</keyname><forenames>Joshua</forenames></author><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Spencer</keyname><forenames>Joel</forenames></author></authors><title>Deterministic Random Walks on Regular Trees</title><categories>math.CO cs.DM math.PR</categories><comments>15 pages, to appear in Random Structures and Algorithms</comments><doi>10.1002/rsa.20314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Jim Propp's rotor router model is a deterministic analogue of a random walk
on a graph. Instead of distributing chips randomly, each vertex serves its
neighbors in a fixed order.
  Cooper and Spencer (Comb. Probab. Comput. (2006)) show a remarkable
similarity of both models. If an (almost) arbitrary population of chips is
placed on the vertices of a grid $\Z^d$ and does a simultaneous walk in the
Propp model, then at all times and on each vertex, the number of chips on this
vertex deviates from the expected number the random walk would have gotten
there by at most a constant. This constant is independent of the starting
configuration and the order in which each vertex serves its neighbors.
  This result raises the question if all graphs do have this property. With
quite some effort, we are now able to answer this question negatively. For the
graph being an infinite $k$-ary tree ($k \ge 3$), we show that for any
deviation $D$ there is an initial configuration of chips such that after
running the Propp model for a certain time there is a vertex with at least $D$
more chips than expected in the random walk model. However, to achieve a
deviation of $D$ it is necessary that at least $\exp(\Omega(D^2))$ vertices
contribute by being occupied by a number of chips not divisible by $k$ at a
certain time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1443</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1443</id><created>2010-06-07</created><authors><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author><author><keyname>Vilenchik</keyname><forenames>Dan</forenames></author></authors><title>Smoothed Analysis of Balancing Networks</title><categories>cs.DS cs.DC</categories><comments>26 pages, to appear in Random Structures and Algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a balancing network each processor has an initial collection of unit-size
jobs (tokens) and in each round, pairs of processors connected by balancers
split their load as evenly as possible. An excess token (if any) is placed
according to some predefined rule. As it turns out, this rule crucially affects
the performance of the network. In this work we propose a model that studies
this effect. We suggest a model bridging the uniformly-random assignment rule,
and the arbitrary one (in the spirit of smoothed-analysis). We start with an
arbitrary assignment of balancer directions and then flip each assignment with
probability $\alpha$ independently. For a large class of balancing networks our
result implies that after $\Oh(\log n)$ rounds the discrepancy is $\Oh(
(1/2-\alpha) \log n + \log \log n)$ with high probability. This matches and
generalizes known upper bounds for $\alpha=0$ and $\alpha=1/2$. We also show
that a natural network matches the upper bound for any $\alpha$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1449</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1449</id><created>2010-06-08</created><authors><author><keyname>Kaskenpalo</keyname><forenames>Petteri</forenames><affiliation>AUT University</affiliation></author></authors><title>On Secure Workflow Decentralisation on the Internet</title><categories>cs.CR cs.DC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 27, 2010, pp. 2-16</journal-ref><doi>10.4204/EPTCS.27.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralised workflow management systems are a new research area, where most
work to-date has focused on the system's overall architecture. As little
attention has been given to the security aspects in such systems, we follow a
security driven approach, and consider, from the perspective of available
security building blocks, how security can be implemented and what new
opportunities are presented when empowering the decentralised environment with
modern distributed security protocols. Our research is motivated by a more
general question of how to combine the positive enablers that email exchange
enjoys, with the general benefits of workflow systems, and more specifically
with the benefits that can be introduced in a decentralised environment. This
aims to equip email users with a set of tools to manage the semantics of a
message exchange, contents, participants and their roles in the exchange in an
environment that provides inherent assurances of security and privacy. This
work is based on a survey of contemporary distributed security protocols, and
considers how these protocols could be used in implementing a distributed
workflow management system with decentralised control . We review a set of
these protocols, focusing on the required message sequences in reviewing the
protocols, and discuss how these security protocols provide the foundations for
implementing core control-flow, data, and resource patterns in a distributed
workflow environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1450</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1450</id><created>2010-06-08</created><authors><author><keyname>Sudeikat</keyname><forenames>Jan</forenames><affiliation>HAW</affiliation></author><author><keyname>Renz</keyname><forenames>Wolfgang</forenames><affiliation>HAW</affiliation></author></authors><title>Separating Agent-Functioning and Inter-Agent Coordination by Activated
  Modules: The DECOMAS Architecture</title><categories>cs.MA</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 27, 2010, pp. 17-31</journal-ref><doi>10.4204/EPTCS.27.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The embedding of self-organizing inter-agent processes in distributed
software applications enables the decentralized coordination system elements,
solely based on concerted, localized interactions. The separation and
encapsulation of the activities that are conceptually related to the
coordination, is a crucial concern for systematic development practices in
order to prepare the reuse and systematic integration of coordination processes
in software systems. Here, we discuss a programming model that is based on the
externalization of processes prescriptions and their embedding in Multi-Agent
Systems (MAS). One fundamental design concern for a corresponding execution
middleware is the minimal-invasive augmentation of the activities that affect
coordination. This design challenge is approached by the activation of agent
modules. Modules are converted to software elements that reason about and
modify their host agent. We discuss and formalize this extension within the
context of a generic coordination architecture and exemplify the proposed
programming model with the decentralized management of (web) service
infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1492</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1492</id><created>2010-06-08</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Edelsbrunner</keyname><forenames>Herbert</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Rannou</keyname><forenames>Philippe</forenames></author></authors><title>Mean-payoff Automaton Expressions</title><categories>cs.LO</categories><doi>10.1007/978-3-642-15375-4_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative languages are an extension of boolean languages that assign to
each word a real number. Mean-payoff automata are finite automata with
numerical weights on transitions that assign to each infinite path the long-run
average of the transition weights. When the mode of branching of the automaton
is deterministic, nondeterministic, or alternating, the corresponding class of
quantitative languages is not robust as it is not closed under the pointwise
operations of max, min, sum, and numerical complement. Nondeterministic and
alternating mean-payoff automata are not decidable either, as the quantitative
generalization of the problems of universality and language inclusion is
undecidable.
  We introduce a new class of quantitative languages, defined by mean-payoff
automaton expressions, which is robust and decidable: it is closed under the
four pointwise operations, and we show that all decision problems are decidable
for this class. Mean-payoff automaton expressions subsume deterministic
mean-payoff automata, and we show that they have expressive power incomparable
to nondeterministic and alternating mean-payoff automata. We also present for
the first time an algorithm to compute distance between two quantitative
languages, and in our case the quantitative languages are given as mean-payoff
automaton expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1497</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1497</id><created>2010-06-08</created><updated>2010-06-15</updated><authors><author><keyname>Raiser</keyname><forenames>Frank</forenames></author><author><keyname>Fr&#xfc;hwirth</keyname><forenames>Thom</forenames></author></authors><title>Analyzing Graph Transformation Systems through Constraint Handling Rules</title><categories>cs.LO cs.PL</categories><comments>45 pages, 11 figures, to appear in Theory and Practice of Logic
  Programming (TPLP)</comments><acm-class>F.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph transformation systems (GTS) and constraint handling rules (CHR) are
non-deterministic rule-based state transition systems. CHR is well-known for
its powerful confluence and program equivalence analyses, for which we provide
the basis in this work to apply them to GTS. We give a sound and complete
embedding of GTS in CHR, investigate confluence of an embedded GTS, and provide
a program equivalence analysis for GTS via the embedding. The results confirm
the suitability of CHR-based program analyses for other formalisms embedded in
CHR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1512</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1512</id><created>2010-06-08</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>The Deterministic Dendritic Cell Algorithm</title><categories>cs.AI cs.NE</categories><comments>12 pages, 1 algorithm, 1 figure, 2 tables, 7th International
  Conference on Artificial Immune Systems (ICARIS 2008)</comments><journal-ref>Proceedings of the 7th International Conference on Artificial
  Immune Systems (ICARIS 2008), Phuket, Thailand, p 291-303</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dendritic Cell Algorithm is an immune-inspired algorithm orig- inally
based on the function of natural dendritic cells. The original instantiation of
the algorithm is a highly stochastic algorithm. While the performance of the
algorithm is good when applied to large real-time datasets, it is difficult to
anal- yse due to the number of random-based elements. In this paper a
deterministic version of the algorithm is proposed, implemented and tested
using a port scan dataset to provide a controllable system. This version
consists of a controllable amount of parameters, which are experimented with in
this paper. In addition the effects are examined of the use of time windows and
variation on the number of cells, both which are shown to influence the
algorithm. Finally a novel metric for the assessment of the algorithms output
is introduced and proves to be a more sensitive metric than the metric used
with the original Dendritic Cell Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1518</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1518</id><created>2010-06-08</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Feyereisl</keyname><forenames>Jan</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>The DCA:SOMe Comparison A comparative study between two
  biologically-inspired algorithms</title><categories>cs.AI cs.CR cs.NE</categories><comments>38 pages, 29 figures, 10 tables, Evolutionary Intelligence</comments><journal-ref>Evolutionary Intelligence, 1 (2), p 85-112, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dendritic Cell Algorithm (DCA) is an immune-inspired algorithm, developed
for the purpose of anomaly detection. The algorithm performs multi-sensor data
fusion and correlation which results in a 'context aware' detection system.
Previous applications of the DCA have included the detection of potentially
malicious port scanning activity, where it has produced high rates of true
positives and low rates of false positives. In this work we aim to compare the
performance of the DCA and of a Self-Organizing Map (SOM) when applied to the
detection of SYN port scans, through experimental analysis. A SOM is an ideal
candidate for comparison as it shares similarities with the DCA in terms of the
data fusion method employed. It is shown that the results of the two systems
are comparable, and both produce false positives for the same processes. This
shows that the DCA can produce anomaly detection results to the same standard
as an established technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1526</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1526</id><created>2010-06-08</created><authors><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Birkin</keyname><forenames>Philip</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>The Motif Tracking Algorithm</title><categories>cs.AI cs.CE cs.NE</categories><comments>13 pages, 10 figures, International Journal of Automation and
  Computing</comments><journal-ref>International Journal of Automation and Computing, 5 (1), p32-44,
  2008</journal-ref><doi>10.1007/s11633.008.0032.0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search for patterns or motifs in data represents a problem area of key
interest to finance and economic researchers. In this paper we introduce the
Motif Tracking Algorithm, a novel immune inspired pattern identification tool
that is able to identify unknown motifs of a non specified length which repeat
within time series data. The power of the algorithm comes from the fact that it
uses a small number of parameters with minimal assumptions regarding the data
being examined or the underlying motifs. Our interest lies in applying the
algorithm to financial time series data to identify unknown patterns that
exist. The algorithm is tested using three separate data sets. Particular
suitability to financial data is shown by applying it to oil price data. In all
cases the algorithm identifies the presence of a motif population in a fast and
efficient manner due to the utilisation of an intuitive symbolic
representation. The resulting population of motifs is shown to have
considerable potential value for other applications such as forecasting and
algorithm seeding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1535</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1535</id><created>2010-06-08</created><authors><author><keyname>Olmos</keyname><forenames>Pablo M.</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author></authors><title>Tree-structure Expectation Propagation for Decoding LDPC codes over
  Binary Erasure Channels</title><categories>cs.IT math.IT</categories><doi>10.1109/ISIT.2010.5513636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expectation Propagation is a generalization to Belief Propagation (BP) in two
ways. First, it can be used with any exponential family distribution over the
cliques in the graph. Second, it can impose additional constraints on the
marginal distributions. We use this second property to impose pair-wise
marginal distribution constraints in some check nodes of the LDPC Tanner graph.
These additional constraints allow decoding the received codeword when the BP
decoder gets stuck. In this paper, we first present the new decoding algorithm,
whose complexity is identical to the BP decoder, and we then prove that it is
able to decode codewords with a larger fraction of erasures, as the block size
tends to infinity. The proposed algorithm can be also understood as a
simplification of the Maxwell decoder, but without its computational
complexity. We also illustrate that the new algorithm outperforms the BP
decoder for finite block-size
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1537</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1537</id><created>2010-06-08</created><authors><author><keyname>Zhou</keyname><forenames>Junping</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author><author><keyname>Zhou</keyname><forenames>Chunguang</forenames></author></authors><title>New worst upper bound for #SAT</title><categories>cs.AI cs.CC</categories><comments>6 pages; proceedings of AAAI 2010</comments><acm-class>F.4.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The rigorous theoretical analyses of algorithms for #SAT have been proposed
in the literature. As we know, previous algorithms for solving #SAT have been
analyzed only regarding the number of variables as the parameter. However, the
time complexity for solving #SAT instances depends not only on the number of
variables, but also on the number of clauses. Therefore, it is significant to
exploit the time complexity from the other point of view, i.e. the number of
clauses. In this paper, we present algorithms for solving #2-SAT and #3-SAT
with rigorous complexity analyses using the number of clauses as the parameter.
By analyzing the algorithms, we obtain the new worst-case upper bounds
O(1.1892m) for #2-SAT and O(1.4142m) for #3-SAT, where m is the number of
clauses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1543</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1543</id><created>2010-06-08</created><authors><author><keyname>Viswanathan</keyname><forenames>Raajay</forenames></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames></author><author><keyname>Unnikrishnan</keyname><forenames>K. P.</forenames></author></authors><title>Efficient Discovery of Large Synchronous Events in Neural Spike Streams</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of finding patterns from multi-neuronal spike trains
that give us insights into the multi-neuronal codes used in the brain and help
us design better brain computer interfaces. We focus on the synchronous firings
of groups of neurons as these have been shown to play a major role in coding
and communication. With large electrode arrays, it is now possible to
simultaneously record the spiking activity of hundreds of neurons over large
periods of time. Recently, techniques have been developed to efficiently count
the frequency of synchronous firing patterns. However, when the number of
neurons being observed grows they suffer from the combinatorial explosion in
the number of possible patterns and do not scale well. In this paper, we
present a temporal data mining scheme that overcomes many of these problems. It
generates a set of candidate patterns from frequent patterns of smaller size;
all possible patterns are not counted. Also we count only a certain well
defined subset of occurrences and this makes the process more efficient. We
highlight the computational advantage that this approach offers over the
existing methods through simulations.
  We also propose methods for assessing the statistical significance of the
discovered patterns. We detect only those patterns that repeat often enough to
be significant and thus be able to automatically fix the threshold for the
data-mining application. Finally we discuss the usefulness of these methods for
brain computer interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1548</identifier>
 <datestamp>2011-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1548</id><created>2010-06-08</created><updated>2011-06-27</updated><authors><author><keyname>Kannu</keyname><forenames>Arun Pachai</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>On Communication over Unknown Sparse Frequency-Selective Block-Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of reliable communication over discrete-time
channels whose impulse responses have length $L$ and exactly $S\leq L$ non-zero
coefficients, and whose support and coefficients remain fixed over blocks of
$N&gt;L$ channel uses but change independently from block to block. Here, it is
assumed that the channel's support and coefficient realizations are both
unknown, although their statistics are known. Assuming Gaussian
non-zero-coefficients and noise, and focusing on the high-SNR regime, it is
first shown that the ergodic noncoherent channel capacity has pre-log factor
$1-\frac{S}{N}$ for any $L$. It is then shown that, to communicate with
arbitrarily small error probability at rates in accordance with the capacity
pre-log factor, it suffices to use pilot-aided orthogonal frequency-division
multiplexing (OFDM) with $S$ pilots per fading block, in conjunction with an
appropriate noncoherent decoder. Since the achievability result is proven using
a noncoherent decoder whose complexity grows exponentially in the number of
fading blocks $K$, a simpler decoder, based on $S+1$ pilots, is also proposed.
Its $\epsilon$-achievable rate is shown to have pre-log factor equal to
$1-\frac{S+1}{N}$ with the previously considered channel, while its achievable
rate is shown to have pre-log factor $1-\frac{S+1}{N}$ when the support of the
block-fading channel remains fixed over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1549</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1549</id><created>2010-06-08</created><authors><author><keyname>Gawron</keyname><forenames>P.</forenames></author><author><keyname>Klamka</keyname><forenames>J.</forenames></author><author><keyname>Miszczak</keyname><forenames>J. A.</forenames></author><author><keyname>Winiarczyk</keyname><forenames>R.</forenames></author></authors><title>Extending scientific computing system with structural quantum
  programming capabilities</title><categories>cs.PL quant-ph</categories><acm-class>J.2; D.3.3</acm-class><journal-ref>Bull. Pol. Acad. Sci., Technical Sciences, Vol. 58, No. 1 (2010)</journal-ref><doi>10.2478/v10175-010-0008-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a basic high-level structures used for developing quantum
programming languages. The presented structures are commonly used in many
existing quantum programming languages and we use quantum pseudo-code based on
QCL quantum programming language to describe them. We also present the
implementation of introduced structures in GNU Octave language for scientific
computing. Procedures used in the implementation are available as a package
quantum-octave, providing a library of functions, which facilitates the
simulation of quantum computing. This package allows also to incorporate
high-level programming concepts into the simulation in GNU Octave and Matlab.
As such it connects features unique for high-level quantum programming
languages, with the full palette of efficient computational routines commonly
available in modern scientific computing systems. To present the major features
of the described package we provide the implementation of selected quantum
algorithms. We also show how quantum errors can be taken into account during
the simulation of quantum algorithms using quantum-octave package. This is
possible thanks to the ability to operate on density matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1551</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1551</id><created>2010-06-08</created><authors><author><keyname>Donato</keyname><forenames>Matt</forenames></author><author><keyname>Loke</keyname><forenames>Seng W.</forenames></author></authors><title>EcoHomeHelper: An Expert System to Empower End-Users in Climate Change
  Action</title><categories>cs.CY</categories><comments>Contains links to the actual thesis on this topic</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Climate change has been a popular topic for a number of years now. Computer
Science has contributed to aiding humanity in reducing energy requirements and
consequently global warming. Much of this work is through calculators which
determine a user's carbon footprint. However there are no expert systems which
can offer advice in an efficient and time saving way. There are many
publications which do offer advice on reducing greenhouse gas (GHG) emissions
but to find the advice the reader seeks will involve reading a lot of
irrelevant material. This work built an expert system (which we call
EcoHomeHelper) and attempted to show that it is useful in changing people's
behaviour with respect to their GHG emissions and that they will be able to
find the information in a more efficient manner. Twelve participants were used.
Seven of which used the program and five who read and attempted to find advice
by reading from a list. The application itself has current implementations and
the concept further developed, has applications for the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1563</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1563</id><created>2010-06-08</created><authors><author><keyname>Feyereisl</keyname><forenames>Jan</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>ToLeRating UR-STD</title><categories>cs.AI cs.CR cs.NE</categories><comments>7 pages, 4 figures, 1 table, 2nd International Conference on Emerging
  Security Information, Systems and Technologies,</comments><journal-ref>Proceedings of the 2nd International Conference on Emerging
  Security Information, Systems and Technologies, Cap Esterel, France, p
  287-293, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new emerging paradigm of Uncertain Risk of Suspicion, Threat and Danger,
observed across the field of information security, is described. Based on this
paradigm a novel approach to anomaly detection is presented. Our approach is
based on a simple yet powerful analogy from the innate part of the human immune
system, the Toll-Like Receptors. We argue that such receptors incorporated as
part of an anomaly detector enhance the detector's ability to distinguish
normal and anomalous behaviour. In addition we propose that Toll-Like Receptors
enable the classification of detected anomalies based on the types of attacks
that perpetrate the anomalous behaviour. Classification of such type is either
missing in existing literature or is not fit for the purpose of reducing the
burden of an administrator of an intrusion detection system. For our model to
work, we propose the creation of a taxonomy of the digital Acytota, based on
which our receptors are created.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1565</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1565</id><created>2010-06-08</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Information Theory and Statistical Physics - Lecture Notes</title><categories>cs.IT cond-mat.dis-nn cond-mat.stat-mech math.IT</categories><comments>176 pages, 26 figures. Lecture notes of a graduate course delivered
  at the Technion in the Spring of 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document consists of lecture notes for a graduate course, which focuses
on the relations between Information Theory and Statistical Physics. The course
is aimed at EE graduate students in the area of Communications and Information
Theory, as well as to graduate students in Physics who have basic background in
Information Theory. Strong emphasis is given to the analogy and parallelism
between Information Theory and Statistical Physics, as well as to the insights,
the analysis tools and techniques that can be borrowed from Statistical Physics
and `imported' to certain problem areas in Information Theory. This is a
research trend that has been very active in the last few decades, and the hope
is that by exposing the student to the meeting points between these two
disciplines, we will enhance his/her background and perspective to carry out
research in the field.
  A short outline of the course is as follows: Introduction; Elementary
Statistical Physics and its Relation to Information Theory; Analysis Tools in
Statistical Physics; Systems of Interacting Particles and Phase Transitions;
The Random Energy Model (REM) and Random Channel Coding; Additional Topics
(optional).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1568</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1568</id><created>2010-06-08</created><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Towards a Conceptual Framework for Innate Immunity</title><categories>cs.AI cs.NE</categories><comments>14 pages, 5 figures, 2 tables, 4th International Conference on
  Artificial Immune Systems (ICARIS 2005)</comments><journal-ref>Proceedings of the 4th International Conference on Artificial
  Immune Systems (ICARIS 2005), Lecture Notes in Computer Science 3627, Banff,
  Canada, p 112-125</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Innate immunity now occupies a central role in immunology. However,
artificial immune system models have largely been inspired by adaptive not
innate immunity. This paper reviews the biological principles and properties of
innate immunity and, adopting a conceptual framework, asks how these can be
incorporated into artificial models. The aim is to outline a meta-framework for
models of innate immunity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1578</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1578</id><created>2010-06-08</created><authors><author><keyname>Tauber</keyname><forenames>Markus</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author></authors><title>Autonomic Management of Maintenance Scheduling in Chord</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper experimentally evaluates the effects of applying autonomic
management to the scheduling of maintenance operations in a deployed Chord
network, for various membership churn and workload patterns. Two versions of an
autonomic management policy were compared with a static configuration. The
autonomic policies varied with respect to the aggressiveness with which they
responded to peer access error rates and to wasted maintenance operations. In
most experiments, significant improvements due to autonomic management were
observed in the performance of routing operations and the quantity of data
transmitted between network members. Of the autonomic policies, the more
aggressive version gave slightly better results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1587</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1587</id><created>2010-06-08</created><updated>2013-05-24</updated><authors><author><keyname>Hod</keyname><forenames>Rani</forenames></author><author><keyname>Krzywkowski</keyname><forenames>Marcin</forenames></author></authors><title>A construction for the hat problem on a directed graph</title><categories>cs.DM math.CO</categories><comments>9 pages. v2: updated title and abstract to match journal version</comments><msc-class>05C20, 05C69, 91A12, 91A43</msc-class><journal-ref>Electronic J. Combinatorics 19 (2012) P30</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A team of players plays the following game. After a strategy session, each
player is randomly fitted with a blue or red hat. Then, without further
communication, everybody can try to guess simultaneously his or her own hat
color by looking at the hat colors of other players. Visibility is defined by a
directed graph; that is, vertices correspond to players, and a player can see
each player to whom she or he is connected by an arc. The team wins if at least
one player guesses his hat color correctly, and no one guesses his hat color
wrong; otherwise the team loses. The team aims to maximize the probability of a
win, and this maximum is called the hat number of the graph.
  Previous works focused on the problem on complete graphs and on undirected
graphs. Some cases were solved, e.g., complete graphs of certain orders, trees,
cycles, bipartite graphs. These led Uriel Feige to conjecture that the hat
number of any graph is equal to the hat number of its maximum clique.
  We show that the conjecture does not hold for directed graphs.Moreover, for
every value of the maximum clique size, we provide a tight characterization of
the range of possible values of the hat number. We construct families of
directed graphs with a fixed clique number the hat number of which is
asymptotically optimal. We also determine the hat number of tournaments to be
one half.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1592</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1592</id><created>2010-06-08</created><authors><author><keyname>Garetto</keyname><forenames>Michele</forenames></author><author><keyname>Nordio</keyname><forenames>Alessandro</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author><author><keyname>Leonardi</keyname><forenames>Emilio</forenames></author></authors><title>Information-theoretic Capacity of Clustered Random Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, in Proceedings of ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the capacity scaling laws of clustered ad hoc networks in which
nodes are distributed according to a doubly stochastic shot-noise Cox process.
We identify five different operational regimes, and for each regime we devise a
communication strategy that allows to achieve a throughput to within a
poly-logarithmic factor (in the number of nodes) of the maximum theoretical
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1658</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1658</id><created>2010-06-08</created><authors><author><keyname>Zeh</keyname><forenames>Alexander</forenames></author><author><keyname>Senger</keyname><forenames>Christian</forenames></author></authors><title>A Link between Guruswami--Sudan's List--Decoding and Decoding of
  Interleaved Reed--Solomon Codes</title><categories>cs.IT math.IT</categories><comments>For ISIT 2010</comments><doi>10.1109/ISIT.2010.5513427</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Welch--Berlekamp approach for Reed--Solomon (RS) codes forms a bridge
between classical syndrome--based decoding algorithms and interpolation--based
list--decoding procedures for list size l=1. It returns the univariate
error--locator polynomial and the evaluation polynomial of the RS code as a
y-root. In this paper, we show the connection between the Welch--Berlekamp
approach for a specific Interleaved Reed--Solomon code scheme and the
Guruswami--Sudan principle. It turns out that the decoding of Interleaved RS
codes can be formulated as a modified Guruswami--Sudan problem with a specific
multiplicity assignment. We show that our new approach results in the same
solution space as the Welch--Berlekamp scheme. Furthermore, we prove some
important properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1661</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1661</id><created>2010-06-08</created><updated>2010-06-10</updated><authors><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Mow</keyname><forenames>Wai Ho</forenames></author><author><keyname>Howgrave-Graham</keyname><forenames>Nick</forenames></author></authors><title>Variants of the LLL Algorithm in Digital Communications: Complexity
  Analysis and Fixed-Complexity Implementation</title><categories>cs.IT math.IT</categories><comments>remove redundant figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lenstra-Lenstra-Lov\'asz (LLL) algorithm is the most practical lattice
reduction algorithm in digital communications. In this paper, several variants
of the LLL algorithm with either lower theoretic complexity or fixed-complexity
implementation are proposed and/or analyzed. Firstly, the $O(n^4\log n)$
theoretic average complexity of the standard LLL algorithm under the model of
i.i.d. complex normal distribution is derived. Then, the use of effective LLL
reduction for lattice decoding is presented, where size reduction is only
performed for pairs of consecutive basis vectors. Its average complexity is
shown to be $O(n^3\log n)$, which is an order lower than previously thought. To
address the issue of variable complexity of standard LLL, two fixed-complexity
approximations of LLL are proposed. One is fixed-complexity effective LLL,
while the other is fixed-complexity LLL with deep insertion, which is closely
related to the well known V-BLAST algorithm. Such fixed-complexity structures
are much desirable in hardware implementation since they allow straightforward
constant-throughput implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1663</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1663</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Tata Kelola Database Perguruan Tinggi Yang Optimal Dengan Data Warehouse</title><categories>cs.DB</categories><comments>10 pages, 12 figures and 4 tables</comments><acm-class>H.2.7</acm-class><journal-ref>TELKOMNIKA Vol. 8, No. 1, April 2010, pp. 25 - 34</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of new higher education institutions has created the
competition in higher education market, and data warehouse can be used as an
effective technology tools for increasing competitiveness in the higher
education market. Data warehouse produce reliable reports for the institution's
high-level management in short time for faster and better decision making, not
only on increasing the admission number of students, but also on the
possibility to find extraordinary, unconventional funds for the institution.
Efficiency comparison was based on length and amount of processed records,
total processed byte, amount of processed tables, time to run query and
produced record on OLTP database and data warehouse. Efficiency percentages was
measured by the formula for percentage increasing and the average efficiency
percentage of 461.801,04% shows that using data warehouse is more powerful and
efficient rather than using OLTP database. Data warehouse was modeled based on
hypercube which is created by limited high demand reports which usually used by
high level management. In every table of fact and dimension fields will be
inserted which represent the loading constructive merge where the ETL
(Extraction, Transformation and Loading) process is run based on the old and
new files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1666</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1666</id><created>2010-06-08</created><updated>2010-06-10</updated><authors><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>On the Proximity Factors of Lattice Reduction-Aided Decoding</title><categories>cs.IT math.IT</categories><comments>remove redundant figures</comments><doi>10.1109/TSP.2011.2123889</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice reduction-aided decoding features reduced decoding complexity and
near-optimum performance in multi-input multi-output communications. In this
paper, a quantitative analysis of lattice reduction-aided decoding is
presented. To this aim, the proximity factors are defined to measure the
worst-case losses in distances relative to closest point search (in an infinite
lattice). Upper bounds on the proximity factors are derived, which are
functions of the dimension $n$ of the lattice alone. The study is then extended
to the dual-basis reduction. It is found that the bounds for dual basis
reduction may be smaller. Reasonably good bounds are derived in many cases. The
constant bounds on proximity factors not only imply the same diversity order in
fading channels, but also relate the error probabilities of (infinite) lattice
decoding and lattice reduction-aided decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1667</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1667</id><created>2010-06-08</created><authors><author><keyname>Yang</keyname><forenames>Echo</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>Interference Channel with Generalized Feedback (a.k.a. with source
  cooperation). Part I: Achievable Region</title><categories>cs.IT math.IT</categories><comments>70 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An Interference Channel with Generalized Feedback (IFC-GF) is a model for a
wireless network where several source-destination pairs compete for the same
channel resources, and where the sources have the ability to sense the current
channel activity. The signal overheard from the channel provides information
about the activity of the other users, and thus furnishes the basis for
cooperation. In this two-part paper we study achievable strategies and outer
bounds for a general IFC-GF with two source-destination pairs. We then evaluate
the proposed regions for the Gaussian channel. Part I: achievable region. We
propose that the generalized feedback is used to gain knowledge about the
message sent by other user and then exploited in two ways: (a) to {\em relay}
the messages that can be decoded at both destinations--thus realizing the gains
of beam-forming of a distributed multi-antenna system--and (b) to {\em hide}
the messages that can not be decoded at the non-intended destination--thus
leveraging the interference &quot;pre-cancellation&quot; property of dirty-paper-type
coding. We show that our achievable region generalizes several known achievable
regions for IFC-GF and that it reduces to known achievable regions for some of
the channels subsumed by the IFC-GF model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1669</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1669</id><created>2010-06-08</created><authors><author><keyname>Ning</keyname><forenames>Haishi</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Leung</keyname><forenames>Kin K.</forenames></author></authors><title>On the Universality of Sequential Slotted Amplify and Forward Strategy
  in Cooperative Communications</title><categories>cs.IT math.IT</categories><comments>22 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While cooperative communication has many benefits and is expected to play an
important role in future wireless networks, many challenges are still unsolved.
Previous research has developed different relaying strategies for cooperative
multiple access channels (CMA), cooperative multiple relay channels (CMR) and
cooperative broadcast channels (CBC). However, there lacks a unifying strategy
that is universally optimal for these three classical channel models.
Sequential slotted amplify and forward (SSAF) strategy was previously proposed
to achieve the optimal diversity and multiplexing tradeoff (DMT) for CMR. In
this paper, the use of SSAF strategy is extended to CBC and CMA, and its
optimality for both of them is shown. For CBC, a CBC-SSAF strategy is proposed
which can asymptotically achieve the DMT upper bound when the number of
cooperative users is large. For CMA, a CMA-SSAF strategy is proposed which even
can exactly achieve the DMT upper bound with any number of cooperative users.
In this way, SSAF strategy is shown to be universally optimal for all these
three classical channel models and has great potential to provide universal
optimality for wireless cooperative networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1673</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1673</id><created>2010-06-08</created><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Michael</keyname><forenames>Nithin</forenames></author><author><keyname>Tang</keyname><forenames>Ao Kevin</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Distributed Algorithms for Learning and Cognitive Medium Access with
  Logarithmic Regret</title><categories>cs.NI stat.ML</categories><comments>Submitted to IEEE JSAC on Advances in Cognitive Radio Networking and
  Communications, Dec. 2009, Revised May 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of distributed learning and channel access is considered in a
cognitive network with multiple secondary users. The availability statistics of
the channels are initially unknown to the secondary users and are estimated
using sensing decisions. There is no explicit information exchange or prior
agreement among the secondary users. We propose policies for distributed
learning and access which achieve order-optimal cognitive system throughput
(number of successful secondary transmissions) under self play, i.e., when
implemented at all the secondary users. Equivalently, our policies minimize the
regret in distributed learning and access. We first consider the scenario when
the number of secondary users is known to the policy, and prove that the total
regret is logarithmic in the number of transmission slots. Our distributed
learning and access policy achieves order-optimal regret by comparing to an
asymptotic lower bound for regret under any uniformly-good learning and access
policy. We then consider the case when the number of secondary users is fixed
but unknown, and is estimated through feedback. We propose a policy in this
scenario whose asymptotic sum regret which grows slightly faster than
logarithmic in the number of transmission slots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1674</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1674</id><created>2010-06-08</created><updated>2011-01-11</updated><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>He</keyname><forenames>Ting</forenames></author><author><keyname>Bisdikian</keyname><forenames>Chatschik</forenames></author><author><keyname>Agrawal</keyname><forenames>Dakshi</forenames></author></authors><title>Seeing Through Black Boxes : Tracking Transactions through Queues under
  Monitoring Resource Constraints</title><categories>cs.PF</categories><comments>Accepted to Elsevier Performance Evaluation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of optimal allocation of monitoring resources for tracking
transactions progressing through a distributed system, modeled as a queueing
network, is considered. Two forms of monitoring information are considered,
viz., locally unique transaction identifiers, and arrival and departure
timestamps of transactions at each processing queue. The timestamps are assumed
available at all the queues but in the absence of identifiers, only enable
imprecise tracking since parallel processing can result in out-of-order
departures. On the other hand, identifiers enable precise tracking but are not
available without proper instrumentation. Given an instrumentation budget, only
a subset of queues can be selected for production of identifiers, while the
remaining queues have to resort to imprecise tracking using timestamps. The
goal is then to optimally allocate the instrumentation budget to maximize the
overall tracking accuracy. The challenge is that the optimal allocation
strategy depends on accuracies of timestamp-based tracking at different queues,
which has complex dependencies on the arrival and service processes, and the
queueing discipline. We propose two simple heuristics for allocation by
predicting the order of timestamp-based tracking accuracies of different
queues. We derive sufficient conditions for these heuristics to achieve
optimality through the notion of stochastic comparison of queues. Simulations
show that our heuristics are close to optimality, even when the parameters
deviate from these conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1676</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1676</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Simple ROI untuk justifikasi investasi proyek Data Warehouse pada
  perguruan tinggi swasta</title><categories>cs.OH</categories><comments>21 pages</comments><acm-class>H.2.7</acm-class><journal-ref>Jurnal Ilmiah Teknik Komputer, November, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decreasing new students for private high education push the management
particularly for high level management for making an information which can help
them to make decisions in order for competition with other high educations. One
of way out by building with information technology approaching like data
warehouse for data handling and making the best decisions. Simple ROI is used
for project justification. Based on ROI value between 1,850.13% and cash flow
Rp. 22,081,297,308 then can be concluded that project data warehouse
development in private high education can be implemented with the particular
assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1678</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1678</id><created>2010-06-08</created><updated>2010-11-08</updated><authors><author><keyname>Fannjiang</keyname><forenames>Albert C.</forenames></author></authors><title>The MUSIC Algorithm for Sparse Objects: A Compressed Sensing Analysis</title><categories>cs.IT math.AP math.IT physics.data-an</categories><comments>Strengthen and in some cases simplify the results in v.2</comments><msc-class>74G75</msc-class><doi>10.1088/0266-5611/27/3/035013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MUSIC algorithm, with its extension for imaging sparse {\em extended}
objects, is analyzed by compressed sensing (CS) techniques. The notion of
restricted isometry property (RIP) and an upper bound on the restricted
isometry constant (RIC) are employed to establish sufficient conditions for the
exact localization by MUSIC with or without the presence of noise. In the
noiseless case, the sufficient condition gives an upper bound on the numbers of
random sampling and incident directions necessary for exact localization. In
the noisy case, the sufficient condition assumes additionally an upper bound
for the noise-to-object ratio in terms of the RIC and the condition number of
objects. Rigorous comparison of performance between MUSIC and the CS
minimization principle, Lasso, is given. In general, the MUSIC algorithm
guarantees to recover, with high probability, $s$ scatterers with $n=\cO(s^2)$
random sampling and incident directions and sufficiently high frequency. For
the favorable imaging geometry where the scatterers are distributed on a
transverse plane MUSIC guarantees to recover, with high probability, $s$
scatterers with a median frequency and $n=\cO(s)$ random sampling/incident
directions. Numerical results confirm that the Lasso outperforms MUSIC in the
well-resolved case while the opposite is true for the under-resolved case. The
latter effect indicates the superresolution capability of the MUSIC algorithm.
Another advantage of MUSIC over the Lasso as applied to imaging is the former's
flexibility with grid spacing and guarantee of {\em approximate} localization
of sufficiently separated objects in an arbitrarily fine grid. The error can be
bounded from above by $\cO(\lambda s)$ for general configurations and
$\cO(\lambda)$ for objects distributed in a transverse plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1679</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1679</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Rancangan Infrastruktur E-Bisnis Business Intelligence Pada Perguruan
  Tinggi</title><categories>cs.OH</categories><comments>12 pages, 11 figures</comments><acm-class>H.2.7</acm-class><journal-ref>Telkomnika Vol. 6, No. 2, Agustus 2008 : pp. 115 - 124</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to compete with others, high education need complete their
infrastructure with Information technology support. High level management as a
decision maker need something that can boost the system to compete with other
high education, they need IT knowledge that can support them to view the future
and can help the whole system to improve their services. Business Intelligence
is one of term of Decision Support System which can help the management by
something that they can forecast and decide. High Education need infrastructure
design to make good foundation for business intelligent implementation which
will be implemented on internet or e-business.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1681</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1681</id><created>2010-06-08</created><authors><author><keyname>Terrazas</keyname><forenames>German</forenames><affiliation>University of Nottingham</affiliation></author><author><keyname>Landa-Silva</keyname><forenames>Dario</forenames><affiliation>University of Nottingham</affiliation></author><author><keyname>Krasnogor</keyname><forenames>Natalio</forenames><affiliation>University of Nottingham</affiliation></author></authors><title>Towards the Design of Heuristics by Means of Self-Assembly</title><categories>cs.AI cs.NE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 135-146</journal-ref><doi>10.4204/EPTCS.26.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current investigations on hyper-heuristics design have sprung up in two
different flavours: heuristics that choose heuristics and heuristics that
generate heuristics. In the latter, the goal is to develop a problem-domain
independent strategy to automatically generate a good performing heuristic for
the problem at hand. This can be done, for example, by automatically selecting
and combining different low-level heuristics into a problem specific and
effective strategy. Hyper-heuristics raise the level of generality on automated
problem solving by attempting to select and/or generate tailored heuristics for
the problem at hand. Some approaches like genetic programming have been
proposed for this. In this paper, we explore an elegant nature-inspired
alternative based on self-assembly construction processes, in which structures
emerge out of local interactions between autonomous components. This idea
arises from previous works in which computational models of self-assembly were
subject to evolutionary design in order to perform the automatic construction
of user-defined structures. Then, the aim of this paper is to present a novel
methodology for the automated design of heuristics by means of self-assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1683</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1683</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Object-oriented modelling with unified modelling language 2.0 for simple
  software application based on agile methodology</title><categories>cs.SE</categories><comments>15 pages, 30 figures</comments><acm-class>D.2.10</acm-class><journal-ref>Behaviour &amp; Information Technology an International Journal, as
  forthcoming articles which first published on 22 September 2009</journal-ref><doi>10.1080/01449290903186231</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unified modelling language (UML) 2.0 introduced in 2002 has been developing
and influencing object-oriented software engineering and has become a standard
and reference for information system analysis and design modelling. There are
many concepts and theories to model the information system or software
application with UML 2.0, which can make ambiguities and inconsistencies for a
novice to learn to how to model the system with UML especially with UML 2.0.
This article will discuss how to model the simple software application by using
some of the diagrams of UML 2.0 and not by using the whole diagrams as
suggested by agile methodology. Agile methodology is considered as convenient
for novices because it can deliver the information technology environment to
the end-user quickly and adaptively with minimal documentation. It also has the
ability to deliver best performance software application according to the
customer's needs. Agile methodology will make simple model with simple
documentation, simple team and simple tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1689</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1689</id><created>2010-06-08</created><authors><author><keyname>Van Cutsem</keyname><forenames>Tom</forenames><affiliation>Vrije Universiteit Brussel</affiliation></author><author><keyname>Miller</keyname><forenames>Mark</forenames><affiliation>Google</affiliation></author></authors><title>Proceedings First International Workshop on Decentralized Coordination
  of Distributed Processes</title><categories>cs.DC cs.CR cs.NI cs.PL</categories><proxy>EPTCS</proxy><acm-class>C2.4; D1.3; D2.11; D4.6</acm-class><journal-ref>EPTCS 27, 2010</journal-ref><doi>10.4204/EPTCS.27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the 1st International Workshop
on &quot;Decentralized Coordination of Distributed Processes&quot;, DCDP 2010, held in
Amsterdam, The Netherlands on June 10th, 2010 in conjunction with the 5th
International Federated Conferences on Distributed Computing Techniques,
DisCoTec 2010. The central theme of the workshop is the decentralized
coordination of distributed processes. Decentralized: there is no single
authority in the network that everything is vulnerable to. Coordinated:
processes need to cooperate to achieve meaningful results, potentially in the
face of mutual suspicion. Distributed: processes are separated by a potentially
unreliable network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1690</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1690</id><created>2010-06-08</created><authors><author><keyname>Lee</keyname><forenames>Jong-Ho</forenames></author><author><keyname>Shin</keyname><forenames>Oh-Soon</forenames></author></authors><title>Full-Duplex Relay based on Zero-Forcing Beamforming</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a full-duplex relay (FDR) based on a zero-forcing
beamforming (ZFBF) for a multiuser MIMO relay system. The ZFBF is employed at
the base station to suppress both the self-interference of the relay and the
multiuser interference at the same time. Numerical results show that the
proposed FDR can enhance the sum rate performance as compared to the
half-duplex relay (HDR), if sufficient isolation between the transmit and
receive antennas is ensured at the relay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1692</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1692</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Measuring interesting rules in Characteristic rule</title><categories>cs.DB cs.AI</categories><comments>5 pages, 5 figures, 12 tables</comments><acm-class>H.2.8; I.2.6</acm-class><journal-ref>2nd International Conference on Soft Computing, Intelligent System
  and Information Technology (ICSIIT), Bali, Indonesia, 1-2 July 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding interesting rule in the sixth strategy step about threshold control
on generalized relations in attribute oriented induction, there is possibility
to select candidate attribute for further generalization and merging of
identical tuples until the number of tuples is no greater than the threshold
value, as implemented in basic attribute oriented induction algorithm. At this
strategy step there is possibility the number of tuples in final generalization
result still greater than threshold value. In order to get the final
generalization result which only small number of tuples and can be easy to
transfer into simple logical formula, the seventh strategy step about rule
transformation is evolved where there will be simplification by unioning or
grouping the identical attribute. Our approach to measure interesting rule is
opposite with heuristic measurement approach by Fudger and Hamilton where the
more complex concept hierarchies, more interesting results are likely to be
found, but our approach the simpler concept hierarchies, more interesting
results are likely to be found and the more complex concept hierarchies, more
complex process generalization in concept tree. The decision to find
interesting rule is influenced with wide or length and depth or level of
concept tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1694</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1694</id><created>2010-06-08</created><updated>2013-05-14</updated><authors><author><keyname>Ezerman</keyname><forenames>Martianus Frederic</forenames></author><author><keyname>Jitman</keyname><forenames>Somphong</forenames></author><author><keyname>Kiah</keyname><forenames>Han Mao</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author></authors><title>Pure Asymmetric Quantum MDS Codes from CSS Construction: A Complete
  Characterization</title><categories>cs.IT math.IT</categories><comments>Change in authors' list. Accepted for publication in Int. Journal of
  Quantum Information</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the Calderbank-Shor-Steane (CSS) construction, pure $q$-ary asymmetric
quantum error-correcting codes attaining the quantum Singleton bound are
constructed. Such codes are called pure CSS asymmetric quantum maximum distance
separable (AQMDS) codes. Assuming the validity of the classical MDS Conjecture,
pure CSS AQMDS codes of all possible parameters are accounted for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1695</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1695</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Attribute Oriented Induction with simple select SQL statement</title><categories>cs.DB</categories><comments>17 pages, 20 tables, 4 figures</comments><acm-class>H.2.8</acm-class><journal-ref>1st International Conference on Computation for Science and
  Technology (ICCST-I), Chiang Mai, Thailand, 4-6 August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Searching learning or rules in relational database for data mining purposes
with characteristic or classification/discriminant rule in attribute oriented
induction technique can be quicker, easy, and simple with simple SQL statement.
With just only one simple SQL statement, characteristic and classification rule
can be created simultaneously. Collaboration SQL statement with any other
application software will increase the ability for creating t-weight as
measurement the typicality of each record in the characteristic rule and
d-weight as measurement the discriminating behavior of the learned
classification/discriminant rule, particularly for further generalization in
characteristic rule. Handling concept hierarchy into tables based on concept
tree will influence for the successful simple SQL statement and by knowing the
right standard knowledge to transform each of concept tree in concept hierarchy
into one table as transforming concept hierarchy into table, the simple SQL
statement can be run properly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1699</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1699</id><created>2010-06-08</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Multidimensional Datawarehouse with Combination Formula</title><categories>cs.DB</categories><comments>7 pages, 12 figures</comments><acm-class>H.2.7</acm-class><journal-ref>The 2nd International Conference on Information and Communication
  Technology and Systems (ICTS), Informatics Department, Faculty of Information
  Technology, Institute of Technology Sepuluh Nopember (ITS), Surabaya,
  Indonesia, 29 August 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional in data warehouse is a compulsion and become the most
important for information delivery, without multidimensional Multidimensional
in data warehouse is a compulsion and become the most important for information
delivery, without multidimensional datawarehouse is incomplete.
Multidimensional give ability to analyze business measurement in many different
ways. Multidimensional is also synonymous with online analytical processing
(OLAP). By using some concepts in datawarehouse like slice-dice,drill down and
roll up will increase the ability of multidimensional datawarehouse. The
research question and the discussing for this paper are how much deepest the
multidimensional ability from each fact table in datawarehouse. By using the
statistic combination formula we try to explore the combination that can be
yielded from each dimension in hypercubes, the entire of dimensi combination,
minimum combination and maximum combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1701</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1701</id><created>2010-06-09</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Virtual information system on working area</title><categories>cs.AI</categories><comments>6 pages, 3 figures</comments><acm-class>H.5.1</acm-class><journal-ref>Indonesian Students' International Scientific Meeting, (Temu
  Ilmiah Internasional Mahasiswa Indonesia, TIIMI), London, United Kingdom, 5-7
  December 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to get strategic positioning for competition in business
organization, the information system must be ahead in this information age
where the information as one of the weapons to win the competition and in the
right hand the information will become a right bullet. The information system
with the information technology support isn't enough if just only on internet
or implemented with internet technology. The growth of information technology
as tools for helping and making people easy to use must be accompanied by
wanting to make fun and happy when they make contact with the information
technology itself. Basically human like to play, since childhood human have
been playing, free and happy and when human grow up they can't play as much as
when human was in their childhood. We have to develop the information system
which is not perform information system itself but can help human to explore
their natural instinct for playing, making fun and happiness when they interact
with the information system. Virtual information system is the way to present
playing and having fun atmosphere on working area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1702</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1702</id><created>2010-06-09</created><authors><author><keyname>De Choudhury</keyname><forenames>Munmun</forenames></author><author><keyname>Sundaram</keyname><forenames>Hari</forenames></author><author><keyname>John</keyname><forenames>Ajita</forenames></author><author><keyname>Seligmann</keyname><forenames>Doree Duncan</forenames></author><author><keyname>Kelliher</keyname><forenames>Aisling</forenames></author></authors><title>&quot;Birds of a Feather&quot;: Does User Homophily Impact Information Diffusion
  in Social Media?</title><categories>cs.CY physics.soc-ph</categories><comments>31 pages, 10 figures, 3 tables</comments><acm-class>H.1.2; H.2.8; H.3.3; H.3.5; H.4.3; H.5.4; I.2.6; J.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This article investigates the impact of user homophily on the social process
of information diffusion in online social media. Over several decades, social
scientists have been interested in the idea that similarity breeds connection:
precisely known as &quot;homophily&quot;. Homophily has been extensively studied in the
social sciences and refers to the idea that users in a social system tend to
bond more with ones who are similar to them than to ones who are dissimilar.
The key observation is that homophily structures the ego-networks of
individuals and impacts their communication behavior. It is therefore likely to
effect the mechanisms in which information propagates among them. To this
effect, we investigate the interplay between homophily along diverse user
attributes and the information diffusion process on social media. In our
approach, we first extract diffusion characteristics---corresponding to the
baseline social graph as well as graphs filtered on different user attributes
(e.g. location, activity). Second, we propose a Dynamic Bayesian Network based
framework to predict diffusion characteristics at a future time. Third, the
impact of attribute homophily is quantified by the ability of the predicted
characteristics in explaining actual diffusion, and external variables,
including trends in search and news. Experimental results on a large Twitter
dataset demonstrate that choice of the homophilous attribute can impact the
prediction of information diffusion, given a specific metric and a topic. In
most cases, attribute homophily is able to explain the actual diffusion and
external trends by ~15-25% over cases when homophily is not considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1703</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1703</id><created>2010-06-09</created><authors><author><keyname>Warnars</keyname><forenames>Spits</forenames></author></authors><title>Indonesian Earthquake Decision Support System</title><categories>cs.AI</categories><comments>8 pages, 7 figures</comments><acm-class>H.4.2</acm-class><journal-ref>The 5th International Conference on Information &amp; Communication
  Technology and Systems (ICTS) 2009, Informatics Department, Institute of
  Technology Sepuluh Nopember (ITS), Surabaya, Indonesia, 3-4 August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Earthquake DSS is an information technology environment which can be used by
government to sharpen, make faster and better the earthquake mitigation
decision. Earthquake DSS can be delivered as E-government which is not only for
government itself but in order to guarantee each citizen's rights for
education, training and information about earthquake and how to overcome the
earthquake. Knowledge can be managed for future use and would become mining by
saving and maintain all the data and information about earthquake and
earthquake mitigation in Indonesia. Using Web technology will enhance global
access and easy to use. Datawarehouse as unNormalized database for
multidimensional analysis will speed the query process and increase reports
variation. Link with other Disaster DSS in one national disaster DSS, link with
other government information system and international will enhance the
knowledge and sharpen the reports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1704</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1704</id><created>2010-06-09</created><updated>2010-06-09</updated><authors><author><keyname>Warnars</keyname><forenames>H. L. H Spits</forenames></author></authors><title>Sistem Pengambilan Keputusan Penanganan Bencana Alam Gempa Bumi Di
  Indonesia</title><categories>cs.OH</categories><comments>14 pages</comments><acm-class>H.4.2</acm-class><journal-ref>Olympic Innovative Paper International Conference (Proceeding
  Olimpiade Karya Tulis Inovatif ,OKTI), L'association des Etudiants
  Indonesiens en France, Paris, France, 10-11 Oct 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After Aceh's quake many earthquakes have struck Indonesia alternately and
even other disasters have been a threat for every citizen in this country.
Actually an everyday occurrence on earth and more than 3 million earthquakes
occur every year, about 8,000 a day, or one every 11 seconds in Indonesia there
are 5 to 30 quakes prediction everyday. Government's responsibility to protect
the citizen has been done by making National body of disaster management.
Preparing, saving and distribution logistic become National body of disaster
management's responsibility to build information management. Many law's
products have been produced as a government's responsibility to give secure
life for the citizen. We can not prevent them totally, we have to learn to live
with them and need to be prepared all the time, need to learn how to mitigate
risk of losses in such events by managing crisis and emergencies correctly.
After disaster happens respond must be rapidly and at an optimal level to save
lives and help to victims. DSS is information technology environment which can
be used to help human in order to learn from past earthquake, record it, learn
and plan for future mitigation and hope will reduce the disaster risk in the
future. Using web technology for DSS will give value added where not only make
a strategic decision for the decision maker, but for others who need national
earthquake information like citizen, scholars, researches and people around the
world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1711</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1711</id><created>2010-06-09</created><authors><author><keyname>Montanari</keyname><forenames>Angelo</forenames><affiliation>Universit&#xe0; di Udine</affiliation></author><author><keyname>Napoli</keyname><forenames>Margherita</forenames><affiliation>Universit&#xe0; di Salerno</affiliation></author><author><keyname>Parente</keyname><forenames>Mimmo</forenames><affiliation>Universit&#xe0; di Salerno</affiliation></author></authors><title>Proceedings First Symposium on Games, Automata, Logic, and Formal
  Verification</title><categories>cs.GT cs.FL cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.1.1; F.4.1; F.3.1; F.4.3</acm-class><journal-ref>EPTCS 25, 2010</journal-ref><doi>10.4204/EPTCS.25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the Proceedings of the first Symposium on &quot;Games,
Automata, Logic, and Formal Verification (GandALF)&quot;, held in Minori (Amalfi
coast), Italy, 17-18 June 2010. The symposium has been promoted by a number of
Italian computer scientists interested in game theory, mathematical logic,
automata theory, and their applications to the specification, design, and
verification of complex systems. It covers a large spectrum of research topics,
ranging from theoretical aspects to concrete applications. Its aim is to
provide a forum where people from different areas, and possibly with a
different background, can successfully interact. The high-level international
profile of the event is witnessed by the composition of the program committee
and by the final program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1714</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1714</id><created>2010-06-09</created><authors><author><keyname>Isaksson</keyname><forenames>Eva</forenames></author></authors><title>Bibliometric Evaluation of the Changing Finnish Astronomy</title><categories>astro-ph.IM cs.DL</categories><comments>3 pages, 2 figures, to appear in Library and Information Services in
  Astronomy VI, ASP Conference Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a follow-up on the bibliometric evaluation of Finnish astronomy
presented by the author at the LISA V conference in 2006. The data from the
previous study are revisited to determine how a wider institutional base and
mergers affect comparisons between research units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1727</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1727</id><created>2010-06-09</created><updated>2010-06-29</updated><authors><author><keyname>Dash</keyname><forenames>Debashis</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Distributed Consensus with Finite Message Passing</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, to be presented at ISIT 2010 (typos corrected)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by distributed resource allocation problems in dynamic topology
networks, we initiate the study of distributed consensus with finite messaging
passing. We first find a sufficient condition on the network graph for which no
distributed protocol can guarantee a conflict-free allocation after $R$ rounds
of message passing. Secondly we fully characterize the conflict minimizing
zero-round protocol for path graphs, namely random allocation, which partitions
the graph into small conflict groups. Thirdly, we enumerate all one-round
protocols for path graphs and show that the best one further partitions each of
the smaller groups. Finally, we show that the number of conflicts decrease to
zero as the number of available resources increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1735</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1735</id><created>2010-06-09</created><authors><author><keyname>Hassanzadeh</keyname><forenames>Mehdi M.</forenames></author><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author></authors><title>Algebraic Attack on the Alternating Step(r,s)Generator</title><categories>cs.CR cs.IT math.IT</categories><comments>5 pages, 2 figures, 2 tables, 2010 IEEE International Symposium on
  Information Theory (ISIT2010),June 13-18, 2010, Austin, Texas</comments><report-no>#1542: 'Algebraic Attack on the Alternating Step(r,s) Generator'</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Alternating Step(r,s) Generator, ASG(r,s), is a clock-controlled sequence
generator which is recently proposed by A. Kanso. It consists of three
registers of length l, m and n bits. The first register controls the clocking
of the two others. The two other registers are clocked r times (or not clocked)
(resp. s times or not clocked) depending on the clock-control bit in the first
register. The special case r=s=1 is the original and well known Alternating
Step Generator. Kanso claims there is no efficient attack against the ASG(r,s)
since r and s are kept secret. In this paper, we present an Alternating Step
Generator, ASG, model for the ASG(r,s) and also we present a new and efficient
algebraic attack on ASG(r,s) using 3(m+n) bits of the output sequence to find
the secret key with O((m^2+n^2)*2^{l+1}+ (2^{m-1})*m^3 + (2^{n-1})*n^3)
computational complexity. We show that this system is no more secure than the
original ASG, in contrast to the claim of the ASG(r,s)'s constructor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1743</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1743</id><created>2010-06-09</created><authors><author><keyname>Wachter</keyname><forenames>Antonia</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>A Basis for all Solutions of the Key Equation for Gabidulin Codes</title><categories>cs.IT math.IT</categories><comments>accepted for ISIT 2010, Austin, TX, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and prove the correctness of an efficient algorithm that provides
a basis for all solutions of a key equation in order to decode Gabidulin (G-)
codes up to a given radius tau. This algorithm is based on a symbolic
equivalent of the Euclidean Algorithm (EA) and can be applied for decoding of
G-codes beyond half the minimum rank distance. If the key equation has a unique
solution, our algorithm reduces to Gabidulin's decoding algorithm up to half
the minimum distance. If the solution is not unique, we provide a basis for all
solutions of the key equation. Our algorithm has time complexity O(tau^2) and
is a generalization of the modified EA by Bossert and Bezzateev for
Reed-Solomon codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1744</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1744</id><created>2010-06-09</created><authors><author><keyname>Albrecht</keyname><forenames>Martin R.</forenames></author><author><keyname>Pernet</keyname><forenames>Cl&#xe9;ment</forenames></author></authors><title>Efficient Decomposition of Dense Matrices over GF(2)</title><categories>cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we describe an efficient implementation of a hierarchy of
algorithms for the decomposition of dense matrices over the field with two
elements (GF(2)). Matrix decomposition is an essential building block for
solving dense systems of linear and non-linear equations and thus much research
has been devoted to improve the asymptotic complexity of such algorithms. In
this work we discuss an implementation of both well-known and improved
algorithms in the M4RI library. The focus of our discussion is on a new variant
of the M4RI algorithm - denoted MMPF in this work -- which allows for
considerable performance gains in practice when compared to the previously
fastest implementation. We provide performance figures on x86_64 CPUs to
demonstrate the viability of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1746</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1746</id><created>2010-06-09</created><authors><author><keyname>Perchet</keyname><forenames>Vianney</forenames><affiliation>EC</affiliation></author></authors><title>Calibration and Internal no-Regret with Partial Monitoring</title><categories>cs.GT cs.LG stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Calibrated strategies can be obtained by performing strategies that have no
internal regret in some auxiliary game. Such strategies can be constructed
explicitly with the use of Blackwell's approachability theorem, in an other
auxiliary game. We establish the converse: a strategy that approaches a convex
$B$-set can be derived from the construction of a calibrated strategy. We
develop these tools in the framework of a game with partial monitoring, where
players do not observe the actions of their opponents but receive random
signals, to define a notion of internal regret and construct strategies that
have no such regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1747</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1747</id><created>2010-06-09</created><updated>2011-03-15</updated><authors><author><keyname>Dietrich</keyname><forenames>Jens</forenames></author><author><keyname>McCartin</keyname><forenames>Catherine</forenames></author><author><keyname>Tempero</keyname><forenames>Ewan</forenames></author><author><keyname>Shah</keyname><forenames>Syed M. Ali</forenames></author></authors><title>On the Detection of High-Impact Refactoring Opportunities in Programs</title><categories>cs.SE</categories><comments>This paper has been submitted to a journal that does not allow open
  access</comments><acm-class>D.2.7; D.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to detect refactoring opportunities by measuring
the participation of references between types in instances of patterns
representing design flaws. This technique is validated using an experiment
where we analyse a set of 95 open-source Java programs for instances of four
patterns representing modularisation problems. It turns out that our algorithm
can detect high impact refactorings opportunities - a small number of
references such that the removal of those references removes the majority of
patterns from the program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1749</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1749</id><created>2010-06-09</created><updated>2011-02-15</updated><authors><author><keyname>Hante</keyname><forenames>Falk</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author><author><keyname>Sigalotti</keyname><forenames>Mario</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author></authors><title>Converse Lyapunov Theorems for Switched Systems in Banach and Hilbert
  Spaces</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><journal-ref>SIAM Journal on Control and Optimization, Vol. 49, Nr. 2, pp.
  752--770, 2011</journal-ref><doi>10.1137/100801561</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider switched systems on Banach and Hilbert spaces governed by
strongly continuous one-parameter semigroups of linear evolution operators. We
provide necessary and sufficient conditions for their global exponential
stability, uniform with respect to the switching signal, in terms of the
existence of a Lyapunov function common to all modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1755</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1755</id><created>2010-06-09</created><authors><author><keyname>F&#xfa;ster-Sabater</keyname><forenames>Amparo</forenames></author><author><keyname>de la Gu'\ia-Mart&#xed;nez</keyname><forenames>Dolores</forenames></author></authors><title>Simple Cellular Automata-Based Linear Models for the Shrinking Generator</title><categories>cs.CR cs.DM</categories><comments>10 pages, 0 figures</comments><msc-class>94A60, 11T71, 14G50</msc-class><acm-class>E.3; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural properties of two well-known families of keystream generators,
Shrinking Generators and Cellular Automata, have been analyzed. Emphasis is on
the equivalence of the binary sequences obtained from both kinds of generators.
In fact, Shrinking Generators (SG) can be identified with a subset of linear
Cellular Automata (mainly rule 90, rule 150 or a hybrid combination of both
rules). The linearity of these cellular models can be advantageously used in
the cryptanalysis of those keystream generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1772</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1772</id><created>2010-06-09</created><updated>2011-07-15</updated><authors><author><keyname>Barman</keyname><forenames>Kishor</forenames></author><author><keyname>Dabeer</keyname><forenames>Onkar</forenames></author></authors><title>Analysis of a Collaborative Filter Based on Popularity Amongst Neighbors</title><categories>cs.IT math.IT</categories><comments>47 pages. Submitted to IEEE Transactions on Information Theory
  (revised in July 2011). A shorter version would be presented at ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze a collaborative filter that answers the simple
question: What is popular amongst your friends? While this basic principle
seems to be prevalent in many practical implementations, there does not appear
to be much theoretical analysis of its performance. In this paper, we partly
fill this gap. While recent works on this topic, such as the low-rank matrix
completion literature, consider the probability of error in recovering the
entire rating matrix, we consider probability of an error in an individual
recommendation (bit error rate (BER)). For a mathematical model introduced in
[1],[2], we identify three regimes of operation for our algorithm (named
Popularity Amongst Friends (PAF)) in the limit as the matrix size grows to
infinity. In a regime characterized by large number of samples and small
degrees of freedom (defined precisely for the model in the paper), the
asymptotic BER is zero; in a regime characterized by large number of samples
and large degrees of freedom, the asymptotic BER is bounded away from 0 and 1/2
(and is identified exactly except for a special case); and in a regime
characterized by a small number of samples, the algorithm fails. We also
present numerical results for the MovieLens and Netflix datasets. We discuss
the empirical performance in light of our theoretical results and compare with
an approach based on low-rank matrix completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1786</identifier>
 <datestamp>2012-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1786</id><created>2010-06-09</created><authors><author><keyname>Aerts</keyname><forenames>Diederik</forenames></author></authors><title>Measuring Meaning on the World-Wide Web</title><categories>cs.AI cs.CL</categories><comments>5 pages</comments><msc-class>68Txx</msc-class><journal-ref>In D. Aerts, J. Broekaert, B. D'Hooghe and N. Note (Eds.),
  Worldviews, Science and Us: Bridging Knowledge and Its Implications for Our
  Perspectives of the World. Singapore: World Scientific (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of the 'meaning bound' of a word with respect to
another word by making use of the World-Wide Web as a conceptual environment
for meaning. The meaning of a word with respect to another word is established
by multiplying the product of the number of webpages containing both words by
the total number of webpages of the World-Wide Web, and dividing the result by
the product of the number of webpages for each of the single words. We
calculate the meaning bounds for several words and analyze different aspects of
these by looking at specific examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1788</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1788</id><created>2010-06-09</created><updated>2011-05-16</updated><authors><author><keyname>Evans</keyname><forenames>T. S.</forenames></author><author><keyname>Lambiotte</keyname><forenames>R.</forenames></author><author><keyname>Panzarasa</keyname><forenames>P.</forenames></author></authors><title>Communities and Patterns of Scientific collaboration</title><categories>physics.soc-ph cs.DL</categories><comments>17 pages. To appear in special edition of Scientometrics. Abstract on
  arXiv meta-data a shorter version of abstract on actual paper (both in
  journal and arXiv full paper version)</comments><report-no>Imperial/TP/10/TSE/01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the role of homophily and focus constraint in shaping
collaborative scientific research. First, homophily structures collaboration
when scientists adhere to a norm of exclusivity in selecting similar partners
at a higher rate than dissimilar ones. Two dimensions on which similarity
between scientists can be assessed are their research specialties and status
positions. Second, focus constraint shapes collaboration when connections among
scientists depend on opportunities for social contact. Constraint comes in two
forms, depending on whether it originates in institutional or geographic space.
Institutional constraint refers to the tendency of scientists to select
collaborators within rather than across institutional boundaries. Geographic
constraint is the principle that, when collaborations span different
institutions, they are more likely to involve scientists that are
geographically co-located than dispersed. To study homophily and focus
constraint, the paper will argue in favour of an idea of collaboration that
moves beyond formal co-authorship to include also other forms of informal
intellectual exchange that do not translate into the publication of joint work.
A community-detection algorithm is applied to the co-authorship network of the
scientists that submitted in Business and Management in the 2001 UK RAE. While
results only partially support research-based homophily, they indicate that
scientists use status positions for discriminating between potential partners
by selecting collaborators from institutions with a rating similar to their
own. Strong support is provided in favour of institutional and geographic
constraints. Scientists tend to forge intra-institutional collaborations; yet,
when they seek collaborators outside their own institutions, they tend to
select those who are in geographic proximity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1803</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1803</id><created>2010-06-09</created><authors><author><keyname>Isaksson</keyname><forenames>Eva</forenames></author></authors><title>E-accessible Astronomy Resources</title><categories>astro-ph.IM cs.HC</categories><comments>8 pages, 4 figures, to appear in Library and Information Services in
  Astronomy VI, ASP Conference Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Making online resources more accessible to physically challenged library
users is a topic deserving informed attention from astronomy librarians.
Recommendations like WCAG 2.0 standards and section 508, in the United States,
have proven valuable, and some vendors are already making their products
compliant with them. But what about the wide variety of databases and other
resources produced by astronomy information professionals themselves? Few, if
any, of these are currently compliant with accessibility standards. Here we
discuss some solutions to these accessibility challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1828</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1828</id><created>2010-06-09</created><authors><author><keyname>Plewczynski</keyname><forenames>Dariusz</forenames></author></authors><title>Landau Theory of Adaptive Integration in Computational Intelligence</title><categories>stat.ML cs.AI nlin.AO q-bio.NC q-bio.PE</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational Intelligence (CI) is a sub-branch of Artificial Intelligence
paradigm focusing on the study of adaptive mechanisms to enable or facilitate
intelligent behavior in complex and changing environments. There are several
paradigms of CI [like artificial neural networks, evolutionary computations,
swarm intelligence, artificial immune systems, fuzzy systems and many others],
each of these has its origins in biological systems [biological neural systems,
natural Darwinian evolution, social behavior, immune system, interactions of
organisms with their environment]. Most of those paradigms evolved into
separate machine learning (ML) techniques, where probabilistic methods are used
complementary with CI techniques in order to effectively combine elements of
learning, adaptation, evolution and Fuzzy logic to create heuristic algorithms
that are, in some sense, intelligent. The current trend is to develop consensus
techniques, since no single machine learning algorithms is superior to others
in all possible situations. In order to overcome this problem several
meta-approaches were proposed in ML focusing on the integration of results from
different methods into single prediction. We discuss here the Landau theory for
the nonlinear equation that can describe the adaptive integration of
information acquired from an ensemble of independent learning agents. The
influence of each individual agent on other learners is described similarly to
the social impact theory. The final decision outcome for the consensus system
is calculated using majority rule in the stationary limit, yet the minority
solutions can survive inside the majority population as the complex
intermittent clusters of opposite opinion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1858</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1858</id><created>2010-06-09</created><updated>2010-06-18</updated><authors><author><keyname>Lancho</keyname><forenames>D.</forenames></author><author><keyname>Martinez</keyname><forenames>J.</forenames></author><author><keyname>Elkouss</keyname><forenames>D.</forenames></author><author><keyname>Soto</keyname><forenames>M.</forenames></author><author><keyname>Martin</keyname><forenames>V.</forenames></author></authors><title>QKD in Standard Optical Telecommunications Networks</title><categories>quant-ph cs.CR</categories><journal-ref>Lecture Notes of the Institute for Computer Sciences, Social
  Informatics and Telecommunications Engineering. Volume 36, pp 142-149. (2010)</journal-ref><doi>10.1007/978-3-642-11731-2_18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To perform Quantum Key Distribution, the mastering of the extremely weak
signals carried by the quantum channel is required. Transporting these signals
without disturbance is customarily done by isolating the quantum channel from
any noise sources using a dedicated physical channel. However, to really profit
from this technology, a full integration with conventional network technologies
would be highly desirable. Trying to use single photon signals with others that
carry an average power many orders of magnitude bigger while sharing as much
infrastructure with a conventional network as possible brings obvious problems.
The purpose of the present paper is to report our efforts in researching the
limits of the integration of QKD in modern optical networks scenarios. We have
built a full metropolitan area network testbed comprising a backbone and an
access network. The emphasis is put in using as much as possible the same
industrial grade technology that is actually used in already installed
networks, in order to understand the throughput, limits and cost of deploying
QKD in a real network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1881</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1881</id><created>2010-06-09</created><authors><author><keyname>Ashlagi</keyname><forenames>Itai</forenames></author><author><keyname>Fischer</keyname><forenames>Felix</forenames></author><author><keyname>Kash</keyname><forenames>Ian A.</forenames></author><author><keyname>Procaccia</keyname><forenames>Ariel D.</forenames></author></authors><title>Mix and Match</title><categories>cs.GT</categories><comments>10 pages, 5 figures. Appeared in Proceedings of 11th ACM Conference
  on Electronic Commerce, Pages 305-314</comments><acm-class>F.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a matching problem on a graph where disjoint sets of vertices are
privately owned by self-interested agents. An edge between a pair of vertices
indicates compatibility and allows the vertices to match. We seek a mechanism
to maximize the number of matches despite self-interest, with agents that each
want to maximize the number of their own vertices that match. Each agent can
choose to hide some of its vertices, and then privately match the hidden
vertices with any of its own vertices that go unmatched by the mechanism. A
prominent application of this model is to kidney exchange, where agents
correspond to hospitals and vertices to donor-patient pairs. Here hospitals may
game an exchange by holding back pairs and harm social welfare. In this paper
we seek to design mechanisms that are strategyproof, in the sense that agents
cannot bene?t from hiding vertices, and approximately maximize efficiency,
i.e., produce a matching that is close in cardinality to the maximum
cardinality matching. Our main result is the design and analysis of the
eponymous Mix-and-Match mechanism; we show that this randomized mechanism is
strategyproof and provides a 2-approximation. Lower bounds establish that the
mechanism is near optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1890</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1890</id><created>2010-06-09</created><authors><author><keyname>Fakoorian</keyname><forenames>S. Ali. A.</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Optimal Power Allocation for GSVD-Based Beamforming in the MIMO Wiretap
  Channel</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers a multiple-input multiple-output (MIMO) Gaussian wiretap
channel model, where there exists a transmitter, a legitimate receiver and an
eavesdropper, each equipped with multiple antennas. Perfect secrecy is achieved
when the transmitter and the legitimate receiver can communicate at some
positive rate, while ensuring that the eavesdropper gets zero bits of
information. In this paper, the perfect secrecy capacity of the multiple
antenna MIMO wiretap channel is found for aribtrary numbers of antennas under
the assumption that the transmitter performs beamforming based on the
generalized singular value decomposition (GSVD). More precisely, the optimal
allocation of power for the GSVD-based precoder that achieves the secrecy
capacity is derived. This solution is shown to have several advantages over
prior work that considered secrecy capacity for the general MIMO Gaussian
wiretap channel under a high SNR assumption. Numerical results are presented to
illustrate the proposed theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1916</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1916</id><created>2010-06-09</created><authors><author><keyname>Futoransky</keyname><forenames>Ariel</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Notarfrancesco</keyname><forenames>Luciano</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Richarte</keyname><forenames>Gerardo</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author></authors><title>Building Computer Network Attacks</title><categories>cs.CR cs.AI</categories><comments>CoreLabs Technical Report</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work we start walking the path to a new perspective for viewing
cyberwarfare scenarios, by introducing conceptual tools (a formal model) to
evaluate the costs of an attack, to describe the theater of operations,
targets, missions, actions, plans and assets involved in cyberwarfare attacks.
We also describe two applications of this model: autonomous planning leading to
automated penetration tests, and attack simulations, allowing a system
administrator to evaluate the vulnerabilities of his network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1918</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1918</id><created>2010-06-09</created><authors><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>Core Security Technologies and Instituto Tecnologico Buenos Aires</affiliation></author><author><keyname>Burroni</keyname><forenames>Javier</forenames><affiliation>Core Security Technologies</affiliation></author></authors><title>Using Neural Networks to improve classical Operating System
  Fingerprinting techniques</title><categories>cs.CR cs.NE</categories><journal-ref>Electronic Journal of SADIO, Vol. 8, no. 1, pp. 35-47 (2008)</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present remote Operating System detection as an inference problem: given a
set of observations (the target host responses to a set of tests), we want to
infer the OS type which most probably generated these observations. Classical
techniques used to perform this analysis present several limitations. To
improve the analysis, we have developed tools using neural networks and
Statistics tools. We present two working modules: one which uses DCE-RPC
endpoints to distinguish Windows versions, and another which uses Nmap
signatures to distinguish different version of Windows, Linux, Solaris,
OpenBSD, FreeBSD and NetBSD systems. We explain the details of the topology and
inner workings of the neural networks used, and the fine tuning of their
parameters. Finally we show positive experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1919</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1919</id><created>2010-06-09</created><authors><author><keyname>Futoransky</keyname><forenames>Ariel</forenames><affiliation>Core Security Technologies</affiliation></author><author><keyname>Miranda</keyname><forenames>Fernando</forenames><affiliation>Core Security Technologies</affiliation></author><author><keyname>Orlicki</keyname><forenames>Jose</forenames><affiliation>Core Security Technologies</affiliation><affiliation>Instituto Tecnologico Buenos Aires</affiliation></author><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>Core Security Technologies</affiliation><affiliation>Instituto Tecnologico Buenos Aires</affiliation></author></authors><title>Simulating Cyber-Attacks for Fun and Profit</title><categories>cs.CR</categories><comments>10 pages, 5 figures</comments><acm-class>I.6.7; I.6.3</acm-class><journal-ref>International Conference on Simulation Tools and Techniques
  (SIMUTools) (2009)</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce a new simulation platform called Insight, created to design and
simulate cyber-attacks against large arbitrary target scenarios. Insight has
surprisingly low hardware and configuration requirements, while making the
simulation a realistic experience from the attacker's standpoint. The scenarios
include a crowd of simulated actors: network devices, hardware devices,
software applications, protocols, users, etc. A novel characteristic of this
tool is to simulate vulnerabilities (including 0-days) and exploits, allowing
an attacker to compromise machines and use them as pivoting stones to continue
the attack. A user can test and modify complex scenarios, with several
interconnected networks, where the attacker has no initial connectivity with
the objective of the attack. We give a concise description of this new
technology, and its possible uses in the security research field, such as
pentesting training, study of the impact of 0-days vulnerabilities, evaluation
of security countermeasures, and risk assessment tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1921</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1921</id><created>2010-06-09</created><authors><author><keyname>Dickerson</keyname><forenames>Matthew T.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Cloning Voronoi Diagrams via Retroactive Data Structures</title><categories>cs.CG cs.CR cs.DS</categories><comments>More complete version of paper appearing in 2010 European Symposium
  on Algorithms (ESA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of replicating a Voronoi diagram $V(S)$ of a planar
point set $S$ by making proximity queries, which are of three possible (in
decreasing order of information content): 1. the exact location of the nearest
site(s) in $S$; 2. the distance to and label(s) of the nearest site(s) in $S$;
3. a unique label for every nearest site in $S$. We provide algorithms showing
how queries of Type 1 and Type 2 allow an exact cloning of $V(S)$ with $O(n)$
queries and $O(n \log^2 n)$ processing time. We also prove that queries of Type
3 can never exactly clone $V(S)$, but we show that with $O(n
\log\frac{1}{\epsilon})$ queries we can construct an $\epsilon$-approximate
cloning of $V(S)$. In addition to showing the limits of nearest-neighbor
database security, our methods also provide one of the first natural
algorithmic applications of retroactive data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1923</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1923</id><created>2010-06-09</created><authors><author><keyname>Blelloch</keyname><forenames>Guy E.</forenames></author><author><keyname>Tangwongsan</keyname><forenames>Kanat</forenames></author></authors><title>Parallel Approximation Algorithms for Facility-Location Problems</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and analysis of parallel approximation
algorithms for facility-location problems, including $\NC$ and $\RNC$
algorithms for (metric) facility location, $k$-center, $k$-median, and
$k$-means. These problems have received considerable attention during the past
decades from the approximation algorithms community, concentrating primarily on
improving the approximation guarantees. In this paper, we ask, is it possible
to parallelize some of the beautiful results from the sequential setting?
  Our starting point is a small, but diverse, subset of results in
approximation algorithms for facility-location problems, with a primary goal of
developing techniques for devising their efficient parallel counterparts. We
focus on giving algorithms with low depth, near work efficiency (compared to
the sequential versions), and low cache complexity. Common in algorithms we
present is the idea that instead of picking only the most cost-effective
element, we make room for parallelism by allowing a small slack (e.g., a
$(1+\vareps)$ factor) in what can be selected---then, we use a clean-up step to
ensure that the behavior does not deviate too much from the sequential steps.
All the algorithms we developed are ``cache efficient'' in that the cache
complexity is bounded by $O(w/B)$, where $w$ is the work in the EREW model and
$B$ is the block size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1926</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1926</id><created>2010-06-09</created><authors><author><keyname>Kunkle</keyname><forenames>Daniel</forenames></author></authors><title>Roomy: A System for Space Limited Computations</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are numerous examples of problems in symbolic algebra in which the
required storage grows far beyond the limitations even of the distributed RAM
of a cluster. Often this limitation determines how large a problem one can
solve in practice. Roomy provides a minimally invasive system to modify the
code for such a computation, in order to use the local disks of a cluster or a
SAN as a transparent extension of RAM.
  Roomy is implemented as a C/C++ library. It provides some simple data
structures (arrays, unordered lists, and hash tables). Some typical programming
constructs that one might employ in Roomy are: map, reduce, duplicate
elimination, chain reduction, pair reduction, and breadth-first search. All
aspects of parallelism and remote I/O are hidden within the Roomy library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1930</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1930</id><created>2010-06-09</created><authors><author><keyname>Aerts</keyname><forenames>Diederik</forenames></author><author><keyname>Czachor</keyname><forenames>Marek</forenames></author><author><keyname>D'Hooghe</keyname><forenames>Bart</forenames></author><author><keyname>Sozzo</keyname><forenames>Sandro</forenames></author></authors><title>The Pet-Fish problem on the World-Wide Web</title><categories>cs.AI cs.CL</categories><comments>8 pages</comments><msc-class>68Txx</msc-class><journal-ref>Proceedings of the AAAI Fall Symposium (FS-10-08), Quantum
  Informatics for Cognitive, Social, and Semantic Processes, pp. 17-21, (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify the presence of Pet-Fish problem situations and the corresponding
Guppy effect of concept theory on the World-Wide Web. For this purpose, we
introduce absolute weights for words expressing concepts and relative weights
between words expressing concepts, and the notion of 'meaning bound' between
two words expressing concepts, making explicit use of the conceptual structure
of the World-Wide Web. The Pet-Fish problem occurs whenever there are exemplars
- in the case of Pet and Fish these can be Guppy or Goldfish - for which the
meaning bound with respect to the conjunction is stronger than the meaning
bounds with respect to the individual concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1937</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1937</id><created>2010-06-09</created><updated>2010-07-23</updated><authors><author><keyname>Cooper</keyname><forenames>S. Barry</forenames></author><author><keyname>Panangaden</keyname><forenames>Prakash</forenames></author><author><keyname>Kashefi</keyname><forenames>Elham</forenames></author></authors><title>Proceedings Sixth Workshop on Developments in Computational Models:
  Causality, Computation, and Physics</title><categories>quant-ph cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010</journal-ref><doi>10.4204/EPTCS.26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DCM 2010 provides a forum for ideas about new computing means and models,
with a particular emphasis in 2010 on computational and causal models related
to physics and biology. We believe that bringing together different approaches
- in a community with the strong foundational background characteristic of FLoC
- results in inspirational cross-boundary exchanges, and innovative further
research. Day two of this pre-FLoC 2010 workshop is given over to physics and
quantum related computation. The content of day one is more typical of previous
DCM workshops - covering a full spectrum of topics related to the development
of new computational models or new features for traditional computational
models. DCM 2010 was designed to foster interactions, and provide a forum for
presenting new ideas and work in progress. It is also intended to enable
newcomers to learn about current research in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1948</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1948</id><created>2010-06-10</created><authors><author><keyname>Hong</keyname><forenames>Dowon</forenames></author><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author></authors><title>Augmented Rotation-Based Transformation for Privacy-Preserving Data
  Clustering</title><categories>cs.CR</categories><comments>11 pages, 11 figures, and 6 tables</comments><journal-ref>ETRI Journal, vol.32, no.3, June 2010, pp.351-361</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple rotation-based transformation (MRBT) was introduced recently for
mitigating the apriori-knowledge independent component analysis (AK-ICA) attack
on rotation-based transformation (RBT), which is used for privacy-preserving
data clustering. MRBT is shown to mitigate the AK-ICA attack but at the expense
of data utility by not enabling conventional clustering. In this paper, we
extend the MRBT scheme and introduce an augmented rotation-based transformation
(ARBT) scheme that utilizes linearity of transformation and that both mitigates
the AK-ICA attack and enables conventional clustering on data subsets
transformed using the MRBT. In order to demonstrate the computational
feasibility aspect of ARBT along with RBT and MRBT, we develop a toolkit and
use it to empirically compare the different schemes of privacy-preserving data
clustering based on data transformation in terms of their overhead and privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1951</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1951</id><created>2010-06-10</created><authors><author><keyname>Cassez</keyname><forenames>Franck</forenames></author></authors><title>Timed Games for Computing Worst-Case Execution-Times</title><categories>cs.SE cs.LO</categories><comments>NICTA Research Report, Sydney, Australia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a framework for computing upper bounds yet
accurate WCET for hardware platforms with caches and pipelines. The methodology
we propose consists of 3 steps: 1) given a program to analyse, compute an
equivalent (WCET-wise) abstract program; 2) build a timed game by composing
this abstract program with a network of timed automata modeling the
architecture; and 3) compute the WCET as the optimal time to reach a winning
state in this game. We demonstrate the applicability of our framework on
standard benchmarks for an ARM9 processor with instruction and data caches, and
compute the WCET with UPPAAL-TiGA. We also show that this framework can easily
be extended to take into account dynamic changes in the speed of the processor
during program execution. %
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1955</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1955</id><created>2010-06-10</created><authors><author><keyname>Shrivastava</keyname><forenames>Suprika Vasudeva</forenames></author><author><keyname>Date</keyname><forenames>Hema</forenames></author></authors><title>Distributed Agile Software Development: A Review</title><categories>cs.SE</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering,Volume 1, Issue 1,
  p10-17, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution of software development is becoming more and more common in
order to save the production cost and reduce the time to market. Large
geographical distance, different time zones and cultural differences in
distributed software development (DSD) leads to weak communication which
adversely affects the project. Using agile practices for distributed
development is also gaining momentum in various organizations to increase the
quality and performance of the project. This paper explores the intersection of
these two significant trends for software development i.e. DSD and agile. We
discuss the challenges faced by geographically distributed agile teams and
proven practices to address these issues, which will help in building a
successful distributed team.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1956</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1956</id><created>2010-06-10</created><updated>2010-06-11</updated><authors><author><keyname>Trivedi</keyname><forenames>Animesh Kr</forenames></author><author><keyname>Arora</keyname><forenames>Rajan</forenames></author><author><keyname>Kapoor</keyname><forenames>Rishi</forenames></author><author><keyname>Sanyal</keyname><forenames>Sudip</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A Semi-distributed Reputation Based Intrusion Detection System for
  Mobile Adhoc Networks</title><categories>cs.NI cs.MA</categories><comments>Adhoc Networking, Security, Promiscuous Mode, Reputation Based
  Intrusion Detection System</comments><journal-ref>Trivedi et al., &quot;A Semi-distributed Reputation Based Intrusion
  Detection System for Mobile Adhoc Networks&quot;. Journal of Information Assurance
  and Security (JIAS), Volume 1, Issue 4, December 2006, pp. 265-274</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A Mobile Adhoc Network (MANET) is a cooperative engagement of a collection of
mobile nodes without any centralized access point or infrastructure to
coordinate among the peers. The underlying concept of coordination among nodes
in a cooperative MANET has induced in them a vulnerability to attacks due to
issues like lack of fixed infrastructure, dynamically changing network
topology, cooperative algorithms, lack of centralized monitoring and management
point, and lack of a clear line of defense. We propose a semi-distributed
approach towards Reputation Based Intrusion Detection System (IDS) that
combines with the DSR routing protocol for strengthening the defense of a
MANET. Our system inherits the features of reputation from human behavior,
hence making the IDS socially inspired. It has a semi-distributed architecture
as the critical observation results of the system are neither spread globally
nor restricted locally. The system assigns maximum weightage to self
observation by nodes for updating any reputation values, thus avoiding the need
of a trust relationship between nodes. Our system is also unique in the sense
that it features the concepts of Redemption and Fading with a robust Path
Manager and Monitor system. Simulation studies show that DSR fortified with our
system outperforms normal DSR in terms of the packet delivery ratio and routing
overhead even when up to half of nodes in the network behave as malicious.
Various parameters introduced such as timing window size, reputation update
values, congestion parameter and other thresholds have been optimized over
several simulation test runs of the system. By combining the semi-distributed
architecture and other design essentials like path manager, monitor module,
redemption and fading concepts; Our system proves to be robust enough to
counter most common attacks in MANETs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1965</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1965</id><created>2010-06-10</created><authors><author><keyname>Chandra</keyname><forenames>Shekhar S.</forenames></author><author><keyname>Normand</keyname><forenames>Nicolas</forenames></author><author><keyname>Kingston</keyname><forenames>Andrew</forenames></author><author><keyname>Gu&#xe9;don</keyname><forenames>Jeanpierre</forenames></author><author><keyname>Svalbe</keyname><forenames>Imants</forenames></author></authors><title>Fast Mojette Transform for Discrete Tomography</title><categories>physics.med-ph cs.DM math.CO</categories><comments>22 pages, 13 figures, Submitted to Elsevier Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm for reconstructing a two dimensional object from a set of one
dimensional projected views is presented that is both computationally exact and
experimentally practical. The algorithm has a computational complexity of O(n
log2 n) with n = N^2 for an NxN image, is robust in the presence of noise and
produces no artefacts in the reconstruction process, as is the case with
conventional tomographic methods. The reconstruction process is approximation
free because the object is assumed to be discrete and utilizes fully discrete
Radon transforms. Noise in the projection data can be suppressed further by
introducing redundancy in the reconstruction. The number of projections
required for exact reconstruction and the response to noise can be controlled
without comprising the digital nature of the algorithm. The digital projections
are those of the Mojette Transform, a form of discrete linogram. A simple
analytical mapping is developed that compacts these projections exactly into
symmetric periodic slices within the Discrete Fourier Transform. A new digital
angle set is constructed that allows the periodic slices to completely fill all
of the objects Discrete Fourier space. Techniques are proposed to acquire these
digital projections experimentally to enable fast and robust two dimensional
reconstructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1990</identifier>
 <datestamp>2012-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1990</id><created>2010-06-10</created><updated>2012-06-11</updated><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>Minimizing a sum of submodular functions</title><categories>cs.DS</categories><comments>accepted to &quot;Discrete Applied Mathematics&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of minimizing a function represented as a sum of
submodular terms. We assume each term allows an efficient computation of {\em
exchange capacities}. This holds, for example, for terms depending on a small
number of variables, or for certain cardinality-dependent terms.
  A naive application of submodular minimization algorithms would not exploit
the existence of specialized exchange capacity subroutines for individual
terms. To overcome this, we cast the problem as a {\em submodular flow} (SF)
problem in an auxiliary graph, and show that applying most existing SF
algorithms would rely only on these subroutines.
  We then explore in more detail Iwata's capacity scaling approach for
submodular flows (Math. Programming, 76(2):299--308, 1997). In particular, we
show how to improve its complexity in the case when the function contains
cardinality-dependent terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1993</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1993</id><created>2010-06-10</created><authors><author><keyname>Moskwa</keyname><forenames>Krzysztof</forenames></author><author><keyname>Rossa</keyname><forenames>Piotr</forenames></author></authors><title>Rozw\'oj bibliotek cyfrowych i repozytori\'ow elektronicznych na Dolnym
  Slasku w latach 2004-2008 / Development of Digital Libraries and Electronic
  Repositories in Lower Silesia in Years 2004-2008</title><categories>cs.DL</categories><comments>12 pages in Polish, 4 tables; Komputerowe wspomaganie bada\'n
  naukowych XVI / The Computer-Aided Scientific Research XVI</comments><journal-ref>Komputerowe wspomaganie badan naukowych XVI = The Computer-Aided
  Scientific Research XVI / red. Jan Zarzycki. Wroclaw, 2009. pp. 15-26, 4
  tab., Summ. (Prace Wroclawskiego Towarzystwa Naukowego., ISSN 0084-3024; nr
  215)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In following elaboration were presented digital libraries and electronic
repositories operating in Lower Silesia region (of Poland) in years 2004-2008.
General description of character and size of their collections was presented,
as well as standards and methods of digital collections management and
juridical aspects of this management. Potential of usage of digital collections
in regional scientific researches was described.
  -----
  W referacie przedstawiono biblioteki cyfrowe i repozytoria elektroniczne
funkcjonujace na Dolnym Slasku w latach 2004-2008. Scharakteryzowano og\'olnie
ich zawarto\'s\'c i wielko\'s\'c, zaprezentowano standardy i systemy
zarzadzania kolekcjami cyfrowymi oraz om\'owiono uwarunkowania prawne
towarzyszace zarzadzaniu zasobami cyfrowymi. Wskazano mo\.zliwo\'sci
wykorzystania kolekcji cyfrowych w badaniach naukowych realizowanych w
regionie.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.1998</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.1998</id><created>2010-06-10</created><updated>2011-05-31</updated><authors><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames></author></authors><title>Geodesic diameter of a polygonal domain in O(n^4 log n) time</title><categories>cs.CG cs.DS</categories><comments>NOTE: It has turned out that, unfortunately, Lemma 2 does not hold,
  which renders the main result incorrect</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the geodesic diameter of a polygonal domain with n vertices can
be computed in O(n^4 log n) time by considering O(n^3) candidate diameter
endpoints; the endpoints are a subset of vertices of the overlay of shortest
path maps from vertices of the domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2002</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2002</id><created>2010-06-10</created><updated>2011-09-28</updated><authors><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Kochman</keyname><forenames>Yuval</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>Colored Gaussian Multiple Descriptions: Spectral-Domain Characterization
  and Time-Domain Design</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. For clarity,
  sections has been rewritten and several propositions has been clarified and
  extended</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that Shannon's rate-distortion function (RDF) in the colored
quadratic Gaussian (QG) case, can be parametrized via a single Lagrangian
variable (the &quot;water level&quot; in the reverse water filling solution). In this
work, we show that the symmetric colored QG multiple-description (MD) RDF in
the case of two descriptions, can be parametrized via two Lagrangian variables.
To establish this result, we use two key ideas. First, we propose a new
representation for the MD test channel, and show that the minimum mutual
information rate across this channel coincide with the QG MD RDF. Second, we
use variational calculus to obtain a spectral domain representation of the test
channel's optimal side and central distortion spectra given the source spectral
density and the side and central distortion constraints. The distortion spectra
are specified via two Lagrangian parameters, which control the trade-off
between the side distortion, the central distortion, and the coding rate.We
also show that the symmetric colored QG MD RDF can be achieved by noise-shaped
predictive coding, dithered quantization, and memoryless entropy coding. In
particular, we show that the proposed MD test channel can be materialized by
embedding two source prediction loops, one for each description, within a
common noise shaping loop whose parameters are explicitly found from the
spectral-domain characterization. The source prediction loops exploit the
source memory, and thus reduce the coding rate. The noise-shaping loop,
controls the trade-off between the side and the central distortions by shaping
the quantization noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2004</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2004</id><created>2010-06-10</created><updated>2010-06-21</updated><authors><author><keyname>Bocherer</keyname><forenames>Georg</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Throughput, Bit-Cost, Network State Information: Tradeoffs in
  Cooperative CSMA Protocols</title><categories>cs.IT math.IT</categories><comments>Some typos in v1 were corrected, to be presented at ISWCS 2010 in
  York, United Kingdom</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless local area networks, spatially varying channel conditions result
in a severe performance discrepancy between different nodes in the uplink,
depending on their position. Both throughput and energy expense are affected.
Cooperative protocols were proposed to mitigate these discrepancies. However,
additional network state information (NSI) from other nodes is needed to enable
cooperation. The aim of this work is to assess how NSI and the degree of
cooperation affect throughput and energy expenses. To this end, a CSMA protocol
called fairMAC is defined, which allows to adjust the amount of NSI at the
nodes and the degree of cooperation among the nodes in a distributed manner. By
analyzing the data obtained by Monte Carlo simulations with varying protocol
parameters for fairMAC, two fundamental tradeoffs are identified: First, more
cooperation leads to higher throughput, but also increases energy expenses.
Second, using more than one helper increases throughput and decreases energy
expenses, however, more NSI has to be acquired by the nodes in the network. The
obtained insights are used to increase the lifetime of a network. While full
cooperation shortens the lifetime compared to no cooperation at all, lifetime
can be increased by over 25% with partial cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2006</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2006</id><created>2010-06-10</created><authors><author><keyname>Sasoglu</keyname><forenames>Eren</forenames></author></authors><title>An entropy inequality for q-ary random variables and its application to
  channel polarization</title><categories>cs.IT math.IT</categories><comments>To be presented at the IEEE 2010 International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that given two copies of a q-ary input channel $W$, where q is
prime, it is possible to create two channels $W^-$ and $W^+$ whose symmetric
capacities satisfy $I(W^-)\le I(W)\le I(W^+)$, where the inequalities are
strict except in trivial cases. This leads to a simple proof of channel
polarization in the q-ary case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2022</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2022</id><created>2010-06-10</created><authors><author><keyname>Permuter</keyname><forenames>Haim</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shlomo</keyname><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname></author><author><keyname>Somekh-Baruch</keyname><forenames>Anelia</forenames></author></authors><title>Message and state cooperation in multiple access channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the capacity of a multiple access channel with cooperating
encoders where partial state information is known to each encoder and full
state information is known to the decoder. The cooperation between the encoders
has a two-fold purpose: to generate empirical state coordination between the
encoders, and to share information about the private messages that each encoder
has. For two-way cooperation, this two-fold purpose is achieved by
double-binning, where the first layer of binning is used to generate the state
coordination similarly to the two-way source coding, and the second layer of
binning is used to transmit information about the private messages. The
complete result provides the framework and perspective for addressing a complex
level of cooperation that mixes states and messages in an optimal way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2048</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2048</id><created>2010-06-10</created><authors><author><keyname>Krishnan</keyname><forenames>Sundaresan</forenames></author><author><keyname>Chaporkar</keyname><forenames>Prasanna</forenames></author></authors><title>Stochastic Approximation Algorithm for Optimal Throughput Performance of
  Wireless LANs</title><categories>cs.NI</categories><comments>16 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Throughput improvement of the Wireless LANs has been a constant area of
research. Most of the work in this area, focuses on designing throughput
optimal schemes for fully connected networks (no hidden nodes). But, we
demonstrate that the proposed schemes, though perform optimally in fully
connected network, achieve significantly lesser throughput even than that of
standard IEEE 802.11 in a network with hidden nodes. This motivates the need
for designing schemes that provide near optimal performance even when hidden
nodes are present. The primary reason for the failure of existing protocols in
the presence of hidden nodes is that these protocols are based on the model
developed by Bianchi. However this model does not hold when hidden nodes exist.
Moreover, analyzing networks with hidden nodes is still an open problem. Thus,
designing throughput optimal schemes in networks with hidden nodes is
particularly challenging. The novelty of our approach is that it is not based
on any underlying mathematical model, rather it directly tunes the control
variables so as to maximize the throughput. We demonstrate that this model
independent approach achieves maximum throughput in networks with hidden
terminals as well. Apart from this major contribution, we present stochastic
approximation based algorithms for achieving weighted fairness in a connected
networks. We also present a throughput optimal exponential backoff based random
access algorithm. We demonstrate that the exponential backoff based scheme may
outperform an optimal p-persistent scheme in networks with hidden terminals.
This demonstrates the merit of exponential backoff based random access schemes
which was deemed unnecessary by results shown by Bianchi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2055</identifier>
 <datestamp>2012-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2055</id><created>2010-06-10</created><updated>2012-04-13</updated><authors><author><keyname>Liu</keyname><forenames>Yipeng</forenames></author><author><keyname>Wan</keyname><forenames>Qun</forenames></author></authors><title>Enhanced Compressive Wideband Frequency Spectrum Sensing for Dynamic
  Spectrum Access</title><categories>cs.IT math.IT</categories><comments>23 pages, 6 figures, 4 table. arXiv admin note: substantial text
  overlap with arXiv:1005.1804</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wideband spectrum sensing detects the unused spectrum holes for dynamic
spectrum access (DSA). Too high sampling rate is the main problem. Compressive
sensing (CS) can reconstruct sparse signal with much fewer randomized samples
than Nyquist sampling with high probability. Since survey shows that the
monitored signal is sparse in frequency domain, CS can deal with the sampling
burden. Random samples can be obtained by the analog-to-information converter.
Signal recovery can be formulated as an L0 norm minimization and a linear
measurement fitting constraint. In DSA, the static spectrum allocation of
primary radios means the bounds between different types of primary radios are
known in advance. To incorporate this a priori information, we divide the whole
spectrum into subsections according to the spectrum allocation policy. In the
new optimization model, the minimization of the L2 norm of each subsection is
used to encourage the cluster distribution locally, while the L0 norm of the L2
norms is minimized to give sparse distribution globally. Because the L0/L2
optimization is not convex, an iteratively re-weighted L1/L2 optimization is
proposed to approximate it. Simulations demonstrate the proposed method
outperforms others in accuracy, denoising ability, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2063</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2063</id><created>2010-06-10</created><authors><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author><author><keyname>Huang</keyname><forenames>Chien-Chung</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author><author><keyname>Wahlstrom</keyname><forenames>Magnus</forenames></author></authors><title>Parameterized Two-Player Nash Equilibrium</title><categories>cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computation of Nash equilibria in a two-player normal form game
from the perspective of parameterized complexity. Recent results proved
hardness for a number of variants, when parameterized by the support size. We
complement those results, by identifying three cases in which the problem
becomes fixed-parameter tractable. These cases occur in the previously studied
settings of sparse games and unbalanced games as well as in the newly
considered case of locally bounded treewidth games that generalizes both these
two cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2074</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2074</id><created>2010-06-10</created><authors><author><keyname>Warnars</keyname><forenames>H. L. H Spits</forenames></author></authors><title>Efektifitas Teknologi Informasi Dalam Proses Belajar Mengajar Pada
  Universitas Budi Luhur</title><categories>cs.OH</categories><comments>4 pages</comments><journal-ref>The 2nd National Seminar Information Technology Application
  (SNATI) 2006, University of Islam Indonesia, pp. A23-A26, Yogyakarta, 17 June
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general, however, IT will empower students to have greater control over
the learning process, with all the benefits associated with active learning and
personal responsibility. Not only will students decide when to learn and how to
learn, increasingly they will also decide what to learn and how that learning
is to be certified. Traditionally, higher education institutions have combined
several functions in their faculty. Faculty are architects as they design
learning programs; navigators as they help advise students in their course of
study; instructors when they lecture; mentors when they help students form a
sense of connectedness to the world; and evaluators and certifiers as they
decide to grant students grades or degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2077</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2077</id><created>2010-06-10</created><authors><author><keyname>Warnars</keyname><forenames>H. L. H Spits</forenames></author></authors><title>Multidimensi Pada Data Warehouse Dengan Menggunakan Rumus Kombinasi</title><categories>cs.DB</categories><comments>6 pages</comments><acm-class>H.2.7</acm-class><journal-ref>The 2nd National Seminar Information Technology Application
  (SNATI) 2006, University of Islam Indonesia, pp. J1-J6, Yogyakarta, 17 June
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional in data warehouse is a compulsion and become the most
important for information delivery, without multidimensional data warehouse is
incomplete. Multidimensional give the able to analyze business measurement in
many different ways. Multidimensional is also synonymous with online analytical
processing (OLAP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2082</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2082</id><created>2010-06-10</created><authors><author><keyname>Anwar</keyname><forenames>Chairil</forenames></author><author><keyname>Warnars</keyname><forenames>H. L. H Spits</forenames></author></authors><title>Sistem Informasi Akademik Online Sebagai Penunjang Sistem Perkuliahan</title><categories>cs.CY</categories><comments>5 pages</comments><acm-class>K.3.2</acm-class><journal-ref>Information System National Conference (KNSI) 2009, University of
  Islam Indonesia, Yogyakarta, 17 Januari 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of Internet technology give a chance for application in all
kind of humans activity include education specially for higher education in
university in order to increase education quality. In this paper we will
discuss about the importance of the elements which must be fulfilled when we
build the online academic application with web technology which will help
teaching process in university. Also we will discuss to implement open source
software as foundation in order to deploy the information system with low cost
without losing the performance. In the future assembling internet technology on
education and training will be need in order to enhancement and distribution
education quality, specially in Indonesia where has many islands separate with
sea and mountain. Students and faculty will enjoy access to multiple resources
from one location, delivering search results with a range of content including
encyclopedia articles, multimedia, related Web sites, magazines, and much more.
Enables schools to implement an online academic program. It equips schools to
host online courses, conduct live and blog-style communication between faculty
and students, track grades, automate test scoring, store course materials, and
much more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2085</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2085</id><created>2010-06-10</created><authors><author><keyname>Pardede</keyname><forenames>Fedro Antonius</forenames></author><author><keyname>Warnars</keyname><forenames>H. L. H Spits</forenames></author></authors><title>Pemanfaatan Teknologi Sistem Informasi Geografis Untuk Menunjang
  Pembangunan Daerah</title><categories>cs.OH</categories><comments>6 pages</comments><acm-class>J.1</acm-class><journal-ref>National seminar University of Budi Luhur 2009, University of Budi
  Luhur, Jakarta, 14-15 August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The territory development will depend on that territory itself, where the
word of autonomy for each province or territory will give contribution how
Indonesian will responsible for development their territory. In order to
develop territory, the information technology can be used as a boost or tools
to give and deliver the best information and Geographic Information System is
one of the information technology tools which can be used to push every each
territory to speed the territory development. As a tool Geographic Information
System has an ability to save, process, analysis and deliver information right
in time and help the decision maker to make better decision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2086</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2086</id><created>2010-06-10</created><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Kerman</keyname><forenames>Ely</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>A Geometric Approach to Low-Rank Matrix Completion</title><categories>cs.IT math.IT math.NA</categories><comments>10 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The low-rank matrix completion problem can be succinctly stated as follows:
given a subset of the entries of a matrix, find a low-rank matrix consistent
with the observations. While several low-complexity algorithms for matrix
completion have been proposed so far, it remains an open problem to devise
search procedures with provable performance guarantees for a broad class of
matrix models. The standard approach to the problem, which involves the
minimization of an objective function defined using the Frobenius metric, has
inherent difficulties: the objective function is not continuous and the
solution set is not closed. To address this problem, we consider an
optimization procedure that searches for a column (or row) space that is
geometrically consistent with the partial observations. The geometric objective
function is continuous everywhere and the solution set is the closure of the
solution set of the Frobenius metric. We also preclude the existence of local
minimizers, and hence establish strong performance guarantees, for special
completion scenarios, which do not require matrix incoherence or large matrix
size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2088</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2088</id><created>2010-06-10</created><authors><author><keyname>H</keyname><forenames>Spits Warnars H. L.</forenames></author></authors><title>Classification rule with simple select SQL statement</title><categories>cs.DB</categories><comments>6 pages</comments><acm-class>H.2.8</acm-class><journal-ref>National seminar University of Budi Luhur 2010, University of Budi
  Luhur, Jakarta, 5 August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple sql statement can be used to search learning or rule in relational
database for data mining purposes particularly for classification rule. With
just only one simple sql statement, characteristic and classification rule can
be created simultaneously. Collaboration sql statement with any other
application software will increase the ability for creating t-weight as
measurement the typicality of each record in the characteristic rule and
d-weight as measurement the discriminating behavior of the learned
classification/discriminant rule, specifically for further generalization in
characteristic rule. Handling concept hierarchy into tables based on concept
tree will influence for the successful simple sql statement and by knowing the
right standard knowledge to transform each of concept tree in concept hierarchy
into one table as to transform concept hierarchy into table, the simple sql
statement can be run properly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2099</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2099</id><created>2010-06-10</created><authors><author><keyname>Tentyukov</keyname><forenames>M.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author><author><keyname>Vollinga</keyname><forenames>J.</forenames></author></authors><title>Parallel versions of the symbolic manipulation system FORM</title><categories>hep-ph cs.SC</categories><journal-ref>PoS ACAT2010:072,2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The symbolic manipulation program FORM is specialized to handle very large
algebraic expressions. Some specific features of its internal structure make
FORM very well suited for parallelization.
  We have now two parallel versions of FORM, one is based on POSIX threads and
is optimal for modern multicore computers while another one uses MPI and can be
used to parallelize FORM on clusters and Massive Parallel Processing systems.
Most existing FORM programs will be able to take advantage of the parallel
execution without the need for modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2104</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2104</id><created>2010-06-10</created><authors><author><keyname>H</keyname><forenames>Spits Warnars H. L.</forenames></author></authors><title>Perbandingan Shell Unix</title><categories>cs.OS</categories><comments>21 Pages</comments><acm-class>D.4.0</acm-class><journal-ref>Widya, Vol 21,No. 230, pp. 9-15, November 2004</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Is it possible for an Information Technology [IT] product to be both mature
and state-of-theart at the same time? In the case of the UNIX system, the
answer is an unqualified &quot;Yes.&quot; The UNIX system has continued to develop over
the past twenty-five years. In millions of installations running on nearly
every hardware platform made, the UNIX system has earned its reputation for
stability and scalability. Over the years, UNIX system suppliers have steadily
assimilated new technologies so that UNIX systems today provide more
functionality as any other operating system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2107</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2107</id><created>2010-06-10</created><authors><author><keyname>H</keyname><forenames>Spits Warnars H. L.</forenames></author></authors><title>Pembobolan website KPU (Komisi Pemilihan Umum) Apakah melanggar UU RI
  no.36 tahun 1999 tentang telekomunikasi ?</title><categories>cs.OH</categories><comments>7 pages</comments><journal-ref>Journal Budi Luhur Information Technology (BIT), Vol.2, No.1 April
  2005</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Information Technology KPU (Indonesia Electoral Commision) is a project in
supporting democratization process in Indonesia. It is a part of General
Election program of KPU-Indonesian Government. The aim of IT KPU is to build
the transparency of the ballot result to the public (citizen and international
world) and as the embrio of e government in Indonesia. It also has the aim for
influence the citizen with Information Technology and the use of computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2117</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2117</id><created>2010-06-10</created><updated>2010-11-11</updated><authors><author><keyname>Hare</keyname><forenames>Kevin G.</forenames></author><author><keyname>Morris</keyname><forenames>Ian D.</forenames></author><author><keyname>Sidorov</keyname><forenames>Nikita</forenames></author><author><keyname>Theys</keyname><forenames>Jacques</forenames></author></authors><title>An explicit counterexample to the Lagarias-Wang finiteness conjecture</title><categories>math.OC cs.DM math.DS math.RA</categories><comments>27 pages, 2 figures</comments><msc-class>15A18, 15A60, 37B10, 65K10, 68R15</msc-class><journal-ref>Advances in Mathematics 226 (2011), 4667-4701</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The joint spectral radius of a finite set of real $d \times d$ matrices is
defined to be the maximum possible exponential rate of growth of long products
of matrices drawn from that set. A set of matrices is said to have the
\emph{finiteness property} if there exists a periodic product which achieves
this maximal rate of growth. J.C. Lagarias and Y. Wang conjectured in 1995 that
every finite set of real $d \times d$ matrices satisfies the finiteness
property. However, T. Bousch and J. Mairesse proved in 2002 that
counterexamples to the finiteness conjecture exist, showing in particular that
there exists a family of pairs of $2 \times 2$ matrices which contains a
counterexample. Similar results were subsequently given by V.D. Blondel, J.
Theys and A.A. Vladimirov and by V.S. Kozyakin, but no explicit counterexample
to the finiteness conjecture has so far been given. The purpose of this paper
is to resolve this issue by giving the first completely explicit description of
a counterexample to the Lagarias-Wang finiteness conjecture. Namely, for the
set \[ \mathsf{A}_{\alpha_*}:= \{({cc}1&amp;1\\0&amp;1), \alpha_*({cc}1&amp;0\\1&amp;1)\}\] we
give an explicit value of \alpha_* \simeq
0.749326546330367557943961948091344672091327370236064317358024...] such that
$\mathsf{A}_{\alpha_*}$ does not satisfy the finiteness property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2125</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2125</id><created>2010-06-10</created><updated>2010-08-22</updated><authors><author><keyname>Karsai</keyname><forenames>M.</forenames></author><author><keyname>Kivel&#xe4;</keyname><forenames>M.</forenames></author><author><keyname>Pan</keyname><forenames>R. K.</forenames></author><author><keyname>Kaski</keyname><forenames>K.</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J.</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>A. -L.</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>J.</forenames></author></authors><title>Small But Slow World: How Network Topology and Burstiness Slow Down
  Spreading</title><categories>physics.soc-ph cs.SI nlin.AO physics.bio-ph</categories><journal-ref>Phys. Rev. E 83, 025102(R) (2011)</journal-ref><doi>10.1103/PhysRevE.83.025102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication networks show the small-world property of short paths, but the
spreading dynamics in them turns out slow. We follow the time evolution of
information propagation through communication networks by using the SI model
with empirical data on contact sequences. We introduce null models where the
sequences are randomly shuffled in different ways, enabling us to distinguish
between the contributions of different impeding effects. The slowing down of
spreading is found to be caused mostly by weight-topology correlations and the
bursty activity patterns of individuals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2155</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2155</id><created>2010-06-10</created><authors><author><keyname>McGowan</keyname><forenames>Martin J.</forenames><suffix>III</suffix></author><author><keyname>Anderson</keyname><forenames>William L.</forenames></author></authors><title>Software Must Move! A Description of the Software Assembly Line</title><categories>cs.SE</categories><journal-ref>Proceedings of the IEEE SOFTFAIR -- A CONFERENCE ON SOFTWARE
  DEVELOPMENT TOOLS, TECHNIQUES, and ALTERNATIVES, 1983</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a set of tools for automating and controlling the
development and maintenance of software systems. The mental model is a software
assembly line. Program design and construction take place at individual
programmer workstations. Integration of individual software components takes
place at subsequent stations on the assembly line. Software is moved
automatically along the assembly line toward final packaging. Software under
construction or maintenance is divided into packages. Each package of software
is composed of a recipe and ingredients. Some new terms are introduced to
describe the ingredients. The recipe specifies how ingredients are transformed
into products. The benefits of the Software Assembly Line for development,
maintenance, and management of large-scale computer systems are explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2156</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2156</id><created>2010-06-10</created><authors><author><keyname>Menon</keyname><forenames>Aditya Krishna</forenames></author><author><keyname>Elkan</keyname><forenames>Charles</forenames></author></authors><title>Dyadic Prediction Using a Latent Feature Log-Linear Model</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In dyadic prediction, labels must be predicted for pairs (dyads) whose
members possess unique identifiers and, sometimes, additional features called
side-information. Special cases of this problem include collaborative filtering
and link prediction. We present the first model for dyadic prediction that
satisfies several important desiderata: (i) labels may be ordinal or nominal,
(ii) side-information can be easily exploited if present, (iii) with or without
side-information, latent features are inferred for dyad members, (iv) it is
resistant to sample-selection bias, (v) it can learn well-calibrated
probabilities, and (vi) it can scale to very large datasets. To our knowledge,
no existing method satisfies all the above criteria. In particular, many
methods assume that the labels are ordinal and ignore side-information when it
is present. Experimental results show that the new method is competitive with
state-of-the-art methods for the special cases of collaborative filtering and
link prediction, and that it makes accurate predictions on nominal data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2162</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2162</id><created>2010-06-10</created><authors><author><keyname>Huh</keyname><forenames>Hoon</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Moon</keyname><forenames>Sung-Hyun</forenames></author><author><keyname>Kim</keyname><forenames>Young-Tae</forenames></author><author><keyname>Lee</keyname><forenames>Inkyu</forenames></author></authors><title>Multi-Cell MIMO Downlink with Cell Cooperation and Fair Scheduling: a
  Large-System Limit Analysis</title><categories>cs.IT math.IT</categories><comments>29 pages, 5 figures, submitted to IEEE Trans. on Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the downlink of a cellular network with multiple cells and
multi-antenna base stations, including a realistic distance-dependent pathloss
model, clusters of cooperating cells, and general &quot;fairness&quot; requirements.
Beyond Monte Carlo simulation, no efficient computation method to evaluate the
ergodic throughput of such systems has been presented so far. We propose an
analytic solution based on the combination of large random matrix results and
convex optimization. The proposed method is computationally much more efficient
than Monte Carlo simulation and provides surprisingly accurate approximations
for the actual finite-dimensional systems, even for a small number of users and
base station antennas. Numerical examples include 2-cell linear and
three-sectored 7-cell planar layouts, with no inter-cell cooperation, sector
cooperation, or full inter-cell cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2165</identifier>
 <datestamp>2011-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2165</id><created>2010-06-10</created><updated>2011-06-08</updated><authors><author><keyname>Deisenroth</keyname><forenames>Marc Peter</forenames></author><author><keyname>Ohlsson</keyname><forenames>Henrik</forenames></author></authors><title>A Probabilistic Perspective on Gaussian Filtering and Smoothing</title><categories>stat.ME cs.AI cs.RO cs.SY math.OC stat.ML</categories><comments>14 pages. Extended version of conference paper (ACC 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general probabilistic perspective on Gaussian filtering and
smoothing. This allows us to show that common approaches to Gaussian
filtering/smoothing can be distinguished solely by their methods of
computing/approximating the means and covariances of joint probabilities. This
implies that novel filters and smoothers can be derived straightforwardly by
providing methods for computing these moments. Based on this insight, we derive
the cubature Kalman smoother and propose a novel robust filtering and smoothing
algorithm based on Gibbs sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2183</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2183</id><created>2010-06-10</created><authors><author><keyname>Bulu\cc</keyname><forenames>Ayd\in</forenames></author><author><keyname>Gilbert</keyname><forenames>John R.</forenames></author></authors><title>Highly Parallel Sparse Matrix-Matrix Multiplication</title><categories>cs.DC cs.MS cs.NA cs.PF</categories><report-no>UCSB technical report CS-2010-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized sparse matrix-matrix multiplication is a key primitive for many
high performance graph algorithms as well as some linear solvers such as
multigrid. We present the first parallel algorithms that achieve increasing
speedups for an unbounded number of processors. Our algorithms are based on
two-dimensional block distribution of sparse matrices where serial sections use
a novel hypersparse kernel for scalability. We give a state-of-the-art MPI
implementation of one of our algorithms. Our experiments show scaling up to
thousands of processors on a variety of test scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2195</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2195</id><created>2010-06-11</created><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Kerman</keyname><forenames>Ely</forenames></author></authors><title>Subspace Evolution and Transfer (SET) for Low-Rank Matrix Completion</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2011.2144977</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new algorithm, termed subspace evolution and transfer (SET),
for solving low-rank matrix completion problems. The algorithm takes as its
input a subset of entries of a low-rank matrix, and outputs one low-rank matrix
consistent with the given observations. The completion task is accomplished by
searching for a column space on the Grassmann manifold that matches the
incomplete observations. The SET algorithm consists of two parts -- subspace
evolution and subspace transfer. In the evolution part, we use a gradient
descent method on the Grassmann manifold to refine our estimate of the column
space. Since the gradient descent algorithm is not guaranteed to converge, due
to the existence of barriers along the search path, we design a new mechanism
for detecting barriers and transferring the estimated column space across the
barriers. This mechanism constitutes the core of the transfer step of the
algorithm. The SET algorithm exhibits excellent empirical performance for both
high and low sampling rate regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2197</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2197</id><created>2010-06-11</created><authors><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Ghasemloo</keyname><forenames>Kaveh</forenames></author><author><keyname>Pourmahdian</keyname><forenames>Massoud</forenames></author></authors><title>Effectiveness in RPL, with Applications to Continuous Logic</title><categories>math.LO cs.LO</categories><msc-class>03D45 (Primary), 03B50 (Secondary)</msc-class><journal-ref>Annals of Pure and Applied Logic, Volume 161, Issue 6, March 2010,
  Pages 789-799 (The proceedings of the IPM 2007 Logic Conference)</journal-ref><doi>10.1016/j.apal.2009.06.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a foundation for computable model theory of
rational Pavelka logic (an extension of {\L}ukasiewicz logic) and continuous
logic, and prove effective versions of some theorems in model theory. We show
how to reduce continuous logic to rational Pavelka logic. We also define
notions of computability and decidability of a model for logics with
computable, but uncountable, set of truth values; show that provability degree
of a formula w.r.t. a linear theory is computable, and use this to carry out an
effective Henkin construction. Therefore, for any effectively given consistent
linear theory in continuous logic, we effectively produce its decidable model.
This is the best possible, since we show that the computable model theory of
continuous logic is an extension of computable model theory of classical logic.
We conclude with noting that the unique separable model of a separably
categorical and computably axiomatizable theory (such as that of a probability
space or an $L^p$ Banach lattice) is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2204</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2204</id><created>2010-06-11</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Rong</keyname><forenames>Nan</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>MDPs with Unawareness</title><categories>cs.AI</categories><comments>11 pages</comments><acm-class>I.2.8; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov decision processes (MDPs) are widely used for modeling decision-making
problems in robotics, automated control, and economics. Traditional MDPs assume
that the decision maker (DM) knows all states and actions. However, this may
not be true in many situations of interest. We define a new framework, MDPs
with unawareness (MDPUs) to deal with the possibilities that a DM may not be
aware of all possible actions. We provide a complete characterization of when a
DM can learn to play near-optimally in an MDPU, and give an algorithm that
learns to play near-optimally when it is possible to do so, as efficiently as
possible. In particular, we characterize when a near-optimal solution can be
found in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2215</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2215</id><created>2010-06-11</created><authors><author><keyname>Mueller-Quade</keyname><forenames>Joern</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Composability in quantum cryptography</title><categories>quant-ph cs.CR</categories><comments>18 pages, 2 figures</comments><journal-ref>New Journal of Physics, 11, 085006, 2009 (Focus on Quantum
  Cryptography: Theory and Practice)</journal-ref><doi>10.1088/1367-2630/11/8/085006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we review several aspects of composability in the context of
quantum cryptography. The first part is devoted to key distribution. We discuss
the security criteria that a quantum key distribution protocol must fulfill to
allow its safe use within a larger security application (e.g., for secure
message transmission). To illustrate the practical use of composability, we
show how to generate a continuous key stream by sequentially composing rounds
of a quantum key distribution protocol. In a second part, we take a more
general point of view, which is necessary for the study of cryptographic
situations involving, for example, mutually distrustful parties. We explain the
universal composability framework and state the composition theorem which
guarantees that secure protocols can securely be composed to larger
applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2218</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2218</id><created>2010-06-11</created><authors><author><keyname>Barron-Romero</keyname><forenames>Carlos</forenames></author></authors><title>The Complexity Of The NP-Class</title><categories>cs.CC cs.DS physics.atm-clus</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel and straight formulation, and gives a complete
insight towards the understanding of the complexity of the problems of the so
called NP-Class. In particular, this paper focuses in the Searching of the
Optimal Geometrical Structures and the Travelling Salesman Problems. The main
results are the polynomial reduction procedure and the solution to the Noted
Conjecture of the NP-Class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2221</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2221</id><created>2010-06-11</created><updated>2011-01-25</updated><authors><author><keyname>Xu</keyname><forenames>Zhiqiang</forenames></author></authors><title>Deterministic Sampling of Sparse Trigonometric Polynomials</title><categories>math.NA cs.IT math.IT</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One can recover sparse multivariate trigonometric polynomials from few
randomly taken samples with high probability (as shown by Kunis and Rauhut). We
give a deterministic sampling of multivariate trigonometric polynomials
inspired by Weil's exponential sum. Our sampling can produce a deterministic
matrix satisfying the statistical restricted isometry property, and also nearly
optimal Grassmannian frames. We show that one can exactly reconstruct every
$M$-sparse multivariate trigonometric polynomial with fixed degree and of
length $D$ from the determinant sampling $X$, using the orthogonal matching
pursuit, and $# X$ is a prime number greater than $(M\log D)^2$. This result is
almost optimal within the $(\log D)^2 $ factor. The simulations show that the
deterministic sampling can offer reconstruction performance similar to the
random sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2249</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2249</id><created>2010-06-11</created><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Koenemann</keyname><forenames>Jochen</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>Integrality Gap of the Hypergraphic Relaxation of Steiner Trees: a short
  proof of a 1.55 upper bound</title><categories>cs.DM math.CO</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently Byrka, Grandoni, Rothvoss and Sanita (at STOC 2010) gave a
1.39-approximation for the Steiner tree problem, using a hypergraph-based
linear programming relaxation. They also upper-bounded its integrality gap by
1.55. We describe a shorter proof of the same integrality gap bound, by
applying some of their techniques to a randomized loss-contracting algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2269</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2269</id><created>2010-06-11</created><updated>2011-08-10</updated><authors><author><keyname>Engblom</keyname><forenames>Stefan</forenames></author></authors><title>On well-separated sets and fast multipole methods</title><categories>math.NA cs.DS cs.NA</categories><msc-class>65M15, 65M80</msc-class><journal-ref>Appl. Numer. Math. 61(10):1096--1102, 2011</journal-ref><doi>10.1016/j.apnum.2011.06.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of well-separated sets is crucial in fast multipole methods as the
main idea is to approximate the interaction between such sets via cluster
expansions. We revisit the one-parameter multipole acceptance criterion in a
general setting and derive a relative error estimate. This analysis benefits
asymmetric versions of the method, where the division of the multipole boxes is
more liberal than in conventional codes. Such variants offer a particularly
elegant implementation with a balanced multipole tree, a feature which might be
very favorable on modern computer architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2283</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2283</id><created>2010-06-11</created><authors><author><keyname>Curien</keyname><forenames>Pierre-Louis</forenames><affiliation>PPS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Munch-Maccagnoni</keyname><forenames>Guillaume</forenames><affiliation>PPS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>The duality of computation under focus</title><categories>cs.LO</categories><proxy>ccsd</proxy><journal-ref>IFIP International Conference on Theoretical Computer Science,
  Brisbane : Australia (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the close relationship between abstract machines for (call-by-name
or call-by-value) lambda-calculi (extended with Felleisen's C) and sequent
calculus, reintroducing on the way Curien-Herbelin's syntactic kit expressing
the duality of computation. We use this kit to provide a term language for a
presentation of LK (with conjunction, disjunction, and negation), and to
transcribe cut elimination as (non confluent) rewriting. A key slogan here,
which may appear here in print for the first time, is that commutative cut
elimination rules are explicit substitution propagation rules. We then describe
the focalised proof search discipline (in the classical setting), and narrow
down the language and the rewriting rules to a confluent calculus (a variant of
the second author's focalising system L). We then define a game of patterns and
counterpatterns, leading us to a fully focalised finitary syntax for a
synthetic presentation of classical logic, that provides a quotient on
(focalised) proofs, abstracting out the order of decomposition of negative
connectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2289</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2289</id><created>2010-06-11</created><updated>2010-09-04</updated><authors><author><keyname>Baader</keyname><forenames>Franz</forenames><affiliation>Institute for Theoretical Computer Science, TU Dresden</affiliation></author><author><keyname>Morawska</keyname><forenames>Barbara</forenames><affiliation>Institute for Theoretical Computer Science, TU Dresden</affiliation></author></authors><title>Unification in the Description Logic EL</title><categories>cs.AI cs.LO</categories><comments>31pages</comments><proxy>LMCS</proxy><acm-class>cs.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  4, 2010) lmcs:1106</journal-ref><doi>10.2168/LMCS-6(3:17)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Description Logic EL has recently drawn considerable attention since, on
the one hand, important inference problems such as the subsumption problem are
polynomial. On the other hand, EL is used to define large biomedical
ontologies. Unification in Description Logics has been proposed as a novel
inference service that can, for example, be used to detect redundancies in
ontologies. The main result of this paper is that unification in EL is
decidable. More precisely, EL-unification is NP-complete, and thus has the same
complexity as EL-matching. We also show that, w.r.t. the unification type, EL
is less well-behaved: it is of type zero, which in particular implies that
there are unification problems that have no finite complete set of unifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2307</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2307</id><created>2010-06-11</created><authors><author><keyname>Go&#xf1;i</keyname><forenames>Joaqu&#xed;n</forenames></author><author><keyname>Corominas-Murtra</keyname><forenames>Bernat</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Ricard V.</forenames></author><author><keyname>Rodr&#xed;guez-Caso</keyname><forenames>Carlos</forenames></author></authors><title>Exploring the randomness of Directed Acyclic Networks</title><categories>physics.soc-ph cond-mat.soft cs.DS q-bio.QM</categories><comments>13 pages, 5 figures and 5 tables</comments><doi>10.1103/PhysRevE.82.066115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The feed-forward relationship naturally observed in time-dependent processes
and in a diverse number of real systems -such as some food-webs and electronic
and neural wiring- can be described in terms of so-called directed acyclic
graphs (DAGs). An important ingredient of the analysis of such networks is a
proper comparison of their observed architecture against an ensemble of
randomized graphs, thereby quantifying the {\em randomness} of the real systems
with respect to suitable null models. This approximation is particularly
relevant when the finite size and/or large connectivity of real systems make
inadequate a comparison with the predictions obtained from the so-called {\em
configuration model}. In this paper we analyze four methods of DAG
randomization as defined by the desired combination of topological invariants
(directed and undirected degree sequence and component distributions) aimed to
be preserved. A highly ordered DAG, called \textit{snake}-graph and a
Erd\:os-R\'enyi DAG were used to validate the performance of the algorithms.
Finally, three real case studies, namely, the \textit{C. elegans} cell lineage
network, a PhD student-advisor network and the Milgram's citation network were
analyzed using each randomization method. Results show how the interpretation
of degree-degree relations in DAGs respect to their randomized ensembles depend
on the topological invariants imposed. In general, real DAGs provide disordered
values, lower than the expected by chance when the directedness of the links is
not preserved in the randomization process. Conversely, if the direction of the
links is conserved throughout the randomization process, disorder indicators
are close to the obtained from the null-model ensemble, although some
deviations are observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2313</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2313</id><created>2010-06-11</created><updated>2011-09-07</updated><authors><author><keyname>Feuillet</keyname><forenames>Mathieu</forenames></author></authors><title>On the flow-level stability of data networks without congestion control:
  the case of linear networks and upstream trees</title><categories>math.PR cs.NI cs.PF</categories><doi>10.1007/s11134-011-9265-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, flow models of networks without congestion control are
considered. Users generate data transfers according to some Poisson processes
and transmit corresponding packet at a fixed rate equal to their access rate
until the entire document is received at the destination; some erasure codes
are used to make the transmission robust to packet losses. We study the
stability of the stochastic process representing the number of active flows in
two particular cases: linear networks and upstream trees. For the case of
linear networks, we notably use fluid limits and an interesting phenomenon of
&quot;time scale separation&quot; occurs. Bounds on the stability region of linear
networks are given. For the case of upstream trees, underlying monotonic
properties are used. Finally, the asymptotic stability of those processes is
analyzed when the access rate of the users decreases to 0. An appropriate
scaling is introduced and used to prove that the stability region of those
networks is asymptotically maximized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2322</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2322</id><created>2010-06-11</created><updated>2011-06-09</updated><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author></authors><title>Discovery of a missing disease spreader</title><categories>cs.AI cs.SI physics.bio-ph physics.soc-ph q-bio.PE</categories><comments>in press</comments><journal-ref>Physica A vol.390, pp.3412-3426 (2011)</journal-ref><doi>10.1016/j.physa.2011.05.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a method to discover an outbreak of an infectious disease
in a region for which data are missing, but which is at work as a disease
spreader. Node discovery for the spread of an infectious disease is defined as
discriminating between the nodes which are neighboring to a missing disease
spreader node, and the rest, given a dataset on the number of cases. The spread
is described by stochastic differential equations. A perturbation theory
quantifies the impact of the missing spreader on the moments of the number of
cases. Statistical discriminators examine the mid-body or tail-ends of the
probability density function, and search for the disturbance from the missing
spreader. They are tested with computationally synthesized datasets, and
applied to the SARS outbreak and flu pandemic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2348</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2348</id><created>2010-06-11</created><updated>2011-06-09</updated><authors><author><keyname>Pumpluen</keyname><forenames>Susanne</forenames></author><author><keyname>Unger</keyname><forenames>Thomas</forenames></author></authors><title>Space-time block codes from nonassociative division algebras</title><categories>cs.IT math.IT</categories><comments>23 pages; final version; to appear in Advances in Mathematics of
  Communications</comments><msc-class>11T71, 68P30, 17A35</msc-class><journal-ref>Adv. Math. Commun. 5 (2011), no. 3, 449-471</journal-ref><doi>10.3934/amc.2011.5.449</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Associative division algebras are a rich source of fully diverse space-time
block codes (STBCs). In this paper the systematic construction of fully diverse
STBCs from nonassociative algebras is discussed. As examples, families of fully
diverse $2\times 2$, $2\times 4$ multiblock and $4\x 4$ STBCs are designed,
employing nonassociative quaternion division algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2356</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2356</id><created>2010-06-11</created><authors><author><keyname>Bendersky</keyname><forenames>Diego</forenames><affiliation>Corelabs, Core Security Technologies</affiliation><affiliation>Departamento de Computacion, FCEyN, Universidad de Buenos Aires</affiliation></author><author><keyname>Futoransky</keyname><forenames>Ariel</forenames><affiliation>Corelabs, Core Security Technologies</affiliation></author><author><keyname>Notarfrancesco</keyname><forenames>Luciano</forenames><affiliation>Corelabs, Core Security Technologies</affiliation></author><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>Corelabs, Core Security Technologies</affiliation><affiliation>Departamento de Matematica, FCEyN, Universidad de Buenos Aires</affiliation></author><author><keyname>Waissbein</keyname><forenames>Ariel</forenames><affiliation>Corelabs, Core Security Technologies</affiliation><affiliation>Departamento de Matematica, FCEyN, Universidad de Buenos Aires</affiliation></author></authors><title>Advanced Software Protection Now</title><categories>cs.CR</categories><comments>20 pages. CoreLabs Technical Report</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Software digital rights management is a pressing need for the software
development industry which remains, as no practical solutions have been
acclamaimed succesful by the industry. We introduce a novel software-protection
method, fully implemented with today's technologies, that provides traitor
tracing and license enforcement and requires no additional hardware nor
inter-connectivity.
  Our work benefits from the use of secure triggers, a cryptographic primitive
that is secure assuming the existence of an ind-cpa secure block cipher. Using
our framework, developers may insert license checks and fingerprints, and
obfuscate the code using secure triggers. As a result, this rises the cost that
software analysis tools have detect and modify protection mechanisms. Thus
rising the complexity of cracking this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2361</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2361</id><created>2010-06-11</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Neubauer</keyname><forenames>Peter</forenames></author></authors><title>Constructions from Dots and Lines</title><categories>cs.DS</categories><comments>In press with the Bulletin of the American Society for Information
  Science and Technology</comments><acm-class>E.1</acm-class><journal-ref>Bulletin of the American Society for Information Science and
  Technology, American Society for Information Science and Technology, 36,(6),
  pp. 35-41, ISSN:1550-8366, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is a data structure composed of dots (i.e. vertices) and lines (i.e.
edges). The dots and lines of a graph can be organized into intricate
arrangements. The ability for a graph to denote objects and their relationships
to one another allow for a surprisingly large number of things to be modeled as
a graph. From the dependencies that link software packages to the wood beams
that provide the framing to a house, most anything has a corresponding graph
representation. However, just because it is possible to represent something as
a graph does not necessarily mean that its graph representation will be useful.
If a modeler can leverage the plethora of tools and algorithms that store and
process graphs, then such a mapping is worthwhile. This article explores the
world of graphs in computing and exposes situations in which graphical models
are beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2368</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2368</id><created>2010-06-11</created><authors><author><keyname>Pianykh</keyname><forenames>Oleg</forenames></author></authors><title>L2-optimal image interpolation and its applications to medical imaging</title><categories>cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital medical images are always displayed scaled to fit particular view.
Interpolation is responsible for this scaling, and if not done properly, can
significantly degrade diagnostic image quality. However, theoretically-optimal
interpolation algorithms may also be the most time-consuming and impractical.
We propose a new approach, adapted to the needs of digital medical imaging, to
combine high interpolation speed and superior L2-optimal image quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2380</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2380</id><created>2010-06-11</created><updated>2011-04-07</updated><authors><author><keyname>Jung</keyname><forenames>Bang Chul</forenames></author><author><keyname>Park</keyname><forenames>Dohyung</forenames></author><author><keyname>Shin</keyname><forenames>Won-Yong</forenames></author></authors><title>Opportunistic Interference Mitigation Achieves Optimal
  Degrees-of-Freedom in Wireless Multi-cell Uplink Networks</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures, Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an opportunistic interference mitigation (OIM) protocol, where a
user scheduling strategy is utilized in $K$-cell uplink networks with
time-invariant channel coefficients and base stations (BSs) having $M$
antennas. Each BS opportunistically selects a set of users who generate the
minimum interference to the other BSs. Two OIM protocols are shown according to
the number $S$ of simultaneously transmitting users per cell: opportunistic
interference nulling (OIN) and opportunistic interference alignment (OIA).
Then, their performance is analyzed in terms of degrees-of-freedom (DoFs). As
our main result, it is shown that $KM$ DoFs are achievable under the OIN
protocol with $M$ selected users per cell, if the total number $N$ of users in
a cell scales at least as $\text{SNR}^{(K-1)M}$. Similarly, it turns out that
the OIA scheme with $S$($&lt;M$) selected users achieves $KS$ DoFs, if $N$ scales
faster than $\text{SNR}^{(K-1)S}$. These results indicate that there exists a
trade-off between the achievable DoFs and the minimum required $N$. By deriving
the corresponding upper bound on the DoFs, it is shown that the OIN scheme is
DoF optimal. Finally, numerical evaluation, a two-step scheduling method, and
the extension to multi-carrier scenarios are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2403</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2403</id><created>2010-06-11</created><authors><author><keyname>Parag</keyname><forenames>Parimal</forenames></author><author><keyname>Chamberland</keyname><forenames>Jean-Francois</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>On the Queueing Behavior of Random Codes over a Gilbert-Elliot Erasure
  Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the queueing performance of a system that transmits
coded data over a time-varying erasure channel. In our model, the queue length
and channel state together form a Markov chain that depends on the system
parameters. This gives a framework that allows a rigorous analysis of the queue
as a function of the code rate. Most prior work in this area either ignores
block-length (e.g., fluid models) or assumes error-free communication using
finite codes. This work enables one to determine when such assumptions provide
good, or bad, approximations of true behavior. Moreover, it offers a new
approach to optimize parameters and evaluate performance. This can be valuable
for delay-sensitive systems that employ short block lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2407</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2407</id><created>2010-06-11</created><authors><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation><affiliation>ITBA</affiliation></author><author><keyname>Miranda</keyname><forenames>Fernando</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Orlicki</keyname><forenames>Jose I.</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation><affiliation>ITBA</affiliation></author></authors><title>Simulation of Computer Network Attacks</title><categories>cs.CR</categories><comments>17 pages, 3 figures. Argentine Symposium on Computing Technology
  (AST) 2007 - 36 JAIIO</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work we present a prototype for simulating computer network attacks.
Our objective is to simulate large networks (thousands of hosts, with
applications and vulnerabilities) while remaining realistic from the attacker's
point of view. The foundation for the simulator is a model of computer
intrusions, based on the analysis of real world attacks. In particular we show
how to interpret vulnerabilities and exploits as communication channels. This
conceptual model gives a tool to describe the theater of operations, targets,
actions and assets involved in multistep network attacks. We conclude with
applications of the attack simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2411</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2411</id><created>2010-06-11</created><authors><author><keyname>Arce</keyname><forenames>Ivan</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Kargieman</keyname><forenames>Emiliano</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Richarte</keyname><forenames>Gerardo</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Waissbein</keyname><forenames>Ariel</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author></authors><title>An attack on MySQL's login protocol</title><categories>cs.CR</categories><comments>15 pages, 3 figures. CoreLabs Technical Report</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The MySQL challenge-and-response authentication protocol is proved insecure.
We show how can an eavesdropper impersonate a valid user after witnessing only
a few executions of this protocol. The algorithm of the underlying attack is
presented. Finally we comment about implementations and statistical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2422</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2422</id><created>2010-06-11</created><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Complexity of Multi-Value Byzantine Agreement</title><categories>cs.DC cs.IT cs.NI math.IT</categories><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of maximizing the throughput of
Byzantine agreement, given that the sum capacity of all links in between nodes
in the system is finite. We have proposed a highly efficient Byzantine
agreement algorithm on values of length l&gt;1 bits. This algorithm uses error
detecting network codes to ensure that fault-free nodes will never disagree,
and routing scheme that is adaptive to the result of error detection. Our
algorithm has a bit complexity of n(n-1)l/(n-t), which leads to a linear cost
(O(n)) per bit agreed upon, and overcomes the quadratic lower bound
(Omega(n^2)) in the literature. Such linear per bit complexity has only been
achieved in the literature by allowing a positive probability of error. Our
algorithm achieves the linear per bit complexity while guaranteeing agreement
is achieved correctly even in the worst case. We also conjecture that our
algorithm can be used to achieve agreement throughput arbitrarily close to the
agreement capacity of a network, when the sum capacity is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2433</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2433</id><created>2010-06-12</created><authors><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>Anonymous Gossiping</title><categories>cs.DC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel gossiping primitive to support privacy
preserving data analytics (PPDA). In contrast to existing computational PPDA
primitives such as secure multiparty computation and data randomization based
approaches, the proposed primitive `anonymous gossiping' is a communication
primitive for privacy preserving personalized information aggregation
complementing such traditional computational analytics. We realize this novel
primitive by composing existing gossiping mechanisms for peer sampling &amp;
information aggregation and onion routing technique for establishing anonymous
communication. This is more an `ideas' paper, rather than providing concrete
and quantified results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2461</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2461</id><created>2010-06-12</created><updated>2011-01-11</updated><authors><author><keyname>Praveen</keyname><forenames>M.</forenames></author></authors><title>Does Treewidth Help in Modal Satisfiability?</title><categories>cs.LO cs.CC cs.DS</categories><comments>Full version of the paper appearing in MFCS 2010. Change from v1:
  improved section 5 to avoid exponential blow-up in formula size</comments><acm-class>F.2.2; F.4.1</acm-class><doi>10.1007/978-3-642-15155-2_51</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many tractable algorithms for solving the Constraint Satisfaction Problem
(CSP) have been developed using the notion of the treewidth of some graph
derived from the input CSP instance. In particular, the incidence graph of the
CSP instance is one such graph. We introduce the notion of an incidence graph
for modal logic formulae in a certain normal form. We investigate the
parameterized complexity of modal satisfiability with the modal depth of the
formula and the treewidth of the incidence graph as parameters. For various
combinations of Euclidean, reflexive, symmetric and transitive models, we show
either that modal satisfiability is FPT, or that it is W[1]-hard. In
particular, modal satisfiability in general models is FPT, while it is
W[1]-hard in transitive models. As might be expected, modal satisfiability in
transitive and Euclidean models is FPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2495</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2495</id><created>2010-06-12</created><authors><author><keyname>Wen</keyname><forenames>Han Xiao</forenames></author></authors><title>Mirrored Language Structure and Innate Logic of the Human Brain as a
  Computable Model of the Oracle Turing Machine</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We wish to present a mirrored language structure (MLS) and four logic rules
determined by this structure for the model of a computable Oracle Turing
machine. MLS has novel features that are of considerable biological and
computational significance. It suggests an algorithm of relation learning and
recognition (RLR) that enables the deterministic computers to simulate the
mechanism of the Oracle Turing machine, or P = NP in a mathematical term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2498</identifier>
 <datestamp>2013-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2498</id><created>2010-06-12</created><updated>2013-01-10</updated><authors><author><keyname>Nitinawarat</keyname><forenames>Sirin</forenames></author></authors><title>On the Deterministic Code Capacity Region of an Arbitrarily Varying
  Multiple-Access Channel Under List Decoding</title><categories>cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory, January 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the capacity region $C_L$ of an arbitrarily varying multiple-access
channel (AVMAC) for deterministic codes with decoding into a list of a fixed
size $L$ and for the average error probability criterion. Motivated by known
results in the study of fixed size list decoding for a point-to-point
arbitrarily varying channel, we define for every AVMAC whose capacity region
for random codes has a nonempty interior, a nonnegative integer $\Omega$ called
its symmetrizability. It is shown that for every $L \leq \Omega$, $C_L$ has an
empty interior, and for every $L \geq (\Omega+1)^2$, $C_L$ equals the
nondegenerate capacity region of the AVMAC for random codes with a known
single-letter characterization. For a binary AVMAC with a nondegenerate random
code capacity region, it is shown that the symmetrizability is always finite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2513</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2513</id><created>2010-06-13</created><updated>2013-08-25</updated><authors><author><keyname>Niazadeh</keyname><forenames>Rad</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Masoud</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>On the Achievability of Cram\'er-Rao Bound In Noisy Compressed Sensing</title><categories>cs.IT cs.LG math.IT</categories><journal-ref>IEEE Transactions on Signal Processing, Volume 60, Issue 1, Pages
  518- 526, January 2012</journal-ref><doi>10.1109/TSP.2011.2171953</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been proved in Babadi et al. that in noisy compressed
sensing, a joint typical estimator can asymptotically achieve the Cramer-Rao
lower bound of the problem.To prove this result, this paper used a lemma,which
is provided in Akcakaya et al,that comprises the main building block of the
proof. This lemma is based on the assumption of Gaussianity of the measurement
matrix and its randomness in the domain of noise. In this correspondence, we
generalize the results obtained in Babadi et al by dropping the Gaussianity
assumption on the measurement matrix. In fact, by considering the measurement
matrix as a deterministic matrix in our analysis, we find a theorem similar to
the main theorem of Babadi et al for a family of randomly generated (but
deterministic in the noise domain) measurement matrices that satisfy a
generalized condition known as The Concentration of Measures Inequality. By
this, we finally show that under our generalized assumptions, the Cramer-Rao
bound of the estimation is achievable by using the typical estimator introduced
in Babadi et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2523</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2523</id><created>2010-06-13</created><updated>2010-06-15</updated><authors><author><keyname>Doku-Amponsah</keyname><forenames>Kwabena</forenames></author></authors><title>Asymptotic Equipartition Properties for simple hierarchical and
  networked structures</title><categories>cs.IT math.IT math.PR</categories><comments>25 pages</comments><msc-class>94A15, 94A24, 60F10, 05C80</msc-class><journal-ref>ESAIM: Probability and Statistics, Volume 16, January 2012, pp
  114-138</journal-ref><doi>10.1051/ps/2010016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove asymptotic equipartition properties for simple hierarchical
structures (modelled as multitype Galton-Watson trees) and networked structures
(modelled as randomly coloured random graphs). For example, for large $n$, a
networked data structure consisting of $n$ units connected by an average number
of links of order $n/log n$ can be coded by about $nH$ bits, where $H$ is an
explicitly defined entropy. The main technique in our proofs are large
deviation principles for suitably defined empirical measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2534</identifier>
 <datestamp>2014-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2534</id><created>2010-06-13</created><updated>2014-03-02</updated><authors><author><keyname>Perisic</keyname><forenames>Aleksandar</forenames></author></authors><title>The Application and Extension of Retrograde Software Analysis</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The retrograde software analysis is a method that emanates from executing a
program backwards - instead of taking input data and following the execution
path, we start from output data and by executing the program backwards, command
by command, analyze data that could lead to the current output. The changed
perspective forces a developer to think in a new way about the program. It can
be applied as a thorough procedure or casual method. With this method, we have
many advantages in testing, algorithm and system analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2552</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2552</id><created>2010-06-13</created><authors><author><keyname>Thakur</keyname><forenames>Gautam</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author><author><keyname>Hsu</keyname><forenames>Wei-Jen</forenames></author></authors><title>Similarity Analysis and Modeling in Mobile Societies: The Missing Link</title><categories>cs.NI</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new generation of &quot;behavior-aware&quot; delay tolerant networks is emerging in
what may define future mobile social networks. With the introduction of novel
behavior-aware protocols, services and architectures, there is a pressing need
to understand and realistically model mobile users behavioral characteristics,
their similarity and clustering. Such models are essential for the analysis,
performance evaluation, and simulation of future DTNs. This paper addresses
issues related to mobile user similarity, its definition, analysis and
modeling. To define similarity, we adopt a behavioral-profile based on users
location preferences using their on-line association matrix and its SVD, then
calculate the behavioral distance to capture user similarity. This measures the
difference of the major spatio-temporal behavioral trends and can be used to
cluster users into similarity groups or communities. We then analyze and
contrast similarity distributions of mobile user populations in two settings:
(i) based on real measurements from four major campuses with over ten thousand
users for a month, and (ii) based on existing mobility models, including random
direction and time-varying community models. Our results show a rich set of
similar communities in real mobile societies with distinct behavioral clusters
of users. This is true for all the traces studied, with the trend being
consistent over time. Surprisingly, however, we find that the existing mobility
models do not explicitly capture similarity and result in homogeneous users
that are all similar to each other. Thus the richness and diversity of user
behavioral patterns is not captured to any degree in the existing models. These
findings strongly suggest that similarity should be explicitly captured in
future mobility models, which motivates the need to re-visit mobility modeling
in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2565</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2565</id><created>2010-06-13</created><authors><author><keyname>Akhbari</keyname><forenames>Bahareh</forenames></author><author><keyname>Mirmohseni</keyname><forenames>Mahtab</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>State-Dependent Relay Channel with Private Messages with Partial Causal
  and Non-Causal Channel State Information</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to be presented at the IEEE International
  Symposium on Information Theory (ISIT 2010), Austin, Texas, June 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a discrete memoryless State-Dependent Relay
Channel with Private Messages (SD-RCPM) as a generalization of the
state-dependent relay channel. We investigate two main cases: SD-RCPM with
non-causal Channel State Information (CSI), and SD-RCPM with causal CSI. In
each case, it is assumed that partial CSI is available at the source and relay.
For non-causal case, we establish an achievable rate region using
Gel'fand-Pinsker type coding scheme at the nodes informed of CSI, and
Compress-and-Forward (CF) scheme at the relay. Using Shannon's strategy and CF
scheme, an achievable rate region for causal case is obtained. As an example,
the Gaussian version of SD-RCPM is considered, and an achievable rate region
for Gaussian SD-RCPM with non-causal perfect CSI only at the source, is
derived. Providing numerical examples, we illustrate the comparison between
achievable rate regions derived using CF and Decode-and-Forward (DF) schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2566</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2566</id><created>2010-06-13</created><authors><author><keyname>Bernaschi</keyname><forenames>M.</forenames></author><author><keyname>Parisi</keyname><forenames>G.</forenames></author><author><keyname>Parisi</keyname><forenames>L.</forenames></author></authors><title>The Heisenberg spin glass model on GPU: myths and actual facts</title><categories>cond-mat.dis-nn cs.DC</categories><comments>13 pages, 2 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe different implementations of the 3D Heisenberg spin glass model
for Graphics Processing Units (GPU). The results show that the {\em fast}
shared memory gives better performance with respect to the {\em slow} global
memory only if a multi-hit technique is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2570</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2570</id><created>2010-06-13</created><authors><author><keyname>Myasnikov</keyname><forenames>Alexei G.</forenames></author><author><keyname>Ushakov</keyname><forenames>Alexander</forenames></author><author><keyname>Won</keyname><forenames>Dong Wook</forenames></author></authors><title>Power Circuits, Exponential Algebra, and Time Complexity</title><categories>math.GR cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by algorithmic problems from combinatorial group theory we study
computational properties of integers equipped with binary operations +, -, z =
x 2^y, z = x 2^{-y} (the former two are partial) and predicates &lt; and =. Notice
that in this case very large numbers, which are obtained as n towers of
exponentiation in the base 2 can be realized as n applications of the operation
x2^y, so working with such numbers given in the usual binary expansions
requires super exponential space. We define a new compressed representation for
integers by power circuits (a particular type of straight-line programs) which
is unique and easily computable, and show that the operations above can be
performed in polynomial time if the numbers are presented by power circuits. We
mention several applications of this technique to algorithmic problems, in
particular, we prove that the quantifier-free theories of various exponential
algebras are decidable in polynomial time, as well as the word problems in some
&quot;hard to crack&quot; one-relator groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2588</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2588</id><created>2010-06-13</created><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Agnostic Active Learning Without Constraints</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and analyze an agnostic active learning algorithm that works
without keeping a version space. This is unlike all previous approaches where a
restricted set of candidate hypotheses is maintained throughout learning, and
only hypotheses from this set are ever returned. By avoiding this version space
approach, our algorithm sheds the computational burden and brittleness
associated with maintaining version spaces, yet still allows for substantial
improvements over supervised learning for classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2592</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2592</id><created>2010-06-13</created><updated>2011-10-16</updated><authors><author><keyname>She</keyname><forenames>Yiyuan</forenames></author><author><keyname>Owen</keyname><forenames>Art B.</forenames></author></authors><title>Outlier Detection Using Nonconvex Penalized Regression</title><categories>stat.ME cs.LG stat.CO</categories><msc-class>62F35, 62J07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the outlier detection problem from the point of view of
penalized regressions. Our regression model adds one mean shift parameter for
each of the $n$ data points. We then apply a regularization favoring a sparse
vector of mean shift parameters. The usual $L_1$ penalty yields a convex
criterion, but we find that it fails to deliver a robust estimator. The $L_1$
penalty corresponds to soft thresholding. We introduce a thresholding (denoted
by $\Theta$) based iterative procedure for outlier detection ($\Theta$-IPOD). A
version based on hard thresholding correctly identifies outliers on some hard
test problems. We find that $\Theta$-IPOD is much faster than iteratively
reweighted least squares for large data because each iteration costs at most
$O(np)$ (and sometimes much less) avoiding an $O(np^2)$ least squares estimate.
We describe the connection between $\Theta$-IPOD and $M$-estimators. Our
proposed method has one tuning parameter with which to both identify outliers
and estimate regression coefficients. A data-dependent choice can be made based
on BIC. The tuned $\Theta$-IPOD shows outstanding performance in identifying
outliers in various situations in comparison to other existing approaches. This
methodology extends to high-dimensional modeling with $p\gg n$, if both the
coefficient vector and the outlier pattern are sparse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2610</identifier>
 <datestamp>2012-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2610</id><created>2010-06-14</created><updated>2012-05-03</updated><authors><author><keyname>Leducq</keyname><forenames>Elodie</forenames><affiliation>IMJ</affiliation></author></authors><title>Functions which are PN on infiitely many extensions of Fp, p odd</title><categories>math.NT cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $p$ be an odd prime number. We prove that for $m\equiv1\mod p$, $x^m$ is
perfectly nonlinear over $\mathbb{F}_{p^n}$ for infinitely many $n$ if and only
if $m$ is of the form $p^l+1$, $l\in\mathbb{N}$. First, we study singularities
of $f(x,y)=\frac{(x+1)^m-x^m-(y+1)^m+y^m}{x-y}$ and we use Bezout theorem to
show that for $m\neq 1+p^l$, $f(x,y)$ has an absolutely irreducible factor.
Then by Weil theorem, f(x,y) has rationnal points such that $x\neq y$ which
means that $x^m$ is not PN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2617</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2617</id><created>2010-06-14</created><authors><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author><author><keyname>Berten</keyname><forenames>Vandy</forenames></author></authors><title>Gang FTP scheduling of periodic and parallel rigid real-time tasks</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the scheduling of periodic and parallel rigid
tasks. We provide (and prove correct) an exact schedulability test for Fixed
Task Priority (FTP) Gang scheduler sub-classes: Parallelism Monotonic, Idling,
Limited Gang, and Limited Slack Reclaiming. Additionally, we study the
predictability of our schedulers: we show that Gang FJP schedulers are not
predictable and we identify several sub-classes which are actually predictable.
Moreover, we extend the definition of rigid, moldable and malleable jobs to
recurrent tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2637</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2637</id><created>2010-06-14</created><authors><author><keyname>Dorin</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Yomsi</keyname><forenames>Patrick Meumeu</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author><author><keyname>Richard</keyname><forenames>Pascal</forenames></author></authors><title>Semi-Partitioned Hard Real-Time Scheduling with Restricted Migrations
  upon Identical Multiprocessor Platforms</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms based on semi-partitioned scheduling have been proposed as a
viable alternative between the two extreme ones based on global and partitioned
scheduling. In particular, allowing migration to occur only for few tasks which
cannot be assigned to any individual processor, while most tasks are assigned
to specific processors, considerably reduces the runtime overhead compared to
global scheduling on the one hand, and improve both the schedulability and the
system utilization factor compared to partitioned scheduling on the other hand.
In this paper, we address the preemptive scheduling problem of hard real-time
systems composed of sporadic constrained-deadline tasks upon identical
multiprocessor platforms. We propose a new algorithm and a scheduling paradigm
based on the concept of semi-partitioned scheduling with restricted migrations
in which jobs are not allowed to migrate, but two subsequent jobs of a task can
be assigned to different processors by following a periodic strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2650</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2650</id><created>2010-06-14</created><authors><author><keyname>De Sarkar</keyname><forenames>Ajanta</forenames></author><author><keyname>Mukherjee</keyname><forenames>Nandini</forenames></author></authors><title>A Study on Performance Analysis Tools for Applications Running on Large
  Distributed Systems</title><categories>cs.DC</categories><journal-ref>International Journal of Information and Computing Science (IJICS)
  in Volume 9, Number 2, pp: 52-67, December 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of distributed architectures and programming paradigms for
performance-oriented program development, challenge the state-of-the-art
technology for performance tools. The area of high performance computing is
rapidly expanding from single parallel systems to clusters and grids of
heterogeneous sequential and parallel systems. Performance analysis and tuning
applications is becoming crucial because it is hardly possible to otherwise
achieve the optimum performance of any application. The objective of this paper
is to study the state-of-the-art technology of the existing performance tools
for distributed systems. The paper surveys some representative tools from
different aspects in order to highlight the approaches and technologies used by
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2660</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2660</id><created>2010-06-14</created><authors><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Martinez-Mateo</keyname><forenames>Jesus</forenames></author><author><keyname>Lancho</keyname><forenames>Daniel</forenames></author><author><keyname>Martin</keyname><forenames>Vicente</forenames></author></authors><title>Rate Compatible Protocol for Information Reconciliation: An application
  to QKD</title><categories>cs.IT math.IT</categories><doi>10.1109/ITWKSPS.2010.5503195</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information Reconciliation is a mechanism that allows to weed out the
discrepancies between two correlated variables. It is an essential component in
every key agreement protocol where the key has to be transmitted through a
noisy channel. The typical case is in the satellite scenario described by
Maurer in the early 90's. Recently the need has arisen in relation with Quantum
Key Distribution (QKD) protocols, where it is very important not to reveal
unnecessary information in order to maximize the shared key length. In this
paper we present an information reconciliation protocol based on a rate
compatible construction of Low Density Parity Check codes. Our protocol
improves the efficiency of the reconciliation for the whole range of error
rates in the discrete variable QKD context. Its adaptability together with its
low interactivity makes it specially well suited for QKD reconciliation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2679</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2679</id><created>2010-06-14</created><authors><author><keyname>Labrador</keyname><forenames>Nicolas Madrid</forenames></author><author><keyname>Straccia</keyname><forenames>Umberto</forenames></author></authors><title>Monotonic Mappings Invariant Linearisation of Finite Posets</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a novel a procedure to build a linear order from an
arbitrary poset which (i) preserves the original ordering and (ii) allows to
extend monotonic and antitonic mappings defined over the original poset to
monotonic and antitonic mappings over the new linear poset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2680</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2680</id><created>2010-06-14</created><authors><author><keyname>Shukla</keyname><forenames>D.</forenames></author><author><keyname>Jain</keyname><forenames>Saurabh</forenames></author><author><keyname>Singhai</keyname><forenames>Rahul</forenames></author><author><keyname>Agarwal</keyname><forenames>R. K.</forenames></author></authors><title>A Markov Chain Model for the Analysis of Round-Robin Scheduling Scheme</title><categories>cs.NI</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the literature of Round-Robin scheduling scheme, each job is processed,
one after the another after giving a fix quantum. In case of First-come
first-served, each process is executed, if the previously arrived processed is
completed. Both these scheduling schemes are used in this paper as its special
cases. A Markov chain model is used to compare several scheduling schemes of
the class. An index measure is defined to compare the model based efficiency of
different scheduling schemes. One scheduling scheme which is the mixture of
FIFO and round robin is found efficient in terms of model based study. The
system simulation procedure is used to derive the conclusion of the content
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2682</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2682</id><created>2010-06-14</created><authors><author><keyname>Sonavane</keyname><forenames>S. S.</forenames></author><author><keyname>Patil</keyname><forenames>B. P.</forenames></author><author><keyname>Kumar</keyname><forenames>V.</forenames></author></authors><title>Experimentation for Packet Loss on MSP430 and nRF24L01 Based Wireless
  Sensor Network</title><categories>cs.NI</categories><comments>5 Pages IJANA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper,a new design of wireless sensor network (WSN)node is discussed
which is based on components with ultra low power.We ha e de eloped a Low cost
and low power WSN Node using MSP430 and nRF24L01.The architectural circuit
details are presented.This architecture fulfils the requirements like low
cost,low power,compact size and self organization.Various tests are carried out
to test the performance of the nRF24L01 module.The packet loss,free Space loss
(FSL)and battery lifetime calculations are described.These test results will
help the researchers to build new applications using abo e node and to work
efficiently with nRF24L01.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2684</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2684</id><created>2010-06-14</created><authors><author><keyname>Rao</keyname><forenames>Mukta</forenames></author><author><keyname>Nipur</keyname></author><author><keyname>Dhaka</keyname><forenames>Vijaypal Singh</forenames></author></authors><title>Enhancing the Authentication of Bank Cheque Signatures by Implementing
  Automated System Using Recurrent Neural Network</title><categories>cs.NI</categories><comments>11 Pages IJANA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The associatie memory feature of the Hopfield type recurrent neural network
is used for the pattern storage and pattern authentication.This paper outlines
an optimization relaxation approach for signature verification based on the
Hopfield neural network (HNN)which is a recurrent network.The standard sample
signature of the customer is cross matched with the one supplied on the
Cheque.The difference percentage is obtained by calculating the different
pixels in both the images.The network topology is built so that each pixel in
the difference image is a neuron in the network.Each neuron is categorized by
its states,which in turn signifies that if the particular pixel is changed.The
network converges to unwavering condition based on the energy function which is
derived in experiments.The Hopfield's model allows each node to take on two
binary state values (changed/unchanged)for each pixel.The performance of the
proposed technique is evaluated by applying it in various binary and gray scale
images.This paper contributes in finding an automated scheme for verification
of authentic signature on bank Cheques.The derived energy function allows a
trade off between the influence of its neighborhood and its own criterion.This
device is able to recall as well as complete partially specified inputs.The
network is trained via a storage prescription that forces stable states to
correspond to (local)minima of a network &quot;energy&quot; function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2689</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2689</id><created>2010-06-14</created><authors><author><keyname>Srinivasulu</keyname><forenames>P.</forenames></author><author><keyname>Rao</keyname><forenames>J. Ranga</forenames></author><author><keyname>Babu</keyname><forenames>I. Ramesh</forenames></author></authors><title>Network Intrusion Detection Using FP Tree Rules</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the faceless world of the Internet,online fraud is one of the greatest
reasons of loss for web merchants.Advanced solutions are needed to protect e
businesses from the constant problems of fraud.Many popular fraud detection
algorithms require supervised training,which needs human intervention to
prepare training cases.Since it is quite often for an online transaction
database to ha e Terabyte level storage,human investigation to identify
fraudulent transactions is very costly.This paper describes the automatic
design of user profiling method for the purpose of fraud detection.We use a FP
(Frequent Pattern) Tree rule learning algorithm to adaptively profile
legitimate customer behavior in a transaction database.Then the incoming
transactions are compared against the user profile to uncover the anomalies The
anomaly outputs are used as input to an accumulation system for combining
evidence to generate high confidence fraud alert value. Favorable experimental
results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2691</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2691</id><created>2010-06-14</created><authors><author><keyname>Ganesh</keyname><forenames>S.</forenames></author><author><keyname>Amutha</keyname><forenames>R.</forenames></author></authors><title>Real Time and Energy Efficient Transport Protocol for Wireless Sensor
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable transport protocols such as TCP are tuned to perform well in
traditional networks where packet losses occur mostly because of congestion.
Many applications of wireless sensor networks are useful only when connected to
an external network. Previous research on transport layer protocols for sensor
networks has focused on designing protocols specifically targeted for sensor
networks. The deployment of TCP/IP in sensor networks would, however, enable
direct connection between the sensor network and external TCP/IP networks. In
this paper we focus on the performance of TCP in the context of wireless sensor
networks. TCP is known to exhibit poor performance in wireless environments,
both in terms of throughput and energy efficiency. To overcome these problems
we introduce a mechanism called TCP Segment Caching .We show by simulation that
TCP Segment Caching significantly improves TCP Performance so that TCP can be
useful e en in wireless sensor
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2693</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2693</id><created>2010-06-14</created><authors><author><keyname>Reddy</keyname><forenames>C. Chandra Sekhar</forenames></author><author><keyname>Prasad</keyname><forenames>K. Ramakrishna</forenames></author><author><keyname>Mamatha</keyname></author></authors><title>The Study State Analysis of Tandem Queue with Blocking and Feedback</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer system models provide detailed answer to system performance.In this
paper a two stage tandem network system with Blocking and Feedback is
considered and it performance has been analyzed by spectral expansion
method.The study state system with balance equations has been discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2695</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2695</id><created>2010-06-14</created><authors><author><keyname>Kaur</keyname><forenames>Damandeep</forenames></author><author><keyname>Shandi</keyname><forenames>Lokesh</forenames></author><author><keyname>Sengupta</keyname><forenames>Jyotsna</forenames></author></authors><title>Customized way of Resource Discovery in a Campus Grid</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Campus Grid computing involves heterogeneous resources of an organization
working in collaboration to sol e the problems that cannot be addressed by a
single resource. However, basic problem for Campus Grid users is how to disco
er the best resources required for the particular type of a job. There are
various approaches using which Grid Discovery can be performed. This paper pro
ides the grid resource discovery solutions for Campus Grid using Globus Toolkit
which will enable us to customize the resource information according to the
requirements based on the jobs to be run on the Campus Grid and present it in
our own format. Here we propose building up our own service on top of globus
MDS in order to process the information provided by MDS and use it in our
Campus Grid Portal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2699</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2699</id><created>2010-06-14</created><authors><author><keyname>Devi</keyname><forenames>D. Asha</forenames></author><author><keyname>Bab</keyname><forenames>M. Suresh</forenames></author><author><keyname>Pavani</keyname><forenames>V. L.</forenames></author><author><keyname>Geethanjali</keyname><forenames>N.</forenames></author></authors><title>Information Delivery System through Bluetooth in Ubiquitous Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  computers into the real world, to serve humans where the ubiquitous network
is the underneath infrastructure. In order to provide ubiquitous services
(u-Service) which deliver useful information to service users without human
intervention, this paper implements a proactive information delivery system
using Bluetooth technology. Bluetooth is a lowpowered networking service that
supports several protocol profiles, most importantly file transfer.Combined
together, ubiquitous computing and Bluetooth ha e the potential to furnish
ubiquitous solutions (u-Solutions) that are efficient, employ simplified design
characteristics, and collaboratively perform functions they are otherwise not
capable. Thus, this paper first addresses the current Bluetooth technology.
Then, it suggests and develops the proactive information delivery system
utilizing Bluetooth and ubiquitous computing network concepts. The proactive
information delivery system can be used in many ubiquitous applications such as
ubiquitous commerce (u-Commerce) and ubiquitous education (u- Education)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2700</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2700</id><created>2010-06-14</created><authors><author><keyname>Xu</keyname><forenames>Robert Sheng</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Salama</keyname><forenames>Magdy</forenames></author></authors><title>Image Segmentation Using Weak Shape Priors</title><categories>cs.CV</categories><comments>27 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of image segmentation is known to become particularly challenging
in the case of partial occlusion of the object(s) of interest, background
clutter, and the presence of strong noise. To overcome this problem, the
present paper introduces a novel approach segmentation through the use of
&quot;weak&quot; shape priors. Specifically, in the proposed method, an segmenting active
contour is constrained to converge to a configuration at which its geometric
parameters attain their empirical probability densities closely matching the
corresponding model densities that are learned based on training samples. It is
shown through numerical experiments that the proposed shape modeling can be
regarded as &quot;weak&quot; in the sense that it minimally influences the segmentation,
which is allowed to be dominated by data-related forces. On the other hand, the
priors provide sufficient constraints to regularize the convergence of
segmentation, while requiring substantially smaller training sets to yield less
biased results as compared to the case of PCA-based regularization methods. The
main advantages of the proposed technique over some existing alternatives is
demonstrated in a series of experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2702</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2702</id><created>2010-06-14</created><authors><author><keyname>Sridaran</keyname><forenames>R.</forenames></author><author><keyname>Padmavathi</keyname><forenames>G.</forenames></author><author><keyname>Iyakutti</keyname><forenames>K.</forenames></author><author><keyname>Mani</keyname><forenames>M. N. S.</forenames></author></authors><title>SPIM Architecture for MVC based Web Applications</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Model / View / Controller design pattern divides an application
environment into three components to handle the user-interactions, computations
and output respectively. This separation greatly favors architectural
reusability. The pattern works well in the case of single-address space and not
proven to be efficient for web applications involving multiple address spaces.
Web applications force the designers to decide which of the components of the
pattern are to be partitioned between the server and client(s) before the
design phase commences. For any rapidly growing web application, it is very
difficult to incorporate future changes in policies related to partitioning.
One solution to this problem is to duplicate the Model and controller
components at both server and client(s). However, this may add further problems
like delayed data fetch, security and scalability issues. In order to overcome
this, a new architecture SPIM has been proposed that deals with the
partitioning problem in an alternative way. SPIM shows tremendous improvements
in performance when compared with a similar architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2718</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2718</id><created>2010-06-11</created><authors><author><keyname>Alarcon</keyname><forenames>Rosa</forenames></author><author><keyname>Wilde</keyname><forenames>Erik</forenames></author></authors><title>From RESTful Services to RDF: Connecting the Web and the Semantic Web</title><categories>cs.AI cs.DL</categories><report-no>2010-041</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RESTful services on the Web expose information through retrievable resource
representations that represent self-describing descriptions of resources, and
through the way how these resources are interlinked through the hyperlinks that
can be found in those representations. This basic design of RESTful services
means that for extracting the most useful information from a service, it is
necessary to understand a service's representations, which means both the
semantics in terms of describing a resource, and also its semantics in terms of
describing its linkage with other resources. Based on the Resource Linking
Language (ReLL), this paper describes a framework for how RESTful services can
be described, and how these descriptions can then be used to harvest
information from these services. Building on this framework, a layered model of
RESTful service semantics allows to represent a service's information in
RDF/OWL. Because REST is based on the linkage between resources, the same model
can be used for aggregating and interlinking multiple services for extracting
RDF data from sets of RESTful services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2719</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2719</id><created>2010-06-14</created><updated>2011-08-25</updated><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Lauser</keyname><forenames>Alexander</forenames></author></authors><title>Partially Ordered Two-way B\&quot;uchi Automata</title><categories>cs.FL cs.LO</categories><comments>The results of this paper were presented at CIAA 2010; University of
  Stuttgart, Computer Science</comments><report-no>TR no. 2010/03</report-no><msc-class>68Q45</msc-class><acm-class>F.1.1; F.4.1</acm-class><doi>10.1007/978-3-642-18098-9_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce partially ordered two-way B\&quot;uchi automata and characterize
their expressive power in terms of fragments of first-order logic FO[&lt;].
Partially ordered two-way B\&quot;uchi automata are B\&quot;uchi automata which can
change the direction in which the input is processed with the constraint that
whenever a state is left, it is never re-entered again. Nondeterministic
partially ordered two-way B\&quot;uchi automata coincide with the first-order
fragment Sigma2. Our main contribution is that deterministic partially ordered
two-way B\&quot;uchi automata are expressively complete for the first-order fragment
Delta2. As an intermediate step, we show that deterministic partially ordered
two-way B\&quot;uchi automata are effectively closed under Boolean operations.
  A small model property yields coNP-completeness of the emptiness problem and
the inclusion problem for deterministic partially ordered two-way B\&quot;uchi
automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2732</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2732</id><created>2010-06-14</created><updated>2011-05-04</updated><authors><author><keyname>Kordy</keyname><forenames>Barbara</forenames></author><author><keyname>Mauw</keyname><forenames>Sjouke</forenames></author><author><keyname>Melissen</keyname><forenames>Matthijs</forenames></author><author><keyname>Schweitzer</keyname><forenames>Patrick</forenames></author></authors><title>Attack--Defense Trees and Two-Player Binary Zero-Sum Extensive Form
  Games Are Equivalent - Technical Report with Proofs</title><categories>cs.CR cs.GT</categories><comments>Added link to springerlink; Proceedings of GameSec 2010</comments><doi>10.1007/978-3-642-17197-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attack--defense trees are used to describe security weaknesses of a system
and possible countermeasures. In this paper, the connection between
attack--defense trees and game theory is made explicit. We show that
attack--defense trees and binary zero-sum two-player extensive form games have
equivalent expressive power when considering satisfiability, in the sense that
they can be converted into each other while preserving their outcome and their
internal structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2734</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2734</id><created>2010-06-14</created><authors><author><keyname>Baya</keyname><forenames>Ariel E.</forenames></author><author><keyname>Granitto</keyname><forenames>Pablo M.</forenames></author></authors><title>Penalized K-Nearest-Neighbor-Graph Based Metrics for Clustering</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A difficult problem in clustering is how to handle data with a manifold
structure, i.e. data that is not shaped in the form of compact clouds of
points, forming arbitrary shapes or paths embedded in a high-dimensional space.
In this work we introduce the Penalized k-Nearest-Neighbor-Graph (PKNNG) based
metric, a new tool for evaluating distances in such cases. The new metric can
be used in combination with most clustering algorithms. The PKNNG metric is
based on a two-step procedure: first it constructs the k-Nearest-Neighbor-Graph
of the dataset of interest using a low k-value and then it adds edges with an
exponentially penalized weight for connecting the sub-graphs produced by the
first step. We discuss several possible schemes for connecting the different
sub-graphs. We use three artificial datasets in four different embedding
situations to evaluate the behavior of the new metric, including a comparison
among different clustering methods. We also evaluate the new metric in a real
world application, clustering the MNIST digits dataset. In all cases the PKNNG
metric shows promising clustering results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2743</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2743</id><created>2010-06-14</created><authors><author><keyname>Petrik</keyname><forenames>Marek</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>Global Optimization for Value Function Approximation</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing value function approximation methods have been successfully used in
many applications, but they often lack useful a priori error bounds. We propose
a new approximate bilinear programming formulation of value function
approximation, which employs global optimization. The formulation provides
strong a priori guarantees on both robust and expected policy loss by
minimizing specific norms of the Bellman residual. Solving a bilinear program
optimally is NP-hard, but this is unavoidable because the Bellman-residual
minimization itself is NP-hard. We describe and analyze both optimal and
approximate algorithms for solving bilinear programs. The analysis shows that
this algorithm offers a convergent generalization of approximate policy
iteration. We also briefly analyze the behavior of bilinear programming
algorithms under incomplete samples. Finally, we demonstrate that the proposed
approach can consistently minimize the Bellman residual on simple benchmark
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2758</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2758</id><created>2010-06-14</created><authors><author><keyname>Sun</keyname><forenames>Liang</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Eigen-Based Transceivers for the MIMO Broadcast Channel with
  Semi-Orthogonal User Selection</title><categories>cs.IT math.IT</categories><comments>35 pages, 3 figures, to appear in IEEE transactions on signal
  processing</comments><doi>10.1109/TSP.2010.2053709</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the sum rate performance of two low complexity
eigenmode-based transmission techniques for the MIMO broadcast channel,
employing greedy semi-orthogonal user selection (SUS). The first approach,
termed ZFDPC-SUS, is based on zero-forcing dirty paper coding; the second
approach, termed ZFBF-SUS, is based on zero-forcing beamforming. We first
employ new analytical methods to prove that as the number of users K grows
large, the ZFDPC-SUS approach can achieve the optimal sum rate scaling of the
MIMO broadcast channel. We also prove that the average sum rates of both
techniques converge to the average sum capacity of the MIMO broadcast channel
for large K. In addition to the asymptotic analysis, we investigate the sum
rates achieved by ZFDPC-SUS and ZFBF-SUS for finite K, and show that ZFDPC-SUS
has significant performance advantages. Our results also provide key insights
into the benefit of multiple receive antennas, and the effect of the SUS
algorithm. In particular, we show that whilst multiple receive antennas only
improves the asymptotic sum rate scaling via the second-order behavior of the
multi-user diversity gain; for finite K, the benefit can be very significant.
We also show the interesting result that the semi-orthogonality constraint
imposed by SUS, whilst facilitating a very low complexity user selection
procedure, asymptotically does not reduce the multi-user diversity gain in
either first (log K) or second-order (loglog K) terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2769</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2769</id><created>2010-06-14</created><updated>2010-06-27</updated><authors><author><keyname>Zhang</keyname><forenames>Lili</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Achievable Rate Regions for Discrete Memoryless Interference Channel
  with State Information</title><categories>cs.IT math.IT</categories><comments>12 pages, 1 figure, submitted to Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the state-dependent two-user interference channel,
where the state information is non-causally known at both transmitters but
unknown to either of the receivers. We propose two coding schemes for the
discrete memoryless case: simultaneous encoding for the sub-messages in the
first one and superposition encoding in the second one, both with rate
splitting and Gel'fand-Pinsker coding. The corresponding achievable rate
regions are established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2772</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2772</id><created>2010-06-14</created><authors><author><keyname>Lasson</keyname><forenames>Marc</forenames></author></authors><title>Controlling program extraction in Elementary Linear Logic</title><categories>cs.LO</categories><comments>15 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an adaptation, based on program extraction in elementary linear
logic, of Krivine &amp; Leivant's system FA_2. This system allows to write
higher-order equations in order to specify the computational content of
extracted programs. The user can then prove a generic formula, using these
equations as axioms, whose proof can be extracted into programs that normalize
in elementary time and satisfy the specifications. Finally, we show that every
elementary recursive functions can be implemented in this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2786</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2786</id><created>2010-06-14</created><authors><author><keyname>kamboj</keyname><forenames>Maninder Singh</forenames></author><author><keyname>Singh</keyname><forenames>Harwinder</forenames></author></authors><title>Performance Analysis of QoS in PMP Mode WiMax Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IEEE 802.16 standard supports two different topologies: point to multipoint
(PMP) and Mesh. In this paper, a QoS mechanism for point to multipoint of IEEE
802.16 and BS scheduler for PMP Mode is proposed. This paper also describes
quality of service over WiMAX networks. Average WiMAX delay, Average WiMAX load
and Average WiMAX throughput at base station is analyzed and compared by
applying different scheduler at Base station and at fixed nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2791</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2791</id><created>2010-06-14</created><updated>2011-01-10</updated><authors><author><keyname>Yazdani</keyname><forenames>A.</forenames></author><author><keyname>Jeffrey</keyname><forenames>P.</forenames></author></authors><title>A note on measurement of network vulnerability under random and
  intentional attacks</title><categories>physics.comp-ph cond-mat.dis-nn cs.NI physics.soc-ph</categories><comments>9 pages, 2 figures</comments><msc-class>05C82, 05C42, 05C40, 68R10, 68M10, 68M14, 68M15</msc-class><acm-class>C.2.1; G.2.2; G.2.3; B.8.1; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an alternative approach for the assessment of
network vulnerability under random and intentional attacks as compared to the
results obtained from the &quot;vulnerability function&quot; given by Criado et al.
[Criado et al. (Int. J. Comput. Math., 86 (2) (2009), pp. 209-218)]. By using
spectral and statistical measurements, we assess robustness as the antonym to
vulnerability of complex networks and suggest a tentative ranking for
vulnerability, based on the interpretation of quantified network
characteristics. We conclude that vulnerability function, derived from the
network's degree distribution and its variations only, is not general enough to
reflect the lack of robustness due to the specific configurations in graphs
with hierarchical or centralized structures. The spectral and statistical
metrics, on the other hand, capture different aspects of network topology which
provide a more thorough assessment of network vulnerability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2798</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2798</id><created>2010-06-14</created><authors><author><keyname>Mohd</keyname><forenames>Mohd Norzali Haji</forenames></author><author><keyname>Wahab</keyname><forenames>Mohd Helmy Bin Abd</forenames></author><author><keyname>Ariffin</keyname><forenames>Siti Khairulnisa</forenames></author></authors><title>Motion Detection Notification System by Short Messaging Service Using
  Network Camera and Global System for Mobile Modem</title><categories>cs.NI</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p18-26, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the technology rapidly grows, the trend is clear that the use of mobile
devices is gain an attention nowadays, thus designing a system by integrating
it with notification feature is becoming an important aspect especially in
tracking and monitoring system. Conventional security surveillance systems
require the constant attention from the user, to monitor the location
concurrently. In order to reduce the cost of computing power and advance
technology of mobile phone in widespread acceptance of the Internet as a viable
communication medium, this paper is aimed to design a low cost web-based system
as a platform to view the image captured. When the network camera detects any
movement from the intruders, it automatically captures the image and sends it
to the database of the web-based directly by the network through File Transfer
Protocol (FTP). The camera is attached through an Ethernet connection and power
source. Therefore, the camera can be viewed from either standard Web browser or
cell phone. Nowadays, when a security camera is installed, user is notified as
long as the camera is switched on since any slight movement requires the
attention of the supervisor. The utility of the system has proven
theoretically. This system will also notify the user by sending a notification
through Short Messages Services (SMS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2802</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2802</id><created>2010-06-14</created><authors><author><keyname>Kewlani</keyname><forenames>Rohit</forenames></author></authors><title>Virtual On-demand Test Lab using Cloud based Architecture</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over a past few decades, VM's or Virtual machines have sort of gained a lot
of momentum, especially for large scale enterprises where the need for resource
optimization &amp; power save is humongous, without compromising with performance
or quality. They are a perfect environment to experiment with new
applications/technologies in a completely secure and closed environment. This
paper discusses how the VM technology can be leveraged to solve day to day
requirement of an odd hundreds or thousands of people, organization-wide, with
new computational resources using a cluster of heterogeneous low or high-end
machines, independent of underlying OS, thereby maximizing resource
utilization. It takes into account both opensource (like VirtualBox) &amp; other
proprietary technologies (like VMWare Workstations) available till date to
propose a viable solution using cloud computing concept. The ease of
scalability to multiple folds for optimizing performance &amp; catering to an even
larger set are some of the salient features of this approach. Using the
snapshot feature, the state of any VM instance could be saved &amp; served back
again on request. Now, this implementation is also served by VMWare ESX server
but again it's a costly solution &amp; requires dedicated high-end machines to work
with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2804</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2804</id><created>2010-06-14</created><authors><author><keyname>Gogoi</keyname><forenames>Minakshi</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>D K</forenames></author></authors><title>An Effective Fingerprint Verification Technique</title><categories>cs.CV</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p27-35, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an effective method for fingerprint verification based on
a data mining technique called minutiae clustering and a graph-theoretic
approach to analyze the process of fingerprint comparison to give a feature
space representation of minutiae and to produce a lower bound on the number of
detectably distinct fingerprints. The method also proving the invariance of
each individual fingerprint by using both the topological behavior of the
minutiae graph and also using a distance measure called Hausdorff distance.The
method provides a graph based index generation mechanism of fingerprint
biometric data. The self-organizing map neural network is also used for
classifying the fingerprints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2805</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2805</id><created>2010-06-14</created><authors><author><keyname>Tavakoli</keyname><forenames>Saeed</forenames></author><author><keyname>Banookh</keyname><forenames>Amir</forenames></author></authors><title>Robust PI Control Design Using Particle Swarm Optimization</title><categories>cs.CE</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p36-41, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a set of robust PI tuning formulae for a first order plus
dead time process using particle swarm optimization. Also, tuning formulae for
an integrating process with dead time, which is a special case of a first order
plus dead time process, is given. The design problem considers three essential
requirements of control problems, namely load disturbance rejection, setpoint
regulation and robustness of closed-loop system against model uncertainties.
The primary design goal is to optimize load disturbance rejection. Robustness
is guaranteed by requiring that the maximum sensitivity is less than or equal
to a specified value. In the first step, PI controller parameters are
determined such that the IAE criterion to a load disturbance step is minimized
and the robustness constraint on maximum sensitivity is satisfied. Using a
structure with two degrees of freedom which introduces an extra parameter, the
setpoint weight, good setpoint regulation is achieved in the second step. The
main advantage of the proposed method is its simplicity. Once the equivalent
first order plus dead time model is determined, the PI parameters are
explicitly given by a set of tuning formulae. In order to show the performance
and effectiveness of the proposed tuning formulae, they are applied to three
simulation examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2806</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2806</id><created>2010-06-14</created><authors><author><keyname>Pushkar</keyname><forenames>Shashank</forenames></author><author><keyname>Mustafi</keyname><forenames>Abhijit</forenames></author><author><keyname>Mishra</keyname><forenames>Akhileshwar</forenames></author></authors><title>A Metaheuristic Approach for IT Projects Portfolio Optimization</title><categories>cs.CE</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p42-47, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal selection of interdependent IT Projects for implementation in multi
periods has been challenging in the framework of real option valuation. This
paper presents a mathematical optimization model for multi-stage portfolio of
IT projects. The model optimizes the value of the portfolio within a given
budgetary and sequencing constraints for each period. These sequencing
constraints are due to time wise interdependencies among projects. A
Metaheuristic approach is well suited for solving this kind of a problem
definition and in this paper a genetic algorithm model has been proposed for
the solution. This optimization model and solution approach can help IT
managers taking optimal funding decision for projects prioritization in
multiple sequential periods. The model also gives flexibility to the managers
to generate alternative portfolio by changing the maximum and minimum number of
projects to be implemented in each sequential period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2807</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2807</id><created>2010-06-14</created><authors><author><keyname>Singh</keyname><forenames>Neetu</forenames></author><author><keyname>Ghrera</keyname><forenames>S. P.</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Pranay</forenames></author></authors><title>Denial of Service Attack: Analysis of Network Traffic Anormaly using
  Queuing Theory</title><categories>cs.NI</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p48-54, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denial-of-service (DOS) attacks increasingly gained reputation over the past
few years. As the Internet becomes more ubiquitous, the threat of the
denial-of-service attacks becomes more realistic and important for individuals,
businesses, governmental organizations, and even countries. There is intensive
need to detect an attack in progress as soon as possible. The efficiency of
diagnosing the DOS attack using concepts of queuing theory and performance
parameter of the system has been investigated in the present work, as the
servers definitely have some mechanisms to store and process the requests.
Utilizing this concept of queuing theory, the collection of data patterns were
generated. With the performance parameter of the system, the analysis of the
data pattern had been made to diagnose the network anomaly. Performance
analysis and results show the accuracy of the proposed scheme in detecting
anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2809</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2809</id><created>2010-06-14</created><authors><author><keyname>Zaidan</keyname><forenames>A. A</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B</forenames></author><author><keyname>Jalab</keyname><forenames>Hamid. A.</forenames></author><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author><author><keyname>Alnaqeib</keyname><forenames>Rami</forenames></author></authors><title>Offline Arabic Handwriting Recognition Using Artificial Neural Network</title><categories>cs.CL</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p55-58, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ambition of a character recognition system is to transform a text
document typed on paper into a digital format that can be manipulated by word
processor software Unlike other languages, Arabic has unique features, while
other language doesn't have, from this language these are seven or eight
language such as ordo, jewie and Persian writing, Arabic has twenty eight
letters, each of which can be linked in three different ways or separated
depending on the case. The difficulty of the Arabic handwriting recognition is
that, the accuracy of the character recognition which affects on the accuracy
of the word recognition, in additional there is also two or three from for each
character, the suggested solution by using artificial neural network can solve
the problem and overcome the difficulty of Arabic handwriting recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2811</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2811</id><created>2010-06-14</created><authors><author><keyname>Raman</keyname><forenames>Ashish</forenames></author><author><keyname>Kumar</keyname><forenames>Anvesh</forenames></author><author><keyname>Sarin</keyname><forenames>R. K.</forenames></author></authors><title>High Speed Reconfigurable FFT Design by Vedic Mathematics</title><categories>cs.OH</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p59-63, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fast Fourier Transform (FFT) is a computationally intensive digital
signal processing (DSP) function widely used in applications such as imaging,
software-defined radio, wireless communication, instrumentation. In this paper,
a reconfigurable FFT design using Vedic multiplier with high speed and small
area is presented. Urdhava Triyakbhyam algorithm of ancient Indian Vedic
Mathematics is utilized to improve its efficiency. In the proposed
architecture, the 4x4 bit multiplication operation is fragmented reconfigurable
FFT modules. The 4x4 multiplication modules are implemented using small 2x2bit
multipliers. Reconfigurability at run time is provided for attaining power
saving. The reconfigurable FFT has been designed, optimized and implemented on
an FPGA based system. This reconfigurable FFT is having the high speed and
small area as compared to the conventional FFT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2812</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2812</id><created>2010-06-14</created><authors><author><keyname>Acharya</keyname><forenames>Arup Abhinna</forenames></author><author><keyname>Jena</keyname><forenames>Sisir Kumar</forenames></author></authors><title>Component Interaction Graph: A new approach to test component
  composition</title><categories>cs.SE</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p64-67, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key factor of component based software development is component
composition technology. A Component interaction graph is used to describe the
interrelation of components. Drawing a complete component interaction graph
(CIG) provides an objective basis and technical means for making the testing
outline. Although many researches have focused on this subject, the quality of
system that is composed of components has not been guaranteed. In this paper, a
CIG is constructed from a state chart diagram and new test cases are generated
to test the component composition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2813</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2813</id><created>2010-06-14</created><authors><author><keyname>Senapati</keyname><forenames>K. K</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author><author><keyname>Bhaumik</keyname><forenames>D.</forenames></author></authors><title>Algorithm for Predicting Protein Secondary Structure</title><categories>cs.CE q-bio.BM</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p68-71, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting protein structure from amino acid sequence is one of the most
important unsolved problems of molecular biology and biophysics.Not only would
a successful prediction algorithm be a tremendous advance in the understanding
of the biochemical mechanisms of proteins, but, since such an algorithm could
conceivably be used to design proteins to carry out specific
functions.Prediction of the secondary structure of a protein (alpha-helix,
beta-sheet, coil) is an important step towards elucidating its three
dimensional structure as well as its function. In this research, we use
different Hidden Markov models for protein secondary structure prediction. In
this paper we have proposed an algorithm for predicting protein secondary
structure. We have used Hidden Markov model with sliding window for secondary
structure prediction.The secondary structure has three regular forms, for each
secondary structural element we are using one Hidden Markov Model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2814</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2814</id><created>2010-06-14</created><updated>2011-11-08</updated><authors><author><keyname>Santos</keyname><forenames>Francisco</forenames></author></authors><title>A counterexample to the Hirsch conjecture</title><categories>math.CO cs.DM math.OC</categories><comments>28 pages, 10 Figures: Changes from v2: Minor edits suggested by
  referees. This version has been accepted in the Annals of Mathematics</comments><msc-class>52B05, 52B55, 90C05</msc-class><journal-ref>Annals of Math. (2), 176 (July 2012), 383-412</journal-ref><doi>10.4007/annals.2012.176.1.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hirsch Conjecture (1957) stated that the graph of a $d$-dimensional
polytope with $n$ facets cannot have (combinatorial) diameter greater than
$n-d$. That is, that any two vertices of the polytope can be connected by a
path of at most $n-d$ edges.
  This paper presents the first counterexample to the conjecture. Our polytope
has dimension 43 and 86 facets. It is obtained from a 5-dimensional polytope
with 48 facets which violates a certain generalization of the $d$-step
conjecture of Klee and Walkup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2816</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2816</id><created>2010-06-14</created><authors><author><keyname>Pani</keyname><forenames>Santosh Kumar</forenames></author><author><keyname>Arundhati</keyname><forenames>Priya</forenames></author></authors><title>An approach to find dynamic slice for C++ Program</title><categories>cs.PL</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p72-76, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented programming has been considered a most promising method in
program development and maintenance. An important feature of object-oriented
programs (OOPs) is their reusability which can be achieved through the
inheritance of classes or reusable components.Dynamic program slicing is an
effective technique for narrowing the errors to the relevant parts of a program
when debugging. Given a slicing criterion, the dynamic slice contains only
those statements that actually affect the variables in the slicing criterion.
This paper proposes a method to dynamically slice object-oriented (00) programs
based on dependence analysis. It uses the Control Dependency Graph for object
program and other static information to reduce the information to be traced
during program execution. In this paper we present a method to find the dynamic
Slice of object oriented programs where we are finding the slices for object
and in case of function overloading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2820</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2820</id><created>2010-06-14</created><authors><author><keyname>Mishra</keyname><forenames>Divya</forenames></author><author><keyname>Mishra</keyname><forenames>Shailendra</forenames></author><author><keyname>Agnihotry</keyname><forenames>Praggya</forenames></author><author><keyname>Kaushik</keyname><forenames>B. K.</forenames></author></authors><title>Effect of Distributed Shield Insertion on Crosstalk in Inductively
  Coupled VLSI Interconnects</title><categories>cs.OH</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p77-81, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crosstalk in VLSI interconnects is a major constrain in DSM and UDSM
technology. Among various strategies followed for its minimization, shield
insertion between Aggressor and Victim is one of the prominent options. This
paper analyzes the extent of crosstalk in inductively coupled interconnects and
minimizes the same through distributed shield insertion. Comparison is drawn
between signal voltage and crosstalk voltage in three different conditions i.e.
prior to shield insertion, after shield insertion and after additional ground
tap insertion at shield terminal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2822</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2822</id><created>2010-06-14</created><authors><author><keyname>Das</keyname><forenames>Debasis</forenames></author><author><keyname>Ray</keyname><forenames>Abhishek</forenames></author></authors><title>A Parallel Encryption Algorithm for Block Ciphers Based on Reversible
  Programmable Cellular Automata</title><categories>cs.CR</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p82-90, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Cellular Automata (CA) is a computing model of complex System using simple
rule. In CA the problem space into number of cell and each cell can be one or
several final state. Cells are affected by neighbours' to the simple rule.
Cellular Automata are highly parallel and discrete dynamical systems, whose
behaviour is completely specified in terms of a local relation. This paper
deals with the Cellular Automata (CA) in cryptography for a class of Block
Ciphers through a new block encryption algorithm based on Reversible
Programmable Cellular Automata Theory. The proposed algorithm belongs to the
class of symmetric key systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2835</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2835</id><created>2010-06-14</created><authors><author><keyname>Reddy</keyname><forenames>P. Venkata Subba</forenames></author></authors><title>Fuzzy Modeling and Natural Language Processing for Panini's Sanskrit
  Grammar</title><categories>cs.CL</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p99-101, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indian languages have long history in World Natural languages. Panini was the
first to define Grammar for Sanskrit language with about 4000 rules in fifth
century. These rules contain uncertainty information. It is not possible to
Computer processing of Sanskrit language with uncertain information. In this
paper, fuzzy logic and fuzzy reasoning are proposed to deal to eliminate
uncertain information for reasoning with Sanskrit grammar. The Sanskrit
language processing is also discussed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2838</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2838</id><created>2010-06-14</created><authors><author><keyname>Vashishtha</keyname><forenames>Rohit</forenames></author><author><keyname>Gupta</keyname><forenames>Ankit</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author><author><keyname>Mishra</keyname><forenames>Shakti</forenames></author><author><keyname>Kushwaha</keyname><forenames>D S</forenames></author></authors><title>A Decentralized Approach for Service Discovery &amp; Availability in P-Grids</title><categories>cs.NI</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p102-111, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread emergence of the Internet as a platform for electronic data
distribution and the advent of structured information have revolutionized our
ability to deliver information to any corner of the world. Although Service
Oriented Architecture (SOA) is a paradigm for organizing and utilizing
distributed capabilities that may be under the control of different ownership
domains and implemented using various technology stacks and every organization
may not be geared up for this. To harness the various software / service
resources placed on various systems, we have proposed and implemented a model
that is able to establish discovery and sharing in load balanced P-grid
environment. The experimental results show that the proposed approach has
dramatically lowered the network traffic (nearly negligible), while achieving
load balancing in P2P grid systems. Our model is able to support discovery and
sharing of resources also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2840</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2840</id><created>2010-06-14</created><authors><author><keyname>Sharma</keyname><forenames>Ashish</forenames></author><author><keyname>Kushwaha</keyname><forenames>D. S.</forenames></author></authors><title>A Complexity measure based on Requirement Engineering Document</title><categories>cs.SE</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p112-117, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research shows, that the major issue in development of quality software is
precise estimation. Further this estimation depends upon the degree of
intricacy inherent in the software i.e. complexity. This paper attempts to
empirically demonstrate the proposed complexity which is based on IEEE
Requirement Engineering document. It is said that a high quality SRS is pre
requisite for high quality software. Requirement Engineering document (SRS) is
a specification for a particular software product, program or set of program
that performs some certain functions for a specific environment. The various
complexity measure given so far are based on Code and Cognitive metrics value
of software, which are code based. So these metrics provide no leverage to the
developer of the code. Considering the shortcoming of code based approaches,
the proposed approach identifies complexity of software immediately after
freezing the requirement in SDLC process. The proposed complexity measure
compares well with established complexity measures. Finally the trend can be
validated with the result of proposed measure. Ultimately, Requirement based
complexity measure can be used to understand the complexity of proposed
software much before the actual implementation of design thus saving on cost
and manpower wastage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2844</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2844</id><created>2010-06-14</created><authors><author><keyname>Burroni</keyname><forenames>Javier</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author><author><keyname>Sarraute</keyname><forenames>Carlos</forenames><affiliation>CoreLabs, Core Security Technologies</affiliation></author></authors><title>Outrepasser les limites des techniques classiques de Prise d'Empreintes
  grace aux Reseaux de Neurones</title><categories>cs.CR cs.AI cs.NE</categories><comments>16 pages, 3 figures. Symposium sur la S\'ecurit\'e des Technologies
  de l'Information et des Communications (SSTIC), Rennes, France, May 31-June
  2, 2006</comments><journal-ref>Actes du symposium SSTIC (2006)</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present an application of Artificial Intelligence techniques to the field
of Information Security. The problem of remote Operating System (OS) Detection,
also called OS Fingerprinting, is a crucial step of the penetration testing
process, since the attacker (hacker or security professional) needs to know the
OS of the target host in order to choose the exploits that he will use. OS
Detection is accomplished by passively sniffing network packets and actively
sending test packets to the target host, to study specific variations in the
host responses revealing information about its operating system.
  The first fingerprinting implementations were based on the analysis of
differences between TCP/IP stack implementations. The next generation focused
the analysis on application layer data such as the DCE RPC endpoint
information. Even though more information was analyzed, some variation of the
&quot;best fit&quot; algorithm was still used to interpret this new information. Our new
approach involves an analysis of the composition of the information collected
during the OS identification process to identify key elements and their
relations. To implement this approach, we have developed tools using Neural
Networks and techniques from the field of Statistics. These tools have been
successfully integrated in a commercial software (Core Impact).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2860</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2860</id><created>2010-06-14</created><authors><author><keyname>Kampf</keyname><forenames>Sabine</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>The Euclidean Algorithm for Generalized Minimum Distance Decoding of
  Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><doi>10.1109/CIG.2010.5592677</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method to merge Generalized Minimum Distance decoding
of Reed-Solomon codes with the extended Euclidean algorithm. By merge, we mean
that the steps taken to perform the Generalized Minimum Distance decoding are
similar to those performed by the extended Euclidean algorithm. The resulting
algorithm has a complexity of O(n^2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2867</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2867</id><created>2010-06-14</created><updated>2011-08-01</updated><authors><author><keyname>Lasson</keyname><forenames>Marc</forenames></author></authors><title>Internalized realizability in pure type systems</title><categories>cs.LO</categories><comments>Technical report. Very dry. The paper has beenbeen withdrawn: it is
  superseded by &quot;Realizability and Parametricity in Pure Type Systems&quot; in
  FOSSACS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let P be any pure type system, we are going to show how we can extend P into
a PTS P' which will be used as a proof system whose formulas express properties
about sets of terms of P. We will show that P' is strongly normalizable if and
only if P is. Given a term t in P and a formula F in P', P' is expressive
enough to construct a formula &quot;t ||- F&quot; that is interpreted as &quot;t is a realizer
of F&quot;. We then prove the following adequacy theorem: if F is provable then by
projecting its proof back to a term t in P we obtain a proof that &quot;t ||- F&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2880</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2880</id><created>2010-06-14</created><updated>2010-08-31</updated><authors><author><keyname>Bahmani</keyname><forenames>Bahman</forenames></author><author><keyname>Chowdhury</keyname><forenames>Abdur</forenames></author><author><keyname>Goel</keyname><forenames>Ashish</forenames></author></authors><title>Fast Incremental and Personalized PageRank</title><categories>cs.DS cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the efficiency of Monte Carlo methods for
incremental computation of PageRank, personalized PageRank, and similar random
walk based methods (with focus on SALSA), on large-scale dynamically evolving
social networks. We assume that the graph of friendships is stored in
distributed shared memory, as is the case for large social networks such as
Twitter.
  For global PageRank, we assume that the social network has $n$ nodes, and $m$
adversarially chosen edges arrive in a random order. We show that with a reset
probability of $\epsilon$, the total work needed to maintain an accurate
estimate (using the Monte Carlo method) of the PageRank of every node at all
times is $O(\frac{n\ln m}{\epsilon^{2}})$. This is significantly better than
all known bounds for incremental PageRank. For instance, if we naively
recompute the PageRanks as each edge arrives, the simple power iteration method
needs $\Omega(\frac{m^2}{\ln(1/(1-\epsilon))})$ total time and the Monte Carlo
method needs $O(mn/\epsilon)$ total time; both are prohibitively expensive.
Furthermore, we also show that we can handle deletions equally efficiently.
  We then study the computation of the top $k$ personalized PageRanks starting
from a seed node, assuming that personalized PageRanks follow a power-law with
exponent $\alpha &lt; 1$. We show that if we store $R&gt;q\ln n$ random walks
starting from every node for large enough constant $q$ (using the approach
outlined for global PageRank), then the expected number of calls made to the
distributed social network database is $O(k/(R^{(1-\alpha)/\alpha}))$.
  We also present experimental results from the social networking site,
Twitter, verifying our assumptions and analyses. The overall result is that
this algorithm is fast enough for real-time queries over a dynamic social
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2883</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2883</id><created>2010-06-15</created><updated>2010-12-24</updated><authors><author><keyname>Bobkov</keyname><forenames>Sergey</forenames></author><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author></authors><title>The entropy per coordinate of a random vector is highly constrained
  under convexity conditions</title><categories>cs.IT math.FA math.IT math.PR</categories><comments>15 pages, revised for IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 57, no. 8, pp.
  4940-4954, August 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The entropy per coordinate in a log-concave random vector of any dimension
with given density at the mode is shown to have a range of just 1. Uniform
distributions on convex bodies are at the lower end of this range, the
distribution with i.i.d. exponentially distributed coordinates is at the upper
end, and the normal is exactly in the middle. Thus in terms of the amount of
randomness as measured by entropy per coordinate, any log-concave random vector
of any dimension contains randomness that differs from that in the normal
random variable with the same maximal density value by at most 1/2. As
applications, we obtain an information-theoretic formulation of the famous
hyperplane conjecture in convex geometry, entropy bounds for certain infinitely
divisible distributions, and quantitative estimates for the behavior of the
density at the mode on convolution. More generally, one may consider so-called
convex or hyperbolic probability measures on Euclidean spaces; we give new
constraints on entropy per coordinate for this class of measures, which
generalize our results under the log-concavity assumption, expose the extremal
role of multivariate Pareto-type distributions, and give some applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2884</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2884</id><created>2010-06-15</created><updated>2011-01-01</updated><authors><author><keyname>Bobkov</keyname><forenames>Sergey</forenames></author><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author><author><keyname>Wang</keyname><forenames>Liyao</forenames></author></authors><title>Fractional generalizations of Young and Brunn-Minkowski inequalities</title><categories>math.FA cs.IT math.IT math.PR</categories><comments>19 pages, numerous typos corrected, exposition improved, and
  references added, but no other substantial changes</comments><journal-ref>Contemporary Mathematics 545, American Mathematical Society, 2011,
  pp. 35-53</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalization of Young's inequality for convolution with sharp constant is
conjectured for scenarios where more than two functions are being convolved,
and it is proven for certain parameter ranges. The conjecture would provide a
unified proof of recent entropy power inequalities of Barron and Madiman, as
well as of a (conjectured) generalization of the Brunn-Minkowski inequality. It
is shown that the generalized Brunn-Minkowski conjecture is true for convex
sets; an application of this to the law of large numbers for random sets is
described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2895</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2895</id><created>2010-06-15</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author></authors><title>Scopus' SNIP Indicator</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rejoinder to Moed [arXiv:1005.4906]: Our main objection is against developing
new indicators which, like some of the older ones (for example, the &quot;crown
indicator&quot; of CWTS), do not allow for indicating error because they do not
provide a statistics, but are based, in our opinion, on a violation of the
order of operations. The claim of validity for the SNIP indicator is hollow
because the normalizations are based on field classifications which are not
valid. Both problems can perhaps be solved by using fractional counting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2896</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2896</id><created>2010-06-15</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author></authors><title>Normalization at the field level: fractional counting of citations</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Van Raan et al. (2010; arXiv:1003.2113) have proposed a new indicator (MNCS)
for field normalization. Since field normalization is also used in the Leiden
Rankings of universities, we elaborate our critique of journal normalization in
Opthof &amp; Leydesdorff (2010; arXiv:1002.2769) in this rejoinder concerning field
normalization. Fractional citation counting thoroughly solves the issue of
normalization for differences in citation behavior among fields. This indicator
can also be used to obtain a normalized impact factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2897</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2897</id><created>2010-06-15</created><updated>2010-11-25</updated><authors><author><keyname>Bryans</keyname><forenames>Nathaniel</forenames></author><author><keyname>Chiniforooshan</keyname><forenames>Ehsan</forenames></author><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author></authors><title>The Power of Nondeterminism in Self-Assembly</title><categories>cs.CC cs.DS</categories><comments>Accepted to SODA 2011. The previous version of this paper (which
  appears in the SODA proceedings) had open questions about computing the
  minimum number of tile types to weakly self-assemble a set. The answer to
  these questions is &quot;no&quot;, by a very simple imitation of the proof that
  Kolmogorov complexity is uncomputable based on the Berry paradox. These open
  questions have been removed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the role of nondeterminism in Winfree's abstract Tile Assembly
Model (aTAM), which was conceived to model artificial molecular self-assembling
systems constructed from DNA. Of particular practical importance is to find
tile systems that minimize resources such as the number of distinct tile types,
each of which corresponds to a set of DNA strands that must be
custom-synthesized in actual molecular implementations of the aTAM. We seek to
identify to what extent the use of nondeterminism in tile systems affects the
resources required by such molecular shape-building algorithms.
  We first show a &quot;molecular computability theoretic&quot; result: there is an
infinite shape S that is uniquely assembled by a tile system but not by any
deterministic tile system. We then show an analogous phenomenon in the finitary
&quot;molecular complexity theoretic&quot; case: there is a finite shape S that is
uniquely assembled by a tile system with c tile types, but every deterministic
tile system that uniquely assembles S has more than c tile types. In fact we
extend the technique to derive a stronger (classical complexity theoretic)
result, showing that the problem of finding the minimum number of tile types
that uniquely assemble a given finite shape is Sigma-P-2-complete. In contrast,
the problem of finding the minimum number of deterministic tile types that
uniquely assemble a shape was shown to be NP-complete by Adleman, Cheng, Goel,
Huang, Kempe, Moisset de Espan\'es, and Rothemund (Combinatorial Optimization
Problems in Self-Assembly, STOC 2002).
  The conclusion is that nondeterminism confers extra power to assemble a shape
from a small tile system, but unless the polynomial hierarchy collapses, it is
computationally more difficult to exploit this power by finding the size of the
smallest tile system, compared to finding the size of the smallest
deterministic tile system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2899</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2899</id><created>2010-06-15</created><updated>2012-07-09</updated><authors><author><keyname>Hazan</keyname><forenames>Tamir</forenames></author><author><keyname>Urtasun</keyname><forenames>Raquel</forenames></author></authors><title>Approximated Structured Prediction for Learning Large Scale Graphical
  Models</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscripts contains the proofs for &quot;A Primal-Dual Message-Passing
Algorithm for Approximated Large Scale Structured Prediction&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2902</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2902</id><created>2010-06-15</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author></authors><title>How to generate an object under an ordinary Boltzmann distribution via
  an exponential Boltzmann sampler</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note presents an efficient way to derive from an exponential
Boltzmann sampler a ordinary Boltzmann sampler
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2921</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2921</id><created>2010-06-15</created><authors><author><keyname>Echenim</keyname><forenames>Mnacho</forenames></author><author><keyname>Peltier</keyname><forenames>Nicolas</forenames></author></authors><title>Instantiation of SMT problems modulo Integers</title><categories>cs.LO</categories><comments>Research report, long version of our AISC 2010 paper</comments><msc-class>68T15</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many decision procedures for SMT problems rely more or less implicitly on an
instantiation of the axioms of the theories under consideration, and differ by
making use of the additional properties of each theory, in order to increase
efficiency. We present a new technique for devising complete instantiation
schemes on SMT problems over a combination of linear arithmetic with another
theory T. The method consists in first instantiating the arithmetic part of the
formula, and then getting rid of the remaining variables in the problem by
using an instantiation strategy which is complete for T. We provide examples
evidencing that not only is this technique generic (in the sense that it
applies to a wide range of theories) but it is also efficient, even compared to
state-of-the-art instantiation schemes for specific theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2926</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2926</id><created>2010-06-15</created><authors><author><keyname>Horev</keyname><forenames>Elad</forenames></author><author><keyname>Krakovski</keyname><forenames>Roi</forenames></author><author><keyname>Smorodinsky</keyname><forenames>Shakhar</forenames></author></authors><title>Conflict-Free Coloring Made Stronger</title><categories>math.CO cs.CG cs.DS</categories><doi>10.1007/978-3-642-13731-0_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In FOCS 2002, Even et al. showed that any set of $n$ discs in the plane can
be Conflict-Free colored with a total of at most $O(\log n)$ colors. That is,
it can be colored with $O(\log n)$ colors such that for any (covered) point $p$
there is some disc whose color is distinct from all other colors of discs
containing $p$. They also showed that this bound is asymptotically tight. In
this paper we prove the following stronger results:
  \begin{enumerate} \item [(i)] Any set of $n$ discs in the plane can be
colored with a total of at most $O(k \log n)$ colors such that (a) for any
point $p$ that is covered by at least $k$ discs, there are at least $k$
distinct discs each of which is colored by a color distinct from all other
discs containing $p$ and (b) for any point $p$ covered by at most $k$ discs,
all discs covering $p$ are colored distinctively. We call such a coloring a
{\em $k$-Strong Conflict-Free} coloring. We extend this result to pseudo-discs
and arbitrary regions with linear union-complexity.
  \item [(ii)] More generally, for families of $n$ simple closed Jordan regions
with union-complexity bounded by $O(n^{1+\alpha})$, we prove that there exists
a $k$-Strong Conflict-Free coloring with at most $O(k n^\alpha)$ colors.
  \item [(iii)] We prove that any set of $n$ axis-parallel rectangles can be
$k$-Strong Conflict-Free colored with at most $O(k \log^2 n)$ colors.
  \item [(iv)] We provide a general framework for $k$-Strong Conflict-Free
coloring arbitrary hypergraphs. This framework relates the notion of $k$-Strong
Conflict-Free coloring and the recently studied notion of $k$-colorful
coloring. \end{enumerate}
  All of our proofs are constructive. That is, there exist polynomial time
algorithms for computing such colorings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2944</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2944</id><created>2010-06-15</created><updated>2010-09-06</updated><authors><author><keyname>Kahrs</keyname><forenames>Stefan Michael</forenames><affiliation>University of Kent</affiliation></author></authors><title>Modularity of Convergence and Strong Convergence in Infinitary Rewriting</title><categories>cs.LO cs.FL</categories><proxy>LMCS</proxy><acm-class>F.4.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  6, 2010) lmcs:878</journal-ref><doi>10.2168/LMCS-6(3:18)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Properties of Term Rewriting Systems are called modular iff they are
preserved under (and reflected by) disjoint union, i.e. when combining two Term
Rewriting Systems with disjoint signatures. Convergence is the property of
Infinitary Term Rewriting Systems that all reduction sequences converge to a
limit. Strong Convergence requires in addition that redex positions in a
reduction sequence move arbitrarily deep. In this paper it is shown that both
Convergence and Strong Convergence are modular properties of non-collapsing
Infinitary Term Rewriting Systems, provided (for convergence) that the term
metrics are granular. This generalises known modularity results beyond metric
\infty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2945</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2945</id><created>2010-06-15</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan M.</forenames></author></authors><title>Two-Timescale Learning Using Idiotypic Behaviour Mediation For A
  Navigating Mobile Robot</title><categories>cs.AI cs.NE cs.RO</categories><comments>40 pages, 12 tables, Journal of Applied Soft Computing</comments><journal-ref>Journal of Applied Soft Computing, 10, p 876-887, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to
solving mobile-robot navigation problems is presented and tested in both the
real and virtual domains. The LTL phase consists of rapid simulations that use
a Genetic Algorithm to derive diverse sets of behaviours, encoded as variable
sets of attributes, and the STL phase is an idiotypic Artificial Immune System.
Results from the LTL phase show that sets of behaviours develop very rapidly,
and significantly greater diversity is obtained when multiple autonomous
populations are used, rather than a single one. The architecture is assessed
under various scenarios, including removal of the LTL phase and switching off
the idiotypic mechanism in the STL phase. The comparisons provide substantial
evidence that the best option is the inclusion of both the LTL phase and the
idiotypic system. In addition, this paper shows that structurally different
environments can be used for the two phases without compromising
transferability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2951</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2951</id><created>2010-06-15</created><updated>2010-08-21</updated><authors><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author><author><keyname>Calude</keyname><forenames>Elena</forenames></author><author><keyname>Svozil</keyname><forenames>Karl</forenames></author></authors><title>The Complexity of Proving Chaoticity and the Church-Turing Thesis</title><categories>nlin.CD cs.CC physics.gen-ph</categories><comments>13 pages, new proof of the main theorem</comments><report-no>CDMTCS preprint nr. 384/2010</report-no><journal-ref>Chaos: An Interdisciplinary Journal of Nonlinear Science 20(3),
  037103 (2010)</journal-ref><doi>10.1063/1.3489096</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proving the chaoticity of some dynamical systems is equivalent to solving the
hardest problems in mathematics. Conversely, one argues that it is not
unconceivable that classical physical systems may &quot;compute the hard or even the
incomputable&quot; by measuring observables which correspond to computationally hard
or even incomputable problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2955</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2955</id><created>2010-06-15</created><authors><author><keyname>Dash</keyname><forenames>Dinesh</forenames></author><author><keyname>Bishnu</keyname><forenames>Arijit</forenames></author><author><keyname>Gupta</keyname><forenames>Arobinda</forenames></author><author><keyname>Nandy</keyname><forenames>Subhas C.</forenames></author></authors><title>Approximation Algorithm for Line Segment Coverage for Wireless Sensor
  Network</title><categories>cs.CG cs.DS</categories><comments>16 pages, 5 figures,</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The coverage problem in wireless sensor networks deals with the problem of
covering a region or parts of it with sensors. In this paper, we address the
problem of covering a set of line segments in sensor networks. A line segment `
is said to be covered if it intersects the sensing regions of at least one
sensor distributed in that region. We show that the problem of ?nding the
minimum number of sensors needed to cover each member in a given set of line
segments in a rectangular area is NP-hard. Next, we propose a constant factor
approximation algorithm for the problem of covering a set of axis-parallel line
segments. We also show that a PTAS exists for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2958</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2958</id><created>2010-06-15</created><authors><author><keyname>Aubry</keyname><forenames>Yves</forenames><affiliation>IML</affiliation></author><author><keyname>Jean-Christophe</keyname><forenames>Godin</forenames><affiliation>IML</affiliation></author><author><keyname>Olivier</keyname><forenames>Togni</forenames><affiliation>LE2I</affiliation></author></authors><title>Extended core and choosability of a graph</title><categories>cs.DM</categories><comments>10 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is $(a,b)$-choosable if for any color list of size $a$ associated
with each vertices, one can choose a subset of $b$ colors such that adjacent
vertices are colored with disjoint color sets. This paper shows an equivalence
between the $(a,b)$-choosability of a graph and the $(a,b)$-choosability of one
of its subgraphs called the extended core. As an application, this result
allows to prove the $(5,2)$-choosability and $(7,3)$-colorability of
triangle-free induced subgraphs of the triangular lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2977</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2977</id><created>2010-06-15</created><authors><author><keyname>Kelley</keyname><forenames>Christine A.</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author></authors><title>Algebraic Constructions of Graph-Based Nested Codes from Protographs</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, To appear in 2010 IEEE International Symposium on
  Information Theory, Austin, TX, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nested codes have been employed in a large number of communication
applications as a specific case of superposition codes, for example to
implement binning schemes in the presence of noise, in joint network-channel
coding, or in physical-layer secrecy. Whereas nested lattice codes have been
proposed recently for continuous-input channels, in this paper we focus on the
construction of nested linear codes for joint channel-network coding problems
based on algebraic protograph LDPC codes. In particular, over the past few
years several constructions of codes have been proposed that are based on
random lifts of suitably chosen base graphs. More recently, an algebraic analog
of this approach was introduced using the theory of voltage graphs. In this
paper we illustrate how these methods can be used in the construction of nested
codes from algebraic lifts of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2992</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2992</id><created>2010-06-07</created><authors><author><keyname>Paul</keyname><forenames>Soumya</forenames><affiliation>The Institute of Mathematical Sciences, Chennai</affiliation></author><author><keyname>Ramanujam</keyname><forenames>R.</forenames><affiliation>The Institute of Mathematical Sciences, Chennai</affiliation></author></authors><title>Imitation in Large Games</title><categories>cs.GT cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 25, 2010, pp. 162-172</journal-ref><doi>10.4204/EPTCS.25.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In games with a large number of players where players may have overlapping
objectives, the analysis of stable outcomes typically depends on player types.
A special case is when a large part of the player population consists of
imitation types: that of players who imitate choice of other (optimizing)
types. Game theorists typically study the evolution of such games in dynamical
systems with imitation rules. In the setting of games of infinite duration on
finite graphs with preference orderings on outcomes for player types, we
explore the possibility of imitation as a viable strategy. In our setup, the
optimising players play bounded memory strategies and the imitators play
according to specifications given by automata. We present algorithmic results
on the eventual survival of types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2993</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2993</id><created>2010-06-07</created><authors><author><keyname>Cardelli</keyname><forenames>Luca</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Two-Domain DNA Strand Displacement</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 47-61</journal-ref><doi>10.4204/EPTCS.26.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the computing power of a restricted class of DNA strand
displacement structures: those that are made of double strands with nicks
(interruptions) in the top strand. To preserve this structural invariant, we
impose restrictions on the single strands they interact with: we consider only
two-domain single strands consisting of one toehold domain and one recognition
domain. We study fork and join signal-processing gates based on these
structures, and we show that these systems are amenable to formalization and to
mechanical verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2996</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.2996</id><created>2010-06-15</created><authors><author><keyname>Zhang</keyname><forenames>Guoqiang</forenames></author><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author><author><keyname>&#xd8;stergaard</keyname><forenames>Jan</forenames></author></authors><title>Bounding the Rate Region of Vector Gaussian Multiple Descriptions with
  Individual and Central Receivers</title><categories>cs.IT math.IT</categories><comments>34 pages, submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the rate region of the vector Gaussian multiple description
problem with individual and central quadratic distortion constraints is
studied. In particular, an outer bound to the rate region of the L-description
problem is derived. The bound is obtained by lower bounding a weighted sum rate
for each supporting hyperplane of the rate region. The key idea is to introduce
at most L-1 auxiliary random variables and further impose upon the variables a
Markov structure according to the ordering of the description weights. This
makes it possible to greatly simplify the derivation of the outer bound. In the
scalar Gaussian case, the complete rate region is fully characterized by
showing that the outer bound is tight. In this case, the optimal weighted sum
rate for each supporting hyperplane is obtained by solving a single
maximization problem. This contrasts with existing results, which require
solving a min-max optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3009</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3009</id><created>2010-06-15</created><authors><author><keyname>Blin</keyname><forenames>L&#xe9;lia</forenames><affiliation>IBISC</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Rovedakis</keyname><forenames>Stephane</forenames><affiliation>IBISC</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Universal Loop-Free Super-Stabilization</title><categories>cs.DC cs.DS cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an univesal scheme to design loop-free and super-stabilizing
protocols for constructing spanning trees optimizing any tree metrics (not only
those that are isomorphic to a shortest path tree). Our scheme combines a novel
super-stabilizing loop-free BFS with an existing self-stabilizing spanning tree
that optimizes a given metric. The composition result preserves the best
properties of both worlds: super-stabilization, loop-freedom, and optimization
of the original metric without any stabilization time penalty. As case study we
apply our composition mechanism to two well known metric-dependent spanning
trees: the maximum-flow tree and the minimum degree spanning tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3017</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3017</id><created>2010-06-15</created><authors><author><keyname>Carofiglio</keyname><forenames>Giovanna</forenames></author><author><keyname>Muscariello</keyname><forenames>Luca</forenames></author><author><keyname>Rossi</keyname><forenames>Dario</forenames></author><author><keyname>Testa</keyname><forenames>Claudio</forenames></author></authors><title>A hands-on Assessment of Transport Protocols with Lower than Best Effort
  Priority</title><categories>cs.NI</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Last year, the official BitTorrent client switched to LEDBAT, a new
congestion control algorithm targeting a lower-than Best Effort transport
service. In this paper, we study this new protocol through packet-level
simulations, with a special focus on a performance comparison with other
lower-than Best Effort protocols such as TCP-LP and TCP-NICE: our aim is indeed
to quantify and relatively weight the level of Low-priority provided by such
protocols.
  Our results show that LEDBAT transport generally achieves the lowest possible
level of priority, with the default configurations of TCP-NICE and TCP-LP
representing increasing levels of aggressiveness. In addition, we perform a
careful sensitivity analysis of LEDBAT performance, by tuning its main
parameters in both inter-protocol (against TCP) and intra-protocol (against
LEDBAT itself) scenarios. In the inter-protocol case, although in case of
misconfiguration LEDBAT competes as aggressively as TCP, however we show that
it is not possible to achieve an arbitrary level of low-priority by merely
tuning its parameters. In the intra-protocol case, we show that coexistence of
legacy flows with slightly dissimilar settings, or experiencing different
network conditions, can result in significant unfairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3018</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3018</id><created>2010-06-15</created><authors><author><keyname>Carofiglio</keyname><forenames>Giovanna</forenames></author><author><keyname>Muscariello</keyname><forenames>Luca</forenames></author><author><keyname>Rossi</keyname><forenames>Dario</forenames></author><author><keyname>Valenti</keyname><forenames>Silvio</forenames></author></authors><title>The quest for LEDBAT fairness</title><categories>cs.NI</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BitTorrent developers have recently introduced a new application layer
congestion control algorithm based on UDP framing at transport layer and
currently under definition at the IETF LEDBAT Working Group. LEDBAT is a
delay-based protocol which aims at offering a &quot;lower than Best Effort&quot; data
transfer service, with a lower priority with respect to elastic TCP and
interactive traffic (e.g., VoIP, game). However, in its current specification,
LEDBAT is affected by a late-comer advantage: indeed the last flow arriving at
the bottleneck is more aggressive due to a wrong estimation of the base delay
and finally takes over all resources. In this work, we study several solutions
to the late-comer problem by means of packet level simulations and simple
analysis: in the investigation process, we individuate the root cause for
LEDBAT unfairness and propose effective countermeasures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3020</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3020</id><created>2010-06-15</created><updated>2011-11-29</updated><authors><author><keyname>Nastos</keyname><forenames>James</forenames></author><author><keyname>Gao</keyname><forenames>Yong</forenames></author></authors><title>Bounded Search Tree Algorithms for Parameterized Cograph Deletion:
  Efficient Branching Rules by Exploiting Structures of Special Graph Classes</title><categories>cs.DM cs.DS</categories><comments>23 pages. Accepted in Discrete Mathematics, Algorithms and
  Applications (DMAA)</comments><doi>10.1007/978-3-642-17461-2_27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many fixed-parameter tractable algorithms using a bounded search tree have
been repeatedly improved, often by describing a larger number of branching
rules involving an increasingly complex case analysis. We introduce a novel and
general search strategy that branches on the forbidden subgraphs of a graph
class relaxation. By using the class of $P_4$-sparse graphs as the relaxed
graph class, we obtain efficient bounded search tree algorithms for several
parameterized deletion problems. We give the first non-trivial bounded search
tree algorithms for the cograph edge-deletion problem and the trivially perfect
edge-deletion problems. For the cograph vertex deletion problem, a refined
analysis of the runtime of our simple bounded search algorithm gives a faster
exponential factor than those algorithms designed with the help of complicated
case distinctions and non-trivial running time analysis [21] and computer-aided
branching rules [11].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3021</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3021</id><created>2010-06-15</created><authors><author><keyname>Fink</keyname><forenames>Michael</forenames></author></authors><title>A General Framework for Equivalences in Answer-Set Programming by
  Countermodels in the Logic of Here-and-There</title><categories>cs.AI</categories><comments>32 pages; to appear in Theory and Practice of Logic Programming
  (TPLP)</comments><report-no>INFSYS RR-1843-09-05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different notions of equivalence, such as the prominent notions of strong and
uniform equivalence, have been studied in Answer-Set Programming, mainly for
the purpose of identifying programs that can serve as substitutes without
altering the semantics, for instance in program optimization. Such semantic
comparisons are usually characterized by various selections of models in the
logic of Here-and-There (HT). For uniform equivalence however, correct
characterizations in terms of HT-models can only be obtained for finite
theories, respectively programs. In this article, we show that a selection of
countermodels in HT captures uniform equivalence also for infinite theories.
This result is turned into coherent characterizations of the different notions
of equivalence by countermodels, as well as by a mixture of HT-models and
countermodels (so-called equivalence interpretations). Moreover, we generalize
the so-called notion of relativized hyperequivalence for programs to
propositional theories, and apply the same methodology in order to obtain a
semantic characterization which is amenable to infinite settings. This allows
for a lifting of the results to first-order theories under a very general
semantics given in terms of a quantified version of HT. We thus obtain a
general framework for the study of various notions of equivalence for theories
under answer-set semantics. Moreover, we prove an expedient property that
allows for a simplified treatment of extended signatures, and provide further
results for non-ground logic programs. In particular, uniform equivalence
coincides under open and ordinary answer-set semantics, and for finite
non-ground programs under these semantics, also the usual characterization of
uniform equivalence in terms of maximal and total HT-models of the grounding is
correct, even for infinite domains, when corresponding ground programs are
infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3027</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3027</id><created>2010-06-15</created><authors><author><keyname>Kurz</keyname><forenames>Alexander</forenames></author><author><keyname>Petri&#x15f;an</keyname><forenames>Daniela</forenames></author><author><keyname>Velebil</keyname><forenames>Ji&#x159;&#xed;</forenames></author></authors><title>Algebraic Theories over Nominal Sets</title><categories>cs.LO math.CT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the foundations of a theory of algebraic data types with
variable binding inside classical universal algebra. In the first part, a
category-theoretic study of monads over the nominal sets of Gabbay and Pitts
leads us to introduce new notions of finitary based monads and uniform monads.
In a second part we spell out these notions in the language of universal
algebra, show how to recover the logics of Gabbay-Mathijssen and
Clouston-Pitts, and apply classical results from universal algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3030</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3030</id><created>2010-06-15</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author></authors><title>Satisfiability Thresholds for k-CNF Formula with Bounded Variable
  Intersections</title><categories>cs.DM</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the thresholds for the number of variables, number of clauses,
number of clause intersection pairs and the maximum clause degree of a k-CNF
formula that guarantees satisfiability under the assumption that every two
clauses share at most $\alpha$ variables. More formally, we call these formulas
$\alpha$-intersecting and define, for example, a threshold $\mu_i(k,\alpha)$
for the number of clause intersection pairs $i$, such that every
$\alpha$-intersecting k-CNF formula in which at most $\mu_i(k,\alpha)$ pairs of
clauses share a variable is satisfiable and there exists an unsatisfiable
$\alpha$-intersecting k-CNF formula with $\mu_m(k,\alpha)$ such intersections.
We provide a lower bound for these thresholds based on the Lovasz Local Lemma
and a nearly matching upper bound by constructing an unsatisfiable k-CNF to
show that $\mu_i(k,\alpha) = \tilde{\Theta}(2^{k(2+1/\alpha)})$. Similar
thresholds are determined for the number of variables ($\mu_n =
\tilde{\Theta}(2^{k/\alpha})$) and the number of clauses ($\mu_m =
\tilde{\Theta}(2^{k(1+\frac{1}{\alpha})})$) (see [Scheder08] for an earlier but
independent report on this threshold). Our upper bound construction gives a
family of unsatisfiable formula that achieve all four thresholds
simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3033</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3033</id><created>2010-06-15</created><updated>2010-11-27</updated><authors><author><keyname>Bouboulis</keyname><forenames>Pantelis</forenames></author><author><keyname>Theodoridis</keyname><forenames>Sergios</forenames></author></authors><title>Extension of Wirtinger's Calculus to Reproducing Kernel Hilbert Spaces
  and the Complex Kernel LMS</title><categories>cs.LG</categories><comments>15 pages (double column), preprint of article accepted in IEEE Trans.
  Sig. Proc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade, kernel methods for nonlinear processing have
successfully been used in the machine learning community. The primary
mathematical tool employed in these methods is the notion of the Reproducing
Kernel Hilbert Space. However, so far, the emphasis has been on batch
techniques. It is only recently, that online techniques have been considered in
the context of adaptive signal processing tasks. Moreover, these efforts have
only been focussed on real valued data sequences. To the best of our knowledge,
no adaptive kernel-based strategy has been developed, so far, for complex
valued signals. Furthermore, although the real reproducing kernels are used in
an increasing number of machine learning problems, complex kernels have not,
yet, been used, in spite of their potential interest in applications that deal
with complex signals, with Communications being a typical example. In this
paper, we present a general framework to attack the problem of adaptive
filtering of complex signals, using either real reproducing kernels, taking
advantage of a technique called \textit{complexification} of real RKHSs, or
complex reproducing kernels, highlighting the use of the complex gaussian
kernel. In order to derive gradients of operators that need to be defined on
the associated complex RKHSs, we employ the powerful tool of Wirtinger's
Calculus, which has recently attracted attention in the signal processing
community. To this end, in this paper, the notion of Wirtinger's calculus is
extended, for the first time, to include complex RKHSs and use it to derive
several realizations of the Complex Kernel Least-Mean-Square (CKLMS) algorithm.
Experiments verify that the CKLMS offers significant performance improvements
over several linear and nonlinear algorithms, when dealing with nonlinearities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3035</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3035</id><created>2010-06-15</created><authors><author><keyname>Cohen</keyname><forenames>Shay B.</forenames></author><author><keyname>Simmons</keyname><forenames>Robert J.</forenames></author><author><keyname>Smith</keyname><forenames>Noah A.</forenames></author></authors><title>Products of Weighted Logic Programs</title><categories>cs.AI cs.PL</categories><journal-ref>TLP 11 (2-3): 263-296, 2011</journal-ref><doi>10.1017/S1471068410000529</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted logic programming, a generalization of bottom-up logic programming,
is a well-suited framework for specifying dynamic programming algorithms. In
this setting, proofs correspond to the algorithm's output space, such as a path
through a graph or a grammatical derivation, and are given a real-valued score
(often interpreted as a probability) that depends on the real weights of the
base axioms used in the proof. The desired output is a function over all
possible proofs, such as a sum of scores or an optimal score. We describe the
PRODUCT transformation, which can merge two weighted logic programs into a new
one. The resulting program optimizes a product of proof scores from the
original programs, constituting a scoring function known in machine learning as
a ``product of experts.'' Through the addition of intuitive constraining side
conditions, we show that several important dynamic programming algorithms can
be derived by applying PRODUCT to weighted logic programs corresponding to
simpler weighted logic programs. In addition, we show how the computation of
Kullback-Leibler divergence, an information-theoretic measure, can be
interpreted using PRODUCT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3039</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3039</id><created>2010-06-15</created><updated>2010-06-20</updated><authors><author><keyname>Lam</keyname><forenames>Edmund S. L.</forenames></author><author><keyname>Sulzmann</keyname><forenames>Martin</forenames></author></authors><title>Concurrent Goal-Based Execution of Constraint Handling Rules</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (To appear in Theory and Practice of Logic Programming (TPLP)) We introduce a
systematic, concurrent execution scheme for Constraint Handling Rules (CHR)
based on a previously proposed sequential goal-based CHR semantics. We
establish strong correspondence results to the abstract CHR semantics, thus
guaranteeing that any answer in the concurrent, goal-based CHR semantics is
reproducible in the abstract CHR semantics. Our work provides the foundation to
obtain efficient, parallel CHR execution schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3046</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3046</id><created>2010-06-15</created><authors><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Identifying Shapes Using Self-Assembly (extended abstract)</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the following problem in the theory of
algorithmic self-assembly: given an input shape as the seed of a tile-based
self-assembly system, design a finite tile set that can, in some sense,
uniquely identify whether or not the given input shape--drawn from a very
general class of shapes--matches a particular target shape. We first study the
complexity of correctly identifying squares. Then we investigate the complexity
associated with the identification of a considerably more general class of
non-square, hole-free shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3056</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3056</id><created>2010-06-15</created><authors><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian
  Mixture Models to Structured Sparsity</title><categories>cs.CV</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general framework for solving image inverse problems is introduced in this
paper. The approach is based on Gaussian mixture models, estimated via a
computationally efficient MAP-EM algorithm. A dual mathematical interpretation
of the proposed framework with structured sparse estimation is described, which
shows that the resulting piecewise linear estimate stabilizes the estimation
when compared to traditional sparse inverse problem techniques. This
interpretation also suggests an effective dictionary motivated initialization
for the MAP-EM algorithm. We demonstrate that in a number of image inverse
problems, including inpainting, zooming, and deblurring, the same algorithm
produces either equal, often significantly better, or very small margin worse
results than the best published ones, at a lower computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3112</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3112</id><created>2010-06-15</created><authors><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Kholosha</keyname><forenames>Alexander</forenames></author></authors><title>Sequences, Bent Functions and Jacobsthal sums</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $p$-ary function $f(x)$ mapping $\mathrm{GF}(p^{4k})$ to $\mathrm{GF}(p)$
and given by $f(x)={\rm Tr}_{4k}\big(ax^d+bx^2\big)$ with
$a,b\in\mathrm{GF}(p^{4k})$ and $d=p^{3k}+p^{2k}-p^k+1$ is studied with the
respect to its exponential sum. In the case when either $a^{p^k(p^k+1)}\neq
b^{p^k+1}$ or $a^2=b^d$ with $b\neq 0$, this sum is shown to be three-valued
and the values are determined. For the remaining cases, the value of the
exponential sum is expressed using Jacobsthal sums of order $p^k+1$. Finding
the values and the distribution of those sums is a long-lasting open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3122</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3122</id><created>2010-06-15</created><authors><author><keyname>van Iersel</keyname><forenames>Leo</forenames></author><author><keyname>Semple</keyname><forenames>Charles</forenames></author><author><keyname>Steel</keyname><forenames>Mike</forenames></author></authors><title>Locating a tree in a phylogenetic network</title><categories>q-bio.PE cs.DS</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phylogenetic trees and networks are leaf-labelled graphs that are used to
describe evolutionary histories of species. The Tree Containment problem asks
whether a given phylogenetic tree is embedded in a given phylogenetic network.
Given a phylogenetic network and a cluster of species, the Cluster Containment
problem asks whether the given cluster is a cluster of some phylogenetic tree
embedded in the network. Both problems are known to be NP-complete in general.
In this article, we consider the restriction of these problems to several
well-studied classes of phylogenetic networks. We show that Tree Containment is
polynomial-time solvable for normal networks, for binary tree-child networks,
and for level-$k$ networks. On the other hand, we show that, even for
tree-sibling, time-consistent, regular networks, both Tree Containment and
Cluster Containment remain NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3128</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3128</id><created>2010-06-15</created><updated>2012-06-25</updated><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>The Sampling Rate-Distortion Tradeoff for Sparsity Pattern Recovery in
  Compressed Sensing</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, vo. 58, no. 10, pp.
  3065-3092, May, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovery of the sparsity pattern (or support) of an unknown sparse vector
from a limited number of noisy linear measurements is an important problem in
compressed sensing. In the high-dimensional setting, it is known that recovery
with a vanishing fraction of errors is impossible if the measurement rate and
the per-sample signal-to-noise ratio (SNR) are finite constants, independent of
the vector length. In this paper, it is shown that recovery with an arbitrarily
small but constant fraction of errors is, however, possible, and that in some
cases computationally simple estimators are near-optimal. Bounds on the
measurement rate needed to attain a desired fraction of errors are given in
terms of the SNR and various key parameters of the unknown vector for several
different recovery algorithms. The tightness of the bounds, in a scaling sense,
as a function of the SNR and the fraction of errors, is established by
comparison with existing information-theoretic necessary bounds. Near
optimality is shown for a wide variety of practically motivated signal models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3134</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3134</id><created>2010-06-16</created><authors><author><keyname>Chaudhuri</keyname><forenames>Kaustuv</forenames></author></authors><title>Classical and Intuitionistic Subexponential Logics are Equally
  Expressive</title><categories>cs.LO</categories><comments>15 pages, to appear in 19th EACSL Annual Conference on Computer
  Science Logic (CSL 2010)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  It is standard to regard the intuitionistic restriction of a classical logic
as increasing the expressivity of the logic because the classical logic can be
adequately represented in the intuitionistic logic by double-negation, while
the other direction has no truth-preserving propositional encodings. We show
here that subexponential logic, which is a family of substructural refinements
of classical logic, each parametric over a preorder over the subexponential
connectives, does not suffer from this asymmetry if the preorder is
systematically modified as part of the encoding. Precisely, we show a bijection
between synthetic (i.e., focused) partial sequent derivations modulo a given
encoding. Particular instances of our encoding for particular subexponential
preorders give rise to both known and novel adequacy theorems for substructural
logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3140</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3140</id><created>2010-06-16</created><authors><author><keyname>Blute</keyname><forenames>Richard</forenames><affiliation>PPS</affiliation></author><author><keyname>Ehrhard</keyname><forenames>Thomas</forenames><affiliation>PPS</affiliation></author><author><keyname>Tasson</keyname><forenames>Christine</forenames><affiliation>LMeASI</affiliation></author></authors><title>A convenient differential category</title><categories>cs.LO math.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the category of Mackey-complete, separated,
topological convex bornological vector spaces and bornological linear maps is a
differential category. Such spaces were introduced by Fr\&quot;olicher and Kriegl,
where they were called convenient vector spaces. While much of the structure
necessary to demonstrate this observation is already contained in Fr\&quot;olicher
and Kriegl's book, we here give a new interpretation of the category of
convenient vector spaces as a model of the differential linear logic of Ehrhard
and Regnier. Rather than base our proof on the abstract categorical structure
presented by Fr\&quot;olicher and Kriegl, we prefer to focus on the bornological
structure of convenient vector spaces. We believe bornological structures will
ultimately yield a wide variety of models of differential logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3141</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3141</id><created>2010-06-16</created><updated>2010-07-21</updated><authors><author><keyname>Blin</keyname><forenames>L&#xe9;lia</forenames><affiliation>IBISC</affiliation></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Rovedakis</keyname><forenames>Stephane</forenames><affiliation>IBISC</affiliation></author></authors><title>Fast Self-Stabilizing Minimum Spanning Tree Construction</title><categories>cs.DC cs.DS cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel self-stabilizing algorithm for minimum spanning tree (MST)
construction. The space complexity of our solution is $O(\log^2n)$ bits and it
converges in $O(n^2)$ rounds. Thus, this algorithm improves the convergence
time of all previously known self-stabilizing asynchronous MST algorithms by a
multiplicative factor $\Theta(n)$, to the price of increasing the best known
space complexity by a factor $O(\log n)$. The main ingredient used in our
algorithm is the design, for the first time in self-stabilizing settings, of a
labeling scheme for computing the nearest common ancestor with only
$O(\log^2n)$ bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3148</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3148</id><created>2010-06-16</created><authors><author><keyname>Wittmann</keyname><forenames>Markus</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Leveraging shared caches for parallel temporal blocking of stencil codes
  on multicore processors and clusters</title><categories>cs.DC cs.PF</categories><comments>16 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandwidth-starved multicore chips have become ubiquitous. It is well known
that the performance of stencil codes can be improved by temporal blocking,
lessening the pressure on the memory interface. We introduce a new pipelined
approach that makes explicit use of shared caches in multicore environments and
minimizes synchronization and boundary overhead. Benchmark results are
presented for three current x86-based microprocessors, showing clearly that our
optimization works best on designs with high-speed shared caches and low memory
bandwidth per core. We furthermore demonstrate that simple bandwidth-based
performance models are inaccurate for this kind of algorithm and employ a more
elaborate, synthetic modeling procedure. Finally we show that temporal blocking
can be employed successfully in a hybrid shared/distributed-memory environment,
albeit with limited benefit at strong scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3151</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3151</id><created>2010-06-16</created><updated>2010-11-23</updated><authors><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Doucet</keyname><forenames>Arnaud</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Channel Tracking for Relay Networks via Adaptive Particle MCMC</title><categories>cs.IT math.IT</categories><comments>30 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for channel tracking and parameter
estimation in cooperative wireless relay networks. We consider a system with
multiple relay nodes operating under an amplify and forward relay function. We
develop a novel algorithm to efficiently solve the challenging problem of joint
channel tracking and parameters estimation of the Jakes' system model within a
mobile wireless relay network. This is based on \textit{particle Markov chain
Monte Carlo} (PMCMC) method. In particular, it first involves developing a
Bayesian state space model, then estimating the associated high dimensional
posterior using an adaptive Markov chain Monte Carlo (MCMC) sampler relying on
a proposal built using a Rao-Blackwellised Sequential Monte Carlo (SMC) filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3154</identifier>
 <datestamp>2011-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3154</id><created>2010-06-16</created><updated>2011-10-28</updated><authors><author><keyname>Han</keyname><forenames>Chong</forenames></author><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Spectrum Sensing in Cooperative Cognitive Radio Networks with Partial
  CSI</title><categories>cs.IT math.IT</categories><comments>a new version is now available</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an efficient algorithm for cooperative spectrum sensing in a relay
based cognitive radio network. We consider a stochastic model where data is
sent from the Base Station (BS) of the Primary User (PU). The data is relayed
by the Secondary Users (SU) to the SU BS. The SU BS has only partial CSI
knowledge of the wireless channels. In order to obtain the optimal decision
rule based on Likelihood Ratio Test (LRT), the marginal likelihood under each
hypothesis needs to be evaluated pointwise. These, however, cannot be obtained
analytically due to the intractability of the integrals. Instead, we
approximate these quantities by utilising the Laplace method. Performance is
evaluated via numerical simulations and it is shown that the proposed spectrum
sensing scheme can achieve superior results to the energy detection scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3155</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3155</id><created>2010-06-16</created><updated>2011-02-15</updated><authors><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Blind Spectrum Sensing in Cognitive Radio over Fading Channels and
  Frequency Offsets</title><categories>cs.IT math.IT</categories><comments>14 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the challenging problem of spectrum sensing in
cognitive radio. We consider a stochastic system model where the the Primary
User (PU) transmits a periodic signal over fading channels. The effect of
frequency offsets due to oscillator mismatch, and Doppler offset is studied. We
show that for this case the Likelihood Ratio Test (LRT) cannot be evaluated
poitnwise. We present a novel approach to approximate the marginilisation of
the frequency offset using a single point estimate. This is obtained via a low
complexity Constrained Adaptive Notch Filter (CANF) to estimate the frequency
offset. Performance is evaluated via numerical simulations and it is shown that
the proposed spectrum sensing scheme can achieve the same performance as the
near-optimal scheme, that is based on a bank of matched filters, using only a
fraction of the complexity required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3156</identifier>
 <datestamp>2011-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3156</id><created>2010-06-16</created><updated>2011-08-31</updated><authors><author><keyname>Tom&#xe1;s</keyname><forenames>Virtudes</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author></authors><title>Decoding of Convolutional Codes over the Erasure Channel</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures, to appear on IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the decoding capabilities of convolutional codes over
the erasure channel. Of special interest will be maximum distance profile (MDP)
convolutional codes. These are codes which have a maximum possible column
distance increase. We show how this strong minimum distance condition of MDP
convolutional codes help us to solve error situations that maximum distance
separable (MDS) block codes fail to solve. Towards this goal, we define two
subclasses of MDP codes: reverse-MDP convolutional codes and complete-MDP
convolutional codes. Reverse-MDP codes have the capability to recover a maximum
number of erasures using an algorithm which runs backward in time. Complete-MDP
convolutional codes are both MDP and reverse-MDP codes. They are capable to
recover the state of the decoder under the mildest condition. We show that
complete-MDP convolutional codes perform in certain sense better than MDS block
codes of the same rate over the erasure channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3159</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3159</id><created>2010-06-16</created><authors><author><keyname>Bouissou</keyname><forenames>Olivier</forenames><affiliation>LMeASI</affiliation></author><author><keyname>Seladji</keyname><forenames>Yassamine</forenames><affiliation>LMeASI</affiliation></author><author><keyname>Chapoutot</keyname><forenames>Alexandre</forenames><affiliation>LIP6</affiliation></author></authors><title>Abstract Fixpoint Computations with Numerical Acceleration Methods</title><categories>cs.PL cs.NA</categories><proxy>ccsd</proxy><journal-ref>Electronic Notes in Theoretical Computer Science (2010) 29-42</journal-ref><doi>10.1016/j.entcs.2010.09.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Static analysis by abstract interpretation aims at automatically proving
properties of computer programs. To do this, an over-approximation of program
semantics, defined as the least fixpoint of a system of semantic equations,
must be computed. To enforce the convergence of this computation, widening
operator is used but it may lead to coarse results. We propose a new method to
accelerate the computation of this fixpoint by using standard techniques of
numerical analysis. Our goal is to automatically and dynamically adapt the
widening operator in order to maintain precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3167</identifier>
 <datestamp>2011-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3167</id><created>2010-06-16</created><updated>2011-12-01</updated><authors><author><keyname>Mazoit</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LaBRI</affiliation></author></authors><title>Tree-width of hypergraphs and surface duality</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Graph Minors III, Robertson and Seymour write: &quot;It seems that the
tree-width of a planar graph and the tree-width of its geometric dual are
approximately equal - indeed, we have convinced ourselves that they differ by
at most one&quot;. They never gave a proof of this. In this paper, we prove a
generalisation of this statement to embedding of hypergraphs on general
surfaces, and we prove that our bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3180</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3180</id><created>2010-06-16</created><authors><author><keyname>Macdonald</keyname><forenames>Angus</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author></authors><title>H2O: An Autonomic, Resource-Aware Distributed Database System</title><categories>cs.DB cs.DC</categories><comments>Presented at SICSA PhD Conference 2010 (http://www.sicsaconf.org/)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design of an autonomic, resource-aware distributed
database which enables data to be backed up and shared without complex manual
administration. The database, H2O, is designed to make use of unused resources
on workstation machines. Creating and maintaining highly-available, replicated
database systems can be difficult for untrained users, and costly for IT
departments. H2O reduces the need for manual administration by autonomically
replicating data and load-balancing across machines in an enterprise.
Provisioning hardware to run a database system can be unnecessarily costly as
most organizations already possess large quantities of idle resources in
workstation machines. H2O is designed to utilize this unused capacity by using
resource availability information to place data and plan queries over
workstation machines that are already being used for other tasks. This paper
discusses the requirements for such a system and presents the design and
implementation of H2O.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3215</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3215</id><created>2010-06-16</created><authors><author><keyname>Zhang</keyname><forenames>Yuanlin</forenames></author><author><keyname>Yap</keyname><forenames>Roland H. C.</forenames></author></authors><title>Solving Functional Constraints by Variable Substitution</title><categories>cs.AI cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional constraints and bi-functional constraints are an important
constraint class in Constraint Programming (CP) systems, in particular for
Constraint Logic Programming (CLP) systems. CP systems with finite domain
constraints usually employ CSP-based solvers which use local consistency, for
example, arc consistency. We introduce a new approach which is based instead on
variable substitution. We obtain efficient algorithms for reducing systems
involving functional and bi-functional constraints together with other
non-functional constraints. It also solves globally any CSP where there exists
a variable such that any other variable is reachable from it through a sequence
of functional constraints. Our experiments on random problems show that
variable elimination can significantly improve the efficiency of solving
problems with functional constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3222</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3222</id><created>2010-06-14</created><authors><author><keyname>Sinha</keyname><forenames>Nirmalendu Bikas</forenames></author><author><keyname>Bera</keyname><forenames>R.</forenames></author><author><keyname>Mitra</keyname><forenames>M.</forenames></author></authors><title>MIMO Detection Algorithms for High Data Rate Wireless Transmission</title><categories>cs.OH cs.IT math.IT</categories><journal-ref>Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p91-98, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by MIMO broad-band fading channel model, in this section a
comparative study is presented regarding various uncoded adaptive and
non-adaptive MIMO detection algorithms with respect to BER/PER performance, and
hardware complexity. All the simulations are conducted within MIMO-OFDM
framework and with a packet structure similar to that of IEEE 802.11a/g
standard. As the comparison results show, the RLS algorithm appears to be an
affordable solution for wideband MIMO system targeting at Giga-bit wireless
transmission. So MIMO can overcome huge processing power required for MIMO
detection by using optimizing channel coding and MIMO detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3246</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3246</id><created>2010-06-16</created><updated>2012-06-05</updated><authors><author><keyname>Nuel</keyname><forenames>Gr&#xe9;gory</forenames><affiliation>MAP5</affiliation></author><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author></authors><title>Sparse approaches for the exact distribution of patterns in long state
  sequences generated by a Markov source</title><categories>math.PR cs.SC q-bio.QM</categories><proxy>ccsd</proxy><journal-ref>Theoretical Computer Science 479 (2013) 22-42</journal-ref><doi>10.1016/j.tcs.2012.10.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two novel approaches for the computation of the exact distribution
of a pattern in a long sequence. Both approaches take into account the sparse
structure of the problem and are two-part algorithms. The first approach relies
on a partial recursion after a fast computation of the second largest
eigenvalue of the transition matrix of a Markov chain embedding. The second
approach uses fast Taylor expansions of an exact bivariate rational
reconstruction of the distribution. We illustrate the interest of both
approaches on a simple toy-example and two biological applications: the
transcription factors of the Human Chromosome 5 and the PROSITE signatures of
functional motifs in proteins. On these example our methods demonstrate their
complementarity and their hability to extend the domain of feasibility for
exact computations in pattern problems to a new level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3259</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3259</id><created>2010-06-16</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Contents of COMP5541 Winter 2010 Final UUIS SRS and SDD Reports</title><categories>cs.SE</categories><comments>an index</comments><acm-class>D.2; K.6; H.5.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This index covers the final course project reports for COMP5541 Winter 2010
at Concordia University, Montreal, Canada, Tools and Techniques for Software
Engineering by 4 teams trying to capture the requirements, provide the design
specification, configuration management, testing and quality assurance of their
partial implementation of the Unified University Inventory System (UUIS) of an
Imaginary University of Arctica (IUfA). Their results are posted here for
comparative studies and analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3271</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3271</id><created>2010-06-16</created><authors><author><keyname>Hsu</keyname><forenames>Anne S.</forenames><affiliation>Univ. College, University London</affiliation></author><author><keyname>Chater</keyname><forenames>Nick</forenames><affiliation>Univ. College, University London</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI, Amsterdam</affiliation></author></authors><title>The probabilistic analysis of language acquisition: Theoretical,
  computational, and experimental analysis</title><categories>cs.CL physics.data-an q-bio.NC</categories><comments>26 pages, pdf, 4 figures, Submitted to &quot;Cognition&quot;</comments><msc-class>91E10, 97C30, 68T50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is much debate over the degree to which language learning is governed
by innate language-specific biases, or acquired through cognition-general
principles. Here we examine the probabilistic language acquisition hypothesis
on three levels: We outline a novel theoretical result showing that it is
possible to learn the exact generative model underlying a wide class of
languages, purely from observing samples of the language. We then describe a
recently proposed practical framework, which quantifies natural language
learnability, allowing specific learnability predictions to be made for the
first time. In previous work, this framework was used to make learnability
predictions for a wide variety of linguistic constructions, for which
learnability has been much debated. Here, we present a new experiment which
tests these learnability predictions. We find that our experimental results
support the possibility that these linguistic constructions are acquired
probabilistically from cognition-general principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3275</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3275</id><created>2010-06-16</created><authors><author><keyname>Terwijn</keyname><forenames>Sebastiaan A.</forenames><affiliation>Radboud Univ. Nijmegen</affiliation></author><author><keyname>Torenvliet</keyname><forenames>Leen</forenames><affiliation>Univ. Amsterdam</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI, Amsterdam</affiliation></author></authors><title>Normalized Information Distance is Not Semicomputable</title><categories>cs.CC cs.CV physics.data-an</categories><comments>9 pages, LaTeX, No figures, To appear in J. Comput. Syst. Sci</comments><msc-class>03Dxx, 62B10, 68T10, 91C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalized information distance (NID) uses the theoretical notion of
Kolmogorov complexity, which for practical purposes is approximated by the
length of the compressed version of the file involved, using a real-world
compression program. This practical application is called 'normalized
compression distance' and it is trivially computable. It is a parameter-free
similarity measure based on compression, and is used in pattern recognition,
data mining, phylogeny, clustering, and classification. The complexity
properties of its theoretical precursor, the NID, have been open. We show that
the NID is neither upper semicomputable nor lower semicomputable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3295</identifier>
 <datestamp>2012-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3295</id><created>2010-06-16</created><updated>2012-05-31</updated><authors><author><keyname>Jelenkovi&#x107;</keyname><forenames>Predrag R.</forenames></author><author><keyname>Olvera-Cravioto</keyname><forenames>Mariana</forenames></author></authors><title>Implicit Renewal Theory and Power Tails on Trees</title><categories>math.PR cs.DM cs.PF</categories><comments>arXiv admin note: substantial text overlap with arXiv:1012.2165</comments><msc-class>60H25 (Primary) 60J80, 60F10, 60K05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend Goldie's (1991) Implicit Renewal Theorem to enable the analysis of
recursions on weighted branching trees. We illustrate the developed method by
deriving the power tail asymptotics of the distributions of the solutions R to:
R =_D sum_{i=1}^N C_i R_i + Q, R =_D max(max_{i=1}^N C_i R_i, Q), and similar
recursions, where (Q, N, C_1,..., C_N) is a nonnegative random vector with N in
{0, 1, 2, 3, ..., infinity}, and {R_i}_{i &gt;= 1} are iid copies of R,
independent of (Q, N, C_1,..., C_N); =_D denotes the equality in distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3301</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3301</id><created>2010-06-16</created><updated>2010-10-20</updated><authors><author><keyname>Jo</keyname><forenames>Han-Shin</forenames></author><author><keyname>Mun</keyname><forenames>Cheol</forenames></author><author><keyname>Yook</keyname><forenames>Jong-Gwan</forenames></author></authors><title>Codebook-Based SDMA for Coexistence with Fixed Wireless Service</title><categories>cs.IT cs.NI math.IT</categories><comments>The paper has been withdrawn by the author due to some error in main
  analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A portion of frequency band for International Mobile Telecommunications
(IMT)-Advanced is currently allocated to Fixed Wireless Service (FWS) such as
Fixed Service (FS), Fixed Satellite Service (FSS), or Fixed Wireless Access
(FWA), which requires frequency sharing between both the systems. SDMA, due to
its high throughput nature, is candidate for IMT-Advanced. This paper proposes
a systematic design of a precoder codebook for SDMA sharing spectrum with
existing FWS. Based on an estimated direction angle of a victim FWS system, an
interfering transmitter adaptively constructs a codebook forming a transmit
null in the direction angle while satisfying orthogonal beamforming constraint.
We derive not only asymptotic throughput scaling laws, but also an upperbound
on throughput loss to analyze performance loss of the proposed SDMA relative to
the popular SDMA called per-user unitary rate control (PU2RC). Furthermore, we
develop a method of evaluating protection distance in order to analyze the
spectrum sharing performance of the proposed approach. The simulation results
of protection distance confirm that the proposed SDMA efficiently shares
spectrum with FWS systems by reducing protection distance to more than 66%.
Although our proposed SDMA always has lower throughput compared to PU2RC in
non-coexistence scenario, it offers an intriguing opportunity to reuse spectrum
already allocated to FWS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3302</identifier>
 <datestamp>2013-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3302</id><created>2010-06-16</created><updated>2013-04-19</updated><authors><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Gairing</keyname><forenames>Martin</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author></authors><title>Quasirandom Load Balancing</title><categories>cs.DS cs.DC</categories><comments>25 pages</comments><msc-class>68W15, 68W20, 68Q87</msc-class><journal-ref>SIAM Journal on Computing, Vol. 41, No. 4, pp. 747-771, 2012</journal-ref><doi>10.1137/100799216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple distributed algorithm for balancing indivisible tokens on
graphs. The algorithm is completely deterministic, though it tries to imitate
(and enhance) a random algorithm by keeping the accumulated rounding errors as
small as possible.
  Our new algorithm surprisingly closely approximates the idealized process
(where the tokens are divisible) on important network topologies. On
d-dimensional torus graphs with n nodes it deviates from the idealized process
only by an additive constant. In contrast to that, the randomized rounding
approach of Friedrich and Sauerwald (2009) can deviate up to Omega(polylog(n))
and the deterministic algorithm of Rabani, Sinclair and Wanka (1998) has a
deviation of Omega(n^{1/d}). This makes our quasirandom algorithm the first
known algorithm for this setting which is optimal both in time and achieved
smoothness. We further show that also on the hypercube our algorithm has a
smaller deviation from the idealized process than the previous algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3334</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3334</id><created>2010-06-16</created><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Gurel-Gurevich</keyname><forenames>Ori</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author><author><keyname>Moscibroda</keyname><forenames>Thomas</forenames></author></authors><title>Optimal whitespace synchronization strategies</title><categories>cs.GT</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The whitespace-discovery problem describes two parties, Alice and Bob, trying
to establish a communication channel over one of a given large segment of
whitespace channels. Subsets of the channels are occupied in each of the local
environments surrounding Alice and Bob, as well as in the global environment
between them (Eve). In the absence of a common clock for the two parties, the
goal is to devise time-invariant (stationary) strategies minimizing the
synchronization time. This emerged from recent applications in discovery of
wireless devices.
  We model the problem as follows. There are $N$ channels, each of which is
open (unoccupied) with probability $p_1,p_2,q$ independently for Alice, Bob and
Eve respectively. Further assume that $N \gg 1/(p_1 p_2 q)$ to allow for
sufficiently many open channels. Both Alice and Bob can detect which channels
are locally open and every time-slot each of them chooses one such channel for
an attempted sync. One aims for strategies that, with high probability over the
environments, guarantee a shortest possible expected sync time depending only
on the $p_i$'s and $q$.
  Here we provide a stationary strategy for Alice and Bob with a guaranteed
expected sync time of $O(1 / (p_1 p_2 q^2))$ given that each party also has
knowledge of $p_1,p_2,q$. When the parties are oblivious of these
probabilities, analogous strategies incur a cost of a poly-log factor, i.e.\
$\tilde{O}(1 / (p_1 p_2 q^2))$. Furthermore, this performance guarantee is
essentially optimal as we show that any stationary strategies of Alice and Bob
have an expected sync time of at least $\Omega(1/(p_1 p_2 q^2))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3360</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3360</id><created>2010-06-16</created><updated>2011-06-11</updated><authors><author><keyname>Zakhour</keyname><forenames>Randa</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen V.</forenames></author></authors><title>Base station cooperation on the downlink: Large system analysis</title><categories>cs.IT math.IT</categories><comments>This paper is a revised version of the first submission. Results are
  the same, but proofs are now more rigorous. Some of the results were
  presented in the Allerton Conference, Oct. 2010. The paper contains 6
  figures, and is 26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers maximizing the network-wide minimum supported rate in
the downlink of a two-cell system, where each base station (BS) is endowed with
multiple antennas. This is done for different levels of cell cooperation. At
one extreme, we consider single cell processing where the BS is oblivious to
the interference it is creating at the other cell. At the other extreme, we
consider full cooperative macroscopic beamforming. In between, we consider
coordinated beamforming, which takes account of inter-cell interference, but
does not require full cooperation between the BSs. We combine elements of
Lagrangian duality and large system analysis to obtain limiting SINRs and
bit-rates, allowing comparison between the considered schemes. The main
contributions of the paper are theorems which provide concise formulas for
optimal transmit power, beamforming vectors, and achieved signal to
interference and noise ratio (SINR) for the considered schemes. The formulas
obtained are valid for the limit in which the number of users per cell, K, and
the number of antennas per base station, N, tend to infinity, with fixed ratio.
These theorems also provide expressions for the effective bandwidths occupied
by users, and the effective interference caused in the adjacent cell, which
allow direct comparisons between the considered schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3366</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3366</id><created>2010-06-17</created><authors><author><keyname>Olagbegi</keyname><forenames>Busola S.</forenames><affiliation>Jackson State University, USA</affiliation></author><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames><affiliation>Jackson State University, USA</affiliation></author></authors><title>A Review of the Energy Efficient and Secure Multicast Routing Protocols
  for Mobile Ad hoc Networks</title><categories>cs.NI</categories><comments>15 pages</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 1-15</journal-ref><doi>10.5121/jgraphoc.2010.2201</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a thorough survey of recent work addressing energy
efficient multicast routing protocols and secure multicast routing protocols in
Mobile Ad hoc Networks (MANETs). There are so many issues and solutions which
witness the need of energy management and security in ad hoc wireless networks.
The objective of a multicast routing protocol for MANETs is to support the
propagation of data from a sender to all the receivers of a multicast group
while trying to use the available bandwidth efficiently in the presence of
frequent topology changes. Multicasting can improve the efficiency of the
wireless link when sending multiple copies of messages by exploiting the
inherent broadcast property of wireless transmission. Secure multicast routing
plays a significant role in MANETs. However, offering energy efficient and
secure multicast routing is a difficult and challenging task. In recent years,
various multicast routing protocols have been proposed for MANETs. These
protocols have distinguishing features and use different mechanisms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3368</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3368</id><created>2010-06-17</created><updated>2010-10-28</updated><authors><author><keyname>Yoshida</keyname><forenames>Yuichi</forenames></author></authors><title>Optimal Constant-Time Approximation Algorithms and (Unconditional)
  Inapproximability Results for Every Bounded-Degree CSP</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Raghavendra (STOC 2008) gave an elegant and surprising result: if Khot's
Unique Games Conjecture (STOC 2002) is true, then for every constraint
satisfaction problem (CSP), the best approximation ratio is attained by a
certain simple semidefinite programming and a rounding scheme for it. In this
paper, we show that similar results hold for constant-time approximation
algorithms in the bounded-degree model. Specifically, we present the
followings: (i) For every CSP, we construct an oracle that serves an access, in
constant time, to a nearly optimal solution to a basic LP relaxation of the
CSP. (ii) Using the oracle, we give a constant-time rounding scheme that
achieves an approximation ratio coincident with the integrality gap of the
basic LP. (iii) Finally, we give a generic conversion from integrality gaps of
basic LPs to hardness results. All of those results are \textit{unconditional}.
Therefore, for every bounded-degree CSP, we give the best constant-time
approximation algorithm among all. A CSP instance is called $\epsilon$-far from
satisfiability if we must remove at least an $\epsilon$-fraction of constraints
to make it satisfiable. A CSP is called testable if there is a constant-time
algorithm that distinguishes satisfiable instances from $\epsilon$-far
instances with probability at least $2/3$. Using the results above, we also
derive, under a technical assumption, an equivalent condition under which a CSP
is testable in the bounded-degree model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3369</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3369</id><created>2010-06-17</created><authors><author><keyname>Samanta</keyname><forenames>Abhishek</forenames><affiliation>Jadavpur University, India</affiliation></author><author><keyname>Bakshi</keyname><forenames>Dripto</forenames><affiliation>Jadavpur University, India</affiliation></author></authors><title>Fault Tolerant Wireless Sensor MAC Protocol for Efficient Collision
  Avoidance</title><categories>cs.NI</categories><comments>14 pages</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 46-59</journal-ref><doi>10.5121/jgraphoc.2010.2205</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In sensor networks communication by broadcast methods involves many hazards,
especially collision. Several MAC layer protocols have been proposed to resolve
the problem of collision namely ARBP, where the best achieved success rate is
90%. We hereby propose a MAC protocol which achieves a greater success rate
(Success rate is defined as the percentage of delivered packets at the source
reaching the destination successfully) by reducing the number of collisions,
but by trading off the average propagation delay of transmission. Our proposed
protocols are also shown to be more energy efficient in terms of energy
dissipation per message delivery, compared to the currently existing protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3371</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3371</id><created>2010-06-17</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames><affiliation>Atmiya Institute of Technology &amp; Science, India</affiliation></author></authors><title>Enhancing QoS and QoE in IMS Enabled Next Generation Networks</title><categories>cs.NI</categories><comments>11 Pages</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 61-71</journal-ref><doi>10.5121/jgraphoc.2010.2206</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Managing network complexity, accommodating greater numbers of subscribers,
improving coverage to support data services (e.g. email, video, and music
downloads), keeping up to speed with fast-changing technology, and driving
maximum value from existing networks - all while reducing CapEX and OpEX and
ensuring Quality of Service (QoS) for the network and Quality of Experience
(QoE) for the user. These are just some of the pressing business issues faced
by mobileservice providers, summarized by the demand to &quot;achieve more, for
less.&quot; The ultimate goal of optimization techniques at the network and
application layer is to ensure End-user perceived QoS. The next generation
networks (NGN), a composite environment of proven telecommunications and
Internet-oriented mechanisms have become generally recognized as the
telecommunications environment of the future. However, the nature of the NGN
environment presents several complex issues regarding quality assurance that
have not existed in the legacy environments (e.g., multi-network, multi-vendor,
and multi-operator IP-based telecommunications environment, distributed
intelligence, third-party provisioning, fixed-wireless and mobile access,
etc.). In this Research Paper, a service aware policy-based approach to NGN
quality assurance is presented, taking into account both perceptual quality of
experience and technologydependant quality of service issues. The respective
procedures, entities, mechanisms, and profiles are discussed. The purpose of
the presented approach is in research, development, and discussion of pursuing
the end-to-end controllability of the quality of the multimedia NGN-based
communications in an environment that is best effort in its nature and promotes
end user's access agnosticism, service agility, and global mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3373</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3373</id><created>2010-06-17</created><authors><author><keyname>Munadi</keyname><forenames>Rendy</forenames><affiliation>Telkom Institute of Technology, Indonesia</affiliation></author><author><keyname>Najwaini</keyname><forenames>Effan</forenames><affiliation>Telkom Institute of Technology, Indonesia</affiliation></author><author><keyname>Mulyana</keyname><forenames>Asep</forenames><affiliation>Telkom Institute of Technology, Indonesia</affiliation></author><author><keyname>M</keyname><forenames>R. Rumani.</forenames><affiliation>Telkom Institute of Technology, Indonesia</affiliation></author></authors><title>Design and Implementation VOIP Service on Open IMS and Asterisk Servers
  Interconnected through Enum Server</title><categories>cs.NI</categories><comments>12 Pages</comments><journal-ref>International Journal of Next-Generation Networks 2.2 (2010) 1-12</journal-ref><doi>10.5121/ijngn.2010.2201</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Asterisk and Open IMS use SIP signal protocol to enable both of them can be
connected. To facilitate both relationships, Enum server- that is able to
translate the numbering address such as PSTN (E.164) to URI address (Uniform
Resource Identifier)- can be used. In this research, we interconnect Open IMS
and Asterisk server Enum server. We then analyze the server performance and PDD
(Post Dial Delay) values resulted by the system. As the result of the
experiment, we found that, for a call from Open IMS user to analog Asterisk
telephone (FXS) with a arrival call each servers is 30 call/sec, the maximum
PDD value is 493.656 ms. Open IMS is able to serve maximum 30 call/s with
computer processor 1.55 GHz, while the Asterisk with computer processor 3.0
GHz, may serve up to 55 call/sec. Enum on server with 1.15 GHz computer
processor have the capability of serving maximum of 8156 queries/sec.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3374</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3374</id><created>2010-06-17</created><authors><author><keyname>Pathak</keyname><forenames>Vibhar</forenames><affiliation>Suresh Gyan Vihar University, India</affiliation></author><author><keyname>Roy</keyname><forenames>Dr. Krishna Chandra</forenames><affiliation>SBCET, India</affiliation></author><author><keyname>Singh</keyname><forenames>Santosh Kumar</forenames><affiliation>Suresh Gyan Vihar University, India</affiliation></author></authors><title>Cross Layer Aware Adaptive MAC based on Knowledge Based Reasoning for
  Cognitive Radio Computer Networks</title><categories>cs.NI</categories><comments>8 pages</comments><journal-ref>International Journal of Next-Generation Networks 2.2 (2010) 14-21</journal-ref><doi>10.5121/ijngn.2010.2202</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we are proposing a new concept in MAC layer protocol design for
Cognitive radio by combining information held by physical layer and MAC layer
with analytical engine based on knowledge based reasoning approach. In the
proposed system a cross layer information regarding signal to interference and
noise ratio (SINR) and received power are analyzed with help of knowledge based
reasoning system to determine minimum power to transmit and size of contention
window, to minimize backoff, collision, save power and drop packets. The
performance analysis of the proposed protocol indicates improvement in power
saving, lowering backoff and significant decrease in number of drop packets.
The simulation environment was implement using OMNET++ discrete simulation tool
with Mobilty framework and MiXiM simulation library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3375</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3375</id><created>2010-06-17</created><authors><author><keyname>Singh</keyname><forenames>Santosh Kumar</forenames><affiliation>Suresh Gyan Vihar University, India and</affiliation></author><author><keyname>Roy</keyname><forenames>Krishna Chandra</forenames><affiliation>SBCET, India</affiliation></author><author><keyname>Pathak</keyname><forenames>Vibhakar</forenames><affiliation>Suresh Gyan Vihar University, India and</affiliation></author></authors><title>Channels Reallocation In Cognitive Radio Networks Based On DNA Sequence
  Alignment</title><categories>cs.NI</categories><comments>12 pages</comments><journal-ref>International Journal of Next-Generation Networks 2.2 (2010) 23-34</journal-ref><doi>10.5121/ijngn.2010.2203</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Nowadays, It has been shown that spectrum scarcity increased due to
tremendous growth of new players in wireless base system by the evolution of
the radio communication. Resent survey found that there are many areas of the
radio spectrum that are occupied by authorized user/primary user (PU), which
are not fully utilized. Cognitive radios (CR) prove to next generation wireless
communication system that proposed as a way to reuse this under-utilised
spectrum in an opportunistic and non-interfering basis. A CR is a self-directed
entity in a wireless communications environment that senses its environment,
tracks changes, and reacts upon its findings and frequently exchanges
information with the networks for secondary user (SU). However, CR facing
collision problem with tracks changes i.e. reallocating of other empty channels
for SU while PU arrives. In this paper, channels reallocation technique based
on DNA sequence alignment algorithm for CR networks has been proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3376</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3376</id><created>2010-06-17</created><authors><author><keyname>Sarddar</keyname><forenames>Debabrata</forenames><affiliation>Jadavpur University, India</affiliation></author><author><keyname>Jana</keyname><forenames>Tapas</forenames><affiliation>Netaji Subhash Engg College, India and</affiliation></author><author><keyname>Saha</keyname><forenames>Souvik Kumar</forenames><affiliation>Jadavpur University, India</affiliation></author><author><keyname>Banerjee</keyname><forenames>Joydeep</forenames><affiliation>Jadavpur University, India</affiliation></author><author><keyname>Biswas</keyname><forenames>Utpal</forenames><affiliation>University of Kalyani, India</affiliation></author><author><keyname>Naskar</keyname><forenames>M. K.</forenames><affiliation>Jadavpur University, India</affiliation></author></authors><title>Minimization of Handoff Failure Probability for Next-Generation Wireless
  Systems</title><categories>cs.NI</categories><comments>16 Pages</comments><journal-ref>International Journal of Next-Generation Networks 2.2 (2010) 36-51</journal-ref><doi>10.5121/ijngn.2010.2204</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  During the past few years, advances in mobile communication theory have
enabled the development and deployment of different wireless technologies,
complementary to each other. Hence, their integration can realize a unified
wireless system that has the best features of the individual networks.
Next-Generation Wireless Systems (NGWS) integrate different wireless systems,
each of which is optimized for some specific services and coverage area to
provide ubiquitous communications to the mobile users. In this paper, we
propose to enhance the handoff performance of mobile IP in wireless IP networks
by reducing the false handoff probability in the NGWS handoff management
protocol. Based on the information of false handoff probability, we analyze its
effect on mobile speed and handoff signaling delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3385</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3385</id><created>2010-06-17</created><updated>2010-10-16</updated><authors><author><keyname>Akhlaghi</keyname><forenames>Soroush</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad Ali</forenames></author></authors><title>A Fixed Precoding Approach to Achieve the Degrees of Freedom in X
  channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to provide a fixed precoding scheme to achieve the Degrees of
Freedom DoF of the generalized ergodic X channel. This is achieved through
using the notion of ergodic interference alignment technique. Accordingly, in
the proposed method the transmitters do not require to know the full channel
state information, while this assumption is the integral part of existing
methods. Instead, a finite-rate feed-back channel is adequate to achieve the
DoF. In other words, it is demonstrated that quantized versions of channel
gains are adequate to achieve theDOF. To get an insight regarding the
functionality of the proposed method, first we rely on finite field channel
models, and then extend the terminology to more realistic cases, including
dispersive fading channels in the presence of quantizer. Accordingly, in a
Rayliegh fading environment, it is shown a feedback rate of
2log(p)+Theta(log(log(p))) can provide the DoF, where $p$ is the total transmit
power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3394</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3394</id><created>2010-06-17</created><authors><author><keyname>Banerjee</keyname><forenames>Soumya</forenames></author><author><keyname>Moses</keyname><forenames>Melanie</forenames></author></authors><title>Modular RADAR: An Immune System Inspired Search and Response Strategy
  for Distributed Systems</title><categories>cs.DC q-bio.PE</categories><comments>14 pages, 3 figures, scale invariant detection and response,
  distributed systems, scale invariant response, scale invariant detection,
  immune system scaling, modular search, modular architecture, sub-modular
  architecture, peer-to-peer systems, artificial immune systems, immune system
  modelling, intrusion detection systems, malware detection systems, mobile
  ad-hoc networks</comments><journal-ref>The 9th International Conference on Artificial Immune Systems
  (ICARIS) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Natural Immune System (NIS) is a distributed system that solves
challenging search and response problems while operating under constraints
imposed by physical space and resource availability. Remarkably, NIS search and
response times do not scale appreciably with the physical size of the animal in
which its search is conducted. Many distributed systems are engineered to solve
analogous problems, and the NIS demonstrates how such engineered systems can
achieve desirable scalability. We hypothesize that the architecture of the NIS,
composed of a hierarchical decentralized detection network of lymph nodes (LN)
facilitates efficient search and response. A sub-modular architecture in which
LN numbers and size both scale with organism size is shown to efficiently
balance tradeoffs between local antigen detection and global antibody
production, leading to nearly scale-invariant detection and response. We
characterize the tradeoffs as balancing local and global communication and show
that similar tradeoffs exist in distributed systems like LN inspired artificial
immune system (AIS) applications and peer-to-peer (P2P) systems. Taking
inspiration from the architecture of the NIS, we propose a modular RADAR
(Robust Adaptive Decentralized search with Automated Response) strategy for
distributed systems. We demonstrate how two existing distributed systems (a LN
inspired multi-robot control application and a P2P system) can be improved by a
modular RADAR strategy. Such a sub-modular architecture is shown to balance the
tradeoffs between local communication (within artificial LNs and P2P clusters)
and global communication (between artificial LNs and P2P clusters), leading to
efficient search and response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3403</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3403</id><created>2010-06-17</created><authors><author><keyname>Atanassov</keyname><forenames>Atanas Marinov</forenames></author></authors><title>Image processing of a spectrogram produced by Spectrometer Airglow
  Temperature Imager</title><categories>physics.comp-ph cs.CV physics.ins-det</categories><comments>4 pages, 5 figures; In Conference Proceedings &quot;Fundamental Space
  Research&quot;, Sunny Beach, Bulgaria, 21-28 Sep 2008, 328-331</comments><doi>10.1016/j.asr.2011.01.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Spectral Airglow Temperature Imager is an instrument, specially designed
for investigation of the wave processes in the Mesosphere-Lower Thermosphere.
In order to determine the kinematics parameters of a wave, the values of a
physical quantity in different space points and their changes in the time
should be known. An approach for image processing of registered spectrograms is
proposed. A detailed description is made of the steps of this approach, related
to recovering CCD pixel values, influenced by cosmic particles, dark image
correction and filter parameters determination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3404</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3404</id><created>2010-06-17</created><authors><author><keyname>Farkas</keyname><forenames>Janos</forenames></author><author><keyname>Bajak</keyname><forenames>Szabolcs</forenames></author><author><keyname>Nagy</keyname><forenames>Benedek</forenames></author></authors><title>Approximating the Euclidean circle in the square grid using
  neighbourhood sequences</title><categories>math.MG cs.CG</categories><comments>Lecture at the 6th Joint Conference on Mathematics and Computer
  Science (MACS '06) Pecs, Hungary, 12-15 July, 2006</comments><msc-class>52C99</msc-class><journal-ref>Pure Mathematics and Applications 17 (2006) 309-322</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance measuring is a very important task in digital geometry and digital
image processing. Due to our natural approach to geometry we think of the set
of points that are equally far from a given point as a Euclidean circle. Using
the classical neighbourhood relations on digital grids, we get circles that
greatly differ from the Euclidean circle. In this paper we examine different
methods of approximating the Euclidean circle in the square grid, considering
the possible motivations as well. We compare the perimeter-, area-, curve- and
noncompactness-based approximations and examine their realization using
neighbourhood sequences. We also provide a table which summarizes our results,
and can be used when developing applications that support neighbourhood
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3417</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3417</id><created>2010-06-17</created><authors><author><keyname>Nguyen</keyname><forenames>Kien C.</forenames></author><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Fictitious Play with Time-Invariant Frequency Update for Network
  Security</title><categories>cs.GT cs.CR cs.LG</categories><comments>Proceedings of the 2010 IEEE Multi-Conference on Systems and Control
  (MSC10), September 2010, Yokohama, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two-player security games which can be viewed as sequences of
nonzero-sum matrix games played by an Attacker and a Defender. The evolution of
the game is based on a stochastic fictitious play process, where players do not
have access to each other's payoff matrix. Each has to observe the other's
actions up to present and plays the action generated based on the best response
to these observations. In a regular fictitious play process, each player makes
a maximum likelihood estimate of her opponent's mixed strategy, which results
in a time-varying update based on the previous estimate and current action. In
this paper, we explore an alternative scheme for frequency update, whose mean
dynamic is instead time-invariant. We examine convergence properties of the
mean dynamic of the fictitious play process with such an update scheme, and
establish local stability of the equilibrium point when both players are
restricted to two actions. We also propose an adaptive algorithm based on this
time-invariant frequency update.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3424</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3424</id><created>2010-06-17</created><updated>2010-09-19</updated><authors><author><keyname>aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Ruggieri</keyname><forenames>Salvatore</forenames></author><author><keyname>Torquati</keyname><forenames>Massimo</forenames></author></authors><title>Porting Decision Tree Algorithms to Multicore using FastFlow</title><categories>cs.DC cs.DB</categories><comments>18 pages + cover</comments><report-no>TR-10-11</report-no><acm-class>D.1.3; D.3.2; C.1.3; H.2.8</acm-class><journal-ref>In J. L. Balc\'azar, F. Bonchi, A. Gionis, and M. Sebag, editors,
  Proc. of European Conference in Machine Learning and Knowledge Discovery in
  Databases (ECML PKDD), volume 6321 of LNCS, pages 7-23, Barcelona, Spain,
  Sept. 2010. Springer</journal-ref><doi>10.1007/978-3-642-15880-3_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The whole computer hardware industry embraced multicores. For these machines,
the extreme optimisation of sequential algorithms is no longer sufficient to
squeeze the real machine power, which can be only exploited via thread-level
parallelism. Decision tree algorithms exhibit natural concurrency that makes
them suitable to be parallelised. This paper presents an approach for
easy-yet-efficient porting of an implementation of the C4.5 algorithm on
multicores. The parallel porting requires minimal changes to the original
sequential code, and it is able to exploit up to 7X speedup on an Intel
dual-quad core machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3425</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3425</id><created>2010-06-17</created><authors><author><keyname>Lande</keyname><forenames>D. V.</forenames></author><author><keyname>Snarskii</keyname><forenames>A. A.</forenames></author></authors><title>Power law in website ratings</title><categories>cs.IR cs.IT math.IT physics.soc-ph</categories><comments>4 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the practical work of websites popularization, analysis of their
efficiency and downloading it is of key importance to take into account
web-ratings data. The main indicators of website traffic include the number of
unique hosts from which the analyzed website was addressed and the number of
granted web pages (hits) per unit time (for example, day, month or year). Of
certain interest is the ratio between the number of hits (S) and hosts (H). In
practice there is even used such a concept as &quot;average number of viewed pages&quot;
(S/H), which on default supposes a linear dependence of S on H. What actually
happens is that linear dependence is observed only as a partial case of power
dependence, and not always. Another new power law has been discovered on the
Internet, in particular, on the WWW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3426</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3426</id><created>2010-06-17</created><updated>2010-06-28</updated><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author></authors><title>HYMAD: Hybrid DTN-MANET Routing for Dense and Highly Dynamic Wireless
  Networks</title><categories>cs.NI</categories><comments>Accepted for publication in the Computer Communications Journal</comments><journal-ref>Computer Communications Vol. 33 Issue 13 (2010) pages 1483-1492</journal-ref><doi>10.1016/j.comcom.2010.03.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay/Disruption-Tolerant Network (DTN) protocols typically address sparse
intermittently connected networks whereas Mobile Ad-hoc Network (MANET)
protocols address the fairly stable and fully connected ones. But many
intermediate situations may occur on mobility dynamics or radio link
instability. In such cases, where the network frequently splits into evolving
connected groups, none of the conventional routing paradigms (DTN or MANET) are
fully satisfactory. In this paper we propose HYMAD, a Hybrid DTN-MANET routing
protocol which uses DTN between disjoint groups of nodes while using MANET
routing within these groups. HYMAD is fully decentralized and only makes use of
topological information exchanges between the nodes. The strength of HYMAD lies
in its ability to adapt to the changing connectivity patterns of the network.
We evaluate the scheme in simulation by replaying synthetic and real life
mobility traces which exhibit a broad range of connectivity dynamics. The
results show that HYMAD introduces limited overhead and outperforms the
multi-copy Spray-and-Wait DTN routing protocol it extends, both in terms of
delivery ratio and delay. This hybrid DTN-MANET approach offers a promising
venue for the delivery of elastic data in mobile ad-hoc networks as it retains
the resilience of a \textit{pure} DTN protocol while significantly improving
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3430</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3430</id><created>2010-06-17</created><authors><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author></authors><title>The Cover Time of Deterministic Random Walks</title><categories>cs.DM math.CO math.PR</categories><comments>27 pages, extended version of a conference paper which appeared in
  the Proceedings of the 16th Annual International Computing and Combinatorics
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rotor router model is a popular deterministic analogue of a random walk
on a graph. Instead of moving to a random neighbor, the neighbors are served in
a fixed order. We examine how fast this &quot;deterministic random walk&quot; covers all
vertices (or all edges). We present general techniques to derive upper bounds
for the vertex and edge cover time and derive matching lower bounds for several
important graph classes. Depending on the topology, the deterministic random
walk can be asymptotically faster, slower or equally fast as the classic random
walk. We also examine the short term behavior of deterministic random walks,
that is, the time to visit a fixed small number of vertices or edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3432</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3432</id><created>2010-06-17</created><authors><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author><author><keyname>Cournier</keyname><forenames>Alain</forenames><affiliation>MIS</affiliation></author><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author><author><keyname>Villain</keyname><forenames>Vincent</forenames><affiliation>MIS</affiliation></author></authors><title>Snap-Stabilizing Linear Message Forwarding</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the first snap-stabilizing message forwarding
protocol that uses a number of buffers per node being inde- pendent of any
global parameter, that is 4 buffers per link. The protocol works on a linear
chain of nodes, that is possibly an overlay on a large- scale and dynamic
system, e.g., Peer-to-Peer systems, Grids. . . Provided that the topology
remains a linear chain and that nodes join and leave &quot;neatly&quot;, the protocol
tolerates topology changes. We expect that this protocol will be the base to
get similar results on more general topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3442</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3442</id><created>2010-06-17</created><authors><author><keyname>F&#xfa;ster-Sabater</keyname><forenames>Amparo</forenames></author><author><keyname>Guill&#xe9;n</keyname><forenames>J. M.</forenames></author></authors><title>New modelling technique for aperiodic-sampling linear systems</title><categories>cs.DM cs.DS</categories><comments>19 pages, 0 figures</comments><msc-class>93C55, 93B10</msc-class><acm-class>F.1.1</acm-class><journal-ref>International Journal of Control, Volume 45, Issue 3 March 1987,
  pages 951 - 968</journal-ref><doi>10.1080/00207178708933780</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general input-output modelling technique for aperiodic-sampling linear
systems has been developed. The procedure describes the dynamics of the system
and includes the sequence of sampling periods among the variables to be
handled. Some restrictive conditions on the sampling sequence are imposed in
order to guarantee the validity of the model. The particularization to the
periodic case represents an alternative to the classic methods of
discretization of continuous systems without using the Z-transform. This kind
of representation can be used largely for identification and control purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3448</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3448</id><created>2010-06-17</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author></authors><title>Orthogonal Persistence Revisited</title><categories>cs.PL cs.DB</categories><comments>2nd International Conference on Object Databases (ICOODB 2009),
  Zurich, Switzerland. pp. 1-22</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The social and economic importance of large bodies of programs and data that
are potentially long-lived has attracted much attention in the commercial and
research communities. Here we concentrate on a set of methodologies and
technologies called persistent programming. In particular we review programming
language support for the concept of orthogonal persistence, a technique for the
uniform treatment of objects irrespective of their types or longevity. While
research in persistent programming has become unfashionable, we show how the
concept is beginning to appear as a major component of modern systems. We
relate these attempts to the original principles of orthogonal persistence and
give a few hints about how the concept may be utilised in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3451</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3451</id><created>2010-06-17</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>An upper bound on the number of states for a strongly universal
  hyperbolic cellular automaton on the pentagrid</title><categories>cs.FL</categories><comments>17 pages, 9 figures</comments><msc-class>68R05</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, following the way opened by a previous paper deposited on
arXiv, we give an upper bound to the number of states for a hyperbolic cellular
automaton in the pentagrid. Indeed, we prove that there is a hyperbolic
cellular automaton which is rotation invariant and whose halting problem is
undecidable and which has 9~states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3452</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3452</id><created>2010-06-17</created><authors><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author></authors><title>Generating a Family of Byzantine Tolerant Protocol Implementations Using
  a Meta-Model Architecture</title><categories>cs.DC</categories><comments>DSN 2007 Workshop on Architecting Dependable Systems, Edinburgh,
  Scotland. pp. 178-183</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an approach to modelling a Byzantine tolerant distributed
algorithm as a family of related finite state machines, generated from a single
meta-model. Various artefacts are generated from each state machine, including
diagrams and source-level protocol implementations. The approach allows a state
machine formulation to be applied to problems for which it would not otherwise
be suitable, increasing confidence in correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3455</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3455</id><created>2010-06-17</created><authors><author><keyname>F&#xfa;ster-Sabater</keyname><forenames>Amparo</forenames></author></authors><title>An External Description for MIMO Systems Sampled in an Aperiodic Way</title><categories>cs.DM cs.IT math.IT</categories><comments>10 pages; 0 figures</comments><msc-class>93C55, 93B10</msc-class><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An external description for aperiodically sampled MIMO linear systems has
been developed. Emphasis is on the sampling period sequence, included among the
variables to be handled. The computational procedure is simple and no use of
polynomial matrix theory is required. This input/output description is believed
to be a basic formulation for its later application to the problem of optimal
control and/or identification of linear dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3463</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3463</id><created>2010-06-17</created><authors><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author></authors><title>Applying Constraint Solving to the Management of Distributed
  Applications</title><categories>cs.DC cs.SE</categories><comments>Submitted to DOA08</comments><report-no>University of St Andrews CS/08/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present our approach for deploying and managing distributed
component-based applications. A Desired State Description (DSD), written in a
high-level declarative language, specifies requirements for a distributed
application. Our infrastructure accepts a DSD as input, and from it
automatically configures and deploys the distributed application. Subsequent
violations of the original requirements are detected and, where possible,
automatically rectified by reconfiguration and redeployment of the necessary
application components. A constraint solving tool is used to plan deployments
that meet the application requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3465</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3465</id><created>2010-06-17</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author></authors><title>Hosting Byzantine Fault Tolerant Services on a Chord Ring</title><categories>cs.DC</categories><comments>Submitted to DSN 2007 Workshop on Architecting Dependable Systems</comments><report-no>University of St Andrews CS/07/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate how stateful Byzantine Fault Tolerant services
may be hosted on a Chord ring. The strategy presented is fourfold: firstly a
replication scheme that dissociates the maintenance of replicated service state
from ring recovery is developed. Secondly, clients of the ring based services
are made replication aware. Thirdly, a consensus protocol is introduced that
supports the serialization of updates. Finally Byzantine fault tolerant
replication protocols are developed that ensure the integrity of service data
hosted on the ring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3468</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3468</id><created>2010-06-17</created><updated>2011-07-11</updated><authors><author><keyname>Atanassov</keyname><forenames>Atanas Marinov</forenames></author></authors><title>Algorithm for Sector Spectra Calculation from Images Registered by the
  Spectral Airglow Temperature Imager</title><categories>physics.data-an cs.CV</categories><comments>4 pages, 4 figures, In Proceedings of &quot;Fundamental Space Research
  2009&quot;, 193-196</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Spectral Airglow Temperature Imager is an instrument, specially designed
for investigation of the wave processes in the Mesosphere-Lower Thermosphere.
In order to determine the kinematic parameters of a wave, the values of a
physical quantity in different space points and their changes in the time
should be known. As a result of the possibilities of the SATI instrument for
space scanning, different parts of the images (sectors of spectrograms)
correspond to the respective mesopause areas (where the radiation is
generated). Algorithms for sector spectra calculation are proposed. In contrast
to the original algorithms where twelve sectors with angles of 30 degrees are
only determined now sectors with arbitrary orientation and angles are
calculated. An algorithm is presented for sector calculation based on pixel
division into sub pixels. A comparative results are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3481</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3481</id><created>2010-06-17</created><authors><author><keyname>Kirby</keyname><forenames>Graham</forenames></author></authors><title>Reflection and Hyper-Programming in Persistent Programming Systems</title><categories>cs.PL cs.SE</categories><comments>PhD Thesis, University of St Andrews. Supervisor: R. Morrison. (1992)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work presented in this thesis seeks to improve programmer productivity in
the following ways:
  - by reducing the amount of code that has to be written to construct an
application;
  - by increasing the reliability of the code written; and
  - by improving the programmer's understanding of the persistent environment
in which applications are constructed. Two programming techniques that may be
used to pursue these goals in a persistent environment are type-safe linguistic
reflection and hyper-programming. The first provides a mechanism by which the
programmer can write generators that, when executed, produce new program
representations. This allows the specification of programs that are highly
generic yet depend in non-trivial ways on the types of the data on which they
operate. Genericity promotes software reuse which in turn reduces the amount of
new code that has to be written. Hyper-programming allows a source program to
contain links to data items in the persistent store. This improves program
reliability by allowing certain program checking to be performed earlier than
is otherwise possible. It also reduces the amount of code written by permitting
direct links to data in the place of textual descriptions. Both techniques
contribute to the understanding of the persistent environment through
supporting the implementation of store browsing tools and allowing source
representations to be associated with all executable programs in the persistent
store. This thesis describes in detail the structure of type-safe linguistic
reflection and hyper-programming, their benefits in the persistent context, and
a suite of programming tools that support reflective programming and
hyper-programming. These tools may be used in conjunction to allow reflection
over hyper-program representations. The implementation of the tools is
described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3498</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3498</id><created>2010-06-17</created><updated>2010-07-28</updated><authors><author><keyname>Ferragina</keyname><forenames>Paolo</forenames></author><author><keyname>Scaiella</keyname><forenames>Ugo</forenames></author></authors><title>Fast and accurate annotation of short texts with Wikipedia pages</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of cross-referencing text fragments with Wikipedia
pages, in a way that synonymy and polysemy issues are resolved accurately and
efficiently. We take inspiration from a recent flow of work [Cucerzan 2007,
Mihalcea and Csomai 2007, Milne and Witten 2008, Chakrabarti et al 2009], and
extend their scenario from the annotation of long documents to the annotation
of short texts, such as snippets of search-engine results, tweets, news, blogs,
etc.. These short and poorly composed texts pose new challenges in terms of
efficiency and effectiveness of the annotation process, that we address by
designing and engineering TAGME, the first system that performs an accurate and
on-the-fly annotation of these short textual fragments. A large set of
experiments shows that TAGME outperforms state-of-the-art algorithms when they
are adapted to work on short texts and it results fast and competitive on long
texts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3506</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3506</id><created>2010-06-17</created><authors><author><keyname>Lopes</keyname><forenames>Ana Paula Brand&#xe3;o</forenames></author><author><keyname>Valle</keyname><forenames>Eduardo Alves do</forenames><suffix>Jr.</suffix></author><author><keyname>de Almeida</keyname><forenames>Jussara Marques</forenames></author><author><keyname>de Ara&#xfa;jo</keyname><forenames>Arnaldo Albuquerque</forenames></author></authors><title>Action Recognition in Videos: from Motion Capture Labs to the Web</title><categories>cs.CV</categories><comments>Preprint submitted to CVIU, survey paper, 46 pages, 2 figures, 4
  tables</comments><acm-class>I.4.8; I.4.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a survey of human action recognition approaches based on
visual data recorded from a single video camera. We propose an organizing
framework which puts in evidence the evolution of the area, with techniques
moving from heavily constrained motion capture scenarios towards more
challenging, realistic, &quot;in the wild&quot; videos. The proposed organization is
based on the representation used as input for the recognition task, emphasizing
the hypothesis assumed and thus, the constraints imposed on the type of video
that each technique is able to address. Expliciting the hypothesis and
constraints makes the framework particularly useful to select a method, given
an application. Another advantage of the proposed organization is that it
allows categorizing newest approaches seamlessly with traditional ones, while
providing an insightful perspective of the evolution of the action recognition
task up to now. That perspective is the basis for the discussion in the end of
the paper, where we also present the main open issues in the area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3514</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3514</id><created>2010-06-17</created><authors><author><keyname>Shinde</keyname><forenames>Rajendra</forenames></author><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Gupta</keyname><forenames>Pankaj</forenames></author><author><keyname>Dutta</keyname><forenames>Debojyoti</forenames></author></authors><title>Similarity Search and Locality Sensitive Hashing using TCAMs</title><categories>cs.DB cs.IR</categories><comments>11 pages, in SIGMOD 2010</comments><acm-class>H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity search methods are widely used as kernels in various machine
learning applications. Nearest neighbor search (NNS) algorithms are often used
to retrieve similar entries, given a query. While there exist efficient
techniques for exact query lookup using hashing, similarity search using exact
nearest neighbors is known to be a hard problem and in high dimensions, best
known solutions offer little improvement over a linear scan. Fast solutions to
the approximate NNS problem include Locality Sensitive Hashing (LSH) based
techniques, which need storage polynomial in $n$ with exponent greater than
$1$, and query time sublinear, but still polynomial in $n$, where $n$ is the
size of the database. In this work we present a new technique of solving the
approximate NNS problem in Euclidean space using a Ternary Content Addressable
Memory (TCAM), which needs near linear space and has O(1) query time. In fact,
this method also works around the best known lower bounds in the cell probe
model for the query time using a data structure near linear in the size of the
data base. TCAMs are high performance associative memories widely used in
networking applications such as access control lists. A TCAM can query for a
bit vector within a database of ternary vectors, where every bit position
represents $0$, $1$ or $*$. The $*$ is a wild card representing either a $0$ or
a $1$. We leverage TCAMs to design a variant of LSH, called Ternary Locality
Sensitive Hashing (TLSH) wherein we hash database entries represented by
vectors in the Euclidean space into $\{0,1,*\}$. By using the added
functionality of a TLSH scheme with respect to the $*$ character, we solve an
instance of the approximate nearest neighbor problem with 1 TCAM access and
storage nearly linear in the size of the database. We believe that this work
can open new avenues in very high speed data mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3520</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3520</id><created>2010-06-17</created><authors><author><keyname>Bennett</keyname><forenames>Charles H.</forenames><affiliation>T.J. Watson IBM Research Center, Yorktown, USA</affiliation></author><author><keyname>Gacs</keyname><forenames>Peter</forenames><affiliation>Boston Univ., Boston, USA</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>Waterloo Univ., Canada</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and Univ. Amsterdam, Netherlands</affiliation></author><author><keyname>Zurek</keyname><forenames>Wojciech H.</forenames><affiliation>Theor. Div., Los Alamos National Laboratories and Santa Fe Inst.</affiliation></author></authors><title>Information Distance</title><categories>cs.IT math.IT math.PR physics.data-an</categories><comments>39 pages, LaTeX, 2 Figures/Tables</comments><msc-class>68Q30, 94A15, 94A17</msc-class><journal-ref>C.H. Bennett, P. G\'acs, M. Li, P.M.B. Vit\'anyi, and W. Zurek,
  Information Distance, IEEE Trans. Information Theory, 44:4(1998) 1407--1423</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While Kolmogorov complexity is the accepted absolute measure of information
content in an individual finite object, a similarly absolute notion is needed
for the information distance between two individual objects, for example, two
pictures. We give several natural definitions of a universal information
metric, based on length of shortest programs for either ordinary computations
or reversible (dissipationless) computations. It turns out that these
definitions are equivalent up to an additive logarithmic term. We show that the
information distance is a universal cognitive similarity distance. We
investigate the maximal correlation of the shortest programs involved, the
maximal uncorrelation of programs (a generalization of the Slepian-Wolf theorem
of classical information theory), and the density properties of the discrete
metric spaces induced by the information distances. A related distance measures
the amount of nonreversibility of a computation. Using the physical theory of
reversible computation, we give an appropriate (universal, anti-symmetric, and
transitive) measure of the thermodynamic work required to transform one object
in another object by the most efficient process. Information distance between
individual objects is needed in pattern recognition where one wants to express
effective notions of &quot;pattern similarity&quot; or &quot;cognitive similarity&quot; between
individual objects and in thermodynamics of computation where one wants to
analyse the energy dissipation of a computation from a particular input to a
particular output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3537</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3537</id><created>2010-06-17</created><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author></authors><title>Fastest Distributed Consensus Averaging Problem on Chain of Rhombus
  Networks</title><categories>cs.IT cs.DC cs.DM math.IT</categories><comments>18 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed consensus has appeared as one of the most important and primary
problems in the context of distributed computation and it has received renewed
interest in the field of sensor networks (due to recent advances in wireless
communications), where solving fastest distributed consensus averaging problem
over networks with different topologies is one of the primary problems in this
issue. Here in this work analytical solution for the problem of fastest
distributed consensus averaging algorithm over Chain of Rhombus networks is
provided, where the solution procedure consists of stratification of associated
connectivity graph of the network and semidefinite programming, particularly
solving the slackness conditions, where the optimal weights are obtained by
inductive comparing of the characteristic polynomials initiated by slackness
conditions. Also characteristic polynomial together with its roots
corresponding to eigenvalues of weight matrix including SLEM of network is
determined inductively. Moreover to see the importance of rhombus graphs it is
indicated that convergence rate of path network increases by replacing a single
node by a rhombus sub graph within the path network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3541</identifier>
 <datestamp>2012-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3541</id><created>2010-06-17</created><authors><author><keyname>de S&#xe1;</keyname><forenames>Vin&#xed;cius G. P.</forenames></author><author><keyname>da Fonseca</keyname><forenames>Guilherme D.</forenames></author><author><keyname>Machado</keyname><forenames>Raphael</forenames></author><author><keyname>de Figueiredo</keyname><forenames>Celina M. H.</forenames></author></authors><title>Complexity dichotomy on partial grid recognition</title><categories>cs.DS</categories><journal-ref>Theoretical Computer Science, 412(22):2370-2379, 2011</journal-ref><doi>10.1016/j.tcs.2011.01.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deciding whether a graph can be embedded in a grid using only unit-length
edges is NP-complete, even when restricted to binary trees. However, it is not
difficult to devise a number of graph classes for which the problem is
polynomial, even trivial. A natural step, outstanding thus far, was to provide
a broad classification of graphs that make for polynomial or NP-complete
instances. We provide such a classification based on the set of allowed vertex
degrees in the input graphs, yielding a full dichotomy on the complexity of the
problem. As byproducts, the previous NP-completeness result for binary trees
was strengthened to strictly binary trees, and the three-dimensional version of
the problem was for the first time proven to be NP-complete. Our results were
made possible by introducing the concepts of consistent orientations and robust
gadgets, and by showing how the former allows NP-completeness proofs by local
replacement even in the absence of the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3573</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3573</id><created>2010-06-17</created><authors><author><keyname>Andersson</keyname><forenames>Mattias</forenames></author><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author><author><keyname>Thobaben</keyname><forenames>Ragnar</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Nested Polar Codes for Wiretap and Relay Channels</title><categories>cs.IT math.IT</categories><comments>3 pages, 1 figure, accepted for publication in IEEE Communications
  Letters</comments><journal-ref>Communications Letters, IEEE , vol.14, no.8, pp.752-754, August
  2010</journal-ref><doi>10.1109/LCOMM.2010.08.100875</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that polar codes asymptotically achieve the whole
capacity-equivocation region for the wiretap channel when the wiretapper's
channel is degraded with respect to the main channel, and the weak secrecy
notion is used. Our coding scheme also achieves the capacity of the physically
degraded receiver-orthogonal relay channel. We show simulation results for
moderate block length for the binary erasure wiretap channel, comparing polar
codes and two edge type LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3585</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3585</id><created>2010-06-17</created><updated>2010-12-07</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author></authors><title>A Derandomized Sparse Johnson-Lindenstrauss Transform</title><categories>cs.DS cs.CC cs.DM</categories><comments>v3: Improved seed length, alternative proof of JL row optimality,
  other minor changes; v2: Improved presentation. Added a warmup section,
  Section 4, which gives a short proof of the JL lemma</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work of [Dasgupta-Kumar-Sarlos, STOC 2010] gave a sparse
Johnson-Lindenstrauss transform and left as a main open question whether their
construction could be efficiently derandomized. We answer their question
affirmatively by giving an alternative proof of their result requiring only
bounded independence hash functions. Furthermore, the sparsity bound obtained
in our proof is improved. The main ingredient in our proof is a spectral moment
bound for quadratic forms that was recently used in [Diakonikolas-Kane-Nelson,
FOCS 2010].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3601</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3601</id><created>2010-06-17</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames></author><author><keyname>Ahipasaoglu</keyname><forenames>Selin Damla</forenames></author><author><keyname>d'Aspremont</keyname><forenames>Alexandre</forenames></author></authors><title>Convex Relaxations for Subset Selection</title><categories>math.OC cs.DS</categories><msc-class>62F07, 90C59, 68W25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use convex relaxation techniques to produce lower bounds on the optimal
value of subset selection problems and generate good approximate solutions. We
then explicitly bound the quality of these relaxations by studying the
approximation ratio of sparse eigenvalue relaxations. Our results are used to
improve the performance of branch-and-bound algorithms to produce exact
solutions to subset selection problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3609</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3609</id><created>2010-06-18</created><authors><author><keyname>Singh</keyname><forenames>Sudha</forenames><affiliation>Bengal College of Engineering And Technology, India</affiliation></author><author><keyname>Singh</keyname><forenames>D. K.</forenames><affiliation>BIT Sindri, India</affiliation></author><author><keyname>Singh</keyname><forenames>M. K.</forenames><affiliation>Ranchi University, India and</affiliation></author><author><keyname>Singh</keyname><forenames>Sujeet Kumar</forenames><affiliation>JPMorgan Chase - Mumbai, India</affiliation></author></authors><title>The Forecasting of 3G Market in India Based on Revised Technology
  Acceptance Model</title><categories>cs.OH</categories><comments>8 Pages</comments><journal-ref>International Journal of Next-Generation Networks 2.2 (2010) 61-68</journal-ref><doi>10.5121/ijngn.2010.2206</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  3G, processor of 2G services, is a family of standards for mobile
telecommunications defined by the International Telecommunication Union [1]. 3G
services include wide-area wireless voice telephone, video calls, and wireless
data, all in a mobile environment. It allows simultaneous use of speech and
data services and higher data rates.3G is defined to facilitate growth,
increased bandwidth and support more diverse applications. The focus of this
study is to examine the factors affecting the adoption of 3G services among
Indian people. The study adopts the revised Technology Acceptance Model by
adding five antecedents-perceived risks, cost of adoption, perceived service
quality, subjective norms, and perceived lack of knowledge. Data have collected
from more than 400 school/college/Institution students &amp; employees of various
Government/Private sectors using interviews &amp; various convenience sampling
procedures and analyzed using MS excel and MATLAB. Result shows that perceived
usefulness has the most significant influence on attitude towards using 3G
services, which is consistent with prior studies. Of the five antecedents,
perceived risk and cost of adoption are found to be significantly influencing
attitude towards use. The outcome of this study would be beneficial to private
and public telecommunication organizations, various service providers, business
community, banking services and people of India. Research findings and
suggestions for future research are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3610</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3610</id><created>2010-06-18</created><authors><author><keyname>Ghosh</keyname><forenames>Kaushik</forenames><affiliation>Mody Institute of Technology, India</affiliation></author><author><keyname>Roy</keyname><forenames>Sarbani</forenames><affiliation>Jadavpur University, India</affiliation></author><author><keyname>Das</keyname><forenames>and Pradip K.</forenames><affiliation>Mody Institute of Technology, India</affiliation></author></authors><title>I-Min: An Intelligent Fermat Point Based Energy Efficient Geographic
  Packet Forwarding Technique for Wireless Sensor and Ad Hoc Networks</title><categories>cs.NI</categories><comments>11 Pages</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 34-44</journal-ref><doi>10.5121/jgraphoc.2010.2204</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Energy consumption and delay incurred in packet delivery are the two
important metrics for measuring the performance of geographic routing protocols
for Wireless Adhoc and Sensor Networks (WASN). A protocol capable of ensuring
both lesser energy consumption and experiencing lesser delay in packet delivery
is thus suitable for networks which are delay sensitive and energy hungry at
the same time. Thus a smart packet forwarding technique addressing both the
issues is thus the one looked for by any geographic routing protocol. In the
present paper we have proposed a Fermat point based forwarding technique which
reduces the delay experienced during packet delivery as well as the energy
consumed for transmission and reception of data packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3638</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3638</id><created>2010-06-18</created><authors><author><keyname>Bauer</keyname><forenames>Andreas</forenames></author></authors><title>Monitorability of $\omega$-regular languages</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arguably, omega-regular languages play an important role as a specification
formalism in many approaches to systems monitoring via runtime verification.
However, since their elements are infinite words, not every omega-regular
language can sensibly be monitored at runtime when only a finite prefix of a
word, modelling the observed system behaviour so far, is available. The
monitorability of an omega-regular language, L, is thus a property that holds,
if for any finite word u, observed so far, it is possible to add another finite
word v, such that uv becomes a &quot;finite witness&quot; wrt. L; that is, for any
infinite word w, we have that uvw \in L, or for any infinite word w, we have
that uvw \not\in L. This notion has been studied in the past by several
authors, and it is known that the class of monitorable languages is strictly
more expressive than, e.g., the commonly used class of so-called safety
languages. But an exact categorisation of monitorable languages has, so far,
been missing. Motivated by the use of linear-time temporal logic (LTL) in many
approaches to runtime verification, this paper first determines the complexity
of the monitorability problem when L is given by an LTL formula. Further, it
then shows that this result, in fact, transfers to omega-regular languages in
general, i.e., whether they are given by an LTL formula, a nondeterministic
Buechi automaton, or even by an omega-regular expression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3650</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3650</id><created>2010-06-18</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan M.</forenames></author></authors><title>The Use of Probabilistic Systems to Mimic the Behaviour of Idiotypic AIS
  Robot Controllers</title><categories>cs.AI cs.NE cs.RO</categories><comments>8 pages, 6 tables, 2 figures, Journal of Systemics, Cybernetics and
  Informatics</comments><journal-ref>Journal of Systemics, Cybernetics and Informatics, 2009, 7(6),
  p72-79</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work has shown that robot navigation systems that employ an
architecture based upon the idiotypic network theory of the immune system have
an advantage over control techniques that rely on reinforcement learning only.
This is thought to be a result of intelligent behaviour selection on the part
of the idiotypic robot. In this paper an attempt is made to imitate idiotypic
dynamics by creating controllers that use reinforcement with a number of
different probabilistic schemes to select robot behaviour. The aims are to show
that the idiotypic system is not merely performing some kind of periodic random
behaviour selection, and to try to gain further insight into the processes that
govern the idiotypic mechanism. Trials are carried out using simulated Pioneer
robots that undertake navigation exercises. Results show that a scheme that
boosts the probability of selecting highly-ranked alternative behaviours to 50%
during stall conditions comes closest to achieving the properties of the
idiotypic system, but remains unable to match it in terms of all round
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3651</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3651</id><created>2010-06-18</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author></authors><title>Quantum algorithms for formula evaluation</title><categories>quant-ph cs.CC cs.DS</categories><comments>11 pages, survey for NATO ARW &quot;Quantum Cryptography and Computing&quot;,
  Gdansk, September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey the recent sequence of algorithms for evaluating Boolean formulas
consisting of NAND gates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3652</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3652</id><created>2010-06-18</created><authors><author><keyname>Majid</keyname><forenames>Mazlina Abdul</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Modelling Reactive and Proactive Behaviour in Simulation</title><categories>cs.AI cs.CE cs.MA</categories><comments>9 pages, 7 figures, Operational Research Society 5th Simulation
  Workshop (SW10)</comments><journal-ref>Proceedings of Operational Research Society 5th Simulation
  Workshop (SW10), Worcestershire, England, 2010, p23-31</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research investigated the simulation model behaviour of a traditional
and combined discrete event as well as agent based simulation models when
modelling human reactive and proactive behaviour in human centric complex
systems. A departmental store was chosen as human centric complex case study
where the operation system of a fitting room in WomensWear department was
investigated. We have looked at ways to determine the efficiency of new
management policies for the fitting room operation through simulating the
reactive and proactive behaviour of staff towards customers. Once development
of the simulation models and their verification had been done, we carried out a
validation experiment in the form of a sensitivity analysis. Subsequently, we
executed a statistical analysis where the mixed reactive and proactive
behaviour experimental results were compared with some reactive experimental
results from previously published works. Generally, this case study discovered
that simple proactive individual behaviour could be modelled in both simulation
models. In addition, we found the traditional discrete event model performed
similar in the simulation model output compared to the combined discrete event
and agent based simulation when modelling similar human behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3654</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3654</id><created>2010-06-18</created><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author></authors><title>Detecting Anomalous Process Behaviour using Second Generation Artificial
  Immune Systems</title><categories>cs.AI cs.CR cs.NE</categories><comments>26 pages, 4 tables, 2 figures, International Journal of
  Unconventional Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Immune Systems have been successfully applied to a number of
problem domains including fault tolerance and data mining, but have been shown
to scale poorly when applied to computer intrusion detec- tion despite the fact
that the biological immune system is a very effective anomaly detector. This
may be because AIS algorithms have previously been based on the adaptive immune
system and biologically-naive mod- els. This paper focuses on describing and
testing a more complex and biologically-authentic AIS model, inspired by the
interactions between the innate and adaptive immune systems. Its performance on
a realistic process anomaly detection problem is shown to be better than
standard AIS methods (negative-selection), policy-based anomaly detection
methods (systrace), and an alternative innate AIS approach (the DCA). In
addition, it is shown that runtime information can be used in combination with
system call information to enhance detection capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3661</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3661</id><created>2010-06-18</created><authors><author><keyname>Fournier-Prunaret</keyname><forenames>Daniele</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>Fractal Basins and Boundaries in 2D Maps inspired in Discrete Population
  Models</title><categories>nlin.CD cs.GR math.DS</categories><comments>4 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-dimensional maps can model interactions between populations. Despite
their simplicity, these dynamical systems can show some complex situations, as
multistability or fractal boundaries between basins that lead to remarkable
pictures. Some of them are shown and explained here for three different 2D
discrete models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3671</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3671</id><created>2010-06-18</created><updated>2010-09-07</updated><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames></author></authors><title>Continuous history variable for programmable quantum processors</title><categories>quant-ph cs.OH</categories><comments>LaTeX, 4 pages, 2 figures; v2: 5 pages, 5 figures, eq.3 corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this brief note is discussed application of continuous quantum history
(&quot;trash&quot;) variable for simplification of scheme of programmable quantum
processor. Similar scheme may be tested also in other models of the theory of
quantum algorithms and complexity, because provides modification of a standard
operation: quantum function evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3678</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3678</id><created>2010-06-18</created><authors><author><keyname>Cabalar</keyname><forenames>Pedro</forenames></author></authors><title>Functional Answer Set Programming</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an extension of Answer Set Programming (ASP), and in
particular, of its most general logical counterpart, Quantified Equilibrium
Logic (QEL), to deal with partial functions. Although the treatment of equality
in QEL can be established in different ways, we first analyse the choice of
decidable equality with complete functions and Herbrand models, recently
proposed in the literature. We argue that this choice yields some
counterintuitive effects from a logic programming and knowledge representation
point of view. We then propose a variant called QELF where the set of functions
is partitioned into partial and Herbrand functions (we also call constructors).
In the rest of the paper, we show a direct connection to Scott's Logic of
Existence and present a practical application, proposing an extension of normal
logic programs to deal with partial functions and equality, so that they can be
translated into function-free normal programs, being possible in this way to
compute their answer sets with any standard ASP solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3679</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3679</id><created>2010-06-18</created><authors><author><keyname>Mobahi</keyname><forenames>Hossein</forenames></author><author><keyname>Rao</keyname><forenames>Shankar R.</forenames></author><author><keyname>Yang</keyname><forenames>Allen Y.</forenames></author><author><keyname>Sastry</keyname><forenames>Shankar S.</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Segmentation of Natural Images by Texture and Boundary Compression</title><categories>cs.CV cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel algorithm for segmentation of natural images that
harnesses the principle of minimum description length (MDL). Our method is
based on observations that a homogeneously textured region of a natural image
can be well modeled by a Gaussian distribution and the region boundary can be
effectively coded by an adaptive chain code. The optimal segmentation of an
image is the one that gives the shortest coding length for encoding all
textures and boundaries in the image, and is obtained via an agglomerative
clustering process applied to a hierarchy of decreasing window sizes as
multi-scale texture features. The optimal segmentation also provides an
accurate estimate of the overall coding length and hence the true entropy of
the image. We test our algorithm on the publicly available Berkeley
Segmentation Dataset. It achieves state-of-the-art segmentation results
compared to other existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3688</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3688</id><created>2010-06-17</created><authors><author><keyname>Frenzel</keyname><forenames>Stefan</forenames></author><author><keyname>Neubert</keyname><forenames>Elke</forenames></author></authors><title>Is the P300 Speller Independent?</title><categories>cs.HC</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The P300 speller is being considered as an independent brain-computer
interface. That means it measures the user's intent, and does not require the
user to move any muscles. In particular it should not require eye fixation of
the desired character. However, it has been shown that posterior electrodes
provide significant discriminative information, which is likely related to
visual processing. These findings imply the need for studies controlling the
effect of eye movements. In experiments with a 3x3 character matrix, attention
and eye fixation was directed to different characters. In the event-related
potentials, a P300 occurred for the attended character, and N200 was seen for
the trials showing the focussed character. It occurred at posterior sites,
reaching its peak at 200ms after stimulus onset. The results suggest that gaze
direction plays an important role in P300 speller paradigm. By controlling gaze
direction it is possible to separate voluntary and involuntary EEG responses to
the highlighting of characters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3701</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3701</id><created>2010-06-18</created><authors><author><keyname>Kenna</keyname><forenames>Ralph</forenames></author><author><keyname>Berche</keyname><forenames>Bertrand</forenames></author></authors><title>Concentration versus dispersion of research resources: a contribution to
  the debate</title><categories>physics.soc-ph cs.DL</categories><comments>17 pages, 8 figures, each with 3 panels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the results of the UK's research assessment exercise, we show that the
size or mass of research groups, rather than individual caliber or prestige of
the institution, is the dominant factor which drives the quality of research
teams. There are two critical masses in research: a lower one, below which
teams are vulnerable and an upper one, above which average dependency of
research quality on team size reduces. This leveling off refutes arguments
which advocate ever increasing concentration of research support into a few
large institutions. We also show that to increase research quality, policies
which nourish two-way communication links between researchers are paramount.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3709</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3709</id><created>2010-06-18</created><authors><author><keyname>Axelsson</keyname><forenames>Roland</forenames></author><author><keyname>Hague</keyname><forenames>Matthew</forenames></author><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Lange</keyname><forenames>Martin</forenames></author><author><keyname>Latte</keyname><forenames>Markus</forenames></author></authors><title>Extended Computation Tree Logic</title><categories>cs.LO</categories><doi>10.1007/978-3-642-16242-8_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a generic extension of the popular branching-time logic CTL
which refines the temporal until and release operators with formal languages.
For instance, a language may determine the moments along a path that an until
property may be fulfilled. We consider several classes of languages leading to
logics with different expressive power and complexity, whose importance is
motivated by their use in model checking, synthesis, abstract interpretation,
etc.
  We show that even with context-free languages on the until operator the logic
still allows for polynomial time model-checking despite the significant
increase in expressive power. This makes the logic a promising candidate for
applications in verification.
  In addition, we analyse the complexity of satisfiability and compare the
expressive power of these logics to CTL* and extensions of PDL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3715</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3715</id><created>2010-06-18</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Dou&#xef;eb</keyname><forenames>Karim</forenames></author></authors><title>Should Static Search Trees Ever Be Unbalanced?</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the question of whether or not a static search tree
should ever be unbalanced. We present several methods to restructure an
unbalanced k-ary search tree $T$ into a new tree $R$ that preserves many of the
properties of $T$ while having a height of $\log_k n +1$ which is one unit off
of the optimal height. More specifically, we show that it is possible to ensure
that the depth of the elements in $R$ is no more than their depth in $T$ plus
at most $\log_k \log_k n +2$. At the same time it is possible to guarantee that
the average access time $P(R)$ in tree $R$ is no more than the average access
time $P(T)$ in tree $T$ plus $O(\log_k P(T))$. This suggests that for most
applications, a balanced tree is always a better option than an unbalanced one
since the balanced tree has similar average access time and much better worst
case access time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3724</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3724</id><created>2010-06-18</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author></authors><title>A Peer-to-Peer Middleware Framework for Resilient Persistent Programming</title><categories>cs.DC</categories><comments>Submitted to EuroSys 2006</comments><report-no>University of St Andrews CS/06/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The persistent programming systems of the 1980s offered a programming model
that integrated computation and long-term storage. In these systems, reliable
applications could be engineered without requiring the programmer to write
translation code to manage the transfer of data to and from non-volatile
storage. More importantly, it simplified the programmer's conceptual model of
an application, and avoided the many coherency problems that result from
multiple cached copies of the same information. Although technically
innovative, persistent languages were not widely adopted, perhaps due in part
to their closed-world model. Each persistent store was located on a single
host, and there were no flexible mechanisms for communication or transfer of
data between separate stores. Here we re-open the work on persistence and
combine it with modern peer-to-peer techniques in order to provide support for
orthogonal persistence in resilient and potentially long-running distributed
applications. Our vision is of an infrastructure within which an application
can be developed and distributed with minimal modification, whereupon the
application becomes resilient to certain failure modes. If a node, or the
connection to it, fails during execution of the application, the objects are
re-instantiated from distributed replicas, without their reference holders
being aware of the failure. Furthermore, we believe that this can be achieved
within a spectrum of application programmer intervention, ranging from minimal
to totally prescriptive, as desired. The same mechanisms encompass an
orthogonally persistent programming model. We outline our approach to
implementing this vision, and describe current progress.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3726</identifier>
 <datestamp>2014-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3726</id><created>2010-06-18</created><updated>2014-07-23</updated><authors><author><keyname>Webb</keyname><forenames>Hazel</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author></authors><title>Diamond Dicing</title><categories>cs.DB</categories><comments>29 pages</comments><journal-ref>Data &amp; Knowledge Engineering, Volume 86, July 2013, Pages 1-18</journal-ref><doi>10.1016/j.datak.2013.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In OLAP, analysts often select an interesting sample of the data. For
example, an analyst might focus on products bringing revenues of at least 100
000 dollars, or on shops having sales greater than 400 000 dollars. However,
current systems do not allow the application of both of these thresholds
simultaneously, selecting products and shops satisfying both thresholds. For
such purposes, we introduce the diamond cube operator, filling a gap among
existing data warehouse operations.
  Because of the interaction between dimensions the computation of diamond
cubes is challenging. We compare and test various algorithms on large data sets
of more than 100 million facts. We find that while it is possible to implement
diamonds in SQL, it is inefficient. Indeed, our custom implementation can be a
hundred times faster than popular database engines (including a row-store and a
column-store).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3728</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3728</id><created>2010-06-18</created><authors><author><keyname>Walker</keyname><forenames>Scott</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author></authors><title>RAFDA: A Policy-Aware Middleware Supporting the Flexible Separation of
  Application Logic from Distribution</title><categories>cs.DC</categories><comments>Submitted to EuroSys 2006</comments><report-no>University of St Andrews CS/06/2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Middleware technologies often limit the way in which object classes may be
used in distributed applications due to the fixed distribution policies that
they impose. These policies permeate applications developed using existing
middleware systems and force an unnatural encoding of application level
semantics. For example, the application programmer has no direct control over
inter-address-space parameter passing semantics. Semantics are fixed by the
distribution topology of the application, which is dictated early in the design
cycle. This creates applications that are brittle with respect to changes in
distribution. This paper explores technology that provides control over the
extent to which inter-address-space communication is exposed to programmers, in
order to aid the creation, maintenance and evolution of distributed
applications. The described system permits arbitrary objects in an application
to be dynamically exposed for remote access, allowing applications to be
written without concern for distribution. Programmers can conceal or expose the
distributed nature of applications as required, permitting object placement and
distribution boundaries to be decided late in the design cycle and even
dynamically. Inter-address-space parameter passing semantics may also be
decided independently of object implementation and at varying times in the
design cycle, again possibly as late as run-time. Furthermore, transmission
policy may be defined on a per-class, per-method or per-parameter basis,
maximizing plasticity. This flexibility is of utility in the development of new
distributed applications, and the creation of management and monitoring
infrastructures for existing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3732</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3732</id><created>2010-06-18</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author><author><keyname>Macdonald</keyname><forenames>Angus</forenames></author><author><keyname>Bigwood</keyname><forenames>Greg</forenames></author></authors><title>Towards Adaptable and Adaptive Policy-Free Middleware</title><categories>cs.DC</categories><comments>Submitted to Dependable and Adaptive Distributed Systems Track, ACM
  SAC 2007</comments><report-no>University of St Andrews CS/06/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We believe that to fully support adaptive distributed applications,
middleware must itself be adaptable, adaptive and policy-free. In this paper we
present a new language-independent adaptable and adaptive policy framework
suitable for integration in a wide variety of middleware systems. This
framework facilitates the construction of adaptive distributed applications.
The framework addresses adaptability through its ability to represent a wide
range of specific middleware policies. Adaptiveness is supported by a rich
contextual model, through which an application programmer may control precisely
how policies should be selected for any particular interaction with the
middleware. A contextual pattern mechanism facilitates the succinct expression
of both coarse- and fine-grain policy contexts. Policies may be specified and
altered dynamically, and may themselves take account of dynamic conditions. The
framework contains no hard-wired policies; instead, all policies can be
configured.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3739</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3739</id><created>2010-06-18</created><authors><author><keyname>Walker</keyname><forenames>Scott</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author></authors><title>Promoting Component Reuse by Separating Transmission Policy from
  Implementation</title><categories>cs.DC</categories><comments>Submitted to ICDCS 2005</comments><report-no>University of St Andrews CS/05/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a methodology and set of tools which assist the
construction of applications from components, by separating the issues of
transmission policy from component definition and implementation. This promotes
a greater degree of software reuse than is possible using traditional
middleware environments. Whilst component technologies are usually presented as
a mechanism for promoting reuse, reuse is often limited due to design choices
that permeate component implementation. The programmer has no direct control
over inter-address-space parameter passing semantics: it is fixed by the
distributed application's structure, based on the remote accessibility of the
components. Using traditional middleware tools and environments, the
application designer may be forced to use an unnatural encoding of application
level semantics since application parameter passing semantics are tightly
coupled with the component deployment topology. This paper describes how
inter-address-space parameter passing semantics may be decided independently of
component implementation. Transmission policy may be dynamically defined on a
per-class, per-method or per-parameter basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3742</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3742</id><created>2010-06-18</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Walker</keyname><forenames>Scott</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author></authors><title>RAFDA: Middleware Supporting the Separation of Application Logic from
  Distribution Policy</title><categories>cs.DC</categories><comments>Submitted to Middleware 2005</comments><report-no>University of St Andrews CS/05/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Middleware technologies often limit the way in which object classes may be
used in distributed applications due to the fixed distribution policies imposed
by the Middleware system. These policies permeate the applications developed
using them and force an unnatural encoding of application level semantics. For
example, the application programmer has no direct control over
inter-address-space parameter passing semantics since it is fixed by the
application's distribution topology which is dictated early in the design cycle
by the Middleware. This creates applications that are brittle with respect to
changes in the way in which the applications are distributed. This paper
explores technology permitting arbitrary objects in an application to be
dynamically exposed for remote access. Using this, the application can be
written without concern for its distribution with object placement and
distribution boundaries decided late in the design cycle and even dynamically.
Inter-address-space parameter passing semantics may also be decided
independently of object implementation and at varying times in the design
cycle, again, possibly as late as run-time. Furthermore, transmission policy
may be defined on a per-class, per-method or per-parameter basis maximizing
plasticity. This flexibility is of utility in the development of new
distributed applications and the creation of management and monitoring
infrastructures for existing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3755</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3755</id><created>2010-06-18</created><authors><author><keyname>Gao</keyname><forenames>Yuan</forenames></author><author><keyname>Yu</keyname><forenames>Sheng</forenames></author></authors><title>State complexity of union and intersection combined with star and
  reversal</title><categories>cs.FL</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the state complexities of union and intersection
combined with star and reversal, respectively. We obtain the state complexities
of these combined operations on regular languages and show that they are less
than the mathematical composition of the state complexities of their individual
participating operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3776</identifier>
 <datestamp>2011-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3776</id><created>2010-06-18</created><authors><author><keyname>Cranston</keyname><forenames>Daniel W.</forenames></author><author><keyname>Kim</keyname><forenames>Seog-Jin</forenames></author><author><keyname>Yu</keyname><forenames>Gexin</forenames></author></authors><title>Injective colorings of graphs with low average degree</title><categories>math.CO cs.DM</categories><comments>15 pages, 3 figures</comments><journal-ref>Algorithmica. Vol. 60(3), 2011, pp. 553-568</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mad(G)$ denote the maximum average degree (over all subgraphs) of $G$
and let $\chi_i(G)$ denote the injective chromatic number of $G$. We prove that
if $\Delta\geq 4$ and $\mad(G)&lt;\frac{14}5$, then $\chi_i(G)\leq\Delta+2$. When
$\Delta=3$, we show that $\mad(G)&lt;\frac{36}{13}$ implies $\chi_i(G)\le 5$. In
contrast, we give a graph $G$ with $\Delta=3$, $\mad(G)=\frac{36}{13}$, and
$\chi_i(G)=6$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3779</identifier>
 <datestamp>2011-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3779</id><created>2010-06-18</created><authors><author><keyname>Cranston</keyname><forenames>Daniel W.</forenames></author><author><keyname>Yu</keyname><forenames>Gexin</forenames></author></authors><title>A New Lower Bound on the Density of Vertex Identifying Codes for the
  Infinite Hexagonal Grid</title><categories>math.CO cs.DS</categories><comments>16 pages, 10 figures</comments><msc-class>05C35, 05C69, 05C90</msc-class><journal-ref>Electronic J. of Combinatorics, R113, Volume 16(1), 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph $G$, an identifying code $C \subseteq V(G)$ is a vertex set
such that for any two distinct vertices $v_1,v_2\in V(G)$, the sets $N[v_1]\cap
C$ and $N[v_2]\cap C$ are distinct and nonempty (here $N[v]$ denotes a vertex
$v$ and its neighbors). We study the case when $G$ is the infinite hexagonal
grid $H$. Cohen et.al. constructed two identifying codes for $H$ with density
$3/7$ and proved that any identifying code for $H$ must have density at least
$16/39\approx0.410256$. Both their upper and lower bounds were best known until
now. Here we prove a lower bound of $12/29\approx0.413793$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3780</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3780</id><created>2010-06-18</created><authors><author><keyname>Barron</keyname><forenames>Andrew R.</forenames></author><author><keyname>Joseph</keyname><forenames>Antony</forenames></author></authors><title>Least Squares Superposition Codes of Moderate Dictionary Size, Reliable
  at Rates up to Capacity</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>17 pages, 4 figures, journal submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the additive white Gaussian noise channel with average codeword power
constraint, new coding methods are devised in which the codewords are sparse
superpositions, that is, linear combinations of subsets of vectors from a given
design, with the possible messages indexed by the choice of subset. Decoding is
by least squares, tailored to the assumed form of linear combination.
Communication is shown to be reliable with error probability exponentially
small for all rates up to the Shannon capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3782</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3782</id><created>2010-06-18</created><authors><author><keyname>Phan</keyname><forenames>Khoa Tran</forenames></author><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Near-Optimal Deviation-Proof Medium Access Control Designs in Wireless
  Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>14 double-column pages, submitted to ACM/IEEE Trans Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed medium access control (MAC) protocols are essential for the
proliferation of low cost, decentralized wireless local area networks (WLANs).
Most MAC protocols are designed with the presumption that nodes comply with
prescribed rules. However, selfish nodes have natural motives to manipulate
protocols in order to improve their own performance. This often degrades the
performance of other nodes as well as that of the overall system. In this work,
we propose a class of protocols that limit the performance gain which nodes can
obtain through selfish manipulation while incurring only a small efficiency
loss. The proposed protocols are based on the idea of a review strategy, with
which nodes collect signals about the actions of other nodes over a period of
time, use a statistical test to infer whether or not other nodes are following
the prescribed protocol, and trigger a punishment if a departure from the
protocol is perceived. We consider the cases of private and public signals and
provide analytical and numerical results to demonstrate the properties of the
proposed protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3786</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3786</id><created>2010-06-18</created><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>On the concentration of the number of solutions of random satisfiability
  formulas</title><categories>cs.DM cond-mat.stat-mech cs.CC cs.LO math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $Z(F)$ be the number of solutions of a random $k$-satisfiability formula
$F$ with $n$ variables and clause density $\alpha$. Assume that the probability
that $F$ is unsatisfiable is $O(1/\log(n)^{1+\e})$ for $\e&gt;0$. We show that
(possibly excluding a countable set of `exceptional' $\alpha$'s) the number of
solutions concentrate in the logarithmic scale, i.e., there exists a non-random
function $\phi(\alpha)$ such that, for any $\delta&gt;0$, $(1/n)\log Z(F)\in
[\phi-\delta,\phi+\delta]$ with high probability. In particular, the assumption
holds for all $\alpha&lt;1$, which proves the above concentration claim in the
whole satisfiability regime of random $2$-SAT. We also extend these results to
a broad class of constraint satisfaction problems. The proof is based on an
interpolation technique from spin-glass theory, and on an application of
Friedgut's theorem on sharp thresholds for graph properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3787</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3787</id><created>2010-06-18</created><updated>2014-04-19</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Complete Complementary Results Report of the MARF's NLP Approach to the
  DEFT 2010 Competition</title><categories>cs.CL</categories><comments>550 pages; 683 tables; index; v6 adds some stats. NLP pipeline
  results, reduces the page and table count by collapsing more tables together,
  corrections to some references and text</comments><msc-class>68T50, 68T10, 68T37</msc-class><acm-class>I.2.7; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This companion paper complements the main DEFT'10 article describing the MARF
approach (arXiv:0905.1235) to the DEFT'10 NLP challenge (described at
http://www.groupes.polymtl.ca/taln2010/deft.php in French). This paper is aimed
to present the complete result sets of all the conducted experiments and their
settings in the resulting tables highlighting the approach and the best
results, but also showing the worse and the worst and their subsequent
analysis. This particular work focuses on application of the MARF's classical
and NLP pipelines to identification tasks within various francophone corpora to
identify decades when certain articles were published for the first track
(Piste 1) and place of origin of a publication (Piste 2), such as the journal
and location (France vs. Quebec). This is the sixth iteration of the release of
the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3825</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3825</id><created>2010-06-18</created><updated>2011-01-28</updated><authors><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Ganty</keyname><forenames>Pierre</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Luttenberger</keyname><forenames>Michael</forenames></author></authors><title>Parikh's Theorem: A simple and direct automaton construction</title><categories>cs.FL</categories><comments>12 pages, 3 figures</comments><journal-ref>Information Processing Letters 111(12) (2011) 614-619</journal-ref><doi>10.1016/j.ipl.2011.03.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parikh's theorem states that the Parikh image of a context-free language is
semilinear or, equivalently, that every context-free language has the same
Parikh image as some regular language. We present a very simple construction
that, given a context-free grammar, produces a finite automaton recognizing
such a regular language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3845</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3845</id><created>2010-06-19</created><authors><author><keyname>Miaji</keyname><forenames>Yaser</forenames><affiliation>University Utara, Malaysia</affiliation></author><author><keyname>Hassan</keyname><forenames>Suhaidi</forenames><affiliation>University Utara, Malaysia</affiliation></author></authors><title>Breaking the Legend: Maxmin Fairness notion is no longer effective</title><categories>cs.NI</categories><comments>8 Pages</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 25-32</journal-ref><doi>10.5121/jgraphoc.2010.2203</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we analytically propose an alternative approach to achieve
better fairness in scheduling mechanisms which could provide better quality of
service particularly for real time application. Our proposal oppose the
allocation of the bandwidth which adopted by all previous scheduling mechanism.
It rather adopt the opposition approach be proposing the notion of
Maxmin-charge which fairly distribute the congestion. Furthermore, analytical
proposition of novel mechanism named as Just Queueing is been demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3848</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3848</id><created>2010-06-19</created><authors><author><keyname>Hasan</keyname><forenames>Mosin</forenames><affiliation>BVM Engineering College, India</affiliation></author><author><keyname>Prajapati</keyname><forenames>Nilesh</forenames><affiliation>BVM Engineering College, India</affiliation></author><author><keyname>Vohara</keyname><forenames>Safvan</forenames><affiliation>BVM Engineering College, India</affiliation></author></authors><title>Case Study On Social Engineering Techniques for Persuasion</title><categories>cs.CR</categories><comments>7 Pages</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 17-23</journal-ref><doi>10.5121/jgraphoc.2010.2202</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  There are plenty of security software in market; each claiming the best,
still we daily face problem of viruses and other malicious activities. If we
know the basic working principal of such malware then we can very easily
prevent most of them even without security software. Hackers and crackers are
experts in psychology to manipulate people into giving them access or the
information necessary to get access. This paper discusses the inner working of
such attacks. Case study of Spyware is provided. In this case study, we got
100% success using social engineering techniques for deception on Linux
operating system, which is considered as the most secure operating system. Few
basic principal of defend, for the individual as well as for the organization,
are discussed here, which will prevent most of such attack if followed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3855</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3855</id><created>2010-06-19</created><authors><author><keyname>Hou</keyname><forenames>Xueying</forenames><affiliation>Vincent</affiliation></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames><affiliation>Vincent</affiliation></author><author><keyname>Kiong</keyname><forenames>Buon</forenames><affiliation>Vincent</affiliation></author><author><keyname>Lau</keyname></author></authors><title>Impact of Channel Asymmetry on Performance of Channel Estimation and
  Precoding for Downlink Base Station Cooperative Transmission</title><categories>cs.IT math.IT</categories><comments>Submitted to the Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Base station (BS) cooperative transmission can improve the spectrum
efficiency of cellular systems, whereas using which the channels will become
asymmetry. In this paper, we study the impact of the asymmetry on the
performance of channel estimation and precoding in downlink BS cooperative
multiple-antenna multiple-carrier systems. We first present three linear
estimators which jointly estimate the channel coefficients from users in
different cells with minimum mean square error, robust design and least square
criterion, and then study the impact of uplink channel asymmetry on their
performance. It is shown that when the large scale channel information is
exploited for channel estimation, using non-orthogonal training sequences among
users in different cells leads to minor performance loss. Next, we analyze the
impact of downlink channel asymmetry on the performance of precoding with
channel estimation errors. Our analysis shows that although the estimation
errors of weak cross links are large, the resulting rate loss is minor because
their contributions are weighted by the receive signal to noise ratio. The
simulation results verify our analysis and show that the rate loss per user is
almost constant no matter where the user is located, when the channel
estimators exploiting the large scale fading gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3863</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3863</id><created>2010-06-19</created><updated>2011-02-22</updated><authors><author><keyname>Kenna</keyname><forenames>Ralph</forenames></author><author><keyname>Berche</keyname><forenames>Bertrand</forenames></author></authors><title>Normalization of peer-evaluation measures of group research quality
  across academic disciplines</title><categories>physics.soc-ph cs.DL</categories><comments>5 figures, each with 2 panels. To appear in the journal Research
  Evaluation</comments><journal-ref>Research Evaluation 20 (2011) 107-116</journal-ref><doi>10.3152/095820211X12941371876625</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-evaluation based measures of group research quality such as the UK's
Research Assessment Exercise (RAE), which do not employ bibliometric analyses,
cannot directly avail of such methods to normalize research impact across
disciplines. This is seen as a conspicuous flaw of such exercises and calls
have been made to find a remedy. Here a simple, systematic solution is proposed
based upon a mathematical model for the relationship between research quality
and group quantity. This model manifests both the Matthew effect and a
phenomenon akin to the Ringelmann effect and reveals the existence of two
critical masses for each academic discipline: a lower value, below which groups
are vulnerable, and an upper value beyond which the dependency of quality on
quantity reduces and plateaus appear when the critical masses are large. A
possible normalization procedure is then to pitch these plateaus at similar
levels. We examine the consequences of this procedure at RAE for a multitude of
academic disciplines, corresponding to a range of critical masses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3870</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3870</id><created>2010-06-19</created><authors><author><keyname>Barron</keyname><forenames>Andrew R</forenames></author><author><keyname>Joseph</keyname><forenames>Antony</forenames></author></authors><title>Toward Fast Reliable Communication at Rates Near Capacity with Gaussian
  Noise</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>5 pages, 4 figures, conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the additive Gaussian noise channel with average codeword power
constraint, sparse superposition codes and adaptive successive decoding is
developed. Codewords are linear combinations of subsets of vectors, with the
message indexed by the choice of subset. A feasible decoding algorithm is
presented. Communication is reliable with error probability exponentially small
for all rates below the Shannon capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3878</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3878</id><created>2010-06-19</created><updated>2011-04-26</updated><authors><author><keyname>Lund</keyname><forenames>Ben D.</forenames></author><author><keyname>Purdy</keyname><forenames>George B.</forenames></author><author><keyname>Smith</keyname><forenames>Justin W.</forenames></author></authors><title>A Bichromatic Incidence Bound and an Application</title><categories>math.CO cs.CG</categories><comments>12 pages</comments><msc-class>51D20</msc-class><journal-ref>Discrete &amp; Computational Geometry, Volume 46, Number 4, 2011,
  611-625</journal-ref><doi>10.1007/s00454-011-9367-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a new, tight upper bound on the number of incidences between points
and hyperplanes in Euclidean d-space. Given n points, of which k are colored
red, there are O_d(m^{2/3}k^{2/3}n^{(d-2)/3} + kn^{d-2} + m) incidences between
the k red points and m hyperplanes spanned by all n points provided that m =
\Omega(n^{d-2}). For the monochromatic case k = n, this was proved by Agarwal
and Aronov.
  We use this incidence bound to prove that a set of n points, no more than n-k
of which lie on any plane or two lines, spans \Omega(nk^2) planes. We also
provide an infinite family of counterexamples to a conjecture of Purdy's on the
number of hyperplanes spanned by a set of points in dimensions higher than 3,
and present new conjectures not subject to the counterexample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3894</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3894</id><created>2010-06-19</created><authors><author><keyname>Altman</keyname><forenames>E.</forenames></author><author><keyname>Bernhard</keyname><forenames>P.</forenames></author><author><keyname>Caron</keyname><forenames>S.</forenames></author><author><keyname>Kesidis</keyname><forenames>G.</forenames></author><author><keyname>Rojas-Mora</keyname><forenames>J.</forenames></author><author><keyname>Wong</keyname><forenames>S.</forenames></author></authors><title>A Study of Non-Neutral Networks with Usage-based Prices</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hahn and Wallsten wrote that network neutrality &quot;usually means that broadband
service providers charge consumers only once for Internet access, do not favor
one content provider over another, and do not charge content providers for
sending information over broadband lines to end users.&quot; In this paper we study
the implications of non-neutral behaviors under a simple model of linear
demand-response to usage-based prices. We take into account advertising
revenues and consider both cooperative and non-cooperative scenarios. In
particular, we model the impact of side-payments between service and content
providers. We also consider the effect of service discrimination by access
providers, as well as an extension of our model to non-monopolistic content
providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3909</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3909</id><created>2010-06-20</created><updated>2010-06-29</updated><authors><author><keyname>Hung</keyname><forenames>Ruo-Wei</forenames></author></authors><title>Constructing Two Edge-Disjoint Hamiltonian Cycles and Two Equal
  Node-Disjoint Cycles in Twisted Cubes</title><categories>cs.DC</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hypercube is one of the most popular interconnection networks since it
has simple structure and is easy to implement. The $n$-dimensional twisted
cube, denoted by $TQ_n$, an important variation of the hypercube, possesses
some properties superior to the hypercube. Recently, some interesting
properties of $TQ_n$ were investigated. In this paper, we construct two
edge-disjoint Hamiltonian cycles in $TQ_n$ for any odd integer $n\geqslant 5$.
The presence of two edge-disjoint Hamiltonian cycles provides an advantage when
implementing two algorithms that require a ring structure by allowing message
traffic to be spread evenly across the twisted cube. Furthermore, we construct
two equal node-disjoint cycles in $TQ_n$ for any odd integer $n\geqslant 3$, in
which these two cycles contain the same number of nodes and every node appears
in one cycle exactly once. In other words, we decompose a twisted cube into two
components with the same size such that each component contains a Hamiltonian
cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3913</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3913</id><created>2010-06-20</created><updated>2011-01-26</updated><authors><author><keyname>Fong</keyname><forenames>Chamberlain</forenames></author></authors><title>Methods for Accelerating Conway's Doomsday Algorithm (part 1)</title><categories>cs.DS cs.DM</categories><comments>added references to Lewis Carroll's early work on a perpetual
  calendar algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modification of a key component in the Doomsday Algorithm for
calculating the day of the week of any calendar date. In particular, we propose
to replace the calculation of the required term: \lfloor \frac{x}{12} \rfloor +
x \bmod 12 + \lfloor \frac{x \bmod 12}{4} \rfloor with the term 2y + 10 \, (y
\bmod 2) + z + \lfloor \frac{2 \, (y \bmod 2) + z}{4} \rfloor where x is an
input 2-digit year; y is the tens digit of x; z is the ones digit of x; We
argue the fact that our modification operates on individual base-10 digits
makes the algorithm easier to calculate mentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3919</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3919</id><created>2010-06-20</created><authors><author><keyname>Cui</keyname><forenames>Ying</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Convergence-Optimal Quantizer Design of Distributed Contraction-based
  Iterative Algorithms with Quantized Message Passing</title><categories>cs.DC</categories><comments>17 pages, 9 figures, Transaction on Signal Processing, accepted</comments><doi>10.1109/TSP.2010.2055861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the convergence behavior of distributed iterative
algorithms with quantized message passing. We first introduce general iterative
function evaluation algorithms for solving fixed point problems distributively.
We then analyze the convergence of the distributed algorithms, e.g. Jacobi
scheme and Gauss-Seidel scheme, under the quantized message passing. Based on
the closed-form convergence performance derived, we propose two quantizer
designs, namely the time invariant convergence-optimal quantizer (TICOQ) and
the time varying convergence-optimal quantizer (TVCOQ), to minimize the effect
of the quantization error on the convergence. We also study the tradeoff
between the convergence error and message passing overhead for both TICOQ and
TVCOQ. As an example, we apply the TICOQ and TVCOQ designs to the iterative
waterfilling algorithm of MIMO interference game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3959</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3959</id><created>2010-06-17</created><updated>2011-07-23</updated><authors><author><keyname>Kadloor</keyname><forenames>Sachin</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author></authors><title>Molecular Communication Using Brownian Motion with Drift</title><categories>physics.bio-ph cond-mat.mes-hall cond-mat.soft cs.IT math.IT</categories><comments>20 pages, 7 figures, Accepted for publication in IEEE Trans. on
  NanoBioscience</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by biological communication systems, molecular communication has
been proposed as a viable scheme to communicate between nano-sized devices
separated by a very short distance. Here, molecules are released by the
transmitter into the medium, which are then sensed by the receiver. This paper
develops a preliminary version of such a communication system focusing on the
release of either one or two molecules into a fluid medium with drift. We
analyze the mutual information between transmitter and the receiver when
information is encoded in the time of release of the molecule. Simplifying
assumptions are required in order to calculate the mutual information, and
theoretical results are provided to show that these calculations are upper
bounds on the true mutual information. Furthermore, optimized degree
distributions are provided, which suggest transmission strategies for a variety
of drift velocities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3962</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3962</id><created>2010-06-20</created><authors><author><keyname>Gonnet</keyname><forenames>Pedro</forenames></author></authors><title>Increasing the Reliability of Adaptive Quadrature Using Explicit
  Interpolants</title><categories>cs.NA math.NA</categories><comments>32 pages, submitted to ACM Transactions on Mathematical Software</comments><acm-class>F.2.1; G.1.4</acm-class><journal-ref>ACM Transactions on Mathematical Software (TOMS), Volume 37 Issue
  3, September 2010</journal-ref><doi>10.1145/1824801.1824804</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two new adaptive quadrature routines. Both routines differ from
previously published algorithms in many aspects, most significantly in how they
represent the integrand, how they treat non-numerical values of the integrand,
how they deal with improper divergent integrals and how they estimate the
integration error. The main focus of these improvements is to increase the
reliability of the algorithms without significantly impacting their efficiency.
Both algorithms are implemented in Matlab and tested using both the &quot;families&quot;
suggested by Lyness and Kaganove and the battery test used by Gander and
Gautschi and Kahaner. They are shown to be more reliable, albeit in some cases
less efficient, than other commonly-used adaptive integrators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3968</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3968</id><created>2010-06-20</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Practical Range Aggregation, Selection and Set Maintenance Techniques</title><categories>cs.DS</categories><msc-class>68P05</msc-class><acm-class>E.1</acm-class><journal-ref>Politehnica University of Bucharest (UPB) Scientific Bulletin,
  Series C - Electrical Engineering and Computer Science, vol. 72, issue 2, pp.
  3-16, 2010. (ISSN: 1454-234X)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present several new and very practical methods and
techniques for range aggregation and selection problems in multidimensional
data structures and other types of sets of values. We also present some new
extensions and applications for some fundamental set maintenance problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3970</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3970</id><created>2010-06-20</created><updated>2010-06-23</updated><authors><author><keyname>Chlamtac</keyname><forenames>Eden</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author></authors><title>Approximating Sparsest Cut in Graphs of Bounded Treewidth</title><categories>cs.DS</categories><acm-class>F.2.2; G.2.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first constant-factor approximation algorithm for Sparsest Cut
with general demands in bounded treewidth graphs. In contrast to previous
algorithms, which rely on the flow-cut gap and/or metric embeddings, our
approach exploits the Sherali-Adams hierarchy of linear programming
relaxations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.3993</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.3993</id><created>2010-06-21</created><authors><author><keyname>Prissette</keyname><forenames>Cyril</forenames><affiliation>LSEET</affiliation></author></authors><title>An Algorithm to List All the Fixed-Point Free Involutions on a Finite
  Set</title><categories>cs.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An involution on a finite set is a bijection such as I(I(e))=e for all the
element of the set. A fixed-point free involution on a finite set is an
involution such as I(e)=e for none element of the set. In this article, the
fixed-point free involutions are represented as partitions of the set and some
properties linked to this representation are exhibited. Then an optimal
algorithm to list all the fixed-point free involutions is presented. Its
soundness relies on the representation of the fixed-point free involutions as
partitions. Finally, an implementation of the algorithm is proposed, with an
effective data representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4014</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4014</id><created>2010-06-21</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author></authors><title>New Developments in Quantum Algorithms</title><categories>quant-ph cs.CC cs.DS</categories><comments>11 pages, 1 figure, to appear as an invited survey talk at MFCS'2010</comments><doi>10.1007/978-3-642-15155-2_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey, we describe two recent developments in quantum algorithms.
  The first new development is a quantum algorithm for evaluating a Boolean
formula consisting of AND and OR gates of size N in time O(\sqrt{N}). This
provides quantum speedups for any problem that can be expressed via Boolean
formulas. This result can be also extended to span problems, a generalization
of Boolean formulas. This provides an optimal quantum algorithm for any Boolean
function in the black-box query model.
  The second new development is a quantum algorithm for solving systems of
linear equations. In contrast with traditional algorithms that run in time
O(N^{2.37...}) where N is the size of the system, the quantum algorithm runs in
time O(\log^c N). It outputs a quantum state describing the solution of the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4026</identifier>
 <datestamp>2011-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4026</id><created>2010-06-21</created><updated>2011-10-24</updated><authors><author><keyname>Leducq</keyname><forenames>Elodie</forenames></author></authors><title>A proof of two conjectures on APN functions</title><categories>math.NT cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dobbertin, Mills, M\&quot;uller, Pott and Willems conjecture that two families of
power mapping are families of APN functions. Here we prove those two
conjectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4030</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4030</id><created>2010-06-21</created><authors><author><keyname>Wu</keyname><forenames>Bin</forenames></author><author><keyname>Masera</keyname><forenames>Guido</forenames></author></authors><title>A Novel VLSI Architecture of Fixed-complexity Sphere Decoder</title><categories>cs.IT math.IT</categories><comments>8 pages, this paper has been accepted by the conference DSD 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fixed-complexity Sphere Decoder (FSD) is a recently proposed technique for
Multiple-Input Multiple-Output (MIMO) detection. It has several outstanding
features such as constant throughput and large potential parallelism, which
makes it suitable for efficient VLSI implementation. However, to our best
knowledge, no VLSI implementation of FSD has been reported in the literature,
although some FPGA prototypes of FSD with pipeline architecture have been
developed. These solutions achieve very high throughput but at very high cost
of hardware resources, making them impractical in real applications. In this
paper, we present a novel four-nodes-per-cycle parallel architecture of FSD,
with a breadth-first processing that allows for short critical path. The
implementation achieves a throughput of 213.3 Mbps at 400 MHz clock frequency,
at a cost of 0.18 mm2 Silicon area on 0.13{\mu}m CMOS technology. The proposed
solution is much more economical compared with the existing FPGA
implementations, and very suitable for practicl applications because of its
balanced performance and hardware-complexity; moreover it has the flexibility
to be expanded into an eight-nodes-per-cycle version in order to double the
throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4035</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4035</id><created>2010-06-21</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Chris</forenames></author></authors><title>Towards the Development of a Simulator for Investigating the Impact of
  People Management Practices on Retail Performance</title><categories>cs.AI cs.CE cs.MA</categories><comments>24 pages, 7 figures, 6 tables, Journal of Simulation 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often models for understanding the impact of management practices on retail
performance are developed under the assumption of stability, equilibrium and
linearity, whereas retail operations are considered in reality to be dynamic,
non-linear and complex. Alternatively, discrete event and agent-based modelling
are approaches that allow the development of simulation models of heterogeneous
non-equilibrium systems for testing out different scenarios. When developing
simulation models one has to abstract and simplify from the real world, which
means that one has to try and capture the 'essence' of the system required for
developing a representation of the mechanisms that drive the progression in the
real system. Simulation models can be developed at different levels of
abstraction. To know the appropriate level of abstraction for a specific
application is often more of an art than a science. We have developed a retail
branch simulation model to investigate which level of model accuracy is
required for such a model to obtain meaningful results for practitioners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4039</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4039</id><created>2010-06-21</created><updated>2011-02-04</updated><authors><author><keyname>Yan</keyname><forenames>Feng</forenames></author><author><keyname>Sundaram</keyname><forenames>Shreyas</forenames></author><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames></author><author><keyname>Qi</keyname><forenames>Yuan</forenames></author></authors><title>Distributed Autonomous Online Learning: Regrets and Intrinsic
  Privacy-Preserving Properties</title><categories>cs.LG cs.AI</categories><comments>25 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online learning has become increasingly popular on handling massive data. The
sequential nature of online learning, however, requires a centralized learner
to store data and update parameters. In this paper, we consider online learning
with {\em distributed} data sources. The autonomous learners update local
parameters based on local data sources and periodically exchange information
with a small subset of neighbors in a communication network. We derive the
regret bound for strongly convex functions that generalizes the work by Ram et
al. (2010) for convex functions. Most importantly, we show that our algorithm
has \emph{intrinsic} privacy-preserving properties, and we prove the sufficient
and necessary conditions for privacy preservation in the network. These
conditions imply that for networks with greater-than-one connectivity, a
malicious learner cannot reconstruct the subgradients (and sensitive raw data)
of other learners, which makes our algorithm appealing in privacy sensitive
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4046</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4046</id><created>2010-06-21</created><updated>2011-07-12</updated><authors><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author><author><keyname>Recht</keyname><forenames>Benjamin</forenames></author></authors><title>Online Identification and Tracking of Subspaces from Highly Incomplete
  Information</title><categories>cs.IT cs.SY math.IT math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents GROUSE (Grassmanian Rank-One Update Subspace Estimation),
an efficient online algorithm for tracking subspaces from highly incomplete
observations. GROUSE requires only basic linear algebraic manipulations at each
iteration, and each subspace update can be performed in linear time in the
dimension of the subspace. The algorithm is derived by analyzing incremental
gradient descent on the Grassmannian manifold of subspaces. With a slight
modification, GROUSE can also be used as an online incremental algorithm for
the matrix completion problem of imputing missing entries of a low-rank matrix.
GROUSE performs exceptionally well in practice both in tracking subspaces and
as an online algorithm for matrix completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4057</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4057</id><created>2010-06-21</created><authors><author><keyname>Lange</keyname><forenames>Christoph</forenames></author></authors><title>Towards OpenMath Content Dictionaries as Linked Data</title><categories>cs.DL cs.MS</categories><comments>Presented at the OpenMath Workshop 2010, http://cicm2010.cnam.fr/om/</comments><msc-class>68T35, 68T30, 68W30</msc-class><acm-class>H.3.5; F.4.m; G.4; H.5.4; I.2.4; J.2; J.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  &quot;The term 'Linked Data' refers to a set of best practices for publishing and
connecting structured data on the web&quot;. Linked Data make the Semantic Web work
practically, which means that information can be retrieved without complicated
lookup mechanisms, that a lightweight semantics enables scalable reasoning, and
that the decentral nature of the Web is respected. OpenMath Content
Dictionaries (CDs) have the same characteristics - in principle, but not yet in
practice. The Linking Open Data movement has made a considerable practical
impact: Governments, broadcasting stations, scientific publishers, and many
more actors are already contributing to the &quot;Web of Data&quot;. Queries can be
answered in a distributed way, and services aggregating data from different
sources are replacing hard-coded mashups. However, these services are currently
entirely lacking mathematical functionality. I will discuss real-world
scenarios, where today's RDF-based Linked Data do not quite get their job done,
but where an integration of OpenMath would help - were it not for certain
conceptual and practical restrictions. I will point out conceptual shortcomings
in the OpenMath 2 specification and common bad practices in publishing CDs and
then propose concrete steps to overcome them and to contribute OpenMath CDs to
the Web of Data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4088</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4088</id><created>2010-06-21</created><updated>2012-09-07</updated><authors><author><keyname>Tang</keyname><forenames>Gongguo</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>The Stability of Low-Rank Matrix Reconstruction: a Constrained Singular
  Value View</title><categories>cs.IT math.IT</categories><comments>IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stability of low-rank matrix reconstruction with respect to noise is
investigated in this paper. The $\ell_*$-constrained minimal singular value
($\ell_*$-CMSV) of the measurement operator is shown to determine the recovery
performance of nuclear norm minimization based algorithms. Compared with the
stability results using the matrix restricted isometry constant, the
performance bounds established using $\ell_*$-CMSV are more concise, and their
derivations are less complex. Isotropic and subgaussian measurement operators
are shown to have $\ell_*$-CMSVs bounded away from zero with high probability,
as long as the number of measurements is relatively large. The $\ell_*$-CMSV
for correlated Gaussian operators are also analyzed and used to illustrate the
advantage of $\ell_*$-CMSV compared with the matrix restricted isometry
constant. We also provide a fixed point characterization of $\ell_*$-CMSV that
is potentially useful for its computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4093</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4093</id><created>2010-06-21</created><authors><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Dynamic Range Reporting in External Memory</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a dynamic external memory data structure that
supports range reporting queries in three dimensions in $O(\log_B^2 N +
\frac{k}{B})$ I/O operations, where $k$ is the number of points in the answer
and $B$ is the block size. This is the first dynamic data structure that
answers three-dimensional range reporting queries in $\log_B^{O(1)} N +
O(\frac{k}{B})$ I/Os.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4104</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4104</id><created>2010-06-21</created><updated>2010-06-24</updated><authors><author><keyname>Domaratzki</keyname><forenames>Michael</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>Abelian Primitive Words</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate Abelian primitive words, which are words that are not Abelian
powers. We show that unlike classical primitive words, the set of Abelian
primitive words is not context-free. We can determine whether a word is Abelian
primitive in linear time. Also different from classical primitive words, we
find that a word may have more than one Abelian root. We also consider
enumeration problems and the relation to the theory of codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4114</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4114</id><created>2010-06-21</created><updated>2011-10-09</updated><authors><author><keyname>Liang</keyname><forenames>Wang</forenames></author><author><keyname>Bo</keyname><forenames>Fang</forenames></author></authors><title>How to build a DNA search engine like Google?</title><categories>q-bio.GN cs.ET cs.IR</categories><comments>5 pages,2 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper proposed a new method to build the large scale DNA sequences
search system based on web search engine technology. We give a very brief
introduction for the methods used in search engine first. Then how to build a
DNA search system like Google is illustrated in detail. Since there is no local
alignment process, this system is able to provide the ms level search services
for billions of DNA sequences in a typical server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4136</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4136</id><created>2010-06-21</created><authors><author><keyname>Cicalese</keyname><forenames>Ferdinando</forenames></author><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Laber</keyname><forenames>Eduardo</forenames></author><author><keyname>Milanic</keyname><forenames>Martin</forenames></author></authors><title>Competitive Boolean Function Evaluation: Beyond Monotonicity, and the
  Symmetric Case</title><categories>cs.DS</categories><comments>15 pages, 1 figure, to appear in Discrete Applied Mathematics</comments><journal-ref>Discrete Applied Mathematics 159 (2011) 1070--1078</journal-ref><doi>10.1016/j.dam.2010.05.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the extremal competitive ratio of Boolean function evaluation. We
provide the first non-trivial lower and upper bounds for classes of Boolean
functions which are not included in the class of monotone Boolean functions.
For the particular case of symmetric functions our bounds are matching and we
exactly characterize the best possible competitiveness achievable by a
deterministic algorithm. Our upper bound is obtained by a simple polynomial
time algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4147</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4147</id><created>2010-06-21</created><updated>2011-01-27</updated><authors><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author><author><keyname>Dickson</keyname><forenames>Neil G.</forenames></author><author><keyname>Hamze</keyname><forenames>Firas</forenames></author><author><keyname>Amin</keyname><forenames>M. H. S.</forenames></author><author><keyname>Drew-Brook</keyname><forenames>Marshall</forenames></author><author><keyname>Chudak</keyname><forenames>Fabian A.</forenames></author><author><keyname>Bunyk</keyname><forenames>Paul I.</forenames></author><author><keyname>Macready</keyname><forenames>William G.</forenames></author><author><keyname>Rose</keyname><forenames>Geordie</forenames></author></authors><title>Investigating the Performance of an Adiabatic Quantum Optimization
  Processor</title><categories>quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adiabatic quantum optimization offers a new method for solving hard
optimization problems. In this paper we calculate median adiabatic times (in
seconds) determined by the minimum gap during the adiabatic quantum
optimization for an NP-hard Ising spin glass instance class with up to 128
binary variables. Using parameters obtained from a realistic superconducting
adiabatic quantum processor, we extract the minimum gap and matrix elements
using high performance Quantum Monte Carlo simulations on a large-scale
Internet-based computing platform. We compare the median adiabatic times with
the median running times of two classical solvers and find that, for the
considered problem sizes, the adiabatic times for the simulated processor
architecture are about 4 and 6 orders of magnitude shorter than the two
classical solvers' times. This shows that if the adiabatic time scale were to
determine the computation time, adiabatic quantum optimization would be
significantly superior to those classical solvers for median spin glass
problems of at least up to 128 qubits. We also discuss important additional
constraints that affect the performance of a realistic system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4173</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4173</id><created>2010-06-21</created><updated>2011-02-22</updated><authors><author><keyname>Amossen</keyname><forenames>Rasmus Resen</forenames></author><author><keyname>Campagna</keyname><forenames>Andrea</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>Better size estimation for sparse matrix products</title><categories>cs.DS cs.DB</categories><comments>Corrected a number of mistakes and typos in the first version (also
  present in the version published at RANDOM 2010). Most importantly, the lower
  bound on the error epsilon is now a function of z rather than n</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of doing fast and reliable estimation of the number
of non-zero entries in a sparse boolean matrix product. This problem has
applications in databases and computer algebra. Let n denote the total number
of non-zero entries in the input matrices. We show how to compute a 1 +-
epsilon approximation (with small probability of error) in expected time O(n)
for any epsilon &gt; 4/\sqrt[4]{z}. The previously best estimation algorithm, due
to Cohen (JCSS 1997), uses time O(n/epsilon^2). We also present a variant using
O(sort(n)) I/Os in expectation in the cache-oblivious model. In contrast to
these results, the currently best algorithms for computing a sparse boolean
matrix product use time omega(n^{4/3}) (resp. omega(n^{4/3}/B) I/Os), even if
the result matrix has only z=O(n) nonzero entries. Our algorithm combines the
size estimation technique of Bar-Yossef et al. (RANDOM 2002) with a particular
class of pairwise independent hash functions that allows the sketch of a set of
the form A x C to be computed in expected time O(|A|+|C|) and O(sort(|A|+|C|))
I/Os. We then describe how sampling can be used to maintain (independent)
sketches of matrices that allow estimation to be performed in time o(n) if z is
sufficiently large. This gives a simpler alternative to the sketching technique
of Ganguly et al. (PODS 2005), and matches a space lower bound shown in that
paper. Finally, we present experiments on real-world data sets that show the
accuracy of both our methods to be significantly better than the worst-case
analysis predicts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4175</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4175</id><created>2010-06-21</created><authors><author><keyname>El-Zehiry</keyname><forenames>Noha</forenames></author><author><keyname>Grady</keyname><forenames>Leo</forenames></author></authors><title>Optimization of Weighted Curvature for Image Segmentation</title><categories>cs.CV</categories><comments>15 pages , 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimization of boundary curvature is a classic regularization technique for
image segmentation in the presence of noisy image data. Techniques for
minimizing curvature have historically been derived from descent methods which
could be trapped in a local minimum and therefore required a good
initialization. Recently, combinatorial optimization techniques have been
applied to the optimization of curvature which provide a solution that achieves
nearly a global optimum. However, when applied to image segmentation these
methods required a meaningful data term. Unfortunately, for many images,
particularly medical images, it is difficult to find a meaningful data term.
Therefore, we propose to remove the data term completely and instead weight the
curvature locally, while still achieving a global optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4225</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4225</id><created>2010-06-22</created><updated>2010-08-09</updated><authors><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author></authors><title>Optimal Spectrum Sharing in MIMO Cognitive Radio Networks via
  Semidefinite Programming</title><categories>cs.NI</categories><comments>12 pages 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the optimal secondary-link beamforming pattern that
balances between the SU's throughput and the interference it causes to PUs in
MIMO cognitive radio networks. In particular, we aim to maximize the throughput
of the SU, while keeping the interference temperature at the primary receivers
below a certain threshold.
  Unlike traditional MIMO systems, SUs may not have the luxury of knowing the
channel state information (CSI) on the links to PUs. This presents a key
challenge for a secondary transmitter to steer interference away from primary
receivers. In this paper, we consider three scenarios, namely when the
secondary transmitter has complete, partial, or no knowledge about the channels
to the primary receivers. In particular, when complete CSI is not available,
the interference-temperature constraints are to be satisfied with high
probability, thus resulting in chance constraints that are typically hard to
deal with. Our contribution is fourfold. First, by analyzing the distributional
characteristics of MIMO channels, we propose a unified homogeneous QCQP
formulation that can be applied to all three scenarios. The homogeneous QCQP
formulation, though non-convex, is amenable to semidefinite programming (SDP)
relaxation methods. Secondly, we show that the SDP relaxation admits no gap
when the number of primary links is no larger than two. Thirdly, we propose a
randomized polynomial-time algorithm for constructing a near-optimal solution
to the QCQP problem when there are more than two primary links. Finally, we
show that when the secondary transmitter has no CSI on the links to primary
receivers, the optimal solution to the QCQP problem can be found by a simple
matrix eigenvalue-eigenvector computation, which can be done much more
efficiently than solving the QCQP directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4228</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4228</id><created>2010-06-22</created><authors><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Chen</keyname><forenames>Darui</forenames></author></authors><title>Sustainable Throughput of Wireless LANs with Multi-Packet Reception
  Capability under Bounded Delay-Moment Requirements</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid proliferation of broadband wireless services, it is of
paramount importance to understand how fast data can be sent through a wireless
local area network (WLAN). Thanks to a large body of research following the
seminal work of Bianchi, WLAN throughput under saturated traffic condition has
been well understood. By contrast, prior investigations on throughput
performance under unsaturated traffic condition was largely based on
phenomenological observations, which lead to a common misconception that WLAN
can support a traffic load as high as saturation throughput, if not higher,
under non-saturation condition. In this paper, we show through rigorous
analysis that this misconception may result in unacceptable quality of service:
mean packet delay and delay jitter may approach infinity even when the traffic
load is far below the saturation throughput. Hence, saturation throughput is
not a sound measure of WLAN capacity under non-saturation condition. To bridge
the gap, we define safe-bounded-mean-delay (SBMD) throughput and
safe-bounded-delay-jitter (SBDJ) throughput that reflect the actual network
capacity users can enjoy when they require finite mean delay and delay jitter,
respectively.
  Our earlier work proved that in a WLAN with multi-packet reception (MPR)
capability, saturation throughput scales super-linearly with the MPR capability
of the network. This paper extends the investigation to the non-saturation case
and shows that super-linear scaling also holds for SBMD and SBDJ throughputs.
Our results here complete the demonstration of MPR as a powerful
capacity-enhancement technique for WLAN under both saturation and
non-saturation conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4248</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4248</id><created>2010-06-22</created><authors><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author></authors><title>Multi-Round Contention in Wireless LANs with Multipacket Reception</title><categories>cs.NI</categories><journal-ref>Y. J. Zhang, &quot;Multi-round contention in wireless LANs with
  multipacket reception,&quot; IEEE Transactions on wireless communications, vol. 9,
  no. 4, pp. 1503-1513, April 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-packet reception (MPR) has been recognized as a powerful
capacity-enhancement technique for random-access wireless local area networks
(WLANs). As is common with all random access protocols, the wireless channel is
often under-utilized in MPR WLANs. In this paper, we propose a novel
multi-round contention random-access protocol to address this problem. This
work complements the existing random-access methods that are based on
single-round contention. In the proposed scheme, stations are given multiple
chances to contend for the channel until there are a sufficient number of
``winning&quot; stations that can share the MPR channel for data packet
transmission. The key issue here is the identification of the optimal time to
stop the contention process and start data transmission. The solution
corresponds to finding a desired tradeoff between channel utilization and
contention overhead. In this paper, we conduct a rigorous analysis to
characterize the optimal strategy using the theory of optimal stopping. An
interesting result is that the optimal stopping strategy is a simple
threshold-based rule, which stops the contention process as soon as the total
number of winning stations exceeds a certain threshold. Compared with the
conventional single-round contention protocol, the multi-round contention
scheme significantly enhances channel utilization when the MPR capability of
the channel is small to medium. Meanwhile, the scheme automatically falls back
to single-round contention when the MPR capability is very large, in which case
the throughput penalty due to random access is already small even with
single-round contention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4255</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4255</id><created>2010-06-22</created><authors><author><keyname>Sasoglu</keyname><forenames>Eren</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund</forenames></author></authors><title>Polar codes for the two-user multiple-access channel</title><categories>cs.IT math.IT</categories><comments>12 pages. Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arikan's polar coding method is extended to two-user multiple-access
channels. It is shown that if the two users of the channel use the Arikan
construction, the resulting channels will polarize to one of five possible
extremals, on each of which uncoded transmission is optimal. The sum rate
achieved by this coding technique is the one that correponds to uniform input
distributions. The encoding and decoding complexities and the error performance
of these codes are as in the single-user case: $O(n\log n)$ for encoding and
decoding, and $o(\exp(-n^{1/2-\epsilon}))$ for block error probability, where
$n$ is the block length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4270</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4270</id><created>2010-06-22</created><updated>2010-09-20</updated><authors><author><keyname>Zhirov</keyname><forenames>A. O.</forenames></author><author><keyname>Zhirov</keyname><forenames>O. V.</forenames></author><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames></author></authors><title>Two-dimensional ranking of Wikipedia articles</title><categories>cs.IR physics.soc-ph</categories><comments>RevTex 9 pages, data, discussion added, more data at
  http://www.quantware.ups-tlse.fr/QWLIB/2drankwikipedia/</comments><journal-ref>Eur. Phys. J. B v.77, p.523 (2010)</journal-ref><doi>10.1140/epjb/e2010-10500-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Library of Babel, described by Jorge Luis Borges, stores an enormous
amount of information. The Library exists {\it ab aeterno}. Wikipedia, a free
online encyclopaedia, becomes a modern analogue of such a Library. Information
retrieval and ranking of Wikipedia articles become the challenge of modern
society. While PageRank highlights very well known nodes with many ingoing
links, CheiRank highlights very communicative nodes with many outgoing links.
In this way the ranking becomes two-dimensional. Using CheiRank and PageRank we
analyze the properties of two-dimensional ranking of all Wikipedia English
articles and show that it gives their reliable classification with rich and
nontrivial features. Detailed studies are done for countries, universities,
personalities, physicists, chess players, Dow-Jones companies and other
categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4271</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4271</id><created>2010-06-22</created><authors><author><keyname>Sonnenbichler</keyname><forenames>Andreas C.</forenames></author></authors><title>A Community Membership Life Cycle Model</title><categories>cs.CY cs.OH</categories><comments>Presented at the International Network For Social Network Analysis
  (INSNA): Sunbelt Conference 2009, San Diego, California, USA. 9 pages, 6
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web 2.0 is transforming the internet: Information consumers become
information producers and consumers at the same time. In virtual places like
Facebook, Youtube, discussion boards and weblogs diversificated topics, groups
and issues are propagated and discussed. Today an internet user is a member of
lots of communities at different virtual places. &quot;Real life&quot; group membership
and group behavior has been analyzed in science intensively in the last
decades. Most interestingly, to our knowledge, user roles and behavior have not
been adapted to the modern internet. In this work, we give a short overview of
traditional community roles. We adapt those models and apply them to virtual
online communities. We suggest a community membership life cycle model
describing roles a user can take during his membership in a community. Our
model is systematic and generic; it can be adapted to concrete communities in
the web. The knowledge of a community's life cycle allows influencing the group
structure: Stage transitions can be supported or harmed, e.g. to strengthen the
binding of a user to a site and keep communities alive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4278</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4278</id><created>2010-06-22</created><updated>2011-08-02</updated><authors><author><keyname>Medjahdi</keyname><forenames>Yahia</forenames></author><author><keyname>Terr&#xe9;</keyname><forenames>Michel</forenames></author><author><keyname>Ruyet</keyname><forenames>Didier Le</forenames></author><author><keyname>Roviras</keyname><forenames>Daniel</forenames></author></authors><title>A New Model for Interference Analysis in Asynchronous Multi-Carrier
  Transmission</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the authors. The paper will be
  improved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference at the radio receiver is a key source of degradation in quality
of service of wireless communication systems. This paper presents a unified
framework for OFDM/FBMC interference characterization and analysis in
asynchronous environment. Multi-user interference is caused by the timing
synchronization errors which lead to the destruction of the orthogonality
between subcarriers. In this paper, we develop a theoretical analysis of the
asynchronous interference considering the multi-path effects on the
interference signal. We further propose an accurate model for interference that
provides a useful computational tool in order to evaluate the performance of an
OFDM/FBMC system in a frequency selective fading environment. Finally,
simulation results confirmed the accuracy of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4288</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4288</id><created>2010-06-22</created><authors><author><keyname>F&#xfa;ster-Sabater</keyname><forenames>Amparo</forenames></author><author><keyname>Guill&#xe9;n</keyname><forenames>J. M.</forenames></author></authors><title>Characterisation of observability and controllability for nonuniformly
  sampled discrete systems</title><categories>cs.DM</categories><comments>13 pages; 2 figures</comments><msc-class>93C55, 93B10</msc-class><acm-class>F.1.1</acm-class><journal-ref>IEE Proceedings, Vol. 135, Pt D, No. 4, pp. 248-252, July 1988</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A joint characterisation of the observability and controllability of a
particular kind of discrete system has been developed. The key idea of the
procedure can be reduced to a correct choice of the sampling sequence. This
freedom, owing to the arbitrary choice of the sampling instants, is used to
improve the sensitivity of system observability and controllability, by
exploiting an adequate geometric structure. Some qualitative examples are
presented for illustrative purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4304</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4304</id><created>2010-06-22</created><authors><author><keyname>Alba-Castro</keyname><forenames>Mauricio</forenames><affiliation>ELP-DSIC, U. Polit&#xe9;cnica de Valencia, Spain. alpuente,sescobar@dsic.upv.es</affiliation></author><author><keyname>Alpuente</keyname><forenames>Mar&#xed;a</forenames><affiliation>ELP-DSIC, U. Polit&#xe9;cnica de Valencia, Spain. alpuente,sescobar@dsic.upv.es</affiliation></author><author><keyname>Escobar</keyname><forenames>Santiago</forenames><affiliation>ELP-DSIC, U. Polit&#xe9;cnica de Valencia, Spain. alpuente,sescobar@dsic.upv.es</affiliation></author></authors><title>Abstract Certification of Global Non-Interference in Rewriting Logic</title><categories>cs.CR cs.LO cs.PL</categories><comments>26 pages. ACM class (full): D.2.4 [Software Engineering]:
  Software/Program Verification---Formal Methods; F.3.2 [Logics and Meaning of
  Programs]: Semantics of Programming Languages---Program Analysis</comments><acm-class>D.2.4; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-interference is a semantic program property that assigns confidentiality
levels to data objects and prevents illicit information flows from occurring
from high to low security levels. In this paper, we present a novel security
model for global non-interference which approximates non-interference as a
safety property. We also propose a certification technique for global
non-interference of complete Java classes based on rewriting logic, a very
general logical and semantic framework that is efficiently implemented in the
high-level programming language Maude. Starting from an existing Java semantics
specification written in Maude, we develop an extended, information-flow Java
semantics that allows us to correctly observe global non-interference policies.
In order to achieve a finite state transition system, we develop an abstract
Java semantics that we use for secure and effective non-interference Java
analysis. The analysis produces certificates that are independently checkable
and are small enough to be used in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4326</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4326</id><created>2010-06-22</created><authors><author><keyname>Yanmaz</keyname><forenames>Evsen</forenames></author><author><keyname>Guclu</keyname><forenames>Hasan</forenames></author></authors><title>Stationary and Mobile Target Detection using Mobile Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>7 pages, 12 figures, appeared in INFOCOM 2010</comments><journal-ref>Proc. INFOCOM IEEE Conference on Computer Communications 2010, p.
  1</journal-ref><doi>10.1109/INFCOMW.2010.5466620</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the target detection and tracking problem in mobile
sensor networks, where the performance metrics of interest are probability of
detection and tracking coverage, when the target can be stationary or mobile
and its duration is finite. We propose a physical coverage-based mobility
model, where the mobile sensor nodes move such that the overlap between the
covered areas by different mobile nodes is small. It is shown that for
stationary target scenario the proposed mobility model can achieve a desired
detection probability with a significantly lower number of mobile nodes
especially when the detection requirements are highly stringent. Similarly,
when the target is mobile the coverage-based mobility model produces a
consistently higher detection probability compared to other models under
investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4330</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4330</id><created>2010-06-22</created><authors><author><keyname>Rulloni</keyname><forenames>Valeria</forenames></author><author><keyname>Bustos</keyname><forenames>Oscar</forenames></author><author><keyname>Flesia</keyname><forenames>Ana Georgina</forenames></author></authors><title>Large gaps imputation in remote sensed imagery of the environment</title><categories>stat.AP cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imputation of missing data in large regions of satellite imagery is necessary
when the acquired image has been damaged by shadows due to clouds, or
information gaps produced by sensor failure.
  The general approach for imputation of missing data, that could not be
considered missed at random, suggests the use of other available data. Previous
work, like local linear histogram matching, take advantage of a co-registered
older image obtained by the same sensor, yielding good results in filling
homogeneous regions, but poor results if the scenes being combined have radical
differences in target radiance due, for example, to the presence of sun glint
or snow.
  This study proposes three different alternatives for filling the data gaps.
The first two involves merging radiometric information from a lower resolution
image acquired at the same time, in the Fourier domain (Method A), and using
linear regression (Method B). The third method consider segmentation as the
main target of processing, and propose a method to fill the gaps in the map of
classes, avoiding direct imputation (Method C).
  All the methods were compared by means of a large simulation study,
evaluating performance with a multivariate response vector with four measures:
Q, RMSE, Kappa and Overall Accuracy coefficients. Difference in performance
were tested with a MANOVA mixed model design with two main effects, imputation
method and type of lower resolution extra data, and a blocking third factor
with a nested sub-factor, introduced by the real Landsat image and the
sub-images that were used. Method B proved to be the best for all criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4333</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4333</id><created>2010-06-22</created><updated>2010-07-12</updated><authors><author><keyname>Gu</keyname><forenames>Weiwen</forenames></author></authors><title>Decomposition Algorithm for Median Graph of Triangulation of a Bordered
  2D Surface</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops an algorithm that identifies and decomposes a median
graph of a triangulation of a 2-dimensional (2D) oriented bordered surface and
in addition restores all corresponding triangulation whenever they exist. The
algorithm is based on the consecutive simplification of the given graph by
reducing degrees of its nodes. From the paper \cite{FST1}, it is known that
such graphs can not have nodes of degrees above 8. Neighborhood of nodes of
degrees 8,7,6,5, and 4 are consecutively simplified. Then, a criterion is
provided to identify median graphs with nodes of degrees at most 3. As a
byproduct, we produce an algorithm that is more effective than previous known
to determine quivers of finite mutation type of size greater than 10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4339</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4339</id><created>2010-06-22</created><authors><author><keyname>Bateni</keyname><forenames>MohammadHossein</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author></authors><title>Prize-collecting Network Design on Planar Graphs</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we reduce Prize-Collecting Steiner TSP (PCTSP),
Prize-Collecting Stroll (PCS), Prize-Collecting Steiner Tree (PCST),
Prize-Collecting Steiner Forest (PCSF) and more generally Submodular
Prize-Collecting Steiner Forest (SPCSF) on planar graphs (and more generally
bounded-genus graphs) to the same problems on graphs of bounded treewidth. More
precisely, we show any $\alpha$-approximation algorithm for these problems on
graphs of bounded treewidth gives an $(\alpha + \epsilon)$-approximation
algorithm for these problems on planar graphs (and more generally bounded-genus
graphs), for any constant $\epsilon &gt; 0$. Since PCS, PCTSP, and PCST can be
solved exactly on graphs of bounded treewidth using dynamic programming, we
obtain PTASs for these problems on planar graphs and bounded-genus graphs. In
contrast, we show PCSF is APX-hard to approximate on series-parallel graphs,
which are planar graphs of treewidth at most 2. This result is interesting on
its own because it gives the first provable hardness separation between
prize-collecting and non-prize-collecting (regular) versions of the problems:
regular Steiner Forest is known to be polynomially solvable on series-parallel
graphs and admits a PTAS on graphs of bounded treewidth. An analogous hardness
result can be shown for Euclidian PCSF. This ends the common belief that
prize-collecting variants should not add any new hardness to the problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4342</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4342</id><created>2010-06-22</created><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author><author><keyname>Pepper</keyname><forenames>Peter</forenames></author><author><keyname>Smith</keyname><forenames>Douglas R.</forenames></author></authors><title>Formal Derivation of Concurrent Garbage Collectors</title><categories>cs.DC cs.LO</categories><comments>38 pages, 21 figures. The short version of this paper appeared in the
  Proceedings of MPC 2010</comments><acm-class>D.3.4; D.4.2; D.1.3; D.2.1; D.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concurrent garbage collectors are notoriously difficult to implement
correctly. Previous approaches to the issue of producing correct collectors
have mainly been based on posit-and-prove verification or on the application of
domain-specific templates and transformations. We show how to derive the upper
reaches of a family of concurrent garbage collectors by refinement from a
formal specification, emphasizing the application of domain-independent design
theories and transformations. A key contribution is an extension to the
classical lattice-theoretic fixpoint theorems to account for the dynamics of
concurrent mutation and collection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4349</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4349</id><created>2010-06-22</created><updated>2011-10-12</updated><authors><author><keyname>Civril</keyname><forenames>Ali</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Exponential Inapproximability of Selecting a Maximum Volume Sub-matrix</title><categories>cs.CC cs.DS</categories><comments>14 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a matrix $A \in \mathbb{R}^{m \times n}$ ($n$ vectors in $m$
dimensions), and a positive integer $k &lt; n$, we consider the problem of
selecting $k$ column vectors from $A$ such that the volume of the
parallelepiped they define is maximum over all possible choices. We prove that
there exists $\delta&lt;1$ and $c&gt;0$ such that this problem is not approximable
within $2^{-ck}$ for $k = \delta n$, unless $P=NP$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4357</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4357</id><created>2010-06-22</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Ene</keyname><forenames>Alina</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author></authors><title>Prize-Collecting Steiner Tree and Forest in Planar Graphs</title><categories>cs.DS</categories><comments>24 pages</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain polynomial-time approximation-preserving reductions (up to a factor
of 1 + \epsilon) from the prize-collecting Steiner tree and prize-collecting
Steiner forest problems in planar graphs to the corresponding problems in
graphs of bounded treewidth. We also give an exact algorithm for the
prize-collecting Steiner tree problem that runs in polynomial time for graphs
of bounded treewidth. This, combined with our reductions, yields a PTAS for the
prize-collecting Steiner tree problem in planar graphs and generalizes the PTAS
of Borradaile, Klein and Mathieu for the Steiner tree problem in planar graphs.
Our results build upon the ideas of Borradaile, Klein and Mathieu and the work
of Bateni, Hajiaghayi and Marx on a PTAS for the Steiner forest problem in
planar graphs. Our main technical result is on the properties of primal-dual
algorithms for Steiner tree and forest problems in general graphs when they are
run with scaled up penalties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4358</identifier>
 <datestamp>2012-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4358</id><created>2010-06-22</created><updated>2012-04-11</updated><authors><author><keyname>Agrawal</keyname><forenames>Mayur</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Venkataramanan</forenames></author></authors><title>Combining Channel Output Feedback and CSI Feedback for MIMO Wireless
  Systems</title><categories>cs.IT math.IT</categories><comments>The paper has been withdrawn and merged with arXiv:1104.2861 to avoid
  redundancy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of channel output feedback to improve the reliability of fading
channels has received scant attention in the literature. In most work on
feedback for fading channels, only channel state information (CSI) feedback has
been exploited for coding at the transmitter. In this work, the design of a
coding scheme for multiple-input multiple-output (MIMO) fading systems with
channel output and channel state feedback at the transmitter is considered.
Under the assumption of additive white Gaussian noise and an independent and
identically distributed fading process, a simple linear coding strategy that
achieves any rate up to capacity is proposed. The framework assumes perfect CSI
at the transmitter and receiver. This simple linear processing scheme can
provide a doubly exponential probability of error decay with blocklength for
all rates less than capacity. Remarkably, this encoding scheme actually
consists of two separate encoding blocks: one that adapts to the current CSI
and one that adapts to the previous channel output feedback. This scheme is
extended to the case when the CSI is quantized at the receiver and conveyed to
the transmitter over a limited rate feedback channel; for multiple-input
single-output (MISO) fading systems it is shown the doubly exponential
probability of error decay is achieved as the blocklength increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4386</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4386</id><created>2010-06-22</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Collaborative Relay Beamforming for Secrecy</title><categories>cs.IT math.IT</categories><comments>The material in this paper was submitted in part at arXiv:0910.4132</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, collaborative use of relays to form a beamforming system and
provide physical-layer security is investigated. In particular,
decode-and-forward (DF) and amplify-and-forward (AF) relay beamforming designs
under total and individual relay power constraints are studied with the goal of
maximizing the secrecy rates when perfect channel state information (CSI) is
available. In the DF scheme, the total power constraint leads to a closed-form
solution, and in this case, the optimal beamforming structure is identified in
the low and high signal-to-noise ratio (SNR) regimes. The beamforming design
under individual relay power constraints is formulated as an optimization
problem which is shown to be easily solved using two different approaches,
namely semidefinite programming and second-order cone programming. A simplified
and suboptimal technique which reduces the computation complexity under
individual power constraints is also presented. In the AF scheme, not having
analytical solutions for the optimal beamforming design under both total and
individual power constraints, an iterative algorithm is proposed to numerically
obtain the optimal beamforming structure and maximize the secrecy rates.
Finally, robust beamforming designs in the presence of imperfect CSI are
investigated for DF-based relay beamforming, and optimization frameworks are
provided
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4387</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4387</id><created>2010-06-22</created><authors><author><keyname>Kompalli</keyname><forenames>Sayee C.</forenames></author><author><keyname>Mazumdar</keyname><forenames>Ravi R.</forenames></author></authors><title>A note on the stability of multiclass Markovian queueing networks</title><categories>cs.NI</categories><comments>Submitted to Journal of Applied Probability</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that in a multiclass Markovian network with unit rate
servers, the condition that the average load $\rho$ at every server is less
than unity is indeed sufficient for the stability or positive recurrence for
\emph{any} work conserving scheduling policy and \emph{class-independent}
routing. We use a variation of the positive recurrence criterion for
multidimensional discrete-time Markov chains over countable state spaces due to
Rosberg (JAP, Vol.~17, No.~3, 1980) and a monotonicity argument to establish
this assertion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4388</identifier>
 <datestamp>2014-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4388</id><created>2010-06-22</created><updated>2014-11-18</updated><authors><author><keyname>Crosson</keyname><forenames>Elizabeth</forenames></author><author><keyname>Bacon</keyname><forenames>Dave</forenames></author><author><keyname>Brown</keyname><forenames>Kenneth R.</forenames></author></authors><title>Making Classical Ground State Spin Computing Fault-Tolerant</title><categories>cond-mat.stat-mech cs.CC quant-ph</categories><comments>24 pages, 1 figure</comments><journal-ref>Physical Review E, 82(3), 031106 (2010)</journal-ref><doi>10.1103/PhysRevE.82.031106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a model of classical deterministic computing in which the ground
state of the classical system is a spatial history of the computation. This
model is relevant to quantum dot cellular automata as well as to recent
universal adiabatic quantum computing constructions. In its most primitive
form, systems constructed in this model cannot compute in an error free manner
when working at non-zero temperature. However, by exploiting a mapping between
the partition function for this model and probabilistic classical circuits we
are able to show that it is possible to make this model effectively error free.
We achieve this by using techniques in fault-tolerant classical computing and
the result is that the system can compute effectively error free if the
temperature is below a critical temperature. We further link this model to
computational complexity and show that a certain problem concerning finite
temperature classical spin systems is complete for the complexity class
Merlin-Arthur. This provides an interesting connection between the physical
behavior of certain many-body spin systems and computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4396</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4396</id><created>2010-06-22</created><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schudy</keyname><forenames>Warren</forenames></author></authors><title>Faster Algorithms for Feedback Arc Set Tournament, Kemeny Rank
  Aggregation and Betweenness Tournament</title><categories>cs.DS cs.DM</categories><comments>14 pages. Version 1 of arXiv:0911.2214 includes a preliminary version
  of this work; version 2 does not</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study fixed parameter algorithms for three problems: Kemeny rank
aggregation, feedback arc set tournament, and betweenness tournament. For
Kemeny rank aggregation we give an algorithm with runtime O*(2^O(sqrt{OPT})),
where n is the number of candidates, OPT is the cost of the optimal ranking,
and O* hides polynomial factors. This is a dramatic improvement on the
previously best known runtime of O*(2^O(OPT)). For feedback arc set tournament
we give an algorithm with runtime O*(2^O(sqrt{OPT})), an improvement on the
previously best known O*(OPT^O(sqrt{OPT})) (Alon, Lokshtanov and Saurabh 2009).
For betweenness tournament we give an algorithm with runtime
O*(2^O(sqrt{OPT/n})), where n is the number of vertices and OPT is the optimal
cost. This improves on the previously known O*(OPT^O(OPT^{1/3}))$ (Saurabh
2009), especially when OPT is small. Unusually we can solve instances with OPT
as large as n (log n)^2 in polynomial time!
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4406</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4406</id><created>2010-06-22</created><authors><author><keyname>Li</keyname><forenames>William Weiliang</forenames><affiliation>Angela</affiliation></author><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Slow Adaptive OFDMA Systems Through Chance Constrained Programming</title><categories>cs.NI</categories><journal-ref>IEEE Transactions on Signal Processing, July 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive OFDMA has recently been recognized as a promising technique for
providing high spectral efficiency in future broadband wireless systems. The
research over the last decade on adaptive OFDMA systems has focused on adapting
the allocation of radio resources, such as subcarriers and power, to the
instantaneous channel conditions of all users. However, such &quot;fast&quot; adaptation
requires high computational complexity and excessive signaling overhead. This
hinders the deployment of adaptive OFDMA systems worldwide. This paper proposes
a slow adaptive OFDMA scheme, in which the subcarrier allocation is updated on
a much slower timescale than that of the fluctuation of instantaneous channel
conditions. Meanwhile, the data rate requirements of individual users are
accommodated on the fast timescale with high probability, thereby meeting the
requirements except occasional outage. Such an objective has a natural chance
constrained programming formulation, which is known to be intractable. To
circumvent this difficulty, we formulate safe tractable constraints for the
problem based on recent advances in chance constrained programming. We then
develop a polynomial-time algorithm for computing an optimal solution to the
reformulated problem. Our results show that the proposed slow adaptation scheme
drastically reduces both computational cost and control signaling overhead when
compared with the conventional fast adaptive OFDMA. Our work can be viewed as
an initial attempt to apply the chance constrained programming methodology to
wireless system designs. Given that most wireless systems can tolerate an
occasional dip in the quality of service, we hope that the proposed methodology
will find further applications in wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4408</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4408</id><created>2010-06-22</created><authors><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Zheng</keyname><forenames>Pengxuan</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>How Does Multiple-Packet Reception Capability Scale the Performance of
  Wireless Local Area Networks?</title><categories>cs.NI</categories><journal-ref>IEEE Transactions on Mobile Computing, July 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thanks to its simplicity and cost efficiency, wireless local area network
(WLAN) enjoys unique advantages in providing high-speed and low-cost wireless
services in hot spots and indoor environments. Traditional WLAN
medium-access-control (MAC) protocols assume that only one station can transmit
at a time: simultaneous transmissions of more than one station cause the
destruction of all packets involved. By exploiting recent advances in PHY-layer
multiuser detection (MUD) techniques, it is possible for a receiver to receive
multiple packets simultaneously. This paper argues that such multipacket
reception (MPR) capability can greatly enhance the capacity of future WLANs. In
addition, the paper provides the MAC-layer and PHY-layer designs needed to
achieve the improved capacity. First, to demonstrate MPR as a powerful
capacity-enhancement technique, we prove a &quot;super-linearity&quot; result, which
states that the system throughput per unit cost increases as the MPR capability
increases. Second, we show that the commonly deployed binary exponential
backoff (BEB) algorithm in today's WLAN MAC may not be optimal in an MPR
system, and that the optimal backoff factor increases with the MPR capability,
the number of packets that can be received simultaneously. Third, based on the
above insights, we design a joint MAC-PHY layer protocol for an IEEE
802.11-like WLAN that incorporates advanced PHY-layer signal processing
techniques to implement MPR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4425</identifier>
 <datestamp>2011-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4425</id><created>2010-06-23</created><updated>2011-07-13</updated><authors><author><keyname>Andreychenko</keyname><forenames>Aleksandr</forenames></author><author><keyname>Crouzen</keyname><forenames>Pepijn</forenames></author><author><keyname>Mikeev</keyname><forenames>Linar</forenames></author><author><keyname>Wolf</keyname><forenames>Verena</forenames></author></authors><title>On-the-fly Uniformization of Time-Inhomogeneous Infinite Markov
  Population Models</title><categories>math.PR cs.CE cs.NA</categories><proxy>EPTCS</proxy><acm-class>J.3, G.3</acm-class><journal-ref>EPTCS 57, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.57.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an on-the-fly uniformization technique for the analysis
of time-inhomogeneous Markov population models. This technique is applicable to
models with infinite state spaces and unbounded rates, which are, for instance,
encountered in the realm of biochemical reaction networks. To deal with the
infinite state space, we dynamically maintain a finite subset of the states
where most of the probability mass is located. This approach yields an
underapproximation of the original, infinite system. We present experimental
results to show the applicability of our technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4442</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4442</id><created>2010-06-23</created><authors><author><keyname>Kimmig</keyname><forenames>Angelika</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author><author><keyname>De Raedt</keyname><forenames>Luc</forenames></author><author><keyname>Costa</keyname><forenames>V&#xed;tor Santos</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>On the Implementation of the Probabilistic Logic Programming Language
  ProbLog</title><categories>cs.PL cs.LG cs.LO</categories><comments>28 pages; To appear in Theory and Practice of Logic Programming
  (TPLP)</comments><journal-ref>Theory and Practice of Logic Programming, 11, 235-262, 2011</journal-ref><doi>10.1017/S1471068410000566</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past few years have seen a surge of interest in the field of
probabilistic logic learning and statistical relational learning. In this
endeavor, many probabilistic logics have been developed. ProbLog is a recent
probabilistic extension of Prolog motivated by the mining of large biological
networks. In ProbLog, facts can be labeled with probabilities. These facts are
treated as mutually independent random variables that indicate whether these
facts belong to a randomly sampled program. Different kinds of queries can be
posed to ProbLog programs. We introduce algorithms that allow the efficient
execution of these queries, discuss their implementation on top of the
YAP-Prolog system, and evaluate their performance in the context of large
networks of biological entities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4444</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4444</id><created>2010-06-23</created><authors><author><keyname>Osorno</keyname><forenames>Bruno</forenames></author></authors><title>Analysis of Microprocessor Based Protective Re-lay's (MBPR) Differential
  Equation Algorithms</title><categories>cs.OH</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2 No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyses and explains from the systems point of view,
microprocessor based protective relay (MBPR) systems with emphasis on
differential equation algorithms. Presently, the application of protective
relaying in power systems, using MBPR systems, based on the differential
equation algorithm is valued more than the protection relaying based on any
other type of algorithm, because of advantages in accuracy and implementation.
MBPR differential equation approach can tolerate some errors caused by power
system abnormality such as DC offset. This paper shows that the algorithm is a
system description based and it is immune from distortions such as DC-offset.
Differential equation algorithms implemented in MBPR are widely used in the
protection of transmission and distribution lines, transformers, buses, motors,
etc. The parameters from the system, utilized in these algorithms, are obtained
from the power system current i(t) or voltage v(t), which are abnormal values
under fault or distortion situations. So, an error study for the algorithm is
considered necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4458</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4458</id><created>2010-06-23</created><authors><author><keyname>Shrinivaasan</keyname><forenames>Ka.</forenames></author></authors><title>Few Algorithms for ascertaining merit of a document and their
  applications</title><categories>cs.IR</categories><comments>32 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing models for ranking documents(mostly in world wide web) are prestige
based. In this article, three algorithms to objectively judge the merit of a
document are proposed - 1) Citation graph maxflow 2) Recursive Gloss Overlap
based intrinsic merit scoring and 3) Interview algorithm. A short discussion on
generic judgement and its mathematical treatment is presented in introduction
to motivate these algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4474</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4474</id><created>2010-06-23</created><authors><author><keyname>Kohlhase</keyname><forenames>Andrea</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>Lange</keyname><forenames>Christoph</forenames></author></authors><title>sTeX+ - a System for Flexible Formalization of Linked Data</title><categories>cs.SE cs.AI</categories><comments>I-SEMANTICS 2010, September 1-3, 2010, Graz, Austria</comments><msc-class>68T35, 68T30</msc-class><acm-class>H.5.3; H.5.4; I.7.2; F.4.m; H.3.5; D.2.1; D.2.7; I.2.4; K.6.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present the sTeX+ system, a user-driven advancement of sTeX - a semantic
extension of LaTeX that allows for producing high-quality PDF documents for
(proof)reading and printing, as well as semantic XML/OMDoc documents for the
Web or further processing. Originally sTeX had been created as an invasive,
semantic frontend for authoring XML documents. Here, we used sTeX in a Software
Engineering case study as a formalization tool. In order to deal with modular
pre-semantic vocabularies and relations, we upgraded it to sTeX+ in a
participatory design process. We present a tool chain that starts with an sTeX+
editor and ultimately serves the generated documents as XHTML+RDFa Linked Data
via an OMDoc-enabled, versioned XML database. In the final output, all
structural annotations are preserved in order to enable semantic information
retrieval services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4484</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4484</id><created>2010-06-23</created><authors><author><keyname>Martinez-Mateo</keyname><forenames>Jesus</forenames></author><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Martin</keyname><forenames>Vicente</forenames></author></authors><title>Interactive Reconciliation with Low-Density Parity-Check Codes</title><categories>cs.IT math.IT</categories><doi>10.1109/ISTC.2010.5613856</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient information reconciliation is crucial in several scenarios, being
quantum key distribution a remarkable example. However, efficiency is not the
only requirement for determining the quality of the information reconciliation
process. In some of these scenarios we find other relevant parameters such as
the interactivity or the adaptability to different channel statistics. We
propose an interactive protocol for information reconciliation based on
low-density parity-check codes. The coding rate is adapted in real time by
using simultaneously puncturing and shortening strategies, allowing it to cover
a predefined error rate range with just a single code. The efficiency of the
information reconciliation process using the proposed protocol is considerably
better than the efficiency of its non-interactive version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4490</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4490</id><created>2010-06-23</created><authors><author><keyname>Rao</keyname><forenames>Ashwin</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Can Realistic BitTorrent Experiments Be Performed on Clusters?</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>10th IEEE International Conference on Peer-to-Peer Computing (IEEE
  P2P'10), Delft : Netherlands (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network latency and packet loss are considered to be an important requirement
for realistic evaluation of Peer-to-Peer protocols. Dedicated clusters, such as
Grid'5000, do not provide the variety of network latency and packet loss rates
that can be found in the Internet. However, compared to the experiments
performed on testbeds such as PlanetLab, the experiments performed on dedicated
clusters are reproducible, as the computational resources are not shared. In
this paper, we perform experiments to study the impact of network latency and
packet loss on the time required to download a file using BitTorrent. In our
experiments, we observe a less than 15% increase on the time required to
download a file when we increase the round-trip time between any two peers,
from 0 ms to 400 ms, and the packet loss rate, from 0% to 5%. Our main
conclusion is that the underlying network latency and packet loss have a
marginal impact on the time required to download a file using BitTorrent.
Hence, dedicated clusters such as Grid'5000 can be safely used to perform
realistic and reproducible BitTorrent experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4504</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4504</id><created>2010-06-23</created><authors><author><keyname>Walker</keyname><forenames>Scott</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Norcross</keyname><forenames>Stuart</forenames></author></authors><title>Exposing Application Components as Web Services</title><categories>cs.DC</categories><comments>Submitted to SAC05</comments><report-no>University of St Andrews CS/04/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores technology permitting arbitrary application components to
be exposed for remote access from other software. Using this, the application
and its constituent components can be written without concern for its
distribution. Software running in different address spaces, on different
machines, can perform operations on the remotely accessible components. This is
of utility in the creation of distributed applications and in permitting tools
such as debuggers, component browsers, observers or remote probes access to
application components. Current middleware systems do not allow arbitrary
exposure of application components: instead, the programmer is forced to decide
statically which classes of component will support remote accessibility. In the
work described here, arbitrary components of any class can be dynamically
exposed via Web Services. Traditional Web Services are extended with a remote
reference scheme. This extension permits application components to be invoked
using either the traditional pass-by-value semantics supported by Web Services
or pass-by-reference semantics. The latter permits the preservation of local
call semantics across address space boundaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4509</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4509</id><created>2010-06-23</created><authors><author><keyname>Guillaud</keyname><forenames>Maxime</forenames></author></authors><title>Receive Diversity and Ergodic Performance of Interference Alignment on
  the MIMO Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider interference alignment (IA) over K-user Gaussian MIMO
interference channel (MIMO-IC) when the SNR is not asymptotically high. We
introduce a generalization of IA which enables receive diversity inside the
interference-free subspace. We generalize the existence criterion of an IA
solution proposed by Yetis et al. to this case, thereby establishing a
multi-user diversity-multiplexing trade-off (DMT) for the interference channel.
Furthermore, we derive a closed-form tight lower-bound for the ergodic mutual
information achievable using IA over a Gaussian MIMO-IC with Gaussian i.i.d.
channel coefficients at arbitrary SNR, when the transmitted signals are white
inside the subspace defined by IA. Finally, as an application of the previous
results, we compare the performance achievable by IA at various operating
points allowed by the DMT, to a recently introduced distributed method based on
game theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4512</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4512</id><created>2010-06-23</created><authors><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author></authors><title>FORM facts</title><categories>hep-ph cs.SC math-ph math.MP</categories><comments>6 pages. Talk presented at the Loops and Legs 2010 workshop</comments><journal-ref>Nucl.Phys.Proc.Suppl.205-206:104-109,2010</journal-ref><doi>10.1016/j.nuclphysbps.2010.08.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some of the new features of the symbolic manipulation system FORM are
discussed. Then some recent results running its multithreaded version TFORM are
shown. Finally the plans for the future are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4524</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4524</id><created>2010-06-23</created><authors><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author></authors><title>Fundamental Rate-Reliability-Complexity Limits in Outage Limited MIMO
  Communications</title><categories>cs.IT cs.CC math.IT math.ST stat.TH</categories><comments>6 pages, no figures. Slide presentation of partial work at ITA 2010.
  Published at ISIT2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work establishes fundamental limits with respect to rate, reliability and
computational complexity, for a general setting of outage-limited MIMO
communications. In the high-SNR regime, the limits are optimized over all
encoders, all decoders, and all complexity regulating policies. The work then
proceeds to explicitly identify encoder-decoder designs and policies, that meet
this optimal tradeoff. In practice, the limits aim to meaningfully quantify
different pertinent measures, such as the optimal rate-reliability capabilities
per unit complexity and power, the optimal diversity gains per complexity
costs, or the optimal number of numerical operations (i.e., flops) per bit.
Finally the tradeoff's simple nature, renders it useful for insightful
comparison of the rate-reliability-complexity capabilities for different
encoders-decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4535</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4535</id><created>2010-06-23</created><authors><author><keyname>Gelernter</keyname><forenames>Judith</forenames></author><author><keyname>Cao</keyname><forenames>Dong</forenames></author><author><keyname>Carbonell</keyname><forenames>Jaime</forenames></author></authors><title>Studies on Relevance, Ranking and Results Display</title><categories>cs.IR</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2 No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study considers the extent to which users with the same query agree as
to what is relevant, and how what is considered relevant may translate into a
retrieval algorithm and results display. To combine user perceptions of
relevance with algorithm rank and to present results, we created a prototype
digital library of scholarly literature. We confine studies to one population
of scientists (paleontologists), one domain of scholarly scientific articles
(paleo-related), and a prototype system (PaleoLit) that we built for the
purpose. Based on the principle that users do not pre-suppose answers to a
given query but that they will recognize what they want when they see it, our
system uses a rules-based algorithm to cluster results into fuzzy categories
with three relevance levels. Our system matches at least 1/3 of our
participants' relevancy ratings 87% of the time. Our subsequent usability study
found that participants trusted our uncertainty labels but did not value our
color-coded horizontal results layout above a standard retrieval list. We posit
that users make such judgments in limited time, and that time optimization per
task might help explain some of our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4536</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4536</id><created>2010-06-23</created><authors><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Leighton</keyname><forenames>Tom</forenames></author><author><keyname>Li</keyname><forenames>Shi</forenames></author><author><keyname>Moitra</keyname><forenames>Ankur</forenames></author></authors><title>Vertex Sparsifiers and Abstract Rounding Algorithms</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of vertex sparsification is introduced in \cite{M}, where it was
shown that for any graph $G = (V, E)$ and a subset of $k$ terminals $K \subset
V$, there is a polynomial time algorithm to construct a graph $H = (K, E_H)$ on
just the terminal set so that simultaneously for all cuts $(A, K-A)$, the value
of the minimum cut in $G$ separating $A$ from $K -A$ is approximately the same
as the value of the corresponding cut in $H$.
  We give the first super-constant lower bounds for how well a cut-sparsifier
$H$ can simultaneously approximate all minimum cuts in $G$. We prove a lower
bound of $\Omega(\log^{1/4} k)$ -- this is polynomially-related to the known
upper bound of $O(\log k/\log \log k)$. This is an exponential improvement on
the $\Omega(\log \log k)$ bound given in \cite{LM} which in fact was for a
stronger vertex sparsification guarantee, and did not apply to cut sparsifiers.
  Despite this negative result, we show that for many natural problems, we do
not need to incur a multiplicative penalty for our reduction. We obtain optimal
$O(\log k)$-competitive Steiner oblivious routing schemes, which generalize the
results in \cite{R}. We also demonstrate that for a wide range of graph packing
problems (which includes maximum concurrent flow, maximum multiflow and
multicast routing, among others, as a special case), the integrality gap of the
linear program is always at most $O(\log k)$ times the integrality gap
restricted to trees. This result helps to explain the ubiquity of the $O(\log
k)$ guarantees for such problems.
  Lastly, we use our ideas to give an efficient construction for
vertex-sparsifiers that match the current best existential results -- this was
previously open. Our algorithm makes novel use of Earth-mover constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4537</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4537</id><created>2010-06-23</created><authors><author><keyname>Deenadayalan</keyname><forenames>T.</forenames></author><author><keyname>Kavitha</keyname><forenames>V.</forenames></author><author><keyname>Rajarajeswari</keyname><forenames>S.</forenames></author></authors><title>Examining Web Application by Clumping and Orienting User Session Data</title><categories>cs.NI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing demand for reliable Web applications gives a central role to
Web testing. Most of the existing works are focused on the definition of novel
testing techniques, specifically tailored to the Web. However, no attempt was
carried out so far to understand the specific nature of Web faults. This paper
presents a user session based testing technique that clusters user sessions
based on the service profile and selects a set of representative user sessions
from each cluster and tailored by augmentation with additional requests to
cover the dependence relationships between web pages. The created suite not
only can significantly reduce the size of the collected user sessions, also
viable to exercise fault sensitive paths. The results demonstrate that our
approach consistently detected the majority of known faults using a relatively
small number of test cases and will be a powerful system when more and more
user sessions are being clustered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4538</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4538</id><created>2010-06-23</created><authors><author><keyname>Tiwari</keyname><forenames>Vivek</forenames></author><author><keyname>Shailendra</keyname><forenames>G.</forenames></author><author><keyname>Tiwari</keyname><forenames>Renu</forenames></author><author><keyname>Kirar</keyname><forenames>Malam</forenames></author></authors><title>Computational Analysis of .NET Remoting and Mobile agent in Distributed
  Environment</title><categories>cs.NI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile agent is a program that is not bound to the system on which it began
execution, but rather travels amongst the hosts in the network with its code
and current execution state (i.e. Distributed Environment).The implementation
of distributed applications can be based on a multiplicity of technologies,
e.g. plain sockets, Remote Procedure Call (RPC), Remote Method Invocation
(RMI), Java Message Service (JMS), .NET Remoting, or Web Services. These
technologies differ widely in complexity, interoperability, standardization,
and ease of use. The Mobile Agent technology is emerging as an alternative to
build a smart generation of highly distributed systems. In this work, we
investigate the performance aspect of agent-based technologies for information
retrieval. We present a comparative performance evaluation model of Mobile
Agents versus .Net remoting by means of an analytical approach. A quantitative
measurements are performed to compare .Net remoting and mobile agents using
communication time, code size (agent code), Data size, number of node as
performance parameters in this research work. The results depict that Mobile
Agent paradigm offers a superior performance compared to .Net remoting
paradigm, offers fast computational speed; procure lower invocation cost by
making local invocations instead of remote invocations over the network,
thereby reducing network bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4539</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4539</id><created>2010-06-23</created><authors><author><keyname>Ramlan</keyname><forenames>Siti Azura</forenames></author><author><keyname>Ismail</keyname><forenames>Nor Azman</forenames></author></authors><title>A Study of User's Performance and Satisfaction on the Web Based Photo
  Annotation with Speech Interaction</title><categories>cs.HC</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports on empirical evaluation study of users' performance and
satisfaction with prototype of Web Based speech photo annotation with speech
interaction. Participants involved consist of Johor Bahru citizens from various
background. They have completed two parts of annotation task; part A involving
PhotoASys; photo annotation system with proposed speech interaction and part B
involving Microsoft Microsoft Vista Speech Interaction style. They have
completed eight tasks for each part including system login and selection of
album and photos. Users' performance was recorded using computer screen
recording software. Data were captured on the task completion time and
subjective satisfaction. Participants need to complete a questionnaire on the
subjective satisfaction when the task was completed. The performance data show
the comparison between proposed speech interaction and Microsoft Vista Speech
interaction applied in photo annotation system, PhotoASys. On average, the
reduction in annotation performance time due to using proposed speech
interaction style was 64.72% rather than using speech interaction Microsoft
Vista style. Data analysis were showed in different statistical significant in
annotation performance and subjective satisfaction for both styles of
interaction. These results could be used for the next design in related
software which involves personal belonging management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4540</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4540</id><created>2010-06-23</created><authors><author><keyname>Suguna</keyname><forenames>N.</forenames></author><author><keyname>Thanushkodi</keyname><forenames>K.</forenames></author></authors><title>A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee
  Colony Optimization</title><categories>cs.LG cs.AI cs.NE</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection refers to the problem of selecting relevant features which
produce the most predictive outcome. In particular, feature selection task is
involved in datasets containing huge number of features. Rough set theory has
been one of the most successful methods used for feature selection. However,
this method is still not able to find optimal subsets. This paper proposes a
new feature selection method based on Rough set theory hybrid with Bee Colony
Optimization (BCO) in an attempt to combat this. This proposed work is applied
in the medical domain to find the minimal reducts and experimentally compared
with the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods
such as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle
Swarm Optimization (PSO).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4542</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4542</id><created>2010-06-23</created><authors><author><keyname>Biswas</keyname><forenames>Kamanashis</forenames></author><author><keyname>Ali</keyname><forenames>Md. Liakat</forenames></author><author><keyname>Harun</keyname><forenames>S. A. M.</forenames></author></authors><title>Algorithm and Implementation of the Blog-Post Supervision Process</title><categories>cs.OH</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A web log or blog in short is a trendy way to share personal entries with
others through website. A typical blog may consist of texts, images, audios and
videos etc. Most of the blogs work as personal online diaries, while others may
focus on specific interest such as photographs (photoblog), art (artblog),
travel (tourblog), IT (techblog) etc. Another type of blogging called
microblogging is also very well known now-a-days which contains very short
posts. Like the developed countries, the users of blogs are gradually
increasing in the developing countries e.g. Bangladesh. Due to the nature of
open access to all users, some people misuse it to spread fake news to achieve
individual or political goals. Some of them also post vulgar materials that
make an embarrass situation for other bloggers. Even, sometimes it indulges the
reputation of the victim. The only way to overcome this problem is to bring all
the posts under supervision of the blog moderator. But it totally contradicts
with blogging concepts. In this paper, we have implemented an algorithm that
would help to prevent the offensive entries from being posted. These entries
would go through a supervision process to justify themselves as legal posts.
From the analysis of the result, we have shown that this approach can eliminate
the chaotic situations in blogosphere at a great extent. Our experiment shows
that about 90% of offensive posts can be detected and stopped from being
published using this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4543</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4543</id><created>2010-06-23</created><authors><author><keyname>Anusuya</keyname><forenames>R.</forenames></author><author><keyname>Kavitha</keyname><forenames>V.</forenames></author><author><keyname>Julie</keyname><forenames>E. Golden</forenames></author></authors><title>Enhancing and Analyzing Search performance in Unstructured Peer to Peer
  Networks Using Enhanced Guided search protocol (EGSP)</title><categories>cs.NI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer (P2P) networks establish loosely coupled application-level
overlays on top of the Internet to facilitate efficient sharing of resources.
It can be roughly classified as either structured or unstructured networks.
Without stringent constraints over the network topology, unstructured P2P
networks can be constructed very efficiently and are therefore considered
suitable to the Internet environment. However, the random search strategies
adopted by these networks usually perform poorly with a large network size. To
enhance the search performance in unstructured P2P networks through exploiting
users' common interest patterns captured within a probability-theoretic
framework termed the user interest model (UIM). A search protocol and a routing
table updating protocol are further proposed in order to expedite the search
process through self organizing the P2P network into a small world. Both
theoretical and experimental analyses are conducted and demonstrated the
effectiveness and efficiency of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4544</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4544</id><created>2010-06-23</created><authors><author><keyname>Hasan</keyname><forenames>Mir Anamul</forenames></author><author><keyname>Sher-E-Alam</keyname><forenames>Khaja Md.</forenames></author><author><keyname>Chowdhury</keyname><forenames>Ahsan Raja</forenames></author></authors><title>Human Disease Diagnosis Using a Fuzzy Expert System</title><categories>cs.AI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human disease diagnosis is a complicated process and requires high level of
expertise. Any attempt of developing a web-based expert system dealing with
human disease diagnosis has to overcome various difficulties. This paper
describes a project work aiming to develop a web-based fuzzy expert system for
diagnosing human diseases. Now a days fuzzy systems are being used successfully
in an increasing number of application areas; they use linguistic rules to
describe systems. This research project focuses on the research and development
of a web-based clinical tool designed to improve the quality of the exchange of
health information between health care professionals and patients.
Practitioners can also use this web-based tool to corroborate diagnosis. The
proposed system is experimented on various scenarios in order to evaluate it's
performance. In all the cases, proposed system exhibits satisfactory results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4545</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4545</id><created>2010-06-23</created><authors><author><keyname>Islam</keyname><forenames>Jeherul</forenames></author><author><keyname>Singh</keyname><forenames>P. K.</forenames></author></authors><title>CORMEN: Coding-Aware Opportunistic Routing in Wireless Mess Network</title><categories>cs.NI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These Network Coding improves the network operation beyond the traditional
routing or store-and-forward, by mixing of data stream within a network.
Network coding techniques explicitly minimizes the total no of transmission in
wireless network. The Coding-aware routing maximizes the coding opportunity by
finding the coding possible path for every packet in the network. Here we
propose CORMEN: a new coding-aware routing mechanism based on opportunistic
routing. In CORMEN, every node independently can take the decision whether to
code packets or not and forwarding of packets is based on the coding
opportunity available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4546</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4546</id><created>2010-06-23</created><authors><author><keyname>Shafi</keyname><forenames>Muhammad Imran</forenames></author><author><keyname>Akram</keyname><forenames>Muhammad</forenames></author><author><keyname>Hayat</keyname><forenames>Sikandar</forenames></author><author><keyname>Sohail</keyname><forenames>Imran</forenames></author></authors><title>Effectiveness of Intrusion Prevention Systems (IPS) in Fast Networks</title><categories>cs.CR</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer systems are facing biggest threat in the form of malicious data
which causing denial of service, information theft, financial and credibility
loss etc. No defense technique has been proved successful in handling these
threats. Intrusion Detection and Prevention Systems (IDPSs) being best of
available solutions. These techniques are getting more and more attention.
Although Intrusion Prevention Systems (IPSs) show a good level of success in
detecting and preventing intrusion attempts to networks, they show a visible
deficiency in their performance when they are employed on fast networks. In
this paper we have presented a design including quantitative and qualitative
methods to identify improvement areas in IPSs. Focus group is used for
qualitative analysis and experiment is used for quantitative analysis. This
paper also describes how to reduce the responding time for IPS when an
intrusion occurs on network, and how can IPS be made to perform its tasks
successfully without effecting network speed negatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4547</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4547</id><created>2010-06-23</created><authors><author><keyname>Alshammari</keyname><forenames>Fahad H.</forenames></author><author><keyname>Alnaqeib</keyname><forenames>Rami</forenames></author><author><keyname>Zaidan</keyname><forenames>M. A.</forenames></author><author><keyname>Hmood</keyname><forenames>Ali K.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author></authors><title>New Quantitative Study for Dissertations Repository System</title><categories>cs.DL</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the age of technology, the information communication technology becomes
very important especially in education field. Students must be allowed to learn
anytime, anywhere and at their own place. The facility of library in the
university should be developed. In this paper we are going to present new
Quantitative Study for Dissertations Repository System and also recommend
future application of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4548</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4548</id><created>2010-06-23</created><authors><author><keyname>D</keyname><forenames>Prasad Reddy P. V. G.</forenames></author><author><keyname>Prasad</keyname><forenames>A.</forenames></author><author><keyname>Srinivas</keyname><forenames>Y.</forenames></author><author><keyname>Brahmaiah</keyname><forenames>P.</forenames></author></authors><title>Gender Based Emotion Recognition System for Telugu Rural Dialects Using
  Hidden Markov Models</title><categories>cs.OH</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic emotion recognition in speech is a research area with a wide range
of applications in human interactions. The basic mathematical tool used for
emotion recognition is Pattern recognition which involves three operations,
namely, pre-processing, feature extraction and classification. This paper
introduces a procedure for emotion recognition using Hidden Markov Models
(HMM), which is used to divide five emotional states: anger, surprise,
happiness, sadness and neutral state. The approach is based on standard speech
recognition technology using hidden continuous markov model by selection of low
level features and the design of the recognition system. Emotional Speech
Database from Telugu Rural Dialects of Andhra Pradesh (TRDAP) was designed
using several speaker's voices comprising the emotional states. The accuracy of
recognizing five different emotions for both genders of classification is 80%
for anger-emotion which is achieved by using the best combination of
39-dimensioanl feature vector for every frame (13 MFCCs, 13 Delta Coefficients
and 13 Acceleration Coefficients) and a classifier using HMM. This outcome very
much matches with that acquired with the same database with subjective
evaluation by human judges. Both gender-dependent and gender-independent
experiments are conducted on TRDAP emotional speech database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4549</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4549</id><created>2010-06-23</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author><author><keyname>Carballo</keyname><forenames>Juan-Carlos Diaz y</forenames></author></authors><title>A Flexible and Secure Deployment Framework for Distributed Applications</title><categories>cs.DC</categories><comments>2nd International Working Conference on Component Deployment (CD
  2004), Edinburgh, Scotland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an implemented system which is designed to support the
deployment of applications offering distributed services, comprising a number
of distributed components. This is achieved by creating high level placement
and topology descriptions which drive tools that deploy applications consisting
of components running on multiple hosts. The system addresses issues of
heterogeneity by providing abstractions over host-specific attributes yielding
a homogeneous run-time environment into which components may be deployed. The
run-time environments provide secure binding mechanisms that permit deployed
components to bind to stored data and services on the hosts on which they are
running.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4550</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4550</id><created>2010-06-23</created><authors><author><keyname>Sirbi</keyname><forenames>Kotrappa</forenames></author><author><keyname>Kulkarni</keyname><forenames>Prakash Jayanth</forenames></author></authors><title>Stronger Enforcement of Security Using AOP and Spring AOP</title><categories>cs.CR</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An application security has two primary goals: first, it is intended to
prevent unauthorised personnel from accessing information at higher
classification than their authorisation. Second, it is intended to prevent
personnel from declassifying information. Using an object oriented approach to
implementing application security results not only with the problem of code
scattering and code tangling, but also results in weaker enforcement of
security. This weaker enforcement of security could be due to the inherent
design of the system or due to a programming error. Aspect Oriented Programming
(AOP) complements Object-Oriented Programming (OOP) by providing another way of
thinking about program structure. The key unit of modularity in OOP is the
class, whereas in AOP the unit of modularity is the aspect. The goal of the
paper is to present that Aspect Oriented Programming AspectJ integrated with
Spring AOP provides very powerful mechanisms for stronger enforcement of
security.Aspect-oriented programming (AOP) allows weaving a security aspect
into an application providing additional security functionality or introducing
completely new security mechanisms.Implementation of security with AOP is a
flexible method to develop separated, extensible and reusable pieces of code
called aspects.In this comparative study paper, we argue that Spring AOP
provides stronger enforcement of security than AspectJ.We have shown both
Spring AOP and AspectJ strive to provide a comprehensive AOP solutions and
complements each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4551</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4551</id><created>2010-06-23</created><authors><author><keyname>Raheja</keyname><forenames>Supriya</forenames></author><author><keyname>Rajpal</keyname><forenames>Smita</forenames></author></authors><title>Vagueness of Linguistic variable</title><categories>cs.AI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the area of computer science focusing on creating machines that can engage
on behaviors that humans consider intelligent. The ability to create
intelligent machines has intrigued humans since ancient times and today with
the advent of the computer and 50 years of research into various programming
techniques, the dream of smart machines is becoming a reality. Researchers are
creating systems which can mimic human thought, understand speech, beat the
best human chessplayer, and countless other feats never before possible.
Ability of the human to estimate the information is most brightly shown in
using of natural languages. Using words of a natural language for valuation
qualitative attributes, for example, the person pawns uncertainty in form of
vagueness in itself estimations. Vague sets, vague judgments, vague conclusions
takes place there and then, where and when the reasonable subject exists and
also is interested in something. The vague sets theory has arisen as the answer
to an illegibility of language the reasonable subject speaks. Language of a
reasonable subject is generated by vague events which are created by the reason
and which are operated by the mind. The theory of vague sets represents an
attempt to find such approximation of vague grouping which would be more
convenient, than the classical theory of sets in situations where the natural
language plays a significant role. Such theory has been offered by known
American mathematician Gau and Buehrer .In our paper we are describing how
vagueness of linguistic variables can be solved by using the vague set
theory.This paper is mainly designed for one of directions of the eventology
(the theory of the random vague events), which has arisen within the limits of
the probability theory and which pursue the unique purpose to describe
eventologically a movement of reason.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4553</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4553</id><created>2010-06-23</created><authors><author><keyname>Yazdi</keyname><forenames>Ebrahim</forenames></author><author><keyname>Haghighat</keyname><forenames>Abolfazl Toroghi</forenames></author></authors><title>Evolution of Biped Walking Using Neural Oscillators Controller and
  Harmony Search Algorithm Optimizer</title><categories>cs.RO</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a simple Neural controller has been used to achieve stable
walking in a NAO biped robot, with 22 degrees of freedom that implemented in a
virtual physics-based simulation environment of Robocup soccer simulation
environment. The algorithm uses a Matsuoka base neural oscillator to generate
control signal for the biped robot. To find the best angular trajectory and
optimize network parameters, a new population-based search algorithm, called
the Harmony Search (HS) algorithm, has been used. The algorithm conceptualized
a group of musicians together trying to search for better state of harmony.
Simulation results demonstrate that the modification of the step period and the
walking motion due to the sensory feedback signals improves the stability of
the walking motion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4555</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4555</id><created>2010-06-23</created><authors><author><keyname>Stieghahn</keyname><forenames>Michael</forenames></author><author><keyname>Engel</keyname><forenames>Thomas</forenames></author></authors><title>Law-Aware Access Control and its Information Model</title><categories>cs.CR</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-border access to a variety of data such as market information,
strategic information, or customer-related information defines the daily
business of many global companies, including financial institutions. These
companies are obliged by law to keep a data processing legal for all offered
services. They need to fulfill different security objectives specified by the
legislation. Therefore, they control access to prevent unauthorized users from
using data. Those security objectives, for example confidentiality or secrecy,
are often defined in the eXtensible Access Control Markup Language that
promotes interoperability between different systems. In this paper, we show the
necessity of incorporating the requirements of legislation into access control.
Based on the work flow in a banking scenario we describe a variety of available
contextual information and their interrelations. Different from other access
control systems our main focus is on law-compliant cross-border data access. By
including legislation directly into access decisions, this lawfulness can be
ensured. We also describe our information model to demonstrate how these
policies can be implemented into an existing network and how the components and
contextual information interrelate. Finally, we outline an event flow for a
request made from a remote user exemplifying how such a system decides about
access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4557</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4557</id><created>2010-06-23</created><authors><author><keyname>Lotfi</keyname><forenames>Mehdi</forenames></author><author><keyname>Jabbehdari</keyname><forenames>Sam</forenames></author><author><keyname>Shahmirzadi</keyname><forenames>Majid Asadi</forenames></author></authors><title>A New Energy Efficient Routing Algorithm Based on a New Cost Function in
  Wireless Ad hoc Networks</title><categories>cs.NI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless ad hoc networks are power constrained since nodes operate with
limited battery energy. Thus, energy consumption is crucial in the design of
new ad hoc routing protocols. In order to maximize the lifetime of ad hoc
networks, traffic should be sent via a route that can be avoid nodes with low
energy. In addition, considering that the nodes of ad hoc networks are mobile,
it is possible that a created path is broken because of nodes mobility and
establishment of a new path would be done again. This is because of sending
additional control packets, accordingly, energy consumption increases. Also, it
should avoid nodes which have more buffered packets. Maybe, because of long
queue, some of these packets are dropped and transmitted again. This is the
reason for wasting of energy. In this paper we propose a new energy efficient
algorithm, that uses a new cost function and avoid nodes with characteristics
which mentioned above. We show that this algorithm improves the network energy
consumption by using this new cost function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4558</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4558</id><created>2010-06-23</created><authors><author><keyname>Akram</keyname><forenames>Muhammad</forenames></author><author><keyname>Sohail</keyname><forenames>Imran</forenames></author><author><keyname>Hayat</keyname><forenames>Sikandar</forenames></author><author><keyname>Shafi</keyname><forenames>M. Imran</forenames></author><author><keyname>Saeed</keyname><forenames>Umer</forenames></author></authors><title>Search Engine Optimization Techniques Practiced in Organizations: A
  Study of Four Organizations</title><categories>cs.OH</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web spammers used Search Engine Optimization (SEO) techniques to increase
search-ranking of web sites. In this paper we have study the essentials SEO
techniques, such as; directory submission, keyword generation and link
exchanges. The impact of SEO techniques can be applied as marketing technique
and to get top listing in major search engines like Google, Yahoo, and MSN. Our
study focuses on these techniques from four different companies' perspectives
of United Kingdom and Pakistan. According to the these companies, these
techniques are low cost and high impacts in profit, because mostly customers
focus on major search engine to find different products on internet, so SEO
technique provides best opportunity to grow their business. This paper also
describes the pros and cons of using these searh engine optimization techniques
in above four companies. We have concluded that these techniques are essential
to increase their business profit and minimize their marketing cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4559</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4559</id><created>2010-06-23</created><authors><author><keyname>AlAbdullah</keyname><forenames>Fadhel. S.</forenames></author><author><keyname>Alshammari</keyname><forenames>Fahad H.</forenames></author><author><keyname>Alnaqeib</keyname><forenames>Rami</forenames></author><author><keyname>Jalab</keyname><forenames>Hamid A.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author></authors><title>Analytical Study on Internet Banking System</title><categories>cs.OH</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet era is a period in the information age in which communication
and commerce via the Internet became a central focus for businesses, consumers,
government, and the media. The Internet era also marks the convergence of the
computer and communications industries and their associated services and
products. Nowadays, the availability of the Internet make it widely used for
everyday life. In order to led business to success, the business and specially
the services should provide comfort use to its costumer. The bank system is one
of the most important businesses who may use the website. The using for the
web-based systems should contain special requirements to achieve the business
goal. Since that the paper will present the functional and non-functional for
the web-based banking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4561</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4561</id><created>2010-06-23</created><authors><author><keyname>Farooq</keyname><forenames>Amjad</forenames></author><author><keyname>Ahsan</keyname><forenames>Syed</forenames></author><author><keyname>Shah</keyname><forenames>Abad</forenames></author></authors><title>An Efficient Technique for Similarity Identification between Ontologies</title><categories>cs.AI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies usually suffer from the semantic heterogeneity when simultaneously
used in information sharing, merging, integrating and querying processes.
Therefore, the similarity identification between ontologies being used becomes
a mandatory task for all these processes to handle the problem of semantic
heterogeneity. In this paper, we propose an efficient technique for similarity
measurement between two ontologies. The proposed technique identifies all
candidate pairs of similar concepts without omitting any similar pair. The
proposed technique can be used in different types of operations on ontologies
such as merging, mapping and aligning. By analyzing its results a reasonable
improvement in terms of completeness, correctness and overall quality of the
results has been found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4562</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4562</id><created>2010-06-23</created><authors><author><keyname>Farooq</keyname><forenames>Amjad</forenames></author><author><keyname>Ahsan</keyname><forenames>Syed</forenames></author><author><keyname>Shah</keyname><forenames>Abad</forenames></author></authors><title>Engineering Semantic Web Applications by Using Object-Oriented Paradigm</title><categories>cs.SE</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The web information resources are growing explosively in number and volume.
Now to retrieve relevant data from web has become very difficult and
time-consuming. Semantic Web envisions that these web resources should be
developed in machine-processable way in order to handle irrelevancy and manual
processing problems. Whereas, the Semantic Web is an extension of current web,
in which web resources are equipped with formal semantics about their
interpretation through machines. These web resources are usually contained in
web applications and systems, and their formal semantics are normally
represented in the form of web-ontologies. In this research paper, an
object-oriented design methodology (OODM) is upgraded for developing semantic
web applications. OODM has been developed for designing of web applications for
the current web. This methodology is good enough to develop web applications.
It also provides a systematic approach for the web applications development but
it is not helpful in generating machine-pocessable content of web applications
in their development. Therefore, this methodology needs to be extended. In this
paper, we propose that extension in OODM. This new extended version is referred
to as the semantic web object-oriented design methodology (SW-OODM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4563</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4563</id><created>2010-06-23</created><authors><author><keyname>Taye</keyname><forenames>Mohammad Mustafa</forenames></author></authors><title>The State of the Art: Ontology Web-Based Languages: XML Based</title><categories>cs.AI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many formal languages have been proposed to express or represent Ontologies,
including RDF, RDFS, DAML+OIL and OWL. Most of these languages are based on XML
syntax, but with various terminologies and expressiveness. Therefore, choosing
a language for building an Ontology is the main step. The main point of
choosing language to represent Ontology is based mainly on what the Ontology
will represent or be used for. That language should have a range of quality
support features such as ease of use, expressive power, compatibility, sharing
and versioning, internationalisation. This is because different kinds of
knowledge-based applications need different language features. The main
objective of these languages is to add semantics to the existing information on
the web. The aims of this paper is to provide a good knowledge of existing
language and understanding of these languages and how could be used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4565</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4565</id><created>2010-06-23</created><authors><author><keyname>Alnaqeib</keyname><forenames>Rami</forenames></author><author><keyname>Alshammari</keyname><forenames>Fahad H.</forenames></author><author><keyname>Zaidan</keyname><forenames>M. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author><author><keyname>Hazza</keyname><forenames>Zubaidah M.</forenames></author></authors><title>An Overview: Extensible Markup Language Technology</title><categories>cs.SE</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML stands for the Extensible Markup Language. It is a markup language for
documents, Nowadays XML is a tool to develop and likely to become a much more
common tool for sharing data and store. XML can communicate structured
information to other users. In other words, if a group of users agree to
implement the same kinds of tags to describe a certain kind of information, XML
applications can assist these users in communicating their information in an
more robust and efficient manner. XML can make it easier to exchange
information between cooperating entities. In this paper we will present the XML
technique by fourth factors Strength of XML, XML Parser, XML Goals and Types of
XML Parsers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4567</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4567</id><created>2010-06-23</created><authors><author><keyname>Taye</keyname><forenames>Mohammad Mustafa</forenames></author></authors><title>Understanding Semantic Web and Ontologies: Theory and Applications</title><categories>cs.AI</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic Web is actually an extension of the current one in that it
represents information more meaningfully for humans and computers alike. It
enables the description of contents and services in machine-readable form, and
enables annotating, discovering, publishing, advertising and composing services
to be automated. It was developed based on Ontology, which is considered as the
backbone of the Semantic Web. In other words, the current Web is transformed
from being machine-readable to machine-understandable. In fact, Ontology is a
key technique with which to annotate semantics and provide a common,
comprehensible foundation for resources on the Semantic Web. Moreover, Ontology
can provide a common vocabulary, a grammar for publishing data, and can supply
a semantic description of data which can be used to preserve the Ontologies and
keep them ready for inference. This paper provides basic concepts of web
services and the Semantic Web, defines the structure and the main applications
of ontology, and provides many relevant terms are explained in order to provide
a basic understanding of ontologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4568</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4568</id><created>2010-06-23</created><authors><author><keyname>Wang</keyname><forenames>Hui Hui</forenames></author><author><keyname>Mohamad</keyname><forenames>Dzulkifli</forenames></author><author><keyname>Ismail</keyname><forenames>N. A.</forenames></author></authors><title>Approaches, Challenges and Future Direction of Image Retrieval</title><categories>cs.IR</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempts to discuss the evolution of the retrieval approaches
focusing on development, challenges and future direction of the image
retrieval. It highlights both the already addressed and outstanding issues. The
explosive growth of image data leads to the need of research and development of
Image Retrieval. However, Image retrieval researches are moving from keyword,
to low level features and to semantic features. Drive towards semantic features
is due to the problem of the keywords which can be very subjective and time
consuming while low level features cannot always describe high level concepts
in the users' mind. Hence, introducing an interpretation inconsistency between
image descriptors and high level semantics that known as the semantic gap. This
paper also discusses the semantic gap issues, user query mechanisms as well as
common ways used to bridge the gap in image retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4569</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4569</id><created>2010-06-23</created><authors><author><keyname>Rahayu</keyname><forenames>S. Siti</forenames></author><author><keyname>Robiah</keyname><forenames>Y.</forenames></author><author><keyname>Shahrin</keyname><forenames>S.</forenames></author><author><keyname>Zaki</keyname><forenames>M. Mohd</forenames></author><author><keyname>Faizal</keyname><forenames>M. A.</forenames></author><author><keyname>Zaheera</keyname><forenames>Z. A.</forenames></author></authors><title>Advanced Trace Pattern For Computer Intrusion Discovery</title><categories>cs.CR</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of crime committed based on the malware intrusion is never ending
as the number of malware variants is growing tremendously and the usage of
internet is expanding globally. Malicious codes easily obtained and use as one
of weapon to gain their objective illegally. Hence, in this research, diverse
logs from different OSI layer are explored to identify the traces left on the
attacker and victim logs in order to establish worm trace pattern to defending
against the attack and help revealing true attacker or victim. For the purpose
of this paper, it focused on malware intrusion and traditional worm namely
sasser worm variants. The concept of trace pattern is created by fusing the
attacker's and victim's perspective. Therefore, the objective of this paper is
to propose a general worm trace pattern for attacker's, victim's and multi-step
(attacker/victim)'s by combining both perspectives. These three proposed worm
trace patterns can be extended into research areas in alert correlation and
computer forensic investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4570</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4570</id><created>2010-06-23</created><authors><author><keyname>Sayem</keyname><forenames>Abu Sadat Md.</forenames></author><author><keyname>Ueda</keyname><forenames>Masashi</forenames></author></authors><title>Optimization of reversible sequential circuits</title><categories>cs.OH</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years reversible logic has been considered as an important issue
for designing low power digital circuits. It has voluminous applications in the
present rising nanotechnology such as DNA computing, Quantum Computing, low
power VLSI and quantum dot automata. In this paper we have proposed optimized
design of reversible sequential circuits in terms of number of gates, delay and
hardware complexity. We have designed the latches with a new reversible gate
and reduced the required number of gates, garbage outputs, and delay and
hardware complexity. As the number of gates and garbage outputs increase the
complexity of reversible circuits, this design will significantly enhance the
performance. We have proposed reversible D-latch and JK latch which are better
than the existing designs available in literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4572</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4572</id><created>2010-06-23</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author></authors><title>A Framework for Constraint-Based Deployment and Autonomic Management of
  Distributed Applications</title><categories>cs.DC</categories><comments>Submitted to ICAC-04</comments><report-no>University of St Andrews CS/04/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for deployment and subsequent autonomic management of
component-based distributed applications. An initial deployment goal is
specified using a declarative constraint language, expressing constraints over
aspects such as component-host mappings and component interconnection topology.
A constraint solver is used to find a configuration that satisfies the goal,
and the configuration is deployed automatically. The deployed application is
instrumented to allow subsequent autonomic management. If, during execution,
the manager detects that the original goal is no longer being met, the
satisfy/deploy process can be repeated automatically in order to generate a
revised deployment that does meet the goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4586</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4586</id><created>2010-06-23</created><updated>2014-04-22</updated><authors><author><keyname>Englert</keyname><forenames>Matthias</forenames></author><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author><author><keyname>Raecke</keyname><forenames>Harald</forenames></author><author><keyname>Talgam</keyname><forenames>Inbal</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>Vertex Sparsifiers: New Results from Old Techniques</title><categories>cs.DS</categories><comments>An extended abstract appears in the 13th International Workshop on
  Approximation Algorithms for Combinatorial Optimization Problems (APPROX),
  2010. Final version to appear in SIAM J. Computing</comments><doi>10.1137/130908440</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a capacitated graph $G = (V,E)$ and a set of terminals $K \subseteq V$,
how should we produce a graph $H$ only on the terminals $K$ so that every
(multicommodity) flow between the terminals in $G$ could be supported in $H$
with low congestion, and vice versa? (Such a graph $H$ is called a
flow-sparsifier for $G$.) What if we want $H$ to be a &quot;simple&quot; graph? What if
we allow $H$ to be a convex combination of simple graphs?
  Improving on results of Moitra [FOCS 2009] and Leighton and Moitra [STOC
2010], we give efficient algorithms for constructing: (a) a flow-sparsifier $H$
that maintains congestion up to a factor of $O(\log k/\log \log k)$, where $k =
|K|$, (b) a convex combination of trees over the terminals $K$ that maintains
congestion up to a factor of $O(\log k)$, and (c) for a planar graph $G$, a
convex combination of planar graphs that maintains congestion up to a constant
factor. This requires us to give a new algorithm for the 0-extension problem,
the first one in which the preimages of each terminal are connected in $G$.
Moreover, this result extends to minor-closed families of graphs.
  Our improved bounds immediately imply improved approximation guarantees for
several terminal-based cut and ordering problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4588</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4588</id><created>2010-06-23</created><authors><author><keyname>Sadek</keyname><forenames>S.</forenames></author><author><keyname>Al-Hamadi</keyname><forenames>A.</forenames></author><author><keyname>Michaelis</keyname><forenames>B.</forenames></author><author><keyname>Sayed</keyname><forenames>U.</forenames></author></authors><title>Efficient Region-Based Image Querying</title><categories>cs.CV</categories><comments>IEEE Publication Format,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retrieving images from large and varied repositories using visual contents
has been one of major research items, but a challenging task in the image
management community. In this paper we present an efficient approach for
region-based image classification and retrieval using a fast multi-level neural
network model. The advantages of this neural model in image classification and
retrieval domain will be highlighted. The proposed approach accomplishes its
goal in three main steps. First, with the help of a mean-shift based
segmentation algorithm, significant regions of the image are isolated.
Secondly, color and texture features of each region are extracted by using
color moments and 2D wavelets decomposition technique. Thirdly the multi-level
neural classifier is trained in order to classify each region in a given image
into one of five predefined categories, i.e., &quot;Sky&quot;, &quot;Building&quot;, &quot;SandnRock&quot;,
&quot;Grass&quot; and &quot;Water&quot;. Simulation results show that the proposed method is
promising in terms of classification and retrieval accuracy results. These
results compare favorably with the best published results obtained by other
state-of-the-art image retrieval techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4607</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4607</id><created>2010-06-23</created><updated>2010-12-08</updated><authors><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author></authors><title>Metric Extension Operators, Vertex Sparsifiers and Lipschitz
  Extendability</title><categories>cs.DS</categories><comments>Appeared at FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study vertex cut and flow sparsifiers that were recently introduced by
Moitra, and Leighton and Moitra. We improve and generalize their results. We
give a new polynomial-time algorithm for constructing O(log k / log log k) cut
and flow sparsifiers, matching the best existential upper bound on the quality
of a sparsifier, and improving the previous algorithmic upper bound of O(log^2
k / log log k). We show that flow sparsifiers can be obtained from linear
operators approximating minimum metric extensions. We introduce the notion of
(linear) metric extension operators, prove that they exist, and give an exact
polynomial-time algorithm for finding optimal operators.
  We then establish a direct connection between flow and cut sparsifiers and
Lipschitz extendability of maps in Banach spaces, a notion studied in
functional analysis since 1930s. Using this connection, we prove a lower bound
of Omega(sqrt{log k/log log k}) for flow sparsifiers and a lower bound of
Omega(sqrt{log k}/log log k) for cut sparsifiers. We show that if a certain
open question posed by Ball in 1992 has a positive answer, then there exist
\tilde O(sqrt{log k}) cut sparsifiers. On the other hand, any lower bound on
cut sparsifiers better than \tilde Omega(sqrt{log k}) would imply a negative
answer to this question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4608</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4608</id><created>2010-06-23</created><authors><author><keyname>Chapanond</keyname><forenames>Anurat</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Mukkai S.</forenames></author><author><keyname>Prabhu</keyname><forenames>G. M.</forenames></author><author><keyname>Punin</keyname><forenames>J.</forenames></author></authors><title>Evolving Graph Representation and Visualization</title><categories>math.CO cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The study of evolution of networks has received increased interest with the
recent discovery that many real-world networks possess many things in common,
in particular the manner of evolution of such networks. By adding a dimension
of time to graph analysis, evolving graphs present opportunities and challenges
to extract valuable information. This paper introduces the Evolving Graph
Markup Language (EGML), an XML application for representing evolving graphs and
related results. Along with EGML, a software tool is provided for the study of
evolving graphs. New evolving graph drawing techniques based on the
force-directed graph layout algorithm are also explored. Our evolving graph
techniques reduce vertex movements between graph instances, so that an evolving
graph can be viewed with smooth transitions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4621</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4621</id><created>2010-06-23</created><authors><author><keyname>Areces</keyname><forenames>Carlos</forenames></author><author><keyname>Figueira</keyname><forenames>Santiago</forenames></author><author><keyname>Gor&#xed;n</keyname><forenames>Daniel</forenames></author></authors><title>The Question of Expressiveness in the Generation of Referring
  Expressions</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of generating referring expressions modulo different
notions of expressive power. We define the notion of $\+L$-referring
expression, for a formal language $\+L$ equipped with a semantics in terms of
relational models. We show that the approach is independent of the particular
algorithm used to generate the referring expression by providing examples using
the frameworks of \cite{AKS08} and \cite{Krahmer2003}. We provide some new
complexity bounds, discuss the issue of the length of the generated
descriptions, and propose ways in which the two approaches can be combined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4625</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4625</id><created>2010-06-23</created><authors><author><keyname>Marquezino</keyname><forenames>F. L.</forenames></author><author><keyname>Portugal</keyname><forenames>R.</forenames></author><author><keyname>Abal</keyname><forenames>G.</forenames></author></authors><title>Mixing Times in Quantum Walks on Two-Dimensional Grids</title><categories>quant-ph cs.CC</categories><comments>11 pages</comments><journal-ref>Physical Review A, v. 82, p. 042341, 2010</journal-ref><doi>10.1103/PhysRevA.82.042341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mixing properties of discrete-time quantum walks on two-dimensional grids
with torus-like boundary conditions are analyzed, focusing on their connection
to the complexity of the corresponding abstract search algorithm. In
particular, an exact expression for the stationary distribution of the coherent
walk over odd-sided lattices is obtained after solving the eigenproblem for the
evolution operator for this particular graph. The limiting distribution and
mixing time of a quantum walk with a coin operator modified as in the abstract
search algorithm are obtained numerically. On the basis of these results, the
relation between the mixing time of the modified walk and the running time of
the corresponding abstract search algorithm is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4627</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4627</id><created>2010-06-23</created><authors><author><keyname>Pahwa</keyname><forenames>Sakshi</forenames></author><author><keyname>Hodges</keyname><forenames>Amelia</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author><author><keyname>Wood</keyname><forenames>Sean</forenames></author></authors><title>Topological analysis of the power grid and mitigation strategies against
  cascading failures</title><categories>nlin.AO cs.NI</categories><comments>5 pages, 8 figures, 1 table. This is a limited version of the work
  due to space limitations of the conference paper. A detailed version is
  submitted to the IEEE Systems Journal and is currently under review</comments><journal-ref>4th Annual International IEEE Systems Conference, April 5-8, 2010</journal-ref><doi>10.1109/SYSTEMS.2010.5482329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a complex systems overview of a power grid network. In
recent years, concerns about the robustness of the power grid have grown
because of several cascading outages in different parts of the world. In this
paper, cascading effect has been simulated on three different networks, the
IEEE 300 bus test system, the IEEE 118 bus test system, and the WSCC 179 bus
equivalent model, using the DC Power Flow Model. Power Degradation has been
discussed as a measure to estimate the damage to the network, in terms of load
loss and node loss. A network generator has been developed to generate graphs
with characteristics similar to the IEEE standard networks and the generated
graphs are then compared with the standard networks to show the effect of
topology in determining the robustness of a power grid. Three mitigation
strategies, Homogeneous Load Reduction, Targeted Range-Based Load Reduction,
and Use of Distributed Renewable Sources in combination with Islanding, have
been suggested. The Homogeneous Load Reduction is the simplest to implement but
the Targeted Range-Based Load Reduction is the most effective strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4645</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4645</id><created>2010-06-23</created><authors><author><keyname>Bartz-Beielstein</keyname><forenames>Thomas</forenames></author></authors><title>SPOT: An R Package For Automatic and Interactive Tuning of Optimization
  Algorithms by Sequential Parameter Optimization</title><categories>cs.NE cs.AI math.OC stat.AP</categories><comments>Related software can be downloaded from
  http://cran.r-project.org/web/packages/SPOT/index.html</comments><report-no>CIOP Technical Report 05/10. Cologne University of Applied Sciences</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The sequential parameter optimization (SPOT) package for R is a toolbox for
tuning and understanding simulation and optimization algorithms. Model-based
investigations are common approaches in simulation and optimization. Sequential
parameter optimization has been developed, because there is a strong need for
sound statistical analysis of simulation and optimization algorithms. SPOT
includes methods for tuning based on classical regression and analysis of
variance techniques; tree-based models such as CART and random forest; Gaussian
process models (Kriging), and combinations of different meta-modeling
approaches. This article exemplifies how SPOT can be used for automatic and
interactive tuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4646</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4646</id><created>2010-06-23</created><authors><author><keyname>Cui</keyname><forenames>Bo</forenames></author><author><keyname>Gao</keyname><forenames>Yuan</forenames></author><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Yu</keyname><forenames>Sheng</forenames></author></authors><title>State Complexity of Two Combined Operations: Reversal-Catenation and
  Star-Catenation</title><categories>cs.FL</categories><comments>20 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that, due to the structural properties of the
resulting automaton obtained from a prior operation, the state complexity of a
combined operation may not be equal but close to the mathematical composition
of the state complexities of its component operations. In particular, we
provide two witness combined operations: reversal combined with catenation and
star combined with catenation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4653</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4653</id><created>2010-06-23</created><updated>2010-07-01</updated><authors><author><keyname>Zirkind</keyname><forenames>Givon</forenames></author></authors><title>Using Repeating Decimals As An Alternative To Prime Numbers In
  Encryption</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author. Paper was replaced by a
  later version</comments><acm-class>D.4.6; E.3; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is meant to provide an additional point of view, applying known
knowledge, to supply keys that have a series of non-repeating digits, in a
manner that is not usually thought of. Traditionally, prime numbers are used in
encryption as keys that have non-repeating sequences. Usually, non-repetition,
especially of digits in a key, is very sought after in encryption. Uniqueness
in a digit sequence defeats decryption. In searching for methods of
non-decryptable encryption as well as ways to provide unique sequences, other
than using prime numbers [5], the idea of using repeating decimals came to me.
Applied correctly, a repeating decimal series of sufficient length will stand
in as well for a prime number. This is so, because only numbers prime to each
other will produce repeating decimals and; within the repeating sequence there
is uniqueness of digit sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4661</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4661</id><created>2010-06-23</created><updated>2012-01-19</updated><authors><author><keyname>Hildebrand</keyname><forenames>Robert</forenames></author><author><keyname>K&#xf6;ppe</keyname><forenames>Matthias</forenames></author></authors><title>A new Lenstra-type Algorithm for Quasiconvex Polynomial Integer
  Minimization with Complexity 2^O(n log n)</title><categories>math.OC cs.DS</categories><comments>28 pages, 10 figures</comments><msc-class>90C10, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the integer minimization of a quasiconvex polynomial with
quasiconvex polynomial constraints. We propose a new algorithm that is an
improvement upon the best known algorithm due to Heinz (Journal of Complexity,
2005). This improvement is achieved by applying a new modern Lenstra-type
algorithm, finding optimal ellipsoid roundings, and considering sparse
encodings of polynomials. For the bounded case, our algorithm attains a
time-complexity of s (r l M d)^{O(1)} 2^{2n log_2(n) + O(n)} when M is a bound
on the number of monomials in each polynomial and r is the binary encoding
length of a bound on the feasible region. In the general case, s l^{O(1)}
d^{O(n)} 2^{2n log_2(n) +O(n)}. In each we assume d&gt;= 2 is a bound on the total
degree of the polynomials and l bounds the maximum binary encoding size of the
input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4681</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4681</id><created>2010-06-23</created><authors><author><keyname>Cassez</keyname><forenames>Franck</forenames></author></authors><title>Dynamic Observers for Fault Diagnosis of Timed Systems</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we extend the work on \emph{dynamic ob\-servers} for fault
diagnosis to timed automata. We study sensor minimization problems with static
observers and then address the problem of computing the most permissive dynamic
observer for a system given by a timed automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4696</identifier>
 <datestamp>2012-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4696</id><created>2010-06-24</created><updated>2012-12-03</updated><authors><author><keyname>Alaei</keyname><forenames>Saeed</forenames></author><author><keyname>Jain</keyname><forenames>Kamal</forenames></author><author><keyname>Malekian</keyname><forenames>Azarakhsh</forenames></author></authors><title>Competitive Equilibria in Two Sided Matching Markets with
  Non-transferable Utilities</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two sided matching markets consisting of agents with
non-transferable utilities; agents from the opposite sides form matching pairs
(e.g., buyers-sellers) and negotiate the terms of their math which may include
a monetary transfer. Competitive equilibria are the elements of the core of
this game.
  We present the first combinatorial characterization of competitive equilibria
that relates the utility of each agent at equilibrium to the equilibrium
utilities of other agents in a strictly smaller market excluding that agent;
thus automatically providing a constructive proof of existence of competitive
equilibria in such markets.
  Our characterization also yields a group strategyproof mechanism for
allocating indivisible goods to unit demand buyers with non-quasilinear
utilities that highly resembles the Vickrey Clarke Groves (VCG) mechanism. As a
direct application of this, we present a group strategyproof welfare maximizing
mechanism for Ad-Auctions without requiring the usual assumption that search
engine and advertisers have consistent estimates of the clickthrough rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4700</identifier>
 <datestamp>2012-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4700</id><created>2010-06-24</created><updated>2012-03-23</updated><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author></authors><title>Arithmetic circuits: the chasm at depth four gets wider</title><categories>cs.CC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In their paper on the &quot;chasm at depth four&quot;, Agrawal and Vinay have shown
that polynomials in m variables of degree O(m) which admit arithmetic circuits
of size 2^o(m) also admit arithmetic circuits of depth four and size 2^o(m).
This theorem shows that for problems such as arithmetic circuit lower bounds or
black-box derandomization of identity testing, the case of depth four circuits
is in a certain sense the general case. In this paper we show that smaller
depth four circuits can be obtained if we start from polynomial size arithmetic
circuits. For instance, we show that if the permanent of n*n matrices has
circuits of size polynomial in n, then it also has depth 4 circuits of size
n^O(sqrt(n)*log(n)). Our depth four circuits use integer constants of
polynomial size. These results have potential applications to lower bounds and
deterministic identity testing, in particular for sums of products of sparse
univariate polynomials. We also give an application to boolean circuit
complexity, and a simple (but suboptimal) reduction to polylogarithmic depth
for arithmetic circuits of polynomial size and polynomially bounded degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4703</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4703</id><created>2010-06-24</created><updated>2011-02-15</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>A construction of universal secure network coding</title><categories>cs.IT cs.CR math.IT</categories><comments>This paper has been withdrawn by the author. The proof technique in
  this paper does not ensure the existence of a coding scheme that is secure
  against all the eavesdropping matrices of rank less than or equal to \mu,
  which means that the proof does not prove the universal security as
  originally claimed. A much extended and corrected version of this paper was
  registered as arXiv:1102.3002. The author appreciates the helpful comment by
  Dr. Jun Muramatsu</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a universal secure network coding. Our construction just
modifies the transmission scheme at the source node and works with every linear
coding at an intermediate node. We relax the security criterion such that the
mutual information between the message and the eavesdropped signal is
sufficiently small instead of strictly zero. Our construction allows the set of
eavesdropped links to change at each time slot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4708</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4708</id><created>2010-06-24</created><authors><author><keyname>Sarmady</keyname><forenames>Siamak</forenames></author></authors><title>A Survey on Peer-to-Peer and DHT</title><categories>cs.DC</categories><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed systems with different levels of dependence to central services
have been designed and used during recent years. Pure peer-to-peer systems
among distributed systems have no dependence on a central resource. DHT is one
of the main techniques behind these systems resulting into failure tolerant
systems which are also able to isolate continuous changes to the network to a
small section of it and therefore making it possible to scale up such networks
to millions of nodes. This survey takes a look at P2P in general and DHT
algorithms and implementations in more detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4730</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4730</id><created>2010-06-24</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author></authors><title>A Framework for Constraint-Based Deployment and Autonomic Management of
  Distributed Applications (Extended Abstract)</title><categories>cs.DC</categories><comments>1st International Conference on Autonomic Computing (ICAC'04)
  pp.300-301, IEEE Computer Society, 2004</comments><doi>10.1109/ICAC.2004.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for the deployment and subsequent autonomic management
of component-based distributed applications. An initial deployment goal is
specified using a declarative constraint language, expressing constraints over
aspects such as component-host mappings and component interconnection topology.
A constraint solver is used to find a configuration that satisfies the goal,
and the configuration is deployed automatically. The deployed application is
instrumented to allow subsequent autonomic management. If, during execution,
the manager detects that the original goal is no longer being met, the
satisfy/deploy process can be repeated automatically in order to generate a
revised deployment that does meet the goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4733</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4733</id><created>2010-06-24</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author></authors><title>A Middleware Framework for Constraint-Based Deployment and Autonomic
  Management of Distributed Applications</title><categories>cs.DC</categories><comments>Submitted to Middleware 04</comments><report-no>University of St Andrews CS/04/2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a middleware framework for deployment and subsequent autonomic
management of component-based distributed applications. An initial deployment
goal is specified using a declarative constraint language, expressing
constraints over aspects such as component-host mappings and component
interconnection topology. A constraint solver is used to find a configuration
that satisfies the goal, and the configuration is deployed automatically. The
deployed application is instrumented to allow subsequent autonomic management.
If, during execution, the manager detects that the original goal is no longer
being met, the satisfy/deploy process can be repeated automatically in order to
generate a revised deployment that does meet the goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4740</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4740</id><created>2010-06-24</created><authors><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Balasubramaniam</keyname><forenames>Dharini</forenames></author><author><keyname>Mickan</keyname><forenames>Kath</forenames></author><author><keyname>Oquendo</keyname><forenames>Flavio</forenames></author><author><keyname>C&#xee;mpan</keyname><forenames>Sorana</forenames></author><author><keyname>Warboys</keyname><forenames>Brian</forenames></author><author><keyname>Snowdon</keyname><forenames>Bob</forenames></author><author><keyname>Greenwood</keyname><forenames>Mark</forenames></author></authors><title>Support for Evolving Software Architectures in the ArchWare ADL</title><categories>cs.SE</categories><comments>4th Working IEEE/IFIP Conference on Software Architecture (WICSA'04)
  pp.69-78, IEEE Computer Society, 2004</comments><doi>10.1109/WICSA.2004.1310691</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software that cannot evolve is condemned to atrophy: it cannot accommodate
the constant revision and re-negotiation of its business goals nor intercept
the potential of new technology. To accommodate change in software systems we
have defined an active software architecture to be: dynamic in that the
structure and cardinality of the components and interactions are changeable
during execution; updatable in that components can be replaced; decomposable in
that an executing system may be (partially) stopped and split up into its
components and interactions; and reflective in that the specification of
components and interactions may be evolved during execution. Here we describe
the facilities of the ArchWare architecture description language (ADL) for
specifying active architectures. The contribution of the work is the unique
combination of concepts including: a {\pi}-calculus based communication and
expression language for specifying executable architectures; hyper-code as an
underlying representation of system execution that can be used for
introspection; a decomposition operator to incrementally break up executing
systems; and structural reflection for creating new components and binding them
into running systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4746</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4746</id><created>2010-06-24</created><authors><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>Dunlop</keyname><forenames>Mark</forenames></author><author><keyname>Connor</keyname><forenames>Richard</forenames></author><author><keyname>Nixon</keyname><forenames>Paddy</forenames></author></authors><title>Active Architecture for Pervasive Contextual Services</title><categories>cs.DC</categories><comments>International Workshop on Middleware for Pervasive and Ad-hoc
  Computing (MPAC 2003), ACM/IFIP/USENIX International Middleware Conference
  (Middleware 2003), Rio de Janeiro, Brazil</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pervasive services may be defined as services that are available &quot;to any
client (anytime, anywhere)&quot;. Here we focus on the software and network
infrastructure required to support pervasive contextual services operating over
a wide area. One of the key requirements is a matching service capable of
as-similating and filtering information from various sources and determining
matches relevant to those services. We consider some of the challenges in
engineering a globally distributed matching service that is scalable,
manageable, and able to evolve incrementally as usage patterns, data formats,
services, network topologies and deployment technologies change. We outline an
approach based on the use of a peer-to-peer architecture to distribute user
events and data, and to support the deployment and evolution of the
infrastructure itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4754</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4754</id><created>2010-06-24</created><authors><author><keyname>Lingashetty</keyname><forenames>Krishna Chaithanya</forenames></author></authors><title>Active Sites model for the B-Matrix Approach</title><categories>cs.NE</categories><comments>11 pages, 4 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper continues on the work of the B-Matrix approach in hebbian learning
proposed by Dr. Kak. It reports the results on methods of improving the memory
retrieval capacity of the hebbian neural network which implements the B-Matrix
approach. Previously, the approach to retrieving the memories from the network
was to clamp all the individual neurons separately and verify the integrity of
these memories. Here we present a network with the capability to identify the
&quot;active sites&quot; in the network during the training phase and use these &quot;active
sites&quot; to generate the memories retrieved from these neurons. Three methods are
proposed for obtaining the update order of the network from the proximity
matrix when multiple neurons are to be clamped. We then present a comparison
between the new methods to the classical case and also among the methods
themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4786</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4786</id><created>2010-06-24</created><authors><author><keyname>Yang</keyname><forenames>Ruiming</forenames></author><author><keyname>Liu</keyname><forenames>Yipeng</forenames></author><author><keyname>Wan</keyname><forenames>Qun</forenames></author><author><keyname>Yang</keyname><forenames>Wanlin</forenames></author></authors><title>Compressive Direction Finding Based on Amplitude Comparison</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, 1 table, part of this paper was presented at
  NSWCTC 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper exploits recent developments in compressive sensing (CS) to
efficiently perform the direction finding via amplitude comprarison. The new
method is proposed based on unimodal characteristic of antenna pattern and
sparse property of received data. Unlike the conventional methods based
peak-searching and symmetric constraint, the sparse reconstruction algorithm
requires less pulse and takes advantage of CS. Simulation results validate the
performance of the proposed method is better than the conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4793</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4793</id><created>2010-06-24</created><updated>2010-06-28</updated><authors><author><keyname>Gore</keyname><forenames>Rajeev</forenames></author><author><keyname>Postniece</keyname><forenames>Linda</forenames></author><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>Cut-Elimination and Proof Search for Bi-Intuitionistic Tense Logic</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an extension of bi-intuitionistic logic with the traditional
modalities from tense logic Kt. Proof theoretically, this extension is obtained
simply by extending an existing sequent calculus for bi-intuitionistic logic
with typical inference rules for the modalities used in display logics. As it
turns out, the resulting calculus, LBiKt, seems to be more basic than most
intuitionistic tense or modal logics considered in the literature, in
particular, those studied by Ewald and Simpson, as it does not assume any a
priori relationship between the diamond and the box modal operators. We recover
Ewald's intuitionistic tense logic and Simpson's intuitionistic modal logic by
modularly extending LBiKt with additional structural rules. The calculus LBiKt
is formulated in a variant of display calculus, using a form of sequents called
nested sequents. Cut elimination is proved for LBiKt, using a technique similar
to that used in display calculi. As in display calculi, the inference rules of
LBiKt are ``shallow'' rules, in the sense that they act on top-level formulae
in a nested sequent. The calculus LBiKt is ill-suited for backward proof search
due to the presence of certain structural rules called ``display postulates''
and the contraction rules on arbitrary structures. We show that these
structural rules can be made redundant in another calculus, DBiKt, which uses
deep inference, allowing one to apply inference rules at an arbitrary depth in
a nested sequent. We prove the equivalence between LBiKt and DBiKt and outline
a proof search strategy for DBiKt. We also give a Kripke semantics and prove
that LBiKt is sound with respect to the semantics, but completeness is still an
open problem. We then discuss various extensions of LBiKt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4801</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4801</id><created>2010-06-24</created><authors><author><keyname>Beheshti</keyname><forenames>Soosan</forenames></author><author><keyname>Hashemi</keyname><forenames>Masoud</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao-Ping</forenames></author><author><keyname>Nikvand</keyname><forenames>Nima</forenames></author></authors><title>Noise Invalidation Denoising</title><categories>stat.ME cs.CV math.ST stat.TH</categories><comments>9 pages, journal submission</comments><doi>10.1109/TSP.2010.2074199</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A denoising technique based on noise invalidation is proposed. The adaptive
approach derives a noise signature from the noise order statistics and utilizes
the signature to denoise the data. The novelty of this approach is in
presenting a general-purpose denoising in the sense that it does not need to
employ any particular assumption on the structure of the noise-free signal,
such as data smoothness or sparsity of the coefficients. An advantage of the
method is in denoising the corrupted data in any complete basis transformation
(orthogonal or non-orthogonal). Experimental results show that the proposed
method, called Noise Invalidation Denoising (NIDe), outperforms existing
denoising approaches in terms of Mean Square Error (MSE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4804</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4804</id><created>2010-06-24</created><updated>2011-08-15</updated><authors><author><keyname>Yan</keyname><forenames>Yimin</forenames></author></authors><title>The General Solutions of Linear ODE and Riccati Equation</title><categories>math.CA cs.SY math-ph math.AP math.MP math.OC nlin.SI</categories><comments>9 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper gives out the general solutions of variable coefficients ODE and
Riccati equation by way of integral series E(X) and F(X). Such kinds of
integral series are the generalized form of exponential function, and keep the
properties of convergent and reversible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4818</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4818</id><created>2010-06-24</created><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Stability (over time) of Modified-CS and LS-CS for Recursive Causal
  Sparse Reconstruction</title><categories>cs.IT math.IT stat.ME</categories><comments>15 pages, one figure with four rows</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we obtain sufficient conditions for the ``stability&quot; of our
recently proposed algorithms, modified-CS (for noisy measurements) and Least
Squares CS-residual (LS-CS), designed for recursive reconstruction of sparse
signal sequences from noisy measurements. By ``stability&quot; we mean that the
number of misses from the current support estimate and the number of extras in
it remain bounded by a time-invariant value at all times. The concept is
meaningful only if the bound is small compared to the current signal support
size. A direct corollary is that the reconstruction errors are also bounded by
a time-invariant and small value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4824</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4824</id><created>2010-06-24</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Cui</keyname><forenames>Ying</forenames></author></authors><title>Decentralized Fair Scheduling in Two-Hop Relay-Assisted Cognitive OFDMA
  Systems</title><categories>cs.PF</categories><comments>29 pages, 9 figures, IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL
  PROCESSING</comments><doi>10.1109/JSTSP.2010.2056352</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a two-hop relay-assisted cognitive downlink OFDMA
system (named as secondary system) dynamically accessing a spectrum licensed to
a primary network, thereby improving the efficiency of spectrum usage. A
cluster-based relay-assisted architecture is proposed for the secondary system,
where relay stations are employed for minimizing the interference to the users
in the primary network and achieving fairness for cell-edge users. Based on
this architecture, an asymptotically optimal solution is derived for jointly
controlling data rates, transmission power, and subchannel allocation to
optimize the average weighted sum goodput where the proportional fair
scheduling (PFS) is included as a special case. This solution supports
decentralized implementation, requires small communication overhead, and is
robust against imperfect channel state information at the transmitter (CSIT)
and sensing measurement. The proposed solution achieves significant throughput
gains and better user-fairness compared with the existing designs. Finally, we
derived a simple and asymptotically optimal scheduling solution as well as the
associated closed-form performance under the proportional fair scheduling for a
large number of users. The system throughput is shown to be
$\mathcal{O}\left(N(1-q_p)(1-q_p^N)\ln\ln K_c\right)$, where $K_c$ is the
number of users in one cluster, $N$ is the number of subchannels and $q_p$ is
the active probability of primary users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4827</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4827</id><created>2010-06-24</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author><author><keyname>Mullen</keyname><forenames>Kevin</forenames></author><author><keyname>Yang</keyname><forenames>Yanyan</forenames></author><author><keyname>Connor</keyname><forenames>Richard</forenames></author><author><keyname>Welen</keyname><forenames>Paula</forenames></author><author><keyname>Wilson</keyname><forenames>Andy</forenames></author></authors><title>Architectural Support for Global Smart Spaces</title><categories>cs.DC</categories><comments>4th International Conference on Mobile Data Management (MDM 2003)</comments><doi>10.1007/3-540-36389-0_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A GLObal Smart Space (GLOSS) provides support for interaction amongst people,
artefacts and places while taking account of both context and movement on a
global scale. Crucial to the definition of a GLOSS is the provision of a set of
location-aware services that detect, convey, store and exploit location
information. We use one of these services, hearsay, to illustrate the
implementation dimensions of a GLOSS. The focus of the paper is on both local
and global software architecture to support the implementation of such
services. The local architecture is based on XML pipe-lines and is used to
construct location-aware components. The global architecture is based on a
hybrid peer-to-peer routing scheme and provides the local architectures with
the means to communicate in the global context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4828</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4828</id><created>2010-06-24</created><authors><author><keyname>Kundeti</keyname><forenames>Vamsi</forenames></author><author><keyname>Rajasekaran</keyname><forenames>Sanguthevar</forenames></author><author><keyname>Dinh</keyname><forenames>Hieu</forenames></author></authors><title>An Efficient Algorithm For Chinese Postman Walk on Bi-directed de Bruijn
  Graphs</title><categories>cs.DS</categories><doi>10.1007/978-3-642-17458-2_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence assembly from short reads is an important problem in biology. It is
known that solving the sequence assembly problem exactly on a bi-directed de
Bruijn graph or a string graph is intractable. However finding a Shortest
Double stranded DNA string (SDDNA) containing all the k-long words in the reads
seems to be a good heuristic to get close to the original genome. This problem
is equivalent to finding a cyclic Chinese Postman (CP) walk on the underlying
un-weighted bi-directed de Bruijn graph built from the reads. The Chinese
Postman walk Problem (CPP) is solved by reducing it to a general bi-directed
flow on this graph which runs in O(|E|2 log2(|V |)) time. In this paper we show
that the cyclic CPP on bi-directed graphs can be solved without reducing it to
bi-directed flow. We present a ?(p(|V | + |E|) log(|V |) + (dmaxp)3) time
algorithm to solve the cyclic CPP on a weighted bi-directed de Bruijn graph,
where p = max{|{v|din(v) - dout(v) &gt; 0}|, |{v|din(v) - dout(v) &lt; 0}|} and dmax
= max{|din(v) - dout(v)}. Our algorithm performs asymptotically better than the
bidirected flow algorithm when the number of imbalanced nodes p is much less
than the nodes in the bi-directed graph. From our experimental results on
various datasets, we have noticed that the value of p/|V | lies between 0.08%
and 0.13% with 95% probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4829</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4829</id><created>2010-06-24</created><authors><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Balasubramaniam</keyname><forenames>Dharini</forenames></author><author><keyname>Mickan</keyname><forenames>Kath</forenames></author><author><keyname>Oquendo</keyname><forenames>Flavio</forenames></author><author><keyname>C&#xee;mpan</keyname><forenames>Sorana</forenames></author><author><keyname>Warboys</keyname><forenames>Brian</forenames></author><author><keyname>Snowdon</keyname><forenames>Bob</forenames></author><author><keyname>Greenwood</keyname><forenames>Mark</forenames></author></authors><title>Constructing Active Architectures in the ArchWare ADL</title><categories>cs.SE</categories><comments>Submitted to ICSE 2004</comments><report-no>University of St Andrews CS/03/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software that cannot change is condemned to atrophy: it cannot accommodate
the constant revision and re-negotiation of its business goals nor intercept
the potential of new technology. To accommodate change in such systems we have
defined an active software architecture to be: dynamic in that the structure
and cardinality of the components and interactions are not statically known;
updatable in that components can be replaced dynamically; and evolvable in that
it permits its executing specification to be changed. Here we describe the
facilities of the ArchWare architecture description language (ADL) for
specifying active architectures. The contribution of the work is the unique
combination of concepts including: a {\pi}-calculus based communication and
expression language for specifying executable architectures; hyper-code as an
underlying representation of system execution; a decomposition operator to
break up and introspect on executing systems; and structural reflection for
creating new components and binding them into running systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4832</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4832</id><created>2010-06-24</created><authors><author><keyname>Pelckmans</keyname><forenames>Kristiaan</forenames></author></authors><title>MINLIP for the Identification of Monotone Wiener Systems</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the MINLIP estimator for the identification of Wiener
systems consisting of a sequence of a linear FIR dynamical model, and a
monotonically increasing (or decreasing) static function. Given $T$
observations, this algorithm boils down to solving a convex quadratic program
with $O(T)$ variables and inequality constraints, implementing an inference
technique which is based entirely on model complexity control. The resulting
estimates of the linear submodel are found to be almost consistent when no
noise is present in the data, under a condition of smoothness of the true
nonlinearity and local Persistency of Excitation (local PE) of the data. This
result is novel as it does not rely on classical tools as a 'linearization'
using a Taylor decomposition, nor exploits stochastic properties of the data.
It is indicated how to extend the method to cope with noisy data, and empirical
evidence contrasts performance of the estimator against other recently proposed
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4833</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4833</id><created>2010-06-24</created><authors><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Zirintsis</keyname><forenames>Evangelos</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author></authors><title>A Generic Storage API</title><categories>cs.DB</categories><comments>Submitted to ACSC 2004</comments><report-no>University of St Andrews CS/03/2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generic API suitable for provision of highly generic storage
facilities that can be tailored to produce various individually customised
storage infrastructures. The paper identifies a candidate set of minimal
storage system building blocks, which are sufficiently simple to avoid
encapsulating policy where it cannot be customised by applications, and
composable to build highly flexible storage architectures. Four main generic
components are defined: the store, the namer, the caster and the interpreter.
It is hypothesised that these are sufficiently general that they could act as
building blocks for any information storage and retrieval system. The essential
characteristics of each are defined by an interface, which may be implemented
by multiple implementing classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4843</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4843</id><created>2010-06-24</created><updated>2011-05-11</updated><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Jir&#xe1;skov&#xe1;</keyname><forenames>Galina</forenames></author><author><keyname>Li</keyname><forenames>Baiyu</forenames></author><author><keyname>Smith</keyname><forenames>Joshua</forenames></author></authors><title>Quotient Complexity of Bifix-, Factor-, and Subword-Free Regular
  Languages</title><categories>cs.FL</categories><comments>24 pages, 11 figures in .eepic format, 2 tables, llncs.cls style
  file. This version contains several new results, and Baiyu Li has been added
  as a co-author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A language L is prefix-free if, whenever words u and v are in L and u is a
prefix of v, then u=v. Suffix-, factor-, and subword-free languages are defined
similarly, where &quot;subword&quot; means &quot;subsequence&quot;. A language is bifix-free if it
is both prefix- and suffix-free. We study the quotient complexity, more
commonly known as state complexity, of operations in the classes of bifix-,
factor-, and subword-free regular languages. We find tight upper bounds on the
quotient complexity of intersection, union, difference, symmetric difference,
concatenation, star, and reversal in these three classes of languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4850</identifier>
 <datestamp>2010-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4850</id><created>2010-06-24</created><authors><author><keyname>Mosina</keyname><forenames>Natalia</forenames></author><author><keyname>Ushakov</keyname><forenames>Alexander</forenames></author></authors><title>Mean-Set Attack: Cryptanalysis of Sibert et al. Authentication Protocol</title><categories>math.GR cs.CR math.PR</categories><msc-class>94A60, 60B15, 68W30, 20F36</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the Sibert et al. group-based (Feige-Fiat-Shamir type)
authentication protocol and show that the protocol is not computationally
zero-knowledge. In addition, we provide experimental evidence that our approach
is practical and can succeed even for groups with no efficiently computable
length function such as braid groups. The novelty of this work is that we are
not attacking the protocol by trying to solve an underlying complex algebraic
problem, namely, the conjugacy search problem, but use a probabilistic
approach, instead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4860</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4860</id><created>2010-06-24</created><authors><author><keyname>Berriman</keyname><forenames>G. Bruce</forenames></author><author><keyname>Deelman</keyname><forenames>Ewa</forenames></author><author><keyname>Groth</keyname><forenames>Paul</forenames></author><author><keyname>Juve</keyname><forenames>Gideon</forenames></author></authors><title>The Application of Cloud Computing to the Creation of Image Mosaics and
  Management of Their Provenance</title><categories>astro-ph.IM cs.DC</categories><comments>15 pages, 3 figure</comments><journal-ref>SPIE Conference 7740: Software and Cyberinfrastructure for
  Astronomy (2010)</journal-ref><doi>10.1117/12.856486</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have used the Montage image mosaic engine to investigate the cost and
performance of processing images on the Amazon EC2 cloud, and to inform the
requirements that higher-level products impose on provenance management
technologies. We will present a detailed comparison of the performance of
Montage on the cloud and on the Abe high performance cluster at the National
Center for Supercomputing Applications (NCSA). Because Montage generates many
intermediate products, we have used it to understand the science requirements
that higher-level products impose on provenance management technologies. We
describe experiments with provenance management technologies such as the
&quot;Provenance Aware Service Oriented Architecture&quot; (PASOA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4892</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4892</id><created>2010-06-24</created><authors><author><keyname>de Carvalho</keyname><forenames>Rogerio Atem</forenames></author><author><keyname>Silva</keyname><forenames>Fernando Luiz de Carvalho e</forenames></author><author><keyname>Manhaes</keyname><forenames>Rodrigo Soares</forenames></author></authors><title>Mapping Business Process Modeling constructs to Behavior Driven
  Development Ubiquitous Language</title><categories>cs.SE</categories><comments>Original work, 12 pages, 9 figures, 1 table</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Behavior-Driven Development (BDD) is a specification technique that
automatically certifies that all functional requirements are treated properly
by source code, through the connection of the textual description of these
requirements to automated tests. Given that in some areas, in special
Enterprise Information Systems, requirements are identified by Business Process
Modeling - which uses graphical notations of the underlying business processes,
this paper aims to provide a mapping from the basic constructs that form the
most common BPM languages to Behavior Driven Development constructs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4900</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4900</id><created>2010-06-24</created><updated>2010-08-03</updated><authors><author><keyname>Terashima</keyname><forenames>R. Seth</forenames></author><author><keyname>Fix</keyname><forenames>James D.</forenames></author></authors><title>Optimal Degree Distributions for Uniform Small World Rings</title><categories>cs.DC</categories><comments>9 pages, 10 references</comments><acm-class>C.2.1; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by Kleinberg's (2000) and subsequent work, we consider the
performance of greedy routing on a directed ring of $n$ nodes augmented with
long-range contacts. In this model, each node $u$ is given an additional $D_u$
edges, a degree chosen from a specified probability distribution. Each such
edge from $u$ is linked to a random node at distance $r$ ahead in the ring with
probability proportional to $1/r$, a &quot;harmonic&quot; distance distribution of
contacts. Aspnes et al. (2002) have shown an $O(\log^2 n / \ell)$ bound on the
expected length of greedy routes in the case when each node is assigned exactly
$\ell$ contacts and, as a consequence of recent work by Dietzfelbinger and
Woelfel (2009), this bound is known to be tight. In this paper, we generalize
Aspnes' upper bound to show that any degree distribution with mean $\ell$ and
maximum value $O(\log n)$ has greedy routes of expected length $O(\log^2n /
\ell)$, implying that any harmonic ring in this family is asymptotically
optimal. Furthermore, for a more general family of rings, we show that a fixed
degree distribution is optimal. More precisely, if each random contact is
chosen at distance $r$ with a probability that decreases with $r$, then among
degree distributions with mean $\ell$, greedy routing time is smallest when
every node is assigned $\floor{\ell}$ or $\ceiling{\ell}$ contacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4903</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4903</id><created>2010-06-24</created><updated>2010-12-30</updated><authors><author><keyname>Garcia-Puente</keyname><forenames>Luis David</forenames></author><author><keyname>Sottile</keyname><forenames>Frank</forenames></author><author><keyname>Zhu</keyname><forenames>Chungang</forenames></author></authors><title>Toric degenerations of Bezier patches</title><categories>cs.GR math.AG</categories><comments>21 pages, many .eps figures</comments><msc-class>65D17, 14M25</msc-class><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control polygon of a Bezier curve is well-defined and has geometric
significance---there is a sequence of weights under which the limiting position
of the curve is the control polygon. For a Bezier surface patch, there are many
possible polyhedral control structures, and none are canonical. We propose a
not necessarily polyhedral control structure for surface patches, regular
control surfaces, which are certain C^0 spline surfaces. While not unique,
regular control surfaces are exactly the possible limiting positions of a
Bezier patch when the weights are allowed to vary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4910</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4910</id><created>2010-06-25</created><updated>2014-09-15</updated><authors><author><keyname>Bayramli</keyname><forenames>Burak</forenames></author></authors><title>3D Visual Tracking with Particle and Kalman Filters</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most visually demonstrable and straightforward uses of filtering
is in the field of Computer Vision. In this document we will try to outline the
issues encountered while designing and implementing a particle and kalman
filter based tracking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4923</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4923</id><created>2010-06-25</created><authors><author><keyname>Creignou</keyname><forenames>Nadia</forenames></author><author><keyname>Schmidt</keyname><forenames>Johannes</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author></authors><title>Complexity Classifications for Propositional Abduction in Post's
  Framework</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the complexity of abduction, a fundamental and
important form of non-monotonic reasoning. Given a knowledge base explaining
the world's behavior it aims at finding an explanation for some observed
manifestation. In this paper we consider propositional abduction, where the
knowledge base and the manifestation are represented by propositional formulae.
The problem of deciding whether there exists an explanation has been shown to
be \SigPtwo-complete in general. We focus on formulae in which the allowed
connectives are taken from certain sets of Boolean functions. We consider
different variants of the abduction problem in restricting both the
manifestations and the hypotheses. For all these variants we obtain a
complexity classification for all possible sets of Boolean functions. In this
way, we identify easier cases, namely \NP-complete, \coNP-complete and
polynomial cases. Thus, we get a detailed picture of the complexity of the
propositional abduction problem, hence highlighting sources of intractability.
Further, we address the problem of counting the explanations and draw a
complete picture for the counting complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4925</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4925</id><created>2010-06-25</created><authors><author><keyname>Luo</keyname><forenames>Xixi</forenames></author><author><keyname>Chen</keyname><forenames>Xiaowu</forenames></author><author><keyname>Zhao</keyname><forenames>Qingping</forenames></author><author><keyname>Shinavier</keyname><forenames>Joshua</forenames></author></authors><title>Simulating information creation in social Semantic Web applications</title><categories>cs.CE</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Appropriate ranking algorithms and incentive mechanisms are essential to the
creation of high-quality information by users of a social network. However,
evaluating such mechanisms in a quantifiable way is a difficult problem.
Studies of live social networks of limited utility, due to the subjective
nature of ranking and the lack of experimental control. Simulation provides a
valuable alternative: insofar as the simulation resembles the live social
network, fielding a new algorithm within a simulated network can predict the
effect it will have on the live network. In this paper, we propose a simulation
model based on the actor-conceptinstance model of semantic social networks,
then we evaluate the model against a number of common ranking algorithms.We
observe their effects on information creation in such a network, and we extend
our results to the evaluation of generic ranking algorithms and incentive
mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4926</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4926</id><created>2010-06-25</created><authors><author><keyname>Zvesper</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>Proof-theoretic Analysis of Rationality for Strategic Games with
  Arbitrary Strategy Sets</title><categories>cs.GT</categories><comments>16 pages, Proc. 11th International Workshop on Computational Logic in
  Multi-Agent Systems (CLIMA XI). To appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of strategic games, we provide an axiomatic proof of the
statement Common knowledge of rationality implies that the players will choose
only strategies that survive the iterated elimination of strictly dominated
strategies. Rationality here means playing only strategies one believes to be
best responses. This involves looking at two formal languages. One is
first-order, and is used to formalise optimality conditions, like avoiding
strictly dominated strategies, or playing a best response. The other is a modal
fixpoint language with expressions for optimality, rationality and belief.
Fixpoints are used to form expressions for common belief and for iterated
elimination of non-optimal strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4937</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4937</id><created>2010-06-25</created><authors><author><keyname>Sunny</keyname><forenames>Albert</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Distributed Greedy Scheduling for Multihop Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of scheduling in multihop wireless networks subject
to interference constraints. We consider a graph based representation of
wireless networks, where scheduled links adhere to the K-hop link interference
model. We develop a distributed greedy heuristic for this scheduling problem.
Further, we show that this distributed greedy heuristic computes the exact same
schedule as the centralized greedy heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4939</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4939</id><created>2010-06-25</created><authors><author><keyname>Safilian</keyname><forenames>Ali Akbar</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author></authors><title>Enumeration Order Equivalency</title><categories>cs.LO math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have investigated enumeration orders of elements of r.e.
sets enumerated by means of Turing machines. We have defined a reducibility
based on enumeration orders named &quot;Enumeration Order Reducibility&quot; on
computable functions and also r.e. sets and studied their properties. Based on
this reducibility we introduce an equivalence relation &quot;Enumeration Order
Equivalency&quot;. We have reached some properties of it. In subsequent, we have
introduced another concept named &quot;type-2 Enumeration Order Equivalency&quot; and
studied its properties too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4943</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4943</id><created>2010-06-25</created><updated>2011-05-06</updated><authors><author><keyname>Pi&#xe9;rard</keyname><forenames>Adrien</forenames></author><author><keyname>Sumii</keyname><forenames>Eijiro</forenames></author></authors><title>Sound Bisimulations for Higher-Order Distributed Process Calculus</title><categories>cs.LO cs.DC cs.PL</categories><comments>15 pages, uses mathpartir and tikz, appendix at
  [http://www.kb.ecei.tohoku.ac.jp/~adrien/pubs/SoundAppendix.pdf], the final
  publication is available at
  [http://www.springerlink.com/content/071k46u248061x72/]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While distributed systems with transfer of processes have become pervasive,
methods for reasoning about their behaviour are underdeveloped. In this paper
we propose a bisimulation technique for proving behavioural equivalence of such
systems modelled in the \emph{higher-order $\pi$-calculus with passivation}
(and restriction). Previous research for this calculus is limited to context
bisimulations and normal bisimulations which are either impractical or unsound.
In contrast, we provide a sound and useful definition of \emph{environmental
bisimulations}, with several non-trivial examples. Technically, a central point
in our bisimulations is the clause for parallel composition, which must account
for passivation of the spawned processes in the middle of their execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4946</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4946</id><created>2010-06-25</created><authors><author><keyname>Hu</keyname><forenames>Guoqiang</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author><author><keyname>Nevin</keyname><forenames>Anne</forenames></author></authors><title>A Virtual Queue Approach for Online Estimation of Loss Probability Based
  on MVA Theory</title><categories>cs.NI cs.PF</categories><comments>5 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In network quality of service provisioning, premium services generally
require to keep a very small loss probability, which is infeasible to measure
directly. The proposed virtual queue scheme estimates the small packet loss
probability of a real queueing system by measuring queue statistics in a set of
separate virtual queues. A novel scaling property between the real queue and
the virtual queues is deduced on the basis of the maximum variance asymptotic
(MVA) theory. The new scheme retains the high accuracy and wide applicability
of the MVA method for aggregated traffic while avoiding the high computational
complexity in a direct application of the original MVA analysis in real time.
This makes it suitable for online measurement applications such as network
performance monitoring and measurement-based admission control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4948</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4948</id><created>2010-06-25</created><authors><author><keyname>Boenn</keyname><forenames>Georg</forenames></author><author><keyname>Brain</keyname><forenames>Martin</forenames></author><author><keyname>De Vos</keyname><forenames>Marina</forenames></author><author><keyname>ffitch</keyname><forenames>John</forenames></author></authors><title>Automatic Music Composition using Answer Set Programming</title><categories>cs.LO cs.AI</categories><comments>31 pages, 10 figures. Extended version of our ICLP2008 paper.
  Formatted following TPLP guidelines</comments><acm-class>D.1.6; I.2.8; I.2.4; J.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music composition used to be a pen and paper activity. These these days music
is often composed with the aid of computer software, even to the point where
the computer compose parts of the score autonomously. The composition of most
styles of music is governed by rules. We show that by approaching the
automation, analysis and verification of composition as a knowledge
representation task and formalising these rules in a suitable logical language,
powerful and expressive intelligent composition tools can be easily built. This
application paper describes the use of answer set programming to construct an
automated system, named ANTON, that can compose melodic, harmonic and rhythmic
music, diagnose errors in human compositions and serve as a computer-aided
composition tool. The combination of harmonic, rhythmic and melodic composition
in a single framework makes ANTON unique in the growing area of algorithmic
composition. With near real-time composition, ANTON reaches the point where it
can not only be used as a component in an interactive composition tool but also
has the potential for live performances and concerts or automatically generated
background music in a variety of applications. With the use of a fully
declarative language and an &quot;off-the-shelf&quot; reasoning engine, ANTON provides
the human composer a tool which is significantly simpler, more compact and more
versatile than other existing systems. This paper has been accepted for
publication in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4949</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4949</id><created>2010-06-25</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Artificial Immune Systems (2010)</title><categories>cs.AI cs.MA cs.NE</categories><comments>29 pages, 1 algorithm, 3 figures, Handbook of Metaheuristics, 2nd
  Edition, Springer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The human immune system has numerous properties that make it ripe for
exploitation in the computational domain, such as robustness and fault
tolerance, and many different algorithms, collectively termed Artificial Immune
Systems (AIS), have been inspired by it. Two generations of AIS are currently
in use, with the first generation relying on simplified immune models and the
second generation utilising interdisciplinary collaboration to develop a deeper
understanding of the immune system and hence produce more complex models. Both
generations of algorithms have been successfully applied to a variety of
problems, including anomaly detection, pattern recognition, optimisation and
robotics. In this chapter an overview of AIS is presented, its evolution is
discussed, and it is shown that the diversification of the field is linked to
the diversity of the immune system itself, leading to a number of algorithms as
opposed to one archetypal system. Two case studies are also presented to help
provide insight into the mechanisms of AIS; these are the idiotypic network
approach and the Dendritic Cell Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4953</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4953</id><created>2010-06-25</created><authors><author><keyname>B&#xed;r&#xf3;</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>Szab&#xf3;</keyname><forenames>J&#xe1;cint</forenames></author></authors><title>Large scale link based latent Dirichlet allocation for web document
  classification</title><categories>cs.IR</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate the applicability of latent Dirichlet allocation
(LDA) for classifying large Web document collections. One of our main results
is a novel influence model that gives a fully generative model of the document
content taking linkage into account. In our setup, topics propagate along links
in such a way that linked documents directly influence the words in the linking
document. As another main contribution we develop LDA specific boosting of
Gibbs samplers resulting in a significant speedup in our experiments. The
inferred LDA model can be applied for classification as dimensionality
reduction similarly to latent semantic indexing. In addition, the model yields
link weights that can be applied in algorithms to process the Web graph; as an
example we deploy LDA link weights in stacked graphical learning. By using
Weka's BayesNet classifier, in terms of the AUC of classification, we achieve
4% improvement over plain LDA with BayesNet and 18% over tf.idf with SVM. Our
Gibbs sampling strategies yield about 5-10 times speedup with less than 1%
decrease in accuracy in terms of likelihood and AUC of classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4955</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4955</id><created>2010-06-25</created><updated>2010-09-07</updated><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames><affiliation>Vrije Universiteit Amsterdam</affiliation></author><author><keyname>de Vrijer</keyname><forenames>Roel</forenames><affiliation>Vrije Universiteit Amsterdam</affiliation></author><author><keyname>Waldmann</keyname><forenames>Johannes</forenames><affiliation>Hochschule fuer Technik, Wirtschaft und Kultur Leipzig</affiliation></author></authors><title>Local Termination: theory and practice</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>D.3.1, F.4.1, F.4.2, I.1.1, I.1.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  7, 2010) lmcs:879</journal-ref><doi>10.2168/LMCS-6(3:20)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The characterisation of termination using well-founded monotone algebras has
been a milestone on the way to automated termination techniques, of which we
have seen an extensive development over the past years. Both the semantic
characterisation and most known termination methods are concerned with global
termination, uniformly of all the terms of a term rewriting system (TRS). In
this paper we consider local termination, of specific sets of terms within a
given TRS. The principal goal of this paper is generalising the semantic
characterisation of global termination to local termination. This is made
possible by admitting the well-founded monotone algebras to be partial. We also
extend our approach to local relative termination. The interest in local
termination naturally arises in program verification, where one is probably
interested only in sensible inputs, or just wants to characterise the set of
inputs for which a program terminates. Local termination will be also be of
interest when dealing with a specific class of terms within a TRS that is known
to be non-terminating, such as combinatory logic (CL) or a TRS encoding
recursive program schemes or Turing machines. We show how some of the
well-known techniques for proving global termination, such as stepwise removal
of rewrite rules and semantic labelling, can be adapted to the local case. We
also describe transformations reducing local to global termination problems.
The resulting techniques for proving local termination have in some cases
already been automated. One of our applications concerns the characterisation
of the terminating S-terms in CL as regular language. Previously this language
had already been found via a tedious analysis of the reduction behaviour of
S-terms. These findings have now been vindicated by a fully automated and
verified proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4959</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4959</id><created>2010-06-25</created><authors><author><keyname>Delarboulas</keyname><forenames>Pierre</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LRI</affiliation></author></authors><title>Open-Ended Evolutionary Robotics: an Information Theoretic Approach</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>PPSN XI, Krakow : Poland (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with designing self-driven fitness functions for
Embedded Evolutionary Robotics. The proposed approach considers the entropy of
the sensori-motor stream generated by the robot controller. This entropy is
computed using unsupervised learning; its maximization, achieved by an on-board
evolutionary algorithm, implements a &quot;curiosity instinct&quot;, favouring
controllers visiting many diverse sensori-motor states (sms). Further, the set
of sms discovered by an individual can be transmitted to its offspring, making
a cultural evolution mode possible. Cumulative entropy (computed from ancestors
and current individual visits to the sms) defines another self-driven fitness;
its optimization implements a &quot;discovery instinct&quot;, as it favours controllers
visiting new or rare sensori-motor states. Empirical results on the benchmark
problems proposed by Lehman and Stanley (2008) comparatively demonstrate the
merits of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4966</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4966</id><created>2010-06-25</created><authors><author><keyname>Aiello</keyname><forenames>Luca Maria</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Ruffo</keyname><forenames>Giancarlo</forenames></author><author><keyname>Schifanella</keyname><forenames>Rossano</forenames></author></authors><title>Link creation and profile alignment in the aNobii social network</title><categories>cs.CY physics.soc-ph</categories><comments>http://www.iisocialcom.org/conference/socialcom2010/</comments><journal-ref>Proceedings of the Second IEEE International Conference on Social
  Computing SocialCom 2010, Minneapolis, USA, August 20-22, 2010</journal-ref><doi>10.1109/SocialCom.2010.42</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work investigates the structural and dynamical properties of
aNobii\footnote{http://www.anobii.com/}, a social bookmarking system designed
for readers and book lovers. Users of aNobii provide information about their
library, reading interests and geographical location, and they can establish
typed social links to other users. Here, we perform an in-depth analysis of the
system's social network and its interplay with users' profiles. We describe the
relation of geographic and interest-based factors to social linking.
Furthermore, we perform a longitudinal analysis to investigate the interplay of
profile similarity and link creation in the social network, with a focus on
triangle closure. We report a reciprocal causal connection: profile similarity
of users drives the subsequent closure in the social network and, reciprocally,
closure in the social network induces subsequent profile alignment. Access to
the dynamics of the social network also allows us to measure quantitative
indicators of preferential linking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.4990</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.4990</id><created>2010-06-25</created><authors><author><keyname>Low</keyname><forenames>Yucheng</forenames></author><author><keyname>Gonzalez</keyname><forenames>Joseph</forenames></author><author><keyname>Kyrola</keyname><forenames>Aapo</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames></author><author><keyname>Hellerstein</keyname><forenames>Joseph M.</forenames></author></authors><title>GraphLab: A New Framework for Parallel Machine Learning</title><categories>cs.LG cs.DC</categories><journal-ref>The 26th Conference on Uncertainty in Artificial Intelligence (UAI
  2010), Catalina Island, California, July 8-11, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing and implementing efficient, provably correct parallel machine
learning (ML) algorithms is challenging. Existing high-level parallel
abstractions like MapReduce are insufficiently expressive while low-level tools
like MPI and Pthreads leave ML experts repeatedly solving the same design
challenges. By targeting common patterns in ML, we developed GraphLab, which
improves upon abstractions like MapReduce by compactly expressing asynchronous
iterative algorithms with sparse computational dependencies while ensuring data
consistency and achieving a high degree of parallel performance. We demonstrate
the expressiveness of the GraphLab framework by designing and implementing
parallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and
Compressed Sensing. We show that using GraphLab we can achieve excellent
parallel performance on large scale real-world problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5003</identifier>
 <datestamp>2015-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5003</id><created>2010-06-25</created><updated>2010-08-24</updated><authors><author><keyname>Gatti</keyname><forenames>Nicola</forenames></author><author><keyname>Monga</keyname><forenames>Mattia</forenames></author><author><keyname>Sicari</keyname><forenames>Sabrina</forenames></author></authors><title>A Game Theoretical Analysis of Localization Security in Wireless Sensor
  Networks with Adversaries</title><categories>cs.GT cs.NI</categories><comments>International Congress on Ultra Modern Telecommunications and Control
  Systems 2010. (ICUMT'10)</comments><acm-class>K.6.5; C.2.0</acm-class><doi>10.1109/ICUMT.2010.5676623</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSN) support data collection and distributed data
processing by means of very small sensing devices that are easy to tamper and
cloning: therefore classical security solutions based on access control and
strong authentication are difficult to deploy. In this paper we look at the
problem of assessing security of node localization. In particular, we analyze
the scenario in which Verifiable Multilateration (VM) is used to localize nodes
and a malicious node (i.e., the adversary) try to masquerade as non-malicious.
We resort to non-cooperative game theory and we model this scenario as a
two-player game. We analyze the optimal players' strategy and we show that the
VM is indeed a proper mechanism to reduce fake positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5008</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5008</id><created>2010-06-25</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author></authors><title>Detecting Danger: The Dendritic Cell Algorithm</title><categories>cs.AI cs.CR cs.NE</categories><comments>27 pages, 8 figures, Robust Intelligent Systems</comments><journal-ref>Robust Intelligent Systems, 12, p 89-112, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dendritic Cell Algorithm (DCA) is inspired by the function of the
dendritic cells of the human immune system. In nature, dendritic cells are the
intrusion detection agents of the human body, policing the tissue and organs
for potential invaders in the form of pathogens. In this research, and abstract
model of DC behaviour is developed and subsequently used to form an algorithm,
the DCA. The abstraction process was facilitated through close collaboration
with laboratory- based immunologists, who performed bespoke experiments, the
results of which are used as an integral part of this algorithm. The DCA is a
population based algorithm, with each agent in the system represented as an
'artificial DC'. Each DC has the ability to combine multiple data streams and
can add context to data suspected as anomalous. In this chapter the abstraction
process and details of the resultant algorithm are given. The algorithm is
applied to numerous intrusion detection problems in computer security including
the detection of port scans and botnets, where it has produced impressive
results with relatively low rates of false positives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5024</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5024</id><created>2010-06-25</created><updated>2016-02-04</updated><authors><author><keyname>Biehl</keyname><forenames>Jacob T.</forenames></author><author><keyname>Turner</keyname><forenames>Thea</forenames></author><author><keyname>Quarfordt</keyname><forenames>Pernilla</forenames></author><author><keyname>van Melle</keyname><forenames>Bill</forenames></author><author><keyname>Dunnigan</keyname><forenames>Tony</forenames></author><author><keyname>Golovchinsky</keyname><forenames>Gene</forenames></author></authors><title>MyUnity: Building Awareness and Fostering Community in the Workplace</title><categories>cs.HC</categories><comments>This paper has been withdrawn to comply with revised corporate
  policies</comments><report-no>FXPAL-TR-09-021</report-no><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Successful collaboration depends on effective communication. Ongoing group
awareness facilitates communication by enabling workers to be more informed
about their collaborators, about their activities, and about the interpersonal
dependencies among people working together. In this paper we present MyUnity, a
new system that aids workers in building group awareness. The system uses
multiple sources, both automatic and user-provided, to report colleagues'
location, availability, current tasks, and preferred communication channels.
Information is aggregated, fused and presented as a simple presence state for
each worker. Workers can each independently control what information is
collected by the system, allowing them to participate in the system without
compromising their privacy. Results from a four-week field study show MyUnity
increased group awareness and fostered an increased sense of community in the
workplace. Results provide insights into the utility of awareness systems in
the workplace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5036</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5036</id><created>2010-06-25</created><authors><author><keyname>Kumar</keyname><forenames>Naveen</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Salapaka</keyname><forenames>Murti</forenames></author></authors><title>Performance evaluation for ML sequence detection in ISI channels with
  Gauss Markov Noise</title><categories>cs.IT math.IT</categories><comments>This paper will appear in GlobeCom 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inter-symbol interference (ISI) channels with data dependent Gauss Markov
noise have been used to model read channels in magnetic recording and other
data storage systems. The Viterbi algorithm can be adapted for performing
maximum likelihood sequence detection in such channels. However, the problem of
finding an analytical upper bound on the bit error rate of the Viterbi detector
in this case has not been fully investigated. Current techniques rely on an
exhaustive enumeration of short error events and determine the BER using a
union bound. In this work, we consider a subset of the class of ISI channels
with data dependent Gauss-Markov noise. We derive an upper bound on the
pairwise error probability (PEP) between the transmitted bit sequence and the
decoded bit sequence that can be expressed as a product of functions depending
on current and previous states in the (incorrect) decoded sequence and the
(correct) transmitted sequence. In general, the PEP is asymmetric. The average
BER over all possible bit sequences is then determined using a pairwise state
diagram. Simulations results which corroborate the analysis of upper bound,
demonstrate that analytic bound on BER is tight in high SNR regime. In the high
SNR regime, our proposed upper bound obviates the need for computationally
expensive simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5038</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5038</id><created>2010-06-25</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Algorithmic Solutions for Several Offline Constrained Resource
  Processing and Data Transfer Multicriteria Optimization Problems</title><categories>cs.DS cs.DC</categories><msc-class>05A05, 05C05, 05C12, 05C38, 68M14, 68P05, 68P10, 90C39</msc-class><acm-class>C.2; G.2</acm-class><journal-ref>Scalable Computing: Practice and Experience, vol. 11, no. 1, pp.
  1-17, 2010. (ISSN: 1895-1767)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present novel algorithmic solutions for several resource
processing and data transfer multicriteria optimization problems. The results
of most of the presented techniques are strategies which solve the considered
problems (almost) optimally. Thus, the developed algorithms construct
intelligent strategies which can be implemented by agents in specific
situations. All the described solutions make use of the properties of the
considered problems and, thus, they are not applicable to a very general class
of problems. However, by considering the specific details of each problem, we
were able to obtain very efficient results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5040</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5040</id><created>2010-06-25</created><authors><author><keyname>Krizhanovsky</keyname><forenames>A. A.</forenames></author></authors><title>The comparison of Wiktionary thesauri transformed into the
  machine-readable format</title><categories>cs.IR</categories><comments>23 pages, 3 tables, 6 figures, preprint</comments><msc-class>68W25, 90C35</msc-class><acm-class>I.7.2; I.7.3; I.7.5; H.3.1; H.3.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Wiktionary is a unique, peculiar, valuable and original resource for natural
language processing (NLP). The paper describes an open-source Wiktionary
parser: its architecture and requirements followed by a description of
Wiktionary features to be taken into account, some open problems of Wiktionary
and the parser. The current implementation of the parser extracts the
definitions, semantic relations, and translations from English and Russian
Wiktionaries. The paper's goal is to interest researchers (1) in using the
constructed machine-readable dictionary for different NLP tasks, (2) in
extending the software to parse 170 still unused Wiktionaries. The comparison
of a number and types of semantic relations, a number of definitions, and a
number of translations in the English Wiktionary and the Russian Wiktionary has
been carried out. It was found that the number of semantic relations in the
English Wiktionary is larger by 1.57 times than in Russian (157 and 100
thousands). But the Russian Wiktionary has more &quot;rich&quot; entries (with a big
number of semantic relations), e.g. the number of entries with three or more
semantic relations is larger by 1.63 times than in the English Wiktionary. Upon
comparison, it was found out the methodological shortcomings of the Wiktionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5041</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5041</id><created>2010-06-24</created><authors><author><keyname>Kawahara</keyname><forenames>Yoshinobu</forenames></author><author><keyname>Bollen</keyname><forenames>Kenneth</forenames></author><author><keyname>Shimizu</keyname><forenames>Shohei</forenames></author><author><keyname>Washio</keyname><forenames>Takashi</forenames></author></authors><title>GroupLiNGAM: Linear non-Gaussian acyclic models for sets of variables</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the structure of a graphical model has been received much attention
in many fields. Recently, it is reported that the non-Gaussianity of data
enables us to identify the structure of a directed acyclic graph without any
prior knowledge on the structure. In this paper, we propose a novel
non-Gaussianity based algorithm for more general type of models; chain graphs.
The algorithm finds an ordering of the disjoint subsets of variables by
iteratively evaluating the independence between the variable subset and the
residuals when the remaining variables are regressed on those. However, its
computational cost grows exponentially according to the number of variables.
Therefore, we further discuss an efficient approximate approach for applying
the algorithm to large sized graphs. We illustrate the algorithm with
artificial and real-world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5047</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5047</id><created>2010-06-25</created><updated>2010-06-29</updated><authors><author><keyname>Singh</keyname><forenames>Santosh Kumar</forenames></author></authors><title>Cognitive radio ad hoc networks (CRAHNs): Cognitive radio ad hoc
  networks (CRAHNs): Resource allocation techniques based on Bio-inspired
  computing</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum is a scarce commodity, and considering the spectrum scarcity faced
by the wireless-based service providers led to high congestion levels.
Technical inefficiencies from pooled spectrum (this is nothing but the &quot;common
carrier principle&quot; adopted in oil/gas/electricity pipelines/networks.), since
all ad hoc networks share a common pool of channels, exhausting the available
channels will force ad hoc networks to block the services. Researchers found
that cognitive radio (CR) technology may resolve the spectrum scarcity. CR
network proved to next generation wireless communication system that proposed
as a way to reuse under-utilised spectrum of licensee user (primary network) in
an opportunistic and non-interfering basis. A CR is a self-configuring entity
in a wireless networking that senses its environment, tracks changes, and
frequently exchanges information with their networks. Adding this layer of such
intelligence to the ad hoc network by looking at the overall geography of the
network known as cognitive radio ad hoc networks (CRAHNs). However, CRAHN
facing challenges and condition become worst while tracks changes i.e.
reallocation of another under-utilised channels while primary network user
arrives. In this paper, channels or resource reallocation technique based on
bio-inspired computing algorithm for CRAHN has been proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5051</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5051</id><created>2010-06-25</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>Fast ABC-Boost for Multi-Class Classification</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abc-boost is a new line of boosting algorithms for multi-class
classification, by utilizing the commonly used sum-to-zero constraint. To
implement abc-boost, a base class must be identified at each boosting step.
Prior studies used a very expensive procedure based on exhaustive search for
determining the base class at each boosting step. Good testing performances of
abc-boost (implemented as abc-mart and abc-logitboost) on a variety of datasets
were reported.
  For large datasets, however, the exhaustive search strategy adopted in prior
abc-boost algorithms can be too prohibitive. To overcome this serious
limitation, this paper suggests a heuristic by introducing Gaps when computing
the base class during training. That is, we update the choice of the base class
only for every $G$ boosting steps (i.e., G=1 in prior studies). We test this
idea on large datasets (Covertype and Poker) as well as datasets of moderate
sizes. Our preliminary results are very encouraging. On the large datasets,
even with G=100 (or larger), there is essentially no loss of test accuracy. On
the moderate datasets, no obvious loss of test accuracy is observed when G&lt;=
20~50. Therefore, aided by this heuristic, it is promising that abc-boost will
be a practical tool for accurate multi-class classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5059</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5059</id><created>2010-06-25</created><authors><author><keyname>Badue</keyname><forenames>Claudine</forenames></author><author><keyname>Almeida</keyname><forenames>Jussara</forenames></author><author><keyname>Almeida</keyname><forenames>Virgilio</forenames></author><author><keyname>Baeza-Yates</keyname><forenames>Ricardo</forenames></author><author><keyname>Ribeiro-Neto</keyname><forenames>Berthier</forenames></author><author><keyname>Ziviani</keyname><forenames>Artur</forenames></author><author><keyname>Ziviani</keyname><forenames>Nivio</forenames></author></authors><title>Capacity Planning for Vertical Search Engines</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vertical search engines focus on specific slices of content, such as the Web
of a single country or the document collection of a large corporation. Despite
this, like general open web search engines, they are expensive to maintain,
expensive to operate, and hard to design. Because of this, predicting the
response time of a vertical search engine is usually done empirically through
experimentation, requiring a costly setup. An alternative is to develop a model
of the search engine for predicting performance. However, this alternative is
of interest only if its predictions are accurate. In this paper we propose a
methodology for analyzing the performance of vertical search engines. Applying
the proposed methodology, we present a capacity planning model based on a
queueing network for search engines with a scale typically suitable for the
needs of large corporations. The model is simple and yet reasonably accurate
and, in contrast to previous work, considers the imbalance in query service
times among homogeneous index servers. We discuss how we tune up the model and
how we apply it to predict the impact on the query response time when
parameters such as CPU and disk capacities are changed. This allows a manager
of a vertical search engine to determine a priori whether a new configuration
of the system might keep the query response under specified performance
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5060</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5060</id><created>2010-06-25</created><updated>2010-07-01</updated><authors><author><keyname>Ye</keyname><forenames>Gui-Bo</forenames></author><author><keyname>Xie</keyname><forenames>Xiaohui</forenames></author></authors><title>Learning sparse gradients for variable selection and dimension reduction</title><categories>stat.ML cs.LG stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variable selection and dimension reduction are two commonly adopted
approaches for high-dimensional data analysis, but have traditionally been
treated separately. Here we propose an integrated approach, called sparse
gradient learning (SGL), for variable selection and dimension reduction via
learning the gradients of the prediction function directly from samples. By
imposing a sparsity constraint on the gradients, variable selection is achieved
by selecting variables corresponding to non-zero partial derivatives, and
effective dimensions are extracted based on the eigenvectors of the derived
sparse empirical gradient covariance matrix. An error analysis is given for the
convergence of the estimated gradients to the true ones in both the Euclidean
and the manifold setting. We also develop an efficient forward-backward
splitting algorithm to solve the SGL problem, making the framework practically
scalable for medium or large datasets. The utility of SGL for variable
selection and feature extraction is explicitly given and illustrated on
artificial data as well as real-world examples. The main advantages of our
method include variable selection for both linear and nonlinear predictions,
effective dimension reduction with sparse loadings, and an efficient algorithm
for large p, small n problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5061</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5061</id><created>2010-06-25</created><authors><author><keyname>Gong</keyname><forenames>Xiaowen</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Tellambura</keyname><forenames>Chintha</forenames></author></authors><title>Optimal Bandwidth and Power Allocation for Sum Ergodic Capacity under
  Fading Channels in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>28 pages, 6 figures, submitted to the IEEE Trans. Signal Processing
  in June 2010</comments><journal-ref>X. Gong, S.A. Vorobyov, C. Tellambura, &quot;Optimal bandwidth and
  power allocation for sum ergodic capacity under fading channels in cognitive
  radio networks,&quot; IEEE Trans. Signal Processing, vol. 59, no. 4, pp.
  1814-1826, Apr. 2011</journal-ref><doi>10.1109/TSP.2010.2101069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies optimal bandwidth and power allocation in a cognitive
radio network where multiple secondary users (SUs) share the licensed spectrum
of a primary user (PU) under fading channels using the frequency division
multiple access scheme. The sum ergodic capacity of all the SUs is taken as the
performance metric of the network. Besides all combinations of the peak/average
transmit power constraints at the SUs and the peak/average interference power
constraint imposed by the PU, total bandwidth constraint of the licensed
spectrum is also taken into account. Optimal bandwidth allocation is derived in
closed-form for any given power allocation. The structures of optimal power
allocations are also derived under all possible combinations of the
aforementioned power constraints. These structures indicate the possible
numbers of users that transmit at nonzero power but below their corresponding
peak powers, and show that other users do not transmit or transmit at their
corresponding peak power. Based on these structures, efficient algorithms are
developed for finding the optimal power allocations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5066</identifier>
 <datestamp>2013-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5066</id><created>2010-06-25</created><authors><author><keyname>Ko</keyname><forenames>Youngwook</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Power Allocation Strategies across N Orthogonal Channels at Both Source
  and Relay</title><categories>cs.IT math.IT</categories><comments>24 pages, 8 figures, submitted to the IEEE Trans. Communications in
  March 2010</comments><journal-ref>Y. Ko, M. Ardakani, and S.A. Vorobyov, &quot;Power allocation
  strategies across N orthogonal channels at both source and relay,&quot; IEEE
  Trans. Communications, vol. 60, no. 6, pp. 1469-1473, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless relay network with one source, one relay and one
destination, where communications between nodes are preformed via N orthogonal
channels. This, for example, is the case when orthogonal frequency division
multiplexing is employed for data communications. Since the power available at
the source and relay is limited, we study optimal power allocation strategies
at the source and relay in order to maximize the overall source-destination
capacity under individual power constraints at the source and/or the relay.
Depending on the availability of the channel state information at the source
and rely, optimal power allocation strategies are performed at both the source
and relay or only at the relay. Considering different setups for the problem,
various optimization problems are formulated and solved. Some properties of the
optimal solution are also proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5086</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5086</id><created>2010-06-25</created><authors><author><keyname>Ye</keyname><forenames>Gui-Bo</forenames></author><author><keyname>Xie</keyname><forenames>Xiaohui</forenames></author></authors><title>Split Bregman method for large scale fused Lasso</title><categories>stat.CO cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  rdering of regression or classification coefficients occurs in many
real-world applications. Fused Lasso exploits this ordering by explicitly
regularizing the differences between neighboring coefficients through an
$\ell_1$ norm regularizer. However, due to nonseparability and nonsmoothness of
the regularization term, solving the fused Lasso problem is computationally
demanding. Existing solvers can only deal with problems of small or medium
size, or a special case of the fused Lasso problem in which the predictor
matrix is identity matrix. In this paper, we propose an iterative algorithm
based on split Bregman method to solve a class of large-scale fused Lasso
problems, including a generalized fused Lasso and a fused Lasso support vector
classifier. We derive our algorithm using augmented Lagrangian method and prove
its convergence properties. The performance of our method is tested on both
artificial data and real-world applications including proteomic data from mass
spectrometry and genomic data from array CGH. We demonstrate that our method is
many times faster than the existing solvers, and show that it is especially
efficient for large p, small n problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5087</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5087</id><created>2010-06-25</created><updated>2012-04-25</updated><authors><author><keyname>Zhou</keyname><forenames>Lei</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Gaussian Z-Interference Channel with a Relay Link: Achievability Region
  and Asymptotic Sum Capacity</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, Vol. 58, No. 4, April 2012</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper studies a Gaussian Z-interference channel with a rate-limited
digital relay link from one receiver to another. Achievable rate regions are
derived based on a combination of Han-Kobayashi common-private information
splitting technique and several different relay strategies including
compress-and-forward and a partial decode-and-forward strategy, in which the
interference is partially decoded then binned and forwarded through the digital
link for subtraction at the other end. For the Gaussian Z-interference channel
with a digital link from the interference-free receiver to the interfered
receiver, the capacity region is established in the strong interference regime;
an achievable rate region is established in the weak interference regime. In
the weak interference regime, the partial decode-and-forward strategy is shown
to be asymptotically sum-capacity achieving in the high signal-to-noise ratio
and high interference-to-noise ratio limit. In this case, each relay bit
asymptotically improves the sum capacity by one bit. For the Gaussian
Z-interference channel with a digital link from the interfered receiver to the
interference-free receiver, the capacity region is established in the strong
interference regime; achievable rate regions are established in the moderately
strong and weak interference regimes. In addition, the asymptotically sum
capacity is established in the limit of large relay link rate. In this case,
the sum capacity improvement due to the digital link is bounded by half a bit
when the interference link is weaker than certain threshold, but the sum
capacity improvement becomes unbounded as the interference link becomes
stronger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5090</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5090</id><created>2010-06-25</created><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>PAC learnability of a concept class under non-atomic measures: a problem
  by Vidyasagar</title><categories>cs.LG</categories><comments>14 pages, 1 figure, latex 2e with Springer macros</comments><msc-class>68T05</msc-class><acm-class>I.2.6</acm-class><journal-ref>Lect. Notes in Artificial Intelligence 6331, Springer, 2010, pp.
  134-147</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In response to a 1997 problem of M. Vidyasagar, we state a necessary and
sufficient condition for distribution-free PAC learnability of a concept class
$\mathscr C$ under the family of all non-atomic (diffuse) measures on the
domain $\Omega$. Clearly, finiteness of the classical Vapnik-Chervonenkis
dimension of $\mathscr C$ is a sufficient, but no longer necessary, condition.
Besides, learnability of $\mathscr C$ under non-atomic measures does not imply
the uniform Glivenko-Cantelli property with regard to non-atomic measures. Our
learnability criterion is stated in terms of a combinatorial parameter
$\VC({\mathscr C}\,{\mathrm{mod}}\,\omega_1)$ which we call the VC dimension of
$\mathscr C$ modulo countable sets. The new parameter is obtained by
``thickening up'' single points in the definition of VC dimension to
uncountable ``clusters''. Equivalently, $\VC(\mathscr C\modd\omega_1)\leq d$ if
and only if every countable subclass of $\mathscr C$ has VC dimension $\leq d$
outside a countable subset of $\Omega$. The new parameter can be also expressed
as the classical VC dimension of $\mathscr C$ calculated on a suitable subset
of a compactification of $\Omega$. We do not make any measurability assumptions
on $\mathscr C$, assuming instead the validity of Martin's Axiom (MA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5094</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5094</id><created>2010-06-25</created><authors><author><keyname>Aldini</keyname><forenames>Alessandro</forenames><affiliation>Univ. of Urbino</affiliation></author></authors><title>Approximate Testing Equivalence Based on Time, Probability, and Observed
  Behavior</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 1-15</journal-ref><doi>10.4204/EPTCS.28.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several application domains require formal but flexible approaches to the
comparison problem. Different process models that cannot be related by
behavioral equivalences should be compared via a quantitative notion of
similarity, which is usually achieved through approximation of some
equivalence. While in the literature the classical equivalence subject to
approximation is bisimulation, in this paper we propose a novel approach based
on testing equivalence. As a step towards flexibility and usability, we study
different relaxations taking into account orthogonal aspects of the process
observations: execution time, event probability, and observed behavior. In this
unifying framework, both interpretation of the measures and decidability of the
verification algorithms are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5095</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5095</id><created>2010-06-25</created><authors><author><keyname>Altisen</keyname><forenames>Karine</forenames><affiliation>Verimag</affiliation></author><author><keyname>Liu</keyname><forenames>Yanhong</forenames><affiliation>Verimag</affiliation></author><author><keyname>Moy</keyname><forenames>Matthieu</forenames><affiliation>Verimag</affiliation></author></authors><title>Performance Evaluation of Components Using a Granularity-based Interface
  Between Real-Time Calculus and Timed Automata</title><categories>cs.PF cs.LO</categories><proxy>EPTCS</proxy><acm-class>C.3; C.4; D.4.7</acm-class><journal-ref>EPTCS 28, 2010, pp. 16-33</journal-ref><doi>10.4204/EPTCS.28.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To analyze complex and heterogeneous real-time embedded systems, recent works
have proposed interface techniques between real-time calculus (RTC) and timed
automata (TA), in order to take advantage of the strengths of each technique
for analyzing various components. But the time to analyze a state-based
component modeled by TA may be prohibitively high, due to the state space
explosion problem. In this paper, we propose a framework of granularity-based
interfacing to speed up the analysis of a TA modeled component. First, we
abstract fine models to work with event streams at coarse granularity. We
perform analysis of the component at multiple coarse granularities and then
based on RTC theory, we derive lower and upper bounds on arrival patterns of
the fine output streams using the causality closure algorithm. Our framework
can help to achieve tradeoffs between precision and analysis time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5096</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5096</id><created>2010-06-25</created><authors><author><keyname>Barsotti</keyname><forenames>Dami&#xe1;n</forenames><affiliation>Universidad Nacional de C&#xf3;rdoba</affiliation></author><author><keyname>Wolovick</keyname><forenames>Nicol&#xe1;s</forenames><affiliation>Universidad Nacional de C&#xf3;rdoba</affiliation></author></authors><title>Automatic Probabilistic Program Verification through Random Variable
  Abstraction</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>F.1.2;G.3</acm-class><journal-ref>EPTCS 28, 2010, pp. 34-47</journal-ref><doi>10.4204/EPTCS.28.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The weakest pre-expectation calculus has been proved to be a mature theory to
analyze quantitative properties of probabilistic and nondeterministic programs.
We present an automatic method for proving quantitative linear properties on
any denumerable state space using iterative backwards fixed point calculation
in the general framework of abstract interpretation. In order to accomplish
this task we present the technique of random variable abstraction (RVA) and we
also postulate a sufficient condition to achieve exact fixed point computation
in the abstract domain. The feasibility of our approach is shown with two
examples, one obtaining the expected running time of a probabilistic program,
and the other the expected gain of a gambling strategy.
  Our method works on general guarded probabilistic and nondeterministic
transition systems instead of plain pGCL programs, allowing us to easily model
a wide range of systems including distributed ones and unstructured programs.
We present the operational and weakest precondition semantics for this programs
and prove its equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5097</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5097</id><created>2010-06-25</created><authors><author><keyname>Bianco</keyname><forenames>Alessandro</forenames><affiliation>University of Naples, Italy</affiliation></author><author><keyname>Faella</keyname><forenames>Marco</forenames><affiliation>University of Naples, Italy</affiliation></author><author><keyname>Mogavero</keyname><forenames>Fabio</forenames><affiliation>University of Naples, Italy</affiliation></author><author><keyname>Murano</keyname><forenames>Aniello</forenames><affiliation>University of Naples, Italy</affiliation></author></authors><title>Quantitative Fairness Games</title><categories>cs.GT cs.DC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 48-63</journal-ref><doi>10.4204/EPTCS.28.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-player games played on finite colored graphs where the goal
is the construction of an infinite path with one of the following
frequency-related properties: (i) all colors occur with the same asymptotic
frequency, (ii) there is a constant that bounds the difference between the
occurrences of any two colors for all prefixes of the path, or (iii) all colors
occur with a fixed asymptotic frequency.
  These properties can be viewed as quantitative refinements of the classical
notion of fair path in a concurrent system, whose simplest form checks whether
all colors occur infinitely often. In particular, the first two properties
enforce equal treatment of all the jobs involved in the system, while the third
one represents a way to assign a given priority to each job. For all the above
goals, we show that the problem of checking whether there exists a winning
strategy is CoNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5098</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5098</id><created>2010-06-25</created><authors><author><keyname>Cachera</keyname><forenames>David</forenames></author><author><keyname>Jobin</keyname><forenames>Arnaud</forenames></author></authors><title>Injecting Abstract Interpretations into Linear Cost Models</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>F.3.2</acm-class><journal-ref>EPTCS 28, 2010, pp. 64-81</journal-ref><doi>10.4204/EPTCS.28.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a semantics based framework for analysing the quantitative
behaviour of programs with regard to resource usage. We start from an
operational semantics equipped with costs. The dioid structure of the set of
costs allows for defining the quantitative semantics as a linear operator. We
then present an abstraction technique inspired from abstract interpretation in
order to effectively compute global cost information from the program.
Abstraction has to take two distinct notions of order into account: the order
on costs and the order on states. We show that our abstraction technique
provides a correct approximation of the concrete cost computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5099</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5099</id><created>2010-06-25</created><authors><author><keyname>Coppo</keyname><forenames>Mario</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Damiani</keyname><forenames>Ferruccio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Drocco</keyname><forenames>Maurizio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Grassi</keyname><forenames>Elena</forenames><affiliation>Dipartimento di Informatica and Molecular Biotechnology Center, Dipartimento di Genetica, Biologia e Biochimica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author></authors><title>Stochastic Calculus of Wrapped Compartments</title><categories>cs.CE cs.FL cs.LO q-bio.QM</categories><proxy>EPTCS</proxy><acm-class>F.3.3; J.3; F.1.2</acm-class><journal-ref>EPTCS 28, 2010, pp. 82-98</journal-ref><doi>10.4204/EPTCS.28.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Calculus of Wrapped Compartments (CWC) is a variant of the Calculus of
Looping Sequences (CLS). While keeping the same expressiveness, CWC strongly
simplifies the development of automatic tools for the analysis of biological
systems. The main simplification consists in the removal of the sequencing
operator, thus lightening the formal treatment of the patterns to be matched in
a term (whose complexity in CLS is strongly affected by the variables matching
in the sequences).
  We define a stochastic semantics for this new calculus. As an application we
model the interaction between macrophages and apoptotic neutrophils and a
mechanism of gene regulation in E.Coli.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5100</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5100</id><created>2010-06-25</created><authors><author><keyname>Georgievska</keyname><forenames>Sonja</forenames></author><author><keyname>Andova</keyname><forenames>Suzana</forenames></author></authors><title>Testing Reactive Probabilistic Processes</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 99-113</journal-ref><doi>10.4204/EPTCS.28.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a testing equivalence in the spirit of De Nicola and Hennessy for
reactive probabilistic processes, i.e. for processes where the internal
nondeterminism is due to random behaviour. We characterize the testing
equivalence in terms of ready-traces. From the characterization it follows that
the equivalence is insensitive to the exact moment in time in which an internal
probabilistic choice occurs, which is inherent from the original testing
equivalence of De Nicola and Hennessy. We also show decidability of the testing
equivalence for finite systems for which the complete model may not be known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5101</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5101</id><created>2010-06-25</created><authors><author><keyname>G&#xfc;demann</keyname><forenames>Matthias</forenames></author><author><keyname>Ortmeier</keyname><forenames>Frank</forenames></author></authors><title>Probabilistic Model-Based Safety Analysis</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 114-128</journal-ref><doi>10.4204/EPTCS.28.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based safety analysis approaches aim at finding critical failure
combinations by analysis of models of the whole system (i.e. software,
hardware, failure modes and environment). The advantage of these methods
compared to traditional approaches is that the analysis of the whole system
gives more precise results. Only few model-based approaches have been applied
to answer quantitative questions in safety analysis, often limited to analysis
of specific failure propagation models, limited types of failure modes or
without system dynamics and behavior, as direct quantitative analysis is uses
large amounts of computing resources. New achievements in the domain of
(probabilistic) model-checking now allow for overcoming this problem.
  This paper shows how functional models based on synchronous parallel
semantics, which can be used for system design, implementation and qualitative
safety analysis, can be directly re-used for (model-based) quantitative safety
analysis. Accurate modeling of different types of probabilistic failure
occurrence is shown as well as accurate interpretation of the results of the
analysis. This allows for reliable and expressive assessment of the safety of a
system in early design stages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5102</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5102</id><created>2010-06-25</created><authors><author><keyname>Ndukwu</keyname><forenames>Ukachukwu</forenames><affiliation>Deptartment of Computing, Macquarie University, Australia.</affiliation></author><author><keyname>McIver</keyname><forenames>Annabelle</forenames><affiliation>Deptartment of Computing, Macquarie University, Australia.</affiliation></author></authors><title>An expectation transformer approach to predicate abstraction and data
  independence for probabilistic programs</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 129-143</journal-ref><doi>10.4204/EPTCS.28.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we revisit the well-known technique of predicate abstraction to
characterise performance attributes of system models incorporating probability.
We recast the theory using expectation transformers, and identify transformer
properties which correspond to abstractions that yield nevertheless exact bound
on the performance of infinite state probabilistic systems. In addition, we
extend the developed technique to the special case of &quot;data independent&quot;
programs incorporating probability. Finally, we demonstrate the subtleness of
the extended technique by using the PRISM model checking tool to analyse an
infinite state protocol, obtaining exact bounds on its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5103</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5103</id><created>2010-06-25</created><authors><author><keyname>Rabe</keyname><forenames>Markus</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Schewe</keyname><forenames>Sven</forenames><affiliation>University of Liverpool</affiliation></author></authors><title>Optimal Time-Abstract Schedulers for CTMDPs and Markov Games</title><categories>cs.FL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 144-158</journal-ref><doi>10.4204/EPTCS.28.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study time-bounded reachability in continuous-time Markov decision
processes for time-abstract scheduler classes. Such reachability problems play
a paramount role in dependability analysis and the modelling of manufacturing
and queueing systems. Consequently, their analysis has been studied
intensively, and techniques for the approximation of optimal control are well
understood. From a mathematical point of view, however, the question of
approximation is secondary compared to the fundamental question whether or not
optimal control exists.
  We demonstrate the existence of optimal schedulers for the time-abstract
scheduler classes for all CTMDPs. Our proof is constructive: We show how to
compute optimal time-abstract strategies with finite memory. It turns out that
these optimal schedulers have an amazingly simple structure - they converge to
an easy-to-compute memoryless scheduling policy after a finite number of steps.
  Finally, we show that our argument can easily be lifted to Markov games: We
show that both players have a likewise simple optimal strategy in these more
general structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5104</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5104</id><created>2010-06-25</created><authors><author><keyname>Stefanek</keyname><forenames>Anton</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Hayden</keyname><forenames>Richard</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Bradley</keyname><forenames>Jeremy</forenames><affiliation>Imperial College London</affiliation></author></authors><title>A new tool for the performance analysis of massively parallel computer
  systems</title><categories>cs.PF cs.DC cs.NA</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010, pp. 159-181</journal-ref><doi>10.4204/EPTCS.28.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new tool, GPA, that can generate key performance measures for
very large systems. Based on solving systems of ordinary differential equations
(ODEs), this method of performance analysis is far more scalable than
stochastic simulation. The GPA tool is the first to produce higher moment
analysis from differential equation approximation, which is essential, in many
cases, to obtain an accurate performance prediction. We identify so-called
switch points as the source of error in the ODE approximation. We investigate
the switch point behaviour in several large models and observe that as the
scale of the model is increased, in general the ODE performance prediction
improves in accuracy. In the case of the variance measure, we are able to
justify theoretically that in the limit of model scale, the ODE approximation
can be expected to tend to the actual variance of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5107</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5107</id><created>2010-06-25</created><authors><author><keyname>Di Pierro</keyname><forenames>Alessandra</forenames><affiliation>University of Verona</affiliation></author><author><keyname>Norman</keyname><forenames>Gethin</forenames><affiliation>University of Glasgow</affiliation></author></authors><title>Proceedings Eighth Workshop on Quantitative Aspects of Programming
  Languages</title><categories>cs.PL cs.LO cs.PF</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 28, 2010</journal-ref><doi>10.4204/EPTCS.28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Eighth Workshop on Quantitative
Aspects of Programming Languages (QAPL 2010), held in Paphos, Cyprus, on March
27-28, 2010. QAPL 2010 is a satellite event of the European Joint Conferences
on Theory and Practice of Software (ETAPS 2010).
  The workshop theme is on quantitative aspects of computation. These aspects
are related to the use of physical quantities (storage space, time, bandwidth,
etc.) as well as mathematical quantities (e.g. probability and measures for
reliability, security and trust), and play an important (sometimes essential)
role in characterising the behavior and determining the properties of systems.
Such quantities are central to the definition of both the model of systems
(architecture, language design, semantics) and the methodologies and tools for
the analysis and verification of the systems properties.
  The aim of this workshop is to discuss the explicit use of quantitative
information such as time and probabilities either directly in the model or as a
tool for the analysis of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5111</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5111</id><created>2010-06-26</created><authors><author><keyname>Matisziw</keyname><forenames>Timothy C.</forenames></author><author><keyname>Murray</keyname><forenames>Alan T.</forenames></author></authors><title>Modeling s-t Path Availability to Support Disaster Vulnerability
  Assessment of Network Infrastructure</title><categories>physics.data-an cs.NA physics.comp-ph</categories><journal-ref>Matisziw, T.C. and A.T. Murray. 2009. Modeling s-t Path
  Availability to Support Disaster Vulnerability Assessment of Network
  Infrastructure. Computers &amp; Operations Research. 36(1), 16-26</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maintenance of system flow is critical for effective network operation.
Any type of disruption to network facilities (arcs/nodes) potentially risks
loss of service, leaving users without access to important resources. It is
therefore an important goal of planners to assess infrastructures for
vulnerabilities, identifying those vital nodes/arcs whose debilitation would
compromise the most source-sink (s-t) interaction or system flow. Due to the
budgetary limitations of disaster management agencies, protection/fortification
and planning for the recovery of these vital infrastructure facilities is a
logical and efficient proactive approach to reducing worst-case risk of service
disruption. Given damage to a network, evaluating the potential for flow
between s-t pairs requires assessing the availability of an operational s-t
path. Recent models proposed for identifying infrastructure vital to system
flow have relied on enumeration of all s-t paths to support this task. This
paper proposes an alternative model constraint structure that does not require
complete enumeration of s-t paths, providing computational benefits over
existing models. To illustrate the model, an application to a practical
infrastructure planning problem is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5113</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5113</id><created>2010-06-26</created><authors><author><keyname>Samara</keyname><forenames>Ghassan</forenames></author><author><keyname>Ramadas</keyname><forenames>Sureswaran</forenames></author><author><keyname>Al-Salihy</keyname><forenames>Wafaa A. H.</forenames></author></authors><title>Design of Simple and Efficient Revocation List Distribution in Urban
  areas for VANET's</title><categories>cs.NI</categories><comments>5 pages</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 1, April 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular Ad hoc Networks is one of the most challenging research area in the
field of Mobile Ad Hoc Networks, in this research we propose a flexible,
simple, and scalable design for revocation list distribution in VANET, which
will reduce channel overhead and eliminate the use of CRL. Also it will
increase the security of the network and helps in identifying the adversary
vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5166</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5166</id><created>2010-06-26</created><updated>2011-06-11</updated><authors><author><keyname>Gohari</keyname><forenames>Amin Aminzadeh</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>On Marton's Inner Bound for the General Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>14 pages, Submitted to IEEE Transactions in Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish several new results on Marton's coding scheme and its
corresponding inner bound on the capacity region of the general broadcast
channel. We show that unlike the Gaussian case, Marton's coding scheme without
superposition coding is not optimal in general even for a degraded broadcast
channel with no common message. We then establish properties of Marton's inner
bound that help restrict the search space for computing the sum-rate. Next, we
show that the inner bound is optimal along certain directions. Finally, we
propose a coding scheme that may lead to a larger inner bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5169</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5169</id><created>2010-06-26</created><updated>2010-09-10</updated><authors><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Fragkiskos</forenames></author><author><keyname>Kitsak</keyname><forenames>Maksim</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author></authors><title>Hyperbolic Geometry of Complex Networks</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.NI physics.soc-ph</categories><journal-ref>Phys. Rev. E 82, 036106 (2010)</journal-ref><doi>10.1103/PhysRevE.82.036106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a geometric framework to study the structure and function of
complex networks. We assume that hyperbolic geometry underlies these networks,
and we show that with this assumption, heterogeneous degree distributions and
strong clustering in complex networks emerge naturally as simple reflections of
the negative curvature and metric property of the underlying hyperbolic
geometry. Conversely, we show that if a network has some metric structure, and
if the network degree distribution is heterogeneous, then the network has an
effective hyperbolic geometry underneath. We then establish a mapping between
our geometric framework and statistical mechanics of complex networks. This
mapping interprets edges in a network as non-interacting fermions whose
energies are hyperbolic distances between nodes, while the auxiliary fields
coupled to edges are linear functions of these energies or distances. The
geometric network ensemble subsumes the standard configuration model and
classical random graphs as two limiting cases with degenerate geometric
structures. Finally, we show that targeted transport processes without global
topology knowledge, made possible by our geometric framework, are maximally
efficient, according to all efficiency measures, in networks with strongest
heterogeneity and clustering, and that this efficiency is remarkably robust
with respect to even catastrophic disturbances and damages to the network
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5188</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5188</id><created>2010-06-27</created><authors><author><keyname>Di Mauro</keyname><forenames>Nicola</forenames></author><author><keyname>Basile</keyname><forenames>Teresa M. A.</forenames></author><author><keyname>Ferilli</keyname><forenames>Stefano</forenames></author><author><keyname>Esposito</keyname><forenames>Floriana</forenames></author></authors><title>Feature Construction for Relational Sequence Learning</title><categories>cs.AI cs.LG</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of multi-class relational sequence learning using
relevant patterns discovered from a set of labelled sequences. To deal with
this problem, firstly each relational sequence is mapped into a feature vector
using the result of a feature construction method. Since, the efficacy of
sequence learning algorithms strongly depends on the features used to represent
the sequences, the second step is to find an optimal subset of the constructed
features leading to high classification accuracy. This feature selection task
has been solved adopting a wrapper approach that uses a stochastic local search
algorithm embedding a naive Bayes classifier. The performance of the proposed
method applied to a real-world dataset shows an improvement when compared to
other established methods, such as hidden Markov models, Fisher kernels and
conditional random fields for relational sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5226</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5226</id><created>2010-06-27</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Fu</keyname><forenames>Huanzhang</forenames><affiliation>DIE</affiliation></author><author><keyname>Guo</keyname><forenames>Yang</forenames><affiliation>DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author></authors><title>A Framework for Interactive Work Design based on Digital Work Analysis
  and Simulation</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Human Factors and Ergonomics in Manufacturing 20, 4 (2010) 339-352</journal-ref><doi>10.1002/hfm.20178</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the flexibility and adaptability of human, manual handling work is
still very important in industry, especially for assembly and maintenance work.
Well-designed work operation can improve work efficiency and quality; enhance
safety, and lower cost. Most traditional methods for work system analysis need
physical mock-up and are time consuming. Digital mockup (DMU) and digital human
modeling (DHM) techniques have been developed to assist ergonomic design and
evaluation for a specific worker population (e.g. 95 percentile); however, the
operation adaptability and adjustability for a specific individual are not
considered enough. In this study, a new framework based on motion tracking
technique and digital human simulation technique is proposed for motion-time
analysis of manual operations. A motion tracking system is used to track a
worker's operation while he/she is conducting a manual handling work. The
motion data is transferred to a simulation computer for real time digital human
simulation. The data is also used for motion type recognition and analysis
either online or offline for objective work efficiency evaluation and
subjective work task evaluation. Methods for automatic motion recognition and
analysis are presented. Constraints and limitations of the proposed method are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5234</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5234</id><created>2010-06-27</created><updated>2012-04-02</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>Approximating the Tutte polynomial of a binary matroid and other related
  combinatorial polynomials</title><categories>cs.CC math.CO</categories><journal-ref>JCSS 79(1) (February, 2013) 68-78</journal-ref><doi>10.1016/j.jcss.2012.04.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of approximating certain combinatorial polynomials.
First, we consider the problem of approximating the Tutte polynomial of a
binary matroid with parameters q&gt;= 2 and gamma. (Relative to the classical
(x,y) parameterisation, q=(x-1)(y-1) and gamma=y-1.) A graph is a special case
of a binary matroid, so earlier work by the authors shows inapproximability
(subject to certain complexity assumptions) for q&gt;2, apart from the trivial
case gamma=0. The situation for q=2 is different. Previous results for graphs
imply inapproximability in the region -2&lt;=gamma&lt;0, apart from at two &quot;special
points&quot; where the polynomial can be computed exactly in polynomial time. For
binary matroids, we extend this result by showing (i) there is no FPRAS in the
region gamma&lt;-2 unless NP=RP, and (ii) in the region gamma&gt;0, the approximation
problem is hard for the complexity class #RHPi_1 under approximation-preserving
(AP) reducibility. The latter result indicates a gap in approximation
complexity at q=2: whereas an FPRAS is known in the graphical case, there can
be none in the binary matroid case, unless there is an FPRAS for all of
#RHPi_1. The result also implies that it is computationally difficult to
approximate the weight enumerator of a binary linear code, apart from at the
special weights at which the problem is exactly solvable in polynomial time. As
a consequence, we show that approximating the cycle index polynomial of a
permutation group is hard for #RHPi_1 under AP-reducibility, partially
resolving a question that we first posed in 1992.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5235</identifier>
 <datestamp>2012-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5235</id><created>2010-06-27</created><authors><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames></author><author><keyname>Riondato</keyname><forenames>Matteo</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author><author><keyname>Vandin</keyname><forenames>Fabio</forenames></author></authors><title>Mining Top-K Frequent Itemsets Through Progressive Sampling</title><categories>cs.DS</categories><comments>16 pages, 2 figures, accepted for presentation at ECML PKDD 2010 and
  publication in the ECML PKDD 2010 special issue of the Data Mining and
  Knowledge Discovery journal</comments><doi>10.1007/s10618-010-0185-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the use of sampling for efficiently mining the top-K frequent
itemsets of cardinality at most w. To this purpose, we define an approximation
to the top-K frequent itemsets to be a family of itemsets which includes
(resp., excludes) all very frequent (resp., very infrequent) itemsets, together
with an estimate of these itemsets' frequencies with a bounded error. Our first
result is an upper bound on the sample size which guarantees that the top-K
frequent itemsets mined from a random sample of that size approximate the
actual top-K frequent itemsets, with probability larger than a specified value.
We show that the upper bound is asymptotically tight when w is constant. Our
main algorithmic contribution is a progressive sampling approach, combined with
suitable stopping conditions, which on appropriate inputs is able to extract
approximate top-K frequent itemsets from samples whose sizes are smaller than
the general upper bound. In order to test the stopping conditions, this
approach maintains the frequency of all itemsets encountered, which is
practical only for small w. However, we show how this problem can be mitigated
by using a variation of Bloom filters. A number of experiments conducted on
both synthetic and real bench- mark datasets show that using samples
substantially smaller than the original dataset (i.e., of size defined by the
upper bound or reached through the progressive sampling approach) enable to
approximate the actual top-K frequent itemsets with accuracy much higher than
what analytically proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5252</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5252</id><created>2010-06-27</created><authors><author><keyname>Ma</keyname><forenames>Rick</forenames></author><author><keyname>Cheng</keyname><forenames>Samuel</forenames></author></authors><title>Decomposition Approach for Low-rank Matrix Completion</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe a low-rank matrix completion method based on
matrix decomposition. An incomplete matrix is decomposed into submatrices which
are filled with a proposed trimming step and then are recombined to form a
low-rank completed matrix. The divide-and-conquer approach can significantly
reduce computation complexity and storage requirement. Moreover, the proposed
decomposition method can be naturally incorporated into any existing matrix
completion methods to attain further gain. Unlike most existing approaches, the
proposed method is not based on norm minimization nor SVD decomposition. This
makes it possible to be applied beyond real domain and can be used in arbitrary
fields including finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5261</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5261</id><created>2010-06-28</created><authors><author><keyname>Khalilian</keyname><forenames>Madjid</forenames></author><author><keyname>Mustapha</keyname><forenames>Norwati</forenames></author></authors><title>Data Stream Clustering: Challenges and Issues</title><categories>cs.DB cs.LG</categories><comments>IMECS2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very large databases are required to store massive amounts of data that are
continuously inserted and queried. Analyzing huge data sets and extracting
valuable pattern in many applications are interesting for researchers. We can
identify two main groups of techniques for huge data bases mining. One group
refers to streaming data and applies mining techniques whereas second group
attempts to solve this problem directly with efficient algorithms. Recently
many researchers have focused on data stream as an efficient strategy against
huge data base mining instead of mining on entire data base. The main problem
in data stream mining means evolving data is more difficult to detect in this
techniques therefore unsupervised methods should be applied. However,
clustering techniques can lead us to discover hidden information. In this
survey, we try to clarify: first, the different problem definitions related to
data stream clustering in general; second, the specific difficulties
encountered in this field of research; third, the varying assumptions,
heuristics, and intuitions forming the basis of different approaches; and how
several prominent solutions tackle different problems. Index Terms- Data
Stream, Clustering, K-Means, Concept drift
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5263</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5263</id><created>2010-06-28</created><authors><author><keyname>Bheemaiah</keyname><forenames>Anil</forenames></author></authors><title>Design specifications of the Human Robotic interface for the biomimetic
  underwater robot &quot;yellow submarine project&quot;</title><categories>cs.MA cs.RO</categories><comments>conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the design of a web based multi agent design for a
collision avoidance auto navigation biomimetic submarine for submarine
hydroelectricity. The paper describes the nature of the map - topology
interface for river bodies and the design of interactive agents for the control
of the robotic submarine. The agents are migratory on the web and are designed
in XML/html interface with both interactive capabilities and visibility on a
map. The paper describes mathematically the user interface and the map
definition languages used for the multi agent description
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5265</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5265</id><created>2010-06-28</created><authors><author><keyname>Ardestanizadeh</keyname><forenames>Ehsan</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author></authors><title>Control-theoretic Approach to Communication with Feedback: Fundamental
  Limits and Code Design</title><categories>cs.IT math.DS math.IT math.OC</categories><comments>Submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feedback communication is studied from a control-theoretic perspective,
mapping the communication problem to a control problem in which the control
signal is received through the same noisy channel as in the communication
problem, and the (nonlinear and time-varying) dynamics of the system determine
a subclass of encoders available at the transmitter. The MMSE capacity is
defined to be the supremum exponential decay rate of the mean square decoding
error. This is upper bounded by the information-theoretic feedback capacity,
which is the supremum of the achievable rates. A sufficient condition is
provided under which the upper bound holds with equality. For the special class
of stationary Gaussian channels, a simple application of Bode's integral
formula shows that the feedback capacity, recently characterized by Kim, is
equal to the maximum instability that can be tolerated by the controller under
a given power constraint. Finally, the control mapping is generalized to the
N-sender AWGN multiple access channel. It is shown that Kramer's code for this
channel, which is known to be sum rate optimal in the class of generalized
linear feedback codes, can be obtained by solving a linear quadratic Gaussian
control problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5271</identifier>
 <datestamp>2013-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5271</id><created>2010-06-28</created><updated>2013-01-25</updated><authors><author><keyname>Muramatsu</keyname><forenames>Jun</forenames></author><author><keyname>Miyake</keyname><forenames>Shigeki</forenames></author></authors><title>Construction of Slepian-Wolf Source Code and Broadcast Channel Code
  Based on Hash Property</title><categories>cs.IT math.IT</categories><comments>The proofs of Lemmas 4 and 9 are revised. Some proofs are simplified.
  Some typos are fixed. A part of this paper has been published in Proceedings
  of 2010 IEEE International Symposium on Information Theory (ISIT2010) and
  Proceedings of 7th Asia-Europe Workshop &quot;CONCEPTS in INFORMATION THEORY&quot;
  (AEW7), 2011, 39 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove theorems for the Slepian-Wolf source coding
and the broadcast channel coding (independent messages and no common message)
based on the the notion of a stronger version of the hash property for an
ensemble of functions. Since an ensemble of sparse matrices has a strong hash
property, codes using sparse matrices can realize the achievable rate region.
Furthermore, extensions to the multiple source coding and multiple output
broadcast channel coding are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5273</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5273</id><created>2010-06-28</created><authors><author><keyname>Gil</keyname><forenames>Myeong-Seon</forenames></author><author><keyname>Moon</keyname><forenames>Yang-Sae</forenames></author><author><keyname>Kim</keyname><forenames>Bum-Soo</forenames></author></authors><title>Linear Detrending Subsequence Matching in Time-Series Databases</title><categories>cs.DB</categories><comments>12 pages</comments><doi>10.1587/transinf.E94.D.917</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each time-series has its own linear trend, the directionality of a
timeseries, and removing the linear trend is crucial to get the more intuitive
matching results. Supporting the linear detrending in subsequence matching is a
challenging problem due to a huge number of possible subsequences. In this
paper we define this problem the linear detrending subsequence matching and
propose its efficient index-based solution. To this end, we first present a
notion of LD-windows (LD means linear detrending), which is obtained as
follows: we eliminate the linear trend from a subsequence rather than each
window itself and obtain LD-windows by dividing the subsequence into windows.
Using the LD-windows we then present a lower bounding theorem for the
index-based matching solution and formally prove its correctness. Based on the
lower bounding theorem, we next propose the index building and subsequence
matching algorithms for linear detrending subsequence matching.We finally show
the superiority of our index-based solution through extensive experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5278</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5278</id><created>2010-06-28</created><updated>2010-12-24</updated><authors><author><keyname>Almazro</keyname><forenames>Dhoha</forenames></author><author><keyname>Shahatah</keyname><forenames>Ghadeer</forenames></author><author><keyname>Albdulkarim</keyname><forenames>Lamia</forenames></author><author><keyname>Kherees</keyname><forenames>Mona</forenames></author><author><keyname>Martinez</keyname><forenames>Romy</forenames></author><author><keyname>Nzoukou</keyname><forenames>William</forenames></author></authors><title>A Survey Paper on Recommender Systems</title><categories>cs.IR cs.LG</categories><comments>This paper has some typos in it</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems apply data mining techniques and prediction algorithms to
predict users' interest on information, products and services among the
tremendous amount of available items. The vast growth of information on the
Internet as well as number of visitors to websites add some key challenges to
recommender systems. These are: producing accurate recommendation, handling
many recommendations efficiently and coping with the vast growth of number of
participants in the system. Therefore, new recommender system technologies are
needed that can quickly produce high quality recommendations even for huge data
sets.
  To address these issues we have explored several collaborative filtering
techniques such as the item based approach, which identify relationship between
items and indirectly compute recommendations for users based on these
relationships. The user based approach was also studied, it identifies
relationships between users of similar tastes and computes recommendations
based on these relationships.
  In this paper, we introduce the topic of recommender system. It provides ways
to evaluate e?ciency, scalability and accuracy of recommender system. The paper
also analyzes different algorithms of user based and item based techniques for
recommendation generation. Moreover, a simple experiment was conducted using a
data mining application -Weka- to apply data mining algorithms to recommender
system. We conclude by proposing our approach that might enhance the quality of
recommender systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5299</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5299</id><created>2010-06-28</created><updated>2010-12-28</updated><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Dingkang</forenames></author></authors><title>The F5 Algorithm in Buchberger's Style</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The famous F5 algorithm for computing \gr basis was presented by Faug\`ere in
2002. The original version of F5 is given in programming codes, so it is a bit
difficult to understand. In this paper, the F5 algorithm is simplified as F5B
in a Buchberger's style such that it is easy to understand and implement. In
order to describe F5B, we introduce F5-reduction, which keeps the signature of
labeled polynomials unchanged after reduction. The equivalence between F5 and
F5B is also shown. At last, some versions of the F5 algorithm are illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5305</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5305</id><created>2010-06-28</created><updated>2010-09-06</updated><authors><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author><author><keyname>Garcia</keyname><forenames>David</forenames></author></authors><title>An Agent-Based Model of Collective Emotions in Online Communities</title><categories>physics.soc-ph cs.MA nlin.AO</categories><comments>European Physical Journal B (in press), version 2 with extended
  introduction, clarifications</comments><journal-ref>European Physical Journal B, vol 77, no 4 (2010) pp 533-545</journal-ref><doi>10.1140/epjb/e2010-00292-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a agent-based framework to model the emergence of collective
emotions, which is applied to online communities. Agents individual emotions
are described by their valence and arousal. Using the concept of Brownian
agents, these variables change according to a stochastic dynamics, which also
considers the feedback from online communication. Agents generate emotional
information, which is stored and distributed in a field modeling the online
medium. This field affects the emotional states of agents in a non-linear
manner. We derive conditions for the emergence of collective emotions,
observable in a bimodal valence distribution. Dependent on a saturated or a
superlinear feedback between the information field and the agent's arousal, we
further identify scenarios where collective emotions only appear once or in a
repeated manner. The analytical results are illustrated by agent-based computer
simulations. Our framework provides testable hypotheses about the emergence of
collective emotions, which can be verified by data from online communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5309</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5309</id><created>2010-06-28</created><authors><author><keyname>Kirsten</keyname><forenames>Toralf</forenames></author><author><keyname>Kolb</keyname><forenames>Lars</forenames></author><author><keyname>Hartung</keyname><forenames>Michael</forenames></author><author><keyname>Gro&#xdf;</keyname><forenames>Anika</forenames></author><author><keyname>K&#xf6;pcke</keyname><forenames>Hanna</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Data Partitioning for Parallel Entity Matching</title><categories>cs.DC</categories><comments>11 pages</comments><acm-class>H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entity matching is an important and difficult step for integrating web data.
To reduce the typically high execution time for matching we investigate how we
can perform entity matching in parallel on a distributed infrastructure. We
propose different strategies to partition the input data and generate multiple
match tasks that can be independently executed. One of our strategies supports
both, blocking to reduce the search space for matching and parallel matching to
improve efficiency. Special attention is given to the number and size of data
partitions as they impact the overall communication overhead and memory
requirements of individual match tasks. We have developed a service-based
distributed infrastructure for the parallel execution of match workflows. We
evaluate our approach in detail for different match strategies for matching
real-world product data of different web shops. We also consider caching of
in-put entities and affinity-based scheduling of match tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5311</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5311</id><created>2010-06-28</created><authors><author><keyname>Goze</keyname><forenames>Nicolas</forenames></author></authors><title>Linear Algebra in the vector space of intervals</title><categories>math.NA cs.NA</categories><msc-class>65F99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper, we have given an algebraic model to the set of
intervals. Here, we apply this model in a linear frame. We define a notion of
diagonalization of square matrices whose coefficients are intervals. But in
this case, with respect to the real case, a matrix of order $n$ could have more
than $n$ eigenvalues (the set of intervals is not factorial). We consider a
notion of central eigenvalues permits to describe criterium of diagonalization.
As application, we define a notion of Exponential mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5318</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5318</id><created>2010-06-28</created><updated>2011-01-17</updated><authors><author><keyname>Palazuelos</keyname><forenames>Carlos</forenames></author><author><keyname>Perez-Garcia</keyname><forenames>David</forenames></author><author><keyname>Villanueva</keyname><forenames>Ignacio</forenames></author></authors><title>Tripartite probability distributions and communication complexity</title><categories>quant-ph cs.CC</categories><comments>This paper has been withdrawn by the authors. We believe the main
  result to be true, but the proof is not correct. We are at the moment trying
  to fix it</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every tripartite quantum correlation generated with a Schmidt
state (in particular every correlation generated with the GHZ state) can be
simulated with the sending of two bits of classical communication from Alice to
Bob and Charlie plus the sending of two bits of classical communication from
Bob to Charlie. This extends recent results which showed that the maximal
violation of Bell inequalities attainable by these correlations is uniformly
bounded. For simplicity, we state and prove the result for three parties, but
the generalization to the case of $n$ parties follows easily.
  We also show that every $n$-partite probability distribution generated with
local resources plus $c$-bits of local communication can violate a Bell
inequality by at most a factor of $2^c$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5352</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5352</id><created>2010-06-28</created><updated>2011-08-04</updated><authors><author><keyname>Goldberg</keyname><forenames>Paul W.</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos H.</forenames></author><author><keyname>Savani</keyname><forenames>Rahul</forenames></author></authors><title>The Complexity of the Homotopy Method, Equilibrium Selection, and
  Lemke-Howson Solutions</title><categories>cs.GT cs.CC</categories><comments>23 pages, 1 figure; to appear in FOCS 2011 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the widely used homotopy method for solving fixpoint problems,
as well as the Harsanyi-Selten equilibrium selection process for games, are
PSPACE-complete to implement. Extending our result for the Harsanyi-Selten
process, we show that several other homotopy-based algorithms for finding
equilibria of games are also PSPACE-complete to implement. A further
application of our techniques yields the result that it is PSPACE-complete to
compute any of the equilibria that could be found via the classical
Lemke-Howson algorithm, a complexity-theoretic strengthening of the result in
[Savani and von Stengel]. These results show that our techniques can be widely
applied and suggest that the PSPACE-completeness of implementing homotopy
methods is a general principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5354</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5354</id><created>2010-06-28</created><authors><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Orlandi</keyname><forenames>Alessio</forenames></author><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author></authors><title>Optimal Trade-Off for Succinct String Indexes</title><categories>cs.DS cs.IT math.IT</categories><comments>Accepted at ICALP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let s be a string whose symbols are solely available through access(i), a
read-only operation that probes s and returns the symbol at position i in s.
Many compressed data structures for strings, trees, and graphs, require two
kinds of queries on s: select(c, j), returning the position in s containing the
jth occurrence of c, and rank(c, p), counting how many occurrences of c are
found in the first p positions of s. We give matching upper and lower bounds
for this problem, improving the lower bounds given by Golynski [Theor. Comput.
Sci. 387 (2007)] [PhD thesis] and the upper bounds of Barbay et al. [SODA
2007]. We also present new results in another model, improving on Barbay et al.
[SODA 2007] and matching a lower bound of Golynski [SODA 2009]. The main
contribution of this paper is to introduce a general technique for proving
lower bounds on succinct data structures, that is based on the access patterns
of the supported operations, abstracting from the particular operations at
hand. For this, it may find application to other interesting problems on
succinct data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5367</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5367</id><created>2010-06-28</created><authors><author><keyname>Kunegis</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>De Luca</keyname><forenames>Ernesto W.</forenames></author><author><keyname>Albayrak</keyname><forenames>Sahin</forenames></author></authors><title>The Link Prediction Problem in Bipartite Networks</title><categories>cs.LG physics.soc-ph</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define and study the link prediction problem in bipartite networks,
specializing general link prediction algorithms to the bipartite case. In a
graph, a link prediction function of two vertices denotes the similarity or
proximity of the vertices. Common link prediction functions for general graphs
are defined using paths of length two between two nodes. Since in a bipartite
graph adjacency vertices can only be connected by paths of odd lengths, these
functions do not apply to bipartite graphs. Instead, a certain class of graph
kernels (spectral transformation kernels) can be generalized to bipartite
graphs when the positive-semidefinite kernel constraint is relaxed. This
generalization is realized by the odd component of the underlying spectral
transformation. This construction leads to several new link prediction
pseudokernels such as the matrix hyperbolic sine, which we examine for rating
graphs, authorship graphs, folksonomies, document--feature networks and other
types of bipartite networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5372</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5372</id><created>2010-06-24</created><updated>2011-01-11</updated><authors><author><keyname>Bedratyuk</keyname><forenames>Leonid</forenames></author></authors><title>The MAPLE package for calculating Poincar\'e series</title><categories>math.AG cs.SC math.AC</categories><comments>Multivariate procedures added. The package can be obtained from the
  web https://sites.google.com/site/bedratyuklp/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We offer a Maple package {\tt Poincare\_Series} for calculating the
Poincar\'e series for the algebras of invariants/covariants of binary forms,
for the algebras of joint invariants/covariants of several binary forms, for
the kernel of Weitzenb\&quot;ock derivations and for the multivariate Poincar\'e
series of algebras of joint invariants/covariants of several binary forms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5376</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5376</id><created>2010-06-28</created><authors><author><keyname>Stillwell</keyname><forenames>Mark</forenames></author><author><keyname>Schanzenbach</keyname><forenames>David</forenames></author><author><keyname>Vivien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Casanova</keyname><forenames>Henri</forenames></author></authors><title>Resource Allocation using Virtual Clusters</title><categories>cs.DC</categories><comments>University of Hawai'i at M{\=a}noa Department of Information and
  Computer Sciences Technical Report</comments><report-no>ICS2008-09-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we demonstrate the potential utility of resource allocation
management systems that use virtual machine technology for sharing parallel
computing resources among competing jobs. We formalize the resource allocation
problem with a number of underlying assumptions, determine its complexity,
propose several heuristic algorithms to find near-optimal solutions, and
evaluate these algorithms in simulation. We find that among our algorithms one
is very efficient and also leads to the best resource allocations. We then
describe how our approach can be made more general by removing several of the
underlying assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5381</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5381</id><created>2010-06-28</created><authors><author><keyname>Anghel</keyname><forenames>Catalin</forenames></author></authors><title>Cresterea securitatii sistemelor informatice si de comunicatii prin
  criptografia cuantica</title><categories>cs.CR</categories><comments>24 pag</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Catch 22 of cryptography - &quot;Before two parties can communicate in secret,
they must first communicate in secret&quot;. The weakness of classical cryptographic
communication systems is that secret communication can only take place after a
key is communicated in secret over a totally secure communication channel. Here
comes quantum key distribution which takes advantage of certain phenomena that
occur at the subatomic level, so that any attempt by an enemy to obtain the
bits in a key not only fails, but gets detected as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5398</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5398</id><created>2010-06-28</created><updated>2010-11-15</updated><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>Ammar</keyname><forenames>Mostafa</forenames></author><author><keyname>Zegura</keyname><forenames>Ellen</forenames></author></authors><title>From Encounters to Plausible Mobility</title><categories>cs.NI</categories><comments>Accepted for publication in the Pervasive and Mobile Computing
  Journal</comments><doi>10.1016/j.pmcj.2010.11.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring plausible node mobility based only on information from wireless
contact traces is a difficult problem. Working with mobility information allows
richer protocol simulations, particularly in dense networks, but requires
complex set-ups to measure. On the other hand, contact information is easier to
measure but only allows for simplistic simulation models. In a contact trace a
lot of node movement information is irretrievably lost so the original
positions and velocities are in general out of reach. In this paper, we propose
a fast heuristic algorithm, inspired by dynamic force-based graph drawing,
capable of inferring a plausible movement from any contact trace, and evaluate
it on both synthetic and real-life contact traces. Our results reveal that (i)
the quality of the inferred mobility is directly linked to the precision of the
measured contact trace, and (ii) the simple addition of appropriate
anticipation forces between nodes leads to an accurate inferred mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5436</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5436</id><created>2010-06-28</created><authors><author><keyname>Pushp</keyname><forenames>Saumay</forenames></author></authors><title>Merging Two Arima Models for Energy Optimization in WSN</title><categories>cs.NI</categories><comments>Rough Work, 10 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of ARIMA model in Sensor network The basic idea of our energy efficient
information collection scheme is to suppress data transmission if the data
sampled by sensor nodes are predictable by the sink node. This is done in two
phases 1) Preliminary Data Collection- During this phase sink node collects
enough data so that it can build up ARIMA model for each node. Then sink node
selects a model for the particular node and sends back the corresponding model
parameters to the node and also keeps them with it. Selecting the model for a
node there is a tradeoff between energy consumption and accuracy of prediction.
So we choose the model according to C = {\alpha} xMAE + (1 - {\alpha}) x rtran
0=&lt; {\alpha} =&lt;1 where the model should minimize C. Here MAE is Mean Absolute
Error which is normalized by some predefined error tolerance and rtran is the
ratio of number of samples transmitted over total number of samples. 2)
Adaptive Data Collection- After the sensor node has received the model
parameters it checks each actual data value with the data value calculated from
the parameters received. If there is deviation beyond some predefined error
tolerance then only it sends the original data value to the sink node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5440</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5440</id><created>2010-06-28</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author></authors><title>Listing All Maximal Cliques in Sparse Graphs in Near-optimal Time</title><categories>cs.DS cs.DM</categories><comments>13 pages, 3 figures</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degeneracy of an $n$-vertex graph $G$ is the smallest number $d$ such
that every subgraph of $G$ contains a vertex of degree at most $d$. We show
that there exists a nearly-optimal fixed-parameter tractable algorithm for
enumerating all maximal cliques, parametrized by degeneracy. To achieve this
result, we modify the classic Bron--Kerbosch algorithm and show that it runs in
time $O(dn3^{d/3})$. We also provide matching upper and lower bounds showing
that the largest possible number of maximal cliques in an $n$-vertex graph with
degeneracy $d$ (when $d$ is a multiple of 3 and $n\ge d+3$) is $(n-d)3^{d/3}$.
Therefore, our algorithm matches the $\Theta(d(n-d)3^{d/3})$ worst-case output
size of the problem whenever $n-d=\Omega(n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5442</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5442</id><created>2010-06-14</created><authors><author><keyname>Knabe</keyname><forenames>Christoph</forenames></author></authors><title>Static and Dynamic Quality Assurance by Aspect Oriented Techniques</title><categories>cs.SE cs.PL</categories><comments>18 pages, 35 TOC items, 38 code snippets, 1 table, 6 references, 21
  source files with the aspects on accompanying web site</comments><acm-class>D.1.m; D.2.3; D.2.11; D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The overall goal of the described research project was to create applicable
quality assurance patterns for Java software systems using the aspect-oriented
programming language extension AspectJ 5. We tried to develop aspects to check
static quality criteria as a variable mutator convention and architectural
layering rules. We successfully developed aspects for automating the following
dynamic quality criteria: Parameterized Exception Chaining, Comfortable
Declaration of Parameterized Exceptions, Not-Null Checking of Reference
Variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5445</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5445</id><created>2010-06-28</created><authors><author><keyname>Liu</keyname><forenames>An</forenames><affiliation>Eugene</affiliation></author><author><keyname>Youjian</keyname><affiliation>Eugene</affiliation></author><author><keyname>Liu</keyname></author><author><keyname>Xiang</keyname><forenames>Haige</forenames></author><author><keyname>Luo</keyname><forenames>Wu</forenames></author></authors><title>Technical Report: MIMO B-MAC Interference Network Optimization under
  Rate Constraints by Polite Water-filling and Duality</title><categories>cs.IT math.IT</categories><comments>43 pages, 9 figures, and 10 tables. Peking University and University
  of Colorado at Boulder Joint Technical Report, June 28th, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We take two new approaches to design efficient algorithms for transmitter
optimization under rate constraints to guarantee the Quality of Service in
general MIMO interference networks, named B-MAC Networks, which is a
combination of multiple interfering broadcast channels (BC) and multiaccess
channels (MAC). Two related optimization problems, maximizing the minimum of
weighted rates under a sum-power constraint and minimizing the sum-power under
rate constraints, are considered. The first approach takes advantage of
existing efficient algorithms for SINR problems by building a bridge between
rate and SINR through the design of optimal mappings between them so that the
problems can be converted to SINR constraint problems. The approach can be
applied to other optimization problems as well. The second approach employs
polite water-filling, which is the optimal network version of water-filling
that we recently found. It replaces almost all generic optimization algorithms
currently used for networks and reduces the complexity while demonstrating
superior performance even in non-convex cases. Both centralized and distributed
algorithms are designed and the performance is analyzed in addition to numeric
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5451</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5451</id><created>2010-06-28</created><authors><author><keyname>Nilsson</keyname><forenames>Kim K.</forenames></author><author><keyname>Moeller-Nilsson</keyname><forenames>Ole</forenames></author></authors><title>Future management needs of a &quot;software-driven&quot; science community</title><categories>astro-ph.IM cs.CY</categories><comments>7 pages, 3 figures, as presented at SPIE Astronomical instrumentation
  2010</comments><doi>10.1117/12.858326</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work of astronomers is getting more complex and advanced as the progress
of computer development occurs. With improved computing capabilities and
increased data flow, more sophisticated software is required in order to
interpret, and fully exploit, astronomic data. However, it is not possible for
every astronomer to also be a software specialist. As history has shown, the
work of scientists always becomes increasingly specialised, and we here argue
in favour of another, at least partial, split between &quot;programmers&quot; and
&quot;interpreters&quot;. In this presentation we outline our vision for a new approach
and symbiosis between software specialists and scientists, and present its
advantages along with a simple test case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5493</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5493</id><created>2010-06-28</created><authors><author><keyname>Zinoviev</keyname><forenames>Dmitry</forenames></author><author><keyname>Duong</keyname><forenames>Vy</forenames></author><author><keyname>Zhang</keyname><forenames>Honggang</forenames></author></authors><title>A Game Theoretical Approach to Modeling Information Dissemination in
  Social Networks</title><categories>cs.GT</categories><comments>6 pages, 5 figures, presented at The SUMMER 4th International
  Conference on Knowledge Generation, Communication and Management: KGCM 2010</comments><journal-ref>D. Zinoviev, V. Duong, and H. Zhang, &quot;A Game Theoretical Approach
  to Modeling Information Dissemination in Social Networks,&quot; in Proc.
  IMCCIC-2010, Vol. I, pp. 407--412, Orlando, FL, April 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One major function of social networks (e.g., massive online social networks)
is the dissemination of information such as scientific knowledge, news, and
rumors. Information can be propagated by the users of the network via natural
connections in written, oral or electronic form. The information passing from a
sender to a receiver intrinsically involves both of them considering their
self-perceived knowledge, reputation, and popularity, which further determine
their decisions of whether or not to forward the information and whether or not
to provide feedback. To understand such human aspects of the information
dissemination, we propose a game theoretical model of the information
forwarding and feedback mechanisms in a social network that take into account
the personalities of the sender and the receiver (including their perceived
knowledgeability, reputation, and desire for popularity) and the global
characteristics of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5502</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5502</id><created>2010-06-29</created><authors><author><keyname>White</keyname><forenames>Jonathan</forenames></author><author><keyname>Banerjee</keyname><forenames>Nilanjan</forenames></author></authors><title>Mirage: Mitigating Illicit Inventorying in a RFID Enabled Retail
  Environment</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given its low dollar and maintenance cost, RFID is poised to become the
enabling technology for inventory control and supply chain management. However,
as an outcome of its low cost, RFID based inventory control is susceptible to
pernicious security and privacy threats. A deleterious attack on such a system
is corporate espionage, where attackers through illicit inventorying infer
sales and restocking trends for products. In this paper, we first present
plausible aftermaths of corporate espionage using real data from online
sources. Second, to mitigate corporate espionage in a retail store environment,
we present a simple lowcost system called Mirage. Mirage uses additional
programmable low cost passive RFID tags called honeytokens to inject noise in
retail store inven-torying. Using a simple history based algorithm that
controls activation and de-activation of honeytokens, Mirage randomizes sales
and restocking trends. We evaluate Mirage in a real warehouse environment using
a commercial off-the-shelf Motorola MC9090 handheld RFID reader and over 450
Gen2 low cost RFID tags. We show that Mirage successfully flattens and
randomizes sales and restocking trends while adding minimal cost to inventory
control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5511</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5511</id><created>2010-06-29</created><updated>2010-07-04</updated><authors><author><keyname>Kharal</keyname><forenames>Athar</forenames></author></authors><title>Soft Approximations and uni-int Decision Making</title><categories>cs.AI</categories><comments>This paper has been withdrawn by the author due to further expansion
  of this work. Work is also submitted to a peer reviewed journal and is
  expected to be published very soon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Notions of core, support and inversion of a soft set have been de ned and
studied. Soft approximations are soft sets developed through core and support,
and are used for granulating the soft space. Membership structure of a soft set
has been probed in and many interesting properties presented. The mathematical
apparatus developed so far in this paper yields a detailed analysis of two
works viz. [N. Cagman, S. Enginoglu, Soft set theory and uni-int decision
making, European Jr. of Operational Research (article in press, available
online 12 May 2010)] and [N. Cagman, S. Enginoglu, Soft matrix theory and its
decision making, Computers and Mathematics with Applications 59 (2010) 3308 -
3314.]. We prove (Theorem 8.1) that uni-int method of Cagman is equivalent to a
core-support expression which is computationally far less expansive than
uni-int. This also highlights some shortcomings in Cagman's uni-int method and
thus motivates us to improve the method. We rst suggest an improvement in
uni-int method and then present a new conjecture to solve the optimum choice
problem given by Cagman and Enginoglu. Our Example 8.6 presents a case where
the optimum choice is intuitively clear yet both uni-int methods (Cagman's and
our improved one) give wrong answer but the new conjecture solves the problem
correctly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5516</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5516</id><created>2010-06-29</created><authors><author><keyname>vagvolgyi</keyname><forenames>Sandor</forenames></author></authors><title>Rewriting Preserving Recognizability of Finite Tree Languages</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that left-linear generalized semi-monadic TRSs effectively preserving
recognizability of finite tree languages (are EPRF-TRSs). We show that
reachability, joinability, and local confluence are decidable for EPRF-TRSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5561</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5561</id><created>2010-06-29</created><updated>2010-09-02</updated><authors><author><keyname>K&#xf8;ber</keyname><forenames>Petter Kristian</forenames><affiliation>University of Oslo</affiliation></author></authors><title>Domain Representable Spaces Defined by Strictly Positive Induction</title><categories>cs.LO</categories><comments>48 pages. Accepted for publication in Logical Methods in Computer
  Science</comments><proxy>LMCS</proxy><acm-class>F.1.1, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (August 26,
  2010) lmcs:955</journal-ref><doi>10.2168/LMCS-6(3:9)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recursive domain equations have natural solutions. In particular there are
domains defined by strictly positive induction. The class of countably based
domains gives a computability theory for possibly non-countably based
topological spaces. A $ qcb_{0} $ space is a topological space characterized by
its strong representability over domains. In this paper, we study strictly
positive inductive definitions for $ qcb_{0} $ spaces by means of domain
representations, i.e. we show that there exists a canonical fixed point of
every strictly positive operation on $qcb_{0} $ spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5572</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5572</id><created>2010-06-29</created><authors><author><keyname>Inoue</keyname><forenames>Hiroaki</forenames></author></authors><title>A Multi-Core Processor Platform for Open Embedded Systems</title><categories>cs.DC</categories><comments>A dissertation presented to the graduate school of science and
  technology of Keio University in candidacy for the degree of Doctor of
  Philosophy in Engineering, September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent proliferation of embedded systems has generated a bold new paradigm,
known as open embedded systems. While traditional embedded systems provide only
closed base applications (natively-installed software) to users, open embedded
systems allow the users to freely execute open applications
(additionally-installed software) in order to meet various user requirements,
such as user personalization and device coordination. Key to the success of
platforms required for open embedded systems is the achievement of both the
scalable extension of base applications and the secure execution of open
applications. Most existing platforms, however, have focused on either scalable
or secure execution, limiting their applicability. This dissertation presents a
new secure platform using multi-core processors, which achieves both
scalability and security. Four techniques feature the new platform: (1)
seamless communication, by which legacy applications designed for a single
processor make it possible to be executed on multiple processors without any
software modifications; (2) secure processor partitioning with hardware
support, by which Operating Systems (OSs) required for base and open
applications are securely executed on separate processors; (3) asymmetric
virtualization, by which many OSs over the number of processors are securely
executed under secure processor partitioning; and (4) secure dynamic
partitioning, by which the number of processors allocated to individual OSs
makes it possible to be dynamically changed under secure processor
partitioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5621</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5621</id><created>2010-06-29</created><authors><author><keyname>Ganian</keyname><forenames>Robert</forenames></author><author><keyname>Hlin&#x11b;n&#xfd;</keyname><forenames>Petr</forenames></author><author><keyname>Obdr&#x17e;&#xe1;lek</keyname><forenames>Jan</forenames></author></authors><title>Better algorithms for satisfiability problems for formulas of bounded
  rank-width</title><categories>cs.DM cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a parameterized polynomial algorithm for the propositional model
counting problem #SAT, the runtime of which is single-exponential in the
rank-width of a formula. Previously, analogous algorithms have been known --
e.g.~[Fischer, Makowsky, and Ravve] -- with a single-exponential dependency on
the clique-width of a formula. Our algorithm thus presents an exponential
runtime improvement (since clique-width reaches up to exponentially higher
values than rank-width), and can be of practical interest for small values of
rank-width. We also provide an algorithm for the MAX-SAT problem along the same
lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5643</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5643</id><created>2010-06-29</created><authors><author><keyname>Portillo</keyname><forenames>&#xc1;lvaro Reb&#xf3;n</forenames></author><author><keyname>Walker</keyname><forenames>Scott</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author></authors><title>A Reflective Approach to Providing Flexibility in Application
  Distribution</title><categories>cs.DC</categories><comments>2nd International Workshop on Reflective and Adaptive Middleware,
  ACM/IFIP/USENIX International Middleware Conference (Middleware 2003), Rio de
  Janeiro, Brazil, pp.95-99</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current middleware systems suffer from drawbacks. Often one is forced to make
decisions early in the design process about which classes may participate in
inter-machine communication. Further, application level and middleware specific
semantics cannot be separated forcing an unnatural design. The RAFDA project
proposes to adress these deficiencies by creating an adaptive, reflective
framework that enables the transformation of non-distributed applications into
isomorphic applications whose distribution architecture is flexible. This paper
describes the code transformation techniques that have been developed as part
of the project. The system enables the distribution of a program according to a
flexible configuration without user intervention. Proxy objects can then be
substituted, permitting cross-address space communication. The distributed
program can adapt to its environment by dynamically altering its distribution
boundaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5657</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5657</id><created>2010-06-29</created><authors><author><keyname>Mileo</keyname><forenames>A.</forenames></author><author><keyname>Merico</keyname><forenames>D.</forenames></author><author><keyname>Bisiani</keyname><forenames>R.</forenames></author></authors><title>Reasoning Support for Risk Prediction and Prevention in Independent
  Living</title><categories>cs.AI</categories><comments>36 pages, 5 figures, 10 tables. To appear in Theory and Practice of
  Logic Programming (TPLP)</comments><acm-class>I.2.1; I.2.3; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years there has been growing interest in solutions for the delivery
of clinical care for the elderly, due to the large increase in aging
population. Monitoring a patient in his home environment is necessary to ensure
continuity of care in home settings, but, to be useful, this activity must not
be too invasive for patients and a burden for caregivers. We prototyped a
system called SINDI (Secure and INDependent lIving), focused on i) collecting a
limited amount of data about the person and the environment through Wireless
Sensor Networks (WSN), and ii) inferring from these data enough information to
support caregivers in understanding patients' well being and in predicting
possible evolutions of their health. Our hierarchical logic-based model of
health combines data from different sources, sensor data, tests results,
common-sense knowledge and patient's clinical profile at the lower level, and
correlation rules between health conditions across upper levels. The logical
formalization and the reasoning process are based on Answer Set Programming.
The expressive power of this logic programming paradigm makes it possible to
reason about health evolution even when the available information is incomplete
and potentially incoherent, while declarativity simplifies rules specification
by caregivers and allows automatic encoding of knowledge. This paper describes
how these issues have been targeted in the application scenario of the SINDI
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5661</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5661</id><created>2010-06-29</created><authors><author><keyname>Coutaz</keyname><forenames>Joelle</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Dupuy-Chessa</keyname><forenames>Sophie</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Lachenal</keyname><forenames>Christophe</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>Rey</keyname><forenames>Gaetan</forenames></author><author><keyname>Zirintsis</keyname><forenames>Evangelos</forenames></author></authors><title>Working Document on Gloss Ontology</title><categories>cs.DC</categories><report-no>Global Smart Spaces Project IST-2000-26070 Report D9.2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the Gloss Ontology. The ontology and associated class
model are organised into several packages. Section 2 describes each package in
detail, while Section 3 contains a summary of the whole ontology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5677</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5677</id><created>2010-06-29</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author></authors><title>Shape of Traveling Densities with Extremum Statistical Complexity</title><categories>nlin.PS cs.IT math.IT</categories><comments>11 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the behavior of statistical complexity in several
systems where two identical densities that travel in opposite direction cross
each other. Besides the crossing between two Gaussian, rectangular and
triangular densities studied in a previous work, we also investigate in detail
the crossing between two exponential and two gamma distributions. For all these
cases, the shape of the total density presenting an extreme value in complexity
is found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5686</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5686</id><created>2010-06-29</created><authors><author><keyname>Xie</keyname><forenames>Nan</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author></authors><title>Geometric Approximations of Some Aloha-like Stability Regions</title><categories>cs.IT math.IT</categories><comments>Presented at IEEE ISIT 2010 (Austin, TX)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most bounds on the stability region of Aloha give necessary and sufficient
conditions for the stability of an arrival rate vector under a specific
contention probability (control) vector. But such results do not yield
easy-to-check bounds on the overall Aloha stability region because they
potentially require checking membership in an uncountably infinite number of
sets parameterized by each possible control vector. In this paper we consider
an important specific inner bound on Aloha that has this property of difficulty
to check membership in the set. We provide ellipsoids (for which membership is
easy-to-check) that we conjecture are inner and outer bounds on this set. We
also study the set of controls that stabilize a fixed arrival rate vector; this
set is shown to be a convex set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5691</identifier>
 <datestamp>2013-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5691</id><created>2010-06-29</created><updated>2013-01-22</updated><authors><author><keyname>Perry</keyname><forenames>Ohad</forenames></author><author><keyname>Whitt</keyname><forenames>Ward</forenames></author></authors><title>A Fluid Limit for an Overloaded X Model Via a Stochastic Averaging
  Principle</title><categories>math.PR cs.PF</categories><comments>There are 55 pages, 46 references and 0 figures</comments><msc-class>60F17, 60K25 (Primary) 60G70, 90B22 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a many-server heavy-traffic fluid limit for an overloaded Markovian
queueing system having two customer classes and two service pools, known in the
call-center literature as the X model. The system uses the
fixed-queue-ratio-with-thresholds (FQR-T) control, which we proposed in a
recent paper as a way for one service system to help another in face of an
unexpected overload. Under FQR-T, customers are served by their own service
pool until a threshold is exceeded. Then, one-way sharing is activated with
customers from one class allowed to be served in both pools. After the control
is activated, it aims to keep the two queues at a pre-specified fixed ratio.
For large systems that fixed ratio is achieved approximately. For the fluid
limit, or FWLLN, we consider a sequence of properly scaled X models in overload
operating under FQR-T. Our proof of the FWLLN follows the compactness approach,
i.e., we show that the sequence of scaled processes is tight, and then show
that all converging subsequences have the specified limit. The characterization
step is complicated because the queue-difference processes, which determine the
customer-server assignments, remain stochastically bounded, and need to be
considered without spatial scaling. Asymptotically, these queue-difference
processes operate in a faster time scale than the fluid-scaled processes. In
the limit, due to a separation of time scales, the driving processes converge
to a time-dependent steady state (or local average) of a time-varying
fast-time-scale process (FTSP). This averaging principle (AP) allows us to
replace the driving processes with the long-run average behavior of the FTSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5739</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5739</id><created>2010-06-29</created><authors><author><keyname>Kounchev</keyname><forenames>Ognyan</forenames></author><author><keyname>Kalaglarsky</keyname><forenames>Damyan</forenames></author><author><keyname>Tsvetkov</keyname><forenames>Milcho</forenames></author></authors><title>Polyharmonic Daubechies type wavelets in Image Processing and Astronomy,
  II</title><categories>math.NA cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the application of the polyharmonic subdivision wavelets (of
Daubechies type) to Image Processing, in particular to Astronomical Images. The
results show an essential advantage over some standard multivariate wavelets
and a potential for better compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5745</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5745</id><created>2010-06-29</created><authors><author><keyname>Garg</keyname><forenames>Poonam</forenames></author></authors><title>Evolutionary Computation Algorithms for Cryptanalysis: A Study</title><categories>cs.CR cs.NE</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The cryptanalysis of various cipher problems can be formulated as NP-Hard
combinatorial problem. Solving such problems requires time and/or memory
requirement which increases with the size of the problem. Techniques for
solving combinatorial problems fall into two broad groups - exact algorithms
and Evolutionary Computation algorithms. An exact algorithms guarantees that
the optimal solution to the problem will be found. The exact algorithms like
branch and bound, simplex method, brute force etc methodology is very
inefficient for solving combinatorial problem because of their prohibitive
complexity (time and memory requirement). The Evolutionary Computation
algorithms are employed in an attempt to find an adequate solution to the
problem. A Evolutionary Computation algorithm - Genetic algorithm, simulated
annealing and tabu search were developed to provide a robust and efficient
methodology for cryptanalysis. The aim of these techniques to find sufficient
&quot;good&quot; solution efficiently with the characteristics of the problem, instead of
the global optimum solution, and thus it also provides attractive alternative
for the large scale applications. This paper focuses on the methodology of
Evolutionary Computation algorithms .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5748</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5748</id><created>2010-06-29</created><updated>2010-07-08</updated><authors><author><keyname>Froese</keyname><forenames>Brittany D.</forenames></author><author><keyname>Oberman</keyname><forenames>Adam M.</forenames></author></authors><title>Fast finite difference solvers for singular solutions of the elliptic
  Monge-Amp\`ere equation</title><categories>math.NA cs.NA math-ph math.MP</categories><comments>23 pages, 4 figures, 4 tables; added arxiv links to references, added
  coments</comments><doi>10.1016/j.jcp.2010.10.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The elliptic Monge-Ampere equation is a fully nonlinear Partial Differential
Equation which originated in geometric surface theory, and has been applied in
dynamic meteorology, elasticity, geometric optics, image processing and image
registration. Solutions can be singular, in which case standard numerical
approaches fail. In this article we build a finite difference solver for the
Monge-Ampere equation, which converges even for singular solutions. Regularity
results are used to select a priori between a stable, provably convergent
monotone discretization and an accurate finite difference discretization in
different regions of the computational domain. This allows singular solutions
to be computed using a stable method, and regular solutions to be computed more
accurately. The resulting nonlinear equations are then solved by Newton's
method. Computational results in two and three dimensions validate the claims
of accuracy and solution speed. A computational example is presented which
demonstrates the necessity of the use of the monotone scheme near
singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5749</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5749</id><created>2010-06-29</created><authors><author><keyname>Garg</keyname><forenames>Poonam</forenames></author></authors><title>Critical Success factors for Enterprise Resource Planning implementation
  in Indian Retail Industry: An Exploratory study</title><categories>cs.OH</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enterprise resource Planning (ERP) has become a key business driver in
today's world. Retailers are also trying to reap in the benefits of the ERP. In
most large Indian Retail Industry ERP systems have replaced nonintegrated
information systems with integrated and maintainable software. Retail ERP
solution integrates demand and supply effectively to help improve bottom line.
The implementation of ERP systems in such firms is a difficult task. So far,
ERP implementations have yielded more failures than successes. Very few
implementation failures are recorded in the literature because few companies
wish to publicize their implementation failure. This paper explores and
validates the existing literature empirically to find out the critical success
factors that lead to the success of ERP in context to Indian retail industry.
The findings of the results provide valuable insights for the researchers and
practitioners who are interested in implementing Enterprise Resource Planning
systems in retail industry, how best they can utilize their limited resources
and to pay adequate attention to those factors that are most likely to have an
impact upon the implementation of the ERP system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5761</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5761</id><created>2010-06-29</created><authors><author><keyname>Di Ruscio</keyname><forenames>Davide</forenames></author><author><keyname>L&#xe4;mmel</keyname><forenames>Ralf</forenames></author><author><keyname>Pierantonio</keyname><forenames>Alfonso</forenames></author></authors><title>Automated co-evolution of GMF editor models</title><categories>cs.SE</categories><comments>15 pages</comments><acm-class>D.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Eclipse Graphical Modeling (GMF) Framework provides the major approach
for implementing visual languages on top of the Eclipse platform. GMF relies on
a family of modeling languages to describe different aspects of the visual
language and its implementation in an editor. GMF uses a model-driven approach
to map the different GMF models to Java code. The framework, as it stands,
provides very little support for evolution. In particular, there is no support
for propagating changes from say the domain model (i.e., the abstract syntax of
the visual language) to other models. We analyze the resulting co-evolution
challenge, and we provide a transformation-based solution, say GMF model
adapters, that serve the propagation of abstract-syntax changes based on the
interpretation of difference models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5762</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5762</id><created>2010-06-29</created><updated>2010-11-08</updated><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Wong</keyname><forenames>Wing Shing</forenames></author></authors><title>Construction and Applications of CRT Sequences</title><categories>cs.IT math.IT</categories><comments>16 pages, 5 figures. Some typos in Section V are corrected</comments><journal-ref>IEEE Trans. on Information Theory, vol. 56, no. 11, p.5780-5795,
  Nov, 2010</journal-ref><doi>10.1109/TIT.2010.2070550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protocol sequences are used for channel access in the collision channel
without feedback. Each user accesses the channel according to a deterministic
zero-one pattern, called the protocol sequence. In order to minimize
fluctuation of throughput due to delay offsets, we want to construct protocol
sequences whose pairwise Hamming cross-correlation is as close to a constant as
possible. In this paper, we present a construction of protocol sequences which
is based on the bijective mapping between one-dimensional sequence and
two-dimensional array by the Chinese Remainder Theorem (CRT). In the
application to the collision channel without feedback, a worst-case lower bound
on system throughput is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5768</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5768</id><created>2010-06-30</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>A Unified Formal Description of Arithmetic and Set Theoretical Data
  Types</title><categories>cs.SC cs.LO</categories><comments>15 pages, preprint of CALCULEMUS 2010 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a &quot;shared axiomatization&quot; of natural numbers and hereditarily
finite sets built around a polymorphic abstraction of bijective base-2
arithmetics.
  The &quot;axiomatization&quot; is described as a progressive refinement of Haskell type
classes with examples of instances converging to an efficient implementation in
terms of arbitrary length integers and bit operations. As an instance, we
derive algorithms to perform arithmetic operations efficiently directly with
hereditarily finite sets.
  The self-contained source code of the paper is available at
http://logic.cse.unt.edu/tarau/research/2010/unified.hs .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5787</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5787</id><created>2010-06-30</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Hu</keyname><forenames>Bo</forenames><affiliation>DIE</affiliation></author><author><keyname>Guillaume</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Fatigue evaluation in maintenance and assembly operations by digital
  human simulation</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Virtual Reality 14, 1 (2010) 339-352</journal-ref><doi>10.1007/s10055-010-0156-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual human techniques have been used a lot in industrial design in order
to consider human factors and ergonomics as early as possible. The physical
status (the physical capacity of virtual human) has been mostly treated as
invariable in the current available human simulation tools, while indeed the
physical capacity varies along time in an operation and the change of the
physical capacity depends on the history of the work as well. Virtual Human
Status is proposed in this paper in order to assess the difficulty of manual
handling operations, especially from the physical perspective. The decrease of
the physical capacity before and after an operation is used as an index to
indicate the work difficulty. The reduction of physical strength is simulated
in a theoretical approach on the basis of a fatigue model in which fatigue
resistances of different muscle groups were regressed from 24 existing maximum
endurance time (MET) models. A framework based on digital human modeling
technique is established to realize the comparison of physical status. An
assembly case in airplane assembly is simulated and analyzed under the
framework. The endurance time and the decrease of the joint moment strengths
are simulated. The experimental result in simulated operations under laboratory
conditions confirms the feasibility of the theoretical approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5794</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5794</id><created>2010-06-30</created><authors><author><keyname>Zirintsis</keyname><forenames>Evangelos</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author></authors><title>Report on the XBase Project</title><categories>cs.DB</categories><report-no>University of St Andrews CS/03/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This project addressed the conceptual fundamentals of data storage,
investigating techniques for provision of highly generic storage facilities
that can be tailored to produce various individually customised storage
infrastructures, compliant to the needs of particular applications. This
requires the separation of mechanism and policy wherever possible. Aspirations
include: actors, whether users or individual processes, should be able to bind
to, update and manipulate data and programs transparently with respect to their
respective locations; programs should be expressed independently of the storage
and network technology involved in their execution; storage facilities should
be structure-neutral so that actors can impose multiple interpretations over
information, simultaneously and safely; information should not be discarded so
that arbitrary historical views are supported; raw stored information should be
open to all; where security restrictions on its use are required this should be
achieved using cryptographic techniques. The key advances of the research were:
1) the identification of a candidate set of minimal storage system building
blocks, which are sufficiently simple to avoid encapsulating policy where it
cannot be customised by applications, and composable to build highly flexible
storage architectures 2) insight into the nature of append-only storage
components, and the issues arising from their application to common storage
use-cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5802</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5802</id><created>2010-06-30</created><updated>2013-08-08</updated><authors><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author><author><keyname>Riera</keyname><forenames>Constanza</forenames></author><author><keyname>Knudsen</keyname><forenames>Joakim Grahl</forenames></author></authors><title>On Graphs and Codes Preserved by Edge Local Complementation</title><categories>math.CO cs.IT math.IT</categories><comments>23 pages, 16 figures</comments><msc-class>94B05 (Primary) 05C30, 94A15, 05C75 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orbits of graphs under local complementation (LC) and edge local
complementation (ELC) have been studied in several different contexts. For
instance, there are connections between orbits of graphs and error-correcting
codes. We define a new graph class, ELC-preserved graphs, comprising all graphs
that have an ELC orbit of size one. Through an exhaustive search, we find all
ELC-preserved graphs of order up to 12 and all ELC-preserved bipartite graphs
of order up to 16. We provide general recursive constructions for infinite
families of ELC-preserved graphs, and show that all known ELC-preserved graphs
arise from these constructions or can be obtained from Hamming codes. We also
prove that certain pairs of ELC-preserved graphs are LC equivalent. We define
ELC-preserved codes as binary linear codes corresponding to bipartite
ELC-preserved graphs, and study the parameters of such codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5804</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5804</id><created>2010-06-30</created><authors><author><keyname>Sage</keyname><forenames>Aled</forenames></author></authors><title>Observation-Driven Configuration of Complex Software Systems</title><categories>cs.SE</categories><comments>PhD Thesis, University of St Andrews, 2003. Supervisor: Graham Kirby</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever-increasing complexity of software systems makes them hard to
comprehend, predict and tune due to emergent properties and non-deterministic
behaviour. Complexity arises from the size of software systems and the wide
variety of possible operating environments: the increasing choice of platforms
and communication policies leads to ever more complex performance
characteristics. In addition, software systems exhibit different behaviour
under different workloads. Many software systems are designed to be
configurable so that policies can be chosen to meet the needs of various
stakeholders. For complex software systems it can be difficult to accurately
predict the effects of a change and to know which configuration is most
appropriate. This thesis demonstrates that it is useful to run automated
experiments that measure a selection of system configurations. Experiments can
find configurations that meet the stakeholders' needs, find interesting
behavioural characteristics, and help produce predictive models of the system's
behaviour. The design and use of ACT (Automated Configuration Tool) for running
such experiments is described, in combination a number of search strategies for
deciding on the configurations to measure. Design Of Experiments (DOE) is
discussed, with emphasis on Taguchi Methods. These statistical methods have
been used extensively in manufacturing, but have not previously been used for
configuring software systems. The novel contribution here is an industrial case
study, applying the combination of ACT and Taguchi Methods to DC-Directory, a
product from Data Connection Ltd (DCL). The case study investigated the
applicability of Taguchi Methods for configuring complex software systems.
Taguchi Methods were found to be useful for modelling and configuring DC-
Directory, making them a valuable addition to the techniques available to
system administrators and developers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5827</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5827</id><created>2010-06-30</created><authors><author><keyname>Guadarrama</keyname><forenames>Sergio</forenames></author><author><keyname>Ruiz-Mayor</keyname><forenames>Antonio</forenames></author></authors><title>Approximate Robotic Mapping from sonar data by modeling Perceptions with
  Antonyms</title><categories>cs.RO cs.CL</categories><comments>To appear in Information Sciences</comments><report-no>FSC-2008-14</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work, inspired by the idea of &quot;Computing with Words and Perceptions&quot;
proposed by Zadeh in 2001, focuses on how to transform measurements into
perceptions for the problem of map building by Autonomous Mobile Robots. We
propose to model the perceptions obtained from sonar-sensors as two grid maps:
one for obstacles and another for empty spaces. The rules used to build and
integrate these maps are expressed by linguistic descriptions and modeled by
fuzzy rules. The main difference of this approach from other studies reported
in the literature is that the method presented here is based on the hypothesis
that the concepts &quot;occupied&quot; and &quot;empty&quot; are antonyms rather than complementary
(as it happens in probabilistic approaches), or independent (as it happens in
the previous fuzzy models).
  Controlled experimentation with a real robot in three representative indoor
environments has been performed and the results presented. We offer a
qualitative and quantitative comparison of the estimated maps obtained by the
probabilistic approach, the previous fuzzy method and the new antonyms-based
fuzzy approach. It is shown that the maps obtained with the antonyms-based
approach are better defined, capture better the shape of the walls and of the
empty-spaces, and contain less errors due to rebounds and short-echoes.
Furthermore, in spite of noise and low resolution inherent to the sonar-sensors
used, the maps obtained are accurate and tolerant to imprecision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5829</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5829</id><created>2010-06-30</created><authors><author><keyname>Nery</keyname><forenames>Bruno</forenames></author><author><keyname>Ventura</keyname><forenames>Rodrigo</forenames></author></authors><title>Online Event Segmentation in Active Perception using Adaptive Strong
  Anticipation</title><categories>cs.RO</categories><comments>Technical report, 20 pages, 7 figures</comments><report-no>RT-701-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most cognitive architectures rely on discrete representation, both in space
(e.g., objects) and in time (e.g., events). However, a robot interaction with
the world is inherently continuous, both in space and in time. The segmentation
of the stream of perceptual inputs a robot receives into discrete and
meaningful events poses as a challenge in bridging the gap between internal
cognitive representations, and the external world. Event Segmentation Theory,
recently proposed in the context of cognitive systems research, sustains that
humans segment time into events based on matching perceptual input with
predictions. In this work we propose a framework for online event segmentation,
targeting robots endowed with active perception. Moreover, sensory processing
systems have an intrinsic latency, resulting from many factors such as sampling
rate, and computational processing, and which is seldom accounted for. This
framework is founded on the theory of dynamical systems synchronization, where
the system considered includes both the robot and the world coupled (strong
anticipation). An adaption rule is used to perform simultaneous system
identi?cation and synchronization, and anticipating synchronization is employed
to predict the short-term system evolution. This prediction allows for an
appropriate control of the robot actuation. Event boundaries are detected once
synchronization is lost (sudden increase of the prediction error). An
experimental proof of concept of the proposed framework is presented, together
with some preliminary results corroborating the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5845</identifier>
 <datestamp>2015-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5845</id><created>2010-06-30</created><authors><author><keyname>Fattori</keyname><forenames>Aristide</forenames></author><author><keyname>Paleari</keyname><forenames>Roberto</forenames></author><author><keyname>Martignoni</keyname><forenames>Lorenzo</forenames></author><author><keyname>Monga</keyname><forenames>Mattia</forenames></author></authors><title>Dynamic and Transparent Analysis of Commodity Production Systems</title><categories>cs.OS cs.SE</categories><comments>10 pages, To appear in the 25th IEEE/ACM International Conference on
  Automated Software Engineering, Antwerp, Belgium, 20-24 September 2010</comments><acm-class>D.2.5; D.4.9</acm-class><doi>10.1145/1858996.1859085</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework that provides a programming interface to perform
complex dynamic system-level analyses of deployed production systems. By
leveraging hardware support for virtualization available nowadays on all
commodity machines, our framework is completely transparent to the system under
analysis and it guarantees isolation of the analysis tools running on its top.
Thus, the internals of the kernel of the running system needs not to be
modified and the whole platform runs unaware of the framework. Moreover, errors
in the analysis tools do not affect the running system and the framework. This
is accomplished by installing a minimalistic virtual machine monitor and
migrating the system, as it runs, into a virtual machine. In order to
demonstrate the potentials of our framework we developed an interactive kernel
debugger, nicknamed HyperDbg. HyperDbg can be used to debug any critical kernel
component, and even to single step the execution of exception and interrupt
handlers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5877</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5877</id><created>2010-06-30</created><updated>2010-09-23</updated><authors><author><keyname>Bouzid</keyname><forenames>Zohir</forenames><affiliation>LIP6</affiliation></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>RoboCast: Asynchronous Communication in Robot Networks</title><categories>cs.DC cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the \emph{RoboCast} communication abstraction. The
RoboCast allows a swarm of non oblivious, anonymous robots that are only
endowed with visibility sensors and do not share a common coordinate system, to
asynchronously exchange information. We propose a generic framework that covers
a large class of asynchronous communication algorithms and show how our
framework can be used to implement fundamental building blocks in robot
networks such as gathering or stigmergy. In more details, we propose a RoboCast
algorithm that allows robots to broadcast their local coordinate systems to
each others. Our algorithm is further refined with a local collision avoidance
scheme. Then, using the RoboCast primitive, we propose algorithms for
deterministic asynchronous gathering and binary information exchange.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5879</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5879</id><created>2010-06-30</created><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Secure Transmission with Multiple Antennas II: The MIMOME Wiretap
  Channel</title><categories>cs.IT cs.CR math.IT</categories><comments>To Appear, IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of the Gaussian wiretap channel model is analyzed when there are
multiple antennas at the sender, intended receiver and eavesdropper. The
associated channel matrices are fixed and known to all the terminals. A
computable characterization of the secrecy capacity is established as the
saddle point solution to a minimax problem. The converse is based on a
Sato-type argument used in other broadcast settings, and the coding theorem is
based on Gaussian wiretap codebooks.
  At high signal-to-noise ratio (SNR), the secrecy capacity is shown to be
attained by simultaneously diagonalizing the channel matrices via the
generalized singular value decomposition, and independently coding across the
resulting parallel channels. The associated capacity is expressed in terms of
the corresponding generalized singular values. It is shown that a semi-blind
&quot;masked&quot; multi-input multi-output (MIMO) transmission strategy that sends
information along directions in which there is gain to the intended receiver,
and synthetic noise along directions in which there is not, can be arbitrarily
far from capacity in this regime.
  Necessary and sufficient conditions for the secrecy capacity to be zero are
provided, which simplify in the limit of many antennas when the entries of the
channel matrices are independent and identically distributed. The resulting
scaling laws establish that to prevent secure communication, the eavesdropper
needs 3 times as many antennas as the sender and intended receiver have
jointly, and that the optimimum division of antennas between sender and
intended receiver is in the ratio of 2:1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5880</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5880</id><created>2010-06-30</created><authors><author><keyname>Afantenos</keyname><forenames>Stergos</forenames></author><author><keyname>Asher</keyname><forenames>Nicholas</forenames></author></authors><title>Testing SDRT's Right Frontier</title><categories>cs.CL</categories><journal-ref>Proceedings of COLING 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Right Frontier Constraint (RFC), as a constraint on the attachment of new
constituents to an existing discourse structure, has important implications for
the interpretation of anaphoric elements in discourse and for Machine Learning
(ML) approaches to learning discourse structures. In this paper we provide
strong empirical support for SDRT's version of RFC. The analysis of about 100
doubly annotated documents by five different naive annotators shows that SDRT's
RFC is respected about 95% of the time. The qualitative analysis of presumed
violations that we have performed shows that they are either click-errors or
structural misconceptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5892</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5892</id><created>2010-06-30</created><authors><author><keyname>Huber</keyname><forenames>Michael</forenames></author></authors><title>Computational complexity of reconstruction and isomorphism testing for
  designs and line graphs</title><categories>cs.CC cs.DM</categories><comments>12 pages; to appear in: &quot;Journal of Combinatorial Theory, Series A&quot;</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs with high symmetry or regularity are the main source for
experimentally hard instances of the notoriously difficult graph isomorphism
problem. In this paper, we study the computational complexity of isomorphism
testing for line graphs of $t$-$(v,k,\lambda)$ designs. For this class of
highly regular graphs, we obtain a worst-case running time of $O(v^{\log v +
O(1)})$ for bounded parameters $t,k,\lambda$. In a first step, our approach
makes use of the Babai--Luks algorithm to compute canonical forms of
$t$-designs. In a second step, we show that $t$-designs can be reconstructed
from their line graphs in polynomial-time. The first is algebraic in nature,
the second purely combinatorial. For both, profound structural knowledge in
design theory is required. Our results extend earlier complexity results about
isomorphism testing of graphs generated from Steiner triple systems and block
designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5894</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5894</id><created>2010-06-30</created><updated>2010-11-11</updated><authors><author><keyname>Rimoldi</keyname><forenames>Anna</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author><author><keyname>Toli</keyname><forenames>Ilia</forenames></author></authors><title>A possible intrinsic weakness of AES and other cryptosystems</title><categories>cs.IT cs.CR math.IT</categories><comments>46 pages- updated bibliography and fixed minor problems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been suggested that the algebraic structure of AES (and other similar
block ciphers) could lead to a weakness exploitable in new attacks. In this
paper, we use the algebraic structure of AES-like ciphers to construct a cipher
embedding where the ciphers may lose their non-linearity. We show some examples
and we discuss the limitations of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5896</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5896</id><created>2010-06-30</created><authors><author><keyname>Janota</keyname><forenames>Mikol&#xe1;&#x161;</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author><author><keyname>Grigore</keyname><forenames>Radu</forenames></author></authors><title>Counterexample Guided Abstraction Refinement Algorithm for Propositional
  Circumscription</title><categories>cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circumscription is a representative example of a nonmonotonic reasoning
inference technique. Circumscription has often been studied for first order
theories, but its propositional version has also been the subject of extensive
research, having been shown equivalent to extended closed world assumption
(ECWA). Moreover, entailment in propositional circumscription is a well-known
example of a decision problem in the second level of the polynomial hierarchy.
This paper proposes a new Boolean Satisfiability (SAT)-based algorithm for
entailment in propositional circumscription that explores the relationship of
propositional circumscription to minimal models. The new algorithm is inspired
by ideas commonly used in SAT-based model checking, namely counterexample
guided abstraction refinement. In addition, the new algorithm is refined to
compute the theory closure for generalized close world assumption (GCWA).
Experimental results show that the new algorithm can solve problem instances
that other solutions are unable to solve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5901</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5901</id><created>2010-06-30</created><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author></authors><title>Secret key agreement on wiretap channels with transmitter side
  information</title><categories>cs.IT math.IT</categories><comments>Presented at European Wireless 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secret-key agreement protocols over wiretap channels controlled by a state
parameter are studied. The entire state sequence is known (non-causally) to the
sender but not to the receiver and the eavesdropper. Upper and lower bounds on
the secret-key capacity are established both with and without public
discussion. The proposed coding scheme involves constructing a codebook to
create common reconstruction of the state sequence at the sender and the
receiver and another secret-key codebook constructed by random binning. For the
special case of Gaussian channels, with no public discussion, - the secret-key
generation with dirty paper problem, the gap between our bounds is at-most 1/2
bit and the bounds coincide in the high signal-to-noise ratio and high
interference-to-noise ratio regimes. In the presence of public discussion our
bounds coincide, yielding the capacity, when then the channels of the receiver
and the eavesdropper satisfy an in- dependent noise condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5902</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5902</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>Sandhya</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Malik</keyname><forenames>L.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author></authors><title>Performance Comparison of SVM and ANN for Handwritten Devnagari
  Character Recognition</title><categories>cs.CV</categories><journal-ref>IJCSI 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification methods based on learning from examples have been widely
applied to character recognition from the 1990s and have brought forth
significant improvements of recognition accuracies. This class of methods
includes statistical methods, artificial neural networks, support vector
machines (SVM), multiple classifier combination, etc. In this paper, we discuss
the characteristics of the some classification methods that have been
successfully applied to handwritten Devnagari character recognition and results
of SVM and ANNs classification method, applied on Handwritten Devnagari
characters. After preprocessing the character image, we extracted shadow
features, chain code histogram features, view based features and longest run
features. These features are then fed to Neural classifier and in support
vector machine for classification. In neural classifier, we explored three ways
of combining decisions of four MLP's designed for four different features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5906</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5906</id><created>2010-06-30</created><authors><author><keyname>Hague</keyname><forenames>M.</forenames></author><author><keyname>Ong</keyname><forenames>C. -H. L.</forenames></author></authors><title>A Saturation Method for the Modal Mu-Calculus with Backwards Modalities
  over Pushdown Systems</title><categories>cs.FL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension of an algorithm for computing directly the denotation
of a mu-calculus formula X over the configuration graph of a pushdown system to
allow backwards modalities. Our method gives the first extension of the
saturation technique to the full mu-calculus with backwards modalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5908</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5908</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>Sandhya</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author></authors><title>Recognition of Non-Compound Handwritten Devnagari Characters using a
  Combination of MLP and Minimum Edit Distance</title><categories>cs.CV</categories><journal-ref>IJCSS 4(1): 107-120 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with a new method for recognition of offline Handwritten
non-compound Devnagari Characters in two stages. It uses two well known and
established pattern recognition techniques: one using neural networks and the
other one using minimum edit distance. Each of these techniques is applied on
different sets of characters for recognition. In the first stage, two sets of
features are computed and two classifiers are applied to get higher recognition
accuracy. Two MLP's are used separately to recognize the characters. For one of
the MLP's the characters are represented with their shadow features and for the
other chain code histogram feature is used. The decision of both MLP's is
combined using weighted majority scheme. Top three results produced by combined
MLP's in the first stage are used to calculate the relative difference values.
In the second stage, based on these relative differences character set is
divided into two. First set consists of the characters with distinct shapes and
second set consists of confused characters, which appear very similar in
shapes. Characters of distinct shapes of first set are classified using MLP.
Confused characters in second set are classified using minimum edit distance
method. Method of minimum edit distance makes use of corner detected in a
character image using modified Harris corner detection technique. Experiment on
this method is carried out on a database of 7154 samples. The overall
recognition is found to be 90.74%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5911</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5911</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>S.</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>M.</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author></authors><title>Application of Statistical Features in Handwritten Devnagari Character
  Recognition</title><categories>cs.CV</categories><journal-ref>IJRTE 2(2):40-42(2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a scheme for offline Handwritten Devnagari Character
Recognition is proposed, which uses different feature extraction methodologies
and recognition algorithms. The proposed system assumes no constraints in
writing style or size. First the character is preprocessed and features namely
: Chain code histogram and moment invariant features are extracted and fed to
Multilayer Perceptrons as a preliminary recognition step. Finally the results
of both MLP's are combined using weighted majority scheme. The proposed system
is tested on 1500 handwritten devnagari character database collected from
different people. It is observed that the proposed system achieves recognition
rates 98.03% for top 5 results and 89.46% for top 1 result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5913</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5913</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>Sandhya</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Multiple Classifier Combination for Off-line Handwritten Devnagari
  Character Recognition</title><categories>cs.CV</categories><journal-ref>ICSC 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents the application of weighted majority voting technique for
combination of classification decision obtained from three Multi_Layer
Perceptron(MLP) based classifiers for Recognition of Handwritten Devnagari
characters using three different feature sets. The features used are
intersection, shadow feature and chain code histogram features. Shadow features
are computed globally for character image while intersection features and chain
code histogram features are computed by dividing the character image into
different segments. On experimentation with a dataset of 4900 samples the
overall recognition rate observed is 92.16% as we considered top five choices
results. This method is compared with other recent methods for Handwritten
Devnagari Character Recognition and it has been observed that this approach has
better success rate than other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5920</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5920</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>Sandhya</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Malik</keyname><forenames>Latesh</forenames></author></authors><title>A Two Stage Classification Approach for Handwritten Devanagari
  Characters</title><categories>cs.CV</categories><journal-ref>ICCIMA 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a two stage classification approach for handwritten
devanagari characters The first stage is using structural properties like
shirorekha, spine in character and second stage exploits some intersection
features of characters which are fed to a feedforward neural network. Simple
histogram based method does not work for finding shirorekha, vertical bar
(Spine) in handwritten devnagari characters. So we designed a differential
distance based technique to find a near straight line for shirorekha and spine.
This approach has been tested for 50000 samples and we got 89.12% success
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5922</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5922</id><created>2010-06-30</created><updated>2010-07-05</updated><authors><author><keyname>Zirkind</keyname><forenames>Givon</forenames></author></authors><title>Using Repeating Decimals As An Alternative To Prime Numbers In
  Encryption</title><categories>cs.CR</categories><acm-class>D.4.6; E.3; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is meant to provide an additional point of view, applying known
knowledge, to supply keys that have a series of non-repeating digits, in a
manner that is not usually thought of. Traditionally, prime numbers are used in
encryption as keys that have non-repeating sequences. Non-repetition of digits
in a key is very sought after in encryption. Uniqueness in a digit sequence
defeats decryption by method. In searching for methods of non-decryptable
encryption as well as ways to provide unique sequences, other than using prime
numbers, the idea of using repeating decimals came to me. Applied correctly, a
repeating decimal series of sufficient length will stand in as well for a prime
number. This is so, because only numbers prime to each other will produce
repeating decimals and; within the repeating sequence there is uniqueness of
digit sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5924</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5924</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>Sandhya</forenames></author><author><keyname>Malik</keyname><forenames>Latesh</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>A novel approach for handwritten Devnagari character recognition</title><categories>cs.CV</categories><journal-ref>ICSIP 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a method for recognition of handwritten devanagari characters
is described. Here, feature vector is constituted by accumulated directional
gradient changes in different segments, number of intersections points for the
character, type of spine present and type of shirorekha present in the
character. One Multi-layer Perceptron with conjugate-gradient training is used
to classify these feature vectors. This method is applied to a database with
1000 sample characters and the recognition rate obtained is 88.12%
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5927</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5927</id><created>2010-06-30</created><authors><author><keyname>Arora</keyname><forenames>Sandhya</forenames></author><author><keyname>Malik</keyname><forenames>Latesh</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>Classification Of Gradient Change Features Using MLP For Handwritten
  Character Recognition</title><categories>cs.CV</categories><journal-ref>EAIT 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel, generic scheme for off-line handwritten English alphabets character
images is proposed. The advantage of the technique is that it can be applied in
a generic manner to different applications and is expected to perform better in
uncertain and noisy environments. The recognition scheme is using a multilayer
perceptron(MLP) neural networks. The system was trained and tested on a
database of 300 samples of handwritten characters. For improved generalization
and to avoid overtraining, the whole available dataset has been divided into
two subsets: training set and test set. We achieved 99.10% and 94.15% correct
recognition rates on training and test sets respectively. The purposed scheme
is robust with respect to various writing styles and size as well as presence
of considerable noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5938</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5938</id><created>2010-06-30</created><authors><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Secure Transmission with Artificial Noise over Fading Channels:
  Achievable Rate and Optimal Power Allocation</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of secure communication with multi-antenna
transmission in fading channels. The transmitter simultaneously transmits an
information bearing signal to the intended receiver and artificial noise to the
eavesdroppers. We obtain an analytical closed-form expression of an achievable
secrecy rate, and use it as the objective function to optimize the transmit
power allocation between the information signal and the artificial noise. Our
analytical and numerical results show that equal power allocation is a simple
yet near optimal strategy for the case of non-colluding eavesdroppers. When the
number of colluding eavesdroppers increases, more power should be used to
generate the artificial noise. We also provide an upper bound on the
signal-to-noise ratio (SNR) above which the achievable secrecy rate is positive
and show that the bound is tight at low SNR. Furthermore, we consider the
impact of imperfect channel state information (CSI) at both the transmitter and
the receiver and find that it is wise to create more artificial noise to
confuse the eavesdroppers than to increase the signal strength for the intended
receiver if the CSI is not accurately obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5940</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5940</id><created>2010-06-29</created><authors><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author><author><keyname>Carballo</keyname><forenames>Juan-Carlos Diaz y</forenames></author></authors><title>An Information Flow Architecture for Global Smart Spaces</title><categories>cs.DC</categories><report-no>Global Smart Spaces Project IST-2000-26070 Report D15</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe an architecture which: Permits the deployment and
execution of components in appropriate geographical locations. Provides
security mechanisms that prevent misuse of the architecture. Supports a
programming model that is familiar to application programmers. Permits
installed components to share data. Permits the deployed components to
communicate via communication channels. Provides evolution mechanisms
permitting the dynamic rearrangement of inter-connection topologies the
components that they connect. Supports the specification and deployment of
distributed component deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5941</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5941</id><created>2010-06-29</created><authors><author><keyname>Zirintsis</keyname><forenames>Evangelos</forenames></author><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Allen</keyname><forenames>Ben</forenames></author><author><keyname>MacInnis</keyname><forenames>Rob</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>Nixon</keyname><forenames>Paddy</forenames></author><author><keyname>Jamieson</keyname><forenames>Andrew</forenames></author><author><keyname>Nicholson</keyname><forenames>Chris</forenames></author><author><keyname>Harris</keyname><forenames>Steven</forenames></author></authors><title>Second Set of Spaces</title><categories>cs.DC</categories><report-no>Global Smart Spaces Project IST-2000-26070 Report D11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the Gloss infrastructure supporting implementation of
location-aware services. The document is in two parts. The first part describes
software architecture for the smart space. As described in D8, a local
architecture provides a framework for constructing Gloss applications, termed
assemblies, that run on individual physical nodes, whereas a global
architecture defines an overlay network for linking individual assemblies. The
second part outlines the hardware installation for local sensing. This
describes the first phase of the installation in Strathclyde University.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5942</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5942</id><created>2010-06-30</created><authors><author><keyname>Halder</keyname><forenames>Santanu</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>FPGA Based Assembling of Facial Components for Human Face Construction</title><categories>cs.CV</categories><journal-ref>IJRTE 1(1):541-545(2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at VLSI realization for generation of a new face from textual
description. The FASY (FAce SYnthesis) System is a Face Database Retrieval and
new Face generation System that is under development. One of its main features
is the generation of the requested face when it is not found in the existing
database. The new face generation system works in three steps - searching
phase, assembling phase and tuning phase. In this paper the tuning phase using
hardware description language and its implementation in a Field Programmable
Gate Array (FPGA) device is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.5945</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1006.5945</id><created>2010-06-30</created><updated>2010-07-05</updated><authors><author><keyname>Halder</keyname><forenames>S.</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>M.</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author></authors><title>Fuzzy Classification of Facial Component Parameters</title><categories>cs.CV</categories><journal-ref>IJRTE 2(2): 66-70(2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel type-2 Fuzzy logic System to define the Shape of
a facial component with the crisp output. This work is the part of our main
research effort to design a system (called FASY) which offers a novel face
construction approach based on the textual description and also extracts and
analyzes the facial components from a face image by an efficient technique. The
Fuzzy model, designed in this paper, takes crisp value of width and height of a
facial component and produces the crisp value of Shape for different facial
components. This method is designed using Matlab 6.5 and Visual Basic 6.0 and
tested with the facial components extracted from 200 male and female face
images of different ages from different face databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0034</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0034</id><created>2010-06-30</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Costello</keyname><forenames>Ben De Lacy</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>On polymorphic logical gates in sub-excitable chemical medium</title><categories>nlin.PS cs.DM</categories><journal-ref>Journal of Bifurcation and Chaos, 2011, 21, 1977-198</journal-ref><doi>10.1142/S0218127411029574</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a sub-excitable light-sensitive Belousov-Zhabotinsky chemical medium an
asymmetric disturbance causes the formation of localized traveling
wave-fragments. Under the right conditions these wave-fragment can conserve
their shape and velocity vectors for extended time periods. The size and life
span of a fragment depend on the illumination level of the medium. When two or
more wave-fragments collide they annihilate or merge into a new wave-fragment.
In computer simulations based on the Oregonator model we demonstrate that the
outcomes of inter-fragment collisions can be controlled by varying the
illumination level applied to the medium. We interpret these wave-fragments as
values of Boolean variables and design collision-based polymorphic logical
gates. The gate implements operation XNOR for low illumination, and it acts as
NOR gate for high illumination. As a NOR gate is a universal gate then we are
able to demonstrate that a simulated light sensitive BZ medium exhibits
computational universality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0050</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0050</id><created>2010-06-30</created><authors><author><keyname>Armstrong</keyname><forenames>P.</forenames></author><author><keyname>Agarwal</keyname><forenames>A.</forenames></author><author><keyname>Bishop</keyname><forenames>A.</forenames></author><author><keyname>Charbonneau</keyname><forenames>A.</forenames></author><author><keyname>Desmarais</keyname><forenames>R.</forenames></author><author><keyname>Fransham</keyname><forenames>K.</forenames></author><author><keyname>Hill</keyname><forenames>N.</forenames></author><author><keyname>Gable</keyname><forenames>I.</forenames></author><author><keyname>Gaudet</keyname><forenames>S.</forenames></author><author><keyname>Goliath</keyname><forenames>S.</forenames></author><author><keyname>Impey</keyname><forenames>R.</forenames></author><author><keyname>Leavett-Brown</keyname><forenames>C.</forenames></author><author><keyname>Ouellete</keyname><forenames>J.</forenames></author><author><keyname>Paterson</keyname><forenames>M.</forenames></author><author><keyname>Pritchet</keyname><forenames>C.</forenames></author><author><keyname>Penfold-Brown</keyname><forenames>D.</forenames></author><author><keyname>Podaima</keyname><forenames>W.</forenames></author><author><keyname>Schade</keyname><forenames>D.</forenames></author><author><keyname>Sobie</keyname><forenames>R. J.</forenames></author></authors><title>Cloud Scheduler: a resource manager for distributed compute clouds</title><categories>cs.DC</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability of Infrastructure-as-a-Service (IaaS) computing clouds gives
researchers access to a large set of new resources for running complex
scientific applications. However, exploiting cloud resources for large numbers
of jobs requires significant effort and expertise. In order to make it simple
and transparent for researchers to deploy their applications, we have developed
a virtual machine resource manager (Cloud Scheduler) for distributed compute
clouds. Cloud Scheduler boots and manages the user-customized virtual machines
in response to a user's job submission. We describe the motivation and design
of the Cloud Scheduler and present results on its use on both science and
commercial clouds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0057</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0057</id><created>2010-06-30</created><authors><author><keyname>Chen</keyname><forenames>Yalin</forenames></author><author><keyname>Chou*</keyname><forenames>Jue-Sam</forenames></author><author><keyname>Huang</keyname><forenames>Chun-Hui</forenames></author></authors><title>Comments on Five Smart Card Based Password Authentication Protocols</title><categories>cs.CR</categories><comments>4 pages,</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 2, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use the ten security requirements proposed by Liao et al.
for a smart card based authentication protocol to examine five recent work in
this area. After analyses, we found that the protocols of Juang et al.'s ,
Hsiang et al.'s, Kim et al.'s, and Li et al.'s all suffer from offline password
guessing attack if the smart card is lost, and the protocol of Xu et al.'s is
subjected to an insider impersonation attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0060</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0060</id><created>2010-06-30</created><authors><author><keyname>Chen</keyname><forenames>Yalin</forenames></author><author><keyname>Chou*</keyname><forenames>Jue-Sam</forenames></author><author><keyname>Huang</keyname><forenames>Chun-Hui</forenames></author></authors><title>Cryptanalysis on Four Two-Party Authentication Protocols</title><categories>cs.CR</categories><comments>5 pages</comments><msc-class>68p25 (data encryption)</msc-class><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 2, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze four authentication protocols of Bindu et al.,
Goriparthi et al., Wang et al. and H\&quot;olbl et al.. After investigation, we
reveal several weaknesses of these schemes. First, Bindu et al.'s protocol
suffers from an insider impersonation attack if a malicious user obtains a lost
smart card. Second, both Goriparthi et al.'s and Wang et al.'s protocols cannot
withstand a DoS attack in the password change phase, i.e. an attacker can
involve the phase to make user's password never be used in subsequent
authentications. Third, H\&quot;olbl et al.'s protocol is vulnerable to an insider
attack since a legal but malevolent user can deduce KGC's secret key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0066</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0066</id><created>2010-07-01</created><updated>2010-09-05</updated><authors><author><keyname>Beloglazov</keyname><forenames>Anton</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Lee</keyname><forenames>Young Choon</forenames></author><author><keyname>Zomaya</keyname><forenames>Albert</forenames></author></authors><title>A Taxonomy and Survey of Energy-Efficient Data Centers and Cloud
  Computing Systems</title><categories>cs.DC</categories><comments>49 pages, 9 pages, 3 tables</comments><report-no>Technical Report, CLOUDS-TR-2010-3, Cloud Computing and Distributed
  Systems Laboratory, The University of Melbourne, Australia, June 30, 2010</report-no><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, the development of computing systems has been focused on
performance improvements driven by the demand of applications from consumer,
scientific and business domains. However, the ever increasing energy
consumption of computing systems has started to limit further performance
growth due to overwhelming electricity bills and carbon dioxide footprints.
Therefore, the goal of the computer system design has been shifted to power and
energy efficiency. To identify open challenges in the area and facilitate
future advancements it is essential to synthesize and classify the research on
power and energy-efficient design conducted to date. In this work we discuss
causes and problems of high power / energy consumption, and present a taxonomy
of energy-efficient design of computing systems covering the hardware,
operating system, virtualization and data center levels. We survey various key
works in the area and map them to our taxonomy to guide future design and
development efforts. This chapter is concluded with a discussion of
advancements identified in energy-efficient computing and our vision on future
research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0085</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0085</id><created>2010-07-01</created><authors><author><keyname>Bhatia</keyname><forenames>Nitin</forenames></author><author><keyname>Vandana</keyname></author></authors><title>Survey of Nearest Neighbor Techniques</title><categories>cs.CV</categories><comments>4 pages, 1 table</comments><journal-ref>IJCSIS vol. 8, No. 2, 2010 pp. 302-305</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nearest neighbor (NN) technique is very simple, highly efficient and
effective in the field of pattern recognition, text categorization, object
recognition etc. Its simplicity is its main advantage, but the disadvantages
can't be ignored even. The memory requirement and computation complexity also
matter. Many techniques are developed to overcome these limitations. NN
techniques are broadly classified into structure less and structure based
techniques. In this paper, we present the survey of such techniques. Weighted
kNN, Model based kNN, Condensed NN, Reduced NN, Generalized NN are structure
less techniques whereas k-d tree, ball tree, Principal Axis Tree, Nearest
Feature Line, Tunable NN, Orthogonal Search Tree are structure based algorithms
developed on the basis of kNN. The structure less method overcome memory
limitation and structure based techniques reduce the computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0087</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0087</id><created>2010-07-01</created><authors><author><keyname>Kumar</keyname><forenames>Krishnan</forenames></author><author><keyname>J</keyname><forenames>Nafeesa Begum</forenames></author><author><keyname>Sumathy</keyname><forenames>V.</forenames></author></authors><title>A Novel Approach towards Cost Effective Region-Based Group Key Agreement
  Protocol for Secure Group Communication</title><categories>cs.CR</categories><comments>10 pages,29 figures</comments><report-no>pkk-2010-02</report-no><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 2, 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper addresses an interesting security problem in wireless ad hoc
networks: the Dynamic Group Key Agreement key establishment. For secure group
communication in an Ad hoc network, a group key shared by all group members is
required. This group key should be updated when there are membership changes
(when the new member joins or current member leaves) in the group. In this
paper, We propose a novel, secure, scalable and efficient Region-Based Group
Key Agreement protocol (RBGKA) for ad-hoc networks. This is implemented by a
two-level structure and a new scheme of group key update. The idea is to divide
the group into subgroups, each maintaining its subgroup keys using Group
Diffie-Hellman (GDH) Protocol and links with other subgroups in a Tree
structure using Tree-based Group Diffie-Hellman (TGDH) protocol. By introducing
region-based approach, messages and key updates will be limited within subgroup
and outer group; hence computation load is distributed among many hosts. Both
theoretical analysis and experimental results show that this Region-based key
agreement protocol performs better for the key establishment problem in ad-hoc
network in terms of memory cost, computation cost and communication cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0089</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0089</id><created>2010-07-01</created><authors><author><keyname>Bhatnagar</keyname><forenames>Nayantara</forenames></author><author><keyname>Bogdanov</keyname><forenames>Andrej</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>The Computational Complexity of Estimating Convergence Time</title><categories>cs.DS math.ST stat.CO stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important problem in the implementation of Markov Chain Monte Carlo
algorithms is to determine the convergence time, or the number of iterations
before the chain is close to stationarity. For many Markov chains used in
practice this time is not known. Even in cases where the convergence time is
known to be polynomial, the theoretical bounds are often too crude to be
practical. Thus, practitioners like to carry out some form of statistical
analysis in order to assess convergence. This has led to the development of a
number of methods known as convergence diagnostics which attempt to diagnose
whether the Markov chain is far from stationarity. We study the problem of
testing convergence in the following settings and prove that the problem is
hard in a computational sense: Given a Markov chain that mixes rapidly, it is
hard for Statistical Zero Knowledge (SZK-hard) to distinguish whether starting
from a given state, the chain is close to stationarity by time t or far from
stationarity at time ct for a constant c. We show the problem is in AM
intersect coAM. Second, given a Markov chain that mixes rapidly it is coNP-hard
to distinguish whether it is close to stationarity by time t or far from
stationarity at time ct for a constant c. The problem is in coAM. Finally, it
is PSPACE-complete to distinguish whether the Markov chain is close to
stationarity by time t or far from being mixed at time ct for c at least 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0097</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0097</id><created>2010-07-01</created><authors><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author><author><keyname>Vajda</keyname><forenames>Igor</forenames></author></authors><title>On Pairs of $f$-divergences and their Joint Range</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>7 pages, 4 figures</comments><msc-class>94A17, 26Dxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare two f-divergences and prove that their joint range is the convex
hull of the joint range for distributions supported on only two points. Some
applications of this result are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0107</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0107</id><created>2010-07-01</created><authors><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>McCarthy</keyname><forenames>Andrew</forenames></author><author><keyname>Morrison</keyname><forenames>Ron</forenames></author><author><keyname>Mullen</keyname><forenames>Kevin</forenames></author><author><keyname>Yang</keyname><forenames>Yanyan</forenames></author><author><keyname>Connor</keyname><forenames>Richard</forenames></author><author><keyname>Welen</keyname><forenames>Paula</forenames></author><author><keyname>Wilson</keyname><forenames>Andy</forenames></author></authors><title>First Smart Spaces</title><categories>cs.DC</categories><report-no>Global Smart Spaces Project IST-2000-26070 Report D8, 2002</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the Gloss software currently implemented. The
description of the Gloss demonstrator for multi-surface interaction can be
found in D17. The ongoing integration activity for the work described in D17
and D8 constitutes our development of infrastructure for a first smart space.
In this report, the focus is on infrastructure to support the implementation of
location aware services. A local architecture provides a framework for
constructing Gloss applications, termed assemblies, that run on individual
physical nodes. A global architecture defines an overlay network for linking
individual assemblies. Both local and global architectures are under active
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0118</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0118</id><created>2010-07-01</created><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author></authors><title>Channel Assortment Strategy for Reliable Communication in Multi-Hop
  Cognitive Radio Networks</title><categories>cs.NI</categories><journal-ref>In Proceedings of the 11th IEEE International Symposium on a World
  of Wireless, Mobile and Multimedia Networks (IEEE WoWMoM 2010), Extended
  Abstract, Montreal, QC, Canada, 14- 17 June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a channel assortment strategy for Reliable
Communication in Multi-Hop Cognitive Radio Networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0120</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0120</id><created>2010-07-01</created><updated>2010-09-01</updated><authors><author><keyname>Ehrhard</keyname><forenames>Thomas</forenames><affiliation>PPS</affiliation></author><author><keyname>Laurent</keyname><forenames>Olivier</forenames><affiliation>PPS</affiliation></author></authors><title>Acyclic Solos and Differential Interaction Nets</title><categories>cs.LO cs.PL</categories><proxy>LMCS</proxy><acm-class>cs.PL</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  1, 2010) lmcs:771</journal-ref><doi>10.2168/LMCS-6(3:11)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a restriction of the solos calculus which is stable under
reduction and expressive enough to contain an encoding of the pi-calculus. As a
consequence, it is shown that equalizing names that are already equal is not
required by the encoding of the pi-calculus. In particular, the induced solo
diagrams bear an acyclicity property that induces a faithful encoding into
differential interaction nets. This gives a (new) proof that differential
interaction nets are expressive enough to contain an encoding of the
pi-calculus. All this is worked out in the case of finitary (replication free)
systems without sum, match nor mismatch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0123</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0123</id><created>2010-07-01</created><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author><author><keyname>Viana</keyname><forenames>Aline Carneiro</forenames></author><author><keyname>Khalife</keyname><forenames>Hicham</forenames></author><author><keyname>Fdida</keyname><forenames>Serge</forenames></author></authors><title>Adaptive and occupancy-based channel selection for unreliable cognitive
  radio networks</title><categories>cs.NI</categories><journal-ref>Rencontres Francophones sur les Aspects Algorithmiques des
  Telecommunications (ALGOTEL) 2009, du 16 au 19 juin 2009, Carry Le Rouet,
  France</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an adaptive and occupancy-based channel selection
for unreliable cognitive radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0126</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0126</id><created>2010-07-01</created><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author><author><keyname>Viana</keyname><forenames>Aline Carneiro</forenames></author><author><keyname>Khalife</keyname><forenames>Hicham</forenames></author><author><keyname>Fdida</keyname><forenames>Serge</forenames></author></authors><title>A Cognitive Radio Based Internet Access Framework for Disaster Response
  Network Deployment</title><categories>cs.NI</categories><report-no>INRIA Research Report RR-7285, May 2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a cognitive radio based Internet access framework
for disaster response network deployment in challenged environments. The
proposed architectural framework is designed to help the existent but partially
damaged networks to restore their connectivity and to connect them to the
global Internet. This architectural framework provides the basis to develop
algorithms and protocols for the future cognitive radio network deployments in
challenged environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0128</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0128</id><created>2010-07-01</created><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author><author><keyname>Viana</keyname><forenames>Aline Carneiro</forenames></author><author><keyname>Khalife</keyname><forenames>Hicham</forenames></author><author><keyname>Fdida</keyname><forenames>Serge</forenames></author></authors><title>Toward Reliable Contention-aware Data Dissemination in Multi-hop
  Cognitive Radio Ad Hoc Networks</title><categories>cs.NI</categories><report-no>INRIA Research Report RR-7288, December 2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new channel selection strategy for reliable
contentionaware data dissemination in multi-hop cognitive radio network. The
key challenge here is to select channels providing a good tradeoff between
connectivity and contention. In other words, channels with good opportunities
for communication due to (1) low primary radio nodes (PRs) activities, and (2)
limited contention of cognitive ratio nodes (CRs) acceding that channel, have
to be selected. Thus, by dynamically exploring residual resources on channels
and by monitoring the number of CRs on a particular channel, SURF allows
building a connected network with limited contention where reliable
communication can take place. Through simulations, we study the performance of
SURF when compared with three other related approaches. Simulation results
confirm that our approach is effective in selecting the best channels for
efficient and reliable multi-hop data dissemination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0134</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0134</id><created>2010-07-01</created><authors><author><keyname>Gebser</keyname><forenames>Martin</forenames></author><author><keyname>Schaub</keyname><forenames>Torsten</forenames></author><author><keyname>Thiele</keyname><forenames>Sven</forenames></author><author><keyname>Veber</keyname><forenames>Philippe</forenames></author></authors><title>Detecting Inconsistencies in Large Biological Networks with Answer Set
  Programming</title><categories>cs.LO</categories><comments>36 pages, 8 figures, 3 tables, to appear in Theory and Practice of
  Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an approach to detecting inconsistencies in large biological
networks by using Answer Set Programming (ASP). To this end, we build upon a
recently proposed notion of consistency between biochemical/genetic reactions
and high-throughput profiles of cell activity. We then present an approach
based on ASP to check the consistency of large-scale data sets. Moreover, we
extend this methodology to provide explanations for inconsistencies by
determining minimal representations of conflicts. In practice, this can be used
to identify unreliable data or to indicate missing reactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0143</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0143</id><created>2010-07-01</created><authors><author><keyname>Lucas</keyname><forenames>Salvador</forenames></author></authors><title>From matrix interpretations over the rationals to matrix interpretations
  over the naturals</title><categories>cs.SC</categories><comments>To appear in Proc. of the 10th International Conference on Artificial
  Intelligence and Symbolic Computation, AISC'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix interpretations generalize linear polynomial interpretations and have
been proved useful in the implementation of tools for automatically proving
termination of Term Rewriting Systems. In view of the successful use of
rational coefficients in polynomial interpretations, we have recently
generalized traditional matrix interpretations (using natural numbers in the
matrix entries) to incorporate real numbers. However, existing results which
formally prove that polynomials over the reals are more powerful than
polynomials over the naturals for proving termination of rewrite systems failed
to be extended to matrix interpretations. In this paper we get deeper into this
problem. We show that, under some conditions, it is possible to transform a
matrix interpretation over the rationals satisfying a set of symbolic
constraints into a matrix interpretation over the naturals (using bigger
matrices) which still satisfies the constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0144</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0144</id><created>2010-07-01</created><authors><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Pavel</keyname><forenames>Lacra</forenames></author><author><keyname>Stefanovic</keyname><forenames>Nem</forenames></author></authors><title>An Optimization and Control Theoretic Approach to Noncooperative Game
  Design</title><categories>cs.GT cs.NI math.OC</categories><comments>Earlier versions of this work have appeared partly in the
  International Conference on Game Theory for Networks (GameNets), in Istanbul,
  Turkey in May 2009 and Conference on Decision and Control (CDC), Shanghai,
  China, in December 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates design of noncooperative games from an optimization
and control theoretic perspective. Pricing mechanisms are used as a design tool
to ensure that the Nash equilibrium of a fairly general class of noncooperative
games satisfies certain global objectives such as welfare maximization or
achieving a certain level of quality-of-service (QoS). The class of games
considered provide a theoretical basis for decentralized resource allocation
and control problems including network congestion control, wireless uplink
power control, and optical power control. The game design problem is analyzed
under different knowledge assumptions (full versus limited information) and
design objectives (QoS versus utility maximization) for separable and
non-separable utility functions. The ``price of anarchy'' is shown not to be an
inherent feature of full-information games that incorporate pricing mechanisms.
Moreover, a simple linear pricing is shown to be sufficient for design of Nash
equilibrium according to a chosen global objective for a fairly general class
of games. Stability properties of the game and pricing dynamics are studied
under the assumption of time-scale separation and in two separate time-scales.
Thus, sufficient conditions are derived, which allow the designer to place the
Nash equilibrium solution or to guide the system trajectory to a desired region
or point. The obtained results are illustrated with a number of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0159</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0159</id><created>2010-07-01</created><authors><author><keyname>Kuhn</keyname><forenames>Adrian</forenames></author><author><keyname>Erni</keyname><forenames>David</forenames></author><author><keyname>Denker</keyname><forenames>Marcus</forenames></author></authors><title>Empowering Collections with Swarm Behavior</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often, when modelling a system there are properties and operations that are
related to a group of objects rather than to a single object. In this paper we
extend Java with Swarm Behavior, a new composition operator that associates
behavior with a collection of instances. The lookup resolution of swarm
behavior is based on the element type of a collection and is thus orthogonal to
the collection hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0199</identifier>
 <datestamp>2014-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0199</id><created>2010-07-01</created><updated>2011-08-24</updated><authors><author><keyname>Junca</keyname><forenames>Mauricio</forenames></author></authors><title>Optimal execution strategy in the presence of permanent price impact and
  fixed transaction cost</title><categories>q-fin.TR cs.SY math.OC math.PR</categories><msc-class>91G80, 93E20, 49L25</msc-class><journal-ref>Optim. Control Appl. and Meth. 33 (6):713-738.(2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a single risky financial asset model subject to price impact and
transaction cost over an infinite horizon. An investor needs to execute a long
position in the asset affecting the price of the asset and possibly incurring
in fixed transaction cost. The objective is to maximize the discounted revenue
obtained by this transaction. This problem is formulated first as an impulse
control problem and we characterize the value function using the viscosity
solutions framework. We also analyze the case where there is no transaction
cost and how this formulation relates with a singular control problem. A
viscosity solution characterization is provided in this case as well. We also
establish a connection between both formulations with zero fixed transaction
cost. Numerical examples with different types of price impact conclude the
discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0210</identifier>
 <datestamp>2014-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0210</id><created>2010-07-01</created><updated>2014-05-02</updated><authors><author><keyname>Gepshtein</keyname><forenames>Sergei</forenames></author><author><keyname>Tyukin</keyname><forenames>Ivan</forenames></author></authors><title>Uncertainty of visual measurement and efficient allocation of sensory
  resources</title><categories>q-bio.NC cs.CV cs.IT math.IT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the reasoning underlying two approaches to combination of sensory
uncertainties. First approach is noncommittal, making no assumptions about
properties of uncertainty or parameters of stimulation. Then we explain the
relationship between this approach and the one commonly used in modeling
&quot;higher level&quot; aspects of sensory systems, such as in visual cue integration,
where assumptions are made about properties of stimulation. The two approaches
follow similar logic, except in one case maximal uncertainty is minimized, and
in the other minimal certainty is maximized. Then we demonstrate how optimal
solutions are found to the problem of resource allocation under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0217</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0217</id><created>2010-07-01</created><authors><author><keyname>Young</keyname><forenames>Neal E.</forenames></author></authors><title>A Bound on the Sum of Weighted Pairwise Distances of Points Constrained
  to Balls</title><categories>cs.DS</categories><comments>Cornell ORIE Tech Report</comments><report-no>1103</report-no><msc-class>90C27 (Primary) 90C22, 52A40 (Secondary)</msc-class><acm-class>G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of choosing Euclidean points to maximize the sum of
their weighted pairwise distances, when each point is constrained to a ball
centered at the origin. We derive a dual minimization problem and show strong
duality holds (i.e., the resulting upper bound is tight) when some locally
optimal configuration of points is affinely independent. We sketch a polynomial
time algorithm for finding a near-optimal set of points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0221</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0221</id><created>2010-07-01</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Regular Labelings and Geometric Structures</title><categories>cs.CG math.CO</categories><comments>6 pages, 3 figures. Invited to the 22nd Canadian Conference on
  Computational Geometry (CCCG 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three types of geometric structure---grid triangulations, rectangular
subdivisions, and orthogonal polyhedra---can each be described combinatorially
by a regular labeling: an assignment of colors and orientations to the edges of
an associated maximal or near-maximal planar graph. We briefly survey the
connections and analogies between these three kinds of labelings, and their
uses in designing efficient geometric algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0267</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0267</id><created>2010-07-01</created><authors><author><keyname>Sahin</keyname><forenames>Onur</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>Interference Channel with an Out-of-Band Relay</title><categories>cs.IT math.IT</categories><comments>52 pages, 12 figures, revised version for IT Transactions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Gaussian interference channel (IC) with a relay is considered. The relay is
assumed to operate over an orthogonal band with respect to the underlying IC,
and the overall system is referred to as IC with an out-of-band relay (IC-OBR).
The system can be seen as operating over two parallel interference-limited
channels: The first is a standard Gaussian IC and the second is a Gaussian
relay channel characterized by two sources and destinations communicating
through the relay without direct links. We refer to the second parallel channel
as OBR Channel (OBRC). The main aim of this work is to identify conditions
under which optimal operation, in terms of the capacity region of the IC-OBR,
entails either signal relaying and/or interference forwarding by the relay,
with either a separable or non-separable use of the two parallel channels, IC
and OBRC. Here &quot;separable&quot; refers to transmission of independent information
over the two constituent channels. For a basic model in which the OBRC consists
of four orthogonal channels from sources to relay and from relay to
destinations (IC-OBR Type-I), a condition is identified under which signal
relaying and separable operation is optimal. When this condition is not
satisfied, various scenarios are identified in which interference forwarding
and non-separable operation are necessary to achieve optimal performance. In
these scenarios, the system exploits the &quot;excess capacity&quot; on the OBRC via
interference forwarding to drive the IC-OBR system in specific interference
regimes (strong or mixed). The analysis is then turned to a more complex
IC-OBR, in which the OBRC consists of only two orthogonal channels, one from
sources to relay and one from relay to destinations (IC-OBR Type-II). For this
channel, some capacity resuls are derived that parallel the conclusions for
IC-OBR Type-I.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0273</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0273</id><created>2010-07-01</created><authors><author><keyname>Caballero</keyname><forenames>Rafael</forenames></author><author><keyname>Collado-Iglesias</keyname><forenames>Blanca</forenames></author><author><keyname>Pozuelo-Gonz&#xe1;lez</keyname><forenames>Sara</forenames></author><author><keyname>Fern&#xe1;ndez-S&#xe1;nchez</keyname><forenames>Antonio</forenames></author></authors><title>New Common Proper-Motion Pairs From the PPMX Catalog</title><categories>astro-ph.SR cs.DB</categories><journal-ref>Journal of Double Star Observations (2010), Vol. 6 No. 3, pages
  206-216</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We use data mining techniques for finding 82 previously unreported common
proper motion pairs from the PPM-Extended catalogue. Special-purpose software
automating the different phases of the process has been developed. The software
simplifies the detection of the new pairs by integrating a set of basic
operations over catalogues. The operations can be combined by the user in
scripts representing different filtering criteria. This procedure facilitates
testing the software and employing the same scripts for different projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0292</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0292</id><created>2010-07-02</created><authors><author><keyname>Prasad</keyname><forenames>Ajay</forenames></author><author><keyname>Panda</keyname><forenames>G. K.</forenames></author><author><keyname>Mitra</keyname><forenames>A.</forenames></author><author><keyname>Singh</keyname><forenames>Arjun</forenames></author><author><keyname>Gour</keyname><forenames>Deepak</forenames></author></authors><title>Applying l-Diversity in anonymizing collaborative social network</title><categories>cs.CY cs.CR</categories><acm-class>H.1.0</acm-class><journal-ref>International Journal of Computer Science and Information Security
  Year 2010 Vol: 8, Issue: 2 pages 324 - 329</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To date publish of a giant social network jointly from different parties is
an easier collaborative approach. Agencies and researchers who collect such
social network data often have a compelling interest in allowing others to
analyze the data. In many cases the data describes relationships that are
private and sharing the data in full can result in unacceptable disclosures.
Thus, preserving privacy without revealing sensitive information in the social
network is a serious concern. Recent developments for preserving privacy using
anonymization techniques are focused on relational data only. Preserving
privacy in social networks against neighborhood attacks is an initiation which
uses the definition of privacy called k-anonymity. k-anonymous social network
still may leak privacy under the cases of homogeneity and background knowledge
attacks. To overcome, we find a place to use a new practical and efficient
definition of privacy called ldiversity. In this paper, we take a step further
on preserving privacy in collaborative social network data with algorithms and
analyze the effect on the utility of the data for social network analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0295</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0295</id><created>2010-07-02</created><authors><author><keyname>Prasad</keyname><forenames>Ajay</forenames></author><author><keyname>Verma</keyname><forenames>Saurabh Singh</forenames></author><author><keyname>Sharma</keyname><forenames>Ashok Kumar</forenames></author></authors><title>Certification Authority Monitored Multilevel and Stateful Policy Based
  Authorization in Services Oriented Grids</title><categories>cs.DC cs.CR</categories><acm-class>H.1.0</acm-class><journal-ref>Certification Authority Monitored Multilevel and Stateful Policy
  Based Authorization in Services Oriented Grids, International Journal of
  Security, (IJS), Volume (3) : Issue(4):48-64, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Services oriented grids will be more prominent among other kinds of grids in
the present distributed environments. With the advent of online government
services the governmental grids will come up in huge numbers. Apart from common
security issues as in other grids, the authorization in service oriented grids
faces certain shortcomings and needs to be looked upon differently. The CMMS
model presented here overcomes all these shortcomings and adds to the
simplicity of implementation because of its tight similarities with certain
government services and their functioning. The model is used to prototype a
State Police Information Grid (SPIG). Small technological restructuring is
required in PKIX and X.509 certificates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0296</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0296</id><created>2010-07-02</created><updated>2012-02-15</updated><authors><author><keyname>Buntine</keyname><forenames>Wray</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>A Bayesian View of the Poisson-Dirichlet Process</title><categories>math.ST cs.LG math.PR stat.TH</categories><comments>50 LaTeX pages, 10 figures, 3 tables, 1 algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two parameter Poisson-Dirichlet Process (PDP), a generalisation of the
Dirichlet Process, is increasingly being used for probabilistic modelling in
discrete areas such as language technology, bioinformatics, and image analysis.
There is a rich literature about the PDP and its derivative distributions such
as the Chinese Restaurant Process (CRP). This article reviews some of the basic
theory and then the major results needed for Bayesian modelling of discrete
problems including details of priors, posteriors and computation.
  The PDP allows one to build distributions over countable partitions. The PDP
has two other remarkable properties: first it is partially conjugate to itself,
which allows one to build hierarchies of PDPs, and second using a marginalised
relative the CRP, one gets fragmentation and clustering properties that lets
one layer partitions to build trees. This article presents the basic theory for
understanding the notion of partitions and distributions over them, the PDP and
the CRP, and the important properties of conjugacy, fragmentation and
clustering, as well as some key related properties such as consistency and
convergence. This article also presents a Bayesian interpretation of the
Poisson-Dirichlet process based on an improper and infinite dimensional
Dirichlet distribution. This means we can understand the process as just
another Dirichlet and thus all its sampling properties emerge naturally.
  The theory of PDPs is usually presented for continuous distributions (more
generally referred to as non-atomic distributions), however, when applied to
discrete distributions its remarkable conjugacy property emerges. This context
and basic results are also presented, as well as techniques for computing the
second order Stirling numbers that occur in the posteriors for discrete
distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0302</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0302</id><created>2010-07-02</created><authors><author><keyname>Syamsuddin</keyname><forenames>Irfan</forenames></author><author><keyname>Hwang</keyname><forenames>Junseok</forenames></author></authors><title>The Application of AHP Model to Guide Decision Makers: A Case Study of
  E-banking Security</title><categories>cs.CY cs.CR</categories><comments>5 pages</comments><doi>10.1109/ICCIT.2009.251</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Changes in technology have resulted in new ways for bankers to deliver their
services to costumers. Electronic banking systems in various forms are the
evidence of such advancement. However, information security threats also
evolving along this trend. This paper proposes the application of Analytic
Hierarchy Process (AHP) methodology to guide decision makers in banking
industries to deal with information security policy. The model is structured
according aspects of information security policy in conjunction with
information security elements. We found that cultural aspect is valued on the
top priority among other security aspects, while confidentiality is considered
as the most important factor in terms of information security elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0305</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0305</id><created>2010-07-02</created><updated>2010-12-21</updated><authors><author><keyname>Fefferman</keyname><forenames>Bill</forenames></author><author><keyname>Umans</keyname><forenames>Christopher</forenames></author></authors><title>Pseudorandom generators and the BQP vs. PH problem</title><categories>cs.CC quant-ph</categories><comments>Updated in light of counterexample to the GLN conjecture</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a longstanding open problem to devise an oracle relative to which BQP
does not lie in the Polynomial-Time Hierarchy (PH). We advance a natural
conjecture about the capacity of the Nisan-Wigderson pseudorandom generator
[NW94] to fool AC_0, with MAJORITY as its hard function. Our conjecture is
essentially that the loss due to the hybrid argument (which is a component of
the standard proof from [NW94]) can be avoided in this setting. This is a
question that has been asked previously in the pseudorandomness literature
[BSW03]. We then make three main contributions: (1) We show that our conjecture
implies the existence of an oracle relative to which BQP is not in the PH. This
entails giving an explicit construction of unitary matrices, realizable by
small quantum circuits, whose row-supports are &quot;nearly-disjoint.&quot; (2) We give a
simple framework (generalizing the setting of Aaronson [A10]) in which any
efficiently quantumly computable unitary gives rise to a distribution that can
be distinguished from the uniform distribution by an efficient quantum
algorithm. When applied to the unitaries we construct, this framework yields a
problem that can be solved quantumly, and which forms the basis for the desired
oracle. (3) We prove that Aaronson's &quot;GLN conjecture&quot; [A10] implies our
conjecture; our conjecture is thus formally easier to prove. The GLN conjecture
was recently proved false for depth greater than 2 [A10a], but it remains open
for depth 2. If true, the depth-2 version of either conjecture would imply an
oracle relative to which BQP is not in AM, which is itself an outstanding open
problem. Taken together, our results have the following interesting
interpretation: they give an instantiation of the Nisan-Wigderson generator
that can be broken by quantum computers, but not by the relevant modes of
classical computation, if our conjecture is true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0313</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0313</id><created>2010-07-02</created><authors><author><keyname>Chau</keyname><forenames>Duc Phu</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Bremond</keyname><forenames>Francois</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Corvee</keyname><forenames>Etienne</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Thonnat</keyname><forenames>Monique</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Repairing People Trajectories Based on Point Clustering</title><categories>cs.CV</categories><proxy>ccsd</proxy><journal-ref>The International Conference on Computer Vision Theory and
  Applications (VISAPP), Lisboa : Portugal (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for improving any object tracking algorithm
based on machine learning. During the training phase, important trajectory
features are extracted which are then used to calculate a confidence value of
trajectory. The positions at which objects are usually lost and found are
clustered in order to construct the set of 'lost zones' and 'found zones' in
the scene. Using these zones, we construct a triplet set of zones i.e. three
zones: In/Out zone (zone where an object can enter or exit the scene), 'lost
zone' and 'found zone'. Thanks to these triplets, during the testing phase, we
can repair the erroneous trajectories according to which triplet they are most
likely to belong to. The advantage of our approach over the existing state of
the art approaches is that (i) this method does not depend on a predefined
contextual scene, (ii) we exploit the semantic of the scene and (iii) we have
proposed a method to filter out noisy trajectories based on their confidence
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0328</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0328</id><created>2010-07-02</created><authors><author><keyname>Tauber</keyname><forenames>Markus</forenames></author></authors><title>Autonomic Management in a Distributed Storage System</title><categories>cs.DC</categories><comments>PhD Thesis, University of St Andrews, 2009. Supervisor: Graham Kirby</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis investigates the application of autonomic management to a
distributed storage system. Effects on performance and resource consumption
were measured in experiments, which were carried out in a local area test-bed.
The experiments were conducted with components of one specific distributed
storage system, but seek to be applicable to a wide range of such systems, in
particular those exposed to varying conditions. The perceived characteristics
of distributed storage systems depend on their configuration parameters and on
various dynamic conditions. For a given set of conditions, one specific
configuration may be better than another with respect to measures such as
resource consumption and performance. Here, configuration parameter values were
set dynamically and the results compared with a static configuration. It was
hypothesised that under non-changing conditions this would allow the system to
converge on a configuration that was more suitable than any that could be set a
priori. Furthermore, the system could react to a change in conditions by
adopting a more appropriate configuration. Autonomic management was applied to
the peer-to-peer (P2P) and data retrieval components of ASA, a distributed
storage system. The effects were measured experimentally for various workload
and churn patterns. The management policies and mechanisms were implemented
using a generic autonomic management framework developed during this work. The
experimental evaluations of autonomic management show promising results, and
suggest several future research topics. The findings of this thesis could be
exploited in building other distributed storage systems that focus on
harnessing storage on user workstations, since these are particularly likely to
be exposed to varying, unpredictable conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0357</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0357</id><created>2010-07-02</created><authors><author><keyname>Kugiumtzis</keyname><forenames>Dimitris</forenames></author></authors><title>Transfer Entropy on Rank Vectors</title><categories>nlin.CD cs.IT math.IT physics.data-an stat.ME</categories><comments>9 pages, 7 figures, accepted in Journal of Nonlinear Systems and
  Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transfer entropy (TE) is a popular measure of information flow found to
perform consistently well in different settings. Symbolic transfer entropy
(STE) is defined similarly to TE but on the ranks of the components of the
reconstructed vectors rather than the reconstructed vectors themselves. First,
we correct STE by forming the ranks for the future samples of the response
system with regard to the current reconstructed vector. We give the grounds for
this modified version of STE, which we call Transfer Entropy on Rank Vectors
(TERV). Then we propose to use more than one step ahead in the formation of the
future of the response in order to capture the information flow from the
driving system over a longer time horizon. To assess the performance of STE, TE
and TERV in detecting correctly the information flow we use receiver operating
characteristic (ROC) curves formed by the measure values in the two coupling
directions computed on a number of realizations of known weakly coupled
systems. We also consider different settings of state space reconstruction,
time series length and observational noise. The results show that TERV indeed
improves STE and in some cases performs better than TE, particularly in the
presence of noise, but overall TE gives more consistent results. The use of
multiple steps ahead improves the accuracy of TE and TERV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0372</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0372</id><created>2010-07-02</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>K&#xfc;nnemann</keyname><forenames>Marvin</forenames></author><author><keyname>Wahlstr&#xf6;m</keyname><forenames>Magnus</forenames></author></authors><title>Randomized Rounding for Routing and Covering Problems: Experiments and
  Improvements</title><categories>cs.DS</categories><comments>Longer version of SEA 2010 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following previous theoretical work by Srinivasan (FOCS 2001) and the first
author (STACS 2006) and a first experimental evaluation on random instances
(ALENEX 2009), we investigate how the recently developed different approaches
to generate randomized roundings satisfying disjoint cardinality constraints
behave when used in two classical algorithmic problems, namely low-congestion
routing in networks and max-coverage problems in hypergraphs.
  We generally find that all randomized rounding algorithms work well, much
better than what is guaranteed by existing theoretical work. The derandomized
versions produce again significantly better rounding errors, with running times
still negligible compared to the one for solving the corresponding LP. It thus
seems worth preferring them over the randomized variants.
  The data created in these experiments lets us propose and investigate the
following new ideas. For the low-congestion routing problems, we suggest to
solve a second LP, which yields the same congestion, but aims at producing a
solution that is easier to round. Experiments show that this reduces the
rounding errors considerably, both in combination with randomized and
derandomized rounding.
  For the max-coverage instances, we generally observe that the greedy
heuristics also performs very good. We develop a strengthened method of
derandomized rounding, and a simple greedy/rounding hybrid approach using
greedy and LP-based rounding elements, and observe that both these improvements
yield again better solutions than both earlier approaches on their own.
  For unit disk max-domination, we also develop a PTAS. Contrary to all other
algorithms investigated, it performs not much better in experiments than in
theory; thus, unless extremely good solutions are to be obtained with huge
computational resources, greedy, LP-based rounding or hybrid approaches are
preferable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0376</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0376</id><created>2010-06-25</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan M.</forenames></author></authors><title>The Transfer of Evolved Artificial Immune System Behaviours between
  Small and Large Scale Robotic Platforms</title><categories>cs.NE cs.RO</categories><comments>12 pages, 3 figures, 2 tables, 9th International Conference on
  Artificial Evolution (EA 09),</comments><journal-ref>Proceedings of the 9th International Conference on Artificial
  Evolution (EA 09), LNCS 5975, Strasbourg, France, 2010, p 122-133</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates that a set of behaviours evolved in simulation on a
miniature robot (epuck) can be transferred to a much larger scale platform (a
virtual Pioneer P3-DX) that also differs in shape, sensor type, sensor
configuration and programming interface. The chosen architecture uses a
reinforcement learning-assisted genetic algorithm to evolve the epuck
behaviours, which are encoded as a genetic sequence. This sequence is then used
by the Pioneers as part of an adaptive, idiotypic artificial immune system
(AIS) control architecture. Testing in three different simulated worlds shows
that the Pioneer can use these behaviours to navigate and solve object-tracking
tasks successfully, as long as its adaptive AIS mechanism is in place.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0379</identifier>
 <datestamp>2013-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0379</id><created>2010-07-02</created><updated>2013-04-11</updated><authors><author><keyname>Lim</keyname><forenames>Fabian</forenames></author><author><keyname>Kavcic</keyname><forenames>Aleksandar</forenames></author></authors><title>Reliability Distributions of Truncated Max-log-map (MLM) Detectors
  Applied to ISI Channels</title><categories>cs.IT math.IT</categories><comments>17 pages, 11 figures</comments><journal-ref>IEEE Trans. on Inform. Theory, Volume 59, Issue 4, pp. 2411-2425,
  April 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The max-log-map (MLM) receiver is an approximated version of the well-known,
Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. The MLM algorithm is attractive due
to its implementation simplicity. In practice, sliding-window implementations
are preferred; these practical implementations consider truncated signaling
neighborhoods around each transmission time instant. In this paper, we consider
sliding-window MLM receivers, where for any integer m, the MLM detector is
truncated to a length- m signaling neighborhood. For any number n of chosen
times instants, we derive exact expressions for both i) the joint distribution
of the MLM symbol reliabilities, and ii) the joint probability of the erroneous
MLM symbol detections. We show that the obtained expressions can be efficiently
evaluated using Monte-Carlo techniques. Our proposed method is efficient; the
most computationally expensive operation (in each Monte-Carlo trial) is an
eigenvalue decomposition of a size 2mn by 2mn matrix. Practical truncation
lengths can be easily handled. Finally, our proposed method is extremely
general, and various scenarios such as correlated noise distributions,
modulation coding, etc. may be easily accommodated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0380</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0380</id><created>2010-07-01</created><authors><author><keyname>Gupta</keyname><forenames>Mithun Das</forenames></author></authors><title>Additive Non-negative Matrix Factorization for Missing Data</title><categories>cs.NA cs.LG</categories><comments>General extension of the NMF framework</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative matrix factorization (NMF) has previously been shown to be a
useful decomposition for multivariate data. We interpret the factorization in a
new way and use it to generate missing attributes from test data. We provide a
joint optimization scheme for the missing attributes as well as the NMF
factors. We prove the monotonic convergence of our algorithms. We present
classification results for cases with missing attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0381</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0381</id><created>2010-07-01</created><authors><author><keyname>Ndoundam</keyname><forenames>Ren&#xe9;</forenames><affiliation>INRIA - IRISA, INRIA - IRISA</affiliation></author><author><keyname>Tchuente</keyname><forenames>Maurice</forenames><affiliation>INRIA - IRISA, INRIA - IRISA</affiliation></author><author><keyname>Tadonki</keyname><forenames>Claude</forenames><affiliation>INRIA - IRISA, INRIA - IRISA</affiliation></author></authors><title>Parallel Chip Firing Game associated with n-cube orientations</title><categories>cs.DM</categories><proxy>ccsd</proxy><journal-ref>International Conference on Computational Science 2004, ICCS 2004,
  Krakov : Poland (2004)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the cycles generated by the chip firing game associated with n-cube
orientations. We show the existence of the cycles generated by parallel
evolutions of even lengths from 2 to $2^n$ on $H_n$ (n &gt;= 1), and of odd
lengths different from 3 and ranging from 1 to $2^{n-1}-1$ on $H_n$ (n &gt;= 4).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0391</identifier>
 <datestamp>2012-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0391</id><created>2010-07-02</created><updated>2012-08-23</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>Approximate Counting for Complex-Weighted Boolean Constraint
  Satisfaction Problems</title><categories>cs.CC</categories><comments>A4, 10 point, 25 pages. This version significantly improves its
  conference version that appeared in the Proceedings of the 8th Workshop on
  Approximation and Online Algorithms (WAOA 2010), Lecture Notes in Computer
  Science, Springer-Verlag, Vol.6534, pp.261-272, 2011</comments><msc-class>68Q15, 68Q17, 68W20, 68W25, 68W40</msc-class><journal-ref>(journal version) Information and Computation Vol.219, pp.17-38,
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint satisfaction problems (or CSPs) have been extensively studied in,
for instance, artificial intelligence, database theory, graph theory, and
statistical physics. From a practical viewpoint, it is beneficial to
approximately solve those CSPs. When one tries to approximate the total number
of truth assignments that satisfy all Boolean-valued constraints for
(unweighted) Boolean CSPs, there is a known trichotomy theorem by which all
such counting problems are neatly classified into exactly three categories
under polynomial-time (randomized) approximation-preserving reductions. In
contrast, we obtain a dichotomy theorem of approximate counting for
complex-weighted Boolean CSPs, provided that all complex-valued unary
constraints are freely available to use. It is the expressive power of free
unary constraints that enables us to prove such a stronger, complete
classification theorem. This discovery makes a step forward in the quest for
the approximation-complexity classification of all counting CSPs. To deal with
complex weights, we employ proof techniques of factorization and arity
reduction along the line of solving Holant problems. Moreover, we introduce a
novel notion of T-constructibility that naturally induces
approximation-preserving reducibility. Our result also gives an approximation
analogue of the dichotomy theorem on the complexity of exact counting for
complex-weighted Boolean CSPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0394</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0394</id><created>2010-07-02</created><authors><author><keyname>Vlachos</keyname><forenames>Ioannis</forenames></author><author><keyname>Kugiumtzis</keyname><forenames>Dimitris</forenames></author></authors><title>Non-uniform state space reconstruction and coupling detection</title><categories>nlin.CD cs.IT math.IT physics.data-an q-bio.NC stat.ME</categories><comments>21 pages, 11 figures, to be published in Physical Review E</comments><doi>10.1103/PhysRevE.82.016207</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the state space reconstruction from multiple time series
derived from continuous and discrete systems and propose a method for building
embedding vectors progressively using information measure criteria regarding
past, current and future states. The embedding scheme can be adapted for
different purposes, such as mixed modelling, cross-prediction and Granger
causality. In particular we apply this method in order to detect and evaluate
information transfer in coupled systems. As a practical application, we
investigate in records of scalp epileptic EEG the information flow across brain
areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0404</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0404</id><created>2010-07-02</created><authors><author><keyname>Mitchell</keyname><forenames>David G. M.</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Lentmaier</keyname><forenames>Michael</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Quasi-Cyclic Asymptotically Regular LDPC Codes</title><categories>cs.IT math.IT</categories><comments>To be presented at the 2010 IEEE Information Theory Workshop, Dublin,
  Ireland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Families of &quot;asymptotically regular&quot; LDPC block code ensembles can be formed
by terminating (J,K)-regular protograph-based LDPC convolutional codes. By
varying the termination length, we obtain a large selection of LDPC block code
ensembles with varying code rates, minimum distance that grows linearly with
block length, and capacity approaching iterative decoding thresholds, despite
the fact that the terminated ensembles are almost regular. In this paper, we
investigate the properties of the quasi-cyclic (QC) members of such an
ensemble. We show that an upper bound on the minimum Hamming distance of
members of the QC sub-ensemble can be improved by careful choice of the
component protographs used in the code construction. Further, we show that the
upper bound on the minimum distance can be improved by using arrays of
circulants in a graph cover of the protograph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0408</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0408</id><created>2010-07-02</created><updated>2010-11-06</updated><authors><author><keyname>Mascetti</keyname><forenames>Sergio</forenames></author><author><keyname>Freni</keyname><forenames>Dario</forenames></author><author><keyname>Bettini</keyname><forenames>Claudio</forenames></author><author><keyname>Wang</keyname><forenames>X. Sean</forenames></author><author><keyname>Jajodia</keyname><forenames>Sushil</forenames></author></authors><title>Privacy in geo-social networks: proximity notification with untrusted
  service providers and curious buddies</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major feature of the emerging geo-social networks is the ability to notify
a user when one of his friends (also called buddies) happens to be
geographically in proximity with the user. This proximity service is usually
offered by the network itself or by a third party service provider (SP) using
location data acquired from the users. This paper provides a rigorous
theoretical and experimental analysis of the existing solutions for the
location privacy problem in proximity services. This is a serious problem for
users who do not trust the SP to handle their location data, and would only
like to release their location information in a generalized form to
participating buddies. The paper presents two new protocols providing complete
privacy with respect to the SP, and controllable privacy with respect to the
buddies. The analytical and experimental analysis of the protocols takes into
account privacy, service precision, and computation and communication costs,
showing the superiority of the new protocols compared to those appeared in the
literature to date. The proposed protocols have also been tested in a full
system implementation of the proximity service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0409</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0409</id><created>2010-07-01</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author><author><keyname>Milton</keyname><forenames>Leslie</forenames></author></authors><title>A Performance Comparison of Stability, Load-Balancing and Power-Aware
  Routing Protocols for Mobile Ad Hoc Networks</title><categories>cs.NI</categories><comments>http://ijict.org/index.php/ijoat/article/view/performance-comparison-manet-routing-protocols</comments><journal-ref>International Journal of Advancements in Technology, Vol 1, No 1
  (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The high-level contribution of this paper is a simulation-based detailed
performance comparison of three different classes of routing protocols for
mobile ad hoc networks: stability-based routing, power-aware routing and
load-balanced routing. We choose the Flow-Oriented Routing protocol (FORP), the
traffic interference based Load Balancing Routing (LBR) protocol and Min-Max
Battery Cost Routing (MMBCR) as representatives of the stability-based routing,
load-balancing and power-aware routing protocols respectively. Among the three
routing protocols, FORP incurs the least number of route transitions; while LBR
incurs the smallest hop count and lowest end-to-end delay per data packet.
Energy consumed per node is the least for MMBCR, closely followed by LBR. MMBCR
is the most fair in terms of node usage and hence it incurs the largest time
for first node failure. FORP tends to repeatedly use nodes lying on the stable
path and hence is the most unfair of the three routing protocols and it incurs
the smallest value for the time of first node failure. As we measure the
failure times of up to the first five nodes in the network, we observe that LBR
incurs the maximum improvement in the lifetime of the nodes and MMBCR incurs
the least improvement beyond the time of first node failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0410</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0410</id><created>2010-07-01</created><authors><author><keyname>Saini</keyname><forenames>Pooja</forenames></author></authors><title>Impact Of Mobility and Transmission Range On The Performance of Backoff
  Algorithms For IEEE 802.11-Based Multi-hop Mobile Ad hoc Networks</title><categories>cs.NI</categories><comments>http://ijict.org/index.php/ijoat/article/view/impact-of-mobility-on-ieee-802-11-manets</comments><journal-ref>International Journal of Advancements in Technology, Vol 1, No 1
  (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In IEEE 802.11 Wireless Local Area Networks (WLANs), network nodes
experiencing collisions on the shared channel need to backoff for a random
period of time, which is uniformly selected from the Contention Window (CW).
This contention window is dynamically controlled by the Backoff algorithm.
First step to design a an efficient backoff algorithm for multi-hop ad hoc
network is to analysis of the existing backoff algorithms in multi-hop ad hoc
networks. Thus, in this paper, we considered two important multi-hop adhoc
network scenarios: (a) Node Mobility Scenario and (b) Transmission Range
Scenario and analyze and evaluate both the impact of mobility (i.e. node speed)
and the impact of transmission range of nodes on the performance of various
backoff algorithms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0411</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0411</id><created>2010-07-01</created><authors><author><keyname>Krishna</keyname><forenames>Addepalli V. N</forenames></author><author><keyname>Babu</keyname><forenames>A Vinay</forenames></author></authors><title>Role of Statistical tests in Estimation of the Security of a New
  Encryption Algorithm</title><categories>cs.NI</categories><comments>http://ijict.org/index.php/ijoat/article/view/statistical-tests-for-encryption-algorithm</comments><journal-ref>International Journal of Advancements in Technology, Vol 1, No 1
  (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Encryption study basically deals with three levels of algorithms. The first
algorithm deals with encryption mechanism, second deals with decryption
Mechanism and the third discusses about the generation of keys and sub keys
used in the encryption study. In the given study, a new algorithm is discussed.
The algorithm executes a series of steps and generates a sequence. This
sequence is being used as sub key to be mapped to plain text to generate cipher
text. The strength of the encryption &amp; Decryption process depends on the
strength of sequence generated against crypto analysis.. In this part of work
some statistical tests like Uniformity tests, Universal tests &amp; Repetition
tests are tried on the sequence generated to test the strength of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0412</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0412</id><created>2010-07-01</created><authors><author><keyname>Gawande</keyname><forenames>Ujwalla</forenames></author><author><keyname>Zaveri</keyname><forenames>Mukesh</forenames></author><author><keyname>Kapur</keyname><forenames>Avichal</forenames></author></authors><title>Improving Iris Recognition Accuracy By Score Based Fusion Method</title><categories>cs.AI</categories><comments>http://ijict.org/index.php/ijoat/article/view/improving-iris-recognition</comments><journal-ref>International Journal of Advancements in Technology, Vol 1, No 1
  (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Iris recognition technology, used to identify individuals by photographing
the iris of their eye, has become popular in security applications because of
its ease of use, accuracy, and safety in controlling access to high-security
areas. Fusion of multiple algorithms for biometric verification performance
improvement has received considerable attention. The proposed method combines
the zero-crossing 1 D wavelet Euler number, and genetic algorithm based for
feature extraction. The output from these three algorithms is normalized and
their score are fused to decide whether the user is genuine or imposter. This
new strategies is discussed in this paper, in order to compute a multimodal
combined score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0413</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0413</id><created>2010-07-01</created><authors><author><keyname>Juneja</keyname><forenames>Dimple</forenames></author><author><keyname>Arora</keyname><forenames>Neha</forenames></author></authors><title>An Ant Based Framework for Preventing DDoS Attack in Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>ISSN : 0976-4860 (Online).
  http://ijict.org/index.php/ijoat/article/view/ant-based-framework-ddos-wsn</comments><journal-ref>International Journal of Advancements in Technology (IJoAT), Vol
  1, No 1 (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Security and Privacy are two important parameters that need to be considered
when dealing with wireless sensor networks as WSN operate in an unattended
environment and carry sensitive information critical to the application.
However, applying security techniques that consume minimum resources is still a
challenge and this paper makes an attempt to address the same. One of the major
attacks in sensor network is denial of service attack that not only diminishes
the network capacity but also affects the reliability of information being
transmitted. This work is an extension of our previous work which could
successfully detect DDoS using ants. However, no emphasis was made towards the
prevention mechanism. In this paper an ant-based framework that exploits the
significance of stateless and stateful signatures and hence preserving the
legtimate packets only, thereby discarding the contaminated packets has been
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0417</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0417</id><created>2010-07-02</created><authors><author><keyname>Lingashetty</keyname><forenames>Krishna Chaithanya</forenames></author></authors><title>Delta Learning Rule for the Active Sites Model</title><categories>cs.NE</categories><comments>12 Pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the results on methods of comparing the memory retrieval
capacity of the Hebbian neural network which implements the B-Matrix approach,
by using the Widrow-Hoff rule of learning. We then, extend the recently
proposed Active Sites model by developing a delta rule to increase memory
capacity. Also, this paper extends the binary neural network to a multi-level
(non-binary) neural network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0436</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0436</id><created>2010-07-02</created><authors><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Transmit Energy Focusing for DOA Estimation in MIMO Radar with Colocated
  Antennas</title><categories>cs.IT math.IT</categories><comments>29 pages, 9 figures, submitted to IEEE Trans. Signal Processing in
  June 2010</comments><report-no>IEEE Trans. Signal Processing, vol. 59, no. 6, pp. 2669-2682, June
  2011</report-no><journal-ref>A. Hassanien and S.A. Vorobyov, &quot;Transmit energy focusing for DOA
  estimation in MIMO radar with colocated antennas,&quot; IEEE Trans. Signal
  Processing, vol. 59, no. 6, pp. 2669-2682, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a transmit beamspace energy focusing technique for
multiple-input multiple-output (MIMO) radar with application to direction
finding for multiple targets. The general angular directions of the targets are
assumed to be located within a certain spatial sector. We focus the energy of
multiple (two or more) transmitted orthogonal waveforms within that spatial
sector using transmit beamformers which are designed to improve the
signal-to-noise ratio (SNR) gain at each receive antenna. The subspace
decomposition-based techniques such as MUSIC can then be used for direction
finding for multiple targets. Moreover, the transmit beamformers can be
designed so that matched-filtering the received data to the waveforms yields
multiple (two or more) data sets with rotational invariance property that
allows applying search-free direction finding techniques such as ESPRIT for two
data sets or parallel factor analysis (PARAFAC) for more than two data sets.
Unlike previously reported MIMO radar ESPRIT/PARAFAC-based direction finding
techniques, our method achieves the rotational invariance property in a
different manner combined also with the transmit energy focusing. As a result,
it achieves better estimation performance at lower computational cost.
Particularly, the proposed technique leads to lower Cramer-Rao bound than the
existing techniques due to the transmit energy focusing capability. Simulation
results also show the superiority of the proposed technique over the existing
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0449</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0449</id><created>2010-07-02</created><authors><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author><author><keyname>Sole</keyname><forenames>Patrick</forenames></author></authors><title>Unimodular Lattices for the Gaussian Wiretap Channel</title><categories>cs.IT cs.CR math.IT</categories><comments>6 pages, 9 figures, 2010 Information Theory Workshop, Dublin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, the authors introduced a lattice invariant called &quot;Secrecy
Gain&quot; which measures the confusion experienced by a passive eavesdropper on the
Gaussian Wiretap Channel. We study, here, the behavior of this invariant for
unimodular lattices by using tools from Modular Forms and show that, for some
families of unimodular lattices, indexed by the dimension, the secrecy gain
exponentially goes to infinity with the dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0465</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0465</id><created>2010-07-02</created><authors><author><keyname>Cai</keyname><forenames>K.</forenames></author><author><keyname>Letaief</keyname><forenames>K. B.</forenames></author><author><keyname>Fan</keyname><forenames>P.</forenames></author><author><keyname>Feng</keyname><forenames>R.</forenames></author></authors><title>On the Solvability of 2-pair Unicast Networks --- A Cut-based
  Characterization</title><categories>cs.IT math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a subnetwork decomposition/combination approach to
investigate the single rate $2$-pair unicast problem. It is shown that the
solvability of a $2$-pair unicast problem is completely determined by four
specific link subsets, namely, $\mathcal A_{1,1}$, $\mathcal A_{2,2}$,
$\mathcal A_{1,2}$ and $\mathcal A_{2,1}$ of its underlying network. As a
result, an efficient cut-based algorithm to determine the solvability of a
$2$-pair unicast problem is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0467</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0467</id><created>2010-07-03</created><updated>2011-03-22</updated><authors><author><keyname>Ishiu</keyname><forenames>Tetsuya</forenames></author></authors><title>Notes on higher-dimensional tarai functions</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proved that for every $n\geq 3$, the $n$-dimensional tarai function
terminates with call-by-need. It was also shown that the closed form for the
function suggested by T. Bailey and J. Cowles is correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0481</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0481</id><created>2010-07-03</created><authors><author><keyname>Kim</keyname><forenames>Byung-Hak</forenames></author><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>IMP: A Message-Passing Algorithmfor Matrix Completion</title><categories>cs.IT cs.LG math.IT</categories><comments>To appear in Proc. 6th International Symposium on Turbo Codes and
  Iterative Information Processing, Brest, France, September 6-10, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new message-passing (MP) method is considered for the matrix completion
problem associated with recommender systems. We attack the problem using a
(generative) factor graph model that is related to a probabilistic low-rank
matrix factorization. Based on the model, we propose a new algorithm, termed
IMP, for the recovery of a data matrix from incomplete observations. The
algorithm is based on a clustering followed by inference via MP (IMP). The
algorithm is compared with a number of other matrix completion algorithms on
real collaborative filtering (e.g., Netflix) data matrices. Our results show
that, while many methods perform similarly with a large number of revealed
entries, the IMP algorithm outperforms all others when the fraction of observed
entries is small. This is helpful because it reduces the well-known cold-start
problem associated with collaborative filtering (CF) systems in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0484</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0484</id><created>2010-07-03</created><authors><author><keyname>Nelson</keyname><forenames>Blaine</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Huang</keyname><forenames>Ling</forenames></author><author><keyname>Joseph</keyname><forenames>Anthony D.</forenames></author><author><keyname>Lee</keyname><forenames>Steven J.</forenames></author><author><keyname>Rao</keyname><forenames>Satish</forenames></author><author><keyname>Tygar</keyname><forenames>J. D.</forenames></author></authors><title>Query Strategies for Evading Convex-Inducing Classifiers</title><categories>cs.LG cs.CR cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifiers are often used to detect miscreant activities. We study how an
adversary can systematically query a classifier to elicit information that
allows the adversary to evade detection while incurring a near-minimal cost of
modifying their intended malfeasance. We generalize the theory of Lowd and Meek
(2005) to the family of convex-inducing classifiers that partition input space
into two sets one of which is convex. We present query algorithms for this
family that construct undetected instances of approximately minimal cost using
only polynomially-many queries in the dimension of the space and in the level
of approximation. Our results demonstrate that near-optimal evasion can be
accomplished without reverse-engineering the classifier's decision boundary. We
also consider general lp costs and show that near-optimal evasion on the family
of convex-inducing classifiers is generally efficient for both positive and
negative convexity for all levels of approximation if p=1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0489</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0489</id><created>2010-07-03</created><authors><author><keyname>Chepoi</keyname><forenames>Victor</forenames></author><author><keyname>Dragan</keyname><forenames>Feodor</forenames></author><author><keyname>Newman</keyname><forenames>Ilan</forenames></author><author><keyname>Rabinovich</keyname><forenames>Yuri</forenames></author><author><keyname>Vaxes</keyname><forenames>Yann</forenames></author></authors><title>Constant approximation algorithms for embedding graph metrics into trees
  and outerplanar graphs</title><categories>math.MG cs.DS</categories><comments>27 pages, 4 figires, extended abstract to appear in the proceedings
  of APPROX-RANDOM 2010</comments><journal-ref>Discrete &amp; Computational Geometry 47 (2012), 187-214</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a simple factor 6 algorithm for approximating the
optimal multiplicative distortion of embedding a graph metric into a tree
metric (thus improving and simplifying the factor 100 and 27 algorithms of
B\v{a}doiu, Indyk, and Sidiropoulos (2007) and B\v{a}doiu, Demaine, Hajiaghayi,
Sidiropoulos, and Zadimoghaddam (2008)). We also present a constant factor
algorithm for approximating the optimal distortion of embedding a graph metric
into an outerplanar metric. For this, we introduce a general notion of metric
relaxed minor and show that if G contains an alpha-metric relaxed H-minor, then
the distortion of any embedding of G into any metric induced by a H-minor free
graph is at meast alpha. Then, for H=K_{2,3}, we present an algorithm which
either finds an alpha-relaxed minor, or produces an O(alpha)-embedding into an
outerplanar metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0496</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0496</id><created>2010-07-03</created><authors><author><keyname>Chen</keyname><forenames>Yang</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Perturbed Hankel Determinants: Applications to the Information Theory of
  MIMO Wireless Communications</title><categories>cs.IT math.IT</categories><comments>77 pages; 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we compute two important information-theoretic quantities which
arise in the application of multiple-input multiple-output (MIMO) antenna
wireless communication systems: the distribution of the mutual information of
multi-antenna Gaussian channels, and the Gallager random coding upper bound on
the error probability achievable by finite-length channel codes. It turns out
that the mathematical problem underpinning both quantities is the computation
of certain Hankel determinants generated by deformed versions of classical
weight functions. For single-user MIMO systems, it is a deformed Laguerre
weight, whereas for multi-user MIMO systems it is a deformed Jacobi weight. We
apply two different methods to characterize each of these Hankel determinants.
First, we employ the ladder operators of the corresponding monic orthogonal
polynomials to give an exact characterization of the Hankel determinants in
terms of Painlev\'{e} differential equations. This turns out to be a
Painlev\'{e} V for the single-user MIMO scenario and a Painlev\'{e} VI for the
multi user scenario. We then employ Coulomb fluid methods to derive new
closed-form approximations for the Hankel determinants which, although formally
valid for large matrix dimensions, are shown to give accurate results for both
the MIMO mutual information distribution and the error exponent even when the
matrix dimensions are small. Focusing on the single-user mutual information
distribution, we then employ both the exact Painlev\'{e} representation and the
Coulomb fluid approximation to yield deeper insights into the scaling behavior
in terms of the number of antennas and signal-to-noise ratio. Among other
things, these results allow us to study the asymptotic Gaussianity of the
distribution as the number of antennas increase, and to explicitly compute the
correction terms to the mean, variance, and higher order cumulants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0501</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0501</id><created>2010-07-03</created><authors><author><keyname>Langford</keyname><forenames>Glenn</forenames></author></authors><title>An Improved Neighbourhood for the Traveling Tournament Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Traveling Tournament Problem (TTP) is a challenging combinatorial
optimization problem that has attracted the interest of researchers around the
world. This paper proposes an improved search neighbourhood for the TTP that
has been tested in a simulated annealing context. The neighbourhood encompasses
both feasible and infeasible schedules, and can be generated efficiently. For
the largest TTP challenge problems with up to 40 teams, solutions found using
this neighbourhood are the best currently known, and for smaller problems with
10 teams, three solutions found were subsequently proven optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0507</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0507</id><created>2010-07-03</created><updated>2010-07-11</updated><authors><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Femto-Macro Cellular Interference Control with Subband Scheduling and
  Interference Cancelation</title><categories>cs.NI</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant technical challenge in deploying femtocells is controlling the
interference from the underlay of femtos onto the overlay of macros. This paper
presents a novel interference control method where the macrocell bandwidth is
partitioned into subbands, and the short-range femtocell links adaptively
allocate their power across the subbands based on a load-spillage power control
method. The scheme can improve rate distribution in the macro network while
also providing opportunities for short-range communication as well. Moreover,
the proposed scheme requires minimal interference coordination communication
between the femtos and macros, which is one of the main challenges in femtocell
systems. Also, simulations show certain advantages over simpler
orthogonalization schemes or power control schemes without subband
partitioning. Further modest gains may also be possible with interference
cancelation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0512</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0512</id><created>2010-07-03</created><updated>2012-02-08</updated><authors><author><keyname>Peters</keyname><forenames>Steven W.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>User Partitioning for Less Overhead in MIMO Interference Channels</title><categories>cs.IT math.IT</categories><comments>34 pages, 11 figures, to appear in IEEE Trans. Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a study on multiple-antenna interference channels,
accounting for general overhead as a function of the number of users and
antennas in the network. The model includes both perfect and imperfect channel
state information based on channel estimation in the presence of noise. Three
low complexity methods are proposed for reducing the impact of overhead in the
sum network throughput by partitioning users into orthogonal groups. The first
method allocates spectrum to the groups equally, creating an imbalance in the
sum rate of each group. The second proposed method allocates spectrum unequally
among the groups to provide rate fairness. Finally, geographic grouping is
proposed for cases where some receivers do not observe significant interference
from other transmitters. For each partitioning method, the optimal solution not
only requires a brute force search over all possible partitions, but also
requires full channel state information, thereby defeating the purpose of
partitioning. We therefore propose greedy methods to solve the problems,
requiring no instantaneous channel knowledge. Simulations show that the
proposed greedy methods switch from time-division to interference alignment as
the coherence time of the channel increases, and have a small loss relative to
optimal partitioning only at moderate coherence times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0515</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0515</id><created>2010-07-03</created><updated>2012-02-20</updated><authors><author><keyname>Dandekar</keyname><forenames>Pranav</forenames></author><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Govindan</keyname><forenames>Ramesh</forenames></author><author><keyname>Post</keyname><forenames>Ian</forenames></author></authors><title>Liquidity in Credit Networks: A Little Trust Goes a Long Way</title><categories>q-fin.TR cs.DS cs.GT</categories><comments>Version that appeared in ACM EC '11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Credit networks represent a way of modeling trust between entities in a
network. Nodes in the network print their own currency and trust each other for
a certain amount of each other's currency. This allows the network to serve as
a decentralized payment infrastructure---arbitrary payments can be routed
through the network by passing IOUs between trusting nodes in their respective
currencies---and obviates the need for a common currency. Nodes can repeatedly
transact with each other and pay for the transaction using trusted currency. A
natural question to ask in this setting is: how long can the network sustain
liquidity, i.e., how long can the network support the routing of payments
before credit dries up? We answer this question in terms of the long term
failure probability of transactions for various network topologies and credit
values.
  We prove that the transaction failure probability is independent of the path
along which transactions are routed. We show that under symmetric transaction
rates, the transaction failure probability in a number of well-known graph
families goes to zero as the size, density or credit capacity of the network
increases. We also show via simulations that even networks of small size and
credit capacity can route transactions with high probability if they are
well-connected. Further, we characterize a centralized currency system as a
special type of a star network (one where edges to the root have infinite
credit capacity, and transactions occur only between leaf nodes) and compute
the steady-state transaction failure probability in a centralized system. We
show that liquidity in star networks, complete graphs and Erd\&quot;{o}s-R\'{e}nyi
networks is comparable to that in equivalent centralized currency systems; thus
we do not lose much liquidity in return for their robustness and decentralized
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0522</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0522</id><created>2010-07-03</created><updated>2011-02-21</updated><authors><author><keyname>Badr</keyname><forenames>Ahmed</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Martinian</keyname><forenames>Emin</forenames></author></authors><title>Diversity Embedded Streaming Erasure Codes (DE-SCo): Constructions and
  Optimality</title><categories>cs.IT cs.NI math.IT</categories><comments>JSAC, May 2011, Special Issue on Trading Rate for Delay at the
  Transport and Application Layers, Shorter version will appear in Globecom
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Streaming erasure codes guarantee that each source packet is recovered within
a fixed delay at the receiver over a burst-erasure channel. This paper
introduces a new class of streaming codes: Diversity Embedded Streaming Erasure
Codes (DE-SCo), that provide a flexible tradeoff between the channel quality
and receiver delay. When the channel conditions are good, the source stream is
recovered with a low delay, whereas when the channel conditions are poor the
source stream is still recovered, albeit with a larger delay. Information
theoretic analysis of the underlying burst-erasure broadcast channel reveals
that DE-SCo achieve the minimum possible delay for the weaker user, without
sacrificing the single-user optimal performance of the stronger user. Our
constructions are explicit, incur polynomial time encoding and decoding
complexity and outperform random linear codes over burst-erasure channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0523</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0523</id><created>2010-07-03</created><authors><author><keyname>Wang</keyname><forenames>Farn</forenames></author></authors><title>Simulation-Checking of Real-Time Systems with Fairness Assumptions</title><categories>cs.LO</categories><comments>18 pages, 5 figures, part of the materials appear in the proceedings
  of FOMRATS 2007 and HSCC 2009</comments><acm-class>D.2.4; F.3.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We investigate the simulation problem in of dense-time system. A
specification simulates a model if the specification can match every transition
that the model can make at a time point. We also adapt the approach of Emerson
and Lei and allow for multiple strong and weak fairness assumptions in checking
the simulation relation. Furthermore, we allow for fairness assumptions
specified as either state-predicates or event-predicates. We focus on a
subclass of the problem with at most one fairness assumption for the
specification. We then present a simulation-checking algorithm for this
subclass. We propose simulation of a model by a specification against a common
environment. We present efficient techniques for such simulations to take the
common environment into consideration. Our experiment shows that such a
consideration can dramatically improve the efficiency of checking simulation.
We also report the performance of our algorithm in checking the liveness
properties with fairness assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0528</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0528</id><created>2010-07-04</created><updated>2010-12-19</updated><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author></authors><title>Binary Independent Component Analysis with OR Mixtures</title><categories>cs.IT cs.NI math.IT</categories><comments>Manuscript submitted to IEEE Transactions on Signal Processing</comments><acm-class>G.3</acm-class><doi>10.1109/TSP.2011.2144975</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Independent component analysis (ICA) is a computational method for separating
a multivariate signal into subcomponents assuming the mutual statistical
independence of the non-Gaussian source signals. The classical Independent
Components Analysis (ICA) framework usually assumes linear combinations of
independent sources over the field of realvalued numbers R. In this paper, we
investigate binary ICA for OR mixtures (bICA), which can find applications in
many domains including medical diagnosis, multi-cluster assignment, Internet
tomography and network resource management. We prove that bICA is uniquely
identifiable under the disjunctive generation model, and propose a
deterministic iterative algorithm to determine the distribution of the latent
random variables and the mixing matrix. The inverse problem concerning
inferring the values of latent variables are also considered along with noisy
measurements. We conduct an extensive simulation study to verify the
effectiveness of the propose algorithm and present examples of real-world
applications where bICA can be applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0542</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0542</id><created>2010-07-04</created><authors><author><keyname>Pentzaropoulos</keyname><forenames>G. C.</forenames></author></authors><title>Limits of responsiveness concerning human-readable knowledge bases: an
  operational analysis</title><categories>cs.DL cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introduction. The purpose of this work is the evaluation of responsiveness
when remote users communicate with a human-readable knowledge base (KB).
Responsiveness [R(s)] is considered here as a measure of service quality.
Method. The preferred method is operational analysis, a variation of classical
stochastic theory, which allows for the study of user-system interaction with
minimal computational effort. Analysis. The analysis is based on well-known
performance metrics, such as service ability, elapsed time, and throughput:
from these metrics estimates of R(s) are derived analytically. Results.
Critical points indicating congestion are obtained: these are limits on the
number of admissible requests and the number of connected users. Also obtained
is a sufficient condition for achieving flow balance between the KB host and
the request-relaying servers. Conclusions. When R(s) is within normal limits,
users should appreciate the benefits from using the services offered by their
KB host. When bottlenecks are formed, R(s) declines, and the whole
communication system heads for saturation. Flow balancing procedures are
necessary for the elimination of bottlenecks, which leads to a better resource
management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0546</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0546</id><created>2010-07-04</created><updated>2013-07-13</updated><authors><author><keyname>Yahya</keyname><forenames>Keyvan</forenames></author><author><keyname>Fard</keyname><forenames>Pouyan Rafiei</forenames></author></authors><title>Computational Model of Music Sight Reading: A Reinforcement Learning
  Approach</title><categories>cs.AI cs.LG cs.NE math.OC</categories><comments>This paper is withdrawn by author due to incomplete justification of
  the model</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the Music Sight Reading process has been studied from the cognitive
psychology view points, but the computational learning methods like the
Reinforcement Learning have not yet been used to modeling of such processes. In
this paper, with regards to essential properties of our specific problem, we
consider the value function concept and will indicate that the optimum policy
can be obtained by the method we offer without to be getting involved with
computing of the complex value functions. Also, we will offer a normative
behavioral model for the interaction of the agent with the musical pitch
environment and by using a slightly different version of Partially observable
Markov decision processes we will show that our method helps for faster
learning of state-action pairs in our implemented agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0547</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0547</id><created>2010-07-04</created><authors><author><keyname>Singh</keyname><forenames>Chandan</forenames></author><author><keyname>Bhatia</keyname><forenames>Nitin</forenames></author></authors><title>A Fast Decision Technique for Hierarchical Hough Transform for Line
  Detection</title><categories>cs.CV</categories><comments>7 pages, published at IEEE conference on Signal and Image Processing
  - 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many techniques have been proposed to speedup the performance of classic
Hough Transform. These techniques are primarily based on converting the voting
procedure to a hierarchy based voting method. These methods use approximate
decision-making process. In this paper, we propose a fast decision making
process that enhances the speed and reduces the space requirements.
Experimental results demonstrate that the proposed algorithm is much faster
than a similar Fast Hough Transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0548</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0548</id><created>2010-07-04</created><updated>2011-11-18</updated><authors><author><keyname>Yahya</keyname><forenames>Keyvan</forenames></author><author><keyname>Fard</keyname><forenames>Pouyan Rafiei</forenames></author></authors><title>A Reinforcement Learning Model Using Neural Networks for Music Sight
  Reading Learning Problem</title><categories>cs.LG cs.NE</categories><comments>This paper is withdrawn because of its lack of novelty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music Sight Reading is a complex process in which when it is occurred in the
brain some learning attributes would be emerged. Besides giving a model based
on actor-critic method in the Reinforcement Learning, the agent is considered
to have a neural network structure. We studied on where the sight reading
process is happened and also a serious problem which is how the synaptic
weights would be adjusted through the learning process. The model we offer here
is a computational model on which an updated weights equation to fix the
weights is accompanied too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0549</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0549</id><created>2010-07-04</created><updated>2011-09-28</updated><authors><author><keyname>Genovese</keyname><forenames>Christopher</forenames></author><author><keyname>Perone-Pacifico</keyname><forenames>Marco</forenames></author><author><keyname>Verdinelli</keyname><forenames>Isabella</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Minimax Manifold Estimation</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>journal submission, revision with some errors corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We find the minimax rate of convergence in Hausdorff distance for estimating
a manifold M of dimension d embedded in R^D given a noisy sample from the
manifold. We assume that the manifold satisfies a smoothness condition and that
the noise distribution has compact support. We show that the optimal rate of
convergence is n^{-2/(2+d)}. Thus, the minimax rate depends only on the
dimension of the manifold, not on the dimension of the space in which M is
embedded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0563</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0563</id><created>2010-07-04</created><updated>2010-11-13</updated><authors><author><keyname>Vats</keyname><forenames>Divyanshu</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Graphical Models as Block-Tree Graphs</title><categories>stat.ML cs.IT math.IT math.PR</categories><comments>29 pages. Correction to version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce block-tree graphs as a framework for deriving efficient
algorithms on graphical models. We define block-tree graphs as a
tree-structured graph where each node is a cluster of nodes such that the
clusters in the graph are disjoint. This differs from junction-trees, where two
clusters connected by an edge always have at least one common node. When
compared to junction-trees, we show that constructing block-tree graphs is
faster, and finding optimal block-tree graphs has a much smaller search space.
Applying our block-tree graph framework to graphical models, we show that, for
some graphs, e.g., grid graphs, using block-tree graphs for inference is
computationally more efficient than using junction-trees. For graphical models
with boundary conditions, the block-tree graph framework transforms the
boundary valued problem into an initial value problem. For Gaussian graphical
models, the block-tree graph framework leads to a linear state-space
representation. Since exact inference in graphical models can be
computationally intractable, we propose to use spanning block-trees to derive
approximate inference algorithms. Experimental results show the improved
performance in using spanning block-trees versus using spanning trees for
approximate estimation over Gaussian graphical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0566</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0566</id><created>2010-07-04</created><updated>2011-05-17</updated><authors><author><keyname>B&#xe1;nyai</keyname><forenames>M.</forenames></author><author><keyname>N&#xe9;gyessy</keyname><forenames>L.</forenames></author><author><keyname>Bazs&#xf3;</keyname><forenames>F.</forenames></author></authors><title>Organisation of signal flow in directed networks</title><categories>physics.data-an cond-mat.dis-nn cs.SI physics.bio-ph physics.soc-ph stat.OT</categories><comments>27 pages, 10 figures, 3 tables</comments><journal-ref>Journal of Statistical Mechanics: Theory and Experiment, (2011)
  P06001</journal-ref><doi>10.1088/1742-5468/2011/06/P06001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Confining an answer to the question whether and how the coherent operation of
network elements is determined by the the network structure is the topic of our
work. We map the structure of signal flow in directed networks by analysing the
degree of edge convergence and the overlap between the in- and output sets of
an edge. Definitions of convergence degree and overlap are based on the
shortest paths, thus they encapsulate global network properties. Using the
defining notions of convergence degree and overlapping set we clarify the
meaning of network causality and demonstrate the crucial role of chordless
circles. In real-world networks the flow representation distinguishes nodes
according to their signal transmitting, processing and control properties. The
analysis of real-world networks in terms of flow representation was in
accordance with the known functional properties of the network nodes. It is
shown that nodes with different signal processing, transmitting and control
properties are randomly connected at the global scale, while local connectivity
patterns depart from randomness. Grouping network nodes according to their
signal flow properties was unrelated to the network's community structure. We
present evidence that signal flow properties of small-world-like, real-world
networks can not be reconstructed by algorithms used to generate small-world
networks. Convergence degree values were calculated for regular oriented trees,
and its probability density function for networks grown with the preferential
attachment mechanism. For Erd\H{o}s-R\'enyi graphs we calculated both the
probability density function of convergence degrees and of overlaps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0571</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0571</id><created>2010-07-04</created><updated>2012-03-02</updated><authors><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author></authors><title>Quickest Detection with Social Learning: Interaction of local and global
  decision makers</title><categories>cs.GT cs.IT math.IT stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider how local and global decision policies interact in stopping time
problems such as quickest time change detection. Individual agents make myopic
local decisions via social learning, that is, each agent records a private
observation of a noisy underlying state process, selfishly optimizes its local
utility and then broadcasts its local decision. Given these local decisions,
how can a global decision maker achieve quickest time change detection when the
underlying state changes according to a phase-type distribution? The paper
presents four results. First, using Blackwell dominance of measures, it is
shown that the optimal cost incurred in social learning based quickest
detection is always larger than that of classical quickest detection. Second,
it is shown that in general the optimal decision policy for social learning
based quickest detection is characterized by multiple thresholds within the
space of Bayesian distributions. Third, using lattice programming and
stochastic dominance, sufficient conditions are given for the optimal decision
policy to consist of a single linear hyperplane, or, more generally, a
threshold curve. Estimation of the optimal linear approximation to this
threshold curve is formulated as a simulation-based stochastic optimization
problem. Finally, the paper shows that in multi-agent sensor management with
quickest detection, where each agent views the world according to its prior,
the optimal policy has a similar structure to social learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0583</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0583</id><created>2010-07-04</created><updated>2012-04-29</updated><authors><author><keyname>Hartman</keyname><forenames>Yair</forenames></author></authors><title>Large Semigroups of Cellular Automata</title><categories>math.DS cs.DM</categories><comments>20 pages, referee suggestions incorporated, to appear in Ergodic
  Theory and Dynamical Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we consider semigroups of transformations of cellular
automata which act on a fixed shift space. In particular, we are interested in
two properties of these semigroups which relate to &quot;largeness&quot;. The first
property is ID and the other property is maximal commutativity (MC). A
semigroup has the ID property if the only infinite invariant closed set (with
respect to the semigroup action) is the entire space. We shall consider two
examples of semigroups: one is spanned by cellular automata transformations
that represent multiplications by integers on the one-dimensional torus and the
other one consists of all the cellular automata transformations which are
linear (when the symbols set is the ring of integers mod n). It will be shown
that the two properties of these semigroups depend on the number of symbols s.
The multiplication semigroup is ID and MC if and only if s is not a power of
prime. The linear semigroup over the mentioned ring is always MC but is ID if
and only if s is prime. When the symbol set is endowed with a finite field
structure (when possible) the linear semigroup is both ID and MC. In addition,
we associate with each semigroup which acts on a one sided shift space a
semigroup acting on a two sided shift space, and vice versa, in such a way that
preserves the ID and the MC properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0602</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0602</id><created>2010-07-04</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>On The Complexity and Completeness of Static Constraints for Breaking
  Row and Column Symmetry</title><categories>cs.AI cs.CC</categories><comments>To appear in the Proceedings of the 16th International Conference on
  Principles and Practice of Constraint Programming (CP 2010)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a common type of symmetry where we have a matrix of decision
variables with interchangeable rows and columns. A simple and efficient method
to deal with such row and column symmetry is to post symmetry breaking
constraints like DOUBLELEX and SNAKELEX. We provide a number of positive and
negative results on posting such symmetry breaking constraints. On the positive
side, we prove that we can compute in polynomial time a unique representative
of an equivalence class in a matrix model with row and column symmetry if the
number of rows (or of columns) is bounded and in a number of other special
cases. On the negative side, we show that whilst DOUBLELEX and SNAKELEX are
often effective in practice, they can leave a large number of symmetric
solutions in the worst case. In addition, we prove that propagating DOUBLELEX
completely is NP-hard. Finally we consider how to break row, column and value
symmetry, correcting a result in the literature about the safeness of combining
different symmetry breaking constraints. We end with the first experimental
study on how much symmetry is left by DOUBLELEX and SNAKELEX on some benchmark
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0603</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0603</id><created>2010-07-04</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Decomposition of the NVALUE constraint</title><categories>cs.AI</categories><comments>To appear in the Proceedings of the 16th International Conference on
  Principles and Practice of Constraint Programming 2010 (CP 2010). An earlier
  version appeared in the Proceedings of the Eighth International Workshop on
  Constraint Modelling and Reformulation, held alongside the 15th International
  Conference on Principles and Practice of Constraint Programming (CP 2009)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study decompositions of the global NVALUE constraint. Our main
contribution is theoretical: we show that there are propagators for global
constraints like NVALUE which decomposition can simulate with the same time
complexity but with a much greater space complexity. This suggests that the
benefit of a global propagator may often not be in saving time but in saving
space. Our other theoretical contribution is to show for the first time that
range consistency can be enforced on NVALUE with the same worst-case time
complexity as bound consistency. Finally, the decompositions we study are
readily encoded as linear inequalities. We are therefore able to use them in
integer linear programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0604</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0604</id><created>2010-07-04</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Symmetry within and between solutions</title><categories>cs.AI</categories><comments>Keynote talk to appear in the Proceedings of the Eleventh Pacific Rim
  International Conference on Artificial Intelligence (PRICAI-10)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry can be used to help solve many problems. For instance, Einstein's
famous 1905 paper (&quot;On the Electrodynamics of Moving Bodies&quot;) uses symmetry to
help derive the laws of special relativity. In artificial intelligence,
symmetry has played an important role in both problem representation and
reasoning. I describe recent work on using symmetry to help solve constraint
satisfaction problems. Symmetries occur within individual solutions of problems
as well as between different solutions of the same problem. Symmetry can also
be applied to the constraints in a problem to give new symmetric constraints.
Reasoning about symmetry can speed up problem solving, and has led to the
discovery of new results in both graph and number theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0614</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0614</id><created>2010-07-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Online Cake Cutting</title><categories>cs.AI</categories><comments>To appear in Proceedings of the Third International Workshop on
  Computational Social Choice (COMSOC-2010)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an online form of the cake cutting problem. This models situations
where players arrive and depart during the process of dividing a resource. We
show that well known fair division procedures like cut-and-choose and the
Dubins-Spanier moving knife procedure can be adapted to apply to such online
problems. We propose some desirable properties that online cake cutting
procedures might possess like online forms of proportionality and
envy-freeness, and identify which properties are in fact possessed by the
different online cake procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0618</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0618</id><created>2010-07-05</created><authors><author><keyname>Halder</keyname><forenames>Santanu</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Face Synthesis (FASY) System for Determining the Characteristics of a
  Face Image</title><categories>cs.CV</categories><journal-ref>RAIT 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at determining the characteristics of a face image by
extracting its components. The FASY (FAce SYnthesis) System is a Face Database
Retrieval and new Face generation System that is under development. One of its
main features is the generation of the requested face when it is not found in
the existing database, which allows a continuous growing of the database also.
To generate the new face image, we need to store the face components in the
database. So we have designed a new technique to extract the face components by
a sophisticated method. After extraction of the facial feature points we have
analyzed the components to determine their characteristics. After extraction
and analysis we have stored the components along with their characteristics
into the face database for later use during the face construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0619</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0619</id><created>2010-07-05</created><authors><author><keyname>Bose</keyname><forenames>Mausumi</forenames></author><author><keyname>Mukerjee</keyname><forenames>Rahul</forenames></author></authors><title>Anti-Collusion Digital Fingerprinting Codes via Partially Cover-Free
  Families</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anti-collusion digital fingerprinting codes have been of significant current
interest in the context of deterring unauthorized use of multimedia content by
a coalition of users. In this article, partially cover-free families of sets
are considered and these are employed to obtain such codes. Compared to the
existing methods of construction, our methods ensure gains in terms of
accommodating more users and/or reducing the number of basis vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0620</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0620</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Quotient Based Multiresolution Image Fusion of Thermal and Visual Images
  Using Daubechies Wavelet Transform for Human Face Recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the multiresolution level-1 and level-2 Quotient
based Fusion of thermal and visual images. In the proposed system, the method-1
namely &quot;Decompose then Quotient Fuse Level-1&quot; and the method-2 namely
&quot;Decompose-Reconstruct then Quotient Fuse Level-2&quot; both work on wavelet
transformations of the visual and thermal face images. The wavelet transform is
well-suited to manage different image resolution and allows the image
decomposition in different kinds of coefficients, while preserving the image
information without any loss. This approach is based on a definition of an
illumination invariant signature image which enables an analytic generation of
the image space with varying illumination. The quotient fused images are passed
through Principal Component Analysis (PCA) for dimension reduction and then
those images are classified using a multi-layer perceptron (MLP). The
performances of both the methods have been evaluated using OTCBVS and IRIS
databases. All the different classes have been tested separately, among them
the maximum recognition result is 100%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0621</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0621</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Fusion of Daubechies Wavelet Coefficients for Human Face Recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper fusion of visual and thermal images in wavelet transformed
domain has been presented. Here, Daubechies wavelet transform, called as D2,
coefficients from visual and corresponding coefficients computed in the same
manner from thermal images are combined to get fused coefficients. After
decomposition up to fifth level (Level 5) fusion of coefficients is done.
Inverse Daubechies wavelet transform of those coefficients gives us fused face
images. The main advantage of using wavelet transform is that it is well-suited
to manage different image resolution and allows the image decomposition in
different kinds of coefficients, while preserving the image information. Fused
images thus found are passed through Principal Component Analysis (PCA) for
reduction of dimensions and then those reduced fused images are classified
using a multi-layer perceptron. For experiments IRIS Thermal/Visual Face
Database was used. Experimental results show that the performance of the
approach presented here achieves maximum success rate of 100% in many cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0626</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0626</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>M. K.</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>M.</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author></authors><title>Fusion of Wavelet Coefficients from Visual and Thermal Face Images for
  Human Face Recognition - A Comparative Study</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a comparative study on fusion of visual and thermal
images using different wavelet transformations. Here, coefficients of discrete
wavelet transforms from both visual and thermal images are computed separately
and combined. Next, inverse discrete wavelet transformation is taken in order
to obtain fused face image. Both Haar and Daubechies (db2) wavelet transforms
have been used to compare recognition results. For experiments IRIS
Thermal/Visual Face Database was used. Experimental results using Haar and
Daubechies wavelets show that the performance of the approach presented here
achieves maximum success rate of 100% in many cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0627</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0627</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>M. K.</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>M.</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author></authors><title>A Parallel Framework for Multilayer Perceptron for Human Face
  Recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial neural networks have already shown their success in face
recognition and similar complex pattern recognition tasks. However, a major
disadvantage of the technique is that it is extremely slow during training for
larger classes and hence not suitable for real-time complex problems such as
pattern recognition. This is an attempt to develop a parallel framework for the
training algorithm of a perceptron. In this paper, two general architectures
for a Multilayer Perceptron (MLP) have been demonstrated. The first
architecture is All-Class-in-One-Network (ACON) where all the classes are
placed in a single network and the second one is One-Class-in-One-Network
(OCON) where an individual single network is responsible for each and every
class. Capabilities of these two architectures were compared and verified in
solving human face recognition, which is a complex pattern recognition task
where several factors affect the recognition performance like pose variations,
facial expression changes, occlusions, and most importantly illumination
changes. Both the structures were implemented and tested for face recognition
purpose and experimental results show that the OCON structure performs better
than the generally used ACON ones in term of training convergence speed of the
network. Unlike the conventional sequential approach of training the neural
networks, the OCON technique may be implemented by training all the classes of
the face images simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0628</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0628</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Image Pixel Fusion for Human Face Recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a technique for fusion of optical and thermal face
images based on image pixel fusion approach. Out of several factors, which
affect face recognition performance in case of visual images, illumination
changes are a significant factor that needs to be addressed. Thermal images are
better in handling illumination conditions but not very consistent in capturing
texture details of the faces. Other factors like sunglasses, beard, moustache
etc also play active role in adding complicacies to the recognition process.
Fusion of thermal and visual images is a solution to overcome the drawbacks
present in the individual thermal and visual face images. Here fused images are
projected into an eigenspace and the projected images are classified using a
radial basis function (RBF) neural network and also by a multi-layer perceptron
(MLP). In the experiments Object Tracking and Classification Beyond Visible
Spectrum (OTCBVS) database benchmark for thermal and visual face images have
been used. Comparison of experimental results show that the proposed approach
performs significantly well in recognizing face images with a success rate of
96% and 95.07% for RBF Neural Network and MLP respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0631</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0631</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>M. K.</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>M.</forenames></author><author><keyname>Basu</keyname><forenames>D. K.</forenames></author><author><keyname>Kundu</keyname><forenames>M.</forenames></author></authors><title>Classification of Fused Images using Radial Basis Function Neural
  Network for Human Face Recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here an efficient fusion technique for automatic face recognition has been
presented. Fusion of visual and thermal images has been done to take the
advantages of thermal images as well as visual images. By employing fusion a
new image can be obtained, which provides the most detailed, reliable, and
discriminating information. In this method fused images are generated using
visual and thermal face images in the first step. In the second step, fused
images are projected into eigenspace and finally classified using a radial
basis function neural network. In the experiments Object Tracking and
Classification Beyond Visible Spectrum (OTCBVS) database benchmark for thermal
and visual face images have been used. Experimental results show that the
proposed approach performs well in recognizing unknown individuals with a
maximum success rate of 96%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0633</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0633</id><created>2010-07-05</created><authors><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Bhowmik</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Classification of fused face images using multilayer perceptron neural
  network</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a concept of image pixel fusion of visual and thermal
faces, which can significantly improve the overall performance of a face
recognition system. Several factors affect face recognition performance
including pose variations, facial expression changes, occlusions, and most
importantly illumination changes. So, image pixel fusion of thermal and visual
images is a solution to overcome the drawbacks present in the individual
thermal and visual face images. Fused images are projected into eigenspace and
finally classified using a multi-layer perceptron. In the experiments we have
used Object Tracking and Classification Beyond Visible Spectrum (OTCBVS)
database benchmark thermal and visual face images. Experimental results show
that the proposed approach significantly improves the verification and
identification performance and the success rate is 95.07%. The main objective
of employing fusion is to produce a fused image that provides the most detailed
and reliable information. Fusion of multiple images together produces a more
efficient representation of the image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0636</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0636</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Classification of Log-Polar-Visual Eigenfaces using Multilayer
  Perceptron</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a simple novel approach to tackle the challenges of
scaling and rotation of face images in face recognition. The proposed approach
registers the training and testing visual face images by log-polar
transformation, which is capable to handle complicacies introduced by scaling
and rotation. Log-polar images are projected into eigenspace and finally
classified using an improved multi-layer perceptron. In the experiments we have
used ORL face database and Object Tracking and Classification Beyond Visible
Spectrum (OTCBVS) database for visual face images. Experimental results show
that the proposed approach significantly improves the recognition performances
from visual to log-polar-visual face images. In case of ORL face database,
recognition rate for visual face images is 89.5% and that is increased to 97.5%
for log-polar-visual face images whereas for OTCBVS face database recognition
rate for visual images is 87.84% and 96.36% for log-polar-visual face images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0637</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0637</id><created>2010-07-05</created><authors><author><keyname>Gelain</keyname><forenames>Mirco</forenames></author><author><keyname>Pini</keyname><forenames>Maria Silvia</forenames></author><author><keyname>RossI</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>Kristen Brent</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Local search for stable marriage problems with ties and incomplete lists</title><categories>cs.AI</categories><comments>12 pages, Proc. PRICAI 2010 (11th Pacific Rim International
  Conference on Artificial Intelligence), Byoung-Tak Zhang and Mehmet A. Orgun
  eds., Springer LNAI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stable marriage problem has a wide variety of practical applications,
ranging from matching resident doctors to hospitals, to matching students to
schools, or more generally to any two-sided market. We consider a useful
variation of the stable marriage problem, where the men and women express their
preferences using a preference list with ties over a subset of the members of
the other sex. Matchings are permitted only with people who appear in these
preference lists. In this setting, we study the problem of finding a stable
matching that marries as many people as possible. Stability is an envy-free
notion: no man and woman who are not married to each other would both prefer
each other to their partners or to being single. This problem is NP-hard. We
tackle this problem using local search, exploiting properties of the problem to
reduce the size of the neighborhood and to make local moves efficiently.
Experimental results show that this approach is able to solve large problems,
quickly returning stable matchings of large and often optimal size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0638</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0638</id><created>2010-07-05</created><authors><author><keyname>Bhowmik</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Human Face Recognition using Line Features</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we investigate a novel approach to handle the challenges of face
recognition, which includes rotation, scale, occlusion, illumination etc. Here,
we have used thermal face images as those are capable to minimize the affect of
illumination changes and occlusion due to moustache, beards, adornments etc.
The proposed approach registers the training and testing thermal face images in
polar coordinate, which is capable to handle complicacies introduced by scaling
and rotation. Line features are extracted from thermal polar images and feature
vectors are constructed using these line. Feature vectors thus obtained passes
through principal component analysis (PCA) for the dimensionality reduction of
feature vectors. Finally, the images projected into eigenspace are classified
using a multi-layer perceptron. In the experiments we have used Object Tracking
and Classification Beyond Visible Spectrum (OTCBVS) database. Experimental
results show that the proposed approach significantly improves the verification
and identification performance and the success rate is 99.25%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0641</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0641</id><created>2010-07-05</created><updated>2010-07-26</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Transmission Line Inspires A New Distributed Algorithm to Solve the
  Nonlinear Dynamical System of Physical Circuit</title><categories>cs.DC math.CA</categories><comments>v1: 12 pages, 7 figures; v2: 19 pages, 13 figures, submitted to 2nd
  International Conference on Circuit Simulation, being reviewed (ICCS,
  Shanghai, 2010); v3: a copy of v2, this is an internal error of arxiv.org;
  v4: Rejected by ICCS, re-submitted to ICCIT'10</comments><msc-class>34A34, 65L20, 65W15</msc-class><acm-class>G.1.5; G.1.7; I.6.1; B.5.2; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As known, physical circuits, e.g. integrated circuits or power system, work
in a distributed manner, but these circuits could not be easily simulated in a
distributed way. This is mainly because that the dynamical system of physical
circuits is nonlinear and the linearized system of physical circuits is
nonsymmetrical. This paper proposes a simple and natural strategy to mimic the
distributed behavior of the physical circuit by mimicking the distributed
behavior of the internal wires inside this circuit. Mimic Transmission Method
(MTM) is a new distributed algorithm to solve the nonlinear ordinary
differential equations extracted from physical circuits. It maps the
transmission delay of interconnects between subcircuits to the communication
delay of digital data link between processors. MTM is a black-box algorithm. By
mimicking the transmission lines, MTM seals the nonlinear dynamical system
within the subcircuit. As the result, we do not need to pay attention on how to
solve the nonlinear dynamic system or nonsymmetrical linear system in parallel.
MTM is a global direct algorithm, and it does only one distributed computation
at each time window to obtain accurate result, so unconvergence issues do not
need to be worried about.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0642</identifier>
 <datestamp>2013-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0642</id><created>2010-07-05</created><updated>2012-10-18</updated><authors><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author><author><keyname>Leicher</keyname><forenames>Andreas</forenames></author><author><keyname>Shah</keyname><forenames>Yogendra</forenames></author><author><keyname>Cha</keyname><forenames>Inhyok</forenames></author></authors><title>Tree-formed Verification Data for Trusted Platforms</title><categories>cs.CR</categories><comments>15 pages, 11 figures, v3: Reference added, v4: Revised, accepted for
  publication in Computers and Security</comments><journal-ref>Computers &amp; Security 32 (2013) 19-35</journal-ref><doi>10.1016/j.cose.2012.09.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The establishment of trust relationships to a computing platform relies on
validation processes. Validation allows an external entity to build trust in
the expected behaviour of the platform based on provided evidence of the
platform's configuration. In a process like remote attestation, the 'trusted'
platform submits verification data created during a start up process. These
data consist of hardware-protected values of platform configuration registers,
containing nested measurement values, e.g., hash values, of loaded or started
components. Commonly, the register values are created in linear order by a
hardware-secured operation. Fine-grained diagnosis of components, based on the
linear order of verification data and associated measurement logs, is not
optimal. We propose a method to use tree-formed verification data to validate a
platform. Component measurement values represent leaves, and protected
registers represent roots of a hash tree. We describe the basic mechanism of
validating a platform using tree-formed measurement logs and root registers and
show an logarithmic speed-up for the search of faults. Secure creation of a
tree is possible using a limited number of hardware-protected registers and a
single protected operation. In this way, the security of tree-formed
verification data is maintained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0660</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0660</id><created>2010-07-05</created><authors><author><keyname>Shashua</keyname><forenames>Amnon</forenames></author><author><keyname>Pragier</keyname><forenames>Gabi</forenames></author></authors><title>The Latent Bernoulli-Gauss Model for Data Analysis</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new latent-variable model employing a Gaussian mixture
integrated with a feature selection procedure (the Bernoulli part of the model)
which together form a &quot;Latent Bernoulli-Gauss&quot; distribution. The model is
applied to MAP estimation, clustering, feature selection and collaborative
filtering and fares favorably with the state-of-the-art latent-variable models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0683</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0683</id><created>2010-06-20</created><authors><author><keyname>Hou</keyname><forenames>I-Hong</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Scheduling Periodic Real-Time Tasks with Heterogeneous Reward
  Requirements</title><categories>cs.OH</categories><comments>10 pages, 7 figures, under submission to RTSS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of scheduling periodic real-time tasks so as to meet
their individual minimum reward requirements. A task generates jobs that can be
given arbitrary service times before their deadlines. A task then obtains
rewards based on the service times received by its jobs. We show that this
model is compatible to the imprecise computation models and the increasing
reward with increasing service models. In contrast to previous work on these
models, which mainly focus on maximize the total reward in the system, we aim
to fulfill different reward requirements by different tasks, which offers
better fairness and allows fine-grained tradeoff between tasks. We first derive
a necessary and sufficient condition for a system, along with reward
requirements of tasks, to be feasible. We also obtain an off-line feasibility
optimal scheduling policy. We then studies a sufficient condition for a policy
to be feasibility optimal or achieves some approximation bound. This condition
can serve as a guideline for designing on-line scheduling policy and we obtains
a greedy policy based on it. We prove that the on-line policy is feasibility
optimal when all tasks have the same periods and also obtain an approximation
bound for the policy under general cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0690</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0690</id><created>2010-07-05</created><authors><author><keyname>Achar</keyname><forenames>Avinash</forenames></author><author><keyname>Laxman</keyname><forenames>Srivatsan</forenames></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames></author></authors><title>A unified view of Automata-based algorithms for Frequent Episode
  Discovery</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequent Episode Discovery framework is a popular framework in Temporal Data
Mining with many applications. Over the years many different notions of
frequencies of episodes have been proposed along with different algorithms for
episode discovery. In this paper we present a unified view of all such
frequency counting algorithms. We present a generic algorithm such that all
current algorithms are special cases of it. This unified view allows one to
gain insights into different frequencies and we present quantitative
relationships among different frequencies. Our unified view also helps in
obtaining correctness proofs for various algorithms as we show here. We also
point out how this unified view helps us to consider generalization of the
algorithm so that they can discover episodes with general partial orders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0714</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0714</id><created>2010-07-05</created><updated>2011-07-29</updated><authors><author><keyname>Couceiro</keyname><forenames>Miguel</forenames></author><author><keyname>Marichal</keyname><forenames>Jean-Luc</forenames></author></authors><title>Axiomatizations of Lov\'asz extensions of pseudo-Boolean functions</title><categories>math.FA cs.DM</categories><msc-class>39B22, 39B72 (Primary) 26B35 (Secondary)</msc-class><journal-ref>Fuzzy Sets and Systems 181 (1) (2011) 28-38</journal-ref><doi>10.1016/j.fss.2011.05.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three important properties in aggregation theory are investigated, namely
horizontal min-additivity, horizontal max-additivity, and comonotonic
additivity, which are defined by certain relaxations of the Cauchy functional
equation in several variables. We show that these properties are equivalent and
we completely describe the functions characterized by them. By adding some
regularity conditions, these functions coincide with the Lov\'asz extensions
vanishing at the origin, which subsume the discrete Choquet integrals. We also
propose a simultaneous generalization of horizontal min-additivity and
horizontal max-additivity, called horizontal median-additivity, and we describe
the corresponding function class. Additional conditions then reduce this class
to that of symmetric Lov\'asz extensions, which includes the discrete symmetric
Choquet integrals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0728</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0728</id><created>2010-07-05</created><updated>2010-09-05</updated><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>Artificial Learning in Artificial Memories</title><categories>cs.AI q-bio.NC</categories><comments>7 pages, 4 figures</comments><acm-class>I.2.0; I.2.2; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory refinements are designed below to detect those sequences of actions
that have been repeated a given number n. Subsequently such sequences are
permitted to run without CPU involvement. This mimics human learning. Actions
are rehearsed and once learned, they are performed automatically without
conscious involvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0730</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0730</id><created>2010-07-05</created><authors><author><keyname>Thouin</keyname><forenames>Frederic</forenames></author><author><keyname>Coates</keyname><forenames>Mark</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>Large scale probabilistic available bandwidth estimation</title><categories>cs.NI</categories><comments>Submitted to Computer Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The common utilization-based definition of available bandwidth and many of
the existing tools to estimate it suffer from several important weaknesses: i)
most tools report a point estimate of average available bandwidth over a
measurement interval and do not provide a confidence interval; ii) the commonly
adopted models used to relate the available bandwidth metric to the measured
data are invalid in almost all practical scenarios; iii) existing tools do not
scale well and are not suited to the task of multi-path estimation in
large-scale networks; iv) almost all tools use ad-hoc techniques to address
measurement noise; and v) tools do not provide enough flexibility in terms of
accuracy, overhead, latency and reliability to adapt to the requirements of
various applications. In this paper we propose a new definition for available
bandwidth and a novel framework that addresses these issues. We define
probabilistic available bandwidth (PAB) as the largest input rate at which we
can send a traffic flow along a path while achieving, with specified
probability, an output rate that is almost as large as the input rate. PAB is
expressed directly in terms of the measurable output rate and includes
adjustable parameters that allow the user to adapt to different application
requirements. Our probabilistic framework to estimate network-wide
probabilistic available bandwidth is based on packet trains, Bayesian
inference, factor graphs and active sampling. We deploy our tool on the
PlanetLab network and our results show that we can obtain accurate estimates
with a much smaller measurement overhead compared to existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0767</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0767</id><created>2010-07-05</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Smolarczyk</keyname><forenames>Milosz</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Retransmission Steganography Applied</title><categories>cs.CR</categories><comments>5 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents experimental results of the implementation of network
steganography method called RSTEG (Retransmission Steganography). The main idea
of RSTEG is to not acknowledge a successfully received packet to intentionally
invoke retransmission. The retransmitted packet carries a steganogram instead
of user data in the payload field. RSTEG can be applied to many network
protocols that utilize retransmissions. We present experimental results for
RSTEG applied to TCP (Transmission Control Protocol) as TCP is the most popular
network protocol which ensures reliable data transfer. The main aim of the
performed experiments was to estimate RSTEG steganographic bandwidth and
detectability by observing its influence on the network retransmission level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0776</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0776</id><created>2010-07-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Is Computational Complexity a Barrier to Manipulation?</title><categories>cs.AI cs.CC cs.GT</categories><comments>To appear in Proceedings of 11th International Workshop on
  Computational Logic in Multi-Agent Systems (CLIMA XI 2010)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When agents are acting together, they may need a simple mechanism to decide
on joint actions. One possibility is to have the agents express their
preferences in the form of a ballot and use a voting rule to decide the winning
action(s). Unfortunately, agents may try to manipulate such an election by
misreporting their preferences. Fortunately, it has been shown that it is
NP-hard to compute how to manipulate a number of different voting rules.
However, NP-hardness only bounds the worst-case complexity. Recent theoretical
results suggest that manipulation may often be easy in practice. To address
this issue, I suggest studying empirically if computational complexity is in
practice a barrier to manipulation. The basic tool used in my investigations is
the identification of computational &quot;phase transitions&quot;. Such an approach has
been fruitful in identifying hard instances of propositional satisfiability and
other NP-hard problems. I show that phase transition behaviour gives insight
into the hardness of manipulating voting rules, increasing concern that
computational complexity is indeed any sort of barrier. Finally, I look at the
problem of computing manipulation of other, related problems like stable
marriage and tournament problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0779</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0779</id><created>2010-07-05</created><authors><author><keyname>Snow</keyname><forenames>Zachary</forenames></author><author><keyname>Baelde</keyname><forenames>David</forenames></author><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>Redundancies in Dependently Typed Lambda Calculi and Their Relevance to
  Proof Search</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dependently typed lambda calculi such as the Logical Framework (LF) are
capable of representing relationships between terms through types. By
exploiting the &quot;formulas-as-types&quot; notion, such calculi can also encode the
correspondence between formulas and their proofs in typing judgments. As such,
these calculi provide a natural yet powerful means for specifying varied formal
systems. Such specifications can be transformed into a more direct form that
uses predicate formulas over simply typed lambda-terms and that thereby
provides the basis for their animation using conventional logic programming
techniques. However, a naive use of this idea is fraught with inefficiencies
arising from the fact that dependently typed expressions typically contain much
redundant typing information. We investigate syntactic criteria for recognizing
and, hence, eliminating such redundancies. In particular, we identify a
property of bound variables in LF types called &quot;rigidity&quot; and formally show
that checking that instantiations of such variables adhere to typing
restrictions is unnecessary for the purpose of ensuring that the overall
expression is well-formed. We show how to exploit this property in a
translation based approach to executing specifications in the Twelf language.
Recognizing redundancy is also relevant to devising compact representations of
dependently typed expressions. We highlight this aspect of our work and discuss
its connection with other approaches proposed in this context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0788</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0788</id><created>2010-07-05</created><authors><author><keyname>Morales-Luna</keyname><forenames>Guillermo</forenames></author></authors><title>A Geometric Presentation of Probabilistic Satisfiability</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By considering probability distributions over the set of assignments the
expected truth values assignment to propositional variables are extended
through linear operators, and the expected truth values of the clauses at any
given conjunctive form are also extended through linear maps. The probabilistic
satisfiability problems are discussed in terms of the introduced linear
extensions. The case of multiple truth values is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0799</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0799</id><created>2010-07-05</created><updated>2010-07-11</updated><authors><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Fountain Codes with Multiplicatively Repeated Non-Binary LDPC Codes</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. 6th International Symposium on Turbo Codes and
  Iterative Information Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study fountain codes transmitted over the binary-input symmetric-output
channel. For channels with small capacity, receivers needs to collects many
channel outputs to recover information bits. Since a collected channel output
yields a check node in the decoding Tanner graph, the channel with small
capacity leads to large decoding complexity. In this paper, we introduce a
novel fountain coding scheme with non-binary LDPC codes. The decoding
complexity of the proposed fountain code does not depend on the channel.
Numerical experiments show that the proposed codes exhibit better performance
than conventional fountain codes, especially for small number of information
bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0803</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0803</id><created>2010-07-06</created><authors><author><keyname>Han</keyname><forenames>Jing</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Guo</keyname><forenames>Lei</forenames></author></authors><title>Soft Control on Collective Behavior of a Group of Autonomous Agents by a
  Shill Agent</title><categories>cs.MA</categories><comments>13 papers, 4 figures. Journal paper. This paper proposes a novel idea
  for intervention to multi-agent systems, called 'soft-control'. A case study
  is shown: add a shill to a multi-agent system (the vicsek's model) to guide
  synchronization</comments><msc-class>93A14</msc-class><acm-class>I.2.11</acm-class><journal-ref>Journal of Systems Science and Complexity, 2006(19):54-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper asks a new question: how can we control the collective behavior of
self-organized multi-agent systems? We try to answer the question by proposing
a new notion called 'Soft Control', which keeps the local rule of the existing
agents in the system. We show the feasibility of soft control by a case study.
Consider the simple but typical distributed multi-agent model proposed by
Vicsek et al. for flocking of birds: each agent moves with the same speed but
with different headings which are updated using a local rule based on the
average of its own heading and the headings of its neighbors. Most studies of
this model are about the self-organized collective behavior, such as
synchronization of headings. We want to intervene in the collective behavior
(headings) of the group by soft control. A specified method is to add a special
agent, called a 'Shill', which can be controlled by us but is treated as an
ordinary agent by other agents. We construct a control law for the shill so
that it can synchronize the whole group to an objective heading. This control
law is proved to be effective analytically and numerically. Note that soft
control is different from the approach of distributed control. It is a natural
way to intervene in the distributed systems. It may bring out many interesting
issues and challenges on the control of complex systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0822</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0822</id><created>2010-07-06</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author><author><keyname>Todorcevic</keyname><forenames>Stevo</forenames><affiliation>ELM</affiliation></author></authors><title>The Isomorphism Relation Between Tree-Automatic Structures</title><categories>math.LO cs.LO</categories><proxy>ccsd</proxy><journal-ref>Central European Journal of Mathematics 8, 2 (2010) p. 299-313</journal-ref><doi>10.2478/s11533-010-0014-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $\omega$-tree-automatic structure is a relational structure whose domain
and relations are accepted by Muller or Rabin tree automata. We investigate in
this paper the isomorphism problem for $\omega$-tree-automatic structures. We
prove first that the isomorphism relation for $\omega$-tree-automatic boolean
algebras (respectively, partial orders, rings, commutative rings, non
commutative rings, non commutative groups, nilpotent groups of class n &gt;1) is
not determined by the axiomatic system ZFC. Then we prove that the isomorphism
problem for $\omega$-tree-automatic boolean algebras (respectively, partial
orders, rings, commutative rings, non commutative rings, non commutative
groups, nilpotent groups of class n &gt;1) is neither a $\Sigma_2^1$-set nor a
$\Pi_2^1$-set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0824</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0824</id><created>2010-07-06</created><authors><author><keyname>Flamary</keyname><forenames>R&#xe9;mi</forenames><affiliation>LITIS</affiliation></author><author><keyname>Labb&#xe9;</keyname><forenames>Benjamin</forenames><affiliation>LITIS</affiliation></author><author><keyname>Rakotomamonjy</keyname><forenames>Alain</forenames><affiliation>LITIS</affiliation></author></authors><title>Filtrage vaste marge pour l'\'etiquetage s\'equentiel \`a noyaux de
  signaux</title><categories>cs.LG</categories><proxy>ccsd</proxy><journal-ref>Conf\'erence Francophone sur l'Apprentissage Automatique, Clermont
  Ferrand : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address in this paper the problem of multi-channel signal sequence
labeling. In particular, we consider the problem where the signals are
contaminated by noise or may present some dephasing with respect to their
labels. For that, we propose to jointly learn a SVM sample classifier with a
temporal filtering of the channels. This will lead to a large margin filtering
that is adapted to the specificity of each channel (noise and time-lag). We
derive algorithms to solve the optimization problem and we discuss different
filter regularizations for automated scaling or selection of channels. Our
approach is tested on a non-linear toy example and on a BCI dataset. Results
show that the classification performance on these problems can be improved by
learning a large margin filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0825</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0825</id><created>2010-07-06</created><updated>2012-03-29</updated><authors><author><keyname>Krivine</keyname><forenames>Jean-Louis</forenames><affiliation>CNRS</affiliation></author></authors><title>Realizability algebras II : new models of ZF + DC</title><categories>math.LO cs.LO</categories><comments>28 p</comments><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  27, 2012) lmcs:1072</journal-ref><doi>10.2168/LMCS-8(1:10)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the proof-program (Curry-Howard) correspondence, we give a new method
to obtain models of ZF and relative consistency results in set theory. We show
the relative consistency of ZF + DC + there exists a sequence of subsets of R
the cardinals of which are strictly decreasing + other similar properties of R.
These results seem not to have been previously obtained by forcing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0831</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0831</id><created>2010-07-06</created><authors><author><keyname>Lynce</keyname><forenames>In&#xea;s</forenames></author><author><keyname>Treinen</keyname><forenames>Ralf</forenames></author></authors><title>Proceedings First International Workshop on Logics for Component
  Configuration</title><categories>cs.LO cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 29, 2010</journal-ref><doi>10.4204/EPTCS.29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the first international workshop
on Logics for Component Configuration (LoCoCo 2010) which was associated with
the International Conference on Theory and Applications of Satisfiability
Testing (SAT 2010) as part of the Federated Logic Conference (FLoC 2010), and
which took place on July 10, 2010 in Edinburgh, UK.
  Modern software distributions are based on the notion of components, which
denote units of independent development and deployment. Components provide the
necessary flexibility when organizing a complex software distribution, but also
are a challenge when it comes to selecting components from a large repository
of possible choices, and configuring these components according to user needs,
resource constraints, and interdependencies with other components. Representing
and solving configuration problems is a hot topic of great importance for many
application domains. Some well-known examples of complex systems of components
are Free and Open Source software distributions like GNU/Linux, or Eclipse
plugins. The LoCoCo workshop has a focus on logic-based methods for specifying
and solving complex configuration problems for software components. The goal
was to bring together both researchers and practitioners active in the area of
component configuration of software systems, using different modeling and
solving techniques, such as constraint and logic programing, description
logics, satisfiability and its extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0859</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0859</id><created>2010-07-06</created><authors><author><keyname>Gelain</keyname><forenames>M.</forenames></author><author><keyname>Pini</keyname><forenames>M. S.</forenames></author><author><keyname>Rossi</keyname><forenames>F.</forenames></author><author><keyname>Venable</keyname><forenames>K. B.</forenames></author><author><keyname>Walsh</keyname><forenames>T.</forenames></author></authors><title>Local search for stable marriage problems</title><categories>cs.AI</categories><comments>12 pages, Proc. COMSOC 2010 (Third International Workshop on
  Computational Social Choice)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stable marriage (SM) problem has a wide variety of practical
applications, ranging from matching resident doctors to hospitals, to matching
students to schools, or more generally to any two-sided market. In the
classical formulation, n men and n women express their preferences (via a
strict total order) over the members of the other sex. Solving a SM problem
means finding a stable marriage where stability is an envy-free notion: no man
and woman who are not married to each other would both prefer each other to
their partners or to being single. We consider both the classical stable
marriage problem and one of its useful variations (denoted SMTI) where the men
and women express their preferences in the form of an incomplete preference
list with ties over a subset of the members of the other sex. Matchings are
permitted only with people who appear in these lists, an we try to find a
stable matching that marries as many people as possible. Whilst the SM problem
is polynomial to solve, the SMTI problem is NP-hard. We propose to tackle both
problems via a local search approach, which exploits properties of the problems
to reduce the size of the neighborhood and to make local moves efficiently. We
evaluate empirically our algorithm for SM problems by measuring its runtime
behaviour and its ability to sample the lattice of all possible stable
marriages. We evaluate our algorithm for SMTI problems in terms of both its
runtime behaviour and its ability to find a maximum cardinality stable
marriage.For SM problems, the number of steps of our algorithm grows only as
O(nlog(n)), and that it samples very well the set of all stable marriages. It
is thus a fair and efficient approach to generate stable marriages.Furthermore,
our approach for SMTI problems is able to solve large problems, quickly
returning stable matchings of large and often optimal size despite the
NP-hardness of this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0875</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0875</id><created>2010-07-06</created><updated>2011-04-12</updated><authors><author><keyname>Dupuy</keyname><forenames>Florian</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author></authors><title>On the Capacity Achieving Covariance Matrix for Frequency Selective MIMO
  Channels Using the Asymptotic Approach</title><categories>cs.IT math.IT</categories><comments>revised version submitted to IEEE-IT on 12th April 2011 (34 pages, 2
  figures, 2 tabs)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, an algorithm for evaluating the capacity-achieving
input covariance matrices for frequency selective Rayleigh MIMO channels is
proposed. In contrast with the flat fading Rayleigh case, no closed-form
expressions for the eigenvectors of the optimum input covariance matrix are
available. Classically, both the eigenvectors and eigenvalues are computed
numerically and the corresponding optimization algorithms remain
computationally very demanding. In this paper, it is proposed to optimize
(w.r.t. the input covariance matrix) a large system approximation of the
average mutual information derived by Moustakas and Simon. The validity of this
asymptotic approximation is clarified thanks to Gaussian large random matrices
methods. It is shown that the approximation is a strictly concave function of
the input covariance matrix and that the average mutual information evaluated
at the argmax of the approximation is equal to the capacity of the channel up
to a O(1/t) term, where t is the number of transmit antennas. An algorithm
based on an iterative waterfilling scheme is proposed to maximize the average
mutual information approximation, and its convergence studied. Numerical
simulation results show that, even for a moderate number of transmit and
receive antennas, the new approach provides the same results as direct
maximization approaches of the average mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0880</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0880</id><created>2010-07-06</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On the independence polynomial of an antiregular graph</title><categories>cs.DM math.CO</categories><comments>11 pages, 5 figures</comments><msc-class>05C31, 05C69 (Primary) 05C07, 05C30 (Secondary)</msc-class><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph with at most two vertices of the same degree is called antiregular
(Merris 2003), maximally nonregular (Zykov 1990) or quasiperfect (Behzad,
Chartrand 1967). If s_{k} is the number of independent sets of cardinality k in
a graph G, then I(G;x) = s_{0} + s_{1}x + ... + s_{alpha}x^{alpha} is the
independence polynomial of G (Gutman, Harary 1983), where alpha = alpha(G) is
the size of a maximum independent set. In this paper we derive closed formulae
for the independence polynomials of antiregular graphs. In particular, we
deduce that every antiregular graph A is uniquely defined by its independence
polynomial I(A;x), within the family of threshold graphs. Moreover, I(A;x) is
logconcave with at most two real roots, and I(A;-1) belongs to {-1,0}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0904</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0904</id><created>2010-07-06</created><updated>2011-06-06</updated><authors><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Martinez-Mateo</keyname><forenames>Jesus</forenames></author><author><keyname>Martin</keyname><forenames>Vicente</forenames></author></authors><title>Secure rate-adaptive reconciliation</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures</comments><doi>10.1109/ISITA.2010.5650099</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper the problem of information reconciliation in the
context of secret key agreement between two legitimate parties, Alice and Bob.
Beginning the discussion with the secret key agreement model introduced by
Ahlswede and Csisz\'ar, the channel-type model with wiretapper, we study a
protocol based on error correcting codes. The protocol can be adapted to
changes in the communication channel extending the original source. The
efficiency of the reconciliation is only limited by the quality of the code
and, while transmitting more information than needed to reconcile Alice's and
Bob's sequences, it does not reveal any more information on the original source
than an ad-hoc code would have revealed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0917</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0917</id><created>2010-07-06</created><authors><author><keyname>Farkas</keyname><forenames>Gyula</forenames></author><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author></authors><title>A Platform for Implementing Secure Wireless Ad Hoc Networks</title><categories>cs.CR cs.NI</categories><comments>Proceedings of the 2nd conference on Recent Achievements in
  Mechatronics, Automation, Computer Science and Robotics, 2010</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We propose a new platform for implementing secure wireless ad hoc networks.
Our proposal is based on a modular architecture, with the software stack
constructed directly on the Ethernet layer. Within our platform we use a new
security protocol that we designed to ensure mutual authentication between
nodes and a secure key exchange. The correctness of the proposed security
protocol is ensured by Guttman's authentication tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0918</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0918</id><created>2010-07-06</created><authors><author><keyname>Heusser</keyname><forenames>Jonathan</forenames></author><author><keyname>Malacaria</keyname><forenames>Pasquale</forenames></author></authors><title>Quantifying Information Leak Vulnerabilities</title><categories>cs.CR</categories><comments>submitted, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leakage of confidential information represents a serious security risk.
Despite a number of novel, theoretical advances, it has been unclear if and how
quantitative approaches to measuring leakage of confidential information could
be applied to substantial, real-world programs. This is mostly due to the high
complexity of computing precise leakage quantities. In this paper, we introduce
a technique which makes it possible to decide if a program conforms to a
quantitative policy which scales to large state-spaces with the help of bounded
model checking.
  Our technique is applied to a number of officially reported information leak
vulnerabilities in the Linux Kernel. Additionally, we also analysed
authentication routines in the Secure Remote Password suite and of a Internet
Message Support Protocol implementation. Our technique shows when there is
unacceptable leakage; the same technique is also used to verify, for the first
time, that the applied software patches indeed plug the information leaks.
  This is the first demonstration of quantitative information flow addressing
security concerns of real-world industrial programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0920</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0920</id><created>2010-07-06</created><authors><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author></authors><title>End-Host Distribution in Application-Layer Multicast: Main Issues and
  Solutions</title><categories>cs.DC cs.NI</categories><comments>9th RoEduNet IEEE International Conference, Sibiu, Romania, 2010</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Application-layer multicast implements the multicast functionality at the
application layer. The main goal of application-layer multicast is to construct
and maintain efficient distribution structures between end-hosts. In this paper
we focus on the implementation of an application-layer multicast distribution
algorithm. We observe that the total time required to measure network latency
over TCP is influenced dramatically by the TCP connection time. We argue that
end-host distribution is not only influenced by the quality of network links
but also by the time required to make connections between nodes. We provide
several solutions to decrease the total end-host distribution time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0931</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0931</id><created>2010-07-06</created><authors><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>LDPC Code Design for Transmission of Correlated Sources Across Noisy
  Channels Without CSIT</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, to appear in ISTC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of transmitting correlated data after independent
encoding to a central receiver through orthogonal channels. We assume that the
channel state information is not known at the transmitter. The receiver has
access to both the source correlation and the channel state information. We
provide a generic framework for analyzing the performance of joint iterative
decoding, using density evolution. Using differential evolution, we design
punctured systematic LDPC codes to maximize the region of achievable channel
conditions, with joint iterative decoding. The main contribution of this paper
is to demonstrate that properly designed LDPC can perform well simultaneously
over a wide range of channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0936</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0936</id><created>2010-07-06</created><authors><author><keyname>Kwapien</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Drozdz</keyname><forenames>Stanislaw</forenames></author><author><keyname>Orczyk</keyname><forenames>Adam</forenames></author></authors><title>Linguistic complexity: English vs. Polish, text vs. corpus</title><categories>cs.CL physics.soc-ph</categories><journal-ref>Acta Phys. Pol. A 117, 716-720 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the rank-frequency distributions of words in selected English and
Polish texts. We show that for the lemmatized (basic) word forms the
scale-invariant regime breaks after about two decades, while it might be
consistent for the whole range of ranks for the inflected word forms. We also
find that for a corpus consisting of texts written by different authors the
basic scale-invariant regime is broken more strongly than in the case of
comparable corpus consisting of texts written by the same author. Similarly,
for a corpus consisting of texts translated into Polish from other languages
the scale-invariant regime is broken more strongly than for a comparable corpus
of native Polish texts. Moreover, we find that if the words are tagged with
their proper part of speech, only verbs show rank-frequency distribution that
is almost scale-invariant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0940</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0940</id><created>2010-07-06</created><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>An axiomatic formalization of bounded rationality based on a
  utility-information equivalence</title><categories>cs.AI cs.GT</categories><comments>22 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classic decision-theory is based on the maximum expected utility (MEU)
principle, but crucially ignores the resource costs incurred when determining
optimal decisions. Here we propose an axiomatic framework for bounded
decision-making that considers resource costs. Agents are formalized as
probability measures over input-output streams. We postulate that any such
probability measure can be assigned a corresponding conjugate utility function
based on three axioms: utilities should be real-valued, additive and monotonic
mappings of probabilities. We show that these axioms enforce a unique
conversion law between utility and probability (and thereby, information).
Moreover, we show that this relation can be characterized as a variational
principle: given a utility function, its conjugate probability measure
maximizes a free utility functional. Transformations of probability measures
can then be formalized as a change in free utility due to the addition of new
constraints expressed by a target utility function. Accordingly, one obtains a
criterion to choose a probability measure that trades off the maximization of a
target utility function and the cost of the deviation from a reference
distribution. We show that optimal control, adaptive estimation and adaptive
control problems can be solved this way in a resource-efficient way. When
resource costs are ignored, the MEU principle is recovered. Our formalization
might thus provide a principled approach to bounded rationality that
establishes a close link to information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0945</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0945</id><created>2010-07-06</created><authors><author><keyname>Mryglod</keyname><forenames>O.</forenames></author><author><keyname>Holovatch</keyname><forenames>Yu.</forenames></author></authors><title>Human activity as the decision-based queueing process: statistical data
  analysis of waiting times in scientific journals</title><categories>physics.data-an cs.IR</categories><comments>Based on the conference presentation (&quot;Computer Science and
  Engineering - 2007&quot;, October 4-6 2007, Lviv, Ukraine)</comments><journal-ref>Bull. of Lviv Polytechnic National University, No. 598, p. 96-100,
  2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the editorial processing of papers in scientific journals as a
human activity process based on the decision making. A functional form of the
probability distributions of random variables describing a human dynamics is
studied using classical approaches of mass service systems theory, physics of
critical phenomena and statistical methods of data analysis. Our additional
goal is to corroborate the scientometrical application of the results obtained.
Keywords: data analysis, statistics, mass service systems, human activity,
scientometrics
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0960</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0960</id><created>2010-07-06</created><authors><author><keyname>Thakur</keyname><forenames>Gautam S.</forenames></author><author><keyname>Kumar</keyname><forenames>Udayan</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author><author><keyname>Hsu</keyname><forenames>Wei-Jen</forenames></author></authors><title>Analysis of Spatio-Temporal Preferences and Encounter Statistics for DTN
  Performance</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatio-temporal preferences and encounter statistics provide realistic
measures to understand mobile user's behavioral preferences and transfer
opportunities in Delay Tolerant Networks (DTNs). The time dependent behavior
and periodic reappearances at specific locations can approximate future online
presence while encounter statistics can aid to forward the routing decisions.
It is theoretically shown that such characteristics heavily affect the
performance of routing protocols. Therefore, mobility models demonstrating such
characteristics are also expected to show identical routing performance.
However, we argue models despite capturing these properties deviate from their
expected routing performance. We use realistic traces to validate this
observation on two mobility models. Our empirical results for epidemic routing
show those models' largely differ (delay 67% &amp; reachability 79%) from the
observed values. This in-turn call for two important activities: (i) Analogous
to routing, explore structural properties on a Global scale (ii) Design new
mobility models that capture them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.0982</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.0982</id><created>2010-07-06</created><authors><author><keyname>Liu</keyname><forenames>An</forenames><affiliation>Eugene</affiliation></author><author><keyname>Youjian</keyname><affiliation>Eugene</affiliation></author><author><keyname>Liu</keyname></author><author><keyname>Xiang</keyname><forenames>Haige</forenames></author><author><keyname>Luo</keyname><forenames>Wu</forenames></author></authors><title>MIMO B-MAC Interference Network Optimization under Rate Constraints by
  Polite Water-filling and Duality</title><categories>cs.IT math.IT</categories><comments>30 pages, 8 figures, and 5 tables. Submitted to IEEE Transactions on
  Signal Processing, Jun. 2010</comments><journal-ref>An Liu; Youjian Liu; Haige Xiang; Wu Luo, &quot;MIMO B-MAC Interference
  Network Optimization Under Rate Constraints by Polite Water-Filling and
  Duality,&quot; IEEE Transactions on Signal Processing, vol.59, no.1, pp.263,276,
  Jan. 2011</journal-ref><doi>10.1109/TSP.2010.2088394</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We take two new approaches to design efficient algorithms for transmitter
optimization under rate constraints, to guarantee the Quality of Service in
general MIMO interference networks, which is a combination of multiple
interfering broadcast channels (BC) and multiaccess channels (MAC) and is named
B-MAC Networks. Two related optimization problems, maximizing the minimum of
weighted rates under a sum-power constraint and minimizing the sum-power under
rate constraints, are considered. The first approach takes advantage of
existing efficient algorithms for SINR problems by building a bridge between
rate and SINR through the design of optimal mappings between them. The approach
can be applied to other optimization problems as well. The second approach
employs polite water-filling, which is the optimal network version of
water-filling that we recently found. It replaces most generic optimization
algorithms currently used for networks and reduces the complexity while
demonstrating superior performance even in non-convex cases. Both centralized
and distributed algorithms are designed and the performance is analyzed in
addition to numeric examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1016</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1016</id><created>2010-07-06</created><authors><author><keyname>Pianykh</keyname><forenames>Oleg S.</forenames></author></authors><title>Bilateral filters: what they can and cannot do</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear bilateral filters (BF) deliver a fine blend of computational
simplicity and blur-free denoising. However, little is known about their
nature, noise-suppressing properties, and optimal choices of filter parameters.
Our study is meant to fill this gap-explaining the underlying mechanism of
bilateral filtering and providing the methodology for optimal filter selection.
Practical application to CT image denoising is discussed to illustrate our
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1020</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1020</id><created>2010-07-06</created><authors><author><keyname>Michel</keyname><forenames>Claude</forenames><affiliation>University of Nice - Sophia Antipolis / I3S-CNRS</affiliation></author><author><keyname>Rueher</keyname><forenames>Michel</forenames><affiliation>University of Nice - Sophia Antipolis / I3S-CNRS</affiliation></author></authors><title>Handling software upgradeability problems with MILP solvers</title><categories>cs.LO</categories><comments>In Proceedings LoCoCo 2010, arXiv:1007.0831</comments><proxy>EPTCS</proxy><acm-class>D2.7; G1.6</acm-class><journal-ref>EPTCS 29, 2010, pp. 1-10</journal-ref><doi>10.4204/EPTCS.29.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upgradeability problems are a critical issue in modern operating systems. The
problem consists in finding the &quot;best&quot; solution according to some criteria, to
install, remove or upgrade packages in a given installation. This is a
difficult problem: the complexity of the upgradeability problem is NP complete
and modern OS contain a huge number of packages (often more than 20 000
packages in a Linux distribution). Moreover, several optimisation criteria have
to be considered, e.g., stability, memory efficiency, network efficiency. In
this paper we investigate the capabilities of MILP solvers to handle this
problem. We show that MILP solvers are very efficient when the resolution is
based on a linear combination of the criteria. Experiments done on real
benchmarks show that the best MILP solvers outperform CP solvers and that they
are significantly better than Pseudo Boolean solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1021</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1021</id><created>2010-07-06</created><authors><author><keyname>Argelich</keyname><forenames>Josep</forenames><affiliation>DIEI</affiliation></author><author><keyname>Berre</keyname><forenames>Daniel Le</forenames><affiliation>CRIL-CNRS</affiliation></author><author><keyname>Lynce</keyname><forenames>In&#xea;s</forenames><affiliation>INESC-ID/IST</affiliation></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames><affiliation>CSI/CASL</affiliation></author><author><keyname>Rapicault</keyname><forenames>Pascal</forenames><affiliation>Sonatype</affiliation></author></authors><title>Solving Linux Upgradeability Problems Using Boolean Optimization</title><categories>cs.LO</categories><comments>In Proceedings LoCoCo 2010, arXiv:1007.0831</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 29, 2010, pp. 11-22</journal-ref><doi>10.4204/EPTCS.29.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Managing the software complexity of package-based systems can be regarded as
one of the main challenges in software architectures. Upgrades are required on
a short time basis and systems are expected to be reliable and consistent after
that. For each package in the system, a set of dependencies and a set of
conflicts have to be taken into account. Although this problem is
computationally hard to solve, efficient tools are required. In the best
scenario, the solutions provided should also be optimal in order to better
fulfill users requirements and expectations. This paper describes two different
tools, both based on Boolean satisfiability (SAT), for solving Linux
upgradeability problems. The problem instances used in the evaluation of these
tools were mainly obtained from real environments, and are subject to two
different lexicographic optimization criteria. The developed tools can provide
optimal solutions for many of the instances, but a few challenges remain.
Moreover, it is our understanding that this problem has many similarities with
other configuration problems, and therefore the same techniques can be used in
other domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1022</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1022</id><created>2010-07-06</created><authors><author><keyname>Trezentos</keyname><forenames>Paulo</forenames><affiliation>ISCTE / ADETTI / Caixa M&#xe1;gica</affiliation></author></authors><title>Comparison of PBO solvers in a dependency solving domain</title><categories>cs.SE cs.LO</categories><comments>In Proceedings LoCoCo 2010, arXiv:1007.0831</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 29, 2010, pp. 23-31</journal-ref><doi>10.4204/EPTCS.29.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linux package managers have to deal with dependencies and conflicts of
packages required to be installed by the user. As an NP-complete problem, this
is a hard task to solve. In this context, several approaches have been pursued.
Apt-pbo is a package manager based on the apt project that encodes the
dependency solving problem as a pseudo-Boolean optimization (PBO) problem. This
paper compares different PBO solvers and their effectiveness on solving the
dependency solving problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1023</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1023</id><created>2010-07-06</created><authors><author><keyname>Ohayon</keyname><forenames>Emmanuel</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>Lemerre</keyname><forenames>Matthieu</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>David</keyname><forenames>Vincent</forenames><affiliation>CEA LIST</affiliation></author></authors><title>CONFIGEN: A tool for managing configuration options</title><categories>cs.SE</categories><comments>In Proceedings LoCoCo 2010, arXiv:1007.0831</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 29, 2010, pp. 32-43</journal-ref><doi>10.4204/EPTCS.29.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces CONFIGEN, a tool that helps modularizing software.
CONFIGEN allows the developer to select a set of elementary components for his
software through an interactive interface. Configuration files for use by
C/assembly code and Makefiles are then automatically generated, and we
successfully used it as a helper tool for complex system software refactoring.
CONFIGEN is based on propositional logic, and its implementation faces hard
theoretical problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1024</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1024</id><created>2010-07-06</created><authors><author><keyname>K&#xfc;bler</keyname><forenames>Andreas</forenames><affiliation>Symbolic Computation Group, Wilhelm Schickard Institute for Computer Science, Universit&#xe4;t T&#xfc;bingen, Germany</affiliation></author><author><keyname>Zengler</keyname><forenames>Christoph</forenames><affiliation>Symbolic Computation Group, Wilhelm Schickard Institute for Computer Science, Universit&#xe4;t T&#xfc;bingen, Germany</affiliation></author><author><keyname>K&#xfc;chlin</keyname><forenames>Wolfgang</forenames><affiliation>Symbolic Computation Group, Wilhelm Schickard Institute for Computer Science, Universit&#xe4;t T&#xfc;bingen, Germany</affiliation></author></authors><title>Model Counting in Product Configuration</title><categories>cs.AI cs.LO cs.SC</categories><comments>In Proceedings LoCoCo 2010, arXiv:1007.0831</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 29, 2010, pp. 44-53</journal-ref><doi>10.4204/EPTCS.29.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how to use propositional model counting for a quantitative
analysis of product configuration data. Our approach computes valuable meta
information such as the total number of valid configurations or the relative
frequency of components. This information can be used to assess the severity of
documentation errors or to measure documentation quality. As an application
example we show how we apply these methods to product documentation formulas of
the Mercedes-Benz line of vehicles. In order to process these large formulas we
developed and implemented a new model counter for non-CNF formulas. Our model
counter can process formulas, whose CNF representations could not be processed
up till now.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1025</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1025</id><created>2010-07-06</created><authors><author><keyname>Fuk&#x15b;</keyname><forenames>Henryk</forenames></author></authors><title>Inflection system of a language as a complex network</title><categories>cs.CL nlin.AO</categories><comments>6 pages, 9 figures</comments><journal-ref>Proceedings of 2009 IEEE Toronto International Conference -
  Science and Technology for Humanity, IEEE, Toronto 2009, pp. 491-496</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate inflection structure of a synthetic language using Latin as an
example. We construct a bipartite graph in which one group of vertices
correspond to dictionary headwords and the other group to inflected forms
encountered in a given text. Each inflected form is connected to its
corresponding headword, which in some cases in non-unique. The resulting sparse
graph decomposes into a large number of connected components, to be called word
groups. We then show how the concept of the word group can be used to construct
coverage curves of selected Latin texts. We also investigate a version of the
inflection graph in which all theoretically possible inflected forms are
included. Distribution of sizes of connected components of this graphs
resembles cluster distribution in a lattice percolation near the critical
point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1033</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1033</id><created>2010-07-06</created><updated>2010-09-02</updated><authors><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>A Theory of Network Equivalence, Parts I and II</title><categories>cs.IT math.IT</categories><comments>91 pages, 18 figures. Submitted to the IEEE Transactions on
  Information Theory on April 14, 2010. Draft 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A family of equivalence tools for bounding network capacities is introduced.
Part I treats networks of point-to-point channels. The main result is roughly
as follows. Given a network of noisy, independent, memoryless point-to-point
channels, a collection of communication demands can be met on the given network
if and only if it can be met on another network where each noisy channel is
replaced by a noiseless bit pipe with throughput equal to the noisy channel
capacity. This result was known previously for the case of a single-source
multicast demand. The result given here treats general demands -- including,
for example, multiple unicast demands -- and applies even when the achievable
rate region for the corresponding demands is unknown in the noiseless network.
In part II, definitions of upper and lower bounding channel models for general
channels are introduced. By these definitions, a collection of communication
demands can be met on a network of independent channels if it can be met on a
network where each channel is replaced by its lower bounding model andonly if
it can be met on a network where each channel is replaced by its upper bounding
model. This work derives general conditions under which a network of noiseless
bit pipes is an upper or lower bounding model for a multiterminal channel.
Example upper and lower bounding models for broadcast, multiple access, and
interference channels are given. It is then shown that bounding the difference
between the upper and lower bounding models for a given channel yields bounds
on the accuracy of network capacity bounds derived using those models. By
bounding the capacity of a network of independent noisy channels by the network
coding capacity of a network of noiseless bit pipes, this approach represents
one step towards the goal of building computational tools for bounding network
capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1045</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1045</id><created>2010-07-07</created><updated>2010-07-26</updated><authors><author><keyname>Carta-Gerardino</keyname><forenames>Edoardo</forenames></author><author><keyname>Babaali</keyname><forenames>Parisa</forenames></author></authors><title>Weighted Automata and Recurrence Equations for Regular Languages</title><categories>cs.FL cs.DM math.CO</categories><comments>14 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{P}(\Sigma^*)$ be the semiring of languages, and consider its
subset $\mathcal{P}(\Sigma)$. In this paper we define the language recognized
by a weighted automaton over $\mathcal{P}(\Sigma)$ and a one-letter alphabet.
Similarly, we introduce the notion of language recognition by linear recurrence
equations with coefficients in $\mathcal{P}(\Sigma)$. As we will see, these two
definitions coincide. We prove that the languages recognized by linear
recurrence equations with coefficients in $\mathcal{P}(\Sigma)$ are precisely
the regular languages, thus providing an alternative way to present these
languages. A remarkable consequence of this kind of recognition is that it
induces a partition of the language into its cross-sections, where the $n$th
cross-section contains all the words of length $n$ in the language. Finally, we
show how to use linear recurrence equations to calculate the density function
of a regular language, which assigns to every $n$ the number of words of length
$n$ in the language. We also show how to count the number of successful paths
of a weighted automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1048</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1048</id><created>2010-07-07</created><authors><author><keyname>Sasikala</keyname><forenames>D.</forenames></author><author><keyname>Neelaveni</keyname><forenames>R.</forenames></author></authors><title>Registration of Brain Images using Fast Walsh Hadamard Transform</title><categories>cs.CV</categories><comments>10 pages, 37 figures, 12 tables</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 2, May 2010</journal-ref><doi>10.5120/1745-2053</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A lot of image registration techniques have been developed with great
significance for data analysis in medicine, astrophotography, satellite imaging
and few other areas. This work proposes a method for medical image registration
using Fast Walsh Hadamard transform. This algorithm registers images of the
same or different modalities. Each image bit is lengthened in terms of Fast
Walsh Hadamard basis functions. Each basis function is a notion of determining
various aspects of local structure, e.g., horizontal edge, corner, etc. These
coefficients are normalized and used as numerals in a chosen number system
which allows one to form a unique number for each type of local structure. The
experimental results show that Fast Walsh Hadamard transform accomplished
better results than the conventional Walsh transform in the time domain. Also
Fast Walsh Hadamard transform is more reliable in medical image registration
consuming less time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1049</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1049</id><created>2010-07-07</created><updated>2010-09-29</updated><authors><author><keyname>Ben-Or</keyname><forenames>Michael</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author></authors><title>Simple Gradecast Based Algorithms</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gradecast is a simple three-round algorithm presented by Feldman and Micali.
The current work presents a very simple algorithm that utilized Gradecast to
achieve Byzantine agreement. Two small variations of the presented algorithm
lead to improved algorithms for solving the Approximate agreement problem and
the Multi-consensus problem.
  An optimal approximate agreement algorithm was presented by Fekete, which
supports up to 1/4 n Byzantine nodes and has message complexity of O(n^k),
where n is the number of nodes and k is the number of rounds.
  Our solution to the approximate agreement problem is optimal, simple and
reduces the message complexity to O(k * n^3), while supporting up to 1/3 n
Byzantine nodes.
  Multi consensus was first presented by Bar-Noy et al. It consists of
consecutive executions of l Byzantine consensuses. Bar-Noy et al., show an
optimal amortized solution to this problem, assuming that all nodes start each
consensus instance at the same time, a property that cannot be guaranteed with
early stopping. Our solution is simpler, preserves round complexity optimality,
allows early stopping and does not require synchronized starts of the consensus
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1054</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1054</id><created>2010-07-07</created><authors><author><keyname>McIver</keyname><forenames>Annabelle</forenames></author><author><keyname>Meinicke</keyname><forenames>Larissa</forenames></author><author><keyname>Morgan</keyname><forenames>Carroll</forenames></author></authors><title>Compositional closure for Bayes Risk in probabilistic noninterference</title><categories>cs.FL</categories><acm-class>F.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a sequential model for noninterference security including probability
(but not demonic choice), thus supporting reasoning about the likelihood that
high-security values might be revealed by observations of low-security
activity. Our novel methodological contribution is the definition of a
refinement order and its use to compare security measures between
specifications and (their supposed) implementations. This contrasts with the
more common practice of evaluating the security of individual programs in
isolation.
  The appropriateness of our model and order is supported by our showing that
our refinement order is the greatest compositional relation --the compositional
closure-- with respect to our semantics and an &quot;elementary&quot; order based on
Bayes Risk --- a security measure already in widespread use. We also relate
refinement to other measures such as Shannon Entropy.
  By applying the approach to a non-trivial example, the anonymous-majority
Three-Judges protocol, we demonstrate by example that correctness arguments can
be simplified by the sort of layered developments --through levels of
increasing detail-- that are allowed and encouraged by compositional semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1059</identifier>
 <datestamp>2012-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1059</id><created>2010-07-07</created><authors><author><keyname>Malinin</keyname><forenames>Leonid</forenames></author><author><keyname>Malinina</keyname><forenames>Natalia</forenames></author></authors><title>On the solution of the Graph Isomorphism Problem Part 1</title><categories>cs.CC math.GM</categories><comments>Microsoft Wopd 2007 46 pages with 38 figures</comments><msc-class>05Cxx (primary), 68Rxx (secondary)</msc-class><acm-class>F.2.2; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The presented material is devoted to the equivalent conversion from the
vertex graphs to the edge graphs. We suggest that the proved theorems solve the
problem of the isomorphism of graphs, the problem of the graph's enumeration
with the help of the effective algorithms without their preliminary plotting,
etc. The examining of the transformation of the vertex graphs into the edge
graph and the opposite operation illustrates the reasons of the appearance of
the NP-completeness from the point of view of the graph theory. We suggest that
it also illustrates the synchronous possibility and impossibility of the
struggle with the NP-completeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1069</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1069</id><created>2010-07-07</created><authors><author><keyname>Wahlberg</keyname><forenames>Patrik</forenames></author><author><keyname>Schreier</keyname><forenames>Peter J.</forenames></author></authors><title>On the instantaneous frequency of Gaussian stochastic processes</title><categories>cs.IT math.IT math.PR</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the instantaneous frequency (IF) of continuous-time,
zero-mean, complex-valued, proper, mean-square differentiable nonstationary
Gaussian stochastic processes. We compute the probability density function for
the IF for fixed time, which extends a result known for wide-sense stationary
processes to nonstationary processes. For a fixed time the IF has either zero
or infinite variance. For harmonizable processes we obtain as a byproduct that
the mean of the IF, for fixed time, is the normalized first order frequency
moment of the Wigner spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1073</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1073</id><created>2010-07-07</created><authors><author><keyname>Chistikov</keyname><forenames>Dmitry V.</forenames></author><author><keyname>Voronenko</keyname><forenames>Andrey A.</forenames></author></authors><title>Learning Read-Once Functions Using Subcube Identity Queries</title><categories>cs.CC</categories><comments>Submitted to SODA11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of exact identification for read-once functions over
arbitrary Boolean bases. We introduce a new type of queries (subcube identity
ones), discuss its connection to previously known ones, and study the
complexity of the problem in question. Besides these new queries, learning
algorithms are allowed to use classic membership ones. We present a technique
of modeling an equivalence query with a polynomial number of membership and
subcube identity ones, thus establishing (under certain conditions) a
polynomial upper bound on the complexity of the problem. We show that in some
circumstances, though, equivalence queries cannot be modeled with a polynomial
number of subcube identity and membership ones. We construct an example of an
infinite Boolean basis with an exponential lower bound on the number of
membership and subcube identity queries required for exact identification. We
prove that for any finite subset of this basis, the problem remains polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1079</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1079</id><created>2010-07-07</created><authors><author><keyname>Mryglod</keyname><forenames>O.</forenames></author><author><keyname>Holovatch</keyname><forenames>Yu.</forenames></author></authors><title>Intelligent data analysis based on the complex network theory methods: a
  case study</title><categories>cs.IR physics.data-an</categories><comments>Based on the presentation on the X International PhD Workshop
  OWD'2008, 18-21 October 2008, Wisla, Poland</comments><journal-ref>Mryglod O., Yu. Holovatch. Intelligent data analysis based on the
  complex network theory methods: a case study. Proc of the X International PhD
  Workshop [OWD-2008], Poland, Wis{\l}a, 18-21 October, 2008, - P. 211</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of modern information technologies permits to collect and to
analyze huge amounts of statistical data in different spheres of life. The main
problem is not to only to collect but to process all relevant information. The
purpose of our work is to show the example of intelligent data analysis in such
complex and non-formalized field as science. Using the statistical data about
scientific periodical it is possible to perform its comprehensive analysis and
to solve different practical problems. The combination of various approaches
including the statistical analysis, methods of the complex network theory and
different techniques that can be used for the concept mapping permits to
perform an intelligent data analysis in order to obtain underlying patterns and
hidden connections. Results of such analysis can be used for particular
practical problems like information retrieval within journal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1086</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1086</id><created>2010-07-07</created><authors><author><keyname>Okun</keyname><forenames>Michael</forenames></author></authors><title>On the Power of Impersonation Attacks</title><categories>cs.DC</categories><comments>This is the full version of a brief announcement (under the same
  name), which appeared in Proc. 21st International Symposium on Distributed
  Computing (DISC 07)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a synchronous message passing system in which in
every round an external adversary is able to send each processor up to k
messages with falsified sender identities and arbitrary content. It is formally
shown that this impersonation model is slightly stronger than the asynchronous
message passing model with crash failures. In particular, we prove that
(k+1)-set agreement can be solved in this model, while k-set agreement is
impossible, for any k&gt;=1. The different strength of the asynchronous and
impersonation models is exhibited by the order preserving renaming problem, for
which an algorithm with n+k target namespace exists in the impersonation model,
while an exponentially larger namespace is required in case of asynchrony.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1087</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1087</id><created>2010-07-07</created><authors><author><keyname>Gaji&#x107;</keyname><forenames>Vojislav</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Rimoldi</keyname><forenames>Bixio</forenames></author></authors><title>Competition of Wireless Providers for Atomic Users</title><categories>cs.IT cs.GT math.IT</categories><comments>Submitted to IEEE/ACM Transactions on Networking, June 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a problem where wireless service providers compete for heterogenous
wireless users. The users differ in their utility functions as well as in the
perceived quality of service of individual providers. We model the interaction
of an arbitrary number of providers and users as a two-stage
multi-leader-follower game. We prove existence and uniqueness of the subgame
perfect Nash equilibrium for a generic channel model and a wide class of users'
utility functions. We show that the competition of resource providers leads to
a globally optimal outcome under mild technical conditions. Most users will
purchase the resource from only one provider at the unique subgame perfect
equilibrium. The number of users who connect to multiple providers at the
equilibrium is always smaller than the number of providers. We also present a
decentralized algorithm that globally converges to the unique system
equilibrium with only local information under mild conditions on the update
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1100</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1100</id><created>2010-07-07</created><authors><author><keyname>Foh</keyname><forenames>Chuan Heng</forenames></author><author><keyname>Cai</keyname><forenames>Jianfei</forenames></author><author><keyname>Qureshi</keyname><forenames>Jalaluddin</forenames></author></authors><title>Collision Codes: Decoding Superimposed BPSK Modulated Wireless
  Transmissions</title><categories>cs.NI</categories><doi>10.1109/CCNC.2010.5421745</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The introduction of physical layer network coding gives rise to the concept
of turning a collision of transmissions on a wireless channel useful. In the
idea of physical layer network coding, two synchronized simultaneous packet
transmissions are carefully encoded such that the superimposed transmission can
be decoded to produce a packet which is identical to the bitwise binary sum of
the two transmitted packets. This paper explores the decoding of superimposed
transmission resulted by multiple synchronized simultaneous transmissions. We
devise a coding scheme that achieves the identification of individual
transmission from the synchronized superimposed transmission. A mathematical
proof for the existence of such a coding scheme is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1146</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1146</id><created>2010-07-07</created><updated>2010-09-07</updated><authors><author><keyname>Hoffmann</keyname><forenames>Christian</forenames></author></authors><title>Exponential Time Complexity of Weighted Counting of Independent Sets</title><categories>cs.CC cond-mat.stat-mech</categories><comments>Introduction revised, differences between versions of counting
  independent sets stated more precisely, minor improvements. 14 pages</comments><doi>10.1007/978-3-642-17493-3_18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider weighted counting of independent sets using a rational weight x:
Given a graph with n vertices, count its independent sets such that each set of
size k contributes x^k. This is equivalent to computation of the partition
function of the lattice gas with hard-core self-repulsion and hard-core pair
interaction. We show the following conditional lower bounds: If counting the
satisfying assignments of a 3-CNF formula in n variables (#3SAT) needs time
2^{\Omega(n)} (i.e. there is a c&gt;0 such that no algorithm can solve #3SAT in
time 2^{cn}), counting the independent sets of size n/3 of an n-vertex graph
needs time 2^{\Omega(n)} and weighted counting of independent sets needs time
2^{\Omega(n/log^3 n)} for all rational weights x\neq 0.
  We have two technical ingredients: The first is a reduction from 3SAT to
independent sets that preserves the number of solutions and increases the
instance size only by a constant factor. Second, we devise a combination of
vertex cloning and path addition. This graph transformation allows us to adapt
a recent technique by Dell, Husfeldt, and Wahlen which enables interpolation by
a family of reductions, each of which increases the instance size only
polylogarithmically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1161</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1161</id><created>2010-07-07</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>Narrow sieves for parameterized paths and packings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present randomized algorithms for some well-studied, hard combinatorial
problems: the k-path problem, the p-packing of q-sets problem, and the
q-dimensional p-matching problem. Our algorithms solve these problems with high
probability in time exponential only in the parameter (k, p, q) and using
polynomial space; the constant bases of the exponentials are significantly
smaller than in previous works. For example, for the k-path problem the
improvement is from 2 to 1.66. We also show how to detect if a d-regular graph
admits an edge coloring with $d$ colors in time within a polynomial factor of
O(2^{(d-1)n/2}).
  Our techniques build upon and generalize some recently published ideas by I.
Koutis (ICALP 2009), R. Williams (IPL 2009), and A. Bj\&quot;orklund (STACS 2010,
FOCS 2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1166</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1166</id><created>2010-07-07</created><updated>2010-07-26</updated><authors><author><keyname>Kutzkov</keyname><forenames>Konstantin</forenames></author><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>Using CSP To Improve Deterministic 3-SAT</title><categories>cs.DS</categories><comments>corrected typos, extended the introduction and added a notation
  section to make paper self-contained</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how one can use certain deterministic algorithms for higher-value
constraint satisfaction problems (CSPs) to speed up deterministic local search
for 3-SAT. This way, we improve the deterministic worst-case running time for
3-SAT to O(1.439^n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1174</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1174</id><created>2010-07-07</created><updated>2010-12-11</updated><authors><author><keyname>Ma</keyname><forenames>Yanjun</forenames></author><author><keyname>Li</keyname><forenames>Jiandong</forenames></author><author><keyname>Liu</keyname><forenames>Qin</forenames></author><author><keyname>Chen</keyname><forenames>Rui</forenames></author></authors><title>Group Based Interference Alignment</title><categories>cs.IT math.IT</categories><comments>3 pages, 3 figures. resubmitted to IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the $K$-user single-input single-output (SISO) frequency-selective fading
interference channel, it is shown that the maximal achievable multiplexing gain
is almost surely $K/2$ by using interference alignment (IA). However, when the
signaling dimensions are limited, allocating all the resources to all users
simultaneously is not optimal. So, a group based interference alignment (GIA)
scheme is proposed, and it is formulated as an unbounded knapsack problem.
Optimal and greedy search algorithms are proposed to obtain group patterns.
Analysis and numerical results show that the GIA scheme can obtain a higher
multiplexing gain when the resources are limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1189</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1189</id><created>2010-07-07</created><updated>2010-07-09</updated><authors><author><keyname>Richa</keyname><forenames>Andrea</forenames></author><author><keyname>Scheideler</keyname><forenames>Christian</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author><author><keyname>Zhang</keyname><forenames>Jin</forenames></author></authors><title>A Jamming-Resistant MAC Protocol for Multi-Hop Wireless Networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a simple local medium access control protocol, called
\textsc{Jade}, for multi-hop wireless networks with a single channel that is
provably robust against adaptive adversarial jamming. The wireless network is
modeled as a unit disk graph on a set of nodes distributed arbitrarily in the
plane. In addition to these nodes, there are adversarial jammers that know the
protocol and its entire history and that are allowed to jam the wireless
channel at any node for an arbitrary $(1-\epsilon)$-fraction of the time steps,
where $0&lt;\epsilon&lt;1$ is an arbitrary constant. We assume that the nodes cannot
distinguish between jammed transmissions and collisions of regular messages.
Nevertheless, we show that \textsc{Jade} achieves an asymptotically optimal
throughput if there is a sufficiently dense distribution of nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1194</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1194</id><created>2010-07-07</created><authors><author><keyname>Mehanna</keyname><forenames>Omar</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author></authors><title>Inter-Sensing Time Optimization in Cognitive Radio Networks</title><categories>cs.NI</categories><comments>9 pages, 4 figures, submitted to IEEE transactions on Mobile
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of primary channels that operate in an unslotted fashion,
switching activity at random times. A secondary user senses the primary
channels searching for transmission opportunities. If a channel is sensed to be
free, the secondary terminal transmits, and if sensed to be busy, the secondary
transmitter remains silent.We solve the problem of determining the optimal time
after which a primary channel needs to be sensed again depending on the sensing
outcome. The objective is to find the inter-sensing times such that the mean
secondary throughput is maximized while imposing a constraint over the maximum
tolerable interference inflicted on the primary network. Our numerical results
show that by optimizing the sensing-dependent inter-sensing times, our proposed
scheme reduces the impact of sensing errors caused by false alarm and
misdetection and outperforms the case of a single sensing period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1209</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1209</id><created>2010-07-07</created><authors><author><keyname>Wu</keyname><forenames>Xuebin</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Wagh</keyname><forenames>Meghanad</forenames></author></authors><title>Prime Factor Cyclotomic Fourier Transforms with Reduced Complexity over
  Finite Fields</title><categories>cs.IT math.IT</categories><comments>submitted to SiPS 2010, accepted</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Discrete Fourier transforms~(DFTs) over finite fields have widespread
applications in error correction coding. Hence, reducing the computational
complexities of DFTs is of great significance, especially for long DFTs as
increasingly longer error control codes are chosen for digital communication
and storage systems. Since DFTs involve both multiplications and additions over
finite fields and multiplications are much more complex than additions,
recently proposed cyclotomic fast Fourier transforms (CFFTs) are promising due
to their low multiplicative complexity. Unfortunately, they have very high
additive complexity. Techniques such as common subexpression elimination (CSE)
can be used to reduce the additive complexity of CFFTs, but their effectiveness
for long DFTs is limited by their complexity. In this paper, we propose prime
factor cyclotomic Fourier transforms (PFCFTs), which use CFFTs as sub-DFTs via
the prime factor algorithm. When the length of DFTs is prime, our PFCFTs reduce
to CFFTs. When the length has co-prime factors, since the sub-DFTs have much
shorter lengths, this allows us to use CSE to significantly reduce their
additive complexity. In comparison to previously proposed fast Fourier
transforms, our PFCFTs achieve reduced overall complexity when the length of
DFTs is at least 255, and the improvement significantly increases as the length
grows. This approach also enables us to propose efficient DFTs with very long
length (e.g., 4095-point), first efficient DFTs of such lengths in the
literature. Finally, our PFCFTs are also advantageous for hardware
implementation due to their regular structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1213</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1213</id><created>2010-07-07</created><updated>2010-12-12</updated><authors><author><keyname>Wu</keyname><forenames>Xuebin</forenames></author><author><keyname>Wagh</keyname><forenames>Meghanad</forenames></author><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Wang</keyname><forenames>Ying</forenames></author></authors><title>Composite Cyclotomic Fourier Transforms with Reduced Complexities</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE trans on Signal Processing</comments><doi>10.1109/TSP.2011.2106778</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Discrete Fourier transforms~(DFTs) over finite fields have widespread
applications in digital communication and storage systems. Hence, reducing the
computational complexities of DFTs is of great significance. Recently proposed
cyclotomic fast Fourier transforms (CFFTs) are promising due to their low
multiplicative complexities. Unfortunately, there are two issues with CFFTs:
(1) they rely on efficient short cyclic convolution algorithms, which has not
been investigated thoroughly yet, and (2) they have very high additive
complexities when directly implemented. In this paper, we address both issues.
One of the main contributions of this paper is efficient bilinear 11-point
cyclic convolution algorithms, which allow us to construct CFFTs over
GF$(2^{11})$. The other main contribution of this paper is that we propose
composite cyclotomic Fourier transforms (CCFTs). In comparison to previously
proposed fast Fourier transforms, our CCFTs achieve lower overall complexities
for moderate to long lengths, and the improvement significantly increases as
the length grows. Our 2047-point and 4095-point CCFTs are also first efficient
DFTs of such lengths to the best of our knowledge. Finally, our CCFTs are also
advantageous for hardware implementations due to their regular and modular
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1214</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1214</id><created>2010-07-07</created><updated>2011-10-11</updated><authors><author><keyname>Blanchet</keyname><forenames>Jose</forenames></author><author><keyname>Stauffer</keyname><forenames>Alexandre</forenames></author></authors><title>Characterizing Optimal Sampling of Binary Contingency Tables via the
  Configuration Model</title><categories>math.PR cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binary contingency table is an m x n array of binary entries with
prescribed row sums r=(r_1,...,r_m) and column sums c=(c_1,...,c_n). The
configuration model for uniformly sampling binary contingency tables proceeds
as follows. First, label N=\sum_{i=1}^{m} r_i tokens of type 1, arrange them in
m cells, and let the i-th cell contain r_i tokens. Next, label another set of
tokens of type 2 containing N=\sum_{j=1}^{n}c_j elements arranged in n cells,
and let the j-th cell contain c_j tokens. Finally, pair the type-1 tokens with
the type-2 tokens by generating a random permutation until the total pairing
corresponds to a binary contingency table. Generating one random permutation
takes O(N) time, which is optimal up to constant factors. A fundamental
question is whether a constant number of permutations is sufficient to obtain a
binary contingency table. In the current paper, we solve this problem by
showing a necessary and sufficient condition so that the probability that the
configuration model outputs a binary contingency table remains bounded away
from 0 as N goes to \infty. Our finding shows surprising differences from
recent results for binary symmetric contingency tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1222</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1222</id><created>2010-07-07</created><authors><author><keyname>Bitner</keyname><forenames>Steven</forenames></author><author><keyname>Daescu</keyname><forenames>Ovidiu</forenames></author></authors><title>Minimum Sum Dipolar Spanning Tree in R^3</title><categories>cs.CG</categories><comments>11 pages, 4 figures, submitted to Computational Geometry: Theory and
  Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider finding a geometric minimum-sum dipolar spanning
tree in R^3, and present an algorithm that takes O(n^2 log^2 n) time using
O(n^2) space, thus almost matching the best known results for the planar case.
Our solution uses an interesting result related to the complexity of the common
intersection of n balls in R^3, of possible different radii, that are all
tangent to a given point p. The problem has applications in communication
networks, when the goal is to minimize the distance between two hubs or servers
as well as the distance from any node in the network to the closer of the two
hubs. The approach used in this paper also provides a solution to the discrete
2-center problem in R^3 within the same time and space bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1229</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1229</id><created>2010-07-07</created><updated>2011-04-14</updated><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>Submodularity on a tree: Unifying $L^\natural$-convex and bisubmodular
  functions</title><categories>cs.DM</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of functions that can be minimized in polynomial
time in the value oracle model. These are functions $f$ satisfying
$f(x)+f(y)\ge f(x \sqcap y)+f(x \sqcup y)$ where the domain of each variable
$x_i$ corresponds to nodes of a rooted binary tree, and operations
$\sqcap,\sqcup$ are defined with respect to this tree. Special cases include
previously studied $L^\natural$-convex and bisubmodular functions, which can be
obtained with particular choices of trees. We present a polynomial-time
algorithm for minimizing functions in the new class. It combines Murota's
steepest descent algorithm for $L^\natural$-convex functions with bisubmodular
minimization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1233</identifier>
 <datestamp>2014-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1233</id><created>2010-07-01</created><authors><author><keyname>Bandyopadhyay</keyname><forenames>Samir Kumar</forenames></author><author><keyname>Maitra</keyname><forenames>Indra Kanta</forenames></author></authors><title>An Alternative Approach of Steganography using Reference Image</title><categories>cs.MM</categories><comments>http://ijict.org/index.php/ijoat/article/view/approach-of-stegnagraphy .
  arXiv admin note: text overlap with
  http://dx.doi.org/10.1016/j.sigpro.2009.08.010 by other authors without
  attribution</comments><journal-ref>International Journal of Advancements in Technology, Vol 1, No 1
  (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper is to create a practical steganographic implementation for 4-bit
images.The proposed technique converts 4 bit image into 4 shaded Gray Scale
image. This image will be act as reference image to hide the text. Using this
grey scale reference image any text can be hidden. Single character of a text
can be represented by 8-bit. The 8-bit character can be split into 4X2 bit
information. If the reference image and the data file are transmitted through
network separately, we can achieve the effect of Steganography. Here the image
is not at all distorted because said image is only used for referencing. Any
huge mount of text material can be hidden using a very small image. Decipher
the text is not possible intercepting the image or data file separately. So, it
is more secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1234</identifier>
 <datestamp>2012-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1234</id><created>2010-07-07</created><updated>2012-06-02</updated><authors><author><keyname>Medvedev</keyname><forenames>Georgi S.</forenames></author></authors><title>Stochastic stability of continuous time consensus protocols</title><categories>math.OC cs.SY nlin.AO q-bio.NC</categories><comments>SIAM Journal on Control and Optimization, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unified approach to studying convergence and stochastic stability of
continuous time consensus protocols (CPs) is presented in this work. Our method
applies to networks with directed information flow; both cooperative and
noncooperative interactions; networks under weak stochastic forcing; and those
whose topology and strength of connections may vary in time. The graph
theoretic interpretation of the analytical results is emphasized. We show how
the spectral properties, such as algebraic connectivity and total effective
resistance, as well as the geometric properties, such the dimension and the
structure of the cycle subspace of the underlying graph, shape stability of the
corresponding CPs. In addition, we explore certain implications of the spectral
graph theory to CP design. In particular, we point out that expanders, sparse
highly connected graphs, generate CPs whose performance remains uniformly high
when the size of the network grows unboundedly. Similarly, we highlight the
benefits of using random versus regular network topologies for CP design. We
illustrate these observations with numerical examples and refer to the relevant
graph-theoretic results.
  Keywords: consensus protocol, dynamical network, synchronization, robustness
to noise, algebraic connectivity, effective resistance, expander, random graph
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1243</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1243</id><created>2010-07-07</created><updated>2010-07-09</updated><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>New Results on the Capacity of the Gaussian Cognitive Interference
  Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of the two-user Gaussian cognitive interference channel, a
variation of the classical interference channel where one of the transmitters
has knowledge of both messages, is known in several parameter regimes but
remains unknown in general. In this paper, we consider the following achievable
scheme: the cognitive transmitter pre-codes its message against the
interference created at its intended receiver by the primary user, and the
cognitive receiver only decodes its intended message, similar to the optimal
scheme for &quot;weak interference&quot;; the primary decoder decodes both messages,
similar to the optimal scheme for &quot;very strong interference&quot;. Although the
cognitive message is pre-coded against the primary message, by decoding it, the
primary receiver obtains information about its own message, thereby improving
its rate. We show: (1) that this proposed scheme achieves capacity in what we
term the &quot;primary decodes cognitive&quot; regime, i.e., a subset of the &quot;strong
interference&quot; regime that is not included in the &quot;very strong interference&quot;
regime for which capacity was known; (2) that this scheme is within one
bit/s/Hz, or a factor two, of capacity for a much larger set of parameters,
thus improving the best known constant gap result; (3) we provide insights into
the trade-off between interference pre-coding at the cognitive encoder and
interference decoding at the primary receiver based on the analysis of the
approximate capacity results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1253</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1253</id><created>2010-07-07</created><updated>2010-11-19</updated><authors><author><keyname>Price</keyname><forenames>Eric</forenames></author></authors><title>Efficient Sketches for the Set Query Problem</title><categories>cs.DS cs.IT math.IT</categories><comments>16 pages, 2 figures. Appearing in SODA 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We develop an algorithm for estimating the values of a vector x in R^n over a
support S of size k from a randomized sparse binary linear sketch Ax of size
O(k). Given Ax and S, we can recover x' with ||x' - x_S||_2 &lt;= eps ||x -
x_S||_2 with probability at least 1 - k^{-\Omega(1)}. The recovery takes O(k)
time.
  While interesting in its own right, this primitive also has a number of
applications. For example, we can:
  1. Improve the linear k-sparse recovery of heavy hitters in Zipfian
distributions with O(k log n) space from a (1+eps) approximation to a (1 +
o(1)) approximation, giving the first such approximation in O(k log n) space
when k &lt;= O(n^{1-eps}).
  2. Recover block-sparse vectors with O(k) space and a (1+eps) approximation.
Previous algorithms required either omega(k) space or omega(1) approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1255</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1255</id><created>2010-07-07</created><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Queue-Architecture and Stability Analysis in Cooperative Relay Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>16 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An abstraction of the physical layer coding using bit pipes that are coupled
through data-rates is insufficient to capture notions such as node cooperation
in cooperative relay networks. Consequently, network-stability analyses based
on such abstractions are valid for non-cooperative schemes alone and
meaningless for cooperative schemes. Motivated from this, this paper develops a
framework that brings the information-theoretic coding scheme together with
network-stability analysis. This framework does not constrain the system to any
particular achievable scheme, i.e., the relays can use any cooperative coding
strategy of its choice, be it amplify/compress/quantize or any
alter-and-forward scheme. The paper focuses on the scenario when coherence
duration is of the same order of the packet/codeword duration, the channel
distribution is unknown and the fading state is only known causally. The main
contributions of this paper are two-fold: first, it develops a low-complexity
queue-architecture to enable stable operation of cooperative relay networks,
and, second, it establishes the throughput optimality of a simple network
algorithm that utilizes this queue-architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1259</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1259</id><created>2010-07-07</created><updated>2011-05-02</updated><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author></authors><title>Privacy-Preserving Access of Outsourced Data via Oblivious RAM
  Simulation</title><categories>cs.DS cs.CR cs.DC</categories><comments>A more complete version of a paper appearing in the 38th
  International Colloquium on Automata, Languages and Programming (ICALP) 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose a client, Alice, has outsourced her data to an external storage
provider, Bob, because he has capacity for her massive data set, of size n,
whereas her private storage is much smaller--say, of size O(n^{1/r}), for some
constant r &gt; 1. Alice trusts Bob to maintain her data, but she would like to
keep its contents private. She can encrypt her data, of course, but she also
wishes to keep her access patterns hidden from Bob as well. We describe schemes
for the oblivious RAM simulation problem with a small logarithmic or
polylogarithmic amortized increase in access times, with a very high
probability of success, while keeping the external storage to be of size O(n).
To achieve this, our algorithmic contributions include a parallel MapReduce
cuckoo-hashing algorithm and an external-memory dataoblivious sorting
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1260</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1260</id><created>2010-07-07</created><updated>2011-02-24</updated><authors><author><keyname>Beigel</keyname><forenames>Richard</forenames></author><author><keyname>Fu</keyname><forenames>Bin</forenames></author></authors><title>A Dense Hierarchy of Sublinear Time Approximation Schemes for Bin
  Packing</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bin packing problem is to find the minimum number of bins of size one to
pack a list of items with sizes $a_1,..., a_n$ in $(0,1]$. Using uniform
sampling, which selects a random element from the input list each time, we
develop a randomized $O({n(\log n)(\log\log n)\over \sum_{i=1}^n a_i}+({1\over
\epsilon})^{O({1\over\epsilon})})$ time $(1+\epsilon)$-approximation scheme for
the bin packing problem. We show that every randomized algorithm with uniform
random sampling needs $\Omega({n\over \sum_{i=1}^n a_i})$ time to give an
$(1+\epsilon)$-approximation. For each function $s(n): N\rightarrow N$, define
$\sum(s(n))$ to be the set of all bin packing problems with the sum of item
sizes equal to $s(n)$. For a constant $b\in (0,1)$, every problem in
$\sum(n^{b})$ has an $O(n^{1-b}(\log n)(\log\log n)+({1\over
\epsilon})^{O({1\over\epsilon})})$ time $(1+\epsilon)$-approximation for an
arbitrary constant $\epsilon$. On the other hand, there is no $o(n^{1-b})$ time
$(1+\epsilon)$-approximation scheme for the bin packing problems in
$\sum(n^{b})$ for some constant $\epsilon&gt;0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1261</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1261</id><created>2010-07-07</created><authors><author><keyname>Bennett</keyname><forenames>Collin</forenames></author><author><keyname>Grossman</keyname><forenames>Robert L.</forenames></author><author><keyname>Locke</keyname><forenames>David</forenames></author><author><keyname>Seidman</keyname><forenames>Jonathan</forenames></author><author><keyname>Vejcik</keyname><forenames>Steve</forenames></author></authors><title>MalStone: Towards A Benchmark for Analytics on Large Data Clouds</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing data mining algorithms that are suitable for cloud computing
platforms is currently an active area of research, as is developing cloud
computing platforms appropriate for data mining. Currently, the most common
benchmark for cloud computing is the Terasort (and related) benchmarks.
Although the Terasort Benchmark is quite useful, it was not designed for data
mining per se. In this paper, we introduce a benchmark called MalStone that is
specifically designed to measure the performance of cloud computing middleware
that supports the type of data intensive computing common when building data
mining models. We also introduce MalGen, which is a utility for generating data
on clouds that can be used with MalStone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1264</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1264</id><created>2010-07-07</created><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Van Nguyen</keyname><forenames>Tam</forenames></author><author><keyname>Kim</keyname><forenames>Dong Il</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author></authors><title>Network Traffic Anomalies Detection and Identification with Flow
  Monitoring</title><categories>cs.NI</categories><comments>Presented at 5th International Conference on Wireless and Optical
  Communications Networks (WOCN'08) May 5-7, 2008, Surabaya, East Java
  Indonesia</comments><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network management and security is currently one of the most vibrant research
areas, among which, research on detecting and identifying anomalies has
attracted a lot of interest. Researchers are still struggling to find an
effective and lightweight method for anomaly detection purpose. In this paper,
we propose a simple, robust method that detects network anomalous traffic data
based on flow monitoring. Our method works based on monitoring the four
predefined metrics that capture the flow statistics of the network. In order to
prove the power of the new method, we did build an application that detects
network anomalies using our method. And the result of the experiments proves
that by using the four simple metrics from the flow data, we do not only
effectively detect but can also identify the network traffic anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1265</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1265</id><created>2010-07-07</created><authors><author><keyname>Van Nguyen</keyname><forenames>Tam</forenames></author><author><keyname>Lim</keyname><forenames>Wontaek</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author></authors><title>Context Awareness Framework Based on Contextual Graph</title><categories>cs.NI</categories><comments>Presented at The 5th International Conference on Wireless and Optical
  Communications Networks (WOCN'08) May 5-7, 2008, Surabaya, East Java
  Indonesia</comments><acm-class>C.2.4; C.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays computing becomes increasingly mobile and pervasive. One of the
important steps in pervasive computing is context-awareness. Context-aware
pervasive systems rely on information about the context and user preferences to
adapt their behavior. However, context-aware applications do not always behave
as user's desire, and can cause users to feel dissatisfied with unexpected
actions. To solve these problems, context-aware systems must provide mechanisms
to adapt automatically when the context changes significantly. The interesting
characteristic of context is its own behaviors which depend on various aspects
of the surrounding contexts. This paper uses contextual graphs to solve the
problem &quot;the mutual relationships among the contexts&quot;. We describe the most
relevant work in this area, as well as ongoing research on developing
context-aware system for ubiquitous computing based on contextual graph. The
usage of contextual graph in context-awareness is expected to make it effective
for developers to develop various applications with the need of context
reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1266</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1266</id><created>2010-07-07</created><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author></authors><title>Network Anomaly Detection: Flow-based or Packet-based Approach?</title><categories>cs.NI</categories><comments>Published on Chonnam National University Networking Journal, Gwangju,
  Korea June 2008</comments><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most critical tasks for network administrator is to ensure system
uptime and availability. For the network security, anomaly detection systems,
along with firewalls and intrusion prevention systems are the must-have tools.
So far in the field of network anomaly detection, people are working on two
different approaches. One is flow-based; usually rely on network elements to
make so-called flow information available for analysis. The second approach is
packet-based; which directly analyzes the data packet information for the
detection of anomalies. This paper describes the main differences between the
two approaches through an in-depth analysis. We try to answer the question of
when and why an approach is better than the other. The answer is critical for
network administrators to make their choices in deploying a defending system,
securing the network and ensuring business continuity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1268</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1268</id><created>2010-07-07</created><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author></authors><title>Application of Data Mining to Network Intrusion Detection: Classifier
  Selection Model</title><categories>cs.NI cs.AI</categories><comments>Presented at The 11th Asia-Pacific Network Operations and Management
  Symposium (APNOMS 2008)</comments><acm-class>C.2.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As network attacks have increased in number and severity over the past few
years, intrusion detection system (IDS) is increasingly becoming a critical
component to secure the network. Due to large volumes of security audit data as
well as complex and dynamic properties of intrusion behaviors, optimizing
performance of IDS becomes an important open problem that is receiving more and
more attention from the research community. The uncertainty to explore if
certain algorithms perform better for certain attack classes constitutes the
motivation for the reported herein. In this paper, we evaluate performance of a
comprehensive set of classifier algorithms using KDD99 dataset. Based on
evaluation results, best algorithms for each attack category is chosen and two
classifier algorithm selection models are proposed. The simulation result
comparison indicates that noticeable performance improvement and real-time
intrusion detection can be achieved as we apply the proposed models to detect
different kinds of network attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1269</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1269</id><created>2010-07-07</created><updated>2011-12-15</updated><authors><author><keyname>Dereniowski</keyname><forenames>Dariusz</forenames></author></authors><title>From Pathwidth to Connected Pathwidth</title><categories>cs.DM</categories><msc-class>68R10 (Primary) 05C83, 05C85 (Secondary)</msc-class><journal-ref>SIAM J. Discrete Mathematics 26 (2012) 1709-1732</journal-ref><doi>10.1137/110826424</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is proven that the connected pathwidth of any graph $G$ is at most
$2\cdot\pw(G)+1$, where $\pw(G)$ is the pathwidth of $G$. The method is
constructive, i.e. it yields an efficient algorithm that for a given path
decomposition of width $k$ computes a connected path decomposition of width at
most $2k+1$. The running time of the algorithm is $O(dk^2)$, where $d$ is the
number of `bags' in the input path decomposition.
  The motivation for studying connected path decompositions comes from the
connection between the pathwidth and the search number of a graph. One of the
advantages of the above bound for connected pathwidth is an inequality
$\csn(G)\leq 2\sn(G)+3$, where $\csn(G)$ and $\sn(G)$ are the connected search
number and the search number of $G$. Moreover, the algorithm presented in this
work can be used to convert a given search strategy using $k$ searchers into a
(monotone) connected one using $2k+3$ searchers and starting at an arbitrary
homebase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1270</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1270</id><created>2010-07-07</created><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Van Nguyen</keyname><forenames>Tam</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author></authors><title>How to Maximize User Satisfaction Degree in Multi-service IP Networks</title><categories>cs.NI cs.AI</categories><comments>Presented at The First Asia Conference on Intelligent Information and
  Database Systems April, 1-3, 2009, Dong Hoi City, Quang Binh province,
  Vietnam</comments><acm-class>C.2.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandwidth allocation is a fundamental problem in communication networks. With
current network moving towards the Future Internet model, the problem is
further intensified as network traffic demanding far from exceeds network
bandwidth capability. Maintaining a certain user satisfaction degree therefore
becomes a challenge research topic. In this paper, we deal with the problem by
proposing BASMIN, a novel bandwidth allocation scheme that aims to maximize
network user's happiness. We also defined a new metric for evaluating network
user satisfaction degree: network worth. A three-step evaluation process is
then conducted to compare BASMIN efficiency with other three popular bandwidth
allocation schemes. Throughout the tests, we experienced BASMIN's advantages
over the others; we even found out that one of the most widely used bandwidth
allocation schemes, in fact, is not effective at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1271</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1271</id><created>2010-07-07</created><authors><author><keyname>Aggarwal</keyname><forenames>Gagan</forenames></author><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Karande</keyname><forenames>Chinmay</forenames></author><author><keyname>Mehta</keyname><forenames>Aranyak</forenames></author></authors><title>Online Vertex-Weighted Bipartite Matching and Single-bid Budgeted
  Allocations</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the following vertex-weighted online bipartite matching problem:
$G(U, V, E)$ is a bipartite graph. The vertices in $U$ have weights and are
known ahead of time, while the vertices in $V$ arrive online in an arbitrary
order and have to be matched upon arrival. The goal is to maximize the sum of
weights of the matched vertices in $U$. When all the weights are equal, this
reduces to the classic \emph{online bipartite matching} problem for which Karp,
Vazirani and Vazirani gave an optimal $\left(1-\frac{1}{e}\right)$-competitive
algorithm in their seminal work~\cite{KVV90}. Our main result is an optimal
$\left(1-\frac{1}{e}\right)$-competitive randomized algorithm for general
vertex weights. We use \emph{random perturbations} of weights by appropriately
chosen multiplicative factors. Our solution constitutes the first known
generalization of the algorithm in~\cite{KVV90} in this model and provides new
insights into the role of randomization in online allocation problems. It also
effectively solves the problem of \emph{online budgeted allocations}
\cite{MSVV05} in the case when an agent makes the same bid for any desired
item, even if the bid is comparable to his budget - complementing the results
of \cite{MSVV05, BJN07} which apply when the bids are much smaller than the
budgets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1272</identifier>
 <datestamp>2012-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1272</id><created>2010-07-07</created><updated>2012-04-19</updated><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Binary is Good: A Binary Inference Framework for Primary User Separation
  in Cognitive Radio Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Withdrawn for updating as a new submission</comments><acm-class>C.2.3; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Primary users (PU) separation concerns with the issues of distinguishing and
characterizing primary users in cognitive radio (CR) networks. We argue the
need for PU separation in the context of collaborative spectrum sensing and
monitor selection. In this paper, we model the observations of monitors as
boolean OR mixtures of underlying binary latency sources for PUs, and devise a
novel binary inference algorithm for PU separation. Simulation results show
that without prior knowledge regarding PUs' activities, the algorithm achieves
high inference accuracy. An interesting implication of the proposed algorithm
is the ability to effectively represent n independent binary sources via
(correlated) binary vectors of logarithmic length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1273</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1273</id><created>2010-07-07</created><authors><author><keyname>Van Nguyen</keyname><forenames>Tam</forenames></author><author><keyname>Lim</keyname><forenames>Wontaek</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author><author><keyname>Lee</keyname><forenames>Chilwoo</forenames></author></authors><title>Context Ontology Implementation for Smart Home</title><categories>cs.NI</categories><comments>Presented at The 2nd International Conference on Ubiquitous
  Information Technologies &amp; Applications (ICUT'07) Java Island, Indonesia</comments><acm-class>C.2.4; C.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context awareness is one of the important fields in ubiquitous computing.
Smart Home, a specific instance of ubiquitous computing, provides every family
with opportunities to enjoy the power of hi-tech home living. Discovering that
relationship among user, activity and context data in home environment is
semantic, therefore, we apply ontology to model these relationships and then
reason them as the semantic information. In this paper, we present the
realization of smart home's context-aware system based on ontology. We discuss
the current challenges in realizing the ontology context base. These challenges
can be listed as collecting context information from heterogeneous sources,
such as devices, agents, sensors into ontology, ontology management, ontology
querying, and the issue related to environment database explosion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1274</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1274</id><created>2010-07-07</created><authors><author><keyname>Van Nguyen</keyname><forenames>Tam</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Choi</keyname><forenames>Deokjai</forenames></author></authors><title>Development of a Context Aware Virtual Smart Home Simulator</title><categories>cs.NI</categories><comments>Presented at 3rd International Conference on Ubiquitous Information
  Technologies &amp; Applications (ICUT'08)</comments><acm-class>C.2.4; C.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context awareness is the most important research area in ubiquitous
computing. In particular, for smart home, context awareness attempts to bring
the best services to the home habitants. However, the implementation in the
real environment is not easy and takes a long time from building the scratch.
Thus, to support the implementation in the real smart home, it is necessary to
demonstrate that thing can be done in the simulator in which context
information can be created by virtual sensors instead of physical sensors. In
this paper, we propose ISS, an Interactive Smart home Simulator system aiming
at controlling and simulating the behavior of an intelligent house. The
developed system aims to provide architects, designers a simulation and useful
tool for understanding the interaction between environment, people and the
impact of embedded and pervasive technology on in daily life. In this research,
the smart house is considered as an environment made up of independent and
distributed devices interacting to support user's goals and tasks. Therefore,
by using ISS, the developer can realize the relationship among virtual home
space, surrounded environment, use and home appliances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1282</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1282</id><created>2010-07-07</created><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>A note on sample complexity of learning binary output neural networks
  under fixed input distributions</title><categories>cs.LG</categories><comments>6 pages, latex in IEEE conference proceedings format</comments><msc-class>68T05</msc-class><acm-class>I.2.6</acm-class><journal-ref>Proc. 2010 Eleventh Brazilian Symposium on Neural Networks (S\~ao
  Bernardo do Campo, SP, Brazil, 23-28 October 2010), IEEE Computer Society,
  2010, pp. 7-12</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the learning sample complexity of a sigmoidal neural network
constructed by Sontag (1992) required to achieve a given misclassification
error under a fixed purely atomic distribution can grow arbitrarily fast: for
any prescribed rate of growth there is an input distribution having this rate
as the sample complexity, and the bound is asymptotically tight. The rate can
be superexponential, a non-recursive function, etc. We further observe that
Sontag's ANN is not Glivenko-Cantelli under any input distribution having a
non-atomic part.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1283</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1283</id><created>2010-07-08</created><authors><author><keyname>Karlin</keyname><forenames>Anna R.</forenames></author><author><keyname>Mathieu</keyname><forenames>Claire</forenames></author><author><keyname>Nguyen</keyname><forenames>C. Thach</forenames></author></authors><title>Integrality Gaps of Linear and Semi-definite Programming Relaxations for
  Knapsack</title><categories>cs.CC cs.DM math.OC</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the integrality gap of the Knapsack linear program in
the Sherali- Adams and Lasserre hierarchies. First, we show that an integrality
gap of 2 - {\epsilon} persists up to a linear number of rounds of
Sherali-Adams, despite the fact that Knapsack admits a fully polynomial time
approximation scheme [27,33]. Second, we show that the Lasserre hierarchy
closes the gap quickly. Specifically, after t rounds of Lasserre, the
integrality gap decreases to t/(t - 1). To the best of our knowledge, this is
the first positive result that uses more than a small number of rounds in the
Lasserre hierarchy. Our proof uses a decomposition theorem for the Lasserre
hierarchy, which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1324</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1324</id><created>2010-07-08</created><updated>2011-11-15</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Separating the basic logics of the basic recurrences</title><categories>cs.LO math.LO</categories><msc-class>03B47, 03B70, 68Q10, 68T27, 68T15</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>Annals of Pure and Applied Logic 163 (2012), pp. 377-389</journal-ref><doi>10.1016/j.apal.2011.11.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that, even at the most basic level, the parallel, countable
branching and uncountable branching recurrences of Computability Logic (see
http://www.cis.upenn.edu/~giorgi/cl.html) validate different principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1328</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1328</id><created>2010-07-08</created><updated>2014-04-25</updated><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author></authors><title>On belief propagation guided decimation for random k-SAT</title><categories>math.CO cs.DM</categories><msc-class>68R01</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let F be a uniformly distributed random k-SAT formula with n variables and m
clauses. Non-constructive arguments show that F is satisfiable for
clause/variable ratios m/n&lt; r(k)~2^k ln 2 with high probability. Yet no
efficient algorithm is know to find a satisfying assignment for densities as
low as m/n r(k).ln(k)/k with a non-vanishing probability. In fact, the density
m/n r(k).ln(k)/k seems to form a barrier for a broad class of local search
algorithms. One of the very few algorithms that plausibly seemed capable of
breaking this barrier is a message passing algorithm called Belief Propagation
Guided Decimation. It was put forward on the basis of deep but non-rigorous
statistical mechanics considerations. Experiments conducted for k=3,4,5
suggested that the algorithm might succeed for densities very close to r_k.
Furnishing the first rigorous analysis of BP decimation, the present paper
shows that the algorithm fails to find a satisfying assignment already for
m/n&gt;c.r(k)/k, for a constant c&gt;0 (independent of k).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1333</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1333</id><created>2010-07-08</created><updated>2011-03-14</updated><authors><author><keyname>Schewe</keyname><forenames>Sven</forenames></author></authors><title>Minimisation of Deterministic Parity and Buchi Automata and Relative
  Minimisation of Deterministic Finite Automata</title><categories>cs.FL</categories><msc-class>68Q45</msc-class><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we study the problem of minimising deterministic automata over
finite and infinite words. Deterministic finite automata are the simplest
devices to recognise regular languages, and deterministic Buchi, Co-Buchi, and
parity automata play a similar role in the recognition of \omega-regular
languages. While it is well known that the minimisation of deterministic finite
and weak automata is cheap, the complexity of minimising deterministic Buchi
and parity automata has remained an open challenge. We establish the
NP-completeness of these problems. A second contribution of this report is the
introduction of relaxed minimisation of deterministic finite automata. Like
hyper-minimisation, relaxed minimisation allows for some changes in the
language of the automaton: We seek a smallest automaton that, when used as a
monitor, provides a wrong answer only a bounded number of times in any run of a
system. We argue that minimisation of finite automata, hyper-minimisation,
relaxed minimisation, and the minimisation of deterministic Buchi (or Co-Buchi)
automata are operations of increasing reduction power, as the respective
equivalence relations on automata become coarser from left to right. When we
allow for minor changes in the language, relaxed minimisation can therefore be
considered as a more powerful minimisation technique than hyper-minimisation
from the perspective of finite automata. From the perspective of Buchi and
Co-Buchi automata, we gain a cheap algorithm for state-space reduction that
also turns out to be beneficial for further heuristic or exhaustive state-space
reductions put on top of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1343</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1343</id><created>2010-07-08</created><authors><author><keyname>Wu</keyname><forenames>Haoyang</forenames></author></authors><title>On the justification of applying quantum strategies to the Prisoners'
  Dilemma and mechanism design</title><categories>quant-ph cs.GT</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Prisoners' Dilemma is perhaps the most famous model in the field of game
theory. Consequently, it is natural to investigate its quantum version when one
considers to apply quantum strategies to game theory. There are two main
results in this paper: 1) The well-known Prisoners' Dilemma can be categorized
into three types and only the third type is adaptable for quantum strategies.
2) As a reverse problem of game theory, mechanism design provides a better
circumstance for quantum strategies than game theory does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1345</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1345</id><created>2010-07-08</created><authors><author><keyname>Rao</keyname><forenames>Chetan S</forenames></author><author><keyname>Geevarghese</keyname><forenames>Jeffrey John</forenames></author><author><keyname>Rajan</keyname><forenames>Karthik</forenames></author></authors><title>Improved approximation bounds for Vector Bin Packing</title><categories>cs.DS cs.DM math.OC</categories><comments>15 pages, 3 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an improved approximation scheme for the Vector Bin
Packing problem (VBP), based on the combination of (near-)optimal solution of
the Linear Programming (LP) relaxation and a greedy (modified first-fit)
heuristic. The Vector Bin Packing problem of higher dimension (d \geq 2) is not
known to have asymptotic polynomial-time approximation schemes (unless P = NP).
  Our algorithm improves over the previously-known guarantee of (ln d + 1 +
epsilon) by Bansal et al. [1] for higher dimensions (d &gt; 2). We provide a
{\theta}(1) approximation scheme for certain set of inputs for any dimension d.
More precisely, we provide a 2-OPT algorithm, a result which is irrespective of
the number of dimensions d.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1361</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1361</id><created>2010-07-08</created><updated>2010-10-18</updated><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Top-K Color Queries for Document Retrieval</title><categories>cs.DS cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a new efficient (in fact optimal) data structure
for the {\em top-$K$ color problem}. Each element of an array $A$ is assigned a
color $c$ with priority $p(c)$. For a query range $[a,b]$ and a value $K$, we
have to report $K$ colors with the highest priorities among all colors that
occur in $A[a..b]$, sorted in reverse order by their priorities. We show that
such queries can be answered in $O(K)$ time using an $O(N\log \sigma)$ bits
data structure, where $N$ is the number of elements in the array and $\sigma$
is the number of colors. Thus our data structure is asymptotically optimal with
respect to the worst-case query time and space. As an immediate application of
our results, we obtain optimal time solutions for several document retrieval
problems. The method of the paper could be also of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1368</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1368</id><created>2010-07-08</created><updated>2010-10-04</updated><authors><author><keyname>Punekar</keyname><forenames>Mayur</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>Low Complexity Linear Programming Decoding of Nonbinary Linear Codes</title><categories>cs.IT math.IT</categories><comments>8 pages, 5 figures, In the Proceedings of the Forty-Eighth Annual
  Allerton Conference on Communication, Control, and Computing, September 29 -
  October 1, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear Programming (LP) decoding of Low-Density Parity-Check (LDPC) codes has
attracted much attention in the research community in the past few years. The
aim of LP decoding is to develop an algorithm which has error-correcting
performance similar to that of the Sum-Product (SP) decoding algorithm, while
at the same time it should be amenable to mathematical analysis. The LP
decoding algorithm has also been extended to nonbinary linear codes by Flanagan
et al. However, the most important problem with LP decoding for both binary and
nonbinary linear codes is that the complexity of standard LP solvers such as
the simplex algorithm remain prohibitively large for codes of moderate to large
block length. To address this problem, Vontobel et al. proposed a low
complexity LP decoding algorithm for binary linear codes which has complexity
linear in the block length. In this paper, we extend the latter work and
propose a low-complexity LP decoding algorithm for nonbinary linear codes. We
use the LP formulation proposed by Flanagan et al. as a basis and derive a pair
of primal-dual LP formulations. The dual LP is then used to develop the
low-complexity LP decoding algorithm for nonbinary linear codes. In contrast to
the binary low-complexity LP decoding algorithm, our proposed algorithm is not
directly related to the nonbinary SP algorithm. Nevertheless, the complexity of
the proposed algorithm is linear in the block length and is limited mainly by
the maximum check node degree. As a proof of concept, we also present a
simulation result for a $[80,48]$ LDPC code defined over $\mathbb{Z}_4$ using
quaternary phase-shift keying over the AWGN channel, and we show that the
error-correcting performance of the proposed LP decoding algorithm is similar
to that of the standard LP decoding using the simplex solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1371</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1371</id><created>2010-07-08</created><updated>2011-12-24</updated><authors><author><keyname>Lakshtanov</keyname><forenames>Evgeny</forenames></author><author><keyname>Roshchina</keyname><forenames>Vera</forenames></author></authors><title>Finiteness in the Card Game of War</title><categories>math.DS cs.DM cs.GT math.CO math.PR</categories><comments>To appear in American Math. Monthly</comments><journal-ref>American Math. Monthly, 119:4, pp/318-323, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The game of war is one of the most popular international children's card
games. In the beginning of the game, the pack is split into two parts, then on
each move the players reveal their top cards. The player having the highest
card collects both and returns them to the bottom of his hand. The player left
with no cards loses. Those who played this game in their childhood did not
always have enough patience to wait until the end of the game. A player who has
collected almost all the cards can lose all but a few cards in the next 3
minutes. That way the children essentially conduct mathematical experiments
observing chaotic dynamics. However, it is not quite so, as the rules of the
game do not prescribe the order in which the winning player will put his take
to the bottom of his hand: own card, then rival's or vice versa: rival's card,
then own. We provide an example of a cycling game with fixed rules. Assume now
that each player can seldom but regularly change the returning order. We have
managed to prove that in this case the mathematical expectation of the length
of the game is finite. In principle it is equivalent to the graph of the game,
which has got edges corresponding to all acceptable transitions, having got the
following property: from each initial configuration there is at least one path
to the end of the game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1378</identifier>
 <datestamp>2013-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1378</id><created>2010-07-08</created><updated>2013-04-09</updated><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author><author><keyname>Efthymiou</keyname><forenames>Charilaos</forenames></author></authors><title>On independent sets in random graphs</title><categories>cs.DM</categories><comments>Polished previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The independence number of a sparse random graph G(n,m) of average degree
d=2m/n is well-known to be \alpha(G(n,m))~2n ln(d)/d with high probability.
Moreover, a trivial greedy algorithm w.h.p. finds an independent set of size
(1+o(1)) n ln(d)/d, i.e. half the maximum size. Yet in spite of 30 years of
extensive research no efficient algorithm has emerged to produce an independent
set with (1+c)n ln(d)/d, for any fixed c&gt;0. In this paper we prove that the
combinatorial structure of the independent set problem in random graphs
undergoes a phase transition as the size k of the independent sets passes the
point k nln(d)/d. Roughly speaking, we prove that independent sets of size
k&gt;(1+c)n ln(d)/d form an intricately ragged landscape, in which local search
algorithms are bound to get stuck. We illustrate this phenomenon by providing
an exponential lower bound for the Metropolis process, a Markov chain for
sampling independents sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1388</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1388</id><created>2010-07-08</created><authors><author><keyname>Feichtinger</keyname><forenames>Christian</forenames></author><author><keyname>Habich</keyname><forenames>Johannes</forenames></author><author><keyname>Koestler</keyname><forenames>Harald</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Ruede</keyname><forenames>Ulrich</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>A Flexible Patch-Based Lattice Boltzmann Parallelization Approach for
  Heterogeneous GPU-CPU Clusters</title><categories>cs.DC cs.PF</categories><comments>20 pages, 12 figures</comments><journal-ref>Parallel Computing 37(9), 536-549 (2011)</journal-ref><doi>10.1016/j.parco.2011.03.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sustaining a large fraction of single GPU performance in parallel
computations is considered to be the major problem of GPU-based clusters. In
this article, this topic is addressed in the context of a lattice Boltzmann
flow solver that is integrated in the WaLBerla software framework. We propose a
multi-GPU implementation using a block-structured MPI parallelization, suitable
for load balancing and heterogeneous computations on CPUs and GPUs. The
overhead required for multi-GPU simulations is discussed in detail and it is
demonstrated that the kernel performance can be sustained to a large extent.
With our GPU implementation, we achieve nearly perfect weak scalability on
InfiniBand clusters. However, in strong scaling scenarios multi-GPUs make less
efficient use of the hardware than IBM BG/P and x86 clusters. Hence, a cost
analysis must determine the best course of action for a particular simulation
task. Additionally, weak scaling results of heterogeneous simulations conducted
on CPUs and GPUs simultaneously are presented using clusters equipped with
varying node configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1398</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1398</id><created>2010-07-08</created><authors><author><keyname>Sznitman</keyname><forenames>Raphael</forenames></author><author><keyname>Gupta</keyname><forenames>Manaswi</forenames></author><author><keyname>Hager</keyname><forenames>Gregory D.</forenames></author><author><keyname>Arratia</keyname><forenames>Paulo E.</forenames></author><author><keyname>Sznitman</keyname><forenames>Josue</forenames></author></authors><title>Multi-environment model estimation for motility analysis of
  Caenorhabditis Elegans</title><categories>cs.CV</categories><comments>21 pages, 8 figures, accepted in: PLoS ONE (2010)</comments><doi>10.1371/journal.pone.0011631</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nematode Caenorhabditis elegans is a well-known model organism used to
investigate fundamental questions in biology. Motility assays of this small
roundworm are designed to study the relationships between genes and behavior.
Commonly, motility analysis is used to classify nematode movements and
characterize them quantitatively. Over the past years, C. elegans' motility has
been studied across a wide range of environments, including crawling on
substrates, swimming in fluids, and locomoting through microfluidic substrates.
However, each environment often requires customized image processing tools
relying on heuristic parameter tuning. In the present study, we propose a novel
Multi-Environment Model Estimation (MEME) framework for automated image
segmentation that is versatile across various environments. The MEME platform
is constructed around the concept of Mixture of Gaussian (MOG) models, where
statistical models for both the background environment and the nematode
appearance are explicitly learned and used to accurately segment a target
nematode. Our method is designed to simplify the burden often imposed on users;
here, only a single image which includes a nematode in its environment must be
provided for model learning. In addition, our platform enables the extraction
of nematode `skeletons' for straightforward motility quantification. We test
our algorithm on various locomotive environments and compare performances with
an intensity-based thresholding method. Overall, MEME outperforms the
threshold-based approach for the overwhelming majority of cases examined.
Ultimately, MEME provides researchers with an attractive platform for C.
elegans' segmentation and `skeletonizing' across a wide range of motility
assays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1407</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1407</id><created>2010-07-08</created><updated>2010-08-17</updated><authors><author><keyname>Ingber</keyname><forenames>Amir</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Parallel Bit Interleaved Coded Modulation</title><categories>cs.IT math.IT</categories><comments>19 pages, 15 figures. A shorter version will be presented at the 48th
  Allerton Conference on Communication, Control, and Computing (Allerton 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new variant of bit interleaved coded modulation (BICM) is proposed. In the
new scheme, called Parallel BICM, L identical binary codes are used in parallel
using a mapper, a newly proposed finite-length interleaver and a binary dither
signal. As opposed to previous approaches, the scheme does not rely on any
assumptions of an ideal, infinite-length interleaver. Over a memoryless
channel, the new scheme is proven to be equivalent to a binary memoryless
channel. Therefore the scheme enables one to easily design coded modulation
schemes using a simple binary code that was designed for that binary channel.
The overall performance of the coded modulation scheme is analytically
evaluated based on the performance of the binary code over the binary channel.
The new scheme is analyzed from an information theoretic viewpoint, where the
capacity, error exponent and channel dispersion are considered. The capacity of
the scheme is identical to the BICM capacity. The error exponent of the scheme
is numerically compared to a recently proposed mismatched-decoding exponent
analysis of BICM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1432</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1432</id><created>2010-07-08</created><authors><author><keyname>Rosten</keyname><forenames>Edward</forenames></author><author><keyname>Reitmayr</keyname><forenames>Gerhard</forenames></author><author><keyname>Drummond</keyname><forenames>Tom</forenames></author></authors><title>Improved RANSAC performance using simple, iterative minimal-set solvers</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RANSAC is a popular technique for estimating model parameters in the presence
of outliers. The best speed is achieved when the minimum possible number of
points is used to estimate hypotheses for the model. Many useful problems can
be represented using polynomial constraints (for instance, the determinant of a
fundamental matrix must be zero) and so have a number of solutions which are
consistent with a minimal set. A considerable amount of effort has been
expended on finding the constraints of such problems, and these often require
the solution of systems of polynomial equations. We show that better
performance can be achieved by using a simple optimization based approach on
minimal sets. For a given minimal set, the optimization approach is not
guaranteed to converge to the correct solution. However, when used within
RANSAC the greater speed and numerical stability results in better performance
overall, and much simpler algorithms. We also show that by selecting more than
the minimal number of points and using robust optimization can yield better
results for very noisy by reducing the number of trials required. The increased
speed of our method demonstrated with experiments on essential matrix
estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1473</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1473</id><created>2010-07-08</created><authors><author><keyname>Xing</keyname><forenames>Xinyu</forenames></author><author><keyname>Dang</keyname><forenames>Jianxun</forenames></author><author><keyname>Han</keyname><forenames>Richard</forenames></author><author><keyname>Liu</keyname><forenames>Xue</forenames></author><author><keyname>Mishra</keyname><forenames>Shivakant</forenames></author></authors><title>Intrusions into Privacy in Video Chat Environments: Attacks and
  Countermeasures</title><categories>cs.CR cs.NI</categories><comments>8 pages, submitted to WPES</comments><report-no>Technical Report CU-CS 1069-10</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Video chat systems such as Chatroulette have become increasingly popular as a
way to meet and converse one-on-one via video and audio with other users online
in an open and interactive manner. At the same time, security and privacy
concerns inherent in such communication have been little explored. This paper
presents one of the first investigations of the privacy threats found in such
video chat systems, identifying three such threats, namely de-anonymization
attacks, phishing attacks, and man-in-the-middle attacks. The paper further
describes countermeasures against each of these attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1483</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1483</id><created>2010-07-08</created><authors><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Banavar</keyname><forenames>Mahesh K.</forenames></author><author><keyname>Spanias</keyname><forenames>Andreas</forenames></author></authors><title>On Inequalities Relating the Characteristic Function and Fisher
  Information</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory; 8 pages; 3
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A relationship between the Fisher information and the characteristic function
is established with the help of two inequalities. A necessary and sufficient
condition for equality is found. These results are used to determine the
asymptotic efficiency of a distributed estimation algorithm that uses constant
modulus transmissions over Gaussian multiple access channels. The loss in
efficiency of the distributed estimation scheme relative to the centralized
approach is quantified for different sensing noise distributions. It is shown
that the distributed estimator does not incur an efficiency loss if and only if
the sensing noise distribution is Gaussian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1484</identifier>
 <datestamp>2015-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1484</id><created>2010-07-08</created><authors><author><keyname>Chambers</keyname><forenames>Erin</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Flows in One-Crossing-Minor-Free Graphs</title><categories>cs.DS</categories><comments>16 pages, 4 figures</comments><acm-class>F.2.2</acm-class><journal-ref>J. Graph Algorithms &amp; Applications 17(3): 201-220, 2013</journal-ref><doi>10.7155/jgaa.00291</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the maximum flow problem in directed H-minor-free graphs where H can
be drawn in the plane with one crossing. If a structural decomposition of the
graph as a clique-sum of planar graphs and graphs of constant complexity is
given, we show that a maximum flow can be computed in O(n log n) time. In
particular, maximum flows in directed K_{3,3}-minor-free graphs and directed
K_5-minor-free graphs can be computed in O(n log n) time without additional
assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1501</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1501</id><created>2010-07-08</created><updated>2011-09-24</updated><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>Sun</keyname><forenames>Xiaorui</forenames></author><author><keyname>Tang</keyname><forenames>Bo</forenames></author><author><keyname>Wang</keyname><forenames>Yajun</forenames></author><author><keyname>Zhu</keyname><forenames>Zeyuan Allen</forenames></author></authors><title>Optimal Pricing in Social Networks with Incomplete Information</title><categories>cs.GT</categories><journal-ref>WINE 2011: The 7th Workshop on Internet &amp; Network Economics</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In revenue maximization of selling a digital product in a social network, the
utility of an agent is often considered to have two parts: a private valuation,
and linearly additive influences from other agents. We study the incomplete
information case where agents know a common distribution about others' private
valuations, and make decisions simultaneously. The &quot;rational behavior&quot; of
agents in this case is captured by the well-known Bayesian Nash equilibrium.
  Two challenging questions arise: how to compute an equilibrium and how to
optimize a pricing strategy accordingly to maximize the revenue assuming agents
follow the equilibrium? In this paper, we mainly focus on the natural model
where the private valuation of each agent is sampled from a uniform
distribution, which turns out to be already challenging.
  Our main result is a polynomial-time algorithm that can exactly compute the
equilibrium and the optimal price, when pairwise influences are non-negative.
If negative influences are allowed, computing any equilibrium even
approximately is PPAD-hard. Our algorithm can also be used to design an FPTAS
for optimizing discriminative price profile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1528</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1528</id><created>2010-07-09</created><authors><author><keyname>Zhang</keyname><forenames>Ying-Yu</forenames></author><author><keyname>Lu</keyname><forenames>Song-Feng</forenames></author></authors><title>Quantum search by partial adiabatic evolution</title><categories>cs.DS quant-ph</categories><doi>10.1103/PhysRevA.82.034304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quantum search algorithm based on the partial adiabatic
evolution\cite{Tulsi2009} is provided. We calculate its time complexity by
studying the Hamiltonian in a two-dimensional Hilbert space. It is found that
the algorithm improves the time complexity, which is $O(\sqrt{N/M})$, of the
local adiabatic search algorithm\cite{Roland2002}, to $O(\sqrt{N}/M)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1535</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1535</id><created>2010-07-09</created><updated>2012-08-14</updated><authors><author><keyname>Bienkowski</keyname><forenames>Marcin</forenames></author></authors><title>An Optimal Lower Bound for Buffer Management in Multi-Queue Switches</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the online packet buffering problem (also known as the unweighted FIFO
variant of buffer management), we focus on a single network packet switching
device with several input ports and one output port. This device forwards
unit-size, unit-value packets from input ports to the output port. Buffers
attached to input ports may accumulate incoming packets for later transmission;
if they cannot accommodate all incoming packets, their excess is lost. A packet
buffering algorithm has to choose from which buffers to transmit packets in
order to minimize the number of lost packets and thus maximize the throughput.
  We present a tight lower bound of e/(e-1) ~ 1.582 on the competitive ratio of
the throughput maximization, which holds even for fractional or randomized
algorithms. This improves the previously best known lower bound of 1.4659 and
matches the performance of the algorithm Random Schedule. Our result
contradicts the claimed performance of the algorithm Random Permutation; we
point out a flaw in its original analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1548</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1548</id><created>2010-07-09</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Morozov</keyname><forenames>Evsey</forenames></author></authors><title>Stability Analysis of GI/G/c/K Retrial Queue with Constant Retrial Rate</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a GI/G/c/K-type retrial queueing system with constant retrial
rate. The system consists of a primary queue and an orbit queue. The primary
queue has $c$ identical servers and can accommodate the maximal number of $K$
jobs. If a newly arriving job finds the full primary queue, it joins the orbit.
The original primary jobs arrive to the system according to a renewal process.
The jobs have general i.i.d. service times. A job in front of the orbit queue
retries to enter the primary queue after an exponentially distributed time
independent of the orbit queue length. Telephone exchange systems, Medium
Access Protocols and short TCP transfers are just some applications of the
proposed queueing system. For this system we establish minimal sufficient
stability conditions. Our model is very general. In addition, to the known
particular cases (e.g., M/G/1/1 or M/M/c/c systems), the proposed model covers
as particular cases the deterministic service model and the Erlang model with
constant retrial rate. The latter particular cases have not been considered in
the past. The obtained stability conditions have clear probabilistic
interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1559</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1559</id><created>2010-07-09</created><authors><author><keyname>Srivastva</keyname><forenames>Dhruv</forenames></author></authors><title>An ICT based solution to make mines safer</title><categories>cs.NI</categories><comments>ICT: Information and communication Technologies,33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concern for the human security inside mines is as old as the mining itself.
However, ICT (Information and communication technologies), which has impacted
human life in so many ways has not been much used for making mines safer. We
propose a method that has been practically implemented which can enhance mine
safety enormously. It is based on integration of wireless sensor network with
an external network through a gateway.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1593</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1593</id><created>2010-07-09</created><updated>2011-05-03</updated><authors><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>A Fast Algorithm for Three-Dimensional Layers of Maxima Problem</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the three-dimensional layers-of-maxima problem can be solved in
$o(n\log n)$ time in the word RAM model. Our algorithm runs in $O(n(\log \log
n)^3)$ deterministic time or $O(n(\log\log n)^2)$ expected time and uses O(n)
space. We also describe an algorithm that uses optimal O(n) space and solves
the three-dimensional layers-of-maxima problem in $O(n\log n)$ time in the
pointer machine model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1604</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1604</id><created>2010-07-09</created><updated>2011-01-25</updated><authors><author><keyname>Pettarin</keyname><forenames>Alberto</forenames></author><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames></author><author><keyname>Pucci</keyname><forenames>Geppino</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>Infectious Random Walks</title><categories>cs.DM cs.DS</categories><comments>21 pages, 3 figures --- The results presented in this paper have been
  extended in: Pettarin et al., Tight Bounds on Information Dissemination in
  Sparse Mobile Networks, http://arxiv.org/abs/1101.4609</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the dynamics of information (or virus) dissemination by $m$ mobile
agents performing independent random walks on an $n$-node grid. We formulate
our results in terms of two scenarios: broadcasting and gossiping. In the
broadcasting scenario, the mobile agents are initially placed uniformly at
random among the grid nodes. At time 0, one agent is informed of a rumor and
starts a random walk. When an informed agent meets an uninformed agent, the
latter becomes informed and starts a new random walk. We study the broadcasting
time of the system, that is, the time it takes for all agents to know the
rumor. In the gossiping scenario, each agent is given a distinct rumor at time
0 and all agents start random walks. When two agents meet, they share all
rumors they are aware of. We study the gossiping time of the system, that is,
the time it takes for all agents to know all rumors. We prove that both the
broadcasting and the gossiping times are $\tilde\Theta(n/\sqrt{m})$ w.h.p.,
thus achieving a tight characterization up to logarithmic factors. Previous
results for the grid provided bounds which were weaker and only concerned
average times. In the context of virus infection, a corollary of our results is
that static and dynamically moving agents are infected at about the same speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1611</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1611</id><created>2010-07-09</created><updated>2010-08-26</updated><authors><author><keyname>Kesselheim</keyname><forenames>Thomas</forenames></author></authors><title>A Constant-Factor Approximation for Wireless Capacity Maximization with
  Power Control in the SINR Model</title><categories>cs.NI cs.DS</categories><comments>17 pages</comments><acm-class>C.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern wireless networks, devices are able to set the power for each
transmission carried out. Experimental but also theoretical results indicate
that such power control can improve the network capacity significantly. We
study this problem in the physical interference model using SINR constraints.
  In the SINR capacity maximization problem, we are given n pairs of senders
and receivers, located in a metric space (usually a so-called fading metric).
The algorithm shall select a subset of these pairs and choose a power level for
each of them with the objective of maximizing the number of simultaneous
communications. This is, the selected pairs have to satisfy the SINR
constraints with respect to the chosen powers.
  We present the first algorithm achieving a constant-factor approximation in
fading metrics. The best previous results depend on further network parameters
such as the ratio of the maximum and the minimum distance between a sender and
its receiver. Expressed only in terms of n, they are (trivial) Omega(n)
approximations.
  Our algorithm still achieves an O(log n) approximation if we only assume to
have a general metric space rather than a fading metric. Furthermore, by using
standard techniques the algorithm can also be used in single-hop and multi-hop
scheduling scenarios. Here, we also get polylog(n) approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1626</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1626</id><created>2010-07-09</created><authors><author><keyname>Jaramillo</keyname><forenames>Juan Jose</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author></authors><title>Scheduling for Optimal Rate Allocation in Ad Hoc Networks With
  Heterogeneous Delay Constraints</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of scheduling in single-hop wireless networks
with real-time traffic, where every packet arrival has an associated deadline
and a minimum fraction of packets must be transmitted before the end of the
deadline. Using optimization and stochastic network theory we propose a
framework to model the quality of service (QoS) requirements under delay
constraints. The model allows for fairly general arrival models with
heterogeneous constraints. The framework results in an optimal scheduling
algorithm which fairly allocates data rates to all flows while meeting
long-term delay demands. We also prove that under a simplified scenario our
solution translates into a greedy strategy that makes optimal decisions with
low complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1632</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1632</id><created>2010-07-09</created><authors><author><keyname>Gharan</keyname><forenames>Shayan Oveis</forenames></author><author><keyname>Vondr&#xe1;k</keyname><forenames>Jan</forenames></author></authors><title>Submodular Maximization by Simulated Annealing</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing a nonnegative (possibly non-monotone)
submodular set function with or without constraints. Feige et al. [FOCS'07]
showed a 2/5-approximation for the unconstrained problem and also proved that
no approximation better than 1/2 is possible in the value oracle model.
Constant-factor approximation was also given for submodular maximization
subject to a matroid independence constraint (a factor of 0.309 Vondrak
[FOCS'09]) and for submodular maximization subject to a matroid base
constraint, provided that the fractional base packing number is at least 2 (a
1/4-approximation, Vondrak [FOCS'09]).
  In this paper, we propose a new algorithm for submodular maximization which
is based on the idea of {\em simulated annealing}. We prove that this algorithm
achieves improved approximation for two problems: a 0.41-approximation for
unconstrained submodular maximization, and a 0.325-approximation for submodular
maximization subject to a matroid independence constraint.
  On the hardness side, we show that in the value oracle model it is impossible
to achieve a 0.478-approximation for submodular maximization subject to a
matroid independence constraint, or a 0.394-approximation subject to a matroid
base constraint in matroids with two disjoint bases. Even for the special case
of cardinality constraint, we prove it is impossible to achieve a
0.491-approximation. (Previously it was conceivable that a 1/2-approximation
exists for these problems.) It is still an open question whether a
1/2-approximation is possible for unconstrained submodular maximization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1660</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1660</id><created>2010-07-09</created><authors><author><keyname>Barsdell</keyname><forenames>Benjamin R.</forenames></author><author><keyname>Barnes</keyname><forenames>David G.</forenames></author><author><keyname>Fluke</keyname><forenames>Christopher J.</forenames></author></authors><title>Analysing Astronomy Algorithms for GPUs and Beyond</title><categories>astro-ph.IM cs.DS</categories><comments>10 pages, 3 figures, accepted for publication in MNRAS</comments><doi>10.1111/j.1365-2966.2010.17257.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Astronomy depends on ever increasing computing power. Processor clock-rates
have plateaued, and increased performance is now appearing in the form of
additional processor cores on a single chip. This poses significant challenges
to the astronomy software community. Graphics Processing Units (GPUs), now
capable of general-purpose computation, exemplify both the difficult
learning-curve and the significant speedups exhibited by massively-parallel
hardware architectures. We present a generalised approach to tackling this
paradigm shift, based on the analysis of algorithms. We describe a small
collection of foundation algorithms relevant to astronomy and explain how they
may be used to ease the transition to massively-parallel computing
architectures. We demonstrate the effectiveness of our approach by applying it
to four well-known astronomy problems: Hogbom CLEAN, inverse ray-shooting for
gravitational lensing, pulsar dedispersion and volume rendering. Algorithms
with well-defined memory access patterns and high arithmetic intensity stand to
receive the greatest performance boost from massively-parallel architectures,
while those that involve a significant amount of decision-making may struggle
to take advantage of the available processing power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1669</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1669</id><created>2010-07-09</created><updated>2010-10-02</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Francois</forenames></author></authors><title>Generalized Mean-payoff and Energy Games</title><categories>cs.LO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mean-payoff games, the objective of the protagonist is to ensure that the
limit average of an infinite sequence of numeric weights is nonnegative. In
energy games, the objective is to ensure that the running sum of weights is
always nonnegative. Generalized mean-payoff and energy games replace individual
weights by tuples, and the limit average (resp. running sum) of each coordinate
must be (resp. remain) nonnegative. These games have applications in the
synthesis of resource-bounded processes with multiple resources.
  We prove the finite-memory determinacy of generalized energy games and show
the inter-reducibility of generalized mean-payoff and energy games for
finite-memory strategies. We also improve the computational complexity for
solving both classes of games with finite-memory strategies: while the
previously best known upper bound was EXPSPACE, and no lower bound was known,
we give an optimal coNP-complete bound. For memoryless strategies, we show that
the problem of deciding the existence of a winning strategy for the protagonist
is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1673</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1673</id><created>2010-07-09</created><updated>2011-08-02</updated><authors><author><keyname>Manshadi</keyname><forenames>Vahideh H.</forenames></author><author><keyname>Gharan</keyname><forenames>Shayan Oveis</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author></authors><title>Online Stochastic Matching: Online Actions Based on Offline Statistics</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the online stochastic matching problem proposed by Feldman et al.
[FMMM09] as a model of display ad allocation. We are given a bipartite graph;
one side of the graph corresponds to a fixed set of bins and the other side
represents the set of possible ball types. At each time step, a ball is sampled
independently from the given distribution and it needs to be matched upon its
arrival to an empty bin. The goal is to maximize the number of allocations.
  We present an online algorithm for this problem with a competitive ratio of
0.702. Before our result, algorithms with a competitive ratio better than
$1-1/e$ were known under the assumption that the expected number of arriving
balls of each type is integral. A key idea of the algorithm is to collect
statistics about the decisions of the optimum offline solution using Monte
Carlo sampling and use those statistics to guide the decisions of the online
algorithm. We also show that our algorithm achieves a competitive ratio of
0.705 when the rates are integral.
  On the hardness side, we prove that no online algorithm can have a
competitive ratio better than 0.823 under the known distribution model (and
henceforth under the permutation model). This improves upon the 5/6 hardness
result proved by Goel and Mehta \cite{GM08} for the permutation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1678</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1678</id><created>2010-07-09</created><authors><author><keyname>Zuckerman</keyname><forenames>David</forenames></author></authors><title>Can Random Coin Flips Speed Up a Computer?</title><categories>cs.CC cs.CR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This expository essay introduces randomness and computation to a lay
audience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1694</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1694</id><created>2010-07-09</created><authors><author><keyname>Gamarnik</keyname><forenames>David</forenames></author><author><keyname>Katz</keyname><forenames>Dmitriy</forenames></author></authors><title>Stability of Skorokhod problem is undecidable</title><categories>math.PR cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skorokhod problem arises in studying Reflected Brownian Motion (RBM) on an
non-negative orthant, specifically in the context of queueing networks in the
heavy traffic regime. One of the key problems is identifying conditions for
stability of a Skorokhod problem, defined as the property that trajectories are
attracted to the origin. The stability conditions are known in dimension up to
three, but not for general dimensions.
  In this paper we explain the fundamental difficulties encountered in trying
to establish stability conditions for general dimensions. We prove that
stability of Skorokhod problem is an undecidable property when the starting
state is a part of the input. Namely, there does not exist an algorithm (a
constructive procedure) for identifying stable Skorokhod problem in general
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1697</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1697</id><created>2010-07-10</created><authors><author><keyname>Dutta</keyname><forenames>Sagarmoy</forenames></author><author><keyname>Kurur</keyname><forenames>Piyush P</forenames></author></authors><title>Quantum Cyclic Code</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we define and study \emph{quantum cyclic codes}, a
generalisation of cyclic codes to the quantum setting. Previously studied
examples of quantum cyclic codes were all quantum codes obtained from classical
cyclic codes via the CSS construction. However, the codes that we study are
much more general. In particular, we construct cyclic stabiliser codes with
parameters $[[5,1,3]]$, $[[17,1,7]]$ and $[[17,9,3]]$, all of which are
\emph{not} CSS. The $[[5,1,3]]$ code is the well known Laflamme code and to the
best of our knowledge the other two are new examples. Our definition of
cyclicity applies to non-stabiliser codes as well; in fact we show that the
$((5,6,2))$ nonstabiliser first constructed by Rains\etal~
cite{rains97nonadditive} and latter by Arvind
\etal~\cite{arvind:2004:nonstabilizer} is cyclic. We also study stabiliser
codes of length $4^m +1$ over $\mathbb{F}_2$ for which we define a notation of
BCH distance. Much like the Berlekamp decoding algorithm for classical BCH
codes, we give efficient quantum algorithms to correct up to
$\floor{\frac{d-1}{2}}$ errors when the BCH distance is $d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1708</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1708</id><created>2010-07-10</created><authors><author><keyname>Charn</keyname><forenames>Lim Huey</forenames></author><author><keyname>Rasid</keyname><forenames>Liyana Nuraini</forenames></author><author><keyname>Suandi</keyname><forenames>Shahrel A.</forenames></author></authors><title>A Study on the Effectiveness of Different Patch Size and Shape for Eyes
  and Mouth Detection</title><categories>cs.CV</categories><comments>9 Pages</comments><journal-ref>(IJCSE) International Journal on Computer Science and Engineering,
  Vol. 2, No. 3, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Template matching is one of the simplest methods used for eyes and mouth
detection. However, it can be modified and extended to become a powerful tool.
Since the patch itself plays a significant role in optimizing detection
performance, a study on the influence of patch size and shape is carried out.
The optimum patch size and shape is determined using the proposed method.
Usually, template matching is also combined with other methods in order to
improve detection accuracy. Thus, in this paper, the effectiveness of two image
processing methods i.e. grayscale and Haar wavelet transform, when used with
template matching are analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1709</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1709</id><created>2010-07-10</created><updated>2010-07-14</updated><authors><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Ben-Or</keyname><forenames>Michael</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>A Fault-Resistant Asynchronous Clock Function</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an asynchronous network in a shared-memory environment consisting of
n nodes. Assume that up to f of the nodes might be Byzantine (n &gt; 12f), where
the adversary is full-information and dynamic (sometimes called adaptive). In
addition, the non-Byzantine nodes may undergo transient failures. Nodes advance
in atomic steps, which consist of reading all registers, performing some
calculation and writing to all registers.
  This paper contains three main contributions. First, the clock-function
problem is defined, which is a generalization of the clock synchronization
problem. This generalization encapsulates previous clock synchronization
problem definitions while extending them to the current paper's model. Second,
a randomized asynchronous self-stabilizing Byzantine tolerant clock
synchronization algorithm is presented.
  In the construction of the clock synchronization algorithm, a building block
that ensures different nodes advance at similar rates is developed. This
feature is the third contribution of the paper. It is self-stabilizing and
Byzantine tolerant and can be used as a building block for different algorithms
that operate in an asynchronous self-stabilizing Byzantine model.
  The convergence time of the presented algorithm is exponential. Observe that
in the asynchronous setting the best known full-information dynamic Byzantine
agreement also has expected exponential convergence time, even though currently
there is no known reduction between the two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1710</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1710</id><created>2010-07-10</created><updated>2012-05-31</updated><authors><author><keyname>Brazdil</keyname><forenames>Tomas</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Kucera</keyname><forenames>Antonin</forenames></author><author><keyname>Varekova</keyname><forenames>Ivana Hutarova</forenames></author></authors><title>Runtime Analysis of Probabilistic Programs with Unbounded Recursion</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study termination time and recurrence time in programs with unbounded
recursion, which are either randomized or operate on some statistically
quantified inputs. As the underlying formal model for such programs we use
probabilistic pushdown automata (pPDA) which are equivalent to probabilistic
recursive state machines. We obtain tail bounds for the distribution of
termination time for pPDA. We also study the recurrence time for probabilistic
recursive programs that are not supposed to terminate (such as system daemons,
network servers, etc.). Typically, such programs react to certain requests
generated by their environment, and hence operate in finite request-service
cycles. We obtain bounds for the frequency of long request-service cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1717</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1717</id><created>2010-07-10</created><updated>2010-08-12</updated><authors><author><keyname>Kamalian</keyname><forenames>R. R.</forenames></author><author><keyname>Petrosyan</keyname><forenames>P. A.</forenames></author></authors><title>A note on interval edge-colorings of graphs</title><categories>cs.DM</categories><comments>4 pages, minor changes</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An edge-coloring of a graph $G$ with colors $1,2,\ldots,t$ is called an
interval $t$-coloring if for each $i\in \{1,2,\ldots,t\}$ there is at least one
edge of $G$ colored by $i$, and the colors of edges incident to any vertex of
$G$ are distinct and form an interval of integers. In this paper we prove that
if a connected graph $G$ with $n$ vertices admits an interval $t$-coloring,
then $t\leq 2n-3$. We also show that if $G$ is a connected $r$-regular graph
with $n$ vertices has an interval $t$-coloring and $n\geq 2r+2$, then this
upper bound can be improved to $2n-5$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1722</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1722</id><created>2010-07-10</created><authors><author><keyname>Tavares</keyname><forenames>Hugo Lopes</forenames></author><author><keyname>Rezende</keyname><forenames>Gustavo Guimaraes</forenames></author><author><keyname>Santos</keyname><forenames>Vanderson Mota dos</forenames></author><author><keyname>Manhaes</keyname><forenames>Rodrigo Soares</forenames></author><author><keyname>de Carvalho</keyname><forenames>Rogerio Atem</forenames></author></authors><title>A tool stack for implementing Behaviour-Driven Development in Python
  Language</title><categories>cs.SE</categories><comments>Original work, 6 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents a tool stack for the implementation, specification and
test of software following the practices of Behavior Driven Development (BDD)
in Python language. The usage of this stack highlights the specification and
validation of the software's expected behavior, reducing the error rate and
improving documentation. Therefore, it is possible to produce code with much
less defects at both functional and unit levels, in addition to better serving
to stakeholders' expectations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1726</identifier>
 <datestamp>2014-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1726</id><created>2010-07-10</created><updated>2014-02-18</updated><authors><author><keyname>Stoichev</keyname><forenames>Stoicho D.</forenames></author></authors><title>Vsep-New Heuristic and Exact Algorithms for Graph Automorphism Group
  Computation</title><categories>cs.DS cs.DM math.CO</categories><comments>40 pages; 1. Changed algorithm COMP (fig.11)- cases CS2/CS4 are
  solved in new way;2. Corrected are some bad symbols!</comments><msc-class>ma.CO</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One exact and two heuristic algorithms for determining the generators, orbits
and order of the graph automorphism group are presented. A basic tool of these
algorithms is the well-known individualization and refinement procedure. A
search tree is used in the algorithms - each node of the tree is a partition.
All nonequivalent discreet partitions derivative of the selected vertices are
stored in a coded form. A new strategy is used in the exact algorithm: if
during its execution some of the searched or intermediate variables obtain a
wrong value then the algorithm continues from a new start point losing some of
the results determined so far. The algorithms has been tested on one of the
known benchmark graphs and shows lower running times for some graph families.
The heuristic versions of the algorithms are based on determining some number
of discreet partitions derivative of each vertex in the selected cell of the
initial partition and comparing them for an automorphism - their search trees
are reduced. The heuristic algorithms are almost exact and are many times
faster than the exact one. The experimental tests exhibit that the worst-cases
running time of the exact algorithm is exponential but it is polynomial for the
heuristic algorithms. Several cell selectors are used. Some of them are new. We
also use a chooser of cell selector for choosing the optimal cell selector for
the manipulated graph. The proposed heuristic algorithms use two main heuristic
procedures that generate two different forests of search trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1733</identifier>
 <datestamp>2011-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1733</id><created>2010-07-10</created><updated>2011-10-18</updated><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Liedloff</keyname><forenames>Mathieu</forenames></author><author><keyname>Stein</keyname><forenames>Maya</forenames></author><author><keyname>Suchan</keyname><forenames>Karol</forenames></author></authors><title>Complexity of Splits Reconstruction for Low-Degree Trees</title><categories>cs.DS cs.DM</categories><journal-ref>Proc. of WG 2011, Springer LNCS 6986, pp. 167-178</journal-ref><doi>10.1007/978-3-642-25870-1_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a vertex-weighted tree T, the split of an edge xy in T is min{s_x(xy),
s_y(xy)} where s_u(uv) is the sum of all weights of vertices that are closer to
u than to v in T. Given a set of weighted vertices V and a multiset of splits
S, we consider the problem of constructing a tree on V whose splits correspond
to S. The problem is known to be NP-complete, even when all vertices have unit
weight and the maximum vertex degree of T is required to be no more than 4. We
show that the problem is strongly NP-complete when T is required to be a path,
the problem is NP-complete when all vertices have unit weight and the maximum
degree of T is required to be no more than 3, and it remains NP-complete when
all vertices have unit weight and T is required to be a caterpillar with
unbounded hair length and maximum degree at most 3. We also design polynomial
time algorithms for the variant where T is required to be a path and the number
of distinct vertex weights is constant, and the variant where all vertices have
unit weight and T has a constant number of leaves. The latter algorithm is not
only polynomial when the number of leaves, k, is a constant, but also
fixed-parameter tractable when parameterized by k. Finally, we shortly discuss
the problem when the vertex weights are not given but can be freely chosen by
an algorithm.
  The considered problem is related to building libraries of chemical compounds
used for drug design and discovery. In these inverse problems, the goal is to
generate chemical compounds having desired structural properties, as there is a
strong correlation between structural properties, such as the Wiener index,
which is closely connected to the considered problem, and biological activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1735</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1735</id><created>2010-07-10</created><authors><author><keyname>Badr</keyname><forenames>Ahmed</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Martinian</keyname><forenames>Emin</forenames></author></authors><title>Diversity Embedded Streaming Erasure Codes (DE-SCo): Constructions and
  Optimality</title><categories>cs.IT cs.NI math.IT</categories><comments>Globecom 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Streaming erasure codes encode a source stream to guarantee that each source
packet is recovered within a fixed delay at the receiver over a burst-erasure
channel. This paper introduces diversity embedded streaming erasure codes
(DE-SCo), that provide a flexible tradeoff between the channel quality and
receiver delay. When the channel conditions are good, the source stream is
recovered with a low delay, whereas when the channel conditions are poor the
source stream is still recovered, albeit with a larger delay. Information
theoretic analysis of the underlying burst-erasure broadcast channel reveals
that DE-SCo achieve the minimum possible delay for the weaker user, without
sacrificing the performance of the stronger user. A larger class of multicast
streaming erasure codes (MU-SCo) that achieve optimal tradeoff between rate,
delay and erasure-burst length is also constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1756</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1756</id><created>2010-07-10</created><updated>2010-07-13</updated><authors><author><keyname>Berry</keyname><forenames>Randall A.</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Shannon Meets Nash on the Interference Channel</title><categories>cs.IT cs.GT math.IT</categories><comments>41 pages, 10 figures, submitted to IEEE Transactions on Information
  Theory, May 2010. Added Figure 6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interference channel is the simplest communication scenario where
multiple autonomous users compete for shared resources. We combine game theory
and information theory to define a notion of a Nash equilibrium region of the
interference channel. The notion is game theoretic: it captures the selfish
behavior of each user as they compete. The notion is also information
theoretic: it allows each user to use arbitrary communication strategies as it
optimizes its own performance. We give an exact characterization of the Nash
equilibrium region of the two-user linear deterministic interference channel
and an approximate characterization of the Nash equilibrium region of the
two-user Gaussian interference channel to within 1 bit/s/Hz..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1766</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1766</id><created>2010-07-11</created><authors><author><keyname>Anthony</keyname><forenames>Gidudu</forenames></author><author><keyname>Gregg</keyname><forenames>Hulley</forenames></author><author><keyname>Tshilidzi</keyname><forenames>Marwala</forenames></author></authors><title>An svm multiclassifier approach to land cover mapping</title><categories>cs.AI</categories><comments>ASPRS 2008 Annual Conference Portland, Oregon. April 28 - May 2, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From the advent of the application of satellite imagery to land cover
mapping, one of the growing areas of research interest has been in the area of
image classification. Image classifiers are algorithms used to extract land
cover information from satellite imagery. Most of the initial research has
focussed on the development and application of algorithms to better existing
and emerging classifiers. In this paper, a paradigm shift is proposed whereby a
committee of classifiers is used to determine the final classification output.
Two of the key components of an ensemble system are that there should be
diversity among the classifiers and that there should be a mechanism through
which the results are combined. In this paper, the members of the ensemble
system include: Linear SVM, Gaussian SVM and Quadratic SVM. The final output
was determined through a simple majority vote of the individual classifiers.
From the results obtained it was observed that the final derived map generated
by an ensemble system can potentially improve on the results derived from the
individual classifiers making up the ensemble system. The ensemble system
classification accuracy was, in this case, better than the linear and quadratic
SVM result. It was however less than that of the RBF SVM. Areas for further
research could focus on improving the diversity of the ensemble system used in
this research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1768</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1768</id><created>2010-07-11</created><authors><author><keyname>Aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Bracciali</keyname><forenames>Andrea</forenames></author><author><keyname>Li&#xf2;</keyname><forenames>Pietro</forenames></author><author><keyname>Sorathiya</keyname><forenames>Anil</forenames></author><author><keyname>Torquati</keyname><forenames>Massimo</forenames></author></authors><title>StochKit-FF: Efficient Systems Biology on Multicore Architectures</title><categories>cs.CE q-bio.QM</categories><comments>14 pages + cover page</comments><report-no>TR-10-12</report-no><acm-class>D.1.3; D.3.2; C.1.3; G.3; I.6; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stochastic modelling of biological systems is an informative, and in some
cases, very adequate technique, which may however result in being more
expensive than other modelling approaches, such as differential equations. We
present StochKit-FF, a parallel version of StochKit, a reference toolkit for
stochastic simulations. StochKit-FF is based on the FastFlow programming
toolkit for multicores and exploits the novel concept of selective memory. We
experiment StochKit-FF on a model of HIV infection dynamics, with the aim of
extracting information from efficiently run experiments, here in terms of
average and variance and, on a longer term, of more structured data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1778</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1778</id><created>2010-07-11</created><updated>2011-07-13</updated><authors><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Hagiwara</keyname><forenames>Manabu</forenames></author><author><keyname>Imai</keyname><forenames>Hideki</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Quantum Error Correction beyond the Bounded Distance Decoding Limit</title><categories>cs.IT math.IT quant-ph</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider quantum error correction over depolarizing
channels with non-binary low-density parity-check codes defined over Galois
field of size $2^p$ . The proposed quantum error correcting codes are based on
the binary quasi-cyclic CSS (Calderbank, Shor and Steane) codes. The resulting
quantum codes outperform the best known quantum codes and surpass the
performance limit of the bounded distance decoder. By increasing the size of
the underlying Galois field, i.e., $2^p$, the error floors are considerably
improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1785</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1785</id><created>2010-07-11</created><updated>2010-09-09</updated><authors><author><keyname>Aschieri</keyname><forenames>Federico</forenames><affiliation>University of Turin and Queen Mary, University of London</affiliation></author><author><keyname>Berardi</keyname><forenames>Stefano</forenames><affiliation>University of Turin</affiliation></author></authors><title>Interactive Learning-Based Realizability for Heyting Arithmetic with EM1</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  7, 2010) lmcs:1061</journal-ref><doi>10.2168/LMCS-6(3:19)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply to the semantics of Arithmetic the idea of ``finite approximation''
used to provide computational interpretations of Herbrand's Theorem, and we
interpret classical proofs as constructive proofs (with constructive rules for
$\vee, \exists$) over a suitable structure $\StructureN$ for the language of
natural numbers and maps of G\&quot;odel's system $\SystemT$. We introduce a new
Realizability semantics we call ``Interactive learning-based Realizability'',
for Heyting Arithmetic plus $\EM_1$ (Excluded middle axiom restricted to
$\Sigma^0_1$ formulas). Individuals of $\StructureN$ evolve with time, and
realizers may ``interact'' with them, by influencing their evolution. We build
our semantics over Avigad's fixed point result, but the same semantics may be
defined over different constructive interpretations of classical arithmetic
(Berardi and de' Liguoro use continuations). Our notion of realizability
extends intuitionistic realizability and differs from it only in the atomic
case: we interpret atomic realizers as ``learning agents''.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1799</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1799</id><created>2010-07-11</created><authors><author><keyname>Moon</keyname><forenames>Taesup</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author><author><keyname>Kim</keyname><forenames>Jae-Young</forenames></author></authors><title>Discrete denoising of heterogenous two-dimensional data</title><categories>cs.IT math.IT</categories><comments>16 pages, submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider discrete denoising of two-dimensional data with characteristics
that may be varying abruptly between regions.
  Using a quadtree decomposition technique and space-filling curves, we extend
the recently developed S-DUDE (Shifting Discrete Universal DEnoiser), which was
tailored to one-dimensional data, to the two-dimensional case. Our scheme
competes with a genie that has access, in addition to the noisy data, also to
the underlying noiseless data, and can employ $m$ different two-dimensional
sliding window denoisers along $m$ distinct regions obtained by a quadtree
decomposition with $m$ leaves, in a way that minimizes the overall loss. We
show that, regardless of what the underlying noiseless data may be, the
two-dimensional S-DUDE performs essentially as well as this genie, provided
that the number of distinct regions satisfies $m=o(n)$, where $n$ is the total
size of the data. The resulting algorithm complexity is still linear in both
$n$ and $m$, as in the one-dimensional case. Our experimental results show that
the two-dimensional S-DUDE can be effective when the characteristics of the
underlying clean image vary across different regions in the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1800</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1800</id><created>2010-07-11</created><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>Multimode Control Attacks on Elections</title><categories>cs.GT cs.CC cs.DS cs.MA</categories><comments>41 pages, 2 tables</comments><report-no>URCS TR-2010-960</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1992, Bartholdi, Tovey, and Trick opened the study of control attacks on
elections---attempts to improve the election outcome by such actions as
adding/deleting candidates or voters. That work has led to many results on how
algorithms can be used to find attacks on elections and how
complexity-theoretic hardness results can be used as shields against attacks.
However, all the work in this line has assumed that the attacker employs just a
single type of attack. In this paper, we model and study the case in which the
attacker launches a multipronged (i.e., multimode) attack. We do so to more
realistically capture the richness of real-life settings. For example, an
attacker might simultaneously try to suppress some voters, attract new voters
into the election, and introduce a spoiler candidate. Our model provides a
unified framework for such varied attacks, and by constructing polynomial-time
multiprong attack algorithms we prove that for various election systems even
such concerted, flexible attacks can be perfectly planned in deterministic
polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1802</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1802</id><created>2010-07-11</created><updated>2010-07-31</updated><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Attiya</keyname><forenames>Hagit</forenames></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Dubois</keyname><forenames>Swan</forenames></author><author><keyname>Gradinariu</keyname><forenames>Maria</forenames></author><author><keyname>Tixeuil</keyname><forenames>Sebastien</forenames></author></authors><title>Practically Stabilizing Atomic Memory</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-stabilizing simulation of a single-writer multi-reader atomic register
is presented. The simulation works in asynchronous message-passing systems, and
allows processes to crash, as long as at least a majority of them remain
working. A key element in the simulation is a new combinatorial construction of
a bounded labeling scheme that can accommodate arbitrary labels, i.e.,
including those not generated by the scheme itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1811</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1811</id><created>2010-07-11</created><updated>2010-09-20</updated><authors><author><keyname>Jiang</keyname><forenames>Jinhua</forenames><affiliation>Shitz</affiliation></author><author><keyname>Maric</keyname><forenames>Ivana</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On the Capacity of a Class of Cognitive Z-interference Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, submitted to ICC2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a special class of the cognitive radio channel in which the receiver
of the cognitive pair does not suffer interference from the primary user.
Previously developed general encoding schemes for this channel are complex as
they attempt to cope with arbitrary channel conditions, which leads to rate
regions that are difficult to evaluate. The focus of our work is to derive
simple rate regions that are easily computable, thereby providing more insights
into achievable rates and good coding strategies under different channel
conditions. We first present several explicit achievable regions for the
general discrete memoryless case. We also present an improved outer bound on
the capacity region for the case of high interference. We then extend these
regions to Gaussian channels. With a simple outer bound we establish a new
capacity region in the high-interference regime. Lastly, we provide numerical
comparisons between the derived achievable rate regions and the outer bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1812</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1812</id><created>2010-07-11</created><updated>2012-03-01</updated><authors><author><keyname>Hansen</keyname><forenames>Kristoffer Arnsfelt</forenames></author><author><keyname>Ibsen-Jensen</keyname><forenames>Rasmus</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author></authors><title>The complexity of solving reachability games using value and strategy
  iteration</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two standard algorithms for approximately solving two-player zero-sum
concurrent reachability games are value iteration and strategy iteration. We
prove upper and lower bounds of 2^(m^(Theta(N))) on the worst case number of
iterations needed by both of these algorithms for providing non-trivial
approximations to the value of a game with N non-terminal positions and m
actions for each player in each position. In particular, both algorithms have
doubly-exponential complexity. Even when the game given as input has only one
non-terminal position, we prove an exponential lower bound on the worst case
number of iterations needed to provide non-trivial approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1819</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1819</id><created>2010-07-12</created><authors><author><keyname>Kurkoski</keyname><forenames>Brian M.</forenames></author></authors><title>Rewritable Codes for Flash Memories Based Upon Lattices, and an Example
  Using the E8 Lattice</title><categories>cs.IT math.IT</categories><comments>Submitted to Globecom 2010. 5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rewriting code construction for flash memories based upon lattices is
described. The values stored in flash cells correspond to lattice points. This
construction encodes information to lattice points in such a way that data can
be written to the memory multiple times without decreasing the cell values. The
construction partitions the flash memory's cubic signal space into blocks. The
minimum number of writes is shown to be linear in one of the code parameters.
An example using the E8 lattice is given, with numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1834</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1834</id><created>2010-07-12</created><authors><author><keyname>Terui</keyname><forenames>Akira</forenames></author></authors><title>GPGCD, an Iterative Method for Calculating Approximate GCD of Univariate
  Polynomials, with the Complex Coefficients</title><categories>math.AC cs.SC</categories><comments>10 pages. The Joint Conference of ASCM 2009 (Asian Symposium on
  Computer Mathematics) and MACIS 2009 (Mathematical Aspects of Computer and
  Information Sciences), December 14-17, 2009, Fukuoka, Japan</comments><msc-class>13P99, 68W30</msc-class><acm-class>I.1.2; F.2.1; G.1.6</acm-class><journal-ref>The Joint Conference of ASCM 2009 and MACIS 2009. COE Lecture Note
  Vol.22. Faculty of Mathematics, Kyushu University, Fukuoka, Japan. pp.
  212-221, December 2009. ISSN 1881-4042</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension of our GPGCD method, an iterative method for
calculating approximate greatest common divisor (GCD) of univariate
polynomials, to polynomials with the complex coefficients. For a given pair of
polynomials and a degree, our algorithm finds a pair of polynomials which has a
GCD of the given degree and whose coefficients are perturbed from those in the
original inputs, making the perturbations as small as possible, along with the
GCD. In our GPGCD method, the problem of approximate GCD is transfered to a
constrained minimization problem, then solved with a so-called modified Newton
method, which is a generalization of the gradient-projection method, by
searching the solution iteratively. While our original method is designed for
polynomials with the real coefficients, we extend it to accept polynomials with
the complex coefficients in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1836</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1836</id><created>2010-07-12</created><authors><author><keyname>Terui</keyname><forenames>Akira</forenames></author></authors><title>GPGCD, an Iterative Method for Calculating Approximate GCD, for Multiple
  Univariate Polynomials</title><categories>math.AC cs.SC</categories><comments>12 pages. To appear Proc. CASC 2010 (Computer Algebra in Scientific
  Computing), Tsakhkadzor, Armenia, September 2010</comments><msc-class>13P99, 68W30</msc-class><acm-class>I.1.2; F.2.1; G.1.6</acm-class><doi>10.1007/978-3-642-15274-0_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension of our GPGCD method, an iterative method for
calculating approximate greatest common divisor (GCD) of univariate
polynomials, to multiple polynomial inputs. For a given pair of polynomials and
a degree, our algorithm finds a pair of polynomials which has a GCD of the
given degree and whose coefficients are perturbed from those in the original
inputs, making the perturbations as small as possible, along with the GCD. In
our GPGCD method, the problem of approximate GCD is transferred to a
constrained minimization problem, then solved with the so-called modified
Newton method, which is a generalization of the gradient-projection method, by
searching the solution iteratively. In this paper, we extend our method to
accept more than two polynomials with the real coefficients as an input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1841</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1841</id><created>2010-07-12</created><authors><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Communication Complexity</title><categories>cs.CC</categories><comments>This is my Master's Thesis written in 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first section starts with the basic definitions following mainly the
notations of the book written by E. Kushilevitz and N. Nisan. At the end of the
first section I examine tree-balancing.
  In the second section I summarize the well-known lower bound methods and
prove the exact complexity of certain functions.
  In the first part of the third section I introduce the random complexity and
prove the basic lemmas about it. In the second part I prove a better lower
bound for the complexity of all random functions. In the third part I introduce
and compare several upper bounds for the complexity of the identity function.
  In the fourth section I examine the well-known Direct-sum conjecture. I
introduce a different model of computation then prove that it is the same as
the original one up to a constant factor. This new model is used to bound the
Amortized Time Complexity of a function by the number of the leaves of its
protocol-tree. After this I examine the Direct-sum problem in case of Partial
Information and in the Random case.
  In the last section I introduce the well-known hierarchy classes, the
reducibility and the completeness of series of functions. Then I define the
class PSPACE and Oracles in the communication complexity model and prove some
basic claims about them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1852</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1852</id><created>2010-07-12</created><updated>2010-11-30</updated><authors><author><keyname>Adcock</keyname><forenames>Ben</forenames></author><author><keyname>Hansen</keyname><forenames>Anders C.</forenames></author></authors><title>A Generalized Sampling Theorem for Stable Reconstructions in Arbitrary
  Bases</title><categories>math.NA cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a generalized framework for sampling and reconstruction in
separable Hilbert spaces. Specifically, we establish that it is always possible
to stably reconstruct a vector in an arbitrary Riesz basis from sufficiently
many of its samples in any other Riesz basis. This framework can be viewed as
an extension of that of Eldar et al. However, whilst the latter imposes
stringent assumptions on the reconstruction basis, and may in practice be
unstable, our framework allows for recovery in any (Riesz) basis in a manner
that is completely stable.
  Whilst the classical Shannon Sampling Theorem is a special case of our
theorem, this framework allows us to exploit additional information about the
approximated vector (or, in this case, function), for example sparsity or
regularity, to design a reconstruction basis that is better suited. Examples
are presented illustrating this procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1868</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1868</id><created>2010-07-12</created><updated>2010-07-13</updated><authors><author><keyname>Matsuki</keyname><forenames>Norichika</forenames></author></authors><title>NP=PSPACE</title><categories>cs.CC</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a misunderstanding about
3QBF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1938</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1938</id><created>2010-07-12</created><updated>2011-10-24</updated><authors><author><keyname>Cusick</keyname><forenames>Thomas W.</forenames></author></authors><title>Affine equivalence of cubic homogeneous rotation symmetric Boolean
  functions</title><categories>cs.IT math.IT math.NT</categories><comments>This is the author's version of a manuscript which has been accepted
  by Information Sciences. The ancillary Mathematica file contains a program
  which computes the equivalence classes described in the paper, given n =
  number of variables</comments><msc-class>94C10, 94A15, 06E30</msc-class><journal-ref>Information Sciences 181 (2011), 5067-5083</journal-ref><doi>10.1016/j.ins.2011.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Homogeneous rotation symmetric Boolean functions have been extensively
studied in recent years because of their applications in cryptography. Little
is known about the basic question of when two such functions are affine
equivalent. The simplest case of quadratic rotation symmetric functions which
are generated by cyclic permutations of the variables in a single monomial was
only settled in 2009. This paper studies the much more complicated cubic case
for such functions. A new concept of \emph{patterns} is introduced, by means of
which the structure of the smallest group G_n, whose action on the set of all
such cubic functions in $n$ variables gives the affine equivalence classes for
these functions under permutation of the variables, is determined. We
conjecture that the equivalence classes are the same if all nonsingular affine
transformations, not just permutations, are allowed. This conjecture is
verified if n &lt; 22. Our method gives much more information about the
equivalence classes; for example, in this paper we give a complete description
of the equivalence classes when n is a prime or a power of 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1944</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1944</id><created>2010-07-12</created><authors><author><keyname>Vaniachine</keyname><forenames>A. V.</forenames></author></authors><title>LHC Databases on the Grid: Achievements and Open Issues</title><categories>cs.DB cs.DC hep-ex physics.data-an</categories><comments>10 pages, invited talk presented at the IV International Conference
  on &quot;Distributed computing and Grid-technologies in science and education&quot;
  (Grid2010), JINR, Dubna, Russia, June 28 - July 3, 2010</comments><report-no>ANL-HEP-CP-10-18</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  To extract physics results from the recorded data, the LHC experiments are
using Grid computing infrastructure. The event data processing on the Grid
requires scalable access to non-event data (detector conditions, calibrations,
etc.) stored in relational databases. The database-resident data are critical
for the event data reconstruction processing steps and often required for
physics analysis. This paper reviews LHC experience with database technologies
for the Grid computing. List of topics includes: database integration with Grid
computing models of the LHC experiments; choice of database technologies;
examples of database interfaces; distributed database applications (data
complexity, update frequency, data volumes and access patterns); scalability of
database access in the Grid computing environment of the LHC experiments. The
review describes areas in which substantial progress was made and remaining
open issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1946</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1946</id><created>2010-07-12</created><updated>2011-08-09</updated><authors><author><keyname>Kanizo</keyname><forenames>Yossi</forenames></author><author><keyname>Hay</keyname><forenames>David</forenames></author><author><keyname>Keslassy</keyname><forenames>Isaac</forenames></author></authors><title>Maximum Bipartite Matching Size And Application to Cuckoo Hashing</title><categories>cs.DS cs.NI</categories><comments>14 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cuckoo hashing with a stash is a robust multiple choice hashing scheme with
high memory utilization that can be used in many network device applications.
Unfortunately, for memory loads beyond 0.5, little is known on its performance.
  In this paper, we analyze its average performance over such loads. We tackle
this problem by recasting the problem as an analysis of the expected maximum
matching size of a given random bipartite graph. We provide exact results for
any finite system, and also deduce asymptotic results as the memory size
increases. We further consider other variants of this problem, and finally
evaluate the performance of our models on Internet backbone traces. More
generally, our results give a tight lower bound on the size of the stash needed
for any multiple-choice hashing scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.1986</identifier>
 <datestamp>2012-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.1986</id><created>2010-07-12</created><updated>2012-04-23</updated><authors><author><keyname>Mirghaderi</keyname><forenames>Reza</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Achievable Error Exponents in the Gaussian Channel with Rate-Limited
  Feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the achievable error probability in communication over an AWGN
discrete time memoryless channel with noiseless delay-less rate-limited
feedback. For the case where the feedback rate R_FB is lower than the data rate
R transmitted over the forward channel, we show that the decay of the
probability of error is at most exponential in blocklength, and obtain an upper
bound for increase in the error exponent due to feedback. Furthermore, we show
that the use of feedback in this case results in an error exponent that is at
least RF B higher than the error exponent in the absence of feedback. For the
case where the feedback rate exceeds the forward rate (R_FB \geq R), we propose
a simple iterative scheme that achieves a probability of error that decays
doubly exponentially with the codeword blocklength n. More generally, for some
positive integer L, we show that a L-th order exponential error decay is
achievable if R_FB \geq (L-1)R. We prove that the above results hold whether
the feedback constraint is expressed in terms of the average feedback rate or
per channel use feedback rate. Our results show that the error exponent as a
function of R_FB has a strong discontinuity at R, where it jumps from a finite
value to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2016</identifier>
 <datestamp>2015-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2016</id><created>2010-07-12</created><updated>2015-09-09</updated><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>On Flat Polyhedra deriving from Alexandrov's Theorem</title><categories>cs.CG cs.DM</categories><comments>8 pages, 3 figures, 10 references. This is a revision of the 2010
  note, to clarify the meaning of 'n' in the complexity claim. Previously n was
  the number of vertices of the polygons, but n should be the complexity of the
  gluing instructions, which could be arbitrarily larger than the number of
  polygon vertices</comments><msc-class>51M20</msc-class><acm-class>F.2.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there is a straightforward algorithm to determine if the
polyhedron guaranteed to exist by Alexandrov's gluing theorem is a degenerate
flat polyhedron, and to reconstruct it from the gluing instructions. The
algorithm runs in O(n^3) time for polygons whose gluings are specified by n
labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2021</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2021</id><created>2010-07-12</created><updated>2011-10-05</updated><authors><author><keyname>Fellows</keyname><forenames>Michael R.</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Rosamond</keyname><forenames>Frances A.</forenames></author></authors><title>Parameterizing by the Number of Numbers</title><categories>cs.DS cs.DM</categories><doi>10.1007/978-3-642-17493-3_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The usefulness of parameterized algorithmics has often depended on what
Niedermeier has called, &quot;the art of problem parameterization&quot;. In this paper we
introduce and explore a novel but general form of parameterization: the number
of numbers. Several classic numerical problems, such as Subset Sum, Partition,
3-Partition, Numerical 3-Dimensional Matching, and Numerical Matching with
Target Sums, have multisets of integers as input. We initiate the study of
parameterizing these problems by the number of distinct integers in the input.
We rely on an FPT result for ILPF to show that all the above-mentioned problems
are fixed-parameter tractable when parameterized in this way. In various
applied settings, problem inputs often consist in part of multisets of integers
or multisets of weighted objects (such as edges in a graph, or jobs to be
scheduled). Such number-of-numbers parameterized problems often reduce to
subproblems about transition systems of various kinds, parameterized by the
size of the system description. We consider several core problems of this kind
relevant to number-of-numbers parameterization. Our main hardness result
considers the problem: given a non-deterministic Mealy machine M (a finite
state automaton outputting a letter on each transition), an input word x, and a
census requirement c for the output word specifying how many times each letter
of the output alphabet should be written, decide whether there exists a
computation of M reading x that outputs a word y that meets the requirement c.
We show that this problem is hard for W[1]. If the question is whether there
exists an input word x such that a computation of M on x outputs a word that
meets c, the problem becomes fixed-parameter tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2049</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2049</id><created>2010-07-13</created><authors><author><keyname>Veness</keyname><forenames>Joel</forenames></author><author><keyname>Ng</keyname><forenames>Kee Siong</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Silver</keyname><forenames>David</forenames></author></authors><title>Reinforcement Learning via AIXI Approximation</title><categories>cs.LG</categories><comments>8 LaTeX pages, 1 figure</comments><journal-ref>Proc. 24th AAAI Conference on Artificial Intelligence (AAAI 2010)
  pages 605-611</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a principled approach for the design of a scalable
general reinforcement learning agent. This approach is based on a direct
approximation of AIXI, a Bayesian optimality notion for general reinforcement
learning agents. Previously, it has been unclear whether the theory of AIXI
could motivate the design of practical algorithms. We answer this hitherto open
question in the affirmative, by providing the first computationally feasible
approximation to the AIXI agent. To develop our approximation, we introduce a
Monte Carlo Tree Search algorithm along with an agent-specific extension of the
Context Tree Weighting algorithm. Empirically, we present a set of encouraging
results on a number of stochastic, unknown, and partially observable domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2071</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2071</id><created>2010-07-13</created><authors><author><keyname>Yeredor</keyname><forenames>Arie</forenames></author></authors><title>Independent Component Analysis Over Galois Fields</title><categories>cs.IT math.IT physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the framework of Independent Component Analysis (ICA) for the
case where the independent sources and their linear mixtures all reside in a
Galois field of prime order P. Similarities and differences from the classical
ICA framework (over the Real field) are explored. We show that a necessary and
sufficient identifiability condition is that none of the sources should have a
Uniform distribution. We also show that pairwise independence of the mixtures
implies their full mutual independence (namely a non-mixing condition) in the
binary (P=2) and ternary (P=3) cases, but not necessarily in higher order (P&gt;3)
cases. We propose two different iterative separation (or identification)
algorithms: One is based on sequential identification of the smallest-entropy
linear combinations of the mixtures, and is shown to be equivariant with
respect to the mixing matrix; The other is based on sequential minimization of
the pairwise mutual information measures. We provide some basic performance
analysis for the binary (P=2) case, supplemented by simulation results for
higher orders, demonstrating advantages and disadvantages of the proposed
separation approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2075</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2075</id><created>2010-07-13</created><authors><author><keyname>Sunehag</keyname><forenames>Peter</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Consistency of Feature Markov Processes</title><categories>cs.LG cs.IT math.IT</categories><comments>16 LaTeX pages</comments><journal-ref>Proc. 21st International Conf. on Algorithmic Learning Theory
  (ALT-2010) pages 360-374</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are studying long term sequence prediction (forecasting). We approach this
by investigating criteria for choosing a compact useful state representation.
The state is supposed to summarize useful information from the history. We want
a method that is asymptotically consistent in the sense it will provably
eventually only choose between alternatives that satisfy an optimality property
related to the used criterion. We extend our work to the case where there is
side information that one can take advantage of and, furthermore, we briefly
discuss the active setting where an agent takes actions to achieve desirable
outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2088</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2088</id><created>2010-07-13</created><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>A Multi-hop Multi-source Algebraic Watchdog</title><categories>cs.CR cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear in IEEE ITW Dublin 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our previous work &quot;An Algebraic Watchdog for Wireless Network Coding&quot;, we
proposed a new scheme in which nodes can detect malicious behaviors
probabilistically, police their downstream neighbors locally using overheard
messages; thus, provide a secure global &quot;self-checking network&quot;. As the first
building block of such a system, we focused on a two-hop network, and presented
a graphical model to understand the inference process by which nodes police
their downstream neighbors and to compute the probabilities of misdetection and
false detection.
  In this paper, we extend the Algebraic Watchdog to a more general network
setting, and propose a protocol in which we can establish &quot;trust&quot; in coded
systems in a distributed manner. We develop a graphical model to detect the
presence of an adversarial node downstream within a general two-hop network.
The structure of the graphical model (a trellis) lends itself to well-known
algorithms, such as Viterbi algorithm, that can compute the probabilities of
misdetection and false detection. Using this as a building block, we generalize
our scheme to multi-hop networks. We show analytically that as long as the
min-cut is not dominated by the Byzantine adversaries, upstream nodes can
monitor downstream neighbors and allow reliable communication with certain
probability. Finally, we present preliminary simulation results that support
our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2117</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2117</id><created>2010-07-13</created><updated>2011-05-11</updated><authors><author><keyname>Hedtke</keyname><forenames>Ivo</forenames></author></authors><title>Strassen's Matrix Multiplication Algorithm for Matrices of Arbitrary
  Order</title><categories>math.NA cs.SC</categories><comments>8 pages, 2 figures</comments><msc-class>65F30, 68Q17</msc-class><journal-ref>Bulletin of Mathematical Analysis and Applications, ISSN
  1821-1291, Volume 3 Issue 2 (2011), Pages 269-277</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well known algorithm of Volker Strassen for matrix multiplication can
only be used for $(m2^k \times m2^k)$ matrices. For arbitrary $(n \times n)$
matrices one has to add zero rows and columns to the given matrices to use
Strassen's algorithm. Strassen gave a strategy of how to set $m$ and $k$ for
arbitrary $n$ to ensure $n\leq m2^k$. In this paper we study the number $d$ of
additional zero rows and columns and the influence on the number of flops used
by the algorithm in the worst case ($d=n/16$), best case ($d=1$) and in the
average case ($d\approx n/48$). The aim of this work is to give a detailed
analysis of the number of additional zero rows and columns and the additional
work caused by Strassen's bad parameters. Strassen used the parameters $m$ and
$k$ to show that his matrix multiplication algorithm needs less than
$4.7n^{\log_2 7}$ flops. We can show in this paper, that these parameters cause
an additional work of approx. 20 % in the worst case in comparison to the
optimal strategy for the worst case. This is the main reason for the search for
better parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2119</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2119</id><created>2010-07-13</created><updated>2011-03-18</updated><authors><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bjorn</forenames></author></authors><title>Free Probability based Capacity Calculation of Multiantenna Gaussian
  Fading Channels with Cochannel Interference</title><categories>cs.IT math.IT</categories><comments>16 pages, 4 figures, 1 table</comments><doi>10.1016/j.phycom.2011.03.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last decade, it has been well understood that communication over
multiple antennas can increase linearly the multiplexing capacity gain and
provide large spectral efficiency improvements. However, the majority of
studies in this area were carried out ignoring cochannel interference. Only a
small number of investigations have considered cochannel interference, but even
therein simple channel models were employed, assuming identically distributed
fading coefficients. In this paper, a generic model for a multi-antenna channel
is presented incorporating four impairments, namely additive white Gaussian
noise, flat fading, path loss and cochannel interference. Both point-to-point
and multiple-access MIMO channels are considered, including the case of
cooperating Base Station clusters. The asymptotic capacity limit of this
channel is calculated based on an asymptotic free probability approach which
exploits the additive and multiplicative free convolution in the R- and
S-transform domain respectively, as well as properties of the eta and Stieltjes
transform. Numerical results are utilized to verify the accuracy of the derived
closed-form expressions and evaluate the effect of the cochannel interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2120</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2120</id><created>2010-07-13</created><authors><author><keyname>Kranakis</keyname><forenames>Evangelos</forenames></author><author><keyname>Krizanc</keyname><forenames>Danny</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Narayanan</keyname><forenames>Lata</forenames></author><author><keyname>Stacho</keyname><forenames>Ladislav</forenames></author></authors><title>A Tight Bound on the Maximum Interference of Random Sensors in the
  Highway Model</title><categories>cs.CG cs.NI</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider $n$ sensors whose positions are represented by $n$ uniform,
independent and identically distributed random variables assuming values in the
open unit interval $(0,1)$. A natural way to guarantee connectivity in the
resulting sensor network is to assign to each sensor as its range, the maximum
of the two possible distances to its two neighbors. The interference at a given
sensor is defined as the number of sensors that have this sensor within their
range. In this paper we prove that the expected maximum interference of the
sensors is $\Theta (\sqrt{\ln n})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2123</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2123</id><created>2010-07-12</created><updated>2010-08-04</updated><authors><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Comparative Studies of Programming Languages; Course Lecture Notes</title><categories>cs.PL</categories><comments>66 pages; index; revision 1.9 -- more copy-editing (Type Systems) and
  index updates; expected to evolve frequently while the course is in progress</comments><acm-class>D.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Lecture notes for the Comparative Studies of Programming Languages course,
COMP6411, taught at the Department of Computer Science and Software
Engineering, Faculty of Engineering and Computer Science, Concordia University,
Montreal, QC, Canada. These notes include a compiled book of primarily related
articles from the Wikipedia, the Free Encyclopedia, as well as Comparative
Programming Languages book and other resources, including our own. The original
notes were compiled by Dr. Paquet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2131</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2131</id><created>2010-07-13</created><updated>2010-08-20</updated><authors><author><keyname>Bandyopadhyay</keyname><forenames>S.</forenames></author><author><keyname>Sarkar</keyname><forenames>D.</forenames></author><author><keyname>Mandal</keyname><forenames>C. R.</forenames></author></authors><title>Equivalence Checking in Embedded Systems Design Verification</title><categories>cs.LO cs.FL</categories><comments>This paper has been withdrawn by the author. I want to modify this
  technical report. Please see arXiv:1010.4953</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we focus on some aspects related to modeling and formal
verification of embedded systems. Many models have been proposed to represent
embedded systems. These models encompass a broad range of styles,
characteristics, and application domains and include the extensions of finite
state machines, data flow graphs, communication processes and Petri nets. In
this report, we have used a PRES+ model (Petri net based Representation for
Embedded Systems) as an extension of classical Petri net model that captures
concurrency, timing behaviour of embedded systems; it allows systems to be
representative in different levels of abstraction and improves expressiveness
by allowing the token to carry information. Modeling using PRES+, as discussed
above, may be convenient for specifying the input behaviour because it supports
concurrency. However, there is no equivalence checking method reported in the
literature for PRES+ models to the best of our knowledge. In contrast,
equivalence checking of FSMD models exist. As a first step, therefore, we seek
to devise an algorithm to translate PRES+ models to FSMD models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2140</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2140</id><created>2010-07-13</created><authors><author><keyname>Goemans</keyname><forenames>Michel X.</forenames></author><author><keyname>Soto</keyname><forenames>Jos&#xe9; A.</forenames></author></authors><title>Symmetric Submodular Function Minimization Under Hereditary Family
  Constraints</title><categories>cs.DS</categories><comments>13 pages, Submitted to SODA 2011</comments><journal-ref>SIAM J. Discrete Math., 27(2), 1123--1145. 2013</journal-ref><doi>10.1137/120891502</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient algorithm to find non-empty minimizers of a symmetric
submodular function over any family of sets closed under inclusion. This for
example includes families defined by a cardinality constraint, a knapsack
constraint, a matroid independence constraint, or any combination of such
constraints. Our algorithm make $O(n^3)$ oracle calls to the submodular
function where $n$ is the cardinality of the ground set. In contrast, the
problem of minimizing a general submodular function under a cardinality
constraint is known to be inapproximable within $o(\sqrt{n/\log n})$ (Svitkina
and Fleischer [2008]).
  The algorithm is similar to an algorithm of Nagamochi and Ibaraki [1998] to
find all nontrivial inclusionwise minimal minimizers of a symmetric submodular
function over a set of cardinality $n$ using $O(n^3)$ oracle calls. Their
procedure in turn is based on Queyranne's algorithm [1998] to minimize a
symmetric submodular
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2152</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2152</id><created>2010-07-13</created><authors><author><keyname>Soto</keyname><forenames>Jos&#xe9; A.</forenames></author></authors><title>Matroid Secretary Problem in the Random Assignment Model</title><categories>cs.DS</categories><comments>16 pages. Submitted to SODA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Matroid Secretary Problem, introduced by Babaioff et al. [SODA 2007],
the elements of a given matroid are presented to an online algorithm in random
order. When an element is revealed, the algorithm learns its weight and decides
whether or not to select it under the restriction that the selected elements
form an independent set in the matroid. The objective is to maximize the total
weight of the chosen elements. In the most studied version of this problem, the
algorithm has no information about the weights beforehand. We refer to this as
the zero information model. In this paper we study a different model, also
proposed by Babaioff et al., in which the relative order of the weights is
random in the matroid. To be precise, in the random assignment model, an
adversary selects a collection of weights that are randomly assigned to the
elements of the matroid. Later, the elements are revealed to the algorithm in a
random order independent of the assignment.
  Our main result is the first constant competitive algorithm for the matroid
secretary problem in the random assignment model. This solves an open question
of Babaioff et al. Our algorithm achieves a competitive ratio of $2e^2/(e-1)$.
It exploits the notion of principal partition of a matroid, its decomposition
into uniformly dense minors, and a $2e$-competitive algorithm for uniformly
dense matroids we also develop. As additional results, we present simple
constant competitive algorithms in the zero information model for various
classes of matroids including cographic, low density and the case when every
element is in a small cocircuit. In the same model, we also give a
$ke$-competitive algorithm for $k$-column sparse linear matroids, and a new
$O(\log r)$-competitive algorithm for general matroids of rank $r$ which only
uses the relative order of the weights seen and not their numerical value, as
previously needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2170</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2170</id><created>2010-07-13</created><updated>2012-02-02</updated><authors><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author><author><keyname>Rothvo&#xdf;</keyname><forenames>Thomas</forenames></author></authors><title>Bin Packing via Discrepancy of Permutations</title><categories>cs.DM math.CO math.OC</categories><comments>Journal version of SODA'11 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well studied special case of bin packing is the 3-partition problem, where
n items of size &gt; 1/4 have to be packed in a minimum number of bins of capacity
one. The famous Karmarkar-Karp algorithm transforms a fractional solution of a
suitable LP relaxation for this problem into an integral solution that requires
at most O(log n) additional bins.
  The three-permutations-problem of Beck is the following. Given any 3
permutations on n symbols, color the symbols red and blue, such that in any
interval of any of those permutations, the number of red and blue symbols is
roughly the same. The necessary difference is called the discrepancy.
  We establish a surprising connection between bin packing and Beck's problem:
The additive integrality gap of the 3-partition linear programming relaxation
can be bounded by the discrepancy of 3 permutations.
  Reversely, making use of a recent example of 3 permutations, for which a
discrepancy of Omega(log n) is necessary, we prove the following: The O(log^2
n) upper bound on the additive gap for bin packing with arbitrary item sizes
cannot be improved by any technique that is based on rounding up items. This
lower bound holds for a large class of algorithms including the Karmarkar-Karp
procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2204</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2204</id><created>2010-07-13</created><authors><author><keyname>Hahn</keyname><forenames>J&#xf6;rg M.</forenames></author></authors><title>What's wrong with Phong - Designers' appraisal of shading in CAD-systems</title><categories>cs.GR</categories><comments>17 pages, 8 figures</comments><acm-class>I.3.7; J.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Phong illumination model is still widely used in realtime 3D
visualization systems. The aim of this article is to document problems with the
Phong illumination model that are encountered by an important professional user
group, namely digital designers. This leads to a visual evaluation of Phong
illumination, which at least in this condensed form seems still to be missing
in the literature. It is hoped that by explicating these flaws, awareness about
the limitations and interdependencies of the model will increase, both among
fellow users, and among researchers and developers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2212</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2212</id><created>2010-07-13</created><updated>2010-07-15</updated><authors><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Tumova</keyname><forenames>Jana</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>Optimal Path Planning under Temporal Logic Constraints</title><categories>cs.RO</categories><comments>Extended version of IROS 2010 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a method for automatically generating optimal robot
trajectories satisfying high level mission specifications. The motion of the
robot in the environment is modeled as a general transition system, enhanced
with weighted transitions. The mission is specified by a general linear
temporal logic formula. In addition, we require that an optimizing proposition
must be repeatedly satisfied. The cost function that we seek to minimize is the
maximum time between satisfying instances of the optimizing proposition. For
every environment model, and for every formula, our method computes a robot
trajectory which minimizes the cost function. The problem is motivated by
applications in robotic monitoring and data gathering. In this setting, the
optimizing proposition is satisfied at all locations where data can be
uploaded, and the entire formula specifies a complex (and infinite horizon)
data collection mission. Our method utilizes B\&quot;uchi automata to produce an
automaton (which can be thought of as a graph) whose runs satisfy the temporal
logic specification. We then present a graph algorithm which computes a path
corresponding to the optimal robot trajectory. We also present an
implementation for a robot performing a data gathering mission in a road
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2216</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2216</id><created>2010-07-13</created><authors><author><keyname>Williams</keyname><forenames>Virginia Vassilevska</forenames></author></authors><title>Faster Replacement Paths</title><categories>cs.DS</categories><comments>the current version contains an improved result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The replacement paths problem for directed graphs is to find for given nodes
s and t and every edge e on the shortest path between them, the shortest path
between s and t which avoids e. For unweighted directed graphs on n vertices,
the best known algorithm runtime was \tilde{O}(n^{2.5}) by Roditty and Zwick.
For graphs with integer weights in {-M,...,M}, Weimann and Yuster recently
showed that one can use fast matrix multiplication and solve the problem in
O(Mn^{2.584}) time, a runtime which would be O(Mn^{2.33}) if the exponent
\omega of matrix multiplication is 2.
  We improve both of these algorithms. Our new algorithm also relies on fast
matrix multiplication and runs in O(M n^{\omega} polylog(n)) time if \omega&gt;2
and O(n^{2+\eps}) for any \eps&gt;0 if \omega=2. Our result shows that, at least
for small integer weights, the replacement paths problem in directed graphs may
be easier than the related all pairs shortest paths problem in directed graphs,
as the current best runtime for the latter is \Omega(n^{2.5}) time even if
\omega=2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2217</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2217</id><created>2010-07-13</created><authors><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Chen</keyname><forenames>Zesheng</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author></authors><title>Darknet-Based Inference of Internet Worm Temporal Characteristics</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet worm attacks pose a significant threat to network security and
management. In this work, we coin the term Internet worm tomography as
inferring the characteristics of Internet worms from the observations of
Darknet or network telescopes that monitor a routable but unused IP address
space. Under the framework of Internet worm tomography, we attempt to infer
Internet worm temporal behaviors, i.e., the host infection time and the worm
infection sequence, and thus pinpoint patient zero or initially infected hosts.
Specifically, we introduce statistical estimation techniques and propose method
of moments, maximum likelihood, and linear regression estimators. We show
analytically and empirically that our proposed estimators can better infer worm
temporal characteristics than a naive estimator that has been used in the
previous work. We also demonstrate that our estimators can be applied to worms
using different scanning strategies such as random scanning and localized
scanning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2238</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2238</id><created>2010-07-13</created><updated>2010-07-26</updated><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Online Algorithms for the Multi-Armed Bandit Problem with Markovian
  Rewards</title><categories>math.OC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the classical multi-armed bandit problem with Markovian rewards.
When played an arm changes its state in a Markovian fashion while it remains
frozen when not played. The player receives a state-dependent reward each time
it plays an arm. The number of states and the state transition probabilities of
an arm are unknown to the player. The player's objective is to maximize its
long-term total reward by learning the best arm over time. We show that under
certain conditions on the state transition probabilities of the arms, a sample
mean based index policy achieves logarithmic regret uniformly over the total
number of trials. The result shows that sample mean based index policies can be
applied to learning problems under the rested Markovian bandit model without
loss of optimality in the order. Moreover, comparision between Anantharam's
index policy and UCB shows that by choosing a small exploration parameter UCB
can have a smaller regret than Anantharam's index policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2255</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2255</id><created>2010-07-14</created><authors><author><keyname>Restrepo</keyname><forenames>Ricardo</forenames></author><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author><author><keyname>Vera</keyname><forenames>Juan C.</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author><author><keyname>Yang</keyname><forenames>Linji</forenames></author></authors><title>Phase Transition for Glauber Dynamics for Independent Sets on Regular
  Trees</title><categories>math.PR cs.DM</categories><msc-class>60J10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the effect of boundary conditions on the relaxation time of the
Glauber dynamics for the hard-core model on the tree. The hard-core model is
defined on the set of independent sets weighted by a parameter $\lambda$,
called the activity. The Glauber dynamics is the Markov chain that updates a
randomly chosen vertex in each step. On the infinite tree with branching factor
$b$, the hard-core model can be equivalently defined as a broadcasting process
with a parameter $\omega$ which is the positive solution to
$\lambda=\omega(1+\omega)^b$, and vertices are occupied with probability
$\omega/(1+\omega)$ when their parent is unoccupied. This broadcasting process
undergoes a phase transition between the so-called reconstruction and
non-reconstruction regions at $\omega_r\approx \ln{b}/b$. Reconstruction has
been of considerable interest recently since it appears to be intimately
connected to the efficiency of local algorithms on locally tree-like graphs,
such as sparse random graphs. In this paper we show that the relaxation time of
the Glauber dynamics on regular $b$-ary trees $T_h$ of height $h$ and $n$
vertices, undergoes a phase transition around the reconstruction threshold. In
particular, we construct a boundary condition for which the relaxation time
slows down at the reconstruction threshold. More precisely, for any $\omega \le
\ln{b}/b$, for $T_h$ with any boundary condition, the relaxation time is
$\Omega(n)$ and $O(n^{1+o_b(1)})$. In contrast, above the reconstruction
threshold we show that for every $\delta&gt;0$, for $\omega=(1+\delta)\ln{b}/b$,
the relaxation time on $T_h$ with any boundary condition is $O(n^{1+\delta +
o_b(1)})$, and we construct a boundary condition where the relaxation time is
$\Omega(n^{1+\delta/2 - o_b(1)})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2280</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2280</id><created>2010-07-14</created><authors><author><keyname>Zhang</keyname><forenames>Guoqiang</forenames></author><author><keyname>Quoitin</keyname><forenames>Bruno</forenames></author><author><keyname>Zhou</keyname><forenames>Shi</forenames></author></authors><title>Phase Changes in the Evolution of the IPv4 and IPv6 AS-Level Internet
  Topologies</title><categories>cs.NI</categories><comments>12 pages, 21 figures; G. Zhang et al.,Phase changes in the evolution
  of the IPv4 and IPv6 AS-Level Internet topologies, Comput. Commun. (2010)</comments><doi>10.1016/j.comcom.2010.06.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the evolution of the IPv4 and IPv6 Internet
topologies at the autonomous system (AS) level over a long period of time.We
provide abundant empirical evidence that there is a phase transition in the
growth trend of the two networks. For the IPv4 network, the phase change
occurred in 2001. Before then the network's size grew exponentially, and
thereafter it followed a linear growth. Changes are also observed around the
same time for the maximum node degree, the average node degree and the average
shortest path length. For the IPv6 network, the phase change occurred in late
2006. It is notable that the observed phase transitions in the two networks are
different, for example the size of IPv6 network initially grew linearly and
then shifted to an exponential growth. Our results show that following decades
of rapid expansion up to the beginning of this century, the IPv4 network has
now evolved into a mature, steady stage characterised by a relatively slow
growth with a stable network structure; whereas the IPv6 network, after a slow
startup process, has just taken off to a full speed growth. We also provide
insight into the possible impact of IPv6-over-IPv4 tunneling deployment scheme
on the evolution of the IPv6 network. The Internet topology generators so far
are based on an inexplicit assumption that the evolution of Internet follows
non-changing dynamic mechanisms. This assumption, however, is invalidated by
our results.Our work reveals insights into the Internet evolution and provides
inputs to future AS-Level Internet models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2282</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2282</id><created>2010-07-14</created><authors><author><keyname>Basavaraju</keyname><forenames>Manu</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author></authors><title>Acyclic Edge Coloring of Triangle Free Planar Graphs</title><categories>cs.DM</categories><comments>16 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $acyclic$ edge coloring of a graph is a proper edge coloring such that
there are no bichromatic cycles. The \emph{acyclic chromatic index} of a graph
is the minimum number k such that there is an acyclic edge coloring using k
colors and is denoted by $a'(G)$. It was conjectured by Alon, Sudakov and Zaks
(and much earlier by Fiamcik) that $a'(G)\le \Delta+2$, where $\Delta
=\Delta(G)$ denotes the maximum degree of the graph.
  If every induced subgraph $H$ of $G$ satisfies the condition $\vert E(H)
\vert \le 2\vert V(H) \vert -1$, we say that the graph $G$ satisfies $Property\
A$. In this paper, we prove that if $G$ satisfies $Property\ A$, then $a'(G)\le
\Delta + 3$. Triangle free planar graphs satisfy $Property\ A$. We infer that
$a'(G)\le \Delta + 3$, if $G$ is a triangle free planar graph. Another class of
graph which satisfies $Property\ A$ is 2-fold graphs (union of two forests).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2315</identifier>
 <datestamp>2011-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2315</id><created>2010-07-14</created><updated>2011-09-22</updated><authors><author><keyname>Bogdanov</keyname><forenames>Andrej</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>On extracting common random bits from correlated sources</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose Alice and Bob receive strings of unbiased independent but noisy bits
from some random source. They wish to use their respective strings to extract a
common sequence of random bits with high probability but without communicating.
How many such bits can they extract? The trivial strategy of outputting the
first $k$ bits yields an agreement probability of $(1 - \eps)^k &lt;
2^{-1.44k\eps}$, where $\eps$ is the amount of noise. We show that no strategy
can achieve agreement probability better than $2^{-k\eps/(1 - \eps)}$.
  On the other hand, we show that when $k \geq 10 + 2 (1 - \eps) / \eps$, there
exists a strategy which achieves an agreement probability of $0.1
(k\eps)^{-1/2} \cdot 2^{-k\eps/(1 - \eps)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2316</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2316</id><created>2010-07-14</created><authors><author><keyname>Detti</keyname><forenames>Paolo</forenames></author><author><keyname>Moretti</keyname><forenames>Marco</forenames></author><author><keyname>Abrardo</keyname><forenames>Andrea</forenames></author></authors><title>Radio resource allocation in OFDMA multi-cell networks</title><categories>math.OC cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of allocating users to radio resources (i.e.,
subcarriers) in the downlink of an OFDMA cellular network is addressed. We
consider a multi-cellular environment with a realistic interference model and a
margin adaptive approach, i.e., we aim at minimizing total transmission power
while maintaining a certain given rate for each user.
  The computational complexity issues of the resulting model is discussed and
proving that the problem is NP-hard in the strong sense. Heuristic approaches,
based on network flow models, that finds optima under suitable conditions, or
&quot;reasonably good&quot; solutions in the general case are presented. Computational
experiences show that, in a comparison with a commercial state-of-the-art
optimization solver, the proposed algorithms are effective in terms of solution
quality and CPU times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2327</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2327</id><created>2010-07-14</created><updated>2010-07-22</updated><authors><author><keyname>Cuevas</keyname><forenames>Ruben</forenames></author><author><keyname>Kryczka</keyname><forenames>Michal</forenames></author><author><keyname>Cuevas</keyname><forenames>Angel</forenames></author><author><keyname>Kaune</keyname><forenames>Sebastian</forenames></author><author><keyname>Guerrero</keyname><forenames>Carmen</forenames></author><author><keyname>Rejaie</keyname><forenames>Reza</forenames></author></authors><title>Is Content Publishing in BitTorrent Altruistic or Profit-Driven</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BitTorrent is the most popular P2P content delivery application where
individual users share various type of content with tens of thousands of other
users. The growing popularity of BitTorrent is primarily due to the
availability of valuable content without any cost for the consumers. However,
apart from required resources, publishing (sharing) valuable (and often
copyrighted) content has serious legal implications for user who publish the
material (or publishers). This raises a question that whether (at least major)
content publishers behave in an altruistic fashion or have other incentives
such as financial. In this study, we identify the content publishers of more
than 55k torrents in 2 major BitTorrent portals and examine their behavior. We
demonstrate that a small fraction of publishers are responsible for 66% of
published content and 75% of the downloads. Our investigations reveal that
these major publishers respond to two different profiles. On one hand,
antipiracy agencies and malicious publishers publish a large amount of fake
files to protect copyrighted content and spread malware respectively. On the
other hand, content publishing in BitTorrent is largely driven by companies
with financial incentive. Therefore, if these companies lose their interest or
are unable to publish content, BitTorrent traffic/portals may disappear or at
least their associated traffic will significantly reduce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2353</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2353</id><created>2010-07-14</created><authors><author><keyname>Kurganskyy</keyname><forenames>Oleksiy</forenames></author><author><keyname>Potapov</keyname><forenames>Igor</forenames></author></authors><title>A measure of state transition of collective of stateless automata in
  discrete environment</title><categories>cs.FL cs.DC</categories><comments>13 pages, 3 figures</comments><msc-class>68Q10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a collective of interacting stateless automata in a discrete
geometric environment is considered as an integral automata-like computational
dynamic object. For such distributed on the environment object different
approaches to definition of the measure of state transition are possible. We
propose a geometric approach for defining what a state is.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2354</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2354</id><created>2010-07-14</created><updated>2011-08-16</updated><authors><author><keyname>Ayaz</keyname><forenames>Ula&#x15f;</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Nonuniform Sparse Recovery with Subgaussian Matrices</title><categories>cs.IT math.IT math.PR</categories><msc-class>15B52, 94A20, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing predicts that sufficiently sparse vectors can be
recovered from highly incomplete information. Efficient recovery methods such
as $\ell_1$-minimization find the sparsest solution to certain systems of
equations. Random matrices have become a popular choice for the measurement
matrix. Indeed, near-optimal uniform recovery results have been shown for such
matrices. In this note we focus on nonuniform recovery using Gaussian random
matrices and $\ell_1$-minimization. We provide a condition on the number of
samples in terms of the sparsity and the signal length which guarantees that a
fixed sparse signal can be recovered with a random draw of the matrix using
$\ell_1$-minimization. The constant 2 in the condition is optimal, and the
proof is rather short compared to a similar result due to Donoho and Tanner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2364</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2364</id><created>2010-07-14</created><authors><author><keyname>Bozzato</keyname><forenames>Loris</forenames><affiliation>DICOM - Universit&#xe0; degli Studi dell'Insubria</affiliation></author><author><keyname>Ferrari</keyname><forenames>Mauro</forenames><affiliation>DICOM - Universit&#xe0; degli Studi dell'Insubria</affiliation></author></authors><title>A Note on Semantic Web Services Specification and Composition in
  Constructive Description Logics</title><categories>cs.AI cs.LO</categories><comments>15 pages, 2 figures. Part of this work will appear as a position
  paper in Proceedings of 4th Int. Conf. on Web Reasoning and Rule Systems (RR
  2010)</comments><acm-class>I.2.4; F.4.1; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of the Semantic Web is to annotate Web content and services with
computer interpretable descriptions with the aim to automatize many tasks
currently performed by human users. In the context of Web services, one of the
most interesting tasks is their composition. In this paper we formalize this
problem in the framework of a constructive description logic. In particular we
propose a declarative service specification language and a calculus for service
composition. We show by means of an example how this calculus can be used to
define composed Web services and we discuss the problem of automatic service
synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2365</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2365</id><created>2010-07-14</created><authors><author><keyname>Byers</keyname><forenames>John</forenames></author><author><keyname>Heeringa</keyname><forenames>Brent</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Zervas</keyname><forenames>Georgios</forenames></author></authors><title>Heapable Sequences and Subsequences</title><categories>cs.DS</categories><comments>15 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let us call a sequence of numbers heapable if they can be sequentially
inserted to form a binary tree with the heap property, where each insertion
subsequent to the first occurs at a leaf of the tree, i.e. below a previously
placed number. In this paper we consider a variety of problems related to
heapable sequences and subsequences that do not appear to have been studied
previously. Our motivation for introducing these concepts is two-fold. First,
such problems correspond to natural extensions of the well-known secretary
problem for hiring an organization with a hierarchical structure. Second, from
a purely combinatorial perspective, our problems are interesting variations on
similar longest increasing subsequence problems, a problem paradigm that has
led to many deep mathematical connections.
  We provide several basic results. We obtain an efficient algorithm for
determining the heapability of a sequence, and also prove that the question of
whether a sequence can be arranged in a complete binary heap is NP-hard.
Regarding subsequences we show that, with high probability, the longest
heapable subsequence of a random permutation of n numbers has length (1 - o(1))
n, and a subsequence of length (1 - o(1)) n can in fact be found online with
high probability. We similarly show that for a random permutation a subsequence
that yields a complete heap of size \alpha n for a constant \alpha can be found
with high probability. Our work highlights the interesting structure underlying
this class of subsequence problems, and we leave many further interesting
variations open for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2377</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2377</id><created>2010-07-14</created><updated>2011-05-20</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author><author><keyname>Harmany</keyname><forenames>Zachary</forenames></author><author><keyname>Marcia</keyname><forenames>Roummel</forenames></author><author><keyname>Willett</keyname><forenames>Rebecca</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Performance bounds for expander-based compressed sensing in Poisson
  noise</title><categories>cs.IT math.IT</categories><comments>revised version; accepted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2011.2157913</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides performance bounds for compressed sensing in the presence
of Poisson noise using expander graphs. The Poisson noise model is appropriate
for a variety of applications, including low-light imaging and digital
streaming, where the signal-independent and/or bounded noise models used in the
compressed sensing literature are no longer applicable. In this paper, we
develop a novel sensing paradigm based on expander graphs and propose a MAP
algorithm for recovering sparse or compressible signals from Poisson
observations. The geometry of the expander graphs and the positivity of the
corresponding sensing matrices play a crucial role in establishing the bounds
on the signal reconstruction error of the proposed algorithm. We support our
results with experimental demonstrations of reconstructing average packet
arrival rates and instantaneous packet counts at a router in a communication
network, where the arrivals of packets in each flow follow a Poisson process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2381</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2381</id><created>2010-07-14</created><authors><author><keyname>Radu</keyname><forenames>Gramatovici</forenames></author><author><keyname>Ionut</keyname><forenames>Tutu</forenames></author></authors><title>A methodological approach on the architectural development of integrated
  e-learning systems</title><categories>cs.SE</categories><comments>13 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a methodological approach to the development of
integrated e-learning systems that is used in the creation of educational
content for standard Learning Management Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2401</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2401</id><created>2010-07-14</created><updated>2010-11-29</updated><authors><author><keyname>Gaston</keyname><forenames>Bernat</forenames></author><author><keyname>Pujol</keyname><forenames>Jaume</forenames></author></authors><title>Double Circulant Minimum Storage Regenerating Codes</title><categories>cs.DC cs.IT cs.NI math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A newer version will appear soon
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2442</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2442</id><created>2010-07-14</created><authors><author><keyname>Johnson</keyname><forenames>Kyle</forenames></author><author><keyname>Chang</keyname><forenames>Clayton</forenames></author><author><keyname>Lipson</keyname><forenames>Hod</forenames></author></authors><title>Neural Network Based Reconstruction of a 3D Object from a 2D Wireframe</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach for constructing a 3D representation from a 2D
wireframe drawing. A drawing is simply a parallel projection of a 3D object
onto a 2D surface; humans are able to recreate mental 3D models from 2D
representations very easily, yet the process is very difficult to emulate
computationally. We hypothesize that our ability to perform this construction
relies on the angles in the 2D scene, among other geometric properties. Being
able to reproduce this reconstruction process automatically would allow for
efficient and robust 3D sketch interfaces. Our research focuses on the
relationship between 2D geometry observable in the sketch and 3D geometry
derived from a potential 3D construction. We present a fully automated system
that constructs 3D representations from 2D wireframes using a neural network in
conjunction with a genetic search algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2449</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2449</id><created>2010-07-14</created><authors><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author></authors><title>A Brief Introduction to Temporality and Causality</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causality is a non-obvious concept that is often considered to be related to
temporality. In this paper we present a number of past and present approaches
to the definition of temporality and causality from philosophical, physical,
and computational points of view. We note that time is an important ingredient
in many relationships and phenomena. The topic is then divided into the two
main areas of temporal discovery, which is concerned with finding relations
that are stretched over time, and causal discovery, where a claim is made as to
the causal influence of certain events on others. We present a number of
computational tools used for attempting to automatically discover temporal and
causal relations in data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2452</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2452</id><created>2010-07-14</created><updated>2015-06-08</updated><authors><author><keyname>Amini</keyname><forenames>Omid</forenames></author><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames></author><author><keyname>Memari</keyname><forenames>Pooran</forenames></author></authors><title>Geometric Tomography With Topological Guarantees</title><categories>cs.CG math.GN</categories><comments>32 Pages, 21 Figure; appeared in Discrete &amp; Computational Geometry:
  Volume 50, Issue 4, Page 821-856, 2013. Extended abstract appeared in the
  proceedings of the 26th Symposium on Computational Geometry 2010</comments><journal-ref>Discrete &amp; Computational Geometry: Volume 50, Issue 4, Page
  821-856, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstructing a compact 3-manifold (with
boundary) embedded in $\mathbb{R}^3$ from its cross-sections $\mathcal S$ with
a given set of cutting planes $\mathcal P$ having arbitrary orientations. Using
the obvious fact that a point $x \in \mathcal P$ belongs to the original object
if and only if it belongs to $\mathcal S$, we follow a very natural
reconstruction strategy: we say that a point $x \in \mathbb{R}^3$ belongs to
the reconstructed object if (at least one of) its nearest point(s) in $\mathcal
P$ belongs to $\mathcal S$. This coincides with the algorithm presented by Liu
et al. in \cite{LB+08}. In the present paper, we prove that under appropriate
sampling conditions, the output of this algorithm preserves the homotopy type
of the original object. Using the homotopy equivalence, we also show that the
reconstructed object is homeomorphic (and isotopic) to the original object.
This is the first time that 3-dimensional shape reconstruction from
cross-sections comes with theoretical guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2460</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2460</id><created>2010-07-14</created><updated>2011-06-29</updated><authors><author><keyname>Fukuda</keyname><forenames>Hiroshi</forenames></author><author><keyname>Kanomata</keyname><forenames>Chiaki</forenames></author><author><keyname>Mutoh</keyname><forenames>Nobuaki</forenames></author><author><keyname>Nakamura</keyname><forenames>Gisaku</forenames></author><author><keyname>Schattschneider</keyname><forenames>Doris</forenames></author></authors><title>Polyominoes and Polyiamonds as Fundamental Domains of Isohedral Tilings
  with Rotational Symmetry</title><categories>cs.CG cs.DM</categories><journal-ref>Symmetry 2011, 3(4), 828-851</journal-ref><doi>10.3390/sym3040828</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe computer algorithms that produce the complete set of isohedral
tilings by n-omino or n-iamond tiles in which the tiles are fundamental domains
and the tilings have 3-, 4-, or 6-fold rotational symmetry. The symmetry groups
of such tilings are of types p3, p31m, p4, p4g, and p6. There are no isohedral
tilings with symmetry groups p3m1, p4m, or p6m that have polyominoes or
polyiamonds as fundamental domains. We display the algorithms' output and give
enumeration tables for small values of n. This expands on our earlier works
(Fukuda et al 2006, 2008).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2484</identifier>
 <datestamp>2012-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2484</id><created>2010-07-15</created><updated>2011-01-30</updated><authors><author><keyname>Bernardi</keyname><forenames>Olivier</forenames><affiliation>MIT</affiliation></author><author><keyname>Fusy</keyname><forenames>Eric</forenames><affiliation>LIX</affiliation></author></authors><title>Schnyder decompositions for regular plane graphs and application to
  drawing</title><categories>math.CO cs.DM cs.DS</categories><proxy>ccsd</proxy><journal-ref>Algorithmica 62 (2012) pp 1159-1197</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schnyder woods are decompositions of simple triangulations into three
edge-disjoint spanning trees crossing each other in a specific way. In this
article, we define a generalization of Schnyder woods to $d$-angulations (plane
graphs with faces of degree $d$) for all $d\geq 3$. A \emph{Schnyder
decomposition} is a set of $d$ spanning forests crossing each other in a
specific way, and such that each internal edge is part of exactly $d-2$ of the
spanning forests. We show that a Schnyder decomposition exists if and only if
the girth of the $d$-angulation is $d$. As in the case of Schnyder woods
($d=3$), there are alternative formulations in terms of orientations
(&quot;fractional&quot; orientations when $d\geq 5$) and in terms of corner-labellings.
Moreover, the set of Schnyder decompositions on a fixed $d$-angulation of girth
$d$ is a distributive lattice. We also show that the structures dual to
Schnyder decompositions (on $d$-regular plane graphs of mincut $d$ rooted at a
vertex $v^*$) are decompositions into $d$ spanning trees rooted at $v^*$ such
that each edge not incident to $v^*$ is used in opposite directions by two
trees. Additionally, for even values of $d$, we show that a subclass of
Schnyder decompositions, which are called even, enjoy additional properties
that yield a reduced formulation; in the case d=4, these correspond to
well-studied structures on simple quadrangulations (2-orientations and
partitions into 2 spanning trees). In the case d=4, the dual of even Schnyder
decompositions yields (planar) orthogonal and straight-line drawing algorithms.
For a 4-regular plane graph $G$ of mincut 4 with $n$ vertices plus a marked
vertex $v$, the vertices of $G\backslash v$ are placed on a $(n-1) \times
(n-1)$ grid according to a permutation pattern, and in the orthogonal drawing
each of the $2n-2$ edges of $G\backslash v$ has exactly one bend. Embedding
also the marked vertex $v$ is doable at the cost of two additional rows and
columns and 8 additional bends for the 4 edges incident to $v$. We propose a
further compaction step for the drawing algorithm and show that the obtained
grid-size is strongly concentrated around $25n/32\times 25n/32$ for a uniformly
random instance with $n$ vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2503</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2503</id><created>2010-07-15</created><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Gamzu</keyname><forenames>Iftah</forenames></author></authors><title>Ranking with Submodular Valuations</title><categories>cs.DS</categories><comments>16 pages, 3 figures</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of ranking with submodular valuations. An instance of
this problem consists of a ground set $[m]$, and a collection of $n$ monotone
submodular set functions $f^1, \ldots, f^n$, where each $f^i: 2^{[m]} \to R_+$.
An additional ingredient of the input is a weight vector $w \in R_+^n$. The
objective is to find a linear ordering of the ground set elements that
minimizes the weighted cover time of the functions. The cover time of a
function is the minimal number of elements in the prefix of the linear ordering
that form a set whose corresponding function value is greater than a unit
threshold value.
  Our main contribution is an $O(\ln(1 / \epsilon))$-approximation algorithm
for the problem, where $\epsilon$ is the smallest non-zero marginal value that
any function may gain from some element. Our algorithm orders the elements
using an adaptive residual updates scheme, which may be of independent
interest. We also prove that the problem is $\Omega(\ln(1 / \epsilon))$-hard to
approximate, unless P = NP. This implies that the outcome of our algorithm is
optimal up to constant factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2534</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2534</id><created>2010-07-15</created><updated>2012-03-08</updated><authors><author><keyname>Camps</keyname><forenames>Rosa</forenames></author><author><keyname>Mora</keyname><forenames>Xavier</forenames></author><author><keyname>Saumell</keyname><forenames>Laia</forenames></author></authors><title>A general method for deciding about logically constrained issues</title><categories>cs.AI</categories><comments>Several substantial improvements have been included. The outline
  structure of the article has also undergone some changes</comments><msc-class>03B42, 68T37, 91B06, 91B14, 91C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general method is given for revising degrees of belief and arriving at
consistent decisions about a system of logically constrained issues. In
contrast to other works about belief revision, here the constraints are assumed
to be fixed. The method has two variants, dual of each other, whose revised
degrees of belief are respectively above and below the original ones. The upper
[resp. lower] revised degrees of belief are uniquely characterized as the
lowest [resp. highest] ones that are invariant by a certain max-min [resp.
min-max] operation determined by the logical constraints. In both variants,
making balance between the revised degree of belief of a proposition and that
of its negation leads to decisions that are ensured to be consistent with the
logical constraints. These decisions are ensured to agree with the majority
criterion as applied to the original degrees of belief whenever this gives a
consistent result. They are also also ensured to satisfy a property of respect
for unanimity about any particular issue, as well as a property of monotonicity
with respect to the original degrees of belief. The application of the method
to certain special domains comes down to well established or increasingly
accepted methods, such as the single-link method of cluster analysis and the
method of paths in preferential voting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2584</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2584</id><created>2010-07-15</created><updated>2013-11-14</updated><authors><author><keyname>Feng</keyname><forenames>Yuan</forenames></author><author><keyname>Duan</keyname><forenames>Runyao</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Bisimulation for quantum processes</title><categories>quant-ph cs.LO</categories><comments>Journal version</comments><acm-class>D.3.1; F.3.1</acm-class><journal-ref>ACM Transactions on Programming Languages and Systems 2012,
  vol.34(4), no.17</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel notion of probabilistic bisimulation for
quantum processes and prove that it is congruent with respect to various
process algebra combinators including parallel composition even when both
classical and quantum communications are present. We also establish some basic
algebraic laws for this bisimulation. In particular, we prove uniqueness of the
solutions to recursive equations of quantum processes, which provides a
powerful proof technique for verifying complex quantum protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2618</identifier>
 <datestamp>2012-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2618</id><created>2010-07-15</created><updated>2012-03-13</updated><authors><author><keyname>Fu</keyname><forenames>Bin</forenames></author><author><keyname>Fu</keyname><forenames>Yunhui</forenames></author></authors><title>Sublinear Time Motif Discovery from Multiple Sequences</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural probabilistic model for motif discovery has been used to
experimentally test the quality of motif discovery programs. In this model,
there are $k$ background sequences, and each character in a background sequence
is a random character from an alphabet $\Sigma$. A motif $G=g_1g_2...g_m$ is a
string of $m$ characters. Each background sequence is implanted a
probabilistically generated approximate copy of $G$. For a probabilistically
generated approximate copy $b_1b_2...b_m$ of $G$, every character $b_i$ is
probabilistically generated such that the probability for $b_i\neq g_i$ is at
most $\alpha$. We develop three algorithms that under the probabilistic model
can find the implanted motif with high probability via a tradeoff between
computational time and the probability of mutation. The methods developed in
this paper have been used in the software implementation. We observed some
encouraging results that show improved performance for motif detection compared
with other softwares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2671</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2671</id><created>2010-07-15</created><authors><author><keyname>Chebotko</keyname><forenames>Artem</forenames></author><author><keyname>Fu</keyname><forenames>Bin</forenames></author></authors><title>XML Reconstruction View Selection in XML Databases: Complexity Analysis
  and Approximation Scheme</title><categories>cs.DS</categories><doi>10.1007/978-3-642-17461-2_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Query evaluation in an XML database requires reconstructing XML subtrees
rooted at nodes found by an XML query. Since XML subtree reconstruction can be
expensive, one approach to improve query response time is to use reconstruction
views - materialized XML subtrees of an XML document, whose nodes are
frequently accessed by XML queries. For this approach to be efficient, the
principal requirement is a framework for view selection. In this work, we are
the first to formalize and study the problem of XML reconstruction view
selection. The input is a tree $T$, in which every node $i$ has a size $c_i$
and profit $p_i$, and the size limitation $C$. The target is to find a subset
of subtrees rooted at nodes $i_1,\cdots, i_k$ respectively such that
$c_{i_1}+\cdots +c_{i_k}\le C$, and $p_{i_1}+\cdots +p_{i_k}$ is maximal.
Furthermore, there is no overlap between any two subtrees selected in the
solution. We prove that this problem is NP-hard and present a fully
polynomial-time approximation scheme (FPTAS) as a solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2673</identifier>
 <datestamp>2010-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2673</id><created>2010-07-15</created><authors><author><keyname>Chen</keyname><forenames>Zhixiang</forenames></author><author><keyname>Fu</keyname><forenames>Bin</forenames></author></authors><title>The Complexity of Testing Monomials in Multivariate Polynomials</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work in this paper is to initiate a theory of testing monomials in
multivariate polynomials. The central question is to ask whether a polynomial
represented by certain economically compact structure has a multilinear
monomial in its sum-product expansion. The complexity aspects of this problem
and its variants are investigated with two folds of objectives. One is to
understand how this problem relates to critical problems in complexity, and if
so to what extent. The other is to exploit possibilities of applying algebraic
properties of polynomials to the study of those problems. A series of results
about $\Pi\Sigma\Pi$ and $\Pi\Sigma$ polynomials are obtained in this paper,
laying a basis for further study along this line.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2675</identifier>
 <datestamp>2010-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2675</id><created>2010-07-15</created><authors><author><keyname>Chen</keyname><forenames>Zhixiang</forenames></author><author><keyname>Fu</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Schweller</keyname><forenames>Robert</forenames></author></authors><title>Algorithms for Testing Monomials in Multivariate Polynomials</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is our second step towards developing a theory of testing
monomials in multivariate polynomials. The central question is to ask whether a
polynomial represented by an arithmetic circuit has some types of monomials in
its sum-product expansion. The complexity aspects of this problem and its
variants have been investigated in our first paper by Chen and Fu (2010),
laying a foundation for further study. In this paper, we present two pairs of
algorithms. First, we prove that there is a randomized $O^*(p^k)$ time
algorithm for testing $p$-monomials in an $n$-variate polynomial of degree $k$
represented by an arithmetic circuit, while a deterministic $O^*(6.4^k + p^k)$
time algorithm is devised when the circuit is a formula, here $p$ is a given
prime number. Second, we present a deterministic $O^*(2^k)$ time algorithm for
testing multilinear monomials in $\Pi_m\Sigma_2\Pi_t\times \Pi_k\Pi_3$
polynomials, while a randomized $O^*(1.5^k)$ algorithm is given for these
polynomials. The first algorithm extends the recent work by Koutis (2008) and
Williams (2009) on testing multilinear monomials. Group algebra is exploited in
the algorithm designs, in corporation with the randomized polynomial identity
testing over a finite field by Agrawal and Biswas (2003), the deterministic
noncommunicative polynomial identity testing by Raz and Shpilka (2005) and the
perfect hashing functions by Chen {\em at el.} (2007). Finally, we prove that
testing some special types of multilinear monomial is W[1]-hard, giving
evidence that testing for specific monomials is not fixed-parameter tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2678</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2678</id><created>2010-07-15</created><authors><author><keyname>Chen</keyname><forenames>Zhixiang</forenames></author><author><keyname>Fu</keyname><forenames>Bin</forenames></author></authors><title>Approximating Multilinear Monomial Coefficients and Maximum Multilinear
  Monomials in Multivariate Polynomials</title><categories>cs.CC</categories><doi>10.1007/978-3-642-17458-2_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is our third step towards developing a theory of testing monomials
in multivariate polynomials and concentrates on two problems: (1) How to
compute the coefficients of multilinear monomials; and (2) how to find a
maximum multilinear monomial when the input is a $\Pi\Sigma\Pi$ polynomial. We
first prove that the first problem is \#P-hard and then devise a $O^*(3^ns(n))$
upper bound for this problem for any polynomial represented by an arithmetic
circuit of size $s(n)$. Later, this upper bound is improved to $O^*(2^n)$ for
$\Pi\Sigma\Pi$ polynomials. We then design fully polynomial-time randomized
approximation schemes for this problem for $\Pi\Sigma$ polynomials. On the
negative side, we prove that, even for $\Pi\Sigma\Pi$ polynomials with terms of
degree $\le 2$, the first problem cannot be approximated at all for any
approximation factor $\ge 1$, nor {\em &quot;weakly approximated&quot;} in a much relaxed
setting, unless P=NP. For the second problem, we first give a polynomial time
$\lambda$-approximation algorithm for $\Pi\Sigma\Pi$ polynomials with terms of
degrees no more a constant $\lambda \ge 2$. On the inapproximability side, we
give a $n^{(1-\epsilon)/2}$ lower bound, for any $\epsilon &gt;0,$ on the
approximation factor for $\Pi\Sigma\Pi$ polynomials. When terms in these
polynomials are constrained to degrees $\le 2$, we prove a $1.0476$ lower
bound, assuming $P\not=NP$; and a higher $1.0604$ lower bound, assuming the
Unique Games Conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2694</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2694</id><created>2010-07-16</created><updated>2011-12-09</updated><authors><author><keyname>Gopalakrishnan</keyname><forenames>Ragavendran</forenames></author><author><keyname>Kanoulas</keyname><forenames>Dimitrios</forenames></author><author><keyname>Karuturi</keyname><forenames>Naga Naresh</forenames></author><author><keyname>Rangan</keyname><forenames>C. Pandu</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author><author><keyname>Sundaram</keyname><forenames>Ravi</forenames></author></authors><title>Capacitated Caching Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by P2P networks and content delivery applications, we study
Capacitated Selfish Replication (CSR) games, which involve nodes on a network
making strategic choices regarding the content to replicate in their caches.
Selfish Replication games were introduced in [Chun et al, PODC2004}, who
analyzed the uncapacitated case leaving the capacitated version as an open
direction.
  In this work, we study pure Nash equilibria of CSR games with an emphasis on
hierarchical networks. Our main result is an exact polynomial-time algorithm
for finding a Nash Equilibrium in any hierarchical network using a new
technique which we term &quot;fictional players&quot;. We show that this technique
extends to a general framework of natural preference orders, orders that are
entirely arbitrary except for two natural constraints - &quot;Nearer is better&quot; and
&quot;Independence of irrelevant alternatives&quot;.
  Using our axiomatic framework, we next study CSR games on arbitrary networks
and delineate the boundary between intractability and effective computability
in terms of the network structure, object preferences, and the total number of
objects. We also show the existence of equilibria for general undirected
networks when either object preferences are binary or there are two objects.
For general CSR games, however, we show that it is NP-hard to determine whether
equilibria exist. We also show that the existence of equilibria in strongly
connected networks with two objects and binary object preferences can be
determined in polynomial time via a reduction to the well-studied even-cycle
problem. Finally, we introduce a fractional version of CSR games (F-SCR) with
application to content distribution using erasure codes. We show that while
every F-CSR game instance possesses an equilibrium, finding an equilibrium in
an F-CSR game is PPAD-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2707</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2707</id><created>2010-07-16</created><authors><author><keyname>Komenda</keyname><forenames>Jan</forenames></author><author><keyname>Masopust</keyname><forenames>Tomas</forenames></author><author><keyname>van Schuppen</keyname><forenames>Jan H.</forenames></author></authors><title>Supervisory Control Synthesis of Discrete-Event Systems using
  Coordination Scheme</title><categories>math.OC cs.FL</categories><comments>29 pages, 11 figures</comments><doi>10.1016/j.automatica.2011.07.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervisory control of discrete-event systems with a global safety
specification and with only local supervisors is a difficult problem. For
global specifications the equivalent conditions for local control synthesis to
equal global control synthesis may not be met. This paper formulates and solves
a control synthesis problem for a generator with a global specification and
with a combination of a coordinator and local controllers. Conditional
controllability is proven to be an equivalent condition for the existence of
such a coordinated controller. A procedure to compute the least restrictive
solution is also provided in this paper and conditions are stated under which
the result of our procedure coincides with the supremal controllable
sublanguage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2738</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2738</id><created>2010-07-16</created><updated>2011-04-16</updated><authors><author><keyname>Pasqualetti</keyname><forenames>Fabio</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Consensus Computation in Unreliable Networks: A System Theoretic
  Approach</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses the problem of ensuring trustworthy computation in a
linear consensus network. A solution to this problem is relevant for several
tasks in multi-agent systems including motion coordination, clock
synchronization, and cooperative estimation. In a linear consensus network, we
allow for the presence of misbehaving agents, whose behavior deviate from the
nominal consensus evolution. We model misbehaviors as unknown and unmeasurable
inputs affecting the network, and we cast the misbehavior detection and
identification problem into an unknown-input system theoretic framework. We
consider two extreme cases of misbehaving agents, namely faulty (non-colluding)
and malicious (Byzantine) agents. First, we characterize the set of inputs that
allow misbehaving agents to affect the consensus network while remaining
undetected and/or unidentified from certain observing agents. Second, we
provide worst-case bounds for the number of concurrent faulty or malicious
agents that can be detected and identified. Precisely, the consensus network
needs to be 2k+1 (resp. k+1) connected for k malicious (resp. faulty) agents to
be generically detectable and identifiable by every well behaving agent. Third,
we quantify the effect of undetectable inputs on the final consensus value.
Fourth, we design three algorithms to detect and identify misbehaving agents.
The first and the second algorithm apply fault detection techniques, and
affords complete detection and identification if global knowledge of the
network is available to each agent, at a high computational cost. The third
algorithm is designed to exploit the presence in the network of weakly
interconnected subparts, and provides local detection and identification of
misbehaving agents whose behavior deviates more than a threshold, which is
quantified in terms of the interconnection structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2754</identifier>
 <datestamp>2014-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2754</id><created>2010-07-16</created><updated>2011-10-18</updated><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author></authors><title>Relational Hidden Variables and Non-Locality</title><categories>quant-ph cs.LO math.LO</categories><comments>42 pages in journal style. To appear in Studia Logica</comments><journal-ref>Studia Logica April 2013, Volume 101, Issue 2, pp 411-452</journal-ref><doi>10.1007/s11225-013-9477-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a simple relational framework to develop the key notions and results
on hidden variables and non-locality. The extensive literature on these topics
in the foundations of quantum mechanics is couched in terms of probabilistic
models, and properties such as locality and no-signalling are formulated
probabilistically. We show that to a remarkable extent, the main structure of
the theory, through the major No-Go theorems and beyond, survives intact under
the replacement of probability distributions by mere relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2783</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2783</id><created>2010-07-16</created><updated>2010-09-01</updated><authors><author><keyname>Krcal</keyname><forenames>Pavel</forenames><affiliation>Uppsala University</affiliation></author><author><keyname>Abdulla</keyname><forenames>Parosh Aziz</forenames><affiliation>Uppsala University</affiliation></author><author><keyname>Yi</keyname><forenames>Wang</forenames><affiliation>Uppsala University</affiliation></author></authors><title>Sampled Semantics of Timed Automata</title><categories>cs.FL</categories><proxy>LMCS</proxy><acm-class>F.1.1, F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  1, 2010) lmcs:868</journal-ref><doi>10.2168/LMCS-6(3:14)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampled semantics of timed automata is a finite approximation of their dense
time behavior. While the former is closer to the actual software or hardware
systems with a fixed granularity of time, the abstract character of the latter
makes it appealing for system modeling and verification. We study one aspect of
the relation between these two semantics, namely checking whether the system
exhibits some qualitative (untimed) behaviors in the dense time which cannot be
reproduced by any implementation with a fixed sampling rate. More formally, the
\emph{sampling problem} is to decide whether there is a sampling rate such that
all qualitative behaviors (the untimed language) accepted by a given timed
automaton in dense time semantics can be also accepted in sampled semantics. We
show that this problem is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2814</identifier>
 <datestamp>2010-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2814</id><created>2010-07-16</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>A Unifying Framework for Local Throughput in Wireless Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increased competition for the electromagnetic spectrum, it is
important to characterize the impact of interference in the performance of a
wireless network, which is traditionally measured by its throughput. This paper
presents a unifying framework for characterizing the local throughput in
wireless networks. We first analyze the throughput of a probe link from a
connectivity perspective, in which a packet is successfully received if it does
not collide with other packets from nodes within its reach (called the audible
interferers). We then characterize the throughput from a
signal-to-interference-plus-noise ratio (SINR) perspective, in which a packet
is successfully received if the SINR exceeds some threshold, considering the
interference from all emitting nodes in the network. Our main contribution is
to generalize and unify various results scattered throughout the literature. In
particular, the proposed framework encompasses arbitrary wireless propagation
effects (e.g, Nakagami-m fading, Rician fading, or log-normal shadowing), as
well as arbitrary traffic patterns (e.g., slotted-synchronous,
slotted-asynchronous, or exponential-interarrivals traffic), allowing us to
draw more general conclusions about network performance than previously
available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2816</identifier>
 <datestamp>2014-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2816</id><created>2010-07-16</created><updated>2010-09-01</updated><authors><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Trichotomy and Dichotomy Results on the Complexity of Reasoning with
  Disjunctive Logic Programs</title><categories>cs.LO</categories><comments>24 pages To appear in Theory and Practice of Logic Programming (TPLP)</comments><acm-class>D.1.6</acm-class><journal-ref>Theory and Practice of Logic Programming, 11(6): 881-904 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present trichotomy results characterizing the complexity of reasoning with
disjunctive logic programs. To this end, we introduce a certain definition
schema for classes of programs based on a set of allowed arities of rules. We
show that each such class of programs has a finite representation, and for each
of the classes definable in the schema we characterize the complexity of the
existence of an answer set problem. Next, we derive similar characterizations
of the complexity of skeptical and credulous reasoning with disjunctive logic
programs. Such results are of potential interest. On the one hand, they reveal
some reasons responsible for the hardness of computing answer sets. On the
other hand, they identify classes of problem instances, for which the problem
is &quot;easy&quot; (in P) or &quot;easier than in general&quot; (in NP). We obtain similar results
for the complexity of reasoning with disjunctive programs under the
supported-model semantics. To appear in Theory and Practice of Logic
Programming (TPLP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2827</identifier>
 <datestamp>2010-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2827</id><created>2010-07-16</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Data processing theorems and the second law of thermodynamics</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>26 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We draw relationships between the generalized data processing theorems of
Zakai and Ziv (1973 and 1975) and the dynamical version of the second law of
thermodynamics, a.k.a. the Boltzmann H-Theorem, which asserts that the Shannon
entropy, $H(X_t)$, pertaining to a finite--state Markov process $\{X_t\}$, is
monotonically non-decreasing as a function of time $t$, provided that the
steady-state distribution of this process is uniform across the state space
(which is the case when the process designates an isolated system). It turns
out that both the generalized data processing theorems and the Boltzmann
H-Theorem can be viewed as special cases of a more general principle concerning
the monotonicity (in time) of a certain generalized information measure applied
to a Markov process. This gives rise to a new look at the generalized data
processing theorem, which suggests to exploit certain degrees of freedom that
may lead to better bounds, for a given choice of the convex function that
defines the generalized mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2855</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2855</id><created>2010-07-16</created><authors><author><keyname>Smith</keyname><forenames>Graeme</forenames></author></authors><title>Quantum Channel Capacities</title><categories>cs.IT math.IT quant-ph</categories><comments>This review of quantum channel capacities is the basis for my
  upcoming talk at ITW 2010 in Dublin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quantum communication channel can be put to many uses: it can transmit
classical information, private classical information, or quantum information.
It can be used alone, with shared entanglement, or together with other
channels. For each of these settings there is a capacity that quantifies a
channel's potential for communication. In this short review, I summarize what
is known about the various capacities of a quantum channel, including a
discussion of the relevant additivity questions. I also give some indication of
potentially interesting directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2876</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2876</id><created>2010-07-16</created><updated>2011-05-05</updated><authors><author><keyname>Lyons</keyname><forenames>Russell</forenames></author></authors><title>The Spread of Evidence-Poor Medicine via Flawed Social-Network Analysis</title><categories>stat.ME cs.SI physics.soc-ph</categories><comments>16 pp, 2 figures</comments><journal-ref>Statistics, Politics, and Policy: (2011) Vol. 2 : Iss. 1, Article
  2: http://www.bepress.com/spp/vol2/iss1/2</journal-ref><doi>10.2202/2151-7509.1024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chronic widespread misuse of statistics is usually inadvertent, not
intentional. We find cautionary examples in a series of recent papers by
Christakis and Fowler that advance statistical arguments for the transmission
via social networks of various personal characteristics, including obesity,
smoking cessation, happiness, and loneliness. Those papers also assert that
such influence extends to three degrees of separation in social networks. We
shall show that these conclusions do not follow from Christakis and Fowler's
statistical analyses. In fact, their studies even provide some evidence against
the existence of such transmission. The errors that we expose arose, in part,
because the assumptions behind the statistical procedures used were
insufficiently examined, not only by the authors, but also by the reviewers.
Our examples are instructive because the practitioners are highly reputed,
their results have received enormous popular attention, and the journals that
published their studies are among the most respected in the world. An
educational bonus emerges from the difficulty we report in getting our critique
published. We discuss the relevance of this episode to understanding
statistical literacy and the role of scientific review, as well as to reforming
statistics education.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2885</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2885</id><created>2010-07-16</created><updated>2011-04-11</updated><authors><author><keyname>Megacz</keyname><forenames>Adam</forenames></author></authors><title>Multi-Level Languages are Generalized Arrows</title><categories>cs.PL math.CT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-level languages and Arrows both facilitate metaprogramming, the act of
writing a program which generates a program. The arr function required of all
Arrows turns arbitrary host language expressions into guest language
expressions; because of this, Arrows may be used for metaprogramming only when
the guest language is a superset of the host language. This restriction is also
present in multi-level languages which offer unlimited cross-level persistence.
&lt;p&gt; This paper introduces generalized arrows and proves that they generalize
Arrows in the following sense: every Arrow in a programming language arises
from a generalized arrow with that language's term category as its codomain.
Generalized arrows impose no containment relationship between the guest
language and host language; they facilitate heterogeneous metaprogramming. The
category having all generalized arrows as its morphisms and the category having
all multi-level languages as its morphisms are isomorphic categories. This is
proven formally in Coq, and the proof is offered as justification for the
assertion that multi-level languages are generalized arrows. &lt;p&gt; Combined with
the existence of a particular kind of retraction in the host language, this
proof can be used to define an invertible translation from two-level terms to
one-level terms parameterized by a generalized arrow instance. This is
ergonomically significant: it lets guest language providers write generalized
arrow instances while the users of those guest languages write multi-level
terms. This is beneficial because implementing a generalized arrow instance is
easier than modifying a compiler, whereas writing two-level terms is easier
than manipulating generalized arrow terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2899</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2899</id><created>2010-07-17</created><updated>2011-03-10</updated><authors><author><keyname>Nayak</keyname><forenames>Ashwin</forenames></author></authors><title>Inverting a permutation is as hard as unordered search</title><categories>quant-ph cs.CC</categories><comments>5 pages. Numerous changes to improve the presentation</comments><msc-class>68Q12, 68Q17, 81P68, 68Q15, 68Q25</msc-class><acm-class>F.2.2; F.1.3; F.1.2</acm-class><journal-ref>Theory of Computing 7(1):19--25, 2011</journal-ref><doi>10.4086/toc.2011.v007a002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how an algorithm for the problem of inverting a permutation may be
used to design one for the problem of unordered search (with a unique
solution). Since there is a straightforward reduction in the reverse direction,
the problems are essentially equivalent.
  The reduction we present helps us bypass the hybrid argument due to Bennett,
Bernstein, Brassard, and Vazirani (1997) and the quantum adversary method due
to Ambainis (2002) that were earlier used to derive lower bounds on the quantum
query complexity of the problem of inverting permutations. It directly implies
that the quantum query complexity of the problem is asymptotically the same as
that for unordered search, namely in Theta(sqrt(n)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2902</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2902</id><created>2010-07-17</created><authors><author><keyname>Zhang</keyname><forenames>Guoqiang</forenames></author><author><keyname>Cheng</keyname><forenames>Suqi</forenames></author><author><keyname>Zhang</keyname><forenames>Guoqing</forenames></author></authors><title>LANC: locality-aware network coding for better P2P traffic localization</title><categories>cs.DC</categories><comments>13 pages, 18 figures This paper has been submitted to Computer
  Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As ISPs begin to cooperate to expose their network locality information as
services, e.g., P4P, solutions based on locality information provision for P2P
traffic localization will soon approach their capability limits. A natural
question is: can we do any better provided that no further locality information
improvement can be made? This paper shows how the utility of locality
information could be limited by conventional P2P data scheduling algorithms,
even as sophisticated as the local rarest first policy.
  Network coding's simplified data scheduling makes it competent for improving
P2P application's throughput. Instead of only using locality information in the
topology construction, this paper proposes the locality-aware network coding
(LANC) that uses locality information in both the topology construction and
downloading decision, and demonstrates its exceptional ability for P2P traffic
localization. The randomization introduced by network coding enhances the
chance for a peer to find innovative blocks in its neighborhood. Aided by
proper locality-awareness, the probability for a peer to get innovative blocks
from its proximity will increase as well, resulting in more efficient use of
network resources. Extensive simulation results show that LANC can
significantly reduce P2P traffic redundancy without sacrificing
application-level performance. Aided by the same locality knowledge, the
traffic redundancies of LANC in most cases are less than 50\% of the current
best approach that does not use network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2924</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2924</id><created>2010-07-17</created><updated>2012-01-05</updated><authors><author><keyname>Thomas</keyname><forenames>Michael</forenames></author></authors><title>On the Applicability of Post's Lattice</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For decision problems P defined over Boolean circuits from a restricted set
of gates, we have that P(B) AC0 many-one reduces to P(B') for all finite sets B
and B' of gates such that all gates from B can be computed by circuits over
gates from B'. In this paper, we show that a weaker version of this statement
holds for decision problems defined over Boolean formulae, namely that P(B) NC2
many-one reduces to P(B' union {and,or}) and that P(B) NC2 many-one reduces to
P(B' union {false,true}), for all finite sets B and B' of Boolean functions
such that all f in B can be defined in B'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2928</identifier>
 <datestamp>2013-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2928</id><created>2010-07-17</created><updated>2013-04-18</updated><authors><author><keyname>Song</keyname><forenames>Wentu</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Feng</keyname><forenames>Rongquan</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>Encoding Complexity of Network Coding with Two Simple Multicast Sessions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The encoding complexity of network coding for single multicast networks has
been intensively studied from several aspects: e.g., the time complexity, the
required number of encoding links, and the required field size for a linear
code solution. However, these issues as well as the solvability are less
understood for networks with multiple multicast sessions. Recently, Wang and
Shroff showed that the solvability of networks with two unit-rate multicast
sessions (2-URMS) can be decided in polynomial time. In this paper, we prove
that for the 2-URMS networks: $1)$ the solvability can be determined with time
$O(|E|)$; $2)$ a solution can be constructed with time $O(|E|)$; $3)$ an
optimal solution can be obtained in polynomial time; $4)$ the number of
encoding links required to achieve a solution is upper-bounded by
$\max\{3,2N-2\}$; and $5)$ the field size required to achieve a linear solution
is upper-bounded by $\max\{2,\lfloor\sqrt{2N-7/4}+1/2\rfloor\}$, where $|E|$ is
the number of links and $N$ is the number of sinks of the underlying network.
Both bounds are shown to be tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2945</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2945</id><created>2010-07-17</created><authors><author><keyname>Tyagi</keyname><forenames>Himanshu</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author></authors><title>When is a Function Securely Computable?</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset of a set of terminals that observe correlated signals seek to
compute a given function of the signals using public communication. It is
required that the value of the function be kept secret from an eavesdropper
with access to the communication. We show that the function is securely
computable if and only if its entropy is less than the &quot;aided secret key&quot;
capacity of an associated secrecy generation model, for which a single-letter
characterization is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2958</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2958</id><created>2010-07-17</created><authors><author><keyname>Trinh</keyname><forenames>Hoang</forenames></author></authors><title>A Machine Learning Approach to Recovery of Scene Geometry from Images</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering the 3D structure of the scene from images yields useful
information for tasks such as shape and scene recognition, object detection, or
motion planning and object grasping in robotics. In this thesis, we introduce a
general machine learning approach called unsupervised CRF learning based on
maximizing the conditional likelihood. We apply our approach to computer vision
systems that recover the 3-D scene geometry from images. We focus on recovering
3D geometry from single images, stereo pairs and video sequences. Building
these systems requires algorithms for doing inference as well as learning the
parameters of conditional Markov random fields (MRF). Our system is trained
unsupervisedly without using ground-truth labeled data. We employ a
slanted-plane stereo vision model in which we use a fixed over-segmentation to
segment the left image into coherent regions called superpixels, then assign a
disparity plane for each superpixel. Plane parameters are estimated by solving
an MRF labelling problem, through minimizing an energy fuction. We demonstrate
the use of our unsupervised CRF learning algorithm for a parameterized
slanted-plane stereo vision model involving shape from texture cues. Our stereo
model with texture cues, only by unsupervised training, outperforms the results
in related work on the same stereo dataset. In this thesis, we also formulate
structure and motion estimation as an energy minimization problem, in which the
model is an extension of our slanted-plane stereo vision model that also
handles surface velocity. Velocity estimation is achieved by solving an MRF
labeling problem using Loopy BP. Performance analysis is done using our novel
evaluation metrics based on the notion of view prediction error. Experiments on
road-driving stereo sequences show encouraging results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2980</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2980</id><created>2010-07-18</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author></authors><title>Publishing and Discovery of Mobile Web Services in Peer to Peer Networks</title><categories>cs.IR cs.NI</categories><comments>First International Workshop on Mobile Services and Personalized
  Environments (MSPE'06), November 16-17, 2006, pp. 15-28. Lecture Notes in
  Informatics, GI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now feasible to host Web Services on a mobile device due to the
advances in cellular devices and mobile communication technologies. However,
the reliability, usability and responsiveness of the Mobile Hosts depend on
various factors including the characteristics of available network,
computational resources, and better means of searching the services provided by
them. P2P enhances the adoption of Mobile Host in commercial environments.
Mobile Hosts in P2P can collaboratively share the resources of individual
peers. P2P also enhances the service discovery of huge number of Web Services
possible with Mobile Hosts. Advanced features like post filtering with weight
of keywords and context-awareness can also be exploited to select the best
possible mobile Web Service. This paper proposes the concept of Mobile Hosts in
P2P networks and identifies the means of publishing and discovery of Web
Services in mobile P2P networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2981</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2981</id><created>2010-07-18</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Jarke</keyname><forenames>Matthias</forenames></author><author><keyname>Prinz</keyname><forenames>Wolfgang</forenames></author></authors><title>A Mediation Framework for Mobile Web Service Provisioning</title><categories>cs.DC cs.NI</categories><comments>Proceedings of 2006 Middleware for Web Services (MWS 2006) Workshop @
  10th International IEEE EDOC Conference &quot;The Enterprise Computing
  Conference&quot;, October 16, 2006, pp. 14-17. IEEE Computer Society</comments><doi>10.1109/EDOCW.2006.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web Services and mobile data services are the newest trends in information
systems engineering in wired and wireless domains, respectively. Web Services
have a broad range of service distributions while mobile phones have large and
expanding user base. To address the confluence of Web Services and pervasive
mobile devices and communication environments, a basic mobile Web Service
provider was developed for smart phones. The performance of this Mobile Host
was also analyzed in detail. Further analysis of the Mobile Host to provide
proper QoS and to check Mobile Host's feasibility in the P2P networks,
identified the necessity of a mediation framework. The paper describes the
research conducted with the Mobile Host, identifies the tasks of the mediation
framework and then discusses the feasible realization details of such a mobile
Web Services mediation framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.2989</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.2989</id><created>2010-07-18</created><updated>2011-07-19</updated><authors><author><keyname>Figueira</keyname><forenames>Diego</forenames></author><author><keyname>Figueira</keyname><forenames>Santiago</forenames></author><author><keyname>Schmitz</keyname><forenames>Sylvain</forenames></author><author><keyname>Schnoebelen</keyname><forenames>Philippe</forenames></author></authors><title>Ackermannian and Primitive-Recursive Bounds with Dickson's Lemma</title><categories>cs.LO cs.CC</categories><acm-class>D.2.4; F.1.3; F.2; F.4.1; G.2.1</acm-class><journal-ref>In LICS 2011, 26th Annual IEEE Symposium on Logic in Computer
  Science, pages 269--278. IEEE Press</journal-ref><doi>10.1109/LICS.2011.39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dickson's Lemma is a simple yet powerful tool widely used in termination
proofs, especially when dealing with counters or related data structures.
However, most computer scientists do not know how to derive complexity upper
bounds from such termination proofs, and the existing literature is not very
helpful in these matters.
  We propose a new analysis of the length of bad sequences over (N^k,\leq) and
explain how one may derive complexity upper bounds from termination proofs. Our
upper bounds improve earlier results and are essentially tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3021</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3021</id><created>2010-07-18</created><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>The Roles of Advice to One-Tape Linear-Time Turing Machines and Finite
  Automata</title><categories>cs.FL cs.CC</categories><comments>A4, 10 pt, 16 pages, 1 figure. This is a complete version of the
  extended abstract, published in the Proceedings of the 20th International
  Symposium on Algorithms and Computation (ISAAC 2009), Lecture Notes in
  Computer Science, Springer-Verlag, Vol.5878, pp.933--942, December 16--18,
  Hawaii, USA, 2009</comments><journal-ref>International Journal of Foundations of Computer Science, Vol.21,
  pp.941-962, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the power and limitation of various &quot;advice,&quot; when it is given
particularly to weak computational models of one-tape linear-time Turing
machines and one-way finite (state) automata. Of various advice types, we
consider deterministically-chosen advice (not necessarily algorithmically
determined) and randomly-chosen advice (according to certain probability
distributions). In particular, we show that certain weak machines can be
significantly enhanced in computational power when randomized advice is
provided in place of deterministic advice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3023</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3023</id><created>2010-07-18</created><updated>2011-02-10</updated><authors><author><keyname>Obua</keyname><forenames>Steven</forenames></author></authors><title>Purely Functional Structured Programming</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of functional programming has played a big role in shaping today's
landscape of mainstream programming languages. Another concept that dominates
the current programming style is Dijkstra's structured programming. Both
concepts have been successfully married, for example in the programming
language Scala. This paper proposes how the same can be achieved for structured
programming and PURELY functional programming via the notion of LINEAR SCOPE.
One advantage of this proposal is that mainstream programmers can reap the
benefits of purely functional programming like easily exploitable parallelism
while using familiar structured programming syntax and without knowing concepts
like monads. A second advantage is that professional purely functional
programmers can often avoid hard to read functional code by using structured
programming syntax that is often easier to parse mentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3036</identifier>
 <datestamp>2013-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3036</id><created>2010-07-18</created><updated>2013-11-05</updated><authors><author><keyname>Adamczyk</keyname><forenames>Marek</forenames></author></authors><title>Greedy algorithm for stochastic matching is a 2-approximation</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications in online dating and kidney exchange, the
stochastic matching problem was introduced by Chen, Immorlica, Karlin, Mahdian
and Rudra (2009). They have proven a 4-approximation of a simple greedy
strategy, but conjectured that it is in fact a 2-approximation. In this paper
we confirm this hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3046</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3046</id><created>2010-07-18</created><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author></authors><title>Strongly Resilient Non-Interactive Key Predistribution For Hierarchical
  Networks</title><categories>cs.CR</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key establishment is the basic necessary tool in the network security, by
which pairs in the network can establish shared keys for protecting their
pairwise communications. There have been some key agreement or predistribution
schemes with the property that the key can be established without the
interaction (\cite{Blom84,BSHKY92,S97}). Recently the hierarchical cryptography
and the key management for hierarchical networks have been active topics(see
\cite{BBG05,GHKRRW08,GS02,HNZI02,HL02,Matt04}. ). Key agreement schemes for
hierarchical networks were presented in \cite{Matt04,GHKRRW08} which is based
on the Blom key predistribution scheme(Blom KPS, [1]) and pairing. In this
paper we introduce generalized Blom-Blundo et al key predistribution schemes.
These generalized Blom-Blundo et al key predistribution schemes have the same
security functionality as the Blom-Blundo et al KPS. However different and
random these KPSs can be used for various parts of the networks for enhancing
the resilience. We also presentkey predistribution schemes from a family
hyperelliptic curves. These key predistribution schemes from different random
curves can be used for various parts of hierarchical networks. Then the
non-interactive, identity-based and dynamic key predistributon scheme based on
this generalized Blom-Blundo et al KPSs and hyperelliptic curve KPSs for
hierarchical networks with the following properties are constructed.
1)$O(A_KU)$ storage at each node in the network where $U$ is the expansion
number and $A_K$ is the number of nodes at the $K$-th level of the hierarchical
network; 2)Strongly resilience to the compromising of arbitrary many leaf and
internal nodes; 3)Information theoretical security without random oracle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3058</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3058</id><created>2010-07-18</created><authors><author><keyname>Samara</keyname><forenames>Ghassan</forenames></author><author><keyname>Ramadas</keyname><forenames>Sureswaran</forenames></author><author><keyname>Al-Salihy</keyname><forenames>Wafaa A. H.</forenames></author></authors><title>Safety Message Power Transmission Control for Vehicular Ad hoc Networks</title><categories>cs.NI</categories><journal-ref>Journal of Computer Science 6 (10): 1027-1032, 2010 ISSN
  1549-3636, 2010 Science Publications</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular Ad hoc Networks (VANET) is one of the most challenging research
area in the field of Mobile Ad Hoc Networks. In this research we proposed a
dynamic power adjustment protocol that will be used for sending the periodical
safety message. (Beacon)based on the analysis of the channel status depending
on the channel congestion and the power used for transmission. The Beacon Power
Control (BPC) protocol first sensed and examined the percentage of the channel
congestion, the result obtained was used to adjust the transmission power for
the safety message to reach the optimal power. This will lead to decrease the
congestion in the channel and achieve good channel performance and beacon
dissemination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3075</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3075</id><created>2010-07-19</created><updated>2010-08-20</updated><authors><author><keyname>Tanbourgi</keyname><forenames>Ralph</forenames></author><author><keyname>J&#xe4;kel</keyname><forenames>Holger</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich K.</forenames></author></authors><title>Resolving the Connectivity-Throughput Trade-Off in Random Networks</title><categories>cs.IT math.IT</categories><comments>This Paper has been withdrawn by the authors. 18 pages, 5 figures</comments><report-no>1007.3075</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrepancy between the upper bound on throughput in wireless networks
and the throughput scaling in random networks which is also known as the
connectivity-throughput trade-off is analyzed. In a random network with
$\lambda$ nodes per unit area, throughput is found to scale by a factor of
$\sqrt{\log{\lambda}}$ worse compared to the upper bound which is due to the
uncertainty in the nodes' location. In the present model, nodes are assumed to
know their geographical location and to employ power control, which we
understand as an additional degree of freedom to improve network performance.
The expected throughput-progress and the expected packet delay normalized to
the one-hop progress are chosen as performance metrics. These metrics are
investigated for a nearest neighbor forwarding strategy, which benefits from
power control by reducing transmission power and, hence spatial contention. It
is shown that the connectivity-throughput trade-off can be resolved if nodes
employ a nearest neighbor forwarding strategy, achieving the upper bound on
throughput on average also in a random network while ensuring asymptotic
connectivity. In this case, the optimal throughput-delay scaling trade-off is
also achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3105</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3105</id><created>2010-07-19</created><authors><author><keyname>Li</keyname><forenames>Di</forenames></author><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Chen</keyname><forenames>Changhai</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>A Selection Region Based Routing Protocol for Random Mobile ad hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 8 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a selection region based multi-hop routing protocol for random
mobile ad hoc networks, where the selection region is defined by two
parameters: a reference distance and a selection angle. At each hop, a relay is
chosen as the nearest node to the transmitter that is located within the
selection region. By assuming that the relay nodes are randomly placed, we
derive an upper bound for the optimum reference distance to maximize the
expected density of progress and investigate the relationship between the
optimum selection angle and the optimum reference distance. We also note that
the optimized expected density of progress scales as $\Theta(\sqrt{\lambda})$,
which matches the prior results in the literature. Compared with the
spatial-reuse multi-hop protocol in \cite{Baccelli:Aloha} recently proposed by
Baccelli \emph{et al.}, in our new protocol the amount of nodes involved and
the calculation complexity for each relay selection are reduced significantly,
which is attractive for energy-limited wireless ad hoc networks (e.g., wireless
sensor networks).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3108</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3108</id><created>2010-07-19</created><updated>2011-05-11</updated><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author></authors><title>Second-Order Weight Distributions</title><categories>cs.IT math.IT</categories><comments>10 pages, accepted for publication in IEEE Transactions on
  Information Theory, May 2011</comments><journal-ref>IEEE Trans. Inf. Theory 57 (2011) 6068-6077</journal-ref><doi>10.1109/TIT.2011.2162272</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental property of codes, the second-order weight distribution, is
proposed to solve the problems such as computing second moments of weight
distributions of linear code ensembles. A series of results, parallel to those
for weight distributions, is established for second-order weight distributions.
In particular, an analogue of MacWilliams identities is proved. The
second-order weight distributions of regular LDPC code ensembles are then
computed. As easy consequences, the second moments of weight distributions of
regular LDPC code ensembles are obtained. Furthermore, the application of
second-order weight distributions in random coding approach is discussed. The
second-order weight distributions of the ensembles generated by a so-called
2-good random generator or parity-check matrix are computed, where a 2-good
random matrix is a kind of generalization of the uniformly distributed random
matrix over a finite filed and is very useful for solving problems that involve
pairwise or triple-wise properties of sequences. It is shown that the 2-good
property is reflected in the second-order weight distribution, which thus plays
a fundamental role in some well-known problems in coding theory and
combinatorics. An example of linear intersecting codes is finally provided to
illustrate this fact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3133</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3133</id><created>2010-07-19</created><authors><author><keyname>Hubert</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Jensen</keyname><forenames>Thomas</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Monfort</keyname><forenames>Vincent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Pichardie</keyname><forenames>David</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Enforcing Secure Object Initialization in Java</title><categories>cs.PL</categories><proxy>ccsd</proxy><journal-ref>15th European Symposium on Research in Computer Security (ESORICS)
  6345 (2010) 101-115</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sun and the CERT recommend for secure Java development to not allow partially
initialized objects to be accessed. The CERT considers the severity of the
risks taken by not following this recommendation as high. The solution
currently used to enforce object initialization is to implement a coding
pattern proposed by Sun, which is not formally checked. We propose a modular
type system to formally specify the initialization policy of libraries or
programs and a type checker to statically check at load time that all loaded
classes respect the policy. This allows to prove the absence of bugs which have
allowed some famous privilege escalations in Java. Our experimental results
show that our safe default policy allows to prove 91% of classes of java.lang,
java.security and javax.security safe without any annotation and by adding 57
simple annotations we proved all classes but four safe. The type system and its
soundness theorem have been formalized and machine checked using Coq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3157</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3157</id><created>2010-07-19</created><authors><author><keyname>Alexandris</keyname><forenames>John</forenames></author><author><keyname>Stavrakakis</keyname><forenames>Gregory Karagiorgos 'and' Ioannis</forenames></author></authors><title>Enhanced Random Walk with Choice: An Empirical Study</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random walk with choice is a well known variation to the random walk that
first selects a subset of $d$ neighbours nodes and then decides to move to the
node which maximizes the value of a certain metric; this metric captures the
number of (past) visits of the walk to the node. In this paper we propose an
enhancement to the random walk with choice by considering a new metric that
captures not only the actual visits to a given node, but also the intensity of
the visits to the neighbourhood of the node. We compare the random walk with
choice with its enhanced counterpart. Simulation results show a significant
improvement in cover time, maximum node load and load balancing, mainly in
random geometric graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3159</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3159</id><created>2010-07-19</created><authors><author><keyname>Gavanelli</keyname><forenames>Marco</forenames></author><author><keyname>Riguzzi</keyname><forenames>Fabrizio</forenames></author><author><keyname>Milano</keyname><forenames>Michela</forenames></author><author><keyname>Cagnoli</keyname><forenames>Paolo</forenames></author></authors><title>Logic-Based Decision Support for Strategic Environmental Assessment</title><categories>cs.AI</categories><comments>17 pages, 1 figure, 26th Int'l. Conference on Logic Programming
  (ICLP'10)</comments><acm-class>J.2; I.2.1; I.2.4; I.2.5</acm-class><journal-ref>Theory and Practice of Logic Programming, 26th Int'l. Conference
  on Logic Programming (ICLP'10) Special Issue, 10(4-6), 643-658, 2010</journal-ref><doi>10.1017/S1471068410000335</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Strategic Environmental Assessment is a procedure aimed at introducing
systematic assessment of the environmental effects of plans and programs. This
procedure is based on the so-called coaxial matrices that define dependencies
between plan activities (infrastructures, plants, resource extractions,
buildings, etc.) and positive and negative environmental impacts, and
dependencies between these impacts and environmental receptors. Up to now, this
procedure is manually implemented by environmental experts for checking the
environmental effects of a given plan or program, but it is never applied
during the plan/program construction. A decision support system, based on a
clear logic semantics, would be an invaluable tool not only in assessing a
single, already defined plan, but also during the planning process in order to
produce an optimized, environmentally assessed plan and to study possible
alternative scenarios. We propose two logic-based approaches to the problem,
one based on Constraint Logic Programming and one on Probabilistic Logic
Programming that could be, in the future, conveniently merged to exploit the
advantages of both. We test the proposed approaches on a real energy plan and
we discuss their limitations and advantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3181</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3181</id><created>2010-07-19</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>On Folding a Polygon to a Polyhedron</title><categories>cs.CG cs.DM</categories><comments>6 pages, 1 figure</comments><acm-class>F.2.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the open problem presented in &quot;Geometric Folding Algorithms:
Linkages, Origami, Polyhedra&quot; [DO07] is solved by a theorem of Burago and
Zalgaller [BZ96] from more than a decade earlier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3183</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3183</id><created>2010-07-19</created><authors><author><keyname>Hubert</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>A Non-Null Annotation Inferencer for Java Bytecode</title><categories>cs.PL</categories><proxy>ccsd</proxy><journal-ref>PASTE: Program analysis for software tools and engineering,
  Atlanta, Georgia : United States (2008)</journal-ref><doi>10.1145/1512475.1512484</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a non-null annotations inferencer for the Java bytecode language.
We previously proposed an analysis to infer non-null annotations and proved it
soundness and completeness with respect to a state of the art type system. This
paper proposes extensions to our former analysis in order to deal with the Java
bytecode language. We have implemented both analyses and compared their
behaviour on several benchmarks. The results show a substantial improvement in
the precision and, despite being a whole-program analysis, production
applications can be analyzed within minutes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3208</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3208</id><created>2010-07-19</created><authors><author><keyname>Kharitonov</keyname><forenames>Evgeny</forenames></author><author><keyname>Slesarev</keyname><forenames>Anton</forenames></author><author><keyname>Muchnik</keyname><forenames>Ilya</forenames></author><author><keyname>Romanenko</keyname><forenames>Fedor</forenames></author><author><keyname>Belyaev</keyname><forenames>Dmitry</forenames></author><author><keyname>Kotlyarov</keyname><forenames>Dmitry</forenames></author></authors><title>Link Graph Analysis for Adult Images Classification</title><categories>cs.IR</categories><comments>7 pages. Young Scientists Conference, 4th Russian Summer School in
  Information Retrieval</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to protect an image search engine's users from undesirable results
adult images' classifier should be built. The information about links from
websites to images is employed to create such a classifier. These links are
represented as a bipartite website-image graph. Each vertex is equipped with
scores of adultness and decentness. The scores for image vertexes are
initialized with zero, those for website vertexes are initialized according to
a text-based website classifier. An iterative algorithm that propagates scores
within a website-image graph is described. The scores obtained are used to
classify images by choosing an appropriate threshold. The experiments on
Internet-scale data have shown that the algorithm under consideration increases
classification recall by 17% in comparison with a simple algorithm which
classifies an image as adult if it is connected with at least one adult site
(at the same precision level).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3223</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3223</id><created>2010-07-19</created><authors><author><keyname>Brummayer</keyname><forenames>Robert</forenames></author><author><keyname>J&#xe4;rvisalo</keyname><forenames>Matti</forenames></author></authors><title>Testing and Debugging Techniques for Answer Set Solver Development</title><categories>cs.AI cs.SE</categories><comments>18 pages</comments><journal-ref>Theory and Practice of Logic Programming, 10(4-6):741-758, 2010</journal-ref><doi>10.1017/S1471068410000396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops automated testing and debugging techniques for answer set
solver development. We describe a flexible grammar-based black-box ASP fuzz
testing tool which is able to reveal various defects such as unsound and
incomplete behavior, i.e. invalid answer sets and inability to find existing
solutions, in state-of-the-art answer set solver implementations. Moreover, we
develop delta debugging techniques for shrinking failure-inducing inputs on
which solvers exhibit defective behavior. In particular, we develop a delta
debugging algorithm in the context of answer set solving, and evaluate two
different elimination strategies for the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3229</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3229</id><created>2010-07-19</created><updated>2011-02-20</updated><authors><author><keyname>BK</keyname><forenames>Pradeepa</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Aggregate Download Throughput for TCP-controlled long file transfers in
  a WLAN with multiple STA-AP association rates</title><categories>cs.NI</categories><comments>Double columns, 3 pages, 3 figures, typos updated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider several WLAN stations associated at rates r1, r2, ..., rk with an
Access Point. Each station is downloading a long file from a local server,
located on the LAN to which the AP is attached. We model these simultaneous
TCP-controlled transfers using a Markov Chain. Our analytical approach leads to
a procedure to compute aggregate download throughput numerically, and the
results match simulations very well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3244</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3244</id><created>2010-07-19</created><authors><author><keyname>Rubin</keyname><forenames>Natan</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>Improved Bounds for Geometric Permutations</title><categories>cs.CG</categories><comments>A preliminary version accepted to FOCS 2010</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the number of geometric permutations of an arbitrary collection
of $n$ pairwise disjoint convex sets in $\mathbb{R}^d$, for $d\geq 3$, is
$O(n^{2d-3}\log n)$, improving Wenger's 20 years old bound of $O(n^{2d-2})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3249</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3249</id><created>2010-07-19</created><updated>2010-07-20</updated><authors><author><keyname>Hubert</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Pichardie</keyname><forenames>David</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Soundly Handling Static Fields: Issues, Semantics and Analysis</title><categories>cs.PL</categories><comments>Proceedings of the Fourth Workshop on Bytecode Semantics,
  Verification, Analysis and Transformation (BYTECODE 2009)</comments><proxy>ccsd</proxy><journal-ref>Electronic Notes in Theoretical Computer Science 253, 5 (2009) 15
  - 30</journal-ref><doi>10.1016/j.entcs.2009.11.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although in most cases class initialization works as expected, some static
fields may be read before being initialized, despite being initialized in their
corresponding class initializer. We propose an analysis which compute, for each
program point, the set of static fields that must have been initialized and
discuss its soundness. We show that such an analysis can be directly applied to
identify the static fields that may be read before being initialized and to
improve the precision while preserving the soundness of a null-pointer
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3250</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3250</id><created>2010-07-19</created><authors><author><keyname>Albert</keyname><forenames>Elvira</forenames></author><author><keyname>G&#xf3;mez-Zamalloa</keyname><forenames>Miguel</forenames></author><author><keyname>Hubert</keyname><forenames>Laurent</forenames></author><author><keyname>Puebla</keyname><forenames>German</forenames></author></authors><title>Verification of Java Bytecode using Analysis and Transformation of Logic
  Programs</title><categories>cs.PL</categories><proxy>ccsd</proxy><journal-ref>The International Symposium on Practical Aspects of Declarative
  Languages 4354 (2007) 124-139</journal-ref><doi>10.1007/978-3-540-69611-7_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State of the art analyzers in the Logic Programming (LP) paradigm are
nowadays mature and sophisticated. They allow inferring a wide variety of
global properties including termination, bounds on resource consumption, etc.
The aim of this work is to automatically transfer the power of such analysis
tools for LP to the analysis and verification of Java bytecode (JVML). In order
to achieve our goal, we rely on well-known techniques for meta-programming and
program specialization. More precisely, we propose to partially evaluate a JVML
interpreter implemented in LP together with (an LP representation of) a JVML
program and then analyze the residual program. Interestingly, at least for the
examples we have studied, our approach produces very simple LP representations
of the original JVML programs. This can be seen as a decompilation from JVML to
high-level LP source. By reasoning about such residual programs, we can
automatically prove in the CiaoPP system some non-trivial properties of JVML
programs such as termination, run-time error freeness and infer bounds on its
resource consumption. We are not aware of any other system which is able to
verify such advanced properties of Java bytecode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3254</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3254</id><created>2010-07-15</created><updated>2010-10-13</updated><authors><author><keyname>Stevanak</keyname><forenames>J. T.</forenames></author><author><keyname>Larue</keyname><forenames>David M.</forenames></author><author><keyname>Carr</keyname><forenames>Lincoln D.</forenames></author></authors><title>Distinguishing Fact from Fiction: Pattern Recognition in Texts Using
  Complex Networks</title><categories>cs.CL cond-mat.stat-mech physics.soc-ph</categories><comments>9 pages, 7 figures -- this is a significant revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish concrete mathematical criteria to distinguish between different
kinds of written storytelling, fictional and non-fictional. Specifically, we
constructed a semantic network from both novels and news stories, with $N$
independent words as vertices or nodes, and edges or links allotted to words
occurring within $m$ places of a given vertex; we call $m$ the word distance.
We then used measures from complex network theory to distinguish between news
and fiction, studying the minimal text length needed as well as the optimized
word distance $m$. The literature samples were found to be most effectively
represented by their corresponding power laws over degree distribution $P(k)$
and clustering coefficient $C(k)$; we also studied the mean geodesic distance,
and found all our texts were small-world networks. We observed a natural
break-point at $k=\sqrt{N}$ where the power law in the degree distribution
changed, leading to separate power law fit for the bulk and the tail of $P(k)$.
Our linear discriminant analysis yielded a $73.8 \pm 5.15%$ accuracy for the
correct classification of novels and $69.1 \pm 1.22%$ for news stories. We
found an optimal word distance of $m=4$ and a minimum text length of 100 to 200
words $N$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3275</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3275</id><created>2010-07-19</created><authors><author><keyname>Benabbou</keyname><forenames>Amel</forenames></author><author><keyname>Bahloul</keyname><forenames>Safia Nait</forenames></author><author><keyname>Amghar</keyname><forenames>Youssef</forenames></author></authors><title>An Algorithmic Structuration of a Type System for an Orthogonal
  Object/Relational Model</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Date and Darwen have proposed a theory of types, the latter forms the basis
of a detailed presentation of a panoply of simple and complex types. However,
this proposal has not been structured in a formal system. Specifically, Date
and Darwen haven't indicated the formalism of the type system that corresponds
to the type theory established. In this paper, we propose a pseudo-algorithmic
and grammatical description of a system of types for Date and Darwen's model.
Our type system is supposed take into account null values; for such intention,
we introduce a particular type noted #, which expresses one or more occurrences
of incomplete information in a database. Our algebraic grammar describes in
detail the complete specification of an inheritance model and the subryping
relation induced, thus the different definitions of related concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3292</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3292</id><created>2010-07-19</created><authors><author><keyname>Yoshida</keyname><forenames>Yuichi</forenames></author></authors><title>Lower Bounds on Query Complexity for Testing Bounded-Degree CSPs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider lower bounds on the query complexity for testing
CSPs in the bounded-degree model.
  First, for any ``symmetric'' predicate $P:{0,1}^{k} \to {0,1}$ except \equ
where $k\geq 3$, we show that every (randomized) algorithm that distinguishes
satisfiable instances of CSP(P) from instances $(|P^{-1}(0)|/2^k-\epsilon)$-far
from satisfiability requires $\Omega(n^{1/2+\delta})$ queries where $n$ is the
number of variables and $\delta&gt;0$ is a constant that depends on $P$ and
$\epsilon$. This breaks a natural lower bound $\Omega(n^{1/2})$, which is
obtained by the birthday paradox. We also show that every one-sided error
tester requires $\Omega(n)$ queries for such $P$. These results are hereditary
in the sense that the same results hold for any predicate $Q$ such that
$P^{-1}(1) \subseteq Q^{-1}(1)$. For EQU, we give a one-sided error tester
whose query complexity is $\tilde{O}(n^{1/2})$. Also, for 2-XOR (or,
equivalently E2LIN2), we show an $\Omega(n^{1/2+\delta})$ lower bound for
distinguishing instances between $\epsilon$-close to and $(1/2-\epsilon)$-far
from satisfiability.
  Next, for the general k-CSP over the binary domain, we show that every
algorithm that distinguishes satisfiable instances from instances
$(1-2k/2^k-\epsilon)$-far from satisfiability requires $\Omega(n)$ queries. The
matching NP-hardness is not known, even assuming the Unique Games Conjecture or
the $d$-to-$1$ Conjecture. As a corollary, for Maximum Independent Set on
graphs with $n$ vertices and a degree bound $d$, we show that every
approximation algorithm within a factor $d/\poly\log d$ and an additive error
of $\epsilon n$ requires $\Omega(n)$ queries. Previously, only super-constant
lower bounds were known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3296</identifier>
 <datestamp>2012-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3296</id><created>2010-07-19</created><updated>2012-09-18</updated><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Kumar</keyname><forenames>Nirman</forenames></author></authors><title>Approximate Nearest Neighbor Search for Low Dimensional Queries</title><categories>cs.CG cs.DS</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Approximate Nearest Neighbor problem for metric spaces where the
query points are constrained to lie on a subspace of low doubling dimension,
while the data is high-dimensional. We show that this problem can be solved
efficiently despite the high dimensionality of the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3303</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3303</id><created>2010-07-19</created><authors><author><keyname>Luo</keyname><forenames>Zhaohua</forenames></author></authors><title>A New Approach to Abstract Machines - Introduction to the Theory of
  Configuration Machines</title><categories>cs.LO cs.FL math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An abstract machine is a theoretical model designed to perform a rigorous
study of computation. Such a model usually consists of configurations,
instructions, programs, inputs and outputs for the machine. In this paper we
formalize these notions as a very simple algebraic system, called a
configuration machine. If an abstract machine is defined as a configuration
machine consisting of primitive recursive functions then the functions computed
by the machine are always recursive. The theory of configuration machines
provides a useful tool to study universal machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3310</identifier>
 <datestamp>2015-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3310</id><created>2010-07-19</created><updated>2015-12-23</updated><authors><author><keyname>Savelyev</keyname><forenames>Yasha</forenames></author></authors><title>Time symmetric Go</title><categories>cs.GT</categories><comments>Added a lot more detail and fixed a somewhat apparent logical problem
  with game rules: removal of Ko rule could not be justified with the older
  rules. The main reason for posting this here is that I would like some help
  in writing a program implementing this game. Comments welcome</comments><msc-class>91A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we describe a time symmetric version of the classical game Go.
Time symmetry means that players move simultaneously without knowledge of the
other player's move. In particular the classical Komi rule is removed, as well
as the Ko rule. This is a perfect information game, (up to the fact that the
other playe r's move is not not known on the given turn) to resolve the natural
issues that can occur with simultaneity we use ideas inspired by quantum
mechanics, but instead of a dice roll there is a certain deterministic
``quantum state'' reduction. This requires introduction of 2 new rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3315</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3315</id><created>2010-07-19</created><updated>2010-11-08</updated><authors><author><keyname>Li</keyname><forenames>Liangbin</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Multi-Source Transmission for Wireless Relay Networks with Linear
  Complexity</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transaction on Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, vol.59, no.6,
  pp.2898-2912, June 2011</journal-ref><doi>10.1109/TSP.2011.2123890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers transmission schemes in multi-access relay networks
(MARNs) where $J$ single-antenna sources send independent information to one
$N$-antenna destination through one $M$-antenna relay. For complexity
considerations, we propose a linear framework, where the relay linearly
transforms its received signals to generate the forwarded signals without
decoding and the destination uses its multi-antennas to fully decouple signals
from different sources before decoding, by which the decoding complexity is
linear in the number of sources. To achieve a high symbol rate, we first
propose a scheme called DSTC-ICRec in which all sources' information streams
are concurrently transmitted in both the source-relay link and the
relay-destination link. In this scheme, distributed space-time coding (DSTC) is
applied at the relay, which satisfies the linear constraint. DSTC also allows
the destination to conduct the zero-forcing interference cancellation (IC)
scheme originally proposed for multi-antenna systems to fully decouple signals
from different sources. Our analysis shows that the symbol rate of DSTC-ICRec
is $1/2$ symbols/source/channel use and the diversity gain of the scheme is
upperbounded by $M-J+1$. To achieve a higher diversity gain, we propose another
scheme called TDMA-ICRec in which the sources time-share the source-relay link.
The relay coherently combines the signals on its antennas to maximize the
signal-to-noise ratio (SNR) of each source, then concurrently forwards all
sources' information. The destination performs zero-forcing IC. It is shown
through both analysis and simulation that when $N \ge 2J-1$, TDMA-ICRec
achieves the same maximum diversity gain as the full TDMA scheme in which the
information stream from each source is assigned to an orthogonal channel in
both links, but with a higher symbol rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3336</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3336</id><created>2010-07-20</created><updated>2013-02-06</updated><authors><author><keyname>Sattari</keyname><forenames>Pegah</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Active Topology Inference using Network Coding</title><categories>cs.NI</categories><doi>10.1016/j.phycom.2012.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our goal is to infer the topology of a network when (i) we can send probes
between sources and receivers at the edge of the network and (ii) intermediate
nodes can perform simple network coding operations, i.e., additions. Our key
intuition is that network coding introduces topology-dependent correlation in
the observations at the receivers, which can be exploited to infer the
topology. For undirected tree topologies, we design hierarchical clustering
algorithms, building on our prior work. For directed acyclic graphs (DAGs),
first we decompose the topology into a number of two-source, two-receiver
(2-by-2) subnetwork components and then we merge these components to
reconstruct the topology. Our approach for DAGs builds on prior work on
tomography, and improves upon it by employing network coding to accurately
distinguish among all different 2-by-2 components. We evaluate our algorithms
through simulation of a number of realistic topologies and compare them to
active tomographic techniques without network coding. We also make connections
between our approach and alternatives, including passive inference, traceroute,
and packet marking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3341</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3341</id><created>2010-07-20</created><authors><author><keyname>Sultanov</keyname><forenames>T. G.</forenames></author><author><keyname>Sukhov</keyname><forenames>A. M.</forenames></author></authors><title>Simulation technique for available bandwidth estimation</title><categories>cs.NI</categories><acm-class>C.2.1; C.4</acm-class><doi>10.1109/EMS.2010.88</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a method for measuring available bandwidth, based on
testing network packets of various sizes (Variable Packet Size method, VPS).
The boundaries of applicability of the model have been found, which are based
on the accuracy of measurements of packet delays, also we have derived a
formula of measuring the upper limit of bandwidth. The computer simulation has
been performed and relationship between the measurement error of available
bandwidth and the number of measurements has been found. Experimental
verification with the use of RIPE Test Box measuring system has shown that the
suggested method has advantages over existing measurement techniques. Pathload
utility has been chosen as an alternative technique of measurement, and to
ensure reliable results statistics by SNMP agent has been withdrawn directly
from the router.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3350</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3350</id><created>2010-07-20</created><authors><author><keyname>Dufourd</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LSIIT</affiliation></author><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Formal study of plane Delaunay triangulation</title><categories>cs.LO</categories><proxy>ccsd</proxy><journal-ref>Interactive Theorem Priving, Edinburgh : United Kingdom (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents the formal proof of correctness for a plane Delaunay
triangulation algorithm. It consists in repeating a sequence of edge flippings
from an initial triangulation until the Delaunay property is achieved. To
describe triangulations, we rely on a combinatorial hypermap specification
framework we have been developing for years. We embed hypermaps in the plane by
attaching coordinates to elements in a consistent way. We then describe what
are legal and illegal Delaunay edges and a flipping operation which we show
preserves hypermap, triangulation, and embedding invariants. To prove the
termination of the algorithm, we use a generic approach expressing that any
non-cyclic relation is well-founded when working on a finite set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3353</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3353</id><created>2010-07-20</created><authors><author><keyname>Hubert</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Barr&#xe9;</keyname><forenames>Nicolas</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Besson</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Demange</keyname><forenames>Delphine</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Jensen</keyname><forenames>Thomas</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Monfort</keyname><forenames>Vincent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Pichardie</keyname><forenames>David</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Turpin</keyname><forenames>Tiphaine</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Sawja: Static Analysis Workshop for Java</title><categories>cs.PL</categories><proxy>ccsd</proxy><journal-ref>The International Conference on Formal Verification of
  Object-Oriented Software 2010.13 (2010) 253--267</journal-ref><doi>10.1007/978-3-642-18070-5_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Static analysis is a powerful technique for automatic verification of
programs but raises major engineering challenges when developing a full-fledged
analyzer for a realistic language such as Java. This paper describes the Sawja
library: a static analysis framework fully compliant with Java 6 which provides
OCaml modules for efficiently manipulating Java bytecode programs. We present
the main features of the library, including (i) efficient functional
data-structures for representing program with implicit sharing and lazy
parsing, (ii) an intermediate stack-less representation, and (iii) fast
computation and manipulation of complete programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3384</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3384</id><created>2010-07-20</created><updated>2010-08-22</updated><authors><author><keyname>Benedetto</keyname><forenames>D.</forenames></author><author><keyname>Caglioti</keyname><forenames>E.</forenames></author><author><keyname>Cristadoro</keyname><forenames>G.</forenames></author><author><keyname>Esposti</keyname><forenames>M. Degli</forenames></author></authors><title>Relative entropy via non-sequential recursive pair substitutions</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>13 pages , 2 figures</comments><msc-class>68P30</msc-class><doi>10.1088/1742-5468/2010/09/P09010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The entropy of an ergodic source is the limit of properly rescaled 1-block
entropies of sources obtained applying successive non-sequential recursive
pairs substitutions (see P. Grassberger 2002 ArXiv:physics/0207023 and D.
Benedetto, E. Caglioti and D. Gabrielli 2006 Jour. Stat. Mech. Theo. Exp. 09
doi:10.1088/1742.-5468/2006/09/P09011). In this paper we prove that the cross
entropy and the Kullback-Leibler divergence can be obtained in a similar way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3415</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3415</id><created>2010-07-20</created><authors><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Searching in Dynamic Catalogs on a Tree</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the following modification of the iterative search
problem. We are given a tree $T$, so that a dynamic catalog $C(v)$ is
associated with every tree node $v$. For any $x$ and for any node-to-root path
$\pi$ in $T$, we must find the predecessor of $x$ in $\cup_{v\in \pi} C(v)$. We
present a linear space dynamic data structure that supports such queries in
$O(t(n)+|\pi|)$ time, where $t(n)$ is the time needed to search in one catalog
and $|\pi|$ denotes the number of nodes on path $\pi$. We also consider the
reporting variant of this problem, in which for any $x_1$, $x_2$ and for any
path $\pi'$ all elements of $\cup_{v\in \pi'} (C(v)\cap [x_1,x_2])$ must be
reported; here $\pi'$ denotes a path between an arbitrary node $v_0$ and its
ancestor $v_1$. We show that such queries can be answered in $O(t(n)+|\pi'|+
k)$ time, where $k$ is the number of elements in the answer. To illustrate
applications of our technique, we describe the first dynamic data structures
for the stabbing-max problem, the horizontal point location problem, and the
orthogonal line-segment intersection problem with optimal $O(\log n/\log \log
n)$ query time and poly-logarithmic update time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3424</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3424</id><created>2010-07-20</created><authors><author><keyname>Amir</keyname><forenames>Amnon</forenames></author><author><keyname>Zuk</keyname><forenames>Or</forenames></author></authors><title>Bacterial Community Reconstruction Using A Single Sequencing Reaction</title><categories>q-bio.GN cs.IT math.IT q-bio.QM stat.AP stat.CO</categories><comments>28 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bacteria are the unseen majority on our planet, with millions of species and
comprising most of the living protoplasm. While current methods enable in-depth
study of a small number of communities, a simple tool for breadth studies of
bacterial population composition in a large number of samples is lacking. We
propose a novel approach for reconstruction of the composition of an unknown
mixture of bacteria using a single Sanger-sequencing reaction of the mixture.
This method is based on compressive sensing theory, which deals with
reconstruction of a sparse signal using a small number of measurements.
Utilizing the fact that in many cases each bacterial community is comprised of
a small subset of the known bacterial species, we show the feasibility of this
approach for determining the composition of a bacterial mixture. Using
simulations, we show that sequencing a few hundred base-pairs of the 16S rRNA
gene sequence may provide enough information for reconstruction of mixtures
containing tens of species, out of tens of thousands, even in the presence of
realistic measurement noise. Finally, we show initial promising results when
applying our method for the reconstruction of a toy experimental mixture with
five species. Our approach may have a potential for a practical and efficient
way for identifying bacterial species compositions in biological samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3459</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3459</id><created>2010-07-20</created><updated>2010-12-26</updated><authors><author><keyname>Dastidar</keyname><forenames>Manosij Ghosh</forenames></author><author><keyname>Gupta</keyname><forenames>Sourav Sen</forenames></author></authors><title>Extension of Stanley's Theorem for Partitions</title><categories>cs.DM math.CO math.NT</categories><comments>13 pages paper, also submitted at a Math Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an extension of Stanley's theorem related to
partitions of positive integers. Stanley's theorem states a relation between
&quot;the sum of the numbers of distinct members in the partitions of a positive
integer $n$&quot; and &quot;the total number of 1's that occur in the partitions of $n$&quot;.
Our generalization states a similar relation between &quot;the sum of the numbers of
distinct members in the partitions of $n$&quot; and the total number of 2's or 3's
or any general $k$ that occur in the partitions of $n$ and the subsequent
integers. We also apply this result to obtain an array of interesting
corollaries, including alternate proofs and analogues of some of the very
well-known results in the theory of partitions. We extend Ramanujan's results
on congruence behavior of the 'number of partition' function $p(n)$ to get
analogous results for the 'number of occurrences of an element $k$ in
partitions of $n$'. Moreover, we present an alternate proof of Ramanujan's
results in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3476</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3476</id><created>2010-07-20</created><authors><author><keyname>Firooz</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Maas</keyname><forenames>Dustin</forenames></author><author><keyname>Zhang</keyname><forenames>Junxing</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Kasera</keyname><forenames>Sneha K.</forenames></author></authors><title>Channel Sounding for the Masses: Low Complexity GNU 802.11b Channel
  Impulse Response Estimation</title><categories>cs.OH</categories><doi>10.1109/TWC.2011.111611.091774</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New techniques in cross-layer wireless networks are building demand for
ubiquitous channel sounding, that is, the capability to measure channel impulse
response (CIR) with any standard wireless network and node. Towards that goal,
we present a software-defined IEEE 802.11b receiver and CIR estimation system
with little additional computational complexity compared to 802.11b reception
alone. The system implementation, using the universal software radio peripheral
(USRP) and GNU Radio, is described and compared to previous work. By overcoming
computational limitations and performing direct-sequence spread-spectrum
(DS-SS) matched filtering on the USRP, we enable high-quality yet inexpensive
CIR estimation. We validate the channel sounder and present a drive test
campaign which measures hundreds of channels between WiFi access points and an
in-vehicle receiver in urban and suburban areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3478</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3478</id><created>2010-07-20</created><updated>2012-06-19</updated><authors><author><keyname>Friedland</keyname><forenames>S.</forenames></author><author><keyname>Gaubert</keyname><forenames>S.</forenames></author></authors><title>Submodular spectral functions of principal submatrices of a hermitian
  matrix, extensions and applications</title><categories>math.SP cs.DM</categories><comments>16 pages</comments><msc-class>15A18, 15B57, 90C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the multiplicative submodularity of the principal determinants of a
nonnegative definite hermitian matrix to other spectral functions. We show that
if $f$ is the primitive of a function that is operator monotone on an interval
containing the spectrum of a hermitian matrix $A$, then the function $I\mapsto
{\rm tr} f(A[I])$ is supermodular, meaning that ${\rm tr} f(A[I])+{\rm tr}
f(A[J])\leq {\rm tr} f(A[I\cup J])+{\rm tr} f(A[I\cap J])$, where $A[I]$
denotes the $I\times I$ principal submatrix of $A$. We discuss extensions to
self-adjoint operators on infinite dimensional Hilbert space and to
$M$-matrices. We discuss an application to CUR approximation of nonnegative
hermitian matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3515</identifier>
 <datestamp>2011-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3515</id><created>2010-07-20</created><updated>2011-12-09</updated><authors><author><keyname>Alferes</keyname><forenames>Jos&#xe9; J&#xfa;lio</forenames></author><author><keyname>Knorr</keyname><forenames>Matthias</forenames></author><author><keyname>Swift</keyname><forenames>Terrance</forenames></author></authors><title>Query-driven Procedures for Hybrid MKNF Knowledge Bases</title><categories>cs.AI</categories><comments>48 pages with 1 figures, submitted to ACM TOCL</comments><acm-class>I.2.4; I.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid MKNF knowledge bases are one of the most prominent tightly integrated
combinations of open-world ontology languages with closed-world (non-monotonic)
rule paradigms. The definition of Hybrid MKNF is parametric on the description
logic (DL) underlying the ontology language, in the sense that non-monotonic
rules can extend any decidable DL language. Two related semantics have been
defined for Hybrid MKNF: one that is based on the Stable Model Semantics for
logic programs and one on the Well-Founded Semantics (WFS). Under WFS, the
definition of Hybrid MKNF relies on a bottom-up computation that has polynomial
data complexity whenever the DL language is tractable. Here we define a general
query-driven procedure for Hybrid MKNF that is sound with respect to the stable
model-based semantics, and sound and complete with respect to its WFS variant.
This procedure is able to answer a slightly restricted form of conjunctive
queries, and is based on tabled rule evaluation extended with an external
oracle that captures reasoning within the ontology. Such an (abstract) oracle
receives as input a query along with knowledge already derived, and replies
with a (possibly empty) set of atoms, defined in the rules, whose truth would
suffice to prove the initial query. With appropriate assumptions on the
complexity of the abstract oracle, the general procedure maintains the data
complexity of the WFS for Hybrid MKNF knowledge bases.
  To illustrate this approach, we provide a concrete oracle for EL+, a fragment
of the light-weight DL EL++. Such an oracle has practical use, as EL++ is the
language underlying OWL 2 EL, which is part of the W3C recommendations for the
Semantic Web, and is tractable for reasoning tasks such as subsumption. We show
that query-driven Hybrid MKNF preserves polynomial data complexity when using
the EL+ oracle and WFS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3518</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3518</id><created>2010-07-20</created><updated>2010-08-05</updated><authors><author><keyname>Nitinawarat</keyname><forenames>Sirin</forenames></author><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author><author><keyname>Reznik</keyname><forenames>Alex</forenames></author></authors><title>Secret Key Generation for a Pairwise Independent Network Model</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, in revision prior to review
  for final approval</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider secret key generation for a &quot;pairwise independent network&quot; model
in which every pair of terminals observes correlated sources that are
independent of sources observed by all other pairs of terminals. The terminals
are then allowed to communicate publicly with all such communication being
observed by all the terminals. The objective is to generate a secret key shared
by a given subset of terminals at the largest rate possible, with the
cooperation of any remaining terminals. Secrecy is required from an
eavesdropper that has access to the public interterminal communication. A
(single-letter) formula for secret key capacity brings out a natural connection
between the problem of secret key generation and a combinatorial problem of
maximal packing of Steiner trees in an associated multigraph. An explicit
algorithm is proposed for secret key generation based on a maximal packing of
Steiner trees in a multigraph; the corresponding maximum rate of Steiner tree
packing is thus a lower bound for the secret key capacity. When only two of the
terminals or when all the terminals seek to share a secret key, the mentioned
algorithm achieves secret key capacity in which case the bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3539</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3539</id><created>2010-07-20</created><authors><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Karande</keyname><forenames>Chinmay</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Single Parameter Combinatorial Auctions with Partially Public Valuations</title><categories>cs.GT</categories><doi>10.1007/978-3-642-16170-4_21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing truthful auctions, when the bidders'
valuations have a public and a private component. In particular, we consider
combinatorial auctions where the valuation of an agent $i$ for a set $S$ of
items can be expressed as $v_if(S)$, where $v_i$ is a private single parameter
of the agent, and the function $f$ is publicly known. Our motivation behind
studying this problem is two-fold: (a) Such valuation functions arise naturally
in the case of ad-slots in broadcast media such as Television and Radio. For an
ad shown in a set $S$ of ad-slots, $f(S)$ is, say, the number of {\em unique}
viewers reached by the ad, and $v_i$ is the valuation per-unique-viewer. (b)
From a theoretical point of view, this factorization of the valuation function
simplifies the bidding language, and renders the combinatorial auction more
amenable to better approximation factors. We present a general technique, based
on maximal-in-range mechanisms, that converts any $\alpha$-approximation
non-truthful algorithm ($\alpha \leq 1$) for this problem into
$\Omega(\frac{\alpha}{\log{n}})$ and $\Omega(\alpha)$-approximate truthful
mechanisms which run in polynomial time and quasi-polynomial time,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3561</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3561</id><created>2010-07-21</created><authors><author><keyname>Breen</keyname><forenames>Barbara J.</forenames></author><author><keyname>Lindner</keyname><forenames>John F.</forenames></author></authors><title>Introduction to Xgrid: Cluster Computing for Everyone</title><categories>physics.comp-ph cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Xgrid is the first distributed computing architecture built into a desktop
operating system. It allows you to run a single job across multiple computers
at once. All you need is at least one Macintosh computer running Mac OS X v10.4
or later. (Mac OS X Server is not required.) We provide explicit instructions
and example code to get you started, including examples of how to distribute
your computing jobs, even if your initial cluster consists of just two old
laptops in your basement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3564</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3564</id><created>2010-07-21</created><updated>2010-07-26</updated><authors><author><keyname>Zhou</keyname><forenames>Tianyi</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Wu</keyname><forenames>Xindong</forenames></author></authors><title>Manifold Elastic Net: A Unified Framework for Sparse Dimension Reduction</title><categories>cs.LG stat.ML</categories><comments>33 pages, 12 figures</comments><journal-ref>Journal of Data Mining and Knowledge Discovery, 2010</journal-ref><doi>10.1007/s10618-010-0182-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is difficult to find the optimal sparse solution of a manifold learning
based dimensionality reduction algorithm. The lasso or the elastic net
penalized manifold learning based dimensionality reduction is not directly a
lasso penalized least square problem and thus the least angle regression (LARS)
(Efron et al. \cite{LARS}), one of the most popular algorithms in sparse
learning, cannot be applied. Therefore, most current approaches take indirect
ways or have strict settings, which can be inconvenient for applications. In
this paper, we proposed the manifold elastic net or MEN for short. MEN
incorporates the merits of both the manifold learning based dimensionality
reduction and the sparse learning based dimensionality reduction. By using a
series of equivalent transformations, we show MEN is equivalent to the lasso
penalized least square problem and thus LARS is adopted to obtain the optimal
sparse solution of MEN. In particular, MEN has the following advantages for
subsequent classification: 1) the local geometry of samples is well preserved
for low dimensional data representation, 2) both the margin maximization and
the classification error minimization are considered for sparse projection
calculation, 3) the projection matrix of MEN improves the parsimony in
computation, 4) the elastic net penalty reduces the over-fitting problem, and
5) the projection matrix of MEN can be interpreted psychologically and
physiologically. Experimental evidence on face recognition over various popular
datasets suggests that MEN is superior to top level dimensionality reduction
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3568</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3568</id><created>2010-07-21</created><updated>2011-09-25</updated><authors><author><keyname>Mahdavifar</keyname><forenames>Hessam</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Achieving the Secrecy Capacity of Wiretap Channels Using Polar Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>16 pages, 5 figures, published in the IEEE Transactions on
  Information Theory, vol. 57, no. 10, October 2011. arXiv admin note:
  substantial text overlap with arXiv:1001.0210</comments><msc-class>94B99, 94A60</msc-class><acm-class>E.4</acm-class><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 10, October
  2011</journal-ref><doi>10.1109/TIT.2011.2162275</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose Alice wishes to send messages to Bob through a communication channel
C_1, but her transmissions also reach an eavesdropper Eve through another
channel C_2. The goal is to design a coding scheme that makes it possible for
Alice to communicate both reliably and securely. Reliability is measured in
terms of Bob's probability of error in recovering the message, while security
is measured in terms of the mutual information between the message and Eve's
observations. Wyner showed that the situation is characterized by a single
constant C_s, called the secrecy capacity, which has the following meaning: for
all $\epsilon &gt; 0$, there exist coding schemes of rate $R \ge C_s - \epsilon$
that asymptotically achieve both the reliability and the security objectives.
However, his proof of this result is based upon a nonconstructive random-coding
argument. To date, despite a considerable research effort, the only case where
we know how to construct coding schemes that achieve secrecy capacity is when
Eve's channel C_2 is an erasure channel, or a combinatorial variation thereof.
  Polar codes were recently invented by Arikan; they approach the capacity of
symmetric binary-input discrete memoryless channels with low encoding and
decoding complexity. Herein, we use polar codes to construct a coding scheme
that achieves the secrecy capacity of general wiretap channels. Our
construction works for any instantiation of the wiretap channel model, as
originally defined by Wyner, as long as both C_1 and C_2 are symmetric and
binary-input. Moreover, we show how to modify our construction in order to
achieve strong security, as defined by Maurer, while still operating at a rate
that approaches the secrecy capacity. In this case, we cannot guarantee that
the reliability condition will be satisfied unless the main channel C_1 is
noiseless, although we believe it can be always satisfied in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3569</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3569</id><created>2010-07-21</created><authors><author><keyname>Tian</keyname><forenames>Cong</forenames></author><author><keyname>Duan</keyname><forenames>Zhenhua</forenames></author></authors><title>Making Abstraction Refinement Efficient in Model Checking</title><categories>cs.LO</categories><comments>14 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abstraction is one of the most important strategies for dealing with the
state space explosion problem in model checking. In the abstract model,
although the state space is largely reduced, however, a counterexample found in
such a model may not be a real counterexample. And the abstract model needs to
be further refined where an NP-hard state separation problem is often involved.
In this paper, a novel method is presented by adding extra variables to the
abstract model for the refinement. With this method, not only the NP-hard state
separation problem is avoided, but also a smaller refined abstract model is
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3572</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3572</id><created>2010-07-21</created><authors><author><keyname>Shcherbacov</keyname><forenames>V. A.</forenames></author></authors><title>Quasigroups in cryptology</title><categories>math.GR cs.CR</categories><comments>31 pages</comments><msc-class>20N05</msc-class><journal-ref>V.A. Shcherbacov, Quasigroups in cryptology, Computer Science
  Journal of Moldova, vol.17, no. 2(50), 2009, 193-228</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a review of some known published applications of quasigroups in
cryptology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3587</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3587</id><created>2010-07-21</created><updated>2011-04-26</updated><authors><author><keyname>Montanaro</keyname><forenames>Ashley</forenames></author></authors><title>A new exponential separation between quantum and classical one-way
  communication complexity</title><categories>quant-ph cs.CC</categories><comments>19 pages; v3: improved results and some bug fixes</comments><journal-ref>Quantum Information &amp; Computation, vol. 11 no. 7&amp;8, pp. 574-591,
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new example of a partial boolean function whose one-way quantum
communication complexity is exponentially lower than its one-way classical
communication complexity. The problem is a natural generalisation of the
previously studied Subgroup Membership problem: Alice receives a bit string x,
Bob receives a permutation matrix M, and their task is to determine whether
Mx=x or Mx is far from x. The proof uses Fourier analysis and an inequality of
Kahn, Kalai and Linial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3588</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3588</id><created>2010-07-21</created><updated>2011-04-01</updated><authors><author><keyname>Martinez-Mateo</keyname><forenames>Jesus</forenames></author><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Martin</keyname><forenames>Vicente</forenames></author></authors><title>Improved construction of irregular progressive edge-growth Tanner graphs</title><categories>cs.IT math.IT</categories><comments>3 pages, 3 figures</comments><journal-ref>Communications Letters, IEEE Volume: 14 , Issue: 12, Publication
  Year: 2010 , Page(s): 1155 - 1157</journal-ref><doi>10.1109/LCOMM.2010.101810.101384</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The progressive edge-growth algorithm is a well-known procedure to construct
regular and irregular low-density parity-check codes. In this paper, we propose
a modification of the original algorithm that improves the performance of these
codes in the waterfall region when constructing codes complying with both,
check and symbol node degree distributions. The proposed algorithm is thus
interesting if a family of irregular codes with a complex check node degree
distribution is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3589</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3589</id><created>2010-07-21</created><authors><author><keyname>Miraz</keyname><forenames>Matteo</forenames></author></authors><title>On the Cooperation of Independent Registries</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Registries play a key role in service-oriented applications. Originally, they
were neutral players between service providers and clients. The UDDI Business
Registry (UBR) was meant to foster these concepts and provide a common
reference for companies interested in Web services. The more Web services were
used, the more companies started create their own local registries: more
efficient discovery processes, better control over the quality of published
information, and also more sophisticated publication policies motivated the
creation of private repositories. The number and heterogeneity of the different
registries - besides the decision to close the UBR are pushing for new and
sophisticated means to make different registries cooperate. This paper proposes
DIRE (DIstributed REgistry), a novel approach based on a publish and subscribe
(P/S) infrastructure to federate different heterogeneous registries and make
them exchange information about published services. The paper discusses the
main motivations for the P/S-based infrastructure, proposes an integrated
service model, introduces the main components of the framework, and exemplifies
them on a simple case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3601</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3601</id><created>2010-07-21</created><authors><author><keyname>Leaw</keyname><forenames>J. N.</forenames></author><author><keyname>Cheong</keyname><forenames>S. A.</forenames></author></authors><title>Strategic Insights From Playing the Quantum Tic-Tac-Toe</title><categories>quant-ph cs.GT math-ph math.MP q-fin.PM</categories><comments>20 pages, 3 figures, and 3 tables. LaTeX 2e using iopart class, and
  braket, color, graphicx, multirow, subfig, url packages</comments><journal-ref>Journal of Physics A: Mathematical and Theoretical, vol. 43, no.
  45, 455304, 2010</journal-ref><doi>10.1088/1751-8113/43/45/455304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we perform a minimalistic quantization of the classical game
of tic-tac-toe, by allowing superpositions of classical moves. In order for the
quantum game to reduce properly to the classical game, we require legal quantum
moves to be orthogonal to all previous moves. We also admit interference
effects, by squaring the sum of amplitudes over all moves by a player to
compute his or her occupation level of a given site. A player wins when the
sums of occupations along any of the eight straight lines we can draw in the $3
\times 3$ grid is greater than three. We play the quantum tic-tac-toe first
randomly, and then deterministically, to explore the impact different opening
moves, end games, and different combinations of offensive and defensive
strategies have on the outcome of the game. In contrast to the classical
tic-tac-toe, the deterministic quantum game does not always end in a draw. In
contrast also to most classical two-player games of no chance, it is possible
for Player 2 to win. More interestingly, we find that Player 1 enjoys an
overwhelming quantum advantage when he opens with a quantum move, but loses
this advantage when he opens with a classical move. We also find the quantum
blocking move, which consists of a weighted superposition of moves that the
opponent could use to win the game, to be very effective in denying the
opponent his or her victory. We then speculate what implications these results
might have on quantum information transfer and portfolio optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3604</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3604</id><created>2010-07-21</created><updated>2012-04-29</updated><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Gamzu</keyname><forenames>Iftah</forenames></author></authors><title>Efficient Submodular Function Maximization under Linear Packing
  Constraints</title><categories>cs.DS cs.DM</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of maximizing a monotone submodular set function subject
to linear packing constraints. An instance of this problem consists of a matrix
$A \in [0,1]^{m \times n}$, a vector $b \in [1,\infty)^m$, and a monotone
submodular set function $f: 2^{[n]} \rightarrow \bbR_+$. The objective is to
find a set $S$ that maximizes $f(S)$ subject to $A x_{S} \leq b$, where $x_S$
stands for the characteristic vector of the set $S$. A well-studied special
case of this problem is when $f$ is linear. This special case captures the
class of packing integer programs.
  Our main contribution is an efficient combinatorial algorithm that achieves
an approximation ratio of $\Omega(1 / m^{1/W})$, where $W = \min\{b_i / A_{ij}
: A_{ij} &gt; 0\}$ is the width of the packing constraints. This result matches
the best known performance guarantee for the linear case. One immediate
corollary of this result is that the algorithm under consideration achieves
constant factor approximation when the number of constraints is constant or
when the width of the constraints is sufficiently large. This motivates us to
study the large width setting, trying to determine its exact approximability.
We develop an algorithm that has an approximation ratio of $(1 - \epsilon)(1 -
1/e)$ when $W = \Omega(\ln m / \epsilon^2)$. This result essentially matches
the theoretical lower bound of $1 - 1/e$. We also study the special setting in
which the matrix $A$ is binary and $k$-column sparse. A $k$-column sparse
matrix has at most $k$ non-zero entries in each of its column. We design a fast
combinatorial algorithm that achieves an approximation ratio of $\Omega(1 /
(Wk^{1/W}))$, that is, its performance guarantee only depends on the sparsity
and width parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3607</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3607</id><created>2010-07-21</created><authors><author><keyname>Aichholzer</keyname><forenames>Oswin</forenames></author><author><keyname>Aurenhammer</keyname><forenames>Franz</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author><author><keyname>Ramos</keyname><forenames>Pedro</forenames></author><author><keyname>Urrutia</keyname><forenames>Jorge</forenames></author></authors><title>On k-Convex Polygons</title><categories>cs.CG math.CO</categories><comments>23 pages, 19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a notion of $k$-convexity and explore polygons in the plane that
have this property. Polygons which are \mbox{$k$-convex} can be triangulated
with fast yet simple algorithms. However, recognizing them in general is a
3SUM-hard problem. We give a characterization of \mbox{$2$-convex} polygons, a
particularly interesting class, and show how to recognize them in \mbox{$O(n
\log n)$} time. A description of their shape is given as well, which leads to
Erd\H{o}s-Szekeres type results regarding subconfigurations of their vertex
sets. Finally, we introduce the concept of generalized geometric permutations,
and show that their number can be exponential in the number of
\mbox{$2$-convex} objects considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3609</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3609</id><created>2010-07-21</created><updated>2010-10-06</updated><authors><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Min st-Cut of a Planar Graph in O(n loglog n) Time</title><categories>cs.DM</categories><comments>Added mainly details and corrections to the r-division section</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a planar undirected n-vertex graph G with non-negative edge weights, we
show how to compute, for given vertices s and t in G, a min st-cut in G in O(n
loglog n) time and O(n) space. The previous best time bound was O(n log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3611</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3611</id><created>2010-07-21</created><updated>2012-03-08</updated><authors><author><keyname>Byrka</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Ghodsi</keyname><forenames>MohammadReza</forenames></author><author><keyname>Srinivasan</keyname><forenames>Aravind</forenames></author></authors><title>LP-rounding algorithms for facility-location problems</title><categories>cs.DS</categories><comments>Added funding information</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study LP-rounding approximation algorithms for metric uncapacitated
facility-location problems. We first give a new analysis for the algorithm of
Chudak and Shmoys, which differs from the analysis of Byrka and Aardal in that
now we do not need any bound based on the solution to the dual LP program.
Besides obtaining the optimal bifactor approximation as do Byrka and Aardal, we
can now also show that the algorithm with scaling parameter equaling 1.58 is,
in fact, an 1.58-approximation algorithm. More importantly, we suggest an
approach based on additional randomization and analyses such as ours, which
could achieve or approach the conjectured optimal 1.46...--approximation for
this basic problem.
  Next, using essentially the same techniques, we obtain improved approximation
algorithms in the 2-stage stochastic variant of the problem, where we must open
a subset of facilities having only stochastic information about the future
demand from the clients. For this problem we obtain a 2.2975-approximation
algorithm in the standard setting, and a 2.4957-approximation in the more
restricted, per-scenario setting.
  We then study robust fault-tolerant facility location, introduced by Chechik
and Peleg: solutions here are designed to provide low connection cost in case
of failure of up to $k$ facilities. Chechik and Peleg gave a 6.5-approximation
algorithm for $k=1$ and a ($7.5k + 1.5$)-approximation algorithm for general
$k$. We improve this to an LP-rounding $(k+5+4/k)$-approximation algorithm. We
also observe that in case of oblivious failures the expected approximation
ratio can be reduced to $k + 1.5$, and that the integrality gap of the natural
LP-relaxation of the problem is at least $k + 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3615</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3615</id><created>2010-07-21</created><authors><author><keyname>Pottier</keyname><forenames>Lo&#xef;c</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Connecting Gr\&quot;obner Bases Programs with Coq to do Proofs in Algebra,
  Geometry and Arithmetics</title><categories>cs.SC cs.LO</categories><proxy>ccsd</proxy><journal-ref>Knowledge Exchange: Automated Provers and Proof Assistants, Doha :
  Qatar (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how we connected three programs that compute Groebner bases to
Coq, to do automated proofs on algebraic, geometrical and arithmetical
expressions. The result is a set of Coq tactics and a certificate mechanism
(downloadable at http://www-sop.inria.fr/marelle/Loic.Pottier/gb-keappa.tgz).
The programs are: F4, GB \, and gbcoq. F4 and GB are the fastest (up to our
knowledge) available programs that compute Groebner bases. Gbcoq is slow in
general but is proved to be correct (in Coq), and we adapted it to our specific
problem to be efficient. The automated proofs concern equalities and
non-equalities on polynomials with coefficients and indeterminates in R or Z,
and are done by reducing to Groebner computation, via Hilbert's
Nullstellensatz. We adapted also the results of Harrison, to allow to prove
some theorems about modular arithmetics. The connection between Coq and the
programs that compute Groebner bases is done using the &quot;external&quot; tactic of Coq
that allows to call arbitrary programs accepting xml inputs and outputs. We
also produce certificates in order to make the proof scripts independant from
the external programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3622</identifier>
 <datestamp>2013-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3622</id><created>2010-07-21</created><updated>2013-04-16</updated><authors><author><keyname>Lember</keyname><forenames>J&#xfc;ri</forenames></author><author><keyname>Koloydenko</keyname><forenames>Alexey A.</forenames></author></authors><title>A generalized risk approach to path inference based on hidden Markov
  models</title><categories>stat.ML cs.LG stat.CO</categories><comments>Section 5: corrected denominators of the scaled beta variables (pp.
  27-30), =&gt; corrections in claims 1, 3, Prop. 12, bottom of Table 1. Decoder
  (49), Corol. 14 are generalized to handle 0 probabilities. Notation is more
  closely aligned with (Bishop, 2006). Details are inserted in eqn-s (43); the
  positivity assumption in Prop. 11 is explicit. Fixed typing errors in
  equation (41), Example 2</comments><msc-class>60J20, 65C60, 62M05, 60G35, 94A12, 94A05, 90C39</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the unceasing interest in hidden Markov models (HMMs), this
paper re-examines hidden path inference in these models, using primarily a
risk-based framework. While the most common maximum a posteriori (MAP), or
Viterbi, path estimator and the minimum error, or Posterior Decoder (PD), have
long been around, other path estimators, or decoders, have been either only
hinted at or applied more recently and in dedicated applications generally
unfamiliar to the statistical learning community. Over a decade ago, however, a
family of algorithmically defined decoders aiming to hybridize the two standard
ones was proposed (Brushe et al., 1998). The present paper gives a careful
analysis of this hybridization approach, identifies several problems and issues
with it and other previously proposed approaches, and proposes practical
resolutions of those. Furthermore, simple modifications of the classical
criteria for hidden path recognition are shown to lead to a new class of
decoders. Dynamic programming algorithms to compute these decoders in the usual
forward-backward manner are presented. A particularly interesting subclass of
such estimators can be also viewed as hybrids of the MAP and PD estimators.
Similar to previously proposed MAP-PD hybrids, the new class is parameterized
by a small number of tunable parameters. Unlike their algorithmic predecessors,
the new risk-based decoders are more clearly interpretable, and, most
importantly, work &quot;out of the box&quot; in practice, which is demonstrated on some
real bioinformatics tasks and data. Some further generalizations and
applications are discussed in conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3624</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3624</id><created>2010-07-21</created><updated>2011-02-10</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Unbounded-error quantum computation with small space bounds</title><categories>cs.CC quant-ph</categories><comments>A preliminary version of this paper appeared in the Proceedings of
  the Fourth International Computer Science Symposium in Russia, pages
  356--367, 2009</comments><journal-ref>Information and Computation, Volume 209, Issue 6, June 2011, Pages
  873-892</journal-ref><doi>10.1016/j.ic.2011.01.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following facts about the language recognition power of quantum
Turing machines (QTMs) in the unbounded error setting: QTMs are strictly more
powerful than probabilistic Turing machines for any common space bound $ s $
satisfying $ s(n)=o(\log \log n) $. For &quot;one-way&quot; Turing machines, where the
input tape head is not allowed to move left, the above result holds for
$s(n)=o(\log n) $. We also give a characterization for the class of languages
recognized with unbounded error by real-time quantum finite automata (QFAs)
with restricted measurements. It turns out that these automata are equal in
power to their probabilistic counterparts, and this fact does not change when
the QFA model is augmented to allow general measurements and mixed states.
Unlike the case with classical finite automata, when the QFA tape head is
allowed to remain stationary in some steps, more languages become recognizable.
We define and use a QTM model that generalizes the other variants introduced
earlier in the study of quantum space complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3629</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3629</id><created>2010-07-21</created><authors><author><keyname>Rodr&#xed;guez-Artalejo</keyname><forenames>Mario</forenames></author><author><keyname>Romero-D&#xed;az</keyname><forenames>Carlos A.</forenames></author></authors><title>A Declarative Semantics for CLP with Qualification and Proximity</title><categories>cs.LO cs.PL</categories><comments>17 pages, 26th Int'l. Conference on Logic Programming (ICLP'10)</comments><journal-ref>Theory and Practice of Logic Programming, 26th Int'l. Conference
  on Logic Programming (ICLP'10) Special Issue, 10(4-6):627-642, 2010</journal-ref><doi>10.1017/S1471068410000323</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty in Logic Programming has been investigated during the last
decades, dealing with various extensions of the classical LP paradigm and
different applications. Existing proposals rely on different approaches, such
as clause annotations based on uncertain truth values, qualification values as
a generalization of uncertain truth values, and unification based on proximity
relations. On the other hand, the CLP scheme has established itself as a
powerful extension of LP that supports efficient computation over specialized
domains while keeping a clean declarative semantics. In this paper we propose a
new scheme SQCLP designed as an extension of CLP that supports qualification
values and proximity relations. We show that several previous proposals can be
viewed as particular cases of the new scheme, obtained by partial
instantiation. We present a declarative semantics for SQCLP that is based on
observables, providing fixpoint and proof-theoretical characterizations of
least program models as well as an implementation-independent notion of goal
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3631</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3631</id><created>2010-07-21</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Jarke</keyname><forenames>Matthias</forenames></author><author><keyname>Prinz</keyname><forenames>Wolfgang</forenames></author></authors><title>Mobile Web Service Discovery in Peer to Peer Networks</title><categories>cs.DC cs.NI</categories><comments>5th International Workshop on Ubiquitous Mobile Information and
  Collaboration Systems (UMICS 2007) @ 19th International Conference on
  Advanced Information Systems Engineering (CAiSE'07), June 11-12, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advanced features of today's smart phones and hand held devices, like the
increased memory and processing capabilities, allowed them to act even as
information providers. Thus a smart phone hosting web services is not a fancy
anymore. But the relevant discovery of these services provided by the smart
phones has became quite complex, because of the volume of services possible
with each Mobile Host providing some services. Centralized registries have
severe drawbacks in such a scenario and alternate means of service discovery
are to be addressed. P2P domain with it resource sharing capabilities comes
quite handy and here in this paper we provide an alternate approach to UDDI
registry for discovering mobile web services. The services are published into
the P2P network as JXTA modules and the discovery issues of these module
advertisements are addressed. The approach also provides alternate means of
identifying the Mobile Host.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3633</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3633</id><created>2010-07-21</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Faruque</keyname><forenames>M. A. A.</forenames></author><author><keyname>Munni</keyname><forenames>M. A. S.</forenames></author></authors><title>Alternatives to Mobile Keypad Design: Improved Text Feed</title><categories>cs.HC</categories><comments>6th International Conference on Computer and Information Technology
  (ICCIT2003), 19-21 December, 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we tried to focus on some of the problems with the mobile
keypad and text entering in these devices, and tried to give some possible
suggestions. We mainly took some of the basic Human Computer Interaction
principles and some general issues into consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3640</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3640</id><created>2010-07-21</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Jarke</keyname><forenames>Matthias</forenames></author><author><keyname>Prinz</keyname><forenames>Wolfgang</forenames></author><author><keyname>Pendyala</keyname><forenames>Kiran</forenames></author></authors><title>Security Aware Mobile Web Service Provisioning</title><categories>cs.DC cs.NI</categories><comments>Proceedings of International Conference for Internet Technology and
  Secured Transactions (ICITST-2006), September 11-13, 2006, pp. 48-56.
  Published by e.Centre for Infonomics, ISBN 0-9546628-2-2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile data services in combination with profluent web services are seemingly
the path breaking domain in current information research. Effectively, these
mobile web services will pave the way for exciting performance and security
challenges, the core need-to-be-addressed issues. On security front, though a
lot of standardized security specifications and implementations exist for web
services in the wired networks, not much has been analysed and standardized in
the wireless environments. This paper addresses some of the critical challenges
in providing security to the mobile web service domain. We first explore mobile
web services and their key security issues, with special focus on provisioning
based on a mobile web service provider realized by us. Later we discuss
state-of-the-art security awareness in the wired and wireless web services, and
finally address the realization of security for the mobile web service
provisioning with performance analysis results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3644</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3644</id><created>2010-07-21</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Jarke</keyname><forenames>Matthias</forenames></author><author><keyname>Prinz</keyname><forenames>Wolfgang</forenames></author></authors><title>A Performance Evaluation of Mobile Web Services Security</title><categories>cs.NI cs.DC</categories><comments>3rd International Conference on Web Information Systems and
  Technologies (WEBIST 2007), March 3-6, 2007, pp. 386-392. INSTICC Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now feasible to host basic web services on a smart phone due to the
advances in wireless devices and mobile communication technologies. The market
capture of mobile web services also has increased significantly, in the past
years. While the applications are quite welcoming, the ability to provide
secure and reliable communication in the vulnerable and volatile mobile ad-hoc
topologies is vastly becoming necessary. Even though a lot of standardized
security specifications like WS-Security, SAML exist for web services in the
wired networks, not much has been analyzed and standardized in the wireless
environments. In this paper we give our analysis of adapting some of the
security standards, especially WS-Security to the cellular domain, with
performance statistics. The performance latencies are obtained and analyzed
while observing the performance and quality of service of our Mobile Host.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3649</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3649</id><created>2010-07-21</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Naumenko</keyname><forenames>Anton</forenames></author></authors><title>Secure Communication and Access Control for Mobile Web Service
  Provisioning</title><categories>cs.DC cs.NI</categories><comments>Proceedings of the First International Conference on Security of
  Information and Networks (SIN 2007), May 8-10, 2007. Trafford Publishing,
  Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now feasible to host basic web services on a smart phone due to the
advances in wireless devices and mobile communication technologies. While the
applications are quite welcoming, the ability to provide secure and reliable
communication in the vulnerable and volatile mobile ad-hoc topologies is vastly
becoming necessary. The paper mainly addresses the details and issues in
providing secured communication and access control for the mobile web service
provisioning domain. While the basic message-level security can be provided,
providing proper access control mechanisms for the Mobile Host still poses a
great challenge. This paper discusses details of secure communication and
proposes the distributed semantics-based authorization mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3661</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3661</id><created>2010-07-21</created><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Non-Binary Polar Codes using Reed-Solomon Codes and Algebraic Geometry
  Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, to appear in ITW 2010 Dublin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes, introduced by Arikan, achieve symmetric capacity of any discrete
memoryless channels under low encoding and decoding complexity. Recently,
non-binary polar codes have been investigated. In this paper, we calculate
error probability of non-binary polar codes constructed on the basis of
Reed-Solomon matrices by numerical simulations. It is confirmed that 4-ary
polar codes have significantly better performance than binary polar codes on
binary-input AWGN channel. We also discuss an interpretation of polar codes in
terms of algebraic geometry codes, and further show that polar codes using
Hermitian codes have asymptotically good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3663</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3663</id><created>2010-07-21</created><authors><author><keyname>Baselice</keyname><forenames>Sabrina</forenames></author><author><keyname>Bonatti</keyname><forenames>Piero A.</forenames></author></authors><title>A decidable subclass of finitary programs</title><categories>cs.AI</categories><journal-ref>Theory and Practice of Logic Programming (2010), 10:481-496
  Cambridge University Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Answer set programming - the most popular problem solving paradigm based on
logic programs - has been recently extended to support uninterpreted function
symbols. All of these approaches have some limitation. In this paper we propose
a class of programs called FP2 that enjoys a different trade-off between
expressiveness and complexity. FP2 programs enjoy the following unique
combination of properties: (i) the ability of expressing predicates with
infinite extensions; (ii) full support for predicates with arbitrary arity;
(iii) decidability of FP2 membership checking; (iv) decidability of skeptical
and credulous stable model reasoning for call-safe queries. Odd cycles are
supported by composing FP2 programs with argument restricted programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3676</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3676</id><created>2010-07-21</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>(n,K)-user Interference Channels: Degrees of Freedom</title><categories>cs.IT math.IT</categories><comments>34 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the gains of opportunistic communication in multiuser interference
channels. Consider a fully connected $n$-user Gaussian interference channel. At
each time instance only $K\leq n$ transmitters are allowed to be communicating
with their respective receivers and the remaining $(n-K)$ transmitter-receiver
pairs remain inactive. For finite $n$, if the transmitters can acquire channel
state information (CSI) and if all channel gains are bounded away from zero and
infinity, the seminal results on interference alignment establish that for any
$K$ {\em arbitrary} active pairs the total number of spatial degrees of freedom
per orthogonal time and frequency domain is $\frac{K}{2}$. Also it is
noteworthy that without transmit-side CSI the interference channel becomes
interference-limited and the degrees of freedom is 0. In {\em dense} networks
($n\rightarrow\infty$), however, as the size of the network increase, it
becomes less likely to sustain the bounding conditions on the channel gains. By
exploiting this fact, we show that when $n$ obeys certain scaling laws, by {\em
opportunistically} and {\em dynamically} selecting the $K$ active pairs at each
time instance, the number of degrees of freedom can exceed $\frac{K}{2}$ and in
fact can be made arbitrarily close to $K$. More specifically when all
transmitters and receivers are equipped with one antenna, then the network size
scaling as $n\in\omega(\snr^{d(K-1)})$ is a {\em sufficient} condition for
achieving $d\in[0,K]$ degrees of freedom. Moreover, achieving these degrees of
freedom does not necessitate the transmitters to acquire channel state
information. Hence, invoking opportunistic communication in the context of
interference channels leads to achieving higher degrees of freedom that are not
achievable otherwise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3680</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3680</id><created>2010-07-21</created><authors><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Broeck</keyname><forenames>Wouter Van den</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Colizza</keyname><forenames>Vittoria</forenames></author><author><keyname>Pinton</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Dynamics of person-to-person interactions from distributed RFID sensor
  networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.HC q-bio.OT</categories><comments>see also http://www.sociopatterns.org</comments><journal-ref>PLoS ONE 5(7): e11596 (2010)</journal-ref><doi>10.1371/journal.pone.0011596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital networks, mobile devices, and the possibility of mining the
ever-increasing amount of digital traces that we leave behind in our daily
activities are changing the way we can approach the study of human and social
interactions. Large-scale datasets, however, are mostly available for
collective and statistical behaviors, at coarse granularities, while
high-resolution data on person-to-person interactions are generally limited to
relatively small groups of individuals. Here we present a scalable experimental
framework for gathering real-time data resolving face-to-face social
interactions with tunable spatial and temporal granularities. We use active
Radio Frequency Identification (RFID) devices that assess mutual proximity in a
distributed fashion by exchanging low-power radio packets. We analyze the
dynamics of person-to-person interaction networks obtained in three
high-resolution experiments carried out at different orders of magnitude in
community size. The data sets exhibit common statistical properties and lack of
a characteristic time scale from 20 seconds to several hours. The association
between the number of connections and their duration shows an interesting
super-linear behavior, which indicates the possibility of defining
super-connectors both in the number and intensity of connections. Taking
advantage of scalability and resolution, this experimental framework allows the
monitoring of social interactions, uncovering similarities in the way
individuals interact in different contexts, and identifying patterns of
super-connector behavior in the community. These results could impact our
understanding of all phenomena driven by face-to-face interactions, such as the
spreading of transmissible infectious diseases and information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3700</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3700</id><created>2010-07-21</created><authors><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Gelfond</keyname><forenames>Gregory</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author></authors><title>Logic Programming for Finding Models in the Logics of Knowledge and its
  Applications: A Case Study</title><categories>cs.AI cs.LO</categories><comments>16 pages, 1 figure, International Conference on Logic Programming
  2010</comments><journal-ref>Theory and Practice of Logic Programming, Volume 10, Special Issue
  4-6, July 2010, pages 675-690</journal-ref><doi>10.1017/S1471068410000359</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The logics of knowledge are modal logics that have been shown to be effective
in representing and reasoning about knowledge in multi-agent domains.
Relatively few computational frameworks for dealing with computation of models
and useful transformations in logics of knowledge (e.g., to support multi-agent
planning with knowledge actions and degrees of visibility) have been proposed.
This paper explores the use of logic programming (LP) to encode interesting
forms of logics of knowledge and compute Kripke models. The LP modeling is
expanded with useful operators on Kripke structures, to support multi-agent
planning in the presence of both world-altering and knowledge actions. This
results in the first ever implementation of a planner for this type of complex
multi-agent domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3706</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3706</id><created>2010-07-21</created><updated>2011-02-05</updated><authors><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Cooperative Convex Optimization in Networked Systems: Augmented
  Lagrangian Algorithms with Directed Gossip Communication</title><categories>cs.IT math.IT</categories><comments>28 pages, journal; revised</comments><doi>10.1109/TSP.2011.2146776</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study distributed optimization in networked systems, where nodes cooperate
to find the optimal quantity of common interest, x=x^\star. The objective
function of the corresponding optimization problem is the sum of private (known
only by a node,) convex, nodes' objectives and each node imposes a private
convex constraint on the allowed values of x. We solve this problem for generic
connected network topologies with asymmetric random link failures with a novel
distributed, decentralized algorithm. We refer to this algorithm as AL-G
(augmented Lagrangian gossiping,) and to its variants as AL-MG (augmented
Lagrangian multi neighbor gossiping) and AL-BG (augmented Lagrangian broadcast
gossiping.) The AL-G algorithm is based on the augmented Lagrangian dual
function. Dual variables are updated by the standard method of multipliers, at
a slow time scale. To update the primal variables, we propose a novel,
Gauss-Seidel type, randomized algorithm, at a fast time scale. AL-G uses
unidirectional gossip communication, only between immediate neighbors in the
network and is resilient to random link failures. For networks with reliable
communication (i.e., no failures,) the simplified, AL-BG (augmented Lagrangian
broadcast gossiping) algorithm reduces communication, computation and data
storage cost. We prove convergence for all proposed algorithms and demonstrate
by simulations the effectiveness on two applications: l_1-regularized logistic
regression for classification and cooperative spectrum sensing for cognitive
radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3708</identifier>
 <datestamp>2011-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3708</id><created>2010-07-21</created><updated>2011-07-01</updated><authors><author><keyname>Galam</keyname><forenames>Serge</forenames></author></authors><title>Tailor Based Allocations for Multiple Authorship: a fractional
  $gh$-index</title><categories>physics.soc-ph cs.DL</categories><comments>Title changed, some parts rewritten, references added. 2 more
  Figures, results unchanged, 23 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quantitative modification to keep the number of published papers invariant
under multiple authorship is suggested. In those cases, fractional allocations
are attributed to each co-author with a summation equal to one. These
allocations are tailored on the basis of each author contribution. It is
denoted &quot;Tailor Based Allocations (TBA)&quot; for multiple authorship. Several
protocols to TBA are suggested. The choice of a specific TBA may vary from one
discipline to another. In addition, TBA is applied to the number of citations
of a multiple author paper to have also this number conserved. Each author gets
only a specific fraction of the total number of citations according to its
fractional paper allocation. The equivalent of the h-index obtained by using
TBA is denoted the gh-index. It yields values which differ drastically from
those given by the h-index. The gh-index departs also from the `h-index
recently proposed by Hirsh to account for multiple authorship. Contrary to the
h-index, the gh-index is a function of the total number of citations of each
paper. A highly cited paper allows a better allocation for all co-authors while
a less cited paper contributes essentially to one or two of the co-authors. The
scheme produces a substantial redistribution of the ranking of scientists in
terms of quantitative records. A few illustrations are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3712</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3712</id><created>2010-07-21</created><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Formal Verification of Self-Assembling Systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the theory and practice of formal verification of
self-assembling systems. We interpret a well-studied abstraction of
nanomolecular self assembly, the Abstract Tile Assembly Model (aTAM), into
Computation Tree Logic (CTL), a temporal logic often used in model checking. We
then consider the class of &quot;rectilinear&quot; tile assembly systems. This class
includes most aTAM systems studied in the theoretical literature, and all
(algorithmic) DNA tile self-assembling systems that have been realized in
laboratories to date. We present a polynomial-time algorithm that, given a tile
assembly system T as input, either provides a counterexample to T's
rectilinearity or verifies whether T has a unique terminal assembly. Using
partial order reductions, the verification search space for this algorithm is
reduced from exponential size to O(n^2), where n x n is the size of the
assembly surface. That reduction is asymptotically the best possible. We report
on experimental results obtained by translating tile assembly simulator files
into a Petri net format manipulable by the SMART model checking engines devised
by Ciardo et al. The model checker runs in O(|T| x n^4) time, where |T| is the
number of tile types in tile assembly system T, and n x n is the surface size.
Atypical for a model checking problem -- in which the practical limit usually
is insufficient memory to store the state space -- the limit in this case was
the amount of memory required to represent the rules of the model. (Storage of
the state space and of the reachability graph were small by comparison.) We
discuss how to overcome this obstacle by means of a front end tailored to the
characteristics of self-assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3726</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3726</id><created>2010-07-21</created><authors><author><keyname>Block</keyname><forenames>Benjamin</forenames></author><author><keyname>Virnau</keyname><forenames>Peter</forenames></author><author><keyname>Preis</keyname><forenames>Tobias</forenames></author></authors><title>Multi-GPU Accelerated Multi-Spin Monte Carlo Simulations of the 2D Ising
  Model</title><categories>physics.comp-ph cs.GR math-ph math.MP</categories><journal-ref>Benjamin Block, Peter Virnau, Tobias Preis, Computer Physics
  Communications 181 (2010) 1549-1556</journal-ref><doi>10.1016/j.cpc.2010.05.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modern graphics processing unit (GPU) is able to perform massively parallel
scientific computations at low cost. We extend our implementation of the
checkerboard algorithm for the two dimensional Ising model [T. Preis et al., J.
Comp. Phys. 228, 4468 (2009)] in order to overcome the memory limitations of a
single GPU which enables us to simulate significantly larger systems. Using
multi-spin coding techniques, we are able to accelerate simulations on a single
GPU by factors up to 35 compared to an optimized single Central Processor Unit
(CPU) core implementation which employs multi-spin coding. By combining the
Compute Unified Device Architecture (CUDA) with the Message Parsing Interface
(MPI) on the CPU level, a single Ising lattice can be updated by a cluster of
GPUs in parallel. For large systems, the computation time scales nearly
linearly with the number of GPUs used. As proof of concept we reproduce the
critical temperature of the 2D Ising model using finite size scaling
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3747</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3747</id><created>2010-07-21</created><authors><author><keyname>Moseley</keyname><forenames>Benjamin</forenames></author></authors><title>Scheduling to Minimize Energy and Flow Time in Broadcast Scheduling</title><categories>cs.DS</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we initiate the study of minimizing power consumption in the
broadcast scheduling model. In this setting there is a wireless transmitter.
Over time requests arrive at the transmitter for pages of information. Multiple
requests may be for the same page. When a page is transmitted, all requests for
that page receive the transmission simulteneously. The speed the transmitter
sends data at can be dynamically scaled to conserve energy. We consider the
problem of minimizing flow time plus energy, the most popular scheduling metric
considered in the standard scheduling model when the scheduler is energy aware.
We will assume that the power consumed is modeled by an arbitrary convex
function. For this problem there is a $\Omega(n)$ lower bound. Due to the lower
bound, we consider the resource augmentation model of Gupta \etal
\cite{GuptaKP10}. Using resource augmentation, we give a scalable algorithm.
Our result also gives a scalable non-clairvoyant algorithm for minimizing
weighted flow time plus energy in the standard scheduling model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3753</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3753</id><created>2010-07-21</created><updated>2012-08-26</updated><authors><author><keyname>Yang</keyname><forenames>Allen Y.</forenames></author><author><keyname>Zhou</keyname><forenames>Zihan</forenames></author><author><keyname>Ganesh</keyname><forenames>Arvind</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Fast L1-Minimization Algorithms For Robust Face Recognition</title><categories>cs.CV cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  L1-minimization refers to finding the minimum L1-norm solution to an
underdetermined linear system b=Ax. Under certain conditions as described in
compressive sensing theory, the minimum L1-norm solution is also the sparsest
solution. In this paper, our study addresses the speed and scalability of its
algorithms. In particular, we focus on the numerical implementation of a
sparsity-based classification framework in robust face recognition, where
sparse representation is sought to recover human identities from very
high-dimensional facial images that may be corrupted by illumination, facial
disguise, and pose variation. Although the underlying numerical problem is a
linear program, traditional algorithms are known to suffer poor scalability for
large-scale applications. We investigate a new solution based on a classical
convex optimization framework, known as Augmented Lagrangian Methods (ALM). The
new convex solvers provide a viable solution to real-world, time-critical
applications such as face recognition. We conduct extensive experiments to
validate and compare the performance of the ALM algorithms against several
popular L1-minimization solvers, including interior-point method, Homotopy,
FISTA, SESOP-PCD, approximate message passing (AMP) and TFOCS. To aid peer
evaluation, the code for all the algorithms has been made publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3760</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3760</id><created>2010-07-21</created><authors><author><keyname>Karra</keyname><forenames>Satish</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>Development of three dimensional constitutive theories based on lower
  dimensional experimental data</title><categories>cs.NA math-ph math.MP physics.flu-dyn</categories><comments>23 pages, 6 figures</comments><msc-class>76A02, 76A05, 76A10, 74D10, 74A15, 74A20</msc-class><journal-ref>Appl. Math. 54 (2009) 147-176</journal-ref><doi>10.1007/s10492-009-0010-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most three dimensional constitutive relations that have been developed to
describe the behavior of bodies are correlated against one dimensional and two
dimensional experiments. What is usually lost sight of is the fact that
infinity of such three dimensional models may be able to explain these
experiments that are lower dimensional. Recently, the notion of maximization of
the rate of entropy production has been used to obtain constitutive relations
based on the choice of the stored energy and rate of entropy production, etc.
In this paper we show different choices for the manner in which the body stores
energy and dissipates energy and satisfies the requirement of maximization of
the rate of entropy production that leads to many three dimensional models. All
of these models, in one dimension, reduce to the model proposed by Burgers to
describe the viscoelastic behavior of bodies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3764</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3764</id><created>2010-07-21</created><authors><author><keyname>Karra</keyname><forenames>Satish</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>A thermodynamic framework to develop rate-type models for fluids without
  instantaneous elasticity</title><categories>cs.NA math-ph math.MP physics.flu-dyn</categories><comments>18 pages, 5 figures</comments><journal-ref>Acta Mech. 205(1-4) (2009) 105-119</journal-ref><doi>10.1007/s00707-009-0167-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply the thermodynamic framework recently put into place
by Rajagopal and co-workers, to develop rate-type models for viscoelastic
fluids which do not possess instantaneous elasticity. To illustrate the
capabilities of such models we make a specific choice for the specific
Helmholtz potential and the rate of dissipation and consider the creep and
stress relaxation response associated with the model. Given specific forms for
the Helmholtz potential and the rate of dissipation, the rate of dissipation is
maximized with the constraint that the difference between the stress power and
the rate of change of Helmholtz potential is equal to the rate of dissipation
and any other constraint that may be applicable such as incompressibility. We
show that the model that is developed exhibits fluid-like characteristics and
is incapable of instantaneous elastic response. It also includes Maxwell-like
and Kelvin-Voigt-like viscoelastic materials (when certain material moduli take
special values).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3769</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3769</id><created>2010-07-21</created><updated>2010-09-16</updated><authors><author><keyname>Silva</keyname><forenames>Alexandra</forenames><affiliation>CWI</affiliation></author><author><keyname>Bonsangue</keyname><forenames>Marcello</forenames><affiliation>LIACS, Leiden University</affiliation></author><author><keyname>Rutten</keyname><forenames>Jan</forenames><affiliation>CWI, VUA + RUN</affiliation></author></authors><title>Non-Deterministic Kleene Coalgebras</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.1, F.3.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  9, 2010) lmcs:695</journal-ref><doi>10.2168/LMCS-6(3:23)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a systematic way of deriving (1) languages of
(generalised) regular expressions, and (2) sound and complete axiomatizations
thereof, for a wide variety of systems. This generalizes both the results of
Kleene (on regular languages and deterministic finite automata) and Milner (on
regular behaviours and finite labelled transition systems), and includes many
other systems such as Mealy and Moore machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3772</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3772</id><created>2010-07-21</created><authors><author><keyname>O'Hara</keyname><forenames>Stephen</forenames></author></authors><title>Video Event Recognition for Surveillance Applications (VERSA)</title><categories>cs.CV</categories><comments>Master's Thesis, University of Nebraska at Omaha, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  VERSA provides a general-purpose framework for defining and recognizing
events in live or recorded surveillance video streams. The approach for event
recognition in VERSA is using a declarative logic language to define the
spatial and temporal relationships that characterize a given event or activity.
Doing so requires the definition of certain fundamental spatial and temporal
relationships and a high-level syntax for specifying frame templates and query
parameters. Although the handling of uncertainty in the current VERSA
implementation is simplistic, the language and architecture is amenable to
extending using Fuzzy Logic or similar approaches. VERSA's high-level
architecture is designed to work in XML-based, services- oriented environments.
VERSA can be thought of as subscribing to the XML annotations streamed by a
lower-level video analytics service that provides basic entity detection,
labeling, and tracking. One or many VERSA Event Monitors could thus analyze
video streams and provide alerts when certain events are detected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3781</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3781</id><created>2010-07-21</created><authors><author><keyname>Meliou</keyname><forenames>Alexandra</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames></author><author><keyname>Hellerstein</keyname><forenames>Joseph M.</forenames></author></authors><title>Multiresolution Cube Estimators for Sensor Network Aggregate Queries</title><categories>cs.DB</categories><comments>14 pages, 8 figures, IV Alberto Mendelzon Workshop on Foundations of
  Data Management</comments><journal-ref>IV Alberto Mendelzon Workshop on Foundations of Data Management,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present in-network techniques to improve the efficiency of
spatial aggregate queries. Such queries are very common in a sensornet setting,
demanding more targeted techniques for their handling. Our approach constructs
and maintains multi-resolution cube hierarchies inside the network, which can
be constructed in a distributed fashion. In case of failures, recovery can also
be performed with in-network decisions. In this paper we demonstrate how
in-network cube hierarchies can be used to summarize sensor data, and how they
can be exploited to improve the efficiency of spatial aggregate queries. We
show that query plans over our cube summaries can be computed in polynomial
time, and we present a PTIME algorithm that selects the minimum number of data
requests that can compute the answer to a spatial query. We further extend our
algorithm to handle optimization over multiple queries, which can also be done
in polynomial time. We discuss enriching cube hierarchies with extra summary
information, and present an algorithm for distributed cube construction.
Finally we investigate node and area failures, and algorithms to recover query
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3794</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3794</id><created>2010-07-21</created><authors><author><keyname>Dixon</keyname><forenames>Lucas</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Duncan</keyname><forenames>Ross</forenames><affiliation>University of Oxford</affiliation></author><author><keyname>Kissinger</keyname><forenames>Aleks</forenames><affiliation>University of Oxford</affiliation></author></authors><title>Open Graphs and Computational Reasoning</title><categories>cs.LO cs.MS cs.SC</categories><comments>In Proceedings DCM 2010, arXiv:1006.1937</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 26, 2010, pp. 169-180</journal-ref><doi>10.4204/EPTCS.26.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a form of algebraic reasoning for computational objects which are
expressed as graphs. Edges describe the flow of data between primitive
operations which are represented by vertices. These graphs have an interface
made of half-edges (edges which are drawn with an unconnected end) and enjoy
rich compositional principles by connecting graphs along these half-edges. In
particular, this allows equations and rewrite rules to be specified between
graphs. Particular computational models can then be encoded as an axiomatic set
of such rules. Further rules can be derived graphically and rewriting can be
used to simulate the dynamics of a computational system, e.g. evaluating a
program on an input. Examples of models which can be formalised in this way
include traditional electronic circuits as well as recent categorical accounts
of quantum information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3799</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3799</id><created>2010-07-22</created><authors><author><keyname>Syed</keyname><forenames>Umar</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author><author><keyname>Mishra</keyname><forenames>Nina</forenames></author></authors><title>Adapting to the Shifting Intent of Search Queries</title><categories>cs.LG</categories><comments>This is the full version of the paper in NIPS'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search engines today present results that are often oblivious to abrupt
shifts in intent. For example, the query `independence day' usually refers to a
US holiday, but the intent of this query abruptly changed during the release of
a major film by that name. While no studies exactly quantify the magnitude of
intent-shifting traffic, studies suggest that news events, seasonal topics, pop
culture, etc account for 50% of all search queries. This paper shows that the
signals a search engine receives can be used to both determine that a shift in
intent has happened, as well as find a result that is now more relevant. We
present a meta-algorithm that marries a classifier with a bandit algorithm to
achieve regret that depends logarithmically on the number of query impressions,
under certain assumptions. We provide strong evidence that this regret is close
to the best achievable. Finally, via a series of experiments, we demonstrate
that our algorithm outperforms prior approaches, particularly as the amount of
intent-shifting traffic increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3801</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3801</id><created>2010-07-22</created><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>On the Approximability of Budget Feasible Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Budget feasible mechanisms, recently initiated by Singer (FOCS 2010), extend
algorithmic mechanism design problems to a realistic setting with a budget
constraint. We consider the problem of designing truthful budget feasible
mechanisms for general submodular functions: we give a randomized mechanism
with approximation ratio $7.91$ (improving the previous best-known result 112),
and a deterministic mechanism with approximation ratio $8.34$. Further we study
the knapsack problem, which is special submodular function, give a $2+\sqrt{2}$
approximation deterministic mechanism (improving the previous best-known result
6), and a 3 approximation randomized mechanism. We provide a similar result for
an extended knapsack problem with heterogeneous items, where items are divided
into groups and one can pick at most one item from each group.
  Finally we show a lower bound of approximation ratio of $1+\sqrt{2}$ for
deterministic mechanisms and 2 for randomized mechanisms for knapsack, as well
as the general submodular functions. Our lower bounds are unconditional, which
do not rely on any computational or complexity assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3804</identifier>
 <datestamp>2012-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3804</id><created>2010-07-22</created><updated>2011-10-25</updated><authors><author><keyname>Grenet</keyname><forenames>Bruno</forenames><affiliation>LIP</affiliation></author><author><keyname>Kaltofen</keyname><forenames>Erich</forenames><affiliation>LIP</affiliation></author><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author><author><keyname>Portier</keyname><forenames>Natacha</forenames><affiliation>LIP</affiliation></author></authors><title>Symmetric Determinantal Representation of Formulas and Weakly Skew
  Circuits</title><categories>cs.CC cs.SC</categories><comments>To appear in the AMS Contemporary Mathematics volume on
  Randomization, Relaxation, and Complexity in Polynomial Equation Solving,
  edited by Gurvits, Pebay, Rojas and Thompson</comments><proxy>ccsd</proxy><report-no>RRLIP2010-24</report-no><journal-ref>Randomization, Relaxation, and Complexity in Polynomial Equation
  Solving, Amer. Math. Soc. (Ed.) (2011) 61-96</journal-ref><doi>10.1090/conm/556</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deploy algebraic complexity theoretic techniques for constructing
symmetric determinantal representations of for00504925mulas and weakly skew
circuits. Our representations produce matrices of much smaller dimensions than
those given in the convex geometry literature when applied to polynomials
having a concise representation (as a sum of monomials, or more generally as an
arithmetic formula or a weakly skew circuit). These representations are valid
in any field of characteristic different from 2. In characteristic 2 we are led
to an almost complete solution to a question of B\&quot;urgisser on the
VNP-completeness of the partial permanent. In particular, we show that the
partial permanent cannot be VNP-complete in a finite field of characteristic 2
unless the polynomial hierarchy collapses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3808</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3808</id><created>2010-07-22</created><authors><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author></authors><title>Characterization of Graph-cover Pseudocodewords of Codes over $F_3$</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented in ITW 2010, Dublin, Ireland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear-programming pseudocodewords play a pivotal role in our understanding
of the linear-programming decoding algorithms. These pseudocodewords are known
to be equivalent to the graph-cover pseudocodewords. The latter
pseudocodewords, when viewed as points in the multidimensional Euclidean space,
lie inside a fundamental cone. This fundamental cone depends on the choice of a
parity-check matrix of a code, rather than on the choice of the code itself.
The cone does not depend on the channel, over which the code is employed. The
knowledge of the boundaries of the fundamental cone could help in studying
various properties of the pseudocodewords, such as their minimum pseudoweight,
pseudoredundancy of the codes, etc. For the binary codes, the full
characterization of the fundamental cone was derived by Koetter et al. However,
if the underlying alphabet is large, such characterization becom is more
involved. In this work, a characterization of the fundamental cone for codes
over $F_3$ is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3819</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3819</id><created>2010-07-22</created><authors><author><keyname>Ping</keyname><forenames>Hou</forenames></author><author><keyname>De Cat</keyname><forenames>Broes</forenames></author><author><keyname>Denecker</keyname><forenames>Marc</forenames></author></authors><title>FO(FD): Extending classical logic with rule-based fixpoint definitions</title><categories>cs.LO</categories><comments>Presented at ICLP 2010. 16 pages, 1 figure</comments><msc-class>68T27</msc-class><acm-class>I.2.4; F.4.3</acm-class><journal-ref>Theory and Practice of Logic Programming, Volume 10, Special Issue
  4-6, July 2010, pp 581-596</journal-ref><doi>10.1017/S1471068410000293</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce fixpoint definitions, a rule-based reformulation of fixpoint
constructs. The logic FO(FD), an extension of classical logic with fixpoint
definitions, is defined. We illustrate the relation between FO(FD) and FO(ID),
which is developed as an integration of two knowledge representation paradigms.
The satisfiability problem for FO(FD) is investigated by first reducing FO(FD)
to difference logic and then using solvers for difference logic. These
reductions are evaluated in the computation of models for FO(FD) theories
representing fairness conditions and we provide potential applications of
FO(FD).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3829</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3829</id><created>2010-07-22</created><authors><author><keyname>Betz</keyname><forenames>Hariolf</forenames></author><author><keyname>Raiser</keyname><forenames>Frank</forenames></author><author><keyname>Fr&#xfc;hwirth</keyname><forenames>Thom</forenames></author></authors><title>A Complete and Terminating Execution Model for Constraint Handling Rules</title><categories>cs.LO</categories><comments>15 pages</comments><journal-ref>Theory and Practice of Logic Programming, Volume 10, Special Issue
  4-6, July 2010, pp 597-610</journal-ref><doi>10.1017/S147106841000030X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We observe that the various formulations of the operational semantics of
Constraint Handling Rules proposed over the years fall into a spectrum ranging
from the analytical to the pragmatic. While existing analytical formulations
facilitate program analysis and formal proofs of program properties, they
cannot be implemented as is. We propose a novel operational semantics, which
has a strong analytical foundation, while featuring a terminating execution
model. We prove its soundness and completeness with respect to existing
analytical formulations and we provide an implementation in the form of a
source-to-source transformation to CHR with rule priorities.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="14000" completeListSize="102538">1122234|15001</resumptionToken>
</ListRecords>
</OAI-PMH>
