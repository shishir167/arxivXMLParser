<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:57:02Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|28001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4743</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4743</id><created>2012-01-23</created><authors><author><keyname>Das</keyname><forenames>Sreejith</forenames></author><author><keyname>Rezek</keyname><forenames>Iead</forenames></author></authors><title>Voting Power : A Generalised Framework</title><categories>math.ST cs.CY cs.GT cs.MA stat.OT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines an area of Game Theory called Voting Power Theory. With
the adoption of a measure theoretic framework it argues that the many different
indices and tools currently used for measuring voting power can be replaced by
just three simple probabilities. The framework is sufficiently general to be
applicable to every conceivable type of voting game, and every possible
decision rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4754</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4754</id><created>2012-01-23</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Brandl</keyname><forenames>Florian</forenames></author></authors><title>Existence of Stability in Hedonic Coalition Formation Games</title><categories>cs.GT</categories><msc-class>91A12, 68Q15</msc-class><acm-class>F.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we examine \emph{hedonic coalition formation games} in which
each player's preferences over partitions of players depend only on the members
of his coalition. We present three main results in which restrictions on the
preferences of the players guarantee the existence of stable partitions for
various notions of stability. The preference restrictions pertain to \emph{top
responsiveness} and \emph{bottom responsiveness} which model optimistic and
pessimistic behavior of players respectively. The existence results apply to
natural subclasses of \emph{additive separable hedonic games} and \emph{hedonic
games with \B-preferences}. It is also shown that our existence results cannot
be strengthened to the case of stronger known stability concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4764</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4764</id><created>2012-01-23</created><authors><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>Matroid Prophet Inequalities</title><categories>cs.DS cs.GT math.PR</categories><comments>18 pages</comments><acm-class>F.1.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a gambler who observes a sequence of independent, non-negative
random numbers and is allowed to stop the sequence at any time, claiming a
reward equal to the most recent observation. The famous prophet inequality of
Krengel, Sucheston, and Garling asserts that a gambler who knows the
distribution of each random variable can achieve at least half as much reward,
in expectation, as a &quot;prophet&quot; who knows the sampled values of each random
variable and can choose the largest one. We generalize this result to the
setting in which the gambler and the prophet are allowed to make more than one
selection, subject to a matroid constraint. We show that the gambler can still
achieve at least half as much reward as the prophet; this result is the best
possible, since it is known that the ratio cannot be improved even in the
original prophet inequality, which corresponds to the special case of rank-one
matroids. Generalizing the result still further, we show that under an
intersection of p matroid constraints, the prophet's reward exceeds the
gambler's by a factor of at most O(p), and this factor is also tight.
  Beyond their interest as theorems about pure online algorithms or optimal
stopping rules, these results also have applications to mechanism design. Our
results imply improved bounds on the ability of sequential posted-price
mechanisms to approximate Bayesian optimal mechanisms in both single-parameter
and multi-parameter settings. In particular, our results imply the first
efficiently computable constant-factor approximations to the Bayesian optimal
revenue in certain multi-parameter settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4766</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4766</id><created>2012-01-23</created><authors><author><keyname>Jacobo</keyname><forenames>Adrian</forenames></author><author><keyname>Gomila</keyname><forenames>Damia</forenames></author><author><keyname>Matias</keyname><forenames>Manuel A.</forenames></author><author><keyname>Colet</keyname><forenames>Pere</forenames></author></authors><title>Logical operations with Localized Structures</title><categories>nlin.PS cs.OH physics.optics</categories><comments>11 pages, 6 figures</comments><journal-ref>New. J. Phys. 14, 013040 (1-9) (2012)</journal-ref><doi>10.1088/1367-2630/14/1/013040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to exploit excitable regimes mediated by localized structures
(LS) to perform AND, OR, and NOT logical operations providing full logical
functionality. Our scheme is general and can be implemented in any physical
system displaying LS. In particular, LS in nonlinear photonic devices can be
used for all-optical computing applications where several reconfigurable logic
gates can be implemented in the transverse plane of a single device, allowing
for parallel computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4768</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4768</id><created>2012-01-23</created><authors><author><keyname>Sorour</keyname><forenames>Sameh</forenames></author><author><keyname>Valaee</keyname><forenames>Shahrokh</forenames></author></authors><title>Completion Delay Minimization for Instantly Decodable Network Codes</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of minimizing the completion delay for
instantly decodable network coding (IDNC), in wireless multicast and broadcast
scenarios. We are interested in this class of network coding due to its
numerous benefits, such as low decoding delay, low coding and decoding
complexities and simple receiver requirements. We first extend the IDNC graph,
which represents all feasible IDNC coding opportunities, to efficiently operate
in both multicast and broadcast scenarios. We then formulate the minimum
completion delay problem for IDNC as a stochastic shortest path (SSP) problem.
Although finding the optimal policy using SSP is intractable, we use this
formulation to draw the theoretical guidelines for the policies that can
efficiently reduce the completion delay in IDNC. Based on these guidelines, we
design a maximum weight clique selection algorithm, which can efficiently
reduce the IDNC completion delay in polynomial time. We also design a quadratic
time heuristic clique selection algorithm, which can operate in real-time
applications. Simulation results show that our proposed algorithms efficiently
reduce the IDNC completion delay compared to the random and maximum-rate
algorithms, and almost achieve the global optimal completion delay performance
over all network codes in broadcast scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4777</identifier>
 <datestamp>2013-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4777</id><created>2012-01-23</created><updated>2013-02-28</updated><authors><author><keyname>Romero</keyname><forenames>Alfonso E.</forenames></author><author><keyname>de Campos</keyname><forenames>Luis M.</forenames></author></authors><title>A probabilistic methodology for multilabel classification</title><categories>cs.AI cs.LG</categories><comments>14 pages, 1 figure, under review</comments><msc-class>68T37, 68T10</msc-class><acm-class>I.2.6; I.2.3; H.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilabel classification is a relatively recent subfield of machine
learning. Unlike to the classical approach, where instances are labeled with
only one category, in multilabel classification, an arbitrary number of
categories is chosen to label an instance. Due to the problem complexity (the
solution is one among an exponential number of alternatives), a very common
solution (the binary method) is frequently used, learning a binary classifier
for every category, and combining them all afterwards. The assumption taken in
this solution is not realistic, and in this work we give examples where the
decisions for all the labels are not taken independently, and thus, a
supervised approach should learn those existing relationships among categories
to make a better classification. Therefore, we show here a generic methodology
that can improve the results obtained by a set of independent probabilistic
binary classifiers, by using a combination procedure with a classifier trained
on the co-occurrences of the labels. We show an exhaustive experimentation in
three different standard corpora of labeled documents (Reuters-21578,
Ohsumed-23 and RCV1), which present noticeable improvements in all of them,
when using our methodology, in three probabilistic base classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4779</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4779</id><created>2012-01-23</created><authors><author><keyname>Flagg</keyname><forenames>Garret M.</forenames></author><author><keyname>Gugercin</keyname><forenames>Serkan</forenames></author></authors><title>On the ADI method for the Sylvester Equation and the
  optimal-$\mathcal{H}_2$ points</title><categories>math.NA cs.SY</categories><journal-ref>Applied Numerical Mathematics, 64 (2013) 50-58</journal-ref><doi>10.1016/j.apnum.2012.10.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ADI iteration is closely related to the rational Krylov projection
methods for constructing low rank approximations to the solution of Sylvester
equation. In this paper we show that the ADI and rational Krylov approximations
are in fact equivalent when a special choice of shifts are employed in both
methods. We will call these shifts pseudo H2-optimal shifts. These shifts are
also optimal in the sense that for the Lyapunov equation, they yield a residual
which is orthogonal to the rational Krylov projection subspace. Via several
examples, we show that the pseudo H2-optimal shifts consistently yield nearly
optimal low rank approximations to the solutions of the Lyapunov equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4787</identifier>
 <datestamp>2012-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4787</id><created>2012-01-23</created><authors><author><keyname>Son</keyname><forenames>Seung-Woo</forenames></author><author><keyname>Christensen</keyname><forenames>Claire</forenames></author><author><keyname>Grassberger</keyname><forenames>Peter</forenames></author><author><keyname>Paczuski</keyname><forenames>Maya</forenames></author></authors><title>PageRank and rank-reversal dependence on the damping factor</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>14 pages, 9 figures</comments><journal-ref>Phys. Rev. E 86, 066104 (2012)</journal-ref><doi>10.1103/PhysRevE.86.066104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PageRank (PR) is an algorithm originally developed by Google to evaluate the
importance of web pages. Considering how deeply rooted Google's PR algorithm is
to gathering relevant information or to the success of modern businesses, the
question of rank-stability and choice of the damping factor (a parameter in the
algorithm) is clearly important. We investigate PR as a function of the damping
factor d on a network obtained from a domain of the World Wide Web, finding
that rank-reversal happens frequently over a broad range of PR (and of d). We
use three different correlation measures, Pearson, Spearman, and Kendall, to
study rank-reversal as d changes, and show that the correlation of PR vectors
drops rapidly as d changes from its frequently cited value, $d_0=0.85$.
Rank-reversal is also observed by measuring the Spearman and Kendall rank
correlation, which evaluate relative ranks rather than absolute PR.
Rank-reversal happens not only in directed networks containing rank-sinks but
also in a single strongly connected component, which by definition does not
contain any sinks. We relate rank-reversals to rank-pockets and bottlenecks in
the directed network structure. For the network studied, the relative rank is
more stable by our measures around $d=0.65$ than at $d=d_0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4788</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4788</id><created>2012-01-23</created><authors><author><keyname>Mighell</keyname><forenames>Kenneth J.</forenames></author></authors><title>Benchmarking CRBLASTER on the 350-MHz 49-core Maestro Development Board</title><categories>astro-ph.IM cs.DC</categories><comments>10 pages, 3 figures. To appear in the ADASS XXI (Paris, 2011)
  conference proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I describe the performance of the CRBLASTER computational framework on a
350-MHz 49-core Maestro Development Board (MDB). The 49-core Interim Test Chip
(ITC) was developed by the U.S. Government and is based on the intellectual
property of the 64-core TILE64 processor of the Tilera Corporation. The Maestro
processor is intended for use in the high radiation environments found in
space; the ITC was fabricated using IBM 90-nm CMOS 9SF technology and
Radiation-Hardening-by-Design (RHDB) rules. CRBLASTER is a parallel-processing
cosmic-ray rejection application based on a simple computational framework that
uses the high-performance computing industry standard Message Passing Interface
(MPI) library. CRBLASTER was designed to be used by research scientists to
easily port image-analysis programs based on embarrassingly-parallel algorithms
to a parallel-processing environment such as a multi-node Beowulf cluster or
multi-core processors using MPI. I describe my experience of porting CRBLASTER
to the 64-core TILE64 processor, the Maestro simulator, and finally the 49-core
Maestro processor itself. Performance comparisons using the ITC are presented
between emulating all floating-point operations in software and doing all
floating point operations with hardware assist from an IEEE-754 compliant
Aurora FPU (floating point unit) that is attached to each of the 49 cores.
Benchmarking of the CRBLASTER computational framework using the
memory-intensive L.A.COSMIC cosmic ray rejection algorithm and a
computational-intensive Poisson noise generator reveal subtleties of the
Maestro hardware design. Lastly, I describe the importance of using real
scientific applications during the testing phase of next-generation computer
hardware; complex real-world scientific applications can stress hardware in
novel ways that may not necessarily be revealed while executing simple
applications or unit tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4793</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4793</id><created>2012-01-23</created><authors><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>De Leonardis</keyname><forenames>Dario</forenames></author><author><keyname>Graziosi</keyname><forenames>Fabio</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Space Shift Keying (SSK-) MIMO with Practical Channel Estimates</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Communications (to appear, 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the performance of space modulation for
Multiple-Input-Multiple-Output (MIMO) wireless systems with imperfect channel
knowledge at the receiver. We focus our attention on two transmission
technologies, which are the building blocks of space modulation: i) Space Shift
Keying (SSK) modulation; and ii) Time-Orthogonal-Signal-Design (TOSD-) SSK
modulation, which is an improved version of SSK modulation providing
transmit-diversity. We develop a single-integral closed-form analytical
framework to compute the Average Bit Error Probability (ABEP) of a mismatched
detector for both SSK and TOSD-SSK modulations. The framework exploits the
theory of quadratic-forms in conditional complex Gaussian Random Variables
(RVs) along with the Gil-Pelaez inversion theorem. The analytical model is very
general and can be used for arbitrary transmit- and receive-antennas, fading
distributions, fading spatial correlations, and training pilots. The analytical
derivation is substantiated through Monte Carlo simulations, and it is shown,
over independent and identically distributed (i.i.d.) Rayleigh fading channels,
that SSK modulation is as robust as single-antenna systems to imperfect channel
knowledge, and that TOSD-SSK modulation is more robust to channel estimation
errors than the Alamouti scheme. Furthermore, it is pointed out that only few
training pilots are needed to get reliable enough channel estimates for data
detection, and that transmit- and receive-diversity of SSK and TOSD-SSK
modulations are preserved even with imperfect channel knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4801</identifier>
 <datestamp>2014-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4801</id><created>2012-01-23</created><updated>2012-03-12</updated><authors><author><keyname>Pierre-Evariste</keyname><forenames>Dagand</forenames></author><author><keyname>Conor</keyname><forenames>McBride</forenames></author></authors><title>Transporting Functions across Ornaments</title><categories>cs.PL</categories><doi>10.1017/S0956796814000069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Programming with dependent types is a blessing and a curse. It is a blessing
to be able to bake invariants into the definition of data-types: we can finally
write correct-by-construction software. However, this extreme accuracy is also
a curse: a data-type is the combination of a structuring medium together with a
special purpose logic. These domain-specific logics hamper any effort of code
reuse among similarly structured data.
  In this paper, we exorcise our data-types by adapting the notion of ornament
to our universe of inductive families. We then show how code reuse can be
achieved by ornamenting functions. Using these functional ornament, we capture
the relationship between functions such as the addition of natural numbers and
the concatenation of lists. With this knowledge, we demonstrate how the
implementation of the former informs the implementation of the latter: the user
can ask the definition of addition to be lifted to lists and she will only be
asked the details necessary to carry on adding lists rather than numbers.
  Our presentation is formalised in a type theory with a universe of data-types
and all our constructions have been implemented as generic programs, requiring
no extension to the type theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4856</identifier>
 <datestamp>2013-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4856</id><created>2012-01-23</created><updated>2013-03-31</updated><authors><author><keyname>Bauer</keyname><forenames>Matthew S.</forenames></author></authors><title>A PSPACE-Complete First Order Fragment of Computability Logic</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recently launched research program for developing logic as a formal
theory of (interactive) computability, several very interesting logics have
been introduced and axiomatized. These fragments of the larger Computability
Logic aim not only to describe &quot;what&quot; can be computed, but also provide a
mechanism for extracting computational algorithms from proofs. Among the most
expressive and fundamental of these is CL4, known to be (constructively) sound
and complete with respect to the underlying computational semantics.
Furthermore, the fragment of CL4 not containing blind quantifiers was shown to
be decidable in polynomial space. The present work extends this result and
proves that this fragment is, in fact, PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4871</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4871</id><created>2012-01-23</created><updated>2012-10-17</updated><authors><author><keyname>Geeraerts</keyname><forenames>Gilles</forenames></author><author><keyname>Heu&#xdf;ner</keyname><forenames>Alexander</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Queue-Dispatch Asynchronous Systems</title><categories>cs.LO cs.DC</categories><comments>38 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To make the development of efficient multi-core applications easier,
libraries, such as Grand Central Dispatch, have been proposed. When using such
a library, the programmer writes so-called blocks, which are chunks of codes,
and dispatches them, using synchronous or asynchronous calls, to several types
of waiting queues. A scheduler is then responsible for dispatching those blocks
on the available cores. Blocks can synchronize via a global memory. In this
paper, we propose Queue-Dispatch Asynchronous Systems as a mathematical model
that faithfully formalizes the synchronization mechanisms and the behavior of
the scheduler in those systems. We study in detail their relationships to
classical formalisms such as pushdown systems, Petri nets, fifo systems, and
counter systems. Our main technical contributions are precise worst-case
complexity results for the Parikh coverability problem for several subclasses
of our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4895</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4895</id><created>2012-01-23</created><updated>2013-06-26</updated><authors><author><keyname>Sankaranarayanan</keyname><forenames>Aswin C</forenames></author><author><keyname>Turaga</keyname><forenames>Pavan K</forenames></author><author><keyname>Chellappa</keyname><forenames>Rama</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G</forenames></author></authors><title>Compressive Acquisition of Dynamic Scenes</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) is a new approach for the acquisition and recovery
of sparse signals and images that enables sampling rates significantly below
the classical Nyquist rate. Despite significant progress in the theory and
methods of CS, little headway has been made in compressive video acquisition
and recovery. Video CS is complicated by the ephemeral nature of dynamic
events, which makes direct extensions of standard CS imaging architectures and
signal models difficult. In this paper, we develop a new framework for video CS
for dynamic textured scenes that models the evolution of the scene as a linear
dynamical system (LDS). This reduces the video recovery problem to first
estimating the model parameters of the LDS from compressive measurements, and
then reconstructing the image frames. We exploit the low-dimensional dynamic
parameters (the state sequence) and high-dimensional static parameters (the
observation matrix) of the LDS to devise a novel compressive measurement
strategy that measures only the dynamic part of the scene at each instant and
accumulates measurements over time to estimate the static parameters. This
enables us to lower the compressive measurement rate considerably. We validate
our approach with a range of experiments involving both video recovery, sensing
hyper-spectral data, and classification of dynamic scenes from compressive
data. Together, these applications demonstrate the effectiveness of the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4897</identifier>
 <datestamp>2012-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4897</id><created>2012-01-23</created><updated>2012-10-30</updated><authors><author><keyname>Gibson</keyname><forenames>Travis E.</forenames></author><author><keyname>Annaswamy</keyname><forenames>Anuradha M.</forenames></author><author><keyname>Lavretsky</keyname><forenames>Eugene</forenames></author></authors><title>Adaptive Systems with Closed-loop Reference Models: Stability,
  Robustness and Transient Performance</title><categories>math.OC cs.SY nlin.AO</categories><comments>16 pages. v2: submission to IEEE CDC 2012, v3: Typos corrected in
  section IV, v4: expanded paper to CMRAC, v5 Typos corrected, v6 Submitted to
  Transactions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the properties of adaptive systems with closed-loop
reference models. Using additional design freedom available in closed-loop
reference models, we design new adaptive controllers that are (a) stable, and
(b) have improved transient properties. Numerical studies that complement
theoretical derivations are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4899</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4899</id><created>2012-01-23</created><updated>2012-02-29</updated><authors><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Finding Endogenously Formed Communities</title><categories>cs.DS</categories><comments>22 pages</comments><acm-class>F.2.0; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in e-commerce is determining overlapping communities among
individuals or objects in the absence of external identification or tagging. We
address this problem by introducing a framework that captures the notion of
communities or clusters determined by the relative affinities among their
members. To this end we define what we call an affinity system, which is a set
of elements, each with a vector characterizing its preference for all other
elements in the set. We define a natural notion of (potentially overlapping)
communities in an affinity system, in which the members of a given community
collectively prefer each other to anyone else outside the community. Thus these
communities are endogenously formed in the affinity system and are
&quot;self-determined&quot; or &quot;self-certified&quot; by its members.
  We provide a tight polynomial bound on the number of self-determined
communities as a function of the robustness of the community. We present a
polynomial-time algorithm for enumerating these communities. Moreover, we
obtain a local algorithm with a strong stochastic performance guarantee that
can find a community in time nearly linear in the of size the community.
  Social networks fit particularly naturally within the affinity system
framework -- if we can appropriately extract the affinities from the relatively
sparse yet rich information from social networks, our analysis then yields a
set of efficient algorithms for enumerating self-determined communities in
social networks. In the context of social networks we also connect our analysis
with results about $(\alpha,\beta)$-clusters introduced by Mishra, Schreiber,
Stanton, and Tarjan \cite{msst}. In contrast with the polynomial bound we prove
on the number of communities in the affinity system model, we show that there
exists a family of networks with superpolynomial number of
$(\alpha,\beta)$-clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4903</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4903</id><created>2012-01-23</created><authors><author><keyname>Rangarajan</keyname><forenames>Ramsharan</forenames></author><author><keyname>Lew</keyname><forenames>Adrian J.</forenames></author></authors><title>Universal Meshes: A new paradigm for computing with nonconforming
  triangulations</title><categories>math.NA cs.CG</categories><msc-class>65N30, 68U05, 65M50, 65N50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a method for discretizing planar C2-regular domains immersed in
non-conforming triangulations. The method consists in constructing mappings
from triangles in a background mesh to curvilinear ones that conform exactly to
the immersed domain. Constructing such a map relies on a novel way of
parameterizing the immersed boundary over a collection of nearby edges with its
closest point projection. By interpolating the mappings to curvilinear
triangles at select points, we recover isoparametric mappings for the immersed
domain defined over the background mesh. Indeed, interpolating the constructed
mappings just at the vertices of the background mesh yields a fast meshing
algorithm that involves only perturbing a few vertices near the boundary.
  For the discretization of a curved domain to be robust, we have to impose
restrictions on the background mesh. Conversely, these restrictions define a
family of domains that can be discretized with a given background mesh. We then
say that the background mesh is a universal mesh for such a family of domains.
The notion of universal meshes is particularly useful in free/moving boundary
problems because the same background mesh can serve as the universal mesh for
the evolving domain for time intervals that are independent of the time step.
Hence it facilitates a framework for finite element calculations over evolving
domains while using a fixed background mesh. Furthermore, since the evolving
geometry can be approximated with any desired order, numerical solutions can be
computed with high-order accuracy. We demonstrate these ideas with various
numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4906</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4906</id><created>2012-01-23</created><authors><author><keyname>Liu</keyname><forenames>Keqin</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Adaptive Shortest-Path Routing under Unknown and Stochastically Varying
  Link States</title><categories>cs.NI cs.LG</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the adaptive shortest-path routing problem in wireless networks
under unknown and stochastically varying link states. In this problem, we aim
to optimize the quality of communication between a source and a destination
through adaptive path selection. Due to the randomness and uncertainties in the
network dynamics, the quality of each link varies over time according to a
stochastic process with unknown distributions. After a path is selected for
communication, the aggregated quality of all links on this path (e.g., total
path delay) is observed. The quality of each individual link is not observable.
We formulate this problem as a multi-armed bandit with dependent arms. We show
that by exploiting arm dependencies, a regret polynomial with network size can
be achieved while maintaining the optimal logarithmic order with time. This is
in sharp contrast with the exponential regret order with network size offered
by a direct application of the classic MAB policies that ignore arm
dependencies. Furthermore, our results are obtained under a general model of
link-quality distributions (including heavy-tailed distributions) and find
applications in cognitive radio and ad hoc networks with unknown and dynamic
communication environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4908</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4908</id><created>2012-01-23</created><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>De Wilde</keyname><forenames>Philippe</forenames></author></authors><title>Self-Organisation of Evolving Agent Populations in Digital Ecosystems</title><categories>cs.NE</categories><comments>50 pages, 25 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the self-organising behaviour of Digital Ecosystems, because a
primary motivation for our research is to exploit the self-organising
properties of biological ecosystems. We extended a definition for the
complexity, grounded in the biological sciences, providing a measure of the
information in an organism's genome. Next, we extended a definition for the
stability, originating from the computer sciences, based upon convergence to an
equilibrium distribution. Finally, we investigated a definition for the
diversity, relative to the selection pressures provided by the user requests.
We conclude with a summary and discussion of the achievements, including the
experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4914</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4914</id><created>2012-01-24</created><authors><author><keyname>Chandrasekhar</keyname><forenames>T.</forenames></author><author><keyname>Thangavel</keyname><forenames>K.</forenames></author><author><keyname>Elayaraja</keyname><forenames>E.</forenames></author></authors><title>Effective Clustering Algorithms for Gene Expression Data</title><categories>cs.CE q-bio.GN q-bio.QM</categories><comments>5 pages</comments><journal-ref>International Journal of Computer Applications (0975 - 8887)
  Volume 32 - No.4, October 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microarrays are made it possible to simultaneously monitor the expression
profiles of thousands of genes under various experimental conditions.
Identification of co-expressed genes and coherent patterns is the central goal
in microarray or gene expression data analysis and is an important task in
Bioinformatics research. In this paper, K-Means algorithm hybridised with
Cluster Centre Initialization Algorithm (CCIA) is proposed Gene Expression
Data. The proposed algorithm overcomes the drawbacks of specifying the number
of clusters in the K-Means methods. Experimental analysis shows that the
proposed method performs well on gene Expression Data when compare with the
traditional K- Means clustering and Silhouette Coefficients cluster measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4943</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4943</id><created>2012-01-24</created><authors><author><keyname>Virmani</keyname><forenames>Deepali</forenames></author><author><keyname>Jain</keyname><forenames>Satbir</forenames></author></authors><title>Decentralized Lifetime Maximizing Tree with Clustering for Data Delivery
  in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>9 pages, 8 figures</comments><journal-ref>IJCSI volume 8, issue 5 ,september 2011,pp 310-318, ISSN (Online):
  1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless sensor network has a wide application domain which is expanding
everyday and they have been deployed pertaining to their application area. An
application independent approach is yet to come to terms with the ongoing
exploitation of the WSNs. In this paper we propose a decentralized lifetime
maximizing tree for application independent data aggregation scheme using the
clustering for data delivery in WSNs. The proposed tree will minimize the
energy consumption which has been a resisting factor in the smooth working of
WSNs as well as minimize the distance between the communicating nodes under the
control of a sub-sink which further communicate and transfer data to the sink
node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4946</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4946</id><created>2012-01-24</created><authors><author><keyname>Virmani</keyname><forenames>Deepali</forenames></author><author><keyname>Jain</keyname><forenames>Satbir</forenames></author></authors><title>Real Time Communication Capacity for Data Delivery in Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>10 pages, 7 figures</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, No 1, July 2011 ISSN (Online): 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time applications are performance critical applications that require
bounded service latency. In multi-hop wireless ad-hoc and sensor networks,
communication delays are dominant over processing delays. Therefore, to enable
real-time applications in such networks, the communication latency must be
bounded. In this paper, we derive expressions of real-time capacity that
characterize the ability of a network to deliver data on time as well as
develop network protocols that achieve this capacity. Real-time capacity
expressions are obtained and analyzed for the earliest deadline first, deadline
monotonic. This paper presents a treatment of the real-time capacity limits.
The limits are derived for two extreme traffic topologies namely, the load
balanced topology and the convergecast (i.e., many-to-one) topology. It
considers DM and EDF scheduling algorithms, and discusses the implications of
the capacity limit expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4949</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4949</id><created>2012-01-24</created><authors><author><keyname>Muller</keyname><forenames>Andreas</forenames></author><author><keyname>Sejdinovic</keyname><forenames>Dino</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author></authors><title>Approximate Message Passing under Finite Alphabet Constraints</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures, to appear in IEEE International Conference on
  Acoustics, Speech, and Signal Processing ICASSP 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider Basis Pursuit De-Noising (BPDN) problems in which
the sparse original signal is drawn from a finite alphabet. To solve this
problem we propose an iterative message passing algorithm, which capitalises
not only on the sparsity but by means of a prior distribution also on the
discrete nature of the original signal. In our numerical experiments we test
this algorithm in combination with a Rademacher measurement matrix and a
measurement matrix derived from the random demodulator, which enables
compressive sampling of analogue signals. Our results show in both cases
significant performance gains over a linear programming based approach to the
considered BPDN problem. We also compare the proposed algorithm to a similar
message passing based algorithm without prior knowledge and observe an even
larger performance improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4955</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4955</id><created>2012-01-24</created><updated>2012-03-06</updated><authors><author><keyname>Do</keyname><forenames>Anne-Ly</forenames></author><author><keyname>Rudolf</keyname><forenames>Lars</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Coordination, Differentiation and Fairness in a population of
  cooperating agents</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 3 figures</comments><journal-ref>Games 2012, 3(1), 30-40</journal-ref><doi>10.3390/g3010030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, we analyzed the self-assembly of a complex cooperation
network. The network was shown to approach a state where every agent invests
the same amount of resources. Nevertheless, highly-connected agents arise that
extract extraordinarily high payoffs while contributing comparably little to
any of their cooperations. Here, we investigate a variant of the model, in
which highly-connected agents have access to additional resources. We study
analytically and numerically whether these resources are invested in existing
collaborations, leading to a fairer load distribution, or in establishing new
collaborations, leading to an even less fair distribution of loads and payoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4995</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4995</id><created>2012-01-24</created><updated>2013-10-28</updated><authors><author><keyname>Viglietta</keyname><forenames>Giovanni</forenames></author></authors><title>Gaming is a hard job, but someone has to do it!</title><categories>cs.CC</categories><comments>37 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish some general schemes relating the computational complexity of a
video game to the presence of certain common elements or mechanics, such as
destroyable paths, collectible items, doors opened by keys or activated by
buttons or pressure plates, etc. Then we apply such &quot;metatheorems&quot; to several
video games published between 1980 and 1998, including Pac-Man, Tron, Lode
Runner, Boulder Dash, Deflektor, Mindbender, Pipe Mania, Skweek, Prince of
Persia, Lemmings, Doom, Puzzle Bobble~3, and Starcraft. We obtain both new
results, and improvements or alternative proofs of previously known results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.4999</identifier>
 <datestamp>2012-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.4999</id><created>2012-01-24</created><updated>2012-03-15</updated><authors><author><keyname>Hu</keyname><forenames>Xiaodong</forenames></author><author><keyname>Nazhad</keyname><forenames>Seyed Hossein Hosseini</forenames></author><author><keyname>Ganguly</keyname><forenames>Mitra</forenames></author></authors><title>A study of distributed QoS adapter in large-scale wireless networks</title><categories>cs.NI cs.MA</categories><comments>This paper has been withdrawn by the author due to a wrong authorship</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the comfortably establishing ad hoc networks, the use of this
type of network is increasing day to day. On the other side, it is predicted
that using multimedia applications will be more public in these network. As it
is known, in contrary to best-effort flows, the transmission of multimedia
flows in any network need support from QoS. However, the wireless ad hoc
networks are severely affected by bandwidth, and establishing a QoS in these
networks face problems. In this paper, we have proposed a thoroughly
distributed algorithm to support the QoS in ad hoc networks. This algorithm
guarantees the QoS of the real-time applications vis-a-vis each other and
best-effort flows as well. The algorithm suggested in this paper dynamically
regulates the Contention Window of the flows and serves the flows in terms of
their requests QoS choosing the smallest CW in every node. This algorithm also
uses the fixed and/or less stationary nodes for the transmission of real-time
flows by increasing the QoS of the multimedia flows. This algorithm is
preferred because it prioritizes the flows that are of the same class but have
not obtained favorite QoS compared to other flows of the same class in addition
to classifying the flows in the network and offering better services to the
classes of higher priority. All this occur without the controlled packets
forwarding and resource reserving and freeing method. We have proved the
correctness of this algorithm using Markov's mathematical model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5009</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5009</id><created>2012-01-22</created><authors><author><keyname>Perry</keyname><forenames>Nicolas</forenames><affiliation>LGM2B</affiliation></author><author><keyname>Ammar-Khodja</keyname><forenames>Samar</forenames><affiliation>IRCCyN</affiliation></author></authors><title>A Knowledge Engineering Method for New Product Development</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>Journal of Decision Systems 19, 1 (2010) pp.117-133</journal-ref><doi>10.3166/jds.19.117-133</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Engineering activities involve large groups of people from different domains
and disciplines. They often generate important information flows that are
difficult to manage. To face these difficulties, a knowledge engineering
process is necessary to structure the information and its use. This paper
presents a deployment of a knowledge capitalization process based on the
enrichment of MOKA methodology to support the integration of Process Planning
knowledge in a CAD System. Our goal is to help different actors to work
collaboratively by proposing one referential view of the domain, the context
and the objectives assuming that it will help them in better decision-making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5019</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5019</id><created>2011-12-22</created><updated>2012-09-17</updated><authors><author><keyname>Sou</keyname><forenames>Kin Cheong</forenames></author><author><keyname>Sandberg</keyname><forenames>Henrik</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>On the Exact Solution to a Smart Grid Cyber-Security Analysis Problem</title><categories>math.OC cs.CE cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a smart grid cyber-security problem analyzing the
vulnerabilities of electric power networks to false data attacks. The analysis
problem is related to a constrained cardinality minimization problem. The main
result shows that an $l_1$ relaxation technique provides an exact optimal
solution to this cardinality minimization problem. The proposed result is based
on a polyhedral combinatorics argument. It is different from well-known results
based on mutual coherence and restricted isometry property. The results are
illustrated on benchmarks including the IEEE 118-bus and 300-bus systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5030</identifier>
 <datestamp>2012-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5030</id><created>2012-01-24</created><updated>2012-04-22</updated><authors><author><keyname>Even</keyname><forenames>Guy</forenames></author><author><keyname>Medina</keyname><forenames>Moti</forenames></author></authors><title>Online Multi-Commodity Flow with High Demands</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of computing, in an online fashion, a
maximum benefit multi-commodity flow (\ONMCF), where the flow demands may be
bigger than the edge capacities of the network.
  We present an online, deterministic, centralized, all-or-nothing, bi-criteria
algorithm. The competitive ratio of the algorithm is constant, and the
algorithm augments the capacities by at most a logarithmic factor.
  The algorithm can handle two types of flow requests: (i) low demand requests
that must be routed along a path, and (ii) high demand requests that may be
routed using a multi-path flow.
  Two extensions are discussed: requests with known durations and machine
scheduling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5070</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5070</id><created>2012-01-24</created><authors><author><keyname>Huschenbett</keyname><forenames>Martin</forenames></author></authors><title>Word Automaticity of Tree Automatic Scattered Linear Orderings Is
  Decidable</title><categories>cs.LO</categories><comments>19 pages, 2 figures</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A tree automatic structure is a structure whose domain can be encoded by a
regular tree language such that each relation is recognisable by a finite
automaton processing tuples of trees synchronously. Words can be regarded as
specific simple trees and a structure is word automatic if it is encodable
using only these trees. The question naturally arises whether a given tree
automatic structure is already word automatic. We prove that this problem is
decidable for tree automatic scattered linear orderings. Moreover, we show that
in case of a positive answer a word automatic presentation is computable from
the tree automatic presentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5073</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5073</id><created>2012-01-24</created><updated>2014-11-03</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Randour</keyname><forenames>Mickael</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Strategy Synthesis for Multi-dimensional Quantitative Objectives</title><categories>cs.GT cs.LO</categories><comments>Conference version published in CONCUR 2012, LNCS 7454. Journal
  version published in Acta Informatica, volume 51, issue 3-4, Springer, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-dimensional mean-payoff and energy games provide the mathematical
foundation for the quantitative study of reactive systems, and play a central
role in the emerging quantitative theory of verification and synthesis. In this
work, we study the strategy synthesis problem for games with such
multi-dimensional objectives along with a parity condition, a canonical way to
express $\omega$-regular conditions. While in general, the winning strategies
in such games may require infinite memory, for synthesis the most relevant
problem is the construction of a finite-memory winning strategy (if one
exists). Our main contributions are as follows. First, we show a tight
exponential bound (matching upper and lower bounds) on the memory required for
finite-memory winning strategies in both multi-dimensional mean-payoff and
energy games along with parity objectives. This significantly improves the
triple exponential upper bound for multi energy games (without parity) that
could be derived from results in literature for games on VASS (vector addition
systems with states). Second, we present an optimal symbolic and incremental
algorithm to compute a finite-memory winning strategy (if one exists) in such
games. Finally, we give a complete characterization of when finite memory of
strategies can be traded off for randomness. In particular, we show that for
one-dimension mean-payoff parity games, randomized memoryless strategies are as
powerful as their pure finite-memory counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5086</identifier>
 <datestamp>2012-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5086</id><created>2012-01-24</created><updated>2012-04-23</updated><authors><author><keyname>Maza</keyname><forenames>Marc Moreno</forenames></author><author><keyname>Xiao</keyname><forenames>Rong</forenames></author></authors><title>Generating Program Invariants via Interpolation</title><categories>cs.SE cs.DM cs.SC math.CO</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article focuses on automatically generating polynomial equations that
are inductive loop invariants of computer programs. We propose a new algorithm
for this task, which is based on polynomial interpolation. Though the proposed
algorithm is not complete, it is efficient and can be applied to a broader
range of problems compared to existing methods targeting similar problems. The
efficiency of our approach is testified by experiments on a large collection of
programs. The current implementation of our method is based on dense
interpolation, for which a total degree bound is needed. On the theoretical
front, we study the degree and dimension of the invariant ideal of loops which
have no branches and where the assignments define a P-solvable recurrence. In
addition, we obtain sufficient conditions for non-trivial polynomial equation
invariants to exist (resp. not to exist).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5102</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5102</id><created>2012-01-24</created><authors><author><keyname>Merzougui</keyname><forenames>Ghalia</forenames></author><author><keyname>Djoudi</keyname><forenames>Mahieddine</forenames></author><author><keyname>Behaz</keyname><forenames>Amel</forenames></author></authors><title>Conception and Use of Ontologies for Indexing and Searching by Semantic
  Contents of Video Courses</title><categories>cs.DL cs.IR</categories><comments>9 pages, 5 figures, 1 table and 2 codes</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the video documents like educational courses available on the web
increases significantly. However, the information retrieval systems today can
not return to the users (students or teachers) of parts of those videos that
meet their exact needs expressed by a query consisting of semantic information.
In this paper, we present a model of pedagogical knowledge of current videos.
This knowledge is used throughout the process of indexing and semantic search
segments instructional videos. Our experimental results show that the proposed
approach is promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5135</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5135</id><created>2012-01-24</created><updated>2016-02-21</updated><authors><author><keyname>Peng</keyname><forenames>Richard</forenames></author><author><keyname>Tangwongsan</keyname><forenames>Kanat</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author></authors><title>Faster and Simpler Width-Independent Parallel Algorithms for Positive
  Semidefinite Programming</title><categories>cs.DS cs.DC</categories><comments>Fixed a mistake in the runtime analyses of previous versions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of finding an $(1+\epsilon)$-approximate
solution to positive semidefinite programs. These are semidefinite programs in
which all matrices in the constraints and objective are positive semidefinite
and all scalars are non-negative.
  We present a simpler \NC parallel algorithm that on input with $n$ constraint
matrices, requires $O(\frac{1}{\epsilon^3} log^3 n)$ iterations, each of which
involves only simple matrix operations and computing the trace of the product
of a matrix exponential and a positive semidefinite matrix. Further, given a
positive SDP in a factorized form, the total work of our algorithm is
nearly-linear in the number of non-zero entries in the factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5154</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5154</id><created>2012-01-24</created><authors><author><keyname>McKilliam</keyname><forenames>Robby</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>Finding short vectors in a lattice of Voronoi's first kind</title><categories>cs.IT cs.DS math.IT</categories><comments>submitted to the 2012 International Symposium on Information Theory
  (ISIT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for those lattices of Voronoi's first kind, a vector of shortest
nonzero Euclidean length can computed in polynomial time by computing a minimum
cut in a graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5162</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5162</id><created>2012-01-24</created><authors><author><keyname>Duque</keyname><forenames>David Fern&#xe1;ndez</forenames></author></authors><title>A sound and complete axiomatization for Dynamic Topological Logic</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic Topological Logic (DTL) is a multimodal system for reasoning about
dynamical systems. It is defined semantically and, as such, most of the work
done in the field has been model-theoretic. In particular, the problem of
finding a complete axiomatization for the full language of DTL over the class
of all dynamical systems has proven to be quite elusive.
  Here we propose to enrich the language to include a polyadic topological
modality, originally introduced by Dawar and Otto in a different context. We
then provide a sound axiomatization for DTL over this extended language, and
prove that it is complete. The polyadic modality is used in an essential way in
our proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5167</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5167</id><created>2012-01-24</created><authors><author><keyname>Meng</keyname><forenames>Jin</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Yang</keyname><forenames>En-Hui</forenames><affiliation>University of Waterloo</affiliation></author></authors><title>Interactive Encoding and Decoding Based on Binary LDPC Codes with
  Syndrome Accumulation</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE transaction on Information Theory, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactive encoding and decoding based on binary low-density parity-check
codes with syndrome accumulation (SA-LDPC-IED) is proposed and investigated.
Assume that the source alphabet is $\mathbf{GF}(2)$, and the side information
alphabet is finite. It is first demonstrated how to convert any classical
universal lossless code $\mathcal{C}_n$ (with block length $n$ and side
information available to both the encoder and decoder) into a universal
SA-LDPC-IED scheme. It is then shown that with the word error probability
approaching 0 sub-exponentially with $n$, the compression rate (including both
the forward and backward rates) of the resulting SA-LDPC-IED scheme is upper
bounded by a functional of that of $\mathcal{C}_n$, which in turn approaches
the compression rate of $\mathcal{C}_n$ for each and every individual sequence
pair $(x^n,y^n)$ and the conditional entropy rate $\mathrm{H}(X |Y)$ for any
stationary, ergodic source and side information $(X, Y)$ as the average
variable node degree $\bar{l}$ of the underlying LDPC code increases without
bound. When applied to the class of binary source and side information $(X, Y)$
correlated through a binary symmetrical channel with cross-over probability
unknown to both the encoder and decoder, the resulting SA-LDPC-IED scheme can
be further simplified, yielding even improved rate performance versus the bit
error probability when $\bar{l}$ is not large. Simulation results (coupled with
linear time belief propagation decoding) on binary source-side information
pairs confirm the theoretic analysis, and further show that the SA-LDPC-IED
scheme consistently outperforms the Slepian-Wolf coding scheme based on the
same underlying LDPC code. As a by-product, probability bounds involving LDPC
established in the course are also interesting on their own and expected to
have implications on the performance of LDPC for channel coding as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5173</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5173</id><created>2012-01-24</created><updated>2013-04-20</updated><authors><author><keyname>Lashgari</keyname><forenames>Sina</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>Timely Throughput of Heterogeneous Wireless Networks: Fundamental Limits
  and Algorithms</title><categories>cs.IT cs.NI math.IT</categories><comments>46 pages, submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of different wireless access technologies, together with
the growing number of multi-radio wireless devices suggest that the
opportunistic utilization of multiple connections at the users can be an
effective solution to the phenomenal growth of traffic demand in wireless
networks. In this paper we consider the downlink of a wireless network with $N$
Access Points (AP's) and $M$ clients, where each client is connected to several
out-of-band AP's, and requests delay-sensitive traffic (e.g., real-time video).
We adopt the framework of Hou, Borkar, and Kumar, and study the maximum total
timely throughput of the network, denoted by $C_{T^3}$, which is the maximum
average number of packets delivered successfully before their deadline. Solving
this problem is challenging since even the number of different ways of
assigning packets to the AP's is $N^M$. We overcome the challenge by proposing
a deterministic relaxation of the problem, which converts the problem to a
network with deterministic delays in each link. We show that the additive gap
between the capacity of the relaxed problem, denoted by $C_{det}$, and
$C_{T^3}$ is bounded by $2\sqrt{N(C_{det}+N/4)}$, which is asymptotically
negligible compared to $C_{det}$, when the network is operating at
high-throughput regime.
  In addition, our numerical results show that the actual gap between $C_{T^3}$
and $C_{det}$ is in most cases much less than the worst-case gap proven
analytically. Moreover, using LP rounding methods we prove that the relaxed
problem can be approximated within additive gap of $N$. We extend the
analytical results to the case of time-varying channel states, real-time
traffic, prioritized traffic, and optimal online policies. Finally, we
generalize the model for deterministic relaxation to consider fading, rate
adaptation, and multiple simultaneous transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5182</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5182</id><created>2012-01-24</created><authors><author><keyname>Pandey</keyname><forenames>Umesh Kumar</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>pal</keyname><forenames>Saurabh</forenames></author></authors><title>Data Mining as a Torch Bearer in Education Sector</title><categories>cs.IR</categories><comments>11 pages; Technical Journal of LBSIMDS, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every data has a lot of hidden information. The processing method of data
decides what type of information data produce. In India education sector has a
lot of data that can produce valuable information. This information can be used
to increase the quality of education. But educational institution does not use
any knowledge discovery process approach on these data. Information and
communication technology puts its leg into the education sector to capture and
compile low cost information. Now a day a new research community, educational
data mining (EDM), is growing which is intersection of data mining and
pedagogy. In this paper we present roadmap of research done in EDM in various
segment of education sector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5198</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5198</id><created>2012-01-25</created><authors><author><keyname>B&#xf6;hme</keyname><forenames>Gesa A.</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Fragmentation transitions in multi-state voter models</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>11 pages, 8 figures</comments><doi>10.1103/PhysRevE.85.066117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive models of opinion formation among humans can display a fragmentation
transition, where a social network breaks into disconnected components. Here,
we investigate this transition in a class of models with arbitrary number of
opinions. In contrast to previous work we do not assume that opinions are
equidistant or arranged on a one-dimensional conceptual axis. Our investigation
reveals detailed analytical results on fragmentations in a three-opinion model,
which are confirmed by agent-based simulations. Furthermore, we show that in
certain models the number of opinions can be reduced without affecting the
fragmentation points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5217</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5217</id><created>2012-01-25</created><authors><author><keyname>Al-Muallim</keyname><forenames>M. T.</forenames></author><author><keyname>El-Kouatly</keyname><forenames>R.</forenames></author></authors><title>Unsupervised Classification Using Immune Algorithm</title><categories>cs.LG cs.AI</categories><doi>10.5120/677-952</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised classification algorithm based on clonal selection principle
named Unsupervised Clonal Selection Classification (UCSC) is proposed in this
paper. The new proposed algorithm is data driven and self-adaptive, it adjusts
its parameters to the data to make the classification operation as fast as
possible. The performance of UCSC is evaluated by comparing it with the well
known K-means algorithm using several artificial and real-life data sets. The
experiments show that the proposed UCSC algorithm is more reliable and has high
classification precision comparing to traditional classification methods such
as K-means.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5227</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5227</id><created>2012-01-25</created><authors><author><keyname>Singh</keyname><forenames>T. Romen</forenames></author><author><keyname>Roy</keyname><forenames>Sudipta</forenames></author><author><keyname>Singh</keyname><forenames>O. Imocha</forenames></author><author><keyname>Sinam</keyname><forenames>Tejmani</forenames></author><author><keyname>Singh</keyname><forenames>Kh. Manglem</forenames></author></authors><title>A New Local Adaptive Thresholding Technique in Binarization</title><categories>cs.CV</categories><comments>ISSN (Online): 1694-0814 http://www.IJCSI.org 271</comments><report-no>rs12</report-no><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 2, (2011) 271-277</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image binarization is the process of separation of pixel values into two
groups, white as background and black as foreground. Thresholding plays a major
in binarization of images. Thresholding can be categorized into global
thresholding and local thresholding. In images with uniform contrast
distribution of background and foreground like document images, global
thresholding is more appropriate. In degraded document images, where
considerable background noise or variation in contrast and illumination exists,
there exists many pixels that cannot be easily classified as foreground or
background. In such cases, binarization with local thresholding is more
appropriate. This paper describes a locally adaptive thresholding technique
that removes background by using local mean and mean deviation. Normally the
local mean computational time depends on the window size. Our technique uses
integral sum image as a prior processing to calculate local mean. It does not
involve calculations of standard deviations as in other local adaptive
techniques. This along with the fact that calculations of mean is independent
of window size speed up the process as compared to other local thresholding
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5229</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5229</id><created>2012-01-25</created><authors><author><keyname>J&#xe9;gourel</keyname><forenames>Cyrille</forenames></author><author><keyname>Legay</keyname><forenames>Axel</forenames></author><author><keyname>Sedwards</keyname><forenames>Sean</forenames></author></authors><title>Cross-entropy optimisation of importance sampling parameters for
  statistical model checking</title><categories>cs.PF cs.CE cs.SY stat.CO</categories><comments>16 pages, 8 figures, LNCS style</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical model checking avoids the exponential growth of states associated
with probabilistic model checking by estimating properties from multiple
executions of a system and by giving results within confidence bounds. Rare
properties are often very important but pose a particular challenge for
simulation-based approaches, hence a key objective under these circumstances is
to reduce the number and length of simulations necessary to produce a given
level of confidence. Importance sampling is a well-established technique that
achieves this, however to maintain the advantages of statistical model checking
it is necessary to find good importance sampling distributions without
considering the entire state space.
  Motivated by the above, we present a simple algorithm that uses the notion of
cross-entropy to find the optimal parameters for an importance sampling
distribution. In contrast to previous work, our algorithm uses a low
dimensional vector of parameters to define this distribution and thus avoids
the often intractable explicit representation of a transition matrix. We show
that our parametrisation leads to a unique optimum and can produce many orders
of magnitude improvement in simulation efficiency. We demonstrate the efficacy
of our methodology by applying it to models from reliability engineering and
biochemistry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5230</identifier>
 <datestamp>2012-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5230</id><created>2012-01-25</created><authors><author><keyname>Cohen</keyname><forenames>Julien</forenames><affiliation>LINA</affiliation></author><author><keyname>Douence</keyname><forenames>R&#xe9;mi</forenames><affiliation>LINA, INRIA - EMN</affiliation></author><author><keyname>Ajouli</keyname><forenames>Akram</forenames><affiliation>LINA, INRIA - EMN</affiliation></author></authors><title>Invertible Program Restructurings for Continuing Modular Maintenance</title><categories>cs.SE</categories><comments>6 pages, Early Research Achievements Track; 16th European Conference
  on Software Maintenance and Reengineering (CSMR 2012), Szeged : Hungary
  (2012)</comments><proxy>ccsd</proxy><doi>10.1109/CSMR.2012.42</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When one chooses a main axis of structural decompostion for a software, such
as function- or data-oriented decompositions, the other axes become secondary,
which can be harmful when one of these secondary axes becomes of main
importance. This is called the tyranny of the dominant decomposition. In the
context of modular extension, this problem is known as the Expression Problem
and has found many solutions, but few solutions have been proposed in a larger
context of modular maintenance. We solve the tyranny of the dominant
decomposition in maintenance with invertible program transformations. We
illustrate this on the typical Expression Problem example. We also report our
experiments with Java and Haskell programs and discuss the open problems with
our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5240</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5240</id><created>2012-01-25</created><updated>2012-02-17</updated><authors><author><keyname>Cheney</keyname><forenames>James</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>A dependent nominal type theory</title><categories>cs.LO cs.PL</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  20, 2012) lmcs:1042</journal-ref><doi>10.2168/LMCS-8(1:8)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nominal abstract syntax is an approach to representing names and binding
pioneered by Gabbay and Pitts. So far nominal techniques have mostly been
studied using classical logic or model theory, not type theory. Nominal
extensions to simple, dependent and ML-like polymorphic languages have been
studied, but decidability and normalization results have only been established
for simple nominal type theories. We present a LF-style dependent type theory
extended with name-abstraction types, prove soundness and decidability of
beta-eta-equivalence checking, discuss adequacy and canonical forms via an
example, and discuss extensions such as dependently-typed recursion and
induction principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5241</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5241</id><created>2012-01-25</created><authors><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Yeung</keyname><forenames>Raymond</forenames></author></authors><title>Entropy functions and determinant inequalities</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the characterisation of all determinant
inequalities for $n \times n$ positive definite matrices is equivalent to
determining the smallest closed and convex cone containing all entropy
functions induced by $n$ scalar Gaussian random variables. We have obtained
inner and outer bounds on the cone by using representable functions and
entropic functions. In particular, these bounds are tight and explicit for $n
\le 3$, implying that determinant inequalities for $3 \times 3$ positive
definite matrices are completely characterized by Shannon-type information
inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5253</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5253</id><created>2012-01-25</created><updated>2012-05-16</updated><authors><author><keyname>Ishikawa</keyname><forenames>Masao</forenames></author><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author></authors><title>Zeilberger's Holonomic Ansatz for Pfaffians</title><categories>math.CO cs.SC</categories><comments>7 pages, final version for the ISSAC proceedings; Proceedings of
  ISSAC 2012</comments><acm-class>G.2.1; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variation of Zeilberger's holonomic ansatz for symbolic determinant
evaluations is proposed which is tailored to deal with Pfaffians. The method is
also applicable to determinants of skew-symmetric matrices, for which the
original approach does not work. As Zeilberger's approach is based on the
Laplace expansion (cofactor expansion) of the determinant, we derive our
approach from the cofactor expansion of the Pfaffian. To demonstrate the power
of our method, we prove, using computer algebra algorithms, some conjectures
proposed in the paper &quot;Pfaffian decomposition and a Pfaffian analogue of
q-Catalan Hankel determinants&quot; by Ishikawa, Tagawa, and Zeng. A minor summation
formula related to partitions and Motzkin paths follows as a corollary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5273</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5273</id><created>2012-01-25</created><authors><author><keyname>Wagner</keyname><forenames>Urs</forenames></author><author><keyname>Maze</keyname><forenames>Gerard</forenames></author></authors><title>Improvements in closest point search based on dual HKZ-bases</title><categories>math.CO cs.CR</categories><msc-class>68R05, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we review the technique to solve the CVP based on dual
HKZ-bases by J. Bloemer. The technique is based on the transference theorems
given by Banaszczyk which imply some necessary conditions on the coefficients
of the closest vectors with respect to a basis whose dual is HKZ reduced.
Recursively, starting with the last coefficient, intervals of length i can be
derived for the i-th coefficient of any closest vector. This leads to n!
candidates for closest vectors. In this paper we refine the necessary
conditions derived from the transference theorems, giving an exponential
reduction of the number of candidates. The improvement is due to the fact that
the lengths of the intervals are not independent. In the original algorithm the
candidates for a coefficient pair (a_i,a_{i+1}) correspond to the integer
points in a rectangle of volume i(i+1). In our analysis we show that the
candidates for (a_i,a_{i+1}) in fact lie in an ellipse with transverse and
conjugate diameter i+1, respectively i. This reduces the overall number of
points to be enumerated by an exponential factor of about 0.886^n. We further
show how a choice of the coefficients (a_n,...,a_{i+1}) influences the interval
from which a_i can be chosen. Numerical computations show that these
considerations allow to bound the number of points to be enumerated by n^{0.75
n} for 10 &lt;= n &lt;= 2000. Under the assumption that the Gaussian heuristic for
the length of the shortest nonzero vector in a lattice is tight, this number
can even be bounded by 2^{-2n} n^{n/2}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5283</identifier>
 <datestamp>2013-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5283</id><created>2012-01-23</created><updated>2013-07-26</updated><authors><author><keyname>Yang</keyname><forenames>Tianbao</forenames></author><author><keyname>Mahdavi</keyname><forenames>Mehrdad</forenames></author><author><keyname>Jin</keyname><forenames>Rong</forenames></author><author><keyname>Zhu</keyname><forenames>Shenghuo</forenames></author></authors><title>An Efficient Primal-Dual Prox Method for Non-Smooth Optimization</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the non-smooth optimization problems in machine learning, where both
the loss function and the regularizer are non-smooth functions. Previous
studies on efficient empirical loss minimization assume either a smooth loss
function or a strongly convex regularizer, making them unsuitable for
non-smooth optimization. We develop a simple yet efficient method for a family
of non-smooth optimization problems where the dual form of the loss function is
bilinear in primal and dual variables. We cast a non-smooth optimization
problem into a minimax optimization problem, and develop a primal dual prox
method that solves the minimax optimization problem at a rate of $O(1/T)$
{assuming that the proximal step can be efficiently solved}, significantly
faster than a standard subgradient descent method that has an $O(1/\sqrt{T})$
convergence rate. Our empirical study verifies the efficiency of the proposed
method for various non-smooth optimization problems that arise ubiquitously in
machine learning by comparing it to the state-of-the-art first order methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5285</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5285</id><created>2012-01-25</created><authors><author><keyname>Merzougui</keyname><forenames>G.</forenames></author><author><keyname>Djoudi</keyname><forenames>M.</forenames></author></authors><title>An Authoring System for Editing Lessons in Phonetic English in SMIL3.0</title><categories>cs.MM</categories><comments>6 pages, 6 figures and 2 codes</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the difficulties of teaching English is the prosody, including the
stress. French learners have difficulties to encode this information about the
word because it is irrelevant for them. Therefore, they have difficulty to
produce this stress when they speak that language. Studies in this area have
concluded that the dual-coding approach (auditory and visual) of a phonetic
phenomenon helps a lot to improve its perception and memorization for novice
learners. The aim of our work is to provide English teachers with an authoring
named SaCoPh for editing multimedia courses that support this approach. This
course is based on a template that fits the educational aspects of phonetics,
exploiting the features of version 3.0 of the standard SMIL (Synchronized
Multimedia Integration Language) for the publication of this course on the web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5298</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5298</id><created>2012-01-25</created><authors><author><keyname>Lampis</keyname><forenames>Michael</forenames></author><author><keyname>Mitsou</keyname><forenames>Valia</forenames></author><author><keyname>So&#x142;tys</keyname><forenames>Karolina</forenames></author></authors><title>Scrabble is PSPACE-Complete</title><categories>cs.CC</categories><msc-class>68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the computational complexity of the game of Scrabble.
We prove the PSPACE-completeness of a derandomized model of the game, answering
an open question of Erik Demaine and Robert Hearn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5335</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5335</id><created>2012-01-25</created><authors><author><keyname>Lelarge</keyname><forenames>Marc</forenames></author></authors><title>A new approach to the orientation of random hypergraphs</title><categories>math.PR cs.DM math.CO</categories><comments>27 pages, preliminary version appeared at SODA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A h-uniform hypergraph H=(V,E) is called (l,k)-orientable if there exists an
assignment of each hyperedge e to exactly l of its vertices such that no vertex
is assigned more than k hyperedges. Let H_{n,m,h} be a hypergraph, drawn
uniformly at random from the set of all h-uniform hypergraphs with n vertices
and m edges. In this paper, we determine the threshold of the existence of a
(l,k)-orientation of H_{n,m,h} for k&gt;=1 and h&gt;l&gt;=1, extending recent results
motivated by applications such as cuckoo hashing or load balancing with
guaranteed maximum load. Our proof combines the local weak convergence of
sparse graphs and a careful analysis of a Gibbs measure on spanning subgraphs
with degree constraints. It allows us to deal with a much broader class than
the uniform hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5338</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5338</id><created>2012-01-25</created><updated>2012-09-21</updated><authors><author><keyname>Wang</keyname><forenames>Xiang</forenames></author><author><keyname>Qian</keyname><forenames>Buyue</forenames></author><author><keyname>Davidson</keyname><forenames>Ian</forenames></author></authors><title>On Constrained Spectral Clustering and Its Applications</title><categories>cs.LG stat.ML</categories><comments>Data Mining and Knowledge Discovery, 2012</comments><acm-class>H.2.8</acm-class><doi>10.1007/s10618-012-0291-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constrained clustering has been well-studied for algorithms such as $K$-means
and hierarchical clustering. However, how to satisfy many constraints in these
algorithmic settings has been shown to be intractable. One alternative to
encode many constraints is to use spectral clustering, which remains a
developing area. In this paper, we propose a flexible framework for constrained
spectral clustering. In contrast to some previous efforts that implicitly
encode Must-Link and Cannot-Link constraints by modifying the graph Laplacian
or constraining the underlying eigenspace, we present a more natural and
principled formulation, which explicitly encodes the constraints as part of a
constrained optimization problem. Our method offers several practical
advantages: it can encode the degree of belief in Must-Link and Cannot-Link
constraints; it guarantees to lower-bound how well the given constraints are
satisfied using a user-specified threshold; it can be solved deterministically
in polynomial time through generalized eigendecomposition. Furthermore, by
inheriting the objective function from spectral clustering and encoding the
constraints explicitly, much of the existing analysis of unconstrained spectral
clustering techniques remains valid for our formulation. We validate the
effectiveness of our approach by empirical results on both artificial and real
datasets. We also demonstrate an innovative use of encoding large number of
constraints: transfer learning via constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5340</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5340</id><created>2012-01-25</created><authors><author><keyname>Szyku&#x142;a</keyname><forenames>Marek</forenames></author><author><keyname>Kisielewicz</keyname><forenames>Andrzej</forenames></author></authors><title>Rainbow Induced Subgraphs in Replication Graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is called a replication graph of a graph $H$ if $G$ is obtained
from $H$ by replacing vertices of $H$ by arbitrary cliques of vertices and then
replacing each edge in $H$ by all the edges between corresponding cligues. For
a given graph $H$ the $\rho_R(H)$ is the minimal number of vertices of a
replication graph $G$ of $H$ such that every proper vertex coloring of $G$
contains a rainbow induced subgraph isomorphic to $H$ having exactly one vertex
in each replication clique of $G$. We prove some bounds for $\rho_R$ for some
classes of graphs and compute some exact values. Also some experimental results
obtained by a computer search are presented and conjectures based on them are
formulated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5346</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5346</id><created>2012-01-25</created><authors><author><keyname>Ajspur</keyname><forenames>Mai</forenames></author><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author><author><keyname>Shkatov</keyname><forenames>Dmitry</forenames></author></authors><title>Tableau-based decision procedure for the multi-agent epistemic logic
  with all coalitional operators for common and distributed knowledge</title><categories>cs.LO cs.AI math.LO</categories><comments>Substantially extended and corrected version of arXiv:0902.2125. To
  appear in: Logic Journal of the IGPL, special issue on Formal Aspects of
  Multi-Agent Systems</comments><msc-class>03B35, 03B42, 03B70, 68T27, 68T15</msc-class><acm-class>F.4.1; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a conceptually clear, intuitive, and feasible decision procedure
for testing satisfi?ability in the full multi-agent epistemic logic CMAEL(CD)
with operators for common and distributed knowledge for all coalitions of
agents mentioned in the language. To that end, we introduce Hintikka structures
for CMAEL(CD) and prove that satisfiability in such structures is equivalent to
satis?fiability in standard models. Using that result, we design an incremental
tableau-building procedure that eventually constructs a satisfying Hintikka
structure for every satisfi?able input set of formulae of CMAEL(CD) and closes
for every unsatisfi?able input set of formulae.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5360</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5360</id><created>2012-01-25</created><updated>2012-05-04</updated><authors><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author></authors><title>Characterization of Information Channels for Asymptotic Mean
  Stationarity and Stochastic Stability of Non-stationary/Unstable Linear
  Systems</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>To appear in IEEE Transactions on Information Theory</comments><msc-class>15A15, 15A09, 15A23</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stabilization of non-stationary linear systems over noisy communication
channels is considered. Stochastically stable sources, and unstable but
noise-free or bounded-noise systems have been extensively studied in
information theory and control theory literature since 1970s, with a renewed
interest in the past decade. There have also been studies on non-causal and
causal coding of unstable/non-stationary linear Gaussian sources. In this
paper, tight necessary and sufficient conditions for stochastic stabilizability
of unstable (non-stationary) possibly multi-dimensional linear systems driven
by Gaussian noise over discrete channels (possibly with memory and feedback)
are presented. Stochastic stability notions include recurrence, asymptotic mean
stationarity and sample path ergodicity, and the existence of finite second
moments. Our constructive proof uses random-time state-dependent stochastic
drift criteria for stabilization of Markov chains. For asymptotic mean
stationarity (and thus sample path ergodicity), it is sufficient that the
capacity of a channel is (strictly) greater than the sum of the logarithms of
the unstable pole magnitudes for memoryless channels and a class of channels
with memory. This condition is also necessary under a mild technical condition.
Sufficient conditions for the existence of finite average second moments for
such systems driven by unbounded noise are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5365</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5365</id><created>2012-01-25</created><updated>2012-04-28</updated><authors><author><keyname>Elsheikh</keyname><forenames>Mustafa</forenames></author><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Novocin</keyname><forenames>Andy</forenames></author><author><keyname>Saunders</keyname><forenames>B. David</forenames></author></authors><title>Fast Computation of Smith Forms of Sparse Matrices Over Local Rings</title><categories>cs.SC math.AC</categories><comments>Preliminary version to appear at ISSAC 2012</comments><acm-class>G.4; I.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms to compute the Smith Normal Form of matrices over two
families of local rings.
  The algorithms use the \emph{black-box} model which is suitable for sparse
and structured matrices. The algorithms depend on a number of tools, such as
matrix rank computation over finite fields, for which the best-known time- and
memory-efficient algorithms are probabilistic.
  For an $\nxn$ matrix $A$ over the ring $\Fzfe$, where $f^e$ is a power of an
irreducible polynomial $f \in \Fz$ of degree $d$, our algorithm requires
$\bigO(\eta de^2n)$ operations in $\F$, where our black-box is assumed to
require $\bigO(\eta)$ operations in $\F$ to compute a matrix-vector product by
a vector over $\Fzfe$ (and $\eta$ is assumed greater than $\Pden$). The
algorithm only requires additional storage for $\bigO(\Pden)$ elements of $\F$.
In particular, if $\eta=\softO(\Pden)$, then our algorithm requires only
$\softO(n^2d^2e^3)$ operations in $\F$, which is an improvement on known dense
methods for small $d$ and $e$.
  For the ring $\ZZ/p^e\ZZ$, where $p$ is a prime, we give an algorithm which
is time- and memory-efficient when the number of nontrivial invariant factors
is small. We describe a method for dimension reduction while preserving the
invariant factors. The time complexity is essentially linear in $\mu n r e \log
p,$ where $\mu$ is the number of operations in $\ZZ/p\ZZ$ to evaluate the
black-box (assumed greater than $n$) and $r$ is the total number of non-zero
invariant factors.
  To avoid the practical cost of conditioning, we give a Monte Carlo
certificate, which at low cost, provides either a high probability of success
or a proof of failure. The quest for a time- and memory-efficient solution
without restrictions on the number of nontrivial invariant factors remains
open. We offer a conjecture which may contribute toward that end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5404</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5404</id><created>2012-01-25</created><authors><author><keyname>Duarte-Carvajalino</keyname><forenames>Julio M.</forenames></author><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture
  Models</title><categories>cs.CV</categories><doi>10.1109/TSP.2012.2225054</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A framework for adaptive and non-adaptive statistical compressive sensing is
developed, where a statistical model replaces the standard sparsity model of
classical compressive sensing. We propose within this framework optimal
task-specific sensing protocols specifically and jointly designed for
classification and reconstruction. A two-step adaptive sensing paradigm is
developed, where online sensing is applied to detect the signal class in the
first step, followed by a reconstruction step adapted to the detected class and
the observed samples. The approach is based on information theory, here
tailored for Gaussian mixture models (GMMs), where an information-theoretic
objective relationship between the sensed signals and a representation of the
specific task of interest is maximized. Experimental results using synthetic
signals, Landsat satellite attributes, and natural images of different sizes
and with different noise levels show the improvements achieved using the
proposed framework when compared to more standard sensing protocols. The
underlying formulation can be applied beyond GMMs, at the price of higher
mathematical and computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5411</identifier>
 <datestamp>2015-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5411</id><created>2012-01-25</created><updated>2015-03-04</updated><authors><author><keyname>Dalai</keyname><forenames>Marco</forenames></author></authors><title>Lower bounds on the Probability of Error for Classical and
  Classical-Quantum Channels</title><categories>cs.IT math.IT quant-ph</categories><comments>Updated to published version + bug fixed in Figure 3</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, issue 12, Dec.
  2013, pp. 8027 - 8056</journal-ref><doi>10.1109/TIT.2013.2283794</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, lower bounds on error probability in coding for discrete
classical and classical-quantum channels are studied. The contribution of the
paper goes in two main directions: i) extending classical bounds of Shannon,
Gallager and Berlekamp to classical-quantum channels, and ii) proposing a new
framework for lower bounding the probability of error of channels with a
zero-error capacity in the low rate region. The relation between these two
problems is revealed by showing that Lov\'asz' bound on zero-error capacity
emerges as a natural consequence of the sphere packing bound once we move to
the more general context of classical-quantum channels. A variation of
Lov\'asz' bound is then derived to lower bound the probability of error in the
low rate region by means of auxiliary channels. As a result of this study,
connections between the Lov\'asz theta function, the expurgated bound of
Gallager, the cutoff rate of a classical channel and the sphere packing bound
for classical-quantum channels are established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5418</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5418</id><created>2012-01-25</created><authors><author><keyname>Caballero</keyname><forenames>R.</forenames></author><author><keyname>Rodriguez-Artalejo</keyname><forenames>M.</forenames></author><author><keyname>Romero-Diaz</keyname><forenames>C. A.</forenames></author></authors><title>A Transformation-based Implementation for CLP with Qualification and
  Proximity</title><categories>cs.LO cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP). arXiv
  admin note: significant text overlap with arXiv:1009.1976</comments><report-no>12-R01-TPLP</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Uncertainty in logic programming has been widely investigated in the last
decades, leading to multiple extensions of the classical LP paradigm. However,
few of these are designed as extensions of the well-established and powerful
CLP scheme for Constraint Logic Programming. In a previous work we have
proposed the SQCLP ({\em proximity-based qualified constraint logic
programming}) scheme as a quite expressive extension of CLP with support for
qualification values and proximity relations as generalizations of uncertainty
values and similarity relations, respectively. In this paper we provide a
transformation technique for transforming SQCLP programs and goals into
semantically equivalent CLP programs and goals, and a practical Prolog-based
implementation of some particularly useful instances of the SQCLP scheme. We
also illustrate, by showing some simple---and working---examples, how the
prototype can be effectively used as a tool for solving problems where
qualification values and proximity relations play a key role. Intended use of
SQCLP includes flexible information retrieval applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5421</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5421</id><created>2012-01-25</created><authors><author><keyname>&#x10c;ern&#xfd;</keyname><forenames>Jakub</forenames></author><author><keyname>Kyn&#x10d;l</keyname><forenames>Jan</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>G&#xe9;za</forenames></author></authors><title>Improvement on the decay of crossing numbers</title><categories>math.CO cs.DM</categories><comments>7 pages, 1 figure</comments><journal-ref>Graphs and Combinatorics 29 (2013), Issue 3, 365-371</journal-ref><doi>10.1007/s00373-012-1137-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the crossing number of a graph decays in a continuous fashion
in the following sense. For any epsilon&gt;0 there is a delta&gt;0 such that for a
sufficiently large n, every graph G with n vertices and m &gt; n^{1+epsilon}
edges, has a subgraph G' of at most (1-delta)m edges and crossing number at
least (1-epsilon)cr(G). This generalizes the result of J. Fox and Cs. Toth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5422</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5422</id><created>2012-01-25</created><updated>2012-06-18</updated><authors><author><keyname>Loeliger</keyname><forenames>Hans-Andrea</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>A Factor-Graph Representation of Probabilities in Quantum Mechanics</title><categories>cs.IT math-ph math.IT math.MP quant-ph</categories><comments>Proc. IEEE International Symposium on Information Theory (ISIT),
  Cambridge, MA, July 1-6, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A factor-graph representation of quantum-mechanical probabilities is
proposed. Unlike standard statistical models, the proposed representation uses
auxiliary variables (state variables) that are not random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5426</identifier>
 <datestamp>2013-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5426</id><created>2012-01-25</created><updated>2013-02-07</updated><authors><author><keyname>Abdallah</keyname><forenames>A. Nait</forenames></author><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Constraint Propagation as Information Maximization</title><categories>cs.AI</categories><comments>21 pages</comments><report-no>Research Report 746, Dept. of Computer Science, University of
  Western Ontario, Canada</report-no><acm-class>D.3.3; F.3.2; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper draws on diverse areas of computer science to develop a unified
view of computation:
  (1) Optimization in operations research, where a numerical objective function
is maximized under constraints, is generalized from the numerical total order
to a non-numerical partial order that can be interpreted in terms of
information. (2) Relations are generalized so that there are relations of which
the constituent tuples have numerical indexes, whereas in other relations these
indexes are variables. The distinction is essential in our definition of
constraint satisfaction problems. (3) Constraint satisfaction problems are
formulated in terms of semantics of conjunctions of atomic formulas of
predicate logic. (4) Approximation structures, which are available for several
important domains, are applied to solutions of constraint satisfaction
problems.
  As application we treat constraint satisfaction problems over reals. These
cover a large part of numerical analysis, most significantly nonlinear
equations and inequalities. The chaotic algorithm analyzed in the paper
combines the efficiency of floating-point computation with the correctness
guarantees of arising from our logico-mathematical model of
constraint-satisfaction problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5430</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5430</id><created>2012-01-25</created><updated>2012-10-03</updated><authors><author><keyname>Gumerov</keyname><forenames>Nail A.</forenames></author><author><keyname>Duraiswami</keyname><forenames>Ramani</forenames></author></authors><title>Efficient FMM accelerated vortex methods in three dimensions via the
  Lamb-Helmholtz decomposition</title><categories>physics.comp-ph cs.NA math-ph math.MP physics.flu-dyn</categories><report-no>CS-TR-5002; UMIACS-TR-2012-02</report-no><doi>10.1016/j.jcp.2013.01.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vortex element methods are often used to efficiently simulate incompressible
flows using Lagrangian techniques. Use of the FMM (Fast Multipole Method)
allows considerable speed up of both velocity evaluation and vorticity
evolution terms in these methods. Both equations require field evaluation of
constrained (divergence free) vector valued quantities (velocity, vorticity)
and cross terms from these. These are usually evaluated by performing several
FMM accelerated sums of scalar harmonic functions.
  We present a formulation of the vortex methods based on the Lamb-Helmholtz
decomposition of the velocity in terms of two scalar potentials. In its
original form, this decomposition is not invariant with respect to translation,
violating a key requirement for the FMM. One of the key contributions of this
paper is a theory for translation for this representation. The translation
theory is developed by introducing &quot;conversion&quot; operators, which enable the
representation to be restored in an arbitrary reference frame. Using this form,
extremely efficient vortex element computations can be made, which need
evaluation of just two scalar harmonic FMM sums for evaluating the velocity and
vorticity evolution terms. Details of the decomposition, translation and
conversion formulae, and sample numerical results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5434</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5434</id><created>2012-01-25</created><authors><author><keyname>Kahlon</keyname><forenames>Arshdeep S.</forenames></author><author><keyname>Szyszkowicz</keyname><forenames>Sebastian S.</forenames></author><author><keyname>Periyalwar</keyname><forenames>Shalini</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Separating the Effect of Independent Interference Sources with Rayleigh
  Faded Signal Link: Outage Analysis and Applications</title><categories>cs.NI</categories><comments>Submitted to IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that, for independent interfering sources and a signal link with
exponentially distributed received power, the total probability of outage can
be decomposed as a simple expression of the outages from the individual
interfering sources. We give a mathematical proof of this result, and discuss
some immediate implications, showing how it results in important
simplifications to statistical outage analysis. We also discuss its application
to two active topics of study: spectrum sharing, and sum of interference powers
(e.g., lognormal) analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5443</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5443</id><created>2012-01-26</created><authors><author><keyname>Abid</keyname><forenames>Sohail</forenames></author><author><keyname>Abid</keyname><forenames>Shahid</forenames></author></authors><title>Dynamic Session Key Exchange Method using Two S-Boxes</title><categories>cs.CR</categories><comments>10 pages, 11 figures, IJCSEA Journal</comments><journal-ref>International Journal of Computer Science, Engineering and
  Applications (IJCSEA), December 2011, Volume 1, Number 6</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents modifications of the Diffie-Hellman (DH) key exchange
method. The presented modifications provide better security than other key
exchange methods. We are going to present a dynamic security that
simultaneously realizes all the three functions with a high efficiency and then
give a security analysis. It also presents secure and dynamic key exchange
method. Signature, encryption and key exchange are some of the most important
and foundational Crypto-graphical tools. In most cases, they are all needed to
provide different secure functions. On the other hand, there are also some
proposals on the efficient combination of key exchange. In this paper, we
present a dynamic, reliable and secure method for the exchange of session key.
Moreover, the proposed modification method could achieve better performance
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5450</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5450</id><created>2012-01-26</created><authors><author><keyname>Roussillon</keyname><forenames>Cyril</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gonzalez</keyname><forenames>Aurelien</forenames><affiliation>LAAS</affiliation></author><author><keyname>Sol&#xe0;</keyname><forenames>Joan</forenames><affiliation>LAAS</affiliation></author><author><keyname>Codol</keyname><forenames>Jean-Marie</forenames><affiliation>LAAS</affiliation></author><author><keyname>Mansard</keyname><forenames>Nicolas</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lacroix</keyname><forenames>Simon</forenames><affiliation>LAAS</affiliation></author><author><keyname>Devy</keyname><forenames>Michel</forenames><affiliation>LAAS</affiliation></author></authors><title>RT-SLAM: A Generic and Real-Time Visual SLAM Implementation</title><categories>cs.RO</categories><comments>10 pages</comments><proxy>ccsd</proxy><journal-ref>Lecture notes in computer science 6962/2011 (2011) 31-40</journal-ref><doi>10.1007/978-3-642-23968-7_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a new open-source C++ implementation to solve the SLAM
problem, which is focused on genericity, versatility and high execution speed.
It is based on an original object oriented architecture, that allows the
combination of numerous sensors and landmark types, and the integration of
various approaches proposed in the literature. The system capacities are
illustrated by the presentation of an inertial/vision SLAM approach, for which
several improvements over existing methods have been introduced, and that copes
with very high dynamic motions. Results with a hand-held camera are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5472</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5472</id><created>2012-01-26</created><authors><author><keyname>Tranouez</keyname><forenames>Pierrick</forenames><affiliation>LITIS</affiliation></author><author><keyname>Daud&#xe9;</keyname><forenames>Eric</forenames><affiliation>IDEES</affiliation></author><author><keyname>Langlois</keyname><forenames>Patrice</forenames><affiliation>IDEES</affiliation></author></authors><title>A multiagent urban traffic simulation</title><categories>cs.AI</categories><comments>arXiv admin note: significant text overlap with arXiv:0909.1021 and
  arXiv:0910.1026</comments><proxy>ccsd</proxy><journal-ref>Journal of Nonlinear Systems and Applications 1, 3 (2010) 9 pp (in
  print)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We built a multiagent simulation of urban traffic to model both ordinary
traffic and emergency or crisis mode traffic. This simulation first builds a
modeled road network based on detailed geographical information. On this
network, the simulation creates two populations of agents: the Transporters and
the Mobiles. Transporters embody the roads themselves; they are utilitarian and
meant to handle the low level realism of the simulation. Mobile agents embody
the vehicles that circulate on the network. They have one or several
destinations they try to reach using initially their beliefs of the structure
of the network (length of the edges, speed limits, number of lanes etc.).
Nonetheless, when confronted to a dynamic, emergent prone environment (other
vehicles, unexpectedly closed ways or lanes, traffic jams etc.), the rather
reactive agent will activate more cognitive modules to adapt its beliefs,
desires and intentions. It may change its destination(s), change the tactics
used to reach the destination (favoring less used roads, following other
agents, using general headings), etc. We describe our current validation of our
model and the next planned improvements, both in validation and in
functionalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5476</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5476</id><created>2012-01-26</created><updated>2012-02-01</updated><authors><author><keyname>Spruit</keyname><forenames>H. C.</forenames></author></authors><title>The relative significance of the H-index</title><categories>astro-ph.IM cs.DL physics.soc-ph</categories><comments>More references added, small corrections. Research note, 3 small
  pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of the Hirsch-index ($h$) as measure of an author's visibility in the
scientific literature has become popular as an alternative to a gross measure
like total citations (c). I show that, at least in astrophysics, $h$ correlates
tightly with overall citations. The mean relation is $h=0.5(\sqrt c+1)$.
Outliers are few and not too far from the mean, especially if `normalized' ADS
citations are used for $c$ and $h$. Whatever the theoretical reasoning behind
it, the Hirsch index in practice does not appear to measure something
significantly new.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5477</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5477</id><created>2012-01-26</created><authors><author><keyname>Sienkiewicz</keyname><forenames>Julian</forenames></author><author><keyname>Skowron</keyname><forenames>Marcin</forenames></author><author><keyname>Paltoglou</keyname><forenames>Georgios</forenames></author><author><keyname>Holyst</keyname><forenames>Janusz A.</forenames></author></authors><title>Entropy-growth-based model of emotionally charged online dialogues</title><categories>physics.soc-ph cs.CL cs.SI physics.data-an</categories><comments>9 pages, 2 tables</comments><journal-ref>Advances in Complex Systems 16, 1350026 (2013)</journal-ref><doi>10.1142/S0219525913500264</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze emotionally annotated massive data from IRC (Internet Relay Chat)
and model the dialogues between its participants by assuming that the driving
force for the discussion is the entropy growth of emotional probability
distribution. This process is claimed to be correlated to the emergence of the
power-law distribution of the discussion lengths observed in the dialogues. We
perform numerical simulations based on the noticed phenomenon obtaining a good
agreement with the real data. Finally, we propose a method to artificially
prolong the duration of the discussion that relies on the entropy of emotional
probability distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5478</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5478</id><created>2012-01-26</created><updated>2012-06-16</updated><authors><author><keyname>Barzanti</keyname><forenames>Luca</forenames></author><author><keyname>Mastroleo</keyname><forenames>Marcello</forenames></author></authors><title>On the Actual Inefficiency of Efficient Negotiation Methods</title><categories>math.OC cs.GT math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution we analyze the effect that mutual information has on the
actual performance of efficient negotiation methods. Specifically, we start by
proposing the theoretical notion of Abstract Negotiation Method (ANM) as a map
from the negotiation domain in itself, for any utility profile of the parties.
ANM can face both direct and iterative negotiations, since we show that ANM
class is closed under the limit operation. The generality of ANM is proven by
showing that it captures a large class of well known in literature negotiation
methods. Hence we show that if mutual information is assumed then any Pareto
efficient ANM is manipulable by one single party or by a collusion of few of
them. We concern about the efficiency of the resulting manipulation. Thus we
find necessarily and sufficient conditions those make manipulability equivalent
to actual inefficiency, meaning that the manipulation implies a change of the
efficient frontier so the Pareto efficient ANM converges to a different, hence
actually inefficient, frontier. In particular we distinguish between strong and
weak actual inefficiency. Where, the strong actual inefficiency is a drawback
which is not possible to overcome of the ANMs, like the Pareto invariant one,
so its negotiation result is invariant for any two profiles of utility sharing
the same Pareto frontier, we present. While the weak actual inefficiency is a
drawback of any mathematical theorization on rational agents which constrain in
a particular way their space of utility functions. For the weak actual
inefficiency we state a principle of Result's Inconsistency by showing that to
falsify theoretical hypotheses is rational for any agent which is informed
about the preference of the other, even if the theoretical assumptions, which
constrain the space of agents' utilities, are exact in the reality, i.e. the
preferences of each single agent are well modeled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5484</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5484</id><created>2012-01-26</created><updated>2012-04-16</updated><authors><author><keyname>Pohorecki</keyname><forenames>Piotr</forenames></author><author><keyname>Sienkiewicz</keyname><forenames>Julian</forenames></author><author><keyname>Mitrovic</keyname><forenames>Marija</forenames></author><author><keyname>Paltoglou</keyname><forenames>Georgios</forenames></author><author><keyname>Holyst</keyname><forenames>Janusz A.</forenames></author></authors><title>Statistical analysis of emotions and opinions at Digg website</title><categories>physics.soc-ph cs.CL cs.SI physics.data-an</categories><comments>26 pages, 16 figures, 6 tables</comments><journal-ref>Acta Physica Polonica A 123, 604 (2013)</journal-ref><doi>10.12693/APhysPolA.123.604</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We performed statistical analysis on data from the Digg.com website, which
enables its users to express their opinion on news stories by taking part in
forum-like discussions as well as directly evaluate previous posts and stories
by assigning so called &quot;diggs&quot;. Owing to fact that the content of each post has
been annotated with its emotional value, apart from the strictly structural
properties, the study also includes an analysis of the average emotional
response of the posts commenting the main story. While analysing correlations
at the story level, an interesting relationship between the number of diggs and
the number of comments received by a story was found. The correlation between
the two quantities is high for data where small threads dominate and
consistently decreases for longer threads. However, while the correlation of
the number of diggs and the average emotional response tends to grow for longer
threads, correlations between numbers of comments and the average emotional
response are almost zero. We also show that the initial set of comments given
to a story has a substantial impact on the further &quot;life&quot; of the discussion:
high negative average emotions in the first 10 comments lead to longer threads
while the opposite situation results in shorter discussions. We also suggest
presence of two different mechanisms governing the evolution of the discussion
and, consequently, its length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5495</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5495</id><created>2012-01-26</created><updated>2013-06-24</updated><authors><author><keyname>Huschenbett</keyname><forenames>Martin</forenames><affiliation>Technical University of Ilmenau</affiliation></author><author><keyname>Kartzow</keyname><forenames>Alexander</forenames><affiliation>University of Leipzig</affiliation></author><author><keyname>Liu</keyname><forenames>Jiamou</forenames><affiliation>Auckland University of Technology</affiliation></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames><affiliation>University of Leipzig</affiliation></author></authors><title>Tree-Automatic Well-Founded Trees</title><categories>cs.LO math.LO</categories><comments>Will appear in Logical Methods of Computer Science</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 2 (June 25,
  2013) lmcs:721</journal-ref><doi>10.2168/LMCS-9(2:10)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate tree-automatic well-founded trees. Using Delhomme's
decomposition technique for tree-automatic structures, we show that the
(ordinal) rank of a tree-automatic well-founded tree is strictly below
omega^omega. Moreover, we make a step towards proving that the ranks of
tree-automatic well-founded partial orders are bounded by omega^omega^omega: we
prove this bound for what we call upwards linear partial orders. As an
application of our result, we show that the isomorphism problem for
tree-automatic well-founded trees is complete for level Delta^0_{omega^omega}
of the hyperarithmetical hierarchy with respect to Turing-reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5513</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5513</id><created>2012-01-26</created><authors><author><keyname>Ouangraoua</keyname><forenames>Aida</forenames></author><author><keyname>Raffinot</keyname><forenames>Mathieu</forenames></author></authors><title>Faster and Simpler Minimal Conflicting Set Identification</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let C be a finite set of N elements and R = r_1,r_2,..., r_m a family of M
subsets of C. A subset X of R verifies the Consecutive Ones Property (C1P) if
there exists a permutation P of C such that each r_i in X is an interval of P.
A Minimal Conflicting Set (MCS) S is a subset of R that does not verify the
C1P, but such that any of its proper subsets does. In this paper, we present a
new simpler and faster algorithm to decide if a given element r in R belongs to
at least one MCS. Our algorithm runs in O(N^2M^2 + NM^7), largely improving the
current O(M^6N^5 (M+N)^2 log(M+N)) fastest algorithm of [Blin {\em et al}, CSR
2011]. The new algorithm is based on an alternative approach considering
minimal forbidden induced subgraphs of interval graphs instead of Tucker
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5529</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5529</id><created>2012-01-26</created><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>Nesme</keyname><forenames>Vincent</forenames></author></authors><title>A simple block representation of reversible cellular automata with
  time-symmetry</title><categories>cs.DM cs.FL quant-ph</categories><comments>6 pages, 3 figures, Automata 2011</comments><msc-class>37B15, 68Q80, 37N20</msc-class><acm-class>B.6.1; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible Cellular Automata (RCA) are a physics-like model of computation
consisting of an array of identical cells, evolving in discrete time steps by
iterating a global evolution G. Further, G is required to be shift-invariant
(it acts the same everywhere), causal (information cannot be transmitted faster
than some fixed number of cells per time step), and reversible (it has an
inverse which verifies the same requirements). An important, though only
recently studied special case is that of Time-symmetric Cellular Automata
(TSCA), for which G and its inverse are related via a local operation. In this
note we revisit the question of the Block representation of RCA, i.e. we
provide a very simple proof of the existence of a reversible circuit
description implementing G. This operational, bottom-up description of G turns
out to be time-symmetric, suggesting interesting connections with TSCA. Indeed
we prove, using a similar technique, that a wide class of them admit an Exact
block representation (EBR), i.e. one which does not increase the state space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5597</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5597</id><created>2012-01-26</created><updated>2012-05-16</updated><authors><author><keyname>Brumleve</keyname><forenames>Dan</forenames></author><author><keyname>Hamkins</keyname><forenames>Joel David</forenames></author><author><keyname>Schlicht</keyname><forenames>Philipp</forenames></author></authors><title>The mate-in-n problem of infinite chess is decidable</title><categories>math.LO cs.LO</categories><comments>10 pages, 1 figure, CiE 2012. updated author list</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infinite chess is chess played on an infinite edgeless chessboard. The
familiar chess pieces move about according to their usual chess rules, and each
player strives to place the opposing king into checkmate. The mate-in-n problem
of infinite chess is the problem of determining whether a designated player can
force a win from a given finite position in at most n moves. A naive
formulation of this problem leads to assertions of high arithmetic complexity
with 2n alternating quantifiers---there is a move for white, such that for
every black reply, there is a counter-move for white, and so on. In such a
formulation, the problem does not appear to be decidable; and one cannot expect
to search an infinitely branching game tree even to finite depth. Nevertheless,
the main theorem of this article, confirming a conjecture of the first author
and C. D. A. Evans, establishes that the mate-in-n problem of infinite chess is
computably decidable, uniformly in the position and in n. Furthermore, there is
a computable strategy for optimal play from such mate-in-n positions. The proof
proceeds by showing that the mate-in-n problem is expressible in what we call
the first-order structure of chess, which we prove (in the relevant fragment)
is an automatic structure, whose theory is therefore decidable. Indeed, it is
definable in Presburger arithmetic. Unfortunately, this resolution of the
mate-in-n problem does not appear to settle the decidability of the more
general winning-position problem, the problem of determining whether a
designated player has a winning strategy from a given position, since a
position may admit a winning strategy without any bound on the number of moves
required. This issue is connected with transfinite game values in infinite
chess, and the exact value of the omega one of chess is not known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5603</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5603</id><created>2012-01-26</created><authors><author><keyname>Nesiolovskiy</keyname><forenames>Igor</forenames></author><author><keyname>Nesiolovskiy</keyname><forenames>Artem</forenames></author></authors><title>BIN@ERN: Binary-Ternary Compressing Data Coding</title><categories>cs.IT cs.DS math.IT</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new method of data encoding which may be used in
various modern digital, computer and telecommunication systems and devices. The
method permits the compression of data for storage or transmission, allowing
the exact original data to be reconstructed without any loss of content. The
method is characterized by the simplicity of implementation, as well as high
speed and compression ratio. The method is based on a unique scheme of
binary-ternary prefix-free encoding of characters of the original data. This
scheme does not require the transmission of the code tables from encoder to
decoder; allows for the linear presentation of the code lists; permits the
usage of computable indexes of the prefix codes in a linear list for decoding;
makes it possible to estimate the compression ratio prior to encoding; makes
the usage of multiplication and division operations, as well as operations with
the floating point unnecessary; proves to be effective for static as well as
adaptive coding; applicable to character sets of any size; allows for repeated
compression to improve the ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5604</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5604</id><created>2012-01-26</created><updated>2015-01-25</updated><authors><author><keyname>Preen</keyname><forenames>Richard J.</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Discrete and fuzzy dynamical genetic programming in the XCSF learning
  classifier system</title><categories>cs.AI cs.LG cs.NE cs.SY math.OC</categories><journal-ref>Soft Computing (2014), 18(1):153-167</journal-ref><doi>10.1007/s00500-013-1044-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of representation schemes have been presented for use within
learning classifier systems, ranging from binary encodings to neural networks.
This paper presents results from an investigation into using discrete and fuzzy
dynamical system representations within the XCSF learning classifier system. In
particular, asynchronous random Boolean networks are used to represent the
traditional condition-action production system rules in the discrete case and
asynchronous fuzzy logic networks in the continuous-valued case. It is shown
possible to use self-adaptive, open-ended evolution to design an ensemble of
such dynamical systems within XCSF to solve a number of well-known test
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5608</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5608</id><created>2012-01-26</created><authors><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author><author><keyname>Sejdinovic</keyname><forenames>Dino</forenames></author></authors><title>Combinatorial Channel Signature Modulation for Wireless ad-hoc Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages, 7 figures, to appear in IEEE International Conference on
  Communications ICC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel modulation and multiplexing method which
facilitates highly efficient and simultaneous communication between multiple
terminals in wireless ad-hoc networks. We term this method Combinatorial
Channel Signature Modulation (CCSM). The CCSM method is particularly efficient
in situations where communicating nodes operate in highly time dispersive
environments. This is all achieved with a minimal MAC layer overhead, since all
users are allowed to transmit and receive at the same time/frequency (full
simultaneous duplex). The CCSM method has its roots in sparse modelling and the
receiver is based on compressive sampling techniques. Towards this end, we
develop a new low complexity algorithm termed Group Subspace Pursuit. Our
analysis suggests that CCSM at least doubles the throughput when compared to
the state-of-the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5621</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5621</id><created>2012-01-26</created><authors><author><keyname>Abhishek</keyname><forenames>Vineet</forenames></author><author><keyname>Kash</keyname><forenames>Ian A.</forenames></author><author><keyname>Key</keyname><forenames>Peter</forenames></author></authors><title>Fixed and Market Pricing for Cloud Services</title><categories>cs.GT</categories><comments>9 pages and 1 figure. An abridged version of this will appear in the
  7th Workshop on the Economics of Networks, Systems, and Computation (NetEcon)
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers two simple pricing schemes for selling cloud instances
and studies the trade-off between them. We characterize the equilibrium for the
hybrid system where arriving jobs can choose between fixed or the market based
pricing. We provide theoretical and simulation based evidence suggesting that
fixed price generates a higher expected revenue than the hybrid system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5626</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5626</id><created>2012-01-26</created><authors><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Conditional strategies and the evolution of cooperation in spatial
  public goods games</title><categories>physics.soc-ph cs.SI nlin.AO q-bio.PE</categories><comments>7 two-column pages, 7 figures; accepted for publication in Physical
  Review E</comments><journal-ref>Phys. Rev. E 85 (2012) 026104</journal-ref><doi>10.1103/PhysRevE.85.026104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fact that individuals will most likely behave differently in different
situations begets the introduction of conditional strategies. Inspired by this,
we study the evolution of cooperation in the spatial public goods game, where
besides unconditional cooperators and defectors, also different types of
conditional cooperators compete for space. Conditional cooperators will
contribute to the public good only if other players within the group are likely
to cooperate as well, but will withhold their contribution otherwise. Depending
on the number of other cooperators that are required to elicit cooperation of a
conditional cooperator, the latter can be classified in as many types as there
are players within each group. We find that the most cautious cooperators, such
that require all other players within a group to be conditional cooperators,
are the undisputed victors of the evolutionary process, even at very low
synergy factors. We show that the remarkable promotion of cooperation is due
primarily to the spontaneous emergence of quarantining of defectors, which
become surrounded by conditional cooperators and are forced into isolated
convex &quot;bubbles&quot; from where they are unable to exploit the public good. This
phenomenon can be observed only in structured populations, thus adding to the
relevance of pattern formation for the successful evolution of cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5653</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5653</id><created>2012-01-26</created><updated>2013-06-02</updated><authors><author><keyname>Goldberg</keyname><forenames>Eugene</forenames></author><author><keyname>Manolios</keyname><forenames>Panagiotis</forenames></author></authors><title>Quantifier Elimination by Dependency Sequents</title><categories>cs.LO</categories><comments>All the changes we made with respect to the previous versions are
  listed in the footnotes. The main change is that we modified the definition
  of a D-sequent using the notion of scoped redundancy of variables. We
  modified a few proofs of propositions affected by this change</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of existential quantifier elimination for Boolean
formulas in Conjunctive Normal Form (CNF). We present a new method for solving
this problem called Derivation of Dependency-Sequents (DDS). A
Dependency-sequent (D-sequent) is used to record that a set of quantified
variables is redundant under a partial assignment. We introduce a
resolution-like operation called join that produces a new D-sequent from two
existing D-sequents. We also show that DDS is compositional, i.e. if our input
formula is a conjunction of independent formulas, DDS automatically recognizes
and exploits this information. We introduce an algorithm based on DDS and
present experimental results demonstrating its potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5666</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5666</id><created>2012-01-26</created><updated>2012-09-06</updated><authors><author><keyname>Diaz</keyname><forenames>Jesus</forenames></author><author><keyname>Arroyo</keyname><forenames>David</forenames></author><author><keyname>Rodriguez</keyname><forenames>Francisco B.</forenames></author></authors><title>A formal methodology for integral security design and verification of
  network protocols</title><categories>cs.CR</categories><doi>10.1016/j.jss.2013.09.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a methodology for verifying security properties of network
protocols at design level. It can be separated in two main parts: context and
requirements analysis and informal verification; and formal representation and
procedural verification. It is an iterative process where the early steps are
simpler than the last ones. Therefore, the effort required for detecting flaws
is proportional to the complexity of the associated attack. Thus, we avoid
wasting valuable resources for simple flaws that can be detected early in the
verification process. In order to illustrate the advantages provided by our
methodology, we also analyze three real protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5681</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5681</id><created>2012-01-26</created><authors><author><keyname>Pan</keyname><forenames>Minqi</forenames></author></authors><title>T2Ku: Building a Semantic Wiki of Mathematics</title><categories>cs.DL</categories><comments>9 Pages, 1 figures, Submitted to IJCAR 2012</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce T2Ku, an open source project that aims at building a semantic
wiki of mathematics featuring automated reasoning(AR) techniques. We want to
utilize AR techniques in a way that truly helps mathematical researchers solve
problems in the real world, instead of building another ambitious yet useless
system. By setting this as our objective, we exploit pragmatic design decisions
that have proven feasible in other projects, while still employs a loosely
coupled architecture to allow better inference programs to be integrated in the
future. In this paper, we state the motivations and examine state-of-the-art
systems, why we are not satisfied with those systems and how we are going to
improve. We then describe our architecture and the way we implemented the
system. We present examples showing how to use its facilities. T2Ku is an
on-going project. We conclude this paper by summarizing the development
progress and encouraging the reader to join the project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5688</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5688</id><created>2012-01-26</created><authors><author><keyname>Gangwar</keyname><forenames>Sanjeev</forenames></author><author><keyname>Pal</keyname><forenames>Saurabh</forenames></author><author><keyname>Kumar</keyname><forenames>Krishan</forenames></author></authors><title>Mobile Ad Hoc Networks: A Comparative Study of QoS Routing Protocols</title><categories>cs.NI</categories><comments>5 pages</comments><journal-ref>International Journal of Computer Science Engineering and
  Technology (IJCSET), Vol.2, Issue 1, 2012, pp 771-775</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Article presents a thorough overview of QoS routing metrics, resources
and factors affecting performance of QoS routing protocols. The relative
strength, weakness, and applicability of existing QoS routing protocols are
also studied and compared. QoS routing protocols are classified according to
the QoS metrics used type of QoS guarantee assured.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5689</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5689</id><created>2012-01-26</created><authors><author><keyname>Lee</keyname><forenames>Yoonjin</forenames></author><author><keyname>Kim</keyname><forenames>Jon-Lark</forenames></author></authors><title>An Efficient Construction of Self-Dual Codes</title><categories>cs.IT math.CO math.IT math.NT</categories><comments>21 pages, 8 Tables</comments><msc-class>94B05 (Primary), 11T71 (secondary), 05E99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We complete the building-up construction for self-dual codes by resolving the
open cases over $GF(q)$ with $q \equiv 3 \pmod 4$, and over $\Z_{p^m}$ and
Galois rings $\GR(p^m,r)$ with an odd prime $p$ satisfying $p \equiv 3 \pmod 4$
with $r$ odd. We also extend the building-up construction for self-dual codes
to finite chain rings. Our building-up construction produces many new
interesting self-dual codes. In particular, we construct 945 new extremal
self-dual ternary $[32,16,9]$ codes, each of which has a trivial automorphism
group. We also obtain many new self-dual codes over $\mathbb Z_9$ of lengths
$12, 16, 20$ all with minimum Hamming weight 6, which is the best possible
minimum Hamming weight that free self-dual codes over $\Z_9$ of these lengths
can attain. From the constructed codes over $\mathbb Z_9$, we reconstruct
optimal Type I lattices of dimensions $12, 16, 20,$ and 24 using Construction
$A$; this shows that our building-up construction can make a good contribution
for finding optimal Type I lattices as well as self-dual codes. We also find
new optimal self-dual $[16,8,7]$ codes over GF(7) and new self-dual codes over
GF(7) with the best known parameters $[24,12,9]$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5719</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5719</id><created>2012-01-27</created><updated>2012-01-30</updated><authors><author><keyname>Borchmann</keyname><forenames>Daniel</forenames></author></authors><title>Deciding Entailment of Implications with Support and Confidence in
  Polynomial Space</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Association Rules are a basic concept of data mining. They are, however, not
understood as logical objects which can be used for reasoning. The purpose of
this paper is to investigate a model based semantic for implications with
certain constraints on their support and confidence in relational data, which
then resemble association rules, and to present a possibility to decide
entailment for them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5722</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5722</id><created>2012-01-27</created><updated>2012-04-25</updated><authors><author><keyname>Palchykov</keyname><forenames>Vasyl</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>Albert-L&#xe1;szl&#xf3;</forenames></author><author><keyname>Dunbar</keyname><forenames>Robin I. M.</forenames></author></authors><title>Sex differences in intimate relationships</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 3 figures, contains electronic supplementary material</comments><journal-ref>Sci. Rep. 2, 370 (2012)</journal-ref><doi>10.1038/srep00370</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks have turned out to be of fundamental importance both for our
understanding human sociality and for the design of digital communication
technology. However, social networks are themselves based on dyadic
relationships and we have little understanding of the dynamics of close
relationships and how these change over time. Evolutionary theory suggests
that, even in monogamous mating systems, the pattern of investment in close
relationships should vary across the lifespan when post-weaning investment
plays an important role in maximising fitness. Mobile phone data sets provide
us with a unique window into the structure of relationships and the way these
change across the lifespan. We here use data from a large national mobile phone
dataset to demonstrate striking sex differences in the pattern in the
gender-bias of preferred relationships that reflect the way the reproductive
investment strategies of the two sexes change across the lifespan: these
differences mainly reflect women's shifting patterns of investment in
reproduction and parental care. These results suggest that human social
strategies may have more complex dynamics than we have tended to assume and a
life-history perspective may be crucial for understanding them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5728</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5728</id><created>2012-01-27</created><authors><author><keyname>Motara</keyname><forenames>Yusuf Moosa</forenames></author></authors><title>Functional Programming and Security</title><categories>cs.CR cs.PL cs.SE</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper analyses the security contribution of typical functional-language
features by examining them in the light of accepted information security
principles. Imperative and functional code are compared to illustrate various
cases. In conclusion, there may be an excellent case for the use of functional
languages on the grounds of better security; however, empirical research should
be done to validate this possibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5729</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5729</id><created>2012-01-27</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On Compatible Normal Odd Partitions in Cubic Graphs</title><categories>cs.DM</categories><comments>Accepted for publication in Journal of Graph Theory</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A normal odd partition T of the edges of a cubic graph is a partition into
trails of odd length (no repeated edge) such that each vertex is the end vertex
of exactly one trail of the partition and internal in some trail. For each
vertex v, we can distinguish the edge for which this vertex is pending. Three
normal odd partitions are compatible whenever these distinguished edges are
distinct for each vertex. We examine this notion and show that a cubic 3
edge-colorable graph can always be provided with three compatible normal odd
partitions. The Petersen graph has this property and we can construct other
cubic graphs with chromatic index four with the same property. Finally, we
propose a new conjecture which, if true, would imply the well known Fan and
Raspaud Conjecture
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5735</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5735</id><created>2012-01-27</created><authors><author><keyname>Kusakov</keyname><forenames>Igor</forenames></author></authors><title>Deconcentration of Attention: Addressing the Complexity of Software
  Engineering</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article attempts to describe specific mental techniques that are related
to resolving very complex tasks in software engineering. This subject may be
familiar to some software specialists to different extents; however, there is
currently no common consensus and popular terminology for this subject area. In
this article, the area is charted from a practical usability perspective.
  This article also proposes to treat software engineering itself as research
on human thinking because software is meant to simulate thinking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5767</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5767</id><created>2012-01-27</created><authors><author><keyname>He</keyname><forenames>Bian</forenames></author><author><keyname>Gu</keyname><forenames>Lei</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao-Dong</forenames></author></authors><title>Nodal domain partition and the number of communities in networks</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 8 figures, 48 references</comments><doi>10.1088/1742-5468/2012/02/P02012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is difficult to detect and evaluate the number of communities in complex
networks, especially when the situation involves with an ambiguous boundary
between the inner- and inter-community densities. In this paper, Discrete Nodal
Domain Theory could be used to provide a criterion to determine how many
communities a network would have and how to partition these communities by
means of the topological structure and geometric characterization. By capturing
the signs of certain Laplacian eigenvectors we can separate the network into
several reasonable clusters. The method leads to a fast and effective algorithm
with application to a variety of real networks data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5788</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5788</id><created>2012-01-25</created><authors><author><keyname>Black</keyname><forenames>Don V.</forenames></author></authors><title>A toolkit to describe and interactively display three-manifolds embedded
  in four-space</title><categories>cs.CG cs.GR</categories><comments>15 pages, 4 color figures, 7 pages of pseudo-code, and is accompanied
  by 3 animated videos referenced in bibliography. Additional animated videos
  can be downloaded from here:
  http://www.hypervisualization.com/videos/uci/toolkit/</comments><acm-class>I.3.3; I.3.5; I.3.6; I.4.10; E.2; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data structure and toolkit are presented here that allow for the
description and manipulation of mathematical models of three-manifolds and
their interactive display from multiple viewpoints via the OpenGL 3D graphics
package. The data structure and vector math package can be extended to support
an arbitrary number of Euclidean spatial dimensions.
  A model in 4-space is described by its bounding pure simplicial 3-complex. By
intersecting a 3-flat with this 3-manifold, the algorithm will extract the
requested closed pure simplicial 2-complex surface enclosing the desired 3D
slice. The user can interactively rotate, pan, zoom, and shade arbitrary 3D
solid or wire-frame views of the revealed 3D object created by intersection,
thus exploring both expected and unexpected symmetries or asymmetries in the
world of 3-manifolds in 4-space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5793</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5793</id><created>2012-01-27</created><updated>2014-01-18</updated><authors><author><keyname>Ullrich</keyname><forenames>Mario</forenames></author></authors><title>Swendsen-Wang is faster than single-bond dynamics</title><categories>math.PR cs.DM math-ph math.MP</categories><comments>17 pages</comments><msc-class>Primary, 60J10, Secondary, 60K35, 68Q87</msc-class><journal-ref>SIAM J. Discrete Math. 28 (2014), pp. 37-48</journal-ref><doi>10.1137/120864003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the spectral gap of the Swendsen-Wang dynamics for the
random-cluster model is larger than the spectral gap of a single-bond dynamics,
that updates only a single edge per step. For this we give a representation of
the algorithms on the joint (Potts/random-cluster) model. Furthermore we obtain
upper and lower bounds on the mixing time of the single-bond dynamics on the
discrete $d$-dimensional torus of side length $L$ at the Potts transition
temperature for $q$ large enough that are exponential in $L^{d-1}$,
complementing a result of Borgs, Chayes and Tetali.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5805</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5805</id><created>2012-01-27</created><updated>2012-05-16</updated><authors><author><keyname>Abdoli</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Ghasemi</keyname><forenames>Akbar</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Keyvan</forenames></author></authors><title>Interference and X Networks with Noisy Cooperation and Feedback</title><categories>cs.IT math.IT</categories><comments>53 pages, 15 figures; Submitted to IEEE Transactions on Information
  Theory, May 2012. To be presented in part in ISIT 2012, Cambridge, MA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gaussian $K$-user interference and $M\times K$ X channels are
investigated with no instantaneous channel state information (CSI) at
transmitters. First, it is assumed that the CSI is fed back to all nodes after
a finite delay (delayed CSIT), and furthermore, the transmitters operate in
full-duplex mode, i.e., they can transmit and receive simultaneously.
Achievable results are obtained on the degrees of freedom (DoF) of these
channels under the above assumption. It is observed that, in contrast with no
CSIT and full CSIT models, when CSIT is delayed, the achievable DoFs for both
channels with full-duplex transmitter cooperation are greater than the best
available achievable results on their DoF without transmitter cooperation. Our
results are the first to show that the full-duplex transmitter cooperation can
potentially improve the channel DoF with delayed CSIT. Then, $K$-user
interference and $K\times K$ X channels are considered with output feedback,
wherein the channel output of each receiver is causally fed back to its
corresponding transmitter. Our achievable results with output feedback
demonstrate strict DoF improvements over those with the full-duplex delayed
CSIT when $K&gt;5$ in the $K$-user interference channel and $K&gt;2$ in the $K\times
K$ X channel. Next, the combination of delayed CSIT and output feedback, known
as Shannon feedback, is studied and strictly higher DoFs compared to the output
feedback model are achieved in the $K$-user interference channel when K=5 or
$K&gt;6$, and in the $K\times K$ X channel when $K&gt;2$. Although being strictly
greater than 1 and increasing with size of the networks, the achievable DoFs in
all the models studied in this paper approach limiting values not greater than
2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5810</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5810</id><created>2012-01-27</created><authors><author><keyname>Emiris</keyname><forenames>Ioannis Z.</forenames></author></authors><title>A General Solver Based on Sparse Resultants</title><categories>cs.SC cs.NA math.AC</categories><comments>20 pages, 1 figure</comments><msc-class>13P15 Solving polynomial systems, resultants (Primary), 68W30
  Symbolic computation and algebraic computation (secondary)</msc-class><acm-class>I.1; F.2.1; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse (or toric) elimination exploits the structure of polynomials by
measuring their complexity in terms of Newton polytopes instead of total
degree. The sparse, or Newton, resultant generalizes the classical homogeneous
resultant and its degree is a function of the mixed volumes of the Newton
polytopes. We sketch the sparse resultant constructions of Canny and Emiris and
show how they reduce the problem of root-finding to an eigenproblem. A novel
method for achieving this reduction is presented which does not increase the
dimension of the problem. Together with an implementation of the sparse
resultant construction, it provides a general solver for polynomial systems. We
discuss the overall implementation and illustrate its use by applying it to
concrete problems from vision, robotics and structural biology. The high
efficiency and accuracy of the solutions suggest that sparse elimination may be
the method of choice for systems of moderate size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5821</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5821</id><created>2012-01-27</created><updated>2012-08-08</updated><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schmied</keyname><forenames>Richard</forenames></author></authors><title>On Approximation Lower Bounds for TSP with Bounded Metrics</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new method for proving explicit approximation lower bounds for
TSP problems with bounded metrics improving on the best up to now known bounds.
They almost match the best known bounds for unbounded metric TSP problems. In
particular, we prove the best known lower bound for TSP with bounded metrics
for the metric bound equal to 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5824</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5824</id><created>2012-01-27</created><authors><author><keyname>Maurer</keyname><forenames>Alexandre</forenames><affiliation>LIP6, LINCS</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, LINCS, IUF</affiliation></author></authors><title>Limiting Byzantien Influence in Multihop Asynchronous Networks</title><categories>cs.DS cs.DC cs.NI</categories><comments>18 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reliably broadcasting information in a multihop
asyn- chronous network that is subject to Byzantine failures. That is, some
nodes of the network can exhibit arbitrary (and potentially malicious)
behavior. Existing solutions provide de- terministic guarantees for
broadcasting between all correct nodes, but require that the communication
network is highly-connected (typically, 2k + 1 connectivity is required, where
k is the total number of Byzantine nodes in the network). In this paper, we
investigate the possibility of Byzantine tolerant reliable broadcast be- tween
most correct nodes in low-connectivity networks (typically, networks with
constant connectivity). In more details, we propose a new broadcast protocol
that is specifically designed for low-connectivity networks. We provide
sufficient conditions for correct nodes using our protocol to reliably
communicate despite Byzantine participants. We present experimental results
that show that our approach is especially effective in low-connectivity
networks when Byzantine nodes are randomly distributed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5835</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5835</id><created>2012-01-27</created><authors><author><keyname>Je&#x159;&#xe1;bek</keyname><forenames>Emil</forenames></author></authors><title>Sequence encoding without induction</title><categories>math.LO cs.LO</categories><comments>7 pages</comments><msc-class>03F30</msc-class><journal-ref>Mathematical Logic Quarterly 58 (2012), no. 3, pp. 244-248</journal-ref><doi>10.1002/malq.201200013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the universally axiomatized, induction-free theory PA^- is a
sequential theory in the sense of Pudl\'ak [5], in contrast to the closely
related Robinson's arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5838</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5838</id><created>2012-01-27</created><authors><author><keyname>Blits</keyname><forenames>Navot</forenames></author></authors><title>Rateless Codes for Finite Message Set</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we consider rateless coding over discrete memoryless channels
(DMC) with feedback. Unlike traditional fixed-rate codes, in rateless codes
each codeword is infinitely long, and the decoding time depends on the
confidence level of the decoder. Using rateless codes along with sequential
decoding, and allowing a fixed probability of error at the decoder, we obtain
results for several communication scenarios. The results shown here are
non-asymptotic, in the sense that the size of the message set is finite. First
we consider the transmission of equiprobable messages using rateless codes over
a DMC, where the decoder knows the channel law. We obtain an achievable rate
for a fixed error probability and a finite message set. We show that as the
message set size grows, the achievable rate approaches the optimum rate for
this setting. We then consider the universal case, in which the channel law is
unknown to the decoder. We introduce a novel decoder that uses a mixture
probability assignment instead of the unknown channel law, and obtain an
achievable rate for this case. Finally, we extend the scope for more advanced
settings. We use different flavors of the rateless coding scheme for joint
source-channel coding, coding with side-information and a combination of the
two with universal coding, which yields a communication scheme that does not
require any information on the source, the channel, or the amount the side
information at the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5841</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5841</id><created>2012-01-27</created><updated>2013-01-26</updated><authors><author><keyname>de Castro</keyname><forenames>Alexandre</forenames></author></authors><title>The thermodynamic cost of fast thought</title><categories>cs.AI</categories><doi>10.1007/s11023-013-9302-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After more than sixty years, Shannon's research1-3 continues to raise
fundamental questions, such as the one formulated by Luce4,5, which is still
unanswered: &quot;Why is information theory not very applicable to psychological
problems, despite apparent similarities of concepts?&quot; On this topic, Pinker6,
one of the foremost defenders of the computational theory of mind6, has argued
that thought is simply a type of computation, and that the gap between human
cognition and computational models may be illusory. In this context, in his
latest book, titled Thinking Fast and Slow8, Kahneman7,8 provides further
theoretical interpretation by differentiating the two assumed systems of the
cognitive functioning of the human mind. He calls them intuition (system 1)
determined to be an associative (automatic, fast and perceptual) machine, and
reasoning (system 2) required to be voluntary and to operate logical-
deductively. In this paper, we propose an ansatz inspired by Ausubel's learning
theory for investigating, from the constructivist perspective9-12, information
processing in the working memory of cognizers. Specifically, a thought
experiment is performed utilizing the mind of a dual-natured creature known as
Maxwell's demon: a tiny &quot;man-machine&quot; solely equipped with the characteristics
of system 1, which prevents it from reasoning. The calculation presented here
shows that [...]. This result indicates that when the system 2 is shut down,
both an intelligent being, as well as a binary machine, incur the same energy
cost per unit of information processed, which mathematically proves the
computational attribute of the system 1, as Kahneman7,8 theorized. This finding
links information theory to human psychological features and opens a new path
toward the conception of a multi-bit reasoning machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5853</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5853</id><created>2012-01-27</created><authors><author><keyname>Grandjean</keyname><forenames>Etienne</forenames></author><author><keyname>Olive</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>richard</keyname><forenames>Ga&#xe9;tan</forenames></author></authors><title>Descriptive complexity for pictures languages (extended abstract)</title><categories>cs.LO cs.CC</categories><comments>33 pages - Submited to Lics 2012</comments><acm-class>F.1.1; F.1.3; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with descriptive complexity of picture languages of any
dimension by syntactical fragments of existential second-order logic.
  - We uniformly generalize to any dimension the characterization by
Giammarresi et al. \cite{GRST96} of the class of \emph{recognizable} picture
languages in existential monadic second-order logic. - We state several logical
characterizations of the class of picture languages recognized in linear time
on nondeterministic cellular automata of any dimension. They are the first
machine-independent characterizations of complexity classes of cellular
automata.
  Our characterizations are essentially deduced from normalization results we
prove for first-order and existential second-order logics over pictures. They
are obtained in a general and uniform framework that allows to extend them to
other &quot;regular&quot; structures. Finally, we describe some hierarchy results that
show the optimality of our logical characterizations and delineate their
limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5871</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5871</id><created>2012-01-27</created><authors><author><keyname>Perry</keyname><forenames>Patrick O.</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>Null models for network data</title><categories>math.ST cs.SI stat.ME stat.TH</categories><comments>12 pages, 2 figures; submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of datasets taking the form of simple, undirected graphs
continues to gain in importance across a variety of disciplines. Two choices of
null model, the logistic-linear model and the implicit log-linear model, have
come into common use for analyzing such network data, in part because each
accounts for the heterogeneity of network node degrees typically observed in
practice. Here we show how these both may be viewed as instances of a broader
class of null models, with the property that all members of this class give
rise to essentially the same likelihood-based estimates of link probabilities
in sparse graph regimes. This facilitates likelihood-based computation and
inference, and enables practitioners to choose the most appropriate null model
from this family based on application context. Comparative model fits for a
variety of network datasets demonstrate the practical implications of our
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5921</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5921</id><created>2012-01-27</created><authors><author><keyname>Kuijper</keyname><forenames>M.</forenames><affiliation>University of Melbourne</affiliation></author><author><keyname>Pinto</keyname><forenames>R.</forenames><affiliation>University of Aveiro</affiliation></author></authors><title>An iterative algorithm for parametrization of shortest length shift
  registers over finite rings</title><categories>cs.IT cs.SC math.IT</categories><comments>Submitted</comments><msc-class>94A55, 11T71</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction of shortest feedback shift registers for a finite sequence
S_1,...,S_N is considered over the finite ring Z_{p^r}. A novel algorithm is
presented that yields a parametrization of all shortest feedback shift
registers for the sequence of numbers S_1,...,S_N, thus solving an open problem
in the literature. The algorithm iteratively processes each number, starting
with S_1, and constructs at each step a particular type of minimal Gr\&quot;obner
basis. The construction involves a simple update rule at each step which leads
to computational efficiency. It is shown that the algorithm simultaneously
computes a similar parametrization for the reciprocal sequence S_N,...,S_1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5938</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5938</id><created>2012-01-28</created><authors><author><keyname>Moradmand</keyname><forenames>Hajar</forenames></author><author><keyname>Setayeshi</keyname><forenames>Saeed</forenames></author><author><keyname>Targhi</keyname><forenames>Hossein Khazaei</forenames></author></authors><title>Comparing Methods for segmentation of Microcalcification Clusters in
  Digitized Mammograms</title><categories>cs.CV</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 1, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The appearance of microcalcifications in mammograms is one of the early signs
of breast cancer. So, early detection of microcalcification clusters (MCCs) in
mammograms can be helpful for cancer diagnosis and better treatment of breast
cancer. In this paper a computer method has been proposed to support
radiologists in detection MCCs in digital mammography. First, in order to
facilitate and improve the detection step, mammogram images have been enhanced
with wavelet transformation and morphology operation. Then for segmentation of
suspicious MCCs, two methods have been investigated. The considered methods
are: adaptive threshold and watershed segmentation. Finally, the detected MCCs
areas in different algorithms will be compared to find out which segmentation
method is more appropriate for extracting MCCs in mammograms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5943</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5943</id><created>2012-01-28</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author><author><keyname>Dimitrijev</keyname><forenames>Sima</forenames></author></authors><title>Cognitive Memory Network</title><categories>cs.AI cs.CV cs.ET</categories><journal-ref>Electronics Letters,46, 10, 677 - 678, 2010</journal-ref><doi>10.1049/el.2010.0279</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A resistive memory network that has no crossover wiring is proposed to
overcome the hardware limitations to size and functional complexity that is
associated with conventional analogue neural networks. The proposed memory
network is based on simple network cells that are arranged in a hierarchical
modular architecture. Cognitive functionality of this network is demonstrated
by an example of character recognition. The network is trained by an
evolutionary process to completely recognise characters deformed by random
noise, rotation, scaling and shifting
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5944</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5944</id><created>2012-01-28</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author><author><keyname>Shariff</keyname><forenames>Fayaz</forenames></author><author><keyname>Maan</keyname><forenames>Akshay Kumar</forenames></author></authors><title>A Neuron Based Switch: Application to Low Power Mixed Signal Circuits</title><categories>cs.ET cs.NE q-bio.NC</categories><comments>2010 International Conference on Advances in Computer Engineering</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Human brain is functionally and physically complex. This 'complexity' can be
seen as a result of biological design process involving extensive use of
concepts such as modularity and hierarchy. Over the past decade, deeper
insights into the functioning of cortical neurons have led to the development
of models that can be implemented in hardware. The implementation of
biologically inspired spiking neuron networks in silicon can provide solutions
to difficult cognitive tasks. The work reported in this paper is an application
of a VLSI cortical neuron model for low power design. The VLSI implementation
shown in this paper is based on the spike and burst firing pattern of cortex
and follows the Izhikevich neuron model. This model is applied to a DC
differential amplifier as practical application of power reduction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5946</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5946</id><created>2012-01-28</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author><author><keyname>Dimitrijev</keyname><forenames>Sima</forenames></author></authors><title>Feature selection using nearest attributes</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection is an important problem in high-dimensional data analysis
and classification. Conventional feature selection approaches focus on
detecting the features based on a redundancy criterion using learning and
feature searching schemes. In contrast, we present an approach that identifies
the need to select features based on their discriminatory ability among
classes. Area of overlap between inter-class and intra-class distances
resulting from feature to feature comparison of an attribute is used as a
measure of discriminatory ability of the feature. A set of nearest attributes
in a pattern having the lowest area of overlap within a degree of tolerance
defined by a selection threshold is selected to represent the best available
discriminable features. State of the art recognition results are reported for
pattern classification problems by using the proposed feature selection scheme
with the nearest neighbour classifier. These results are reported with
benchmark databases having high dimensional feature vectors in the problems
involving images and micro array data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5947</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5947</id><created>2012-01-28</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author><author><keyname>Dimitrijev</keyname><forenames>Sima</forenames></author></authors><title>Examplers based image fusion features for face recognition</title><categories>cs.CV cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Examplers of a face are formed from multiple gallery images of a person and
are used in the process of classification of a test image. We incorporate such
examplers in forming a biologically inspired local binary decisions on
similarity based face recognition method. As opposed to single model approaches
such as face averages the exampler based approach results in higher recognition
accu- racies and stability. Using multiple training samples per person, the
method shows the following recognition accuracies: 99.0% on AR, 99.5% on FERET,
99.5% on ORL, 99.3% on EYALE, 100.0% on YALE and 100.0% on CALTECH face
databases. In addition to face recognition, the method also detects the natural
variability in the face images which can find application in automatic tagging
of face images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5954</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5954</id><created>2012-01-28</created><authors><author><keyname>Echenim</keyname><forenames>Mnacho</forenames></author><author><keyname>Peltier</keyname><forenames>Nicolas</forenames></author></authors><title>A Calculus for Generating Ground Explanations (Technical Report)</title><categories>cs.LO</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a modification of the superposition calculus that is meant to
generate explanations why a set of clauses is satisfiable. This process is
related to abductive reasoning, and the explanations generated are clauses
constructed over so-called abductive constants. We prove the correctness and
completeness of the calculus in the presence of redundancy elimination rules,
and develop a sufficient condition guaranteeing its termination; this
sufficient condition is then used to prove that all possible explanations can
be generated infinite time for several classes of clause sets, including many
of interest to the SMT community. We propose a procedure that generates a set
of explanations that should be useful to a human user and conclude by
suggesting several extensions to this novel approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5958</identifier>
 <datestamp>2014-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5958</id><created>2012-01-28</created><updated>2014-03-05</updated><authors><author><keyname>Adiga</keyname><forenames>Abhijin</forenames></author><author><keyname>Babu</keyname><forenames>Jasine</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author></authors><title>Parameterized and Approximation Algorithms for Boxicity</title><categories>cs.DS cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boxicity of a graph $G(V,$ $E)$, denoted by $box(G)$, is the minimum integer
$k$ such that $G$ can be represented as the intersection graph of axis parallel
boxes in $\mathbb{R}^k$. The problem of computing boxicity is inapproximable
even for graph classes like bipartite, co-bipartite and split graphs within
$O(n^{1 - \epsilon})$-factor, for any $\epsilon &gt;0$ in polynomial time unless
$NP=ZPP$. We give FPT approximation algorithms for computing the boxicity of
graphs, where the parameter used is the vertex or edge edit distance of the
given graph from families of graphs of bounded boxicity. This can be seen as a
generalization of the parameterizations discussed in \cite{Adiga2}.
  Extending the same idea in one of our algorithms, we also get an
$O\left(\frac{n\sqrt{\log \log n}}{\sqrt{\log n}}\right)$ factor approximation
algorithm for computing boxicity and an $O\left(\frac{n {(\log \log
n)}^{\frac{3}{2}}}{\sqrt{\log n}}\right)$ factor approximation algorithm for
computing the cubicity. These seem to be the first $o(n)$ factor approximation
algorithms known for both boxicity and cubicity. As a consequence of this
result, a $o(n)$ factor approximation algorithm for computing the partial order
dimension of finite posets and a $o(n)$ factor approximation algorithm for
computing the threshold dimension of split graphs would follow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5959</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5959</id><created>2012-01-28</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author></authors><title>Memory Based Machine Intelligence Techniques in VLSI hardware</title><categories>cs.AI cs.RO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We briefly introduce the memory based approaches to emulate machine
intelligence in VLSI hardware, describing the challenges and advantages.
Implementation of artificial intelligence techniques in VLSI hardware is a
practical and difficult problem. Deep architectures, hierarchical temporal
memories and memory networks are some of the contemporary approaches in this
area of research. The techniques attempt to emulate low level intelligence
tasks and aim at providing scalable solutions to high level intelligence
problems such as sparse coding and contextual processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5972</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5972</id><created>2012-01-28</created><updated>2012-07-03</updated><authors><author><keyname>Dadush</keyname><forenames>Daniel</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Near-Optimal Deterministic Algorithms for Volume Computation and Lattice
  Problems via M-Ellipsoids</title><categories>cs.CC cs.DS math.FA</categories><msc-class>52C07, 68Q25</msc-class><doi>10.1073/pnas.1203863110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a deterministic 2^{O(n)} algorithm for computing an M-ellipsoid of a
convex body, matching a known lower bound. This has several interesting
consequences including improved deterministic algorithms for volume estimation
of convex bodies and the shortest and closest lattice vector problems under
general norms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5975</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5975</id><created>2012-01-28</created><authors><author><keyname>Masotti</keyname><forenames>Glauco</forenames></author></authors><title>Floating-Point Numbers with Error Estimates (revised)</title><categories>cs.NA</categories><comments>45 pages, 18 figures, 39 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study addresses the problem of precision in floating-point (FP)
computations. A method for estimating the errors which affect intermediate and
final results is proposed and a summary of many software simulations is
discussed. The basic idea consists of representing FP numbers by means of a
data structure collecting value and estimated error information. Under certain
constraints, the estimate of the absolute error is accurate and has a compact
statistical distribution. By monitoring the estimated relative error during a
computation (an ad-hoc definition of relative error has been used), the
validity of results can be ensured. The error estimate enables the
implementation of robust algorithms, and the detection of ill-conditioned
problems. A dynamic extension of number precision, under the control of error
estimates, is advocated, in order to compute results within given error bounds.
A reduced time penalty could be achieved by a specialized FP processor. The
realization of a hardwired processor incorporating the method, with current
technology, should not be anymore a problem and would make the practical
adoption of the method feasible for most applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5985</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5985</id><created>2012-01-28</created><authors><author><keyname>Berthom&#xe9;</keyname><forenames>Pascal</forenames><affiliation>LIFO</affiliation></author><author><keyname>Lalande</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LIFO</affiliation></author><author><keyname>Levorato</keyname><forenames>Vincent</forenames><affiliation>LIFO</affiliation></author></authors><title>Implementation of exponential and parametrized algorithms in the AGAPE
  project</title><categories>cs.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report describes the implementation of exact and parametrized
exponential algorithms, developed during the French ANR Agape during 2010-2012.
The developed algorithms are distributed under the CeCILL license and have been
written in Java using the Jung graph library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.5988</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.5988</id><created>2012-01-28</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>Tools for parsimonious edge-colouring of graphs with maximum degree
  three</title><categories>cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:0809.4747</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of a $\delta$-minimum edge-colouring was introduced by J-L.
Fouquet (in his french PhD Thesis \cite{FouPhD}). Here we present some
structural properties of $\delta$-minimum edge-colourings, partially taken from
the above thesis. The paper serves as an auxiliary tool for another paper
submitted by the authors to Graphs and Combinatorics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6012</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6012</id><created>2012-01-28</created><authors><author><keyname>Han</keyname><forenames>Sunghyu</forenames></author><author><keyname>Kim</keyname><forenames>Jon-Lark</forenames></author><author><keyname>Lee</keyname><forenames>Heisook</forenames></author><author><keyname>Lee</keyname><forenames>Yoonjin</forenames></author></authors><title>Construction of quasi-cyclic self-dual codes</title><categories>cs.IT math.AC math.CO math.IT</categories><comments>25 pages, 2 tables; Finite Fields and Their Applications, 2012</comments><msc-class>94B05 (Primary) 11T71 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a one-to-one correspondence between $\ell$-quasi-cyclic codes over a
finite field $\mathbb F_q$ and linear codes over a ring $R = \mathbb
F_q[Y]/(Y^m-1)$. Using this correspondence, we prove that every
$\ell$-quasi-cyclic self-dual code of length $m\ell$ over a finite field
$\mathbb F_q$ can be obtained by the {\it building-up} construction, provided
that char $(\mathbb F_q)=2$ or $q \equiv 1 \pmod 4$, $m$ is a prime $p$, and
$q$ is a primitive element of $\mathbb F_p$. We determine possible weight
enumerators of a binary $\ell$-quasi-cyclic self-dual code of length $p\ell$
(with $p$ a prime) in terms of divisibility by $p$. We improve the result of
[3] by constructing new binary cubic (i.e., $\ell$-quasi-cyclic codes of length
$3\ell$) optimal self-dual codes of lengths $30, 36, 42, 48$ (Type I), 54 and
66. We also find quasi-cyclic optimal self-dual codes of lengths 40, 50, and
60. When $m=5$, we obtain a new 8-quasi-cyclic self-dual $[40, 20, 12]$ code
over $\mathbb F_3$ and a new 6-quasi-cyclic self-dual $[30, 15, 10]$ code over
$\mathbb F_4$. When $m=7$, we find a new 4-quasi-cyclic self-dual $[28, 14, 9]$
code over $\mathbb F_4$ and a new 6-quasi-cyclic self-dual $[42,21,12]$ code
over $\mathbb F_4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6022</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6022</id><created>2012-01-29</created><updated>2013-01-01</updated><authors><author><keyname>Domb</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Non-Random Coding Error Exponent for Lattices</title><categories>cs.IT math.IT</categories><comments>A subset of this work was submitted to the IEEE International
  Symposium on Information Theory (ISIT) 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An upper bound on the error probability of specific lattices, based on their
distance-spectrum, is constructed. The derivation is accomplished using a
simple alternative to the Minkowski-Hlawka mean-value theorem of the geometry
of numbers. In many ways, the new bound greatly resembles the Shulman-Feder
bound for linear codes. Based on the new bound, an error-exponent is derived
for specific lattice sequences (of increasing dimension) over the AWGN channel.
Measuring the sequence's gap to capacity, using the new exponent, is
demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6028</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6028</id><created>2012-01-29</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Turing Impossibility Properties for Stack Machine Programming</title><categories>cs.LO</categories><comments>arXiv admin note: substantial text overlap with arXiv:0910.5564</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The strong, intermediate, and weak Turing impossibility properties are
introduced. Some facts concerning Turing impossibility for stack machine
programming are trivially adapted from previous work. Several intriguing
questions are raised about the Turing impossibility properties concerning
different method interfaces for stack machine programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6033</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6033</id><created>2012-01-29</created><authors><author><keyname>Trt&#xed;k</keyname><forenames>Marek</forenames></author></authors><title>Compact Symbolic Execution (technical report)</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generalisation of King's symbolic execution technique called
compact symbolic execution. It is based on a concept of templates: a template
is a declarative parametric description of such a program part, generating
paths in symbolic execution tree with regularities in program states along
them. Typical sources of these paths are program loops and recursive calls.
Using the templates we fold the corresponding paths into single vertices and
therefore considerably reduce size of the tree without loss of any information.
There are even programs for which compact symbolic execution trees are finite
even though the classic symbolic execution trees are infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6034</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6034</id><created>2012-01-29</created><authors><author><keyname>Datta</keyname><forenames>Tanumay</forenames></author><author><keyname>Kumar</keyname><forenames>N. Ashok</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Novel MCMC Based Receiver for Large-Scale Uplink Multiuser MIMO
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose low complexity algorithms based on Markov chain
Monte Carlo (MCMC) technique for signal detection and channel estimation on the
uplink in large scale multiuser multiple input multiple output (MIMO) systems
with tens to hundreds of antennas at the base station (BS) and similar number
of uplink users. A BS receiver that employs a randomized sampling method (which
makes a probabilistic choice between Gibbs sampling and random sampling in each
iteration) for detection and a Gibbs sampling based method for channel
estimation is proposed. The algorithm proposed for detection alleviates the
stalling problem encountered at high SNRs in conventional MCMC algorithm and
achieves near-optimal performance in large systems. A novel ingredient in the
detection algorithm that is responsible for achieving near-optimal performance
at low complexities is the joint use of a {\it randomized MCMC (R-MCMC)
strategy} coupled with a {\it multiple restart strategy} with an efficient
restart criterion. Near-optimal detection performance is demonstrated for large
number of BS antennas and users (e.g., 64, 128, 256 BS antennas/users). The
proposed MCMC based channel estimation algorithm refines an initial estimate of
the channel obtained during pilot phase through iterations with R-MCMC
detection during data phase. In time division duplex (TDD) systems where
channel reciprocity holds, these channel estimates can be used for multiuser
MIMO precoding on the downlink. Further, we employ this receiver architecture
in the frequency domain for receiving cyclic prefixed single carrier (CPSC)
signals on frequency selective fading between users and the BS. The proposed
receiver achieves performance that is near optimal and close to that achieved
with perfect channel knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6035</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6035</id><created>2012-01-29</created><authors><author><keyname>Druinsky</keyname><forenames>Alex</forenames></author><author><keyname>Toledo</keyname><forenames>Sivan</forenames></author></authors><title>How Accurate is inv(A)*b?</title><categories>cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several widely-used textbooks lead the reader to believe that solving a
linear system of equations Ax = b by multiplying the vector b by a computed
inverse inv(A) is inaccurate. Virtually all other textbooks on numerical
analysis and numerical linear algebra advise against using computed inverses
without stating whether this is accurate or not. In fact, under reasonable
assumptions on how the inverse is computed, x = inv(A)*b is as accurate as the
solution computed by the best backward-stable solvers. This fact is not new,
but obviously obscure. We review the literature on the accuracy of this
computation and present a self-contained numerical analysis of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6043</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6043</id><created>2012-01-29</created><updated>2012-04-04</updated><authors><author><keyname>Alahmadi</keyname><forenames>Adel</forenames></author><author><keyname>Aldred</keyname><forenames>R. E. L.</forenames></author><author><keyname>Cruz</keyname><forenames>Romar dela</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author><author><keyname>Thomassen</keyname><forenames>Carsten</forenames></author></authors><title>The maximum number of minimal codewords in long codes</title><categories>cs.IT math.CO math.IT</categories><comments>9 pages, submitted to Discrete Applied Math</comments><msc-class>94A10 (Primary) 05C38, 05B35 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upper bounds on the maximum number of minimal codewords in a binary code
follow from the theory of matroids. Random coding provide lower bounds. In this
paper we compare these bounds with analogous bounds for the cycle code of
graphs. This problem (in the graphic case) was considered in 1981 by Entringer
and Slater who asked if a connected graph with $p$ vertices and $q$ edges can
have only slightly more that $2^{q-p}$ cycles. The bounds in this note answer
this in the affirmative for all graphs except possibly some that have fewer
than $2p+3\log_2(3p)$ edges. We also conclude that an Eulerian (even) graph has
at most $2^{q-p}$ cycles unless the graph is a subdivision of a 4-regular graph
that is the edge-disjoint union of two Hamiltonian cycles, in which case it may
have as many as $2^{q-p}+p$ cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6046</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6046</id><created>2012-01-29</created><updated>2012-01-31</updated><authors><author><keyname>Boczkowski</keyname><forenames>Lucas</forenames></author></authors><title>Extended Extremes of Information Combining</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extremes of information combining inequalities play an important role in the
analysis of sparse-graph codes under message-passing decoding. We introduce new
tools for the derivation of such inequalities, and show by means of a concrete
examples how they can be applied to solve some optimization problems in the
analysis of low-density parity-check codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6049</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6049</id><created>2012-01-29</created><authors><author><keyname>Knill</keyname><forenames>Oliver</forenames></author></authors><title>The theorems of Green-Stokes,Gauss-Bonnet and Poincare-Hopf in Graph
  Theory</title><categories>math.DG cs.DM</categories><comments>10 pages, 30 figures, pedagogical exposition</comments><msc-class>05C10, 57M15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By proving graph theoretical versions of Green-Stokes, Gauss-Bonnet and
Poincare-Hopf, core ideas of undergraduate mathematics can be illustrated in a
simple graph theoretical setting. In this pedagogical exposition we present the
main proofs on a single page and add illustrations. While discrete Stokes is is
old, the other two results for graphs were found only recently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6053</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6053</id><created>2012-01-29</created><authors><author><keyname>Amooee</keyname><forenames>Golriz</forenames></author><author><keyname>Minaei-Bidgoli</keyname><forenames>Behrouz</forenames></author><author><keyname>Bagheri-Dehnavi</keyname><forenames>Malihe</forenames></author></authors><title>A Comparison Between Data Mining Prediction Algorithms for Fault
  Detection(Case study: Ahanpishegan co.)</title><categories>cs.LG</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011 ISSN (Online): 1694-0814 www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current competitive world, industrial companies seek to manufacture
products of higher quality which can be achieved by increasing reliability,
maintainability and thus the availability of products. On the other hand,
improvement in products lifecycle is necessary for achieving high reliability.
Typically, maintenance activities are aimed to reduce failures of industrial
machinery and minimize the consequences of such failures. So the industrial
companies try to improve their efficiency by using different fault detection
techniques. One strategy is to process and analyze previous generated data to
predict future failures. The purpose of this paper is to detect wasted parts
using different data mining algorithms and compare the accuracy of these
algorithms. A combination of thermal and physical characteristics has been used
and the algorithms were implemented on Ahanpishegan's current data to estimate
the availability of its produced parts.
  Keywords: Data Mining, Fault Detection, Availability, Prediction Algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6054</identifier>
 <datestamp>2014-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6054</id><created>2012-01-29</created><updated>2014-03-06</updated><authors><author><keyname>Bauso</keyname><forenames>Dario</forenames></author><author><keyname>Lehrer</keyname><forenames>Ehud</forenames></author><author><keyname>Solan</keyname><forenames>Eilon</forenames></author><author><keyname>Venel</keyname><forenames>Xavier</forenames></author></authors><title>Attainability in Repeated Games with Vector Payoffs</title><categories>math.OC cs.GT</categories><comments>28 pages, 2 figures, conference version at NetGCoop 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of attainable sets of payoffs in two-player repeated
games with vector payoffs. A set of payoff vectors is called {\em attainable}
if player 1 can ensure that there is a finite horizon $T$ such that after time
$T$ the distance between the set and the cumulative payoff is arbitrarily
small, regardless of what strategy player 2 is using. This paper focuses on the
case where the attainable set consists of one payoff vector. In this case the
vector is called an attainable vector. We study properties of the set of
attainable vectors, and characterize when a specific vector is attainable and
when every vector is attainable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6057</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6057</id><created>2012-01-29</created><authors><author><keyname>Laemmel</keyname><forenames>Ralf</forenames></author><author><keyname>Thompson</keyname><forenames>Simon</forenames></author><author><keyname>Kaiser</keyname><forenames>Markus</forenames></author></authors><title>Programming errors in traversal programs over structured data</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traversal strategies \'a la Stratego (also \'a la Strafunski and 'Scrap Your
Boilerplate') provide an exceptionally versatile and uniform means of querying
and transforming deeply nested and heterogeneously structured data including
terms in functional programming and rewriting, objects in OO programming, and
XML documents in XML programming. However, the resulting traversal programs are
prone to programming errors. We are specifically concerned with errors that go
beyond conservative type errors; examples we examine include divergent
traversals, prematurely terminated traversals, and traversals with dead code.
Based on an inventory of possible programming errors we explore options of
static typing and static analysis so that some categories of errors can be
avoided. This exploration generates suggestions for improvements to strategy
libraries as well as their underlying programming languages. Haskell is used
for illustrations and specifications with sufficient explanations to make the
presentation comprehensible to the non-specialist. The overall ideas are
language-agnostic and they are summarized accordingly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6065</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6065</id><created>2012-01-29</created><authors><author><keyname>Wang</keyname><forenames>Qingsi</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Throughput Optimal Switching in Multi-channel WLANs</title><categories>cs.SY cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We observe that in a multi-channel wireless system, an opportunistic
channel/spectrum access scheme that solely focuses on channel quality sensing
measured by received SNR may induce users to use channels that, while providing
better signals, are more congested. Ultimately the notion of channel quality
should include both the signal quality and the level of congestion, and a good
multi-channel access scheme should take both into account in deciding which
channel to use and when. Motivated by this, we focus on the congestion aspect
and examine what type of dynamic channel switching schemes may result in the
best system throughput performance. Specifically we derive the stability region
of a multi-user multi-channel WLAN system and determine the throughput optimal
channel switching scheme within a certain class of schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6078</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6078</id><created>2012-01-29</created><updated>2012-02-20</updated><authors><author><keyname>Tan</keyname><forenames>Shin Hwei</forenames></author><author><keyname>Marinov</keyname><forenames>Darko</forenames></author><author><keyname>Tan</keyname><forenames>Lin</forenames></author><author><keyname>Leavens</keyname><forenames>Gary T.</forenames></author></authors><title>@tComment: Testing Javadoc Comments to Detect Comment-Code
  Inconsistencies</title><categories>cs.SE</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6090</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6090</id><created>2012-01-29</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Yao</keyname><forenames>Penghui</forenames></author></authors><title>A parallel approximation algorithm for mixed packing and covering
  semidefinite programs</title><categories>cs.DS cs.DC</categories><comments>8 pages, version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a parallel approximation algorithm for a class of mixed packing
and covering semidefinite programs which generalize on the class of positive
semidefinite programs as considered by Jain and Yao [2011]. As a corollary we
get a faster approximation algorithm for positive semidefinite programs with
better dependence of the parallel running time on the approximation factor, as
compared to that of Jain and Yao [2011]. Our algorithm and analysis is on
similar lines as that of Young [2001] who considered analogous linear programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6095</identifier>
 <datestamp>2013-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6095</id><created>2012-01-29</created><updated>2013-07-29</updated><authors><author><keyname>Wu</keyname><forenames>Lingfei</forenames></author><author><keyname>Ackland</keyname><forenames>Robert</forenames></author></authors><title>How Web 1.0 Fails: The Mismatch Between Hyperlinks and Clickstreams</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The core of the Web is a hyperlink navigation system collaboratively set up
by webmasters to help users find desired websites. But does this system really
work as expected? We show that the answer seems to be negative: there is a
substantial mismatch between hyperlinks and the pathways that users actually
take. A closer look at empirical surfing activities reveals the reason of the
mismatch: webmasters try to build a global virtual world without geographical
or cultural boundaries, but users in fact prefer to navigate within more
fragmented, language-based groups of websites. We call this type of behavior
&quot;preferential navigation&quot; and find that it is driven by &quot;local&quot; search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6112</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6112</id><created>2012-01-30</created><authors><author><keyname>Mousavi</keyname><forenames>Seyed Aliakbar</forenames></author><author><keyname>Arshad</keyname><forenames>Muhammad Rafie Hj</forenames></author><author><keyname>Mohamed</keyname><forenames>Hasimah Hj</forenames></author><author><keyname>Alomari</keyname><forenames>Saleh Ali</forenames></author></authors><title>An Efficient Method for Mining Event-Related Potential Patterns</title><categories>cs.DB</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 1, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, we propose a Neuroelectromagnetic Ontology Framework
(NOF) for mining Event-related Potentials (ERP) patterns as well as the
process. The aim for this research is to develop an infrastructure for mining,
analysis and sharing the ERP domain ontologies. The outcome of this research is
a Neuroelectromagnetic knowledge-based system. The framework has 5 stages: 1)
Data pre-processing and preparation; 2) Data mining application; 3) Rule
Comparison and Evaluation; 4) Association rules Post-processing 5) Domain
Ontologies. In 5th stage a new set of hidden rules can be discovered base on
comparing association rules by domain ontologies and expert rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6116</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6116</id><created>2012-01-30</created><authors><author><keyname>Banderier</keyname><forenames>Cyril</forenames><affiliation>LIPN</affiliation></author><author><keyname>Hitczenko</keyname><forenames>Pawel</forenames></author></authors><title>Enumeration and asymptotics of restricted compositions having the same
  number of parts</title><categories>math.CO cs.DM math.PR</categories><comments>Discrete Applied Mathematics (2012) 1-13</comments><proxy>ccsd</proxy><journal-ref>Discrete Applied Mathematics. Volume 160, Issue 18, December 2012,
  Pages 2542-2554</journal-ref><doi>10.1016/j.dam.2011.12.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study pairs and m--tuples of compositions of a positive integer n with
parts restricted to a subset P of positive integers. We obtain some exact
enumeration results for the number of tuples of such compositions having the
same number of parts. Under the uniform probability model, we obtain the
asymptotics for the probability that two or, more generally, m randomly and
independently chosen compositions of n have the same number of parts. For a
large class of compositions, we show how a nice interplay between complex
analysis and probability theory allows to get full asymptotics for this
probability. Our results extend an earlier work of B\'ona and Knopfmacher.
While we restrict our attention to compositions, our approach is also of
interest for tuples of other combinatorial structures having the same number of
parts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6117</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6117</id><created>2012-01-30</created><updated>2012-05-11</updated><authors><author><keyname>Ivan</keyname><forenames>Ioana</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author><author><keyname>Yuen</keyname><forenames>Henry</forenames></author></authors><title>Continuous Time Channels with Interference</title><categories>cs.IT math.IT</categories><comments>7 pages. To appear in ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Khanna and Sudan \cite{KS11} studied a natural model of continuous time
channels where signals are corrupted by the effects of both noise and delay,
and showed that, surprisingly, in some cases both are not enough to prevent
such channels from achieving unbounded capacity. Inspired by their work, we
consider channels that model continuous time communication with adversarial
delay errors. The sender is allowed to subdivide time into an arbitrarily large
number $M$ of micro-units in which binary symbols may be sent, but the symbols
are subject to unpredictable delays and may interfere with each other. We model
interference by having symbols that land in the same micro-unit of time be
summed, and we study $k$-interference channels, which allow receivers to
distinguish sums up to the value $k$. We consider both a channel adversary that
has a limit on the maximum number of steps it can delay each symbol, and a more
powerful adversary that only has a bound on the average delay.
  We give precise characterizations of the threshold between finite and
infinite capacity depending on the interference behavior and on the type of
channel adversary: for max-bounded delay, the threshold is at
$D_{\text{max}}=\ThetaM \log\min{k, M}))$, and for average bounded delay the
threshold is at $D_{\text{avg}} = \Theta(\sqrt{M \cdot \min\{k, M\}})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6134</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6134</id><created>2012-01-30</created><updated>2014-07-15</updated><authors><author><keyname>Antulov-Fantulin</keyname><forenames>Nino</forenames></author><author><keyname>Bosnjak</keyname><forenames>Matko</forenames></author><author><keyname>Zlatic</keyname><forenames>Vinko</forenames></author><author><keyname>Grcar</keyname><forenames>Miha</forenames></author><author><keyname>Smuc</keyname><forenames>Tomislav</forenames></author></authors><title>Synthetic sequence generator for recommender systems - memory biased
  random walk on sequence multilayer network</title><categories>cs.IR cs.CY</categories><comments>The new updated version of the paper</comments><acm-class>K.4.1; H.2.8; G.3</acm-class><doi>10.1007/978-3-319-11812-3_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personalized recommender systems rely on each user's personal usage data in
the system, in order to assist in decision making. However, privacy policies
protecting users' rights prevent these highly personal data from being publicly
available to a wider researcher audience. In this work, we propose a memory
biased random walk model on multilayer sequence network, as a generator of
synthetic sequential data for recommender systems. We demonstrate the
applicability of the synthetic data in training recommender system models for
cases when privacy policies restrict clickstream publishing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6141</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6141</id><created>2012-01-30</created><updated>2014-08-07</updated><authors><author><keyname>Gopichand</keyname><forenames>Merugu.</forenames></author><author><keyname>Rao</keyname><forenames>A. Ananda</forenames></author></authors><title>Four Layered Approach to Non-Functional Requirements Analysis</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of non-functional requirements is important for successful
development and deployment of the software product. The acceptance of the
software product by the customer depends on the non-functional requirements
which are incorporated in the software. For this, we need to identify all the
non-functional requirements required by all stakeholders. In the literature not
many approaches are available for this purpose. Hence, we have proposed a four
layered analysis approach for identification of non-functional requirements.
The proposed layered approach has many advantages over non-layered approach. As
part of this approach some rules are also proposed to be used in each layer.
The approach is applied successfully on two case studies. The identified
non-functional requirements are validated using a check list and in addition
the completeness of the identified non-requirements is computed using a metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6162</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6162</id><created>2012-01-30</created><authors><author><keyname>Christou</keyname><forenames>Michalis</forenames></author><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author><author><keyname>Iliopoulos</keyname><forenames>Costas</forenames></author></authors><title>Quasiperiodicities in Fibonacci strings</title><categories>math.CO cs.DS</categories><comments>In Local Proceedings of &quot;The 38th International Conference on Current
  Trends in Theory and Practice of Computer Science&quot; (SOFSEM 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding quasiperiodicities in a Fibonacci string.
A factor u of a string y is a cover of y if every letter of y falls within some
occurrence of u in y. A string v is a seed of y, if it is a cover of a
superstring of y. A left seed of a string y is a prefix of y that it is a cover
of a superstring of y. Similarly a right seed of a string y is a suffix of y
that it is a cover of a superstring of y. In this paper, we present some
interesting results regarding quasiperiodicities in Fibonacci strings, we
identify all covers, left/right seeds and seeds of a Fibonacci string and all
covers of a circular Fibonacci string.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6166</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6166</id><created>2012-01-30</created><authors><author><keyname>Reddy</keyname><forenames>P. V. Subba</forenames></author><author><keyname>Iyer</keyname><forenames>K. V.</forenames></author></authors><title>Conditional and Unique Coloring of Graphs (revised resubmission)</title><categories>cs.DM</categories><comments>Was submitted and withdrawn from Utilitas Mathematica prior to
  submission to Graphs and Combinatorics where the paper in this version is now
  under review</comments><msc-class>68R10, 05C15</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  For integers $k&gt;0$ and $0&lt;r \leq \Delta$ (where $r \leq k$), a conditional
$(k,r)$-coloring of a graph $G$ is a proper $k$-coloring of the vertices of $G$
such that every vertex $v$ of degree $d(v)$ in $G$ is adjacent to vertices with
at least $\min\{r, d(v)\}$ differently colored neighbors. The smallest integer
$k$ for which a graph $G$ has a conditional $(k,r)$-coloring is called the
$r$th order conditional chromatic number, denoted by $\chi_r(G)$. For different
values of $r$ we first give results (exact values or bounds for $\chi_r(G)$
depending on $r$) related to the conditional coloring of graphs. Then we obtain
$\chi_r(G)$ of certain parameterized graphs viz., windmill graph, line graph of
windmill graph, middle graph of friendship graph, middle graph of a cycle, line
graph of friendship graph, middle graph of complete $k$-partite graph, middle
graph of a bipartite graph and gear graph. Finally we introduce \emph{unique
conditional colorability} and give some related results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6174</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6174</id><created>2012-01-30</created><updated>2012-12-19</updated><authors><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author></authors><title>A Time-Efficient Output-Sensitive Quantum Algorithm for Boolean Matrix
  Multiplication</title><categories>quant-ph cs.DS</categories><comments>v2: slight modification of the title, addition of Theorem 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a quantum algorithm that computes the product of two
$n\times n$ Boolean matrices in $\tilde O(n\sqrt{\ell}+\ell\sqrt{n})$ time,
where $\ell$ is the number of non-zero entries in the product. This improves
the previous output-sensitive quantum algorithms for Boolean matrix
multiplication in the time complexity setting by Buhrman and \v{S}palek
(SODA'06) and Le Gall (SODA'12). We also show that our approach cannot be
further improved unless a breakthrough is made: we prove that any significant
improvement would imply the existence of an algorithm based on quantum search
that multiplies two $n\times n$ Boolean matrices in $O(n^{5/2-\varepsilon})$
time, for some constant $\varepsilon&gt;0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6179</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6179</id><created>2012-01-30</created><updated>2012-03-09</updated><authors><author><keyname>Bartolucci</keyname><forenames>Francesco</forenames></author></authors><title>Decomposition of the h-index</title><categories>cs.DL physics.soc-ph</categories><comments>Trasformed into a letter to the Editor of the &quot;Journal of the
  American Society for Information&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I introduce a decomposition of the h-index, which is nowadays the leading
criterion to assess the relevance of a scientist in his/her research field.
According to the proposed decomposition, the h-index is the product of two
indicators, the first of which measures the impact of the scientist on the
research community and the second may be seen as a measure of concentration of
the citations in correspondence of a reduced number of papers. The
decomposition is illustrated by an application based on data concerning a group
of top level economists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6181</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6181</id><created>2012-01-30</created><updated>2012-07-12</updated><authors><author><keyname>Jung</keyname><forenames>Tobias</forenames></author><author><keyname>Martin</keyname><forenames>Sylvain</forenames></author><author><keyname>Ernst</keyname><forenames>Damien</forenames></author><author><keyname>Leduc</keyname><forenames>Guy</forenames></author></authors><title>Contextual Multi-armed Bandits for the Prevention of Spam in VoIP
  Networks</title><categories>cs.NI</categories><comments>Technical report, 19 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we argue that contextual multi-armed bandit algorithms could
open avenues for designing self-learning security modules for computer networks
and related tasks. The paper has two contributions: a conceptual one and an
algorithmical one. The conceptual contribution is to formulate -- as an example
-- the real-world problem of preventing SPIT (Spam in VoIP networks), which is
currently not satisfyingly addressed by standard techniques, as a sequential
learning problem, namely as a contextual multi-armed bandit. Our second
contribution is to present CMABFAS, a new algorithm for general contextual
multi-armed bandit learning that specifically targets domains with finite
actions. We illustrate how CMABFAS could be used to design a fully
self-learning SPIT filter that does not rely on feedback from the end-user
(i.e., does not require labeled data) and report first simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6188</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6188</id><created>2012-01-30</created><authors><author><keyname>Bartoletti</keyname><forenames>Massimo</forenames></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames></author><author><keyname>Zunino</keyname><forenames>Roberto</forenames></author></authors><title>On the realizability of contracts in dishonest systems</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a theory of contracting systems, where behavioural contracts may
be violated by dishonest participants after they have been agreed upon - unlike
in traditional approaches based on behavioural types. We consider the contracts
of \cite{CastagnaPadovaniGesbert09toplas}, and we embed them in a calculus that
allows distributed participants to advertise contracts, reach agreements, query
the fulfilment of contracts, and realise them (or choose not to).
  Our contract theory makes explicit who is culpable at each step of a
computation. A participant is honest in a given context S when she is not
culpable in each possible interaction with S. Our main result is a sufficient
criterion for classifying a participant as honest in all possible contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6190</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6190</id><created>2012-01-30</created><authors><author><keyname>Jung</keyname><forenames>Tobias</forenames></author><author><keyname>Martin</keyname><forenames>Sylvain</forenames></author><author><keyname>Nassar</keyname><forenames>Mohamed</forenames></author><author><keyname>Ernst</keyname><forenames>Damien</forenames></author><author><keyname>Leduc</keyname><forenames>Guy</forenames></author></authors><title>Outbound SPIT Filter with Optimal Performance Guarantees</title><categories>cs.NI</categories><comments>in submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a formal framework for identifying and filtering SPIT
calls (SPam in Internet Telephony) in an outbound scenario with provable
optimal performance. In so doing, our work is largely different from related
previous work: our goal is to rigorously formalize the problem in terms of
mathematical decision theory, find the optimal solution to the problem, and
derive concrete bounds for its expected loss (number of mistakes the SPIT
filter will make in the worst case).
  This goal is achieved by considering an abstracted scenario amenable to
theoretical analysis, namely SPIT detection in an outbound scenario with pure
sources. Our methodology is to first define the cost of making an error (false
positive and false negative), apply Wald's sequential probability ratio test to
the individual sources, and then determine analytically error probabilities
such that the resulting expected loss is minimized.
  The benefits of our approach are: (1) the method is optimal (in a sense
defined in the paper); (2) the method does not rely on manual tuning and
tweaking of parameters but is completely self-contained and mathematically
justified; (3) the method is computationally simple and scalable. These are
desirable features that would make our method a component of choice in larger,
autonomic frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6207</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6207</id><created>2012-01-30</created><updated>2012-02-01</updated><authors><author><keyname>Kloks</keyname><forenames>T.</forenames></author></authors><title>k-Probe DH-graphs</title><categories>cs.DS</categories><comments>We are working on an improved description of these results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let k be a natural number. Let G be a graph and let N_1,...,N_k be k
independent sets in G. The graph G is k-probe distance hereditary if G can be
embedded into a DH-graph by adding edges between vertices that are contained in
the same independent set. We show that there exists a polynomial-time algorithm
to check if a graph G is k-probe distance hereditary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6218</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6218</id><created>2012-01-30</created><authors><author><keyname>Janicki</keyname><forenames>Artur</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Influence of Speech Codecs Selection on Transcoding Steganography</title><categories>cs.CR cs.MM</categories><comments>17 pages, 5 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The typical approach to steganography is to compress the covert data in order
to limit its size, which is reasonable in the context of a limited
steganographic bandwidth. TranSteg (Trancoding Steganography) is a new IP
telephony steganographic method that was recently proposed that offers high
steganographic bandwidth while retaining good voice quality. In TranSteg,
compression of the overt data is used to make space for the steganogram. In
this paper we focus on analyzing the influence of the selection of speech
codecs on hidden transmission performance, that is, which codecs would be the
most advantageous ones for TranSteg. Therefore, by considering the codecs which
are currently most popular for IP telephony we aim to find out which codecs
should be chosen for transcoding to minimize the negative influence on voice
quality while maximizing the obtained steganographic bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6222</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6222</id><created>2012-01-30</created><updated>2013-05-12</updated><authors><author><keyname>Krcal</keyname><forenames>Marek</forenames></author><author><keyname>Matousek</keyname><forenames>Jiri</forenames></author><author><keyname>Sergeraert</keyname><forenames>Francis</forenames></author></authors><title>Polynomial-time homology for simplicial Eilenberg-MacLane spaces</title><categories>cs.CG math.AT</categories><comments>31 pages; a mistake in the analysis of the bubblesort field from the
  previous versions fixed</comments><msc-class>68U05, 68W99, 55S45, 55S37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an earlier paper of Cadek, Vokrinek, Wagner, and the present authors, we
investigated an algorithmic problem in computational algebraic topology,
namely, the computation of all possible homotopy classes of maps between two
topological spaces, under suitable restriction on the spaces.
  We aim at showing that, if the dimensions of the considered spaces are
bounded by a constant, then the computations can be done in polynomial time. In
this paper we make a significant technical step towards this goal: we show that
the Eilenberg-MacLane space K(Z,1), represented as a simplicial group, can be
equipped with polynomial-time homology (this is a polynomial-time version of
effective homology considered in previous works of the third author and
co-workers). To this end, we construct a suitable discrete vector field, in the
sense of Forman's discrete Morse theory, on K(Z,1). The construction is purely
combinatorial and it can be understood as a certain procedure for reducing
finite sequences of integers, without any reference to topology.The
Eilenberg-MacLane spaces are the basic building blocks in a Postnikov system,
which is a &quot;layered&quot; representation of a topological space suitable for
homotopy-theoretic computations.
  Employing the result of this paper together with some other results on
polynomial-time homology, in another paper we obtain, for every fixed k, a
polynomial-time algorithm for computing the k-th homotopy group pi_k(X) of a
given simply connected space X, as well as the first k stages of a Postnikov
system for X, and also a polynomial-time version of the algorithm of Cadek et
al. mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6224</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6224</id><created>2012-01-30</created><updated>2012-02-01</updated><authors><author><keyname>Haralambous</keyname><forenames>Yannis</forenames></author><author><keyname>Klyuev</keyname><forenames>Vitaly</forenames></author></authors><title>Wikipedia Arborification and Stratified Explicit Semantic Analysis</title><categories>cs.CL</categories><comments>13 pages, 2 figures, submitted to conference TALN 2012</comments><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  [This is the translation of paper &quot;Arborification de Wikip\'edia et analyse
s\'emantique explicite stratifi\'ee&quot; submitted to TALN 2012.]
  We present an extension of the Explicit Semantic Analysis method by
Gabrilovich and Markovitch. Using their semantic relatedness measure, we weight
the Wikipedia categories graph. Then, we extract a minimal spanning tree, using
Chu-Liu &amp; Edmonds' algorithm. We define a notion of stratified tfidf where the
stratas, for a given Wikipedia page and a given term, are the classical tfidf
and categorical tfidfs of the term in the ancestor categories of the page
(ancestors in the sense of the minimal spanning tree). Our method is based on
this stratified tfidf, which adds extra weight to terms that &quot;survive&quot; when
climbing up the category tree. We evaluate our method by a text classification
on the WikiNews corpus: it increases precision by 18%. Finally, we provide
hints for future research
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6236</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6236</id><created>2012-01-30</created><updated>2013-04-24</updated><authors><author><keyname>Hare</keyname><forenames>Kevin G.</forenames></author><author><keyname>Morris</keyname><forenames>Ian D.</forenames></author><author><keyname>Sidorov</keyname><forenames>Nikita</forenames></author></authors><title>Extremal sequences of polynomial complexity</title><categories>math.OC cs.DM math.DS math.OA</categories><comments>15 pages</comments><msc-class>15A60 (Primary) 37B10, 65K10, 68R15 (Secondary)</msc-class><journal-ref>Math. Proc. Camb. Phil. Soc. 155 (2013),191-205</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The joint spectral radius of a bounded set of $d \times d$ real matrices is
defined to be the maximum possible exponential growth rate of products of
matrices drawn from that set. For a fixed set of matrices, a sequence of
matrices drawn from that set is called \emph{extremal} if the associated
sequence of partial products achieves this maximal rate of growth. An
influential conjecture of J. Lagarias and Y. Wang asked whether every finite
set of matrices admits an extremal sequence which is periodic. This is
equivalent to the assertion that every finite set of matrices admits an
extremal sequence with bounded subword complexity. Counterexamples were
subsequently constructed which have the property that every extremal sequence
has at least linear subword complexity. In this paper we extend this result to
show that for each integer $p \geq 1$, there exists a pair of square matrices
of dimension $2^p(2^{p+1}-1)$ for which every extremal sequence has subword
complexity at least $2^{-p^2}n^p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6248</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6248</id><created>2012-01-30</created><updated>2012-04-23</updated><authors><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>List Decoding Algorithms based on Groebner Bases for General One-Point
  AG Codes</title><categories>cs.IT cs.SC math.AC math.AG math.IT</categories><comments>IEEEtran.cls, 5 pages, no figure. To appear in Proc. 2012 IEEE
  International Symposium on Information Theory, July 1-6, 2012, Boston, MA,
  USA. Version 4 corrected wrong description of the work by Lee, Bras-Amor\'os
  and O'Sullivan, and added four references</comments><msc-class>94B35 (Primary) 13P10, 94B27, 14G50 (Secondary)</msc-class><acm-class>E.4; F.2.1; I.1.2; I.1.4</acm-class><journal-ref>Proc. 2012 IEEE International Symposium on Information Theory,
  July 1-6, 2012, Boston, MA, USA, pages 86-90</journal-ref><doi>10.1109/ISIT.2012.6284685</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the list decoding algorithm for Hermitian codes proposed by Lee
and O'Sullivan based on Gr\&quot;obner bases to general one-point AG codes, under an
assumption weaker than one used by Beelen and Brander. By using the same
principle, we also generalize the unique decoding algorithm for one-point AG
codes over the Miura-Kamiya $C_{ab}$ curves proposed by Lee, Bras-Amor\'os and
O'Sullivan to general one-point AG codes, without any assumption. Finally we
extend the latter unique decoding algorithm to list decoding, modify it so that
it can be used with the Feng-Rao improved code construction, prove equality
between its error correcting capability and half the minimum distance lower
bound by Andersen and Geil that has not been done in the original proposal, and
remove the unnecessary computational steps so that it can run faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6251</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6251</id><created>2012-01-27</created><authors><author><keyname>Tigas</keyname><forenames>Panagiotis</forenames></author></authors><title>Real-time jam-session support system</title><categories>cs.HC cs.LG cs.SD</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We propose a method for the problem of real time chord accompaniment of
improvised music. Our implementation can learn an underlying structure of the
musical performance and predict next chord. The system uses Hidden Markov Model
to find the most probable chord sequence for the played melody and then a
Variable Order Markov Model is used to a) learn the structure (if any) and b)
predict next chord. We implemented our system in Java and MAX/Msp and compared
and evaluated using objective (prediction accuracy) and subjective
(questionnaire) evaluation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6257</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6257</id><created>2012-01-30</created><authors><author><keyname>Buesser</keyname><forenames>Pierre</forenames></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames></author></authors><title>Supercooperation in Evolutionary Games on Correlated Weighted Networks</title><categories>physics.soc-ph cs.SI</categories><comments>21 pages</comments><journal-ref>Phys. Rev. E 85, 016107 (2012)</journal-ref><doi>10.1103/PhysRevE.85.016107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the behavior of classical two-person, two-strategies
evolutionary games on a class of weighted networks derived from
Barab\'asi-Albert and random scale-free unweighted graphs. Using customary
imitative dynamics, our numerical simulation results show that the presence of
link weights that are correlated in a particular manner with the degree of the
link endpoints, leads to unprecedented levels of cooperation in the whole
games' phase space, well above those found for the corresponding unweighted
complex networks. We provide intuitive explanations for this favorable behavior
by transforming the weighted networks into unweighted ones with particular
topological properties. The resulting structures help to understand why
cooperation can thrive and also give ideas as to how such supercooperative
networks might be built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6271</identifier>
 <datestamp>2012-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6271</id><created>2012-01-30</created><updated>2012-02-02</updated><authors><author><keyname>Nabaee</keyname><forenames>Mahdy</forenames></author><author><keyname>Labeau</keyname><forenames>Fabrice</forenames></author></authors><title>Quantized Network Coding for Sparse Messages</title><categories>cs.IT math.IT</categories><doi>10.1109/SSP.2012.6319834</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the data gathering problem in the context of power
grids by using a network of sensors, where the sensed data have inter-node
redundancy. Specifically, we propose a new transmission method, calledquantized
network coding, which performs linear net-work coding in the field of real
numbers, and quantization to accommodate the finite capacity of edges. By using
the concepts in compressed sensing literature, we propose to use
l1-minimization to decode the quantized network coded packets, especially when
the number of received packets at the decoder is less than the size of sensed
data (i.e. number of nodes). We also propose an appropriate design for network
coding coefficients, based on restricted isometry property, which results in
robust l1-min decoding. Our numerical analysis show that the proposed quantized
network coding scheme with l1-min decoding can achieve significant
improvements, in terms of compression ratio and delivery delay, compared to
conventional packet forwarding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6278</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6278</id><created>2012-01-30</created><authors><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Shi</keyname><forenames>Kerui</forenames></author><author><keyname>Guo</keyname><forenames>Qiang</forenames></author></authors><title>Solving the accuracy-diversity dilemma via directed random walks</title><categories>physics.data-an cs.IR</categories><comments>8 pages, 6 figures</comments><journal-ref>PhysRevE.85.016118 (2012)</journal-ref><doi>10.1103/PhysRevE.85.016118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random walks have been successfully used to measure user or object
similarities in collaborative filtering (CF) recommender systems, which is of
high accuracy but low diversity. A key challenge of CF system is that the
reliably accurate results are obtained with the help of peers' recommendation,
but the most useful individual recommendations are hard to be found among
diverse niche objects. In this paper we investigate the direction effect of the
random walk on user similarity measurements and find that the user similarity,
calculated by directed random walks, is reverse to the initial node's degree.
Since the ratio of small-degree users to large-degree users is very large in
real data sets, the large-degree users' selections are recommended extensively
by traditional CF algorithms. By tuning the user similarity direction from
neighbors to the target user, we introduce a new algorithm specifically to
address the challenge of diversity of CF and show how it can be used to solve
the accuracy-diversity dilemma. Without relying on any context-specific
information, we are able to obtain accurate and diverse recommendations, which
outperforms the state-of-the-art CF methods. This work suggests that the random
walk direction is an important factor to improve the personalized
recommendation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6282</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6282</id><created>2012-01-30</created><updated>2012-02-29</updated><authors><author><keyname>Zubow</keyname><forenames>Anatolij</forenames></author><author><keyname>Marotzke</keyname><forenames>Johannes</forenames></author></authors><title>On the Frequency-Selective Scheduling Gain in SDMA-OFDMA Systems</title><categories>cs.NI</categories><comments>7 pages, 8 figures</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal Frequency Division Multiple Access (OFDMA) is a multi-user version
of the Orthogonal Frequency Division Multiplexing (OFDM) transmission
technique, which divides a wideband channel into a number of orthogonal
narrowband subchannels, called subcarriers. An OFDMA system takes advantage of
both frequency diversity (FD) gain and frequency-selective scheduling (FSS)
gain. A FD gain is achieved by allocating a user the subcarriers distributed
over the entire frequency band whereas a FSS gain is achieved by allocating a
user adjacent subcarriers located within a subband of a small bandwidth having
the most favorable channel conditions among other subbands in the entire
frequency band. Multi-User Multiple Input Multiple Output (MU-MIMO) is a
promising technology to increase spectral efficiency. A well-known MU-MIMO mode
is Space-Division Multiple Access (SDMA) which can be used in the downlink
direction to allow a group of spatially separable users to share the same
time/frequency resources. In this paper, we study the gain from FSS in
SDMA-OFDMA systems using the example of WiMAX. Therefore, a complete SDMA-OFDMA
MAC scheduling solution supporting both FD and FSS is proposed. The proposed
solution is analyzed in a typical urban macro-cell scenario by means of
system-level packet-based simulations, with detailed MAC and physical layer
abstractions. By explicitly simulating the MAC layer overhead (MAP) which is
required to signal every packed data burst in the OFDMA frame we can present
the overall performance to be expected at the MAC layer. Our results show that
in general the gain from FSS when applying SDMA is low. However, under specific
conditions, small number of BS antennas or large channel bandwidth, a
significant gain can be achieved from FSS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6306</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6306</id><created>2012-01-30</created><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author></authors><title>Meditations on Quantified Constraint Satisfaction</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quantified constraint satisfaction problem (QCSP) is the problem of
deciding, given a structure and a first-order prenex sentence whose
quantifier-free part is the conjunction of atoms, whether or not the sentence
holds on the structure. One obtains a family of problems by defining, for each
structure B, the problem QCSP(B) to be the QCSP where the structure is fixed to
be B. In this article, we offer a viewpoint on the research program of
understanding the complexity of the problems QCSP(B) on finite structures. In
particular, we propose and discuss a group of conjectures; throughout, we
attempt to place the conjectures in relation to existing results and to
emphasize open issues and potential research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6313</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6313</id><created>2012-01-30</created><authors><author><keyname>Tandon</keyname><forenames>Ravi</forenames><affiliation>Shitz</affiliation></author><author><keyname>Mohajer</keyname><forenames>Soheil</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>On X-Channels with Feedback and Delayed CSI</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE ISIT 2012 on Jan 22, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum degrees of freedom (DoF) of the two-user MIMO X-channel is
characterized in the presence of output feedback and delayed channel state
information (CSI). The number of antennas at each transmitters is assumed to be
M and the number of antennas at each of the receivers is assumed to be N. It is
shown that the sum DoF of the two-user MIMO X-channel is the same as the sum
DoF of a two-user MIMO broadcast channel with 2M transmit antennas, and N
antennas at each receiver. Hence, for this symmetric antenna configuration,
there is no performance loss in the sum degrees of freedom due to the
distributed nature of the transmitters. This result highlights the usefulness
of feedback and delayed CSI for the MIMO X-channel.
  The K-user X-channel with single antenna at each transmitter and each
receiver is also studied. In this network, each transmitter has a message
intended for each receiver. For this network, it is shown that the sum DoF with
partial output feedback alone is at least 2K/(K+1). This lower bound is
strictly better than the best lower bound known for the case of delayed CSI
assumption for all values of K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6322</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6322</id><created>2012-01-30</created><authors><author><keyname>Regev</keyname><forenames>Eyal</forenames></author><author><keyname>Altshuler</keyname><forenames>Yaniv</forenames></author><author><keyname>Bruckstein</keyname><forenames>Alfred M.</forenames></author></authors><title>The Cooperative Cleaners Problem in Stochastic Dynamic Environments</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the strengths and limitations of collaborative teams
of simple agents. In particular, we discuss the efficient use of &quot;ant robots&quot;
for covering a connected region on the $Z^{2}$ grid, whose area is unknown in
advance and which expands stochastically. Specifically, we discuss the problem
where an initial connected region of $S_0$ boundary tiles expand outward with
probability $p$ at every time step. On this grid region a group of $k$ limited
and simple agents operate, in order to clean the unmapped and dynamically
expanding region. A preliminary version of this problem was discussed in
[1],[2] involving a deterministic expansion of a region in the grid.In this
work we extend the model and examine cases where the spread of the region is
done stochastically, where each tile has some probability $p$ to expand, at
every time step. For this extended model we obtain an analytic probabilistic
lower bounds for the minimal number of agents and minimal time required to
enable a collaborative coverage of the expanding region, regardless of the
algorithm used and the robots' hardware and software specifications. In
addition, we present an impossibility result, for a variety of regions that
would be impossible to completely clean, regardless of the algorithm used.
Finally, we validate the analytic bounds using extensive empirical computer
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6339</identifier>
 <datestamp>2012-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6339</id><created>2012-01-30</created><updated>2012-03-28</updated><authors><author><keyname>Dickison</keyname><forenames>M.</forenames></author><author><keyname>Havlin</keyname><forenames>S.</forenames></author><author><keyname>Stanley</keyname><forenames>H. E.</forenames></author></authors><title>Epidemics on Interconnected Networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Populations are seldom completely isolated from their environment.
Individuals in a particular geographic or social region may be considered a
distinct network due to strong local ties, but will also interact with
individuals in other networks. We study the susceptible-infected-recovered
(SIR) process on interconnected network systems, and find two distinct regimes.
In strongly-coupled network systems, epidemics occur simultaneously across the
entire system at a critical infection strength $\beta_c$, below which the
disease does not spread. In contrast, in weakly-coupled network systems, a
mixed phase exists below $\beta_c$ of the coupled network system, where an
epidemic occurs in one network but does not spread to the coupled network. We
derive an expression for the network and disease parameters that allow this
mixed phase and verify it numerically. Public health implications of
communities comprising these two classes of network systems are also mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6358</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6358</id><created>2012-01-30</created><authors><author><keyname>Kao</keyname><forenames>Ming-Yang</forenames></author><author><keyname>Leung</keyname><forenames>Henry C. M.</forenames></author><author><keyname>Sun</keyname><forenames>He</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>Deterministic Polynomial-Time Algorithms for Designing Short DNA Words</title><categories>cs.DS cs.CE cs.IT math.IT</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing short DNA words is a problem of constructing a set (i.e., code) of
n DNA strings (i.e., words) with the minimum length such that the Hamming
distance between each pair of words is at least k and the n words satisfy a set
of additional constraints. This problem has applications in, e.g., DNA
self-assembly and DNA arrays. Previous works include those that extended
results from coding theory to obtain bounds on code and word sizes for
biologically motivated constraints and those that applied heuristic local
searches, genetic algorithms, and randomized algorithms. In particular, Kao,
Sanghi, and Schweller (2009) developed polynomial-time randomized algorithms to
construct n DNA words of length within a multiplicative constant of the
smallest possible word length (e.g., 9 max{log n, k}) that satisfy various sets
of constraints with high probability. In this paper, we give deterministic
polynomial-time algorithms to construct DNA words based on derandomization
techniques. Our algorithms can construct n DNA words of shorter length (e.g.,
2.1 log n + 6.28 k) and satisfy the same sets of constraints as the words
constructed by the algorithms of Kao et al. Furthermore, we extend these new
algorithms to construct words that satisfy a larger set of constraints for
which the algorithms of Kao et al. do not work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6371</identifier>
 <datestamp>2014-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6371</id><created>2012-01-30</created><updated>2014-06-03</updated><authors><author><keyname>Sobottka</keyname><forenames>Marcelo</forenames></author></authors><title>Standard decomposition of expansive ergodically supported dynamics</title><categories>math.DS cs.IT math.GR math.IT</categories><comments>18 pages, the conditions on the entropy in Theorem 3.5 was improved.
  Some small changes in the text, by adding more explanations</comments><msc-class>20N05, 17C10, 94A55, 68P30</msc-class><doi>10.1007/s11071-014-1383-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce the notion of weak quasigroups, that are quasigroup
operations defined almost everywhere on some set. Then we prove that the
topological entropy and the ergodic period of an invertible expansive
ergodically supported dynamical system $(X,T)$ with the shadowing property
establishes a sufficient criterion for the existence of quasigroup operations
defined almost everywhere outside of universally null sets and for which $T$ is
an automorphism. Furthermore, we find a decomposition of the dynamics of $T$ in
terms of $T$-invariant weak topological subquasigroups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6388</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6388</id><created>2012-01-30</created><authors><author><keyname>Dokow</keyname><forenames>Elad</forenames></author><author><keyname>Falik</keyname><forenames>Dvir</forenames></author></authors><title>Models of Manipulation on Aggregation of Binary Evaluations</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a general aggregation problem in which a society has to determine
its position on each of several issues, based on the positions of the members
of the society on those issues. There is a prescribed set of feasible
evaluations, i.e., permissible combinations of positions on the issues. Among
other things, this framework admits the modeling of preference aggregation,
judgment aggregation, classification, clustering and facility location. An
important notion in aggregation of evaluations is strategy-proofness. In the
general framework we discuss here, several definitions of strategy-proofness
may be considered. We present here 3 natural \textit{general} definitions of
strategy-proofness and analyze the possibility of designing an annonymous,
strategy-proof aggregation rule under these definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6397</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6397</id><created>2012-01-30</created><authors><author><keyname>Hernando</keyname><forenames>Fernando</forenames></author><author><keyname>H&#xf8;holdt</keyname><forenames>Tom</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>List Decoding of Matrix-Product Codes from nested codes: an application
  to Quasi-Cyclic codes</title><categories>cs.IT math.IT</categories><msc-class>94B05 (Primary) 94B35 (Secondary)</msc-class><journal-ref>Advances in Mathematics of Communications, Volume 6, Issue 3,
  pages 259-272 (2012)</journal-ref><doi>10.3934/amc.2012.6.259</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A list decoding algorithm for matrix-product codes is provided when $C_1,...,
C_s$ are nested linear codes and $A$ is a non-singular by columns matrix. We
estimate the probability of getting more than one codeword as output when the
constituent codes are Reed-Solomon codes. We extend this list decoding
algorithm for matrix-product codes with polynomial units, which are
quasi-cyclic codes. Furthermore, it allows us to consider unique decoding for
matrix-product codes with polynomial units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6398</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6398</id><created>2012-01-30</created><authors><author><keyname>Kaced</keyname><forenames>Tarik</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author></authors><title>Conditional and unconditional information inequalities: an algebraic
  example</title><categories>cs.IT math.IT math.PR</categories><comments>Short note</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a simple example showing that some conditional information
inequalities (even in a weak form) cannot be derived from unconditional
inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6402</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6402</id><created>2012-01-30</created><authors><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author></authors><title>A Note on Disk Drag Dynamics</title><categories>cs.PF cs.DB physics.class-ph</categories><comments>5 pages, 3 figures</comments><acm-class>B.3.2; C.4; D.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electrical power consumed by typical magnetic hard disk drives (HDD) not
only increases linearly with the number of spindles but, more significantly, it
increases as very fast power-laws of speed (RPM) and diameter. Since the
theoretical basis for this relationship is neither well-known nor readily
accessible in the literature, we show how these exponents arise from
aerodynamic disk drag and discuss their import for green storage capacity
planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6421</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6421</id><created>2012-01-30</created><authors><author><keyname>Kloks</keyname><forenames>Ton</forenames></author></authors><title>The black-and-white coloring problem on permutation graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G and integers b and w. The black-and-white coloring problem
asks if there exist disjoint sets of vertices B and W with |B|=b and |W|=w such
that no vertex in B is adjacent to any vertex in W. In this paper we show that
the problem is polynomial when restricted to permutation graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6425</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6425</id><created>2012-01-30</created><authors><author><keyname>Kumar</keyname><forenames>Gowtham</forenames></author><author><keyname>Manolakos</keyname><forenames>Alexandros</forenames></author></authors><title>No input symbol should occur more frequently than 1-1/e</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider any discrete memoryless channel (DMC) with arbitrarily but finite
input and output alphabets X, Y respectively. Then, for any capacity achieving
input distribution all symbols occur less frequently than 1-1/e$. That is, \[
\max\limits_{x \in \mathcal{X}} P^*(x) &lt; 1-\frac{1}{e} \] \noindent where
$P^*(x)$ is a capacity achieving input distribution. Also, we provide
sufficient conditions for which a discrete distribution can be a capacity
achieving input distribution for some DMC channel. Lastly, we show that there
is no similar restriction on the capacity achieving output distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6429</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6429</id><created>2012-01-30</created><updated>2014-04-24</updated><authors><author><keyname>Caragiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Kaklamanis</keyname><forenames>Christos</forenames></author><author><keyname>Kanellopoulos</keyname><forenames>Panagiotis</forenames></author><author><keyname>Kyropoulou</keyname><forenames>Maria</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author><author><keyname>Tardos</keyname><forenames>&#xc9;va</forenames></author></authors><title>Bounding the inefficiency of outcomes in generalized second price
  auctions</title><categories>cs.GT</categories><comments>Accepted to JET (Journal of Economic Theory). A preliminary version
  of this paper appeared in arxiv with the title &quot;On the efficiency of
  equilibria in generalized second price auctions&quot;. Conference versions of
  those results appeared in FOCS'10, EC'11 and EC'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Generalized Second Price (GSP) auction is the primary auction used for
monetizing the use of the Internet. It is well-known that truthtelling is not a
dominant strategy in this auction and that inefficient equilibria can arise. In
this paper we study the space of equilibria in GSP, and quantify the efficiency
loss that can arise in equilibria under a wide range of sources of uncertainty,
as well as in the full information setting. The traditional Bayesian game
models uncertainty in the valuations (types) of the participants. The
Generalized Second Price (GSP) auction gives rise to a further form of
uncertainty: the selection of quality factors resulting in uncertainty about
the behavior of the underlying ad allocation algorithm. The bounds we obtain
apply to both forms of uncertainty, and are robust in the sense that they apply
under various perturbations of the solution concept, extending to models with
information asymmetries and bounded rationality in the form of learning
strategies.
  We present a constant bound (2.927) on the factor of the efficiency loss
(\emph{price of anarchy}) of the corresponding game for the Bayesian model of
partial information about other participants and about ad quality factors. For
the full information setting, we prove a surprisingly low upper bound of 1.282
on the price of anarchy over pure Nash equilibria, nearly matching a lower
bound of 1.259 for the case of three advertisers. Further, we do not require
that the system reaches equilibrium, and give similarly low bounds also on the
quality degradation for any no-regret learning outcome. Our conclusion is that
the number of advertisers in the auction has almost no impact on the price of
anarchy, and that the efficiency of GSP is very robust with respect to the
belief and rationality assumptions imposed on the participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6439</identifier>
 <datestamp>2014-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6439</id><created>2012-01-30</created><updated>2014-05-29</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Fran&#xe7;oise</forenames></author><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames></author></authors><title>A baby step-giant step roadmap algorithm for general algebraic sets</title><categories>math.AG cs.SC</categories><comments>48 pages, 2 figures. Final version to appear in Foundations of
  Computational Mathematics</comments><msc-class>Primary 14Q20, Secondary 14P05, 68W05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathrm{R}$ be a real closed field and $\mathrm{D} \subset \mathrm{R}$
an ordered domain. We give an algorithm that takes as input a polynomial $Q \in
\mathrm{D}[X_1,\ldots,X_k]$, and computes a description of a roadmap of the set
of zeros, $\mathrm{Zer}(Q,\mathrm{R}^k)$, of $Q$ in $\mathrm{R}^k$. The
complexity of the algorithm, measured by the number of arithmetic operations in
the ordered domain $\mathrm{D}$, is bounded by $d^{O(k \sqrt{k})}$, where $d =
\mathrm{deg}(Q)\ge 2$. As a consequence, there exist algorithms for computing
the number of semi-algebraically connected components of a real algebraic set,
$\mathrm{Zer}(Q,\mathrm{R}^k)$, whose complexity is also bounded by $d^{O(k
\sqrt{k})}$, where $d = \mathrm{deg}(Q)\ge 2$. The best previously known
algorithm for constructing a roadmap of a real algebraic subset of
$\mathrm{R}^k$ defined by a polynomial of degree $d$ has complexity
$d^{O(k^2)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6444</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6444</id><created>2012-01-30</created><authors><author><keyname>Bindjeme</keyname><forenames>Patrick</forenames></author><author><keyname>Fill</keyname><forenames>James Allen</forenames></author></authors><title>The limiting distribution for the number of symbol comparisons used by
  QuickSort is nondegenerate (extended abstract)</title><categories>math.PR cs.DS</categories><msc-class>60F25 (Primary) 68W40 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a continuous-time setting, Fill (2010) proved, for a large class of
probabilistic sources, that the number of symbol comparisons used by QuickSort,
when centered by subtracting the mean and scaled by dividing by time, has a
limiting distribution, but proved little about that limiting random variable Y
-- not even that it is nondegenerate. We establish the nondegeneracy of Y. The
proof is perhaps surprisingly difficult.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6445</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6445</id><created>2012-01-30</created><authors><author><keyname>Bindjeme</keyname><forenames>Patrick</forenames></author><author><keyname>Fill</keyname><forenames>James Allen</forenames></author></authors><title>Exact L^2-distance from the limit for QuickSort key comparisons
  (extended abstract)</title><categories>math.PR cs.DS</categories><msc-class>60F25 (Primary) 68W40 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a recursive approach, we obtain a simple exact expression for the
L^2-distance from the limit in R\'egnier's (1989) classical limit theorem for
the number of key comparisons required by QuickSort. A previous study by Fill
and Janson (2002) using a similar approach found that the d_2-distance is of
order between n^{-1} log n and n^{-1/2}, and another by Neininger and
Ruschendorf (2002) found that the Zolotarev zeta_3-distance is of exact order
n^{-1} log n. Our expression reveals that the L^2-distance is asymptotically
equivalent to (2 n^{-1} ln n)^{1/2}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6453</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6453</id><created>2012-01-31</created><updated>2012-07-12</updated><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Kawabata</keyname><forenames>Tsutomu</forenames></author></authors><title>A Greedy Algorithm of Data-Dependent User Selection for Fast Fading
  Gaussian Vector Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEICE Trans. Fundamentals</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User selection (US) with Zero-forcing beamforming is considered in fast
fading Gaussian vector broadcast channels with perfect channel state
information (CSI) at the transmitter. A novel criterion for US is proposed,
which depends on both CSI and the data symbols, while conventional criteria
only depend on CSI. Since the optimization of US based on the proposed
criterion is infeasible, a greedy algorithm of data-dependent US is proposed to
perform the optimization approximately. An overhead issue arises in fast fading
channels: On every update of US, the transmitter might inform each user whether
he/she has been selected, using a certain fraction of resources. This overhead
results in a significant rate loss for fast fading channels. In order to
circumvent this overhead issue, iterative detection and decoding schemes are
proposed on the basis of belief propagation. The proposed iterative schemes
require no information about whether each user has been selected. The proposed
US scheme is compared to a data-independent US scheme. The complexity of the
two schemes is comparable to each other for fast fading channels. Numerical
simulations show that the proposed scheme can outperform the data-independent
scheme for fast fading channels in terms of energy efficiency, bit error rate,
and achievable sum rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6459</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6459</id><created>2012-01-31</created><updated>2013-07-06</updated><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Matroidal Framework for Network-Error Correcting Codes</title><categories>cs.IT math.IT</categories><comments>New results on insufficiency of network-error detection added.
  Submitted to Transactions on Info. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We abstract the essential aspects of network-error detecting and correcting
codes to arrive at the definitions of matroidal error detecting networks and
matroidal error correcting networks. An acyclic network (with arbitrary sink
demands) is then shown to possess a scalar linear error detecting (correcting)
network code if and only if it is a matroidal error detecting (correcting)
network associated with a representable matroid. Therefore, constructing such
network-error correcting and detecting codes implies the construction of
certain representable matroids that satisfy some special conditions, and vice
versa. We then present algorithms which enable the construction of matroidal
error detecting and correcting networks with a specified capability of
network-error correction. Using these construction algorithms, a large class of
hitherto unknown scalar linearly solvable networks with multisource multicast
and multiple-unicast network-error correcting codes is made available for
theoretical use and practical implementation, with parameters such as number of
information symbols, number of sinks, number of coding nodes, error correcting
capability, etc. being arbitrary but for computing power (for the execution of
the algorithms). The complexity of the construction of these networks is shown
to be comparable to the complexity of existing algorithms that design multicast
scalar linear network-error correcting codes. Finally we also show that linear
network coding is not sufficient for the general network-error detection
problem with arbitrary demands. In particular, for the same number of
network-errors, we show a network for which there is a nonlinear network-error
detecting code satisfying the demands at the sinks, while there are no linear
network-error detecting codes that do the same.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6462</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6462</id><created>2012-01-31</created><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author><author><keyname>Begleiter</keyname><forenames>Ron</forenames></author></authors><title>Active Learning of Custering with Side Information Using $\eps$-Smooth
  Relative Regret Approximations</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is considered a non-supervised learning setting, in which the goal
is to partition a collection of data points into disjoint clusters. Often a
bound $k$ on the number of clusters is given or assumed by the practitioner.
Many versions of this problem have been defined, most notably $k$-means and
$k$-median.
  An underlying problem with the unsupervised nature of clustering it that of
determining a similarity function. One approach for alleviating this difficulty
is known as clustering with side information, alternatively, semi-supervised
clustering. Here, the practitioner incorporates side information in the form of
&quot;must be clustered&quot; or &quot;must be separated&quot; labels for data point pairs. Each
such piece of information comes at a &quot;query cost&quot; (often involving human
response solicitation). The collection of labels is then incorporated in the
usual clustering algorithm as either strict or as soft constraints, possibly
adding a pairwise constraint penalty function to the chosen clustering
objective.
  Our work is mostly related to clustering with side information. We ask how to
choose the pairs of data points. Our analysis gives rise to a method provably
better than simply choosing them uniformly at random. Roughly speaking, we show
that the distribution must be biased so as more weight is placed on pairs
incident to elements in smaller clusters in some optimal solution. Of course we
do not know the optimal solution, hence we don't know the bias. Using the
recently introduced method of $\eps$-smooth relative regret approximations of
Ailon, Begleiter and Ezra, we can show an iterative process that improves both
the clustering and the bias in tandem. The process provably converges to the
optimal solution faster (in terms of query cost) than an algorithm selecting
pairs uniformly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6465</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6465</id><created>2012-01-31</created><updated>2012-02-02</updated><authors><author><keyname>Lin</keyname><forenames>Lei</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Huang</keyname><forenames>Xiujie</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author></authors><title>An Information-Spectrum Approach to the Capacity Region of General
  Interference Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with general interference channels characterized by a
sequence of transition (conditional) probabilities. We present a general
formula for the capacity region of the interference channel with two pairs of
users. The formula shows that the capacity region is the union of a family of
rectangles, where each rectangle is determined by a pair of spectral inf-mutual
information rates. Although the presented formula is usually difficult to
compute, it provides us useful insights into the interference channels. For
example, the formula suggests us that the simplest inner bounds (obtained by
treating the interference as noise) could be improved by taking into account
the structure of the interference processes. This is verified numerically by
computing the mutual information rates for Gaussian interference channels with
embedded convolutional codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6468</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6468</id><created>2012-01-31</created><updated>2012-05-30</updated><authors><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Broadcast Channels with Confidential Messages by Randomness Constrained
  Stochastic Encoder</title><categories>cs.IT math.IT</categories><comments>13 pages, 3 figures, In v2, references and a numerical example are
  added. A part of this paper will be presented at ISIT2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In coding schemes for the wire-tap channel or the broadcast channels with
confidential messages, it is well known that the sender needs to use a
stochastic encoding to avoid the information about the transmitted confidential
message to be leaked to an eavesdropper. In this paper, it is investigated that
the trade-off between the rate of the random number to realize the stochastic
encoding and the rates of the common, private, and confidential messages. For
the direct theorem, the superposition coding scheme for the wire-tap channel
recently proposed by Chia and El Gamal is employed, and its strong security is
proved. The matching converse theorem is also established. Our result clarifies
that a combination of the ordinary stochastic encoding and the channel
prefixing by the channel simulation is suboptimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6488</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6488</id><created>2012-01-31</created><updated>2012-04-03</updated><authors><author><keyname>Safro</keyname><forenames>Ilya</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author><author><keyname>Schulz</keyname><forenames>Christian</forenames></author></authors><title>Advanced Coarsening Schemes for Graph Partitioning</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The graph partitioning problem is widely used and studied in many practical
and theoretical applications. The multilevel strategies represent today one of
the most effective and efficient generic frameworks for solving this problem on
large-scale graphs. Most of the attention in designing the multilevel
partitioning frameworks has been on the refinement phase. In this work we focus
on the coarsening phase, which is responsible for creating structurally similar
to the original but smaller graphs. We compare different matching- and
AMG-based coarsening schemes, experiment with the algebraic distance between
nodes, and demonstrate computational results on several classes of graphs that
emphasize the running time and quality advantages of different coarsenings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6499</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6499</id><created>2012-01-31</created><authors><author><keyname>Warsi</keyname><forenames>Naqueeb Ahmad</forenames></author></authors><title>Power Control in Multiuser Mulicarrier Wireless Data Networks</title><categories>cs.IT math.IT</categories><comments>11 pages, 1 figure. arXiv admin note: text overlap with arXiv:some
  0806.1565 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A game-theoretic model is presented to study the management of transmission
power in a wireless data network. We propose a power game for a multiuser
multicarrier setting where all the users are assumed to transmit at equal rate.
At equilibrium, each user is shown to transmit over a single carrier, as in
[Mehskati et al., 2006]. We derive the necessary conditions on the path gains
when the Nash equilibrium point exists. We further prove the existence of the
Nash equilibrium point using the concept of locally gross direction preserving
map. A greedy algorithm is proposed and its correctness is established, where
each user acts selfishly to achieve the Nash equilibrium point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6506</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6506</id><created>2012-01-31</created><updated>2012-10-04</updated><authors><author><keyname>Gebhardt</keyname><forenames>Volker</forenames></author></authors><title>Computing growth functions of braid monoids and counting vertex-labelled
  bipartite graphs</title><categories>math.GR cs.DM math.CO</categories><comments>reference added</comments><msc-class>20F36 (Primary) 20F10, 05A15, 68R05 (Secondary)</msc-class><journal-ref>Journal of Combinatorial Theory, Series A 120 (2013) 232-244</journal-ref><doi>10.1016/j.jcta.2012.08.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a recurrence relation for the number of simple vertex-labelled
bipartite graphs with given degrees of the vertices and use this result to
obtain a new method for computing the growth function of the Artin monoid of
type $A_{n-1}$ with respect to the simple elements (permutation braids) as
generators. Instead of matrices of size $2^{n-1}\times 2^{n-1}$, we use
matrices of size $p(n)\times p(n)$, where $p(n)$ is the number of partitions of
$n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6511</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6511</id><created>2012-01-31</created><authors><author><keyname>M&#xe9;tral</keyname><forenames>Claudine</forenames></author><author><keyname>Falquet</keyname><forenames>Gilles</forenames></author><author><keyname>Karatzas</keyname><forenames>Kostas</forenames></author></authors><title>Ontologies for the Integration of Air Quality Models and 3D City Models</title><categories>cs.AI</categories><journal-ref>In Conceptual Models for Practitioners, J. Teller, C. Tweed, G.
  Rabino (Eds.), Societ\`a Editrice Esculapio, Bologna, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The holistic approach to sustainable urban planning implies using different
models in an integrated way that is capable of simulating the urban system. As
the interconnection of such models is not a trivial task, one of the key
elements that may be applied is the description of the urban geometric
properties in an &quot;interoperable&quot; way. Focusing on air quality as one of the
most pronounced urban problems, the geometric aspects of a city may be
described by objects such as those defined in CityGML, so that an appropriate
air quality model can be applied for estimating the quality of the urban air on
the basis of atmospheric flow and chemistry equations.
  In this paper we first present theoretical background and motivations for the
interconnection of 3D city models and other models related to sustainable
development and urban planning. Then we present a practical experiment based on
the interconnection of CityGML with an air quality model. Our approach is based
on the creation of an ontology of air quality models and on the extension of an
ontology of urban planning process (OUPP) that acts as an ontology mediator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6527</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6527</id><created>2012-01-31</created><updated>2012-02-01</updated><authors><author><keyname>Wong</keyname><forenames>Wing Shing</forenames></author><author><keyname>Baillieul</keyname><forenames>John</forenames></author></authors><title>Control Communication Complexity of Distributed Actions</title><categories>cs.SY</categories><comments>34 pages, 1 figure, To appear in the IEEE Trans. Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent papers have treated {\em control communication complexity} in the
context of information-based, multiple agent control systems including
nonlinear systems of the type that have been studied in connection with quantum
information processing. The present paper continues this line of investigation
into a class of two-agent distributed control systems in which the agents
cooperate in order to realize common goals that are determined via independent
actions undertaken individually by the agents. A basic assumption is that the
actions taken are unknown in advance to the other agent. These goals can be
conveniently summarized in the form of a {\em target matrix}, whose entries are
computed by the control system responding to the choices of inputs made by the
two agents. We show how to realize such target matrices for a broad class of
systems that possess an input-output mapping that is bilinear. One can classify
control-communication strategies, known as {\em control protocols}, according
to the amount of information sharing occurring between the two agents.
Protocols that assume no information sharing on the inputs that each agent
selects and protocols that allow sufficient information sharing for identifying
the common goals are the two extreme cases. Control protocols will also be
evaluated and compared in terms of cost functionals given by integrated
quadratic functions of the control inputs. The minimal control cost of the two
classes of control protocols are analyzed and compared. The difference in the
control costs between the two classes reflects an inherent trade-off between
communication complexity and control cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6530</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6530</id><created>2012-01-31</created><updated>2012-03-26</updated><authors><author><keyname>Kar</keyname><forenames>Purushottam</forenames></author><author><keyname>Karnick</keyname><forenames>Harish</forenames></author></authors><title>Random Feature Maps for Dot Product Kernels</title><categories>cs.LG cs.CG math.FA stat.ML</categories><comments>To appear in the proceedings of the 15th International Conference on
  Artificial Intelligence and Statistics (AISTATS 2012). This version corrects
  a minor error with Lemma 10. Acknowledgements : Devanshu Bhimwal</comments><journal-ref>Journal of Machine Learning Research, W&amp;CP 22 (2012) 583-591</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximating non-linear kernels using feature maps has gained a lot of
interest in recent years due to applications in reducing training and testing
times of SVM classifiers and other kernel based learning algorithms. We extend
this line of work and present low distortion embeddings for dot product kernels
into linear Euclidean spaces. We base our results on a classical result in
harmonic analysis characterizing all dot product kernels and use it to define
randomized feature maps into explicit low dimensional Euclidean spaces in which
the native dot product provides an approximation to the dot product kernel with
high confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6533</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6533</id><created>2012-01-31</created><authors><author><keyname>Alahmadi</keyname><forenames>Adel</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author><author><keyname>Sboui</keyname><forenames>Houda</forenames></author><author><keyname>Yemen</keyname><forenames>Olfa</forenames></author></authors><title>Cyclic codes over $M_2(\F_2)$</title><categories>cs.IT math.IT math.RA</categories><comments>10 pages; submitted</comments><msc-class>Primary 94B15, Secondary 16S36</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ring in the title is the first non commutative ring to have been used as
alphabet for block codes. The original motivation was the construction of some
quaternionic modular lattices from codes. The new application is the
construction of space time codes obtained by concatenation from the Golden
code. In this article, we derive structure theorems for cyclic codes over that
ring, and use them to characterize the lengths where self dual cyclic codes
exist. These codes in turn give rise to formally self dual quaternary codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6548</identifier>
 <datestamp>2014-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6548</id><created>2012-01-31</created><updated>2014-05-08</updated><authors><author><keyname>Abrardo</keyname><forenames>A.</forenames></author><author><keyname>Ferrari</keyname><forenames>G.</forenames></author><author><keyname>Martalo'</keyname><forenames>M.</forenames></author><author><keyname>Franceschini</keyname><forenames>M.</forenames></author><author><keyname>Raheli</keyname><forenames>R.</forenames></author></authors><title>Orthogonal Multiple Access with Correlated Sources: Feasible Region and
  Pragmatic Schemes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider orthogonal multiple access coding schemes, where
correlated sources are encoded in a distributed fashion and transmitted,
through additive white Gaussian noise (AWGN) channels, to an access point (AP).
At the AP, component decoders, associated with the source encoders, iteratively
exchange soft information by taking into account the source correlation. The
first goal of this paper is to investigate the ultimate achievable performance
limits in terms of a multi-dimensional feasible region in the space of channel
parameters, deriving insights on the impact of the number of sources. The
second goal is the design of pragmatic schemes, where the sources use
&quot;off-the-shelf&quot; channel codes. In order to analyze the performance of given
coding schemes, we propose an extrinsic information transfer (EXIT)-based
approach, which allows to determine the corresponding multi-dimensional
feasible regions. On the basis of the proposed analytical framework, the
performance of pragmatic coded schemes, based on serially concatenated
convolutional codes (SCCCs), is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6563</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6563</id><created>2012-01-31</created><authors><author><keyname>Sun</keyname><forenames>Yizhou</forenames></author><author><keyname>Aggarwal</keyname><forenames>Charu C.</forenames></author><author><keyname>Han</keyname><forenames>Jiawei</forenames></author></authors><title>Relation Strength-Aware Clustering of Heterogeneous Information Networks
  with Incomplete Attributes</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  394-405 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of online social media, online shopping sites and
cyber-physical systems, heterogeneous information networks have become
increasingly popular and content-rich over time. In many cases, such networks
contain multiple types of objects and links, as well as different kinds of
attributes. The clustering of these objects can provide useful insights in many
applications. However, the clustering of such networks can be challenging since
(a) the attribute values of objects are often incomplete, which implies that an
object may carry only partial attributes or even no attributes to correctly
label itself; and (b) the links of different types may carry different kinds of
semantic meanings, and it is a difficult task to determine the nature of their
relative importance in helping the clustering for a given purpose. In this
paper, we address these challenges by proposing a model-based clustering
algorithm. We design a probabilistic model which clusters the objects of
different types into a common hidden space, by using a user-specified set of
attributes, as well as the links from different relations. The strengths of
different types of links are automatically learned, and are determined by the
given purpose of clustering. An iterative algorithm is designed for solving the
clustering problem, in which the strengths of different types of links and the
quality of clustering results mutually enhance each other. Our experimental
results on real and synthetic data sets demonstrate the effectiveness and
efficiency of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6564</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6564</id><created>2012-01-31</created><authors><author><keyname>Wu</keyname><forenames>Lingkun</forenames></author><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Deng</keyname><forenames>Dingxiong</forenames></author><author><keyname>Cong</keyname><forenames>Gao</forenames></author><author><keyname>Zhu</keyname><forenames>Andy Diwen</forenames></author><author><keyname>Zhou</keyname><forenames>Shuigeng</forenames></author></authors><title>Shortest Path and Distance Queries on Road Networks: An Experimental
  Evaluation</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  406-417 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the shortest path between two given locations in a road network is
an important problem that finds applications in various map services and
commercial navigation products. The state-of-the-art solutions for the problem
can be divided into two categories: spatial-coherence-based methods and
vertex-importance-based approaches. The two categories of techniques, however,
have not been compared systematically under the same experimental framework, as
they were developed from two independent lines of research that do not refer to
each other. This renders it difficult for a practitioner to decide which
technique should be adopted for a specific application. Furthermore, the
experimental evaluation of the existing techniques, as presented in previous
work, falls short in several aspects. Some methods were tested only on small
road networks with up to one hundred thousand vertices; some approaches were
evaluated using distance queries (instead of shortest path queries), namely,
queries that ask only for the length of the shortest path; a state-of-the-art
technique was examined based on a faulty implementation that led to incorrect
query results. To address the above issues, this paper presents a comprehensive
comparison of the most advanced spatial-coherence-based and
vertex-importance-based approaches. Using a variety of real road networks with
up to twenty million vertices, we evaluated each technique in terms of its
preprocessing time, space consumption, and query efficiency (for both shortest
path and distance queries). Our experimental results reveal the characteristics
of different techniques, based on which we provide guidelines on selecting
appropriate methods for various scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6565</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6565</id><created>2012-01-31</created><authors><author><keyname>Erd&#xf6;s</keyname><forenames>D&#xf3;ra</forenames></author><author><keyname>Ishakian</keyname><forenames>Vatche</forenames></author><author><keyname>Lapets</keyname><forenames>Andrei</forenames></author><author><keyname>Terzi</keyname><forenames>Evimaria</forenames></author><author><keyname>Bestavros</keyname><forenames>Azer</forenames></author></authors><title>The Filter-Placement Problem and its Application to Minimizing
  Information Multiplicity</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  418-429 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many information networks, data items -- such as updates in social
networks, news flowing through interconnected RSS feeds and blogs, measurements
in sensor networks, route updates in ad-hoc networks -- propagate in an
uncoordinated manner: nodes often relay information they receive to neighbors,
independent of whether or not these neighbors received the same information
from other sources. This uncoordinated data dissemination may result in
significant, yet unnecessary communication and processing overheads, ultimately
reducing the utility of information networks. To alleviate the negative impacts
of this information multiplicity phenomenon, we propose that a subset of nodes
(selected at key positions in the network) carry out additional information
filtering functionality. Thus, nodes are responsible for the removal (or
significant reduction) of the redundant data items relayed through them. We
refer to such nodes as filters. We formally define the Filter Placement problem
as a combinatorial optimization problem, and study its computational complexity
for different types of graphs. We also present polynomial-time approximation
algorithms and scalable heuristics for the problem. Our experimental results,
which we obtained through extensive simulations on synthetic and real-world
information flow networks, suggest that in many settings a relatively small
number of filters are fairly effective in removing a large fraction of
redundant information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6566</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6566</id><created>2012-01-31</created><authors><author><keyname>Fujiwara</keyname><forenames>Yasuhiro</forenames></author><author><keyname>Nakatsuji</keyname><forenames>Makoto</forenames></author><author><keyname>Onizuka</keyname><forenames>Makoto</forenames></author><author><keyname>Kitsuregawa</keyname><forenames>Masaru</forenames></author></authors><title>Fast and Exact Top-k Search for Random Walk with Restart</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  442-453 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs are fundamental data structures and have been employed for centuries
to model real-world systems and phenomena. Random walk with restart (RWR)
provides a good proximity score between two nodes in a graph, and it has been
successfully used in many applications such as automatic image captioning,
recommender systems, and link prediction. The goal of this work is to find
nodes that have top-k highest proximities for a given node. Previous approaches
to this problem find nodes efficiently at the expense of exactness. The main
motivation of this paper is to answer, in the affirmative, the question, `Is it
possible to improve the search time without sacrificing the exactness?'. Our
solution, {it K-dash}, is based on two ideas: (1) It computes the proximity of
a selected node efficiently by sparse matrices, and (2) It skips unnecessary
proximity computations when searching for the top-k nodes. Theoretical analyses
show that K-dash guarantees result exactness. We perform comprehensive
experiments to verify the efficiency of K-dash. The results show that K-dash
can find top-k nodes significantly faster than the previous approaches while it
guarantees exactness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6567</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6567</id><created>2012-01-31</created><authors><author><keyname>Bahmani</keyname><forenames>Bahman</forenames></author><author><keyname>Kumar</keyname><forenames>Ravi</forenames></author><author><keyname>Vassilvitskii</keyname><forenames>Sergei</forenames></author></authors><title>Densest Subgraph in Streaming and MapReduce</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  454-465 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of finding locally dense components of a graph is an important
primitive in data analysis, with wide-ranging applications from community
mining to spam detection and the discovery of biological network modules. In
this paper we present new algorithms for finding the densest subgraph in the
streaming model. For any epsilon&gt;0, our algorithms make O((log n)/log
(1+epsilon)) passes over the input and find a subgraph whose density is
guaranteed to be within a factor 2(1+epsilon) of the optimum. Our algorithms
are also easily parallelizable and we illustrate this by realizing them in the
MapReduce model. In addition we perform extensive experimental evaluation on
massive real-world graphs showing the performance and scalability of our
algorithms in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6568</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6568</id><created>2012-01-31</created><authors><author><keyname>Silva</keyname><forenames>Arlei</forenames></author><author><keyname>Meira</keyname><forenames>Wagner</forenames><suffix>Jr.</suffix></author><author><keyname>Zaki</keyname><forenames>Mohammed J.</forenames></author></authors><title>Mining Attribute-structure Correlated Patterns in Large Attributed
  Graphs</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  466-477 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the correlation between attribute sets and the
occurrence of dense subgraphs in large attributed graphs, a task we call
structural correlation pattern mining. A structural correlation pattern is a
dense subgraph induced by a particular attribute set. Existing methods are not
able to extract relevant knowledge regarding how vertex attributes interact
with dense subgraphs. Structural correlation pattern mining combines aspects of
frequent itemset and quasi-clique mining problems. We propose statistical
significance measures that compare the structural correlation of attribute sets
against their expected values using null models. Moreover, we evaluate the
interestingness of structural correlation patterns in terms of size and
density. An efficient algorithm that combines search and pruning strategies in
the identification of the most relevant structural correlation patterns is
presented. We apply our method for the analysis of three real-world attributed
graphs: a collaboration, a music, and a citation network, verifying that it
provides valuable knowledge in a feasible time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6569</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6569</id><created>2012-01-31</created><authors><author><keyname>Fink</keyname><forenames>Robert</forenames></author><author><keyname>Han</keyname><forenames>Larisa</forenames></author><author><keyname>Olteanu</keyname><forenames>Dan</forenames></author></authors><title>Aggregation in Probabilistic Databases via Knowledge Compilation</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 5, pp.
  490-501 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a query evaluation technique for positive relational
algebra queries with aggregates on a representation system for probabilistic
data based on the algebraic structures of semiring and semimodule. The core of
our evaluation technique is a procedure that compiles semimodule and semiring
expressions into so-called decomposition trees, for which the computation of
the probability distribution can be done in time linear in the product of the
sizes of the probability distributions represented by its nodes. We give
syntactic characterisations of tractable queries with aggregates by exploiting
the connection between query tractability and polynomial-time decomposition
trees. A prototype of the technique is incorporated in the probabilistic
database engine SPROUT. We report on performance experiments with custom
datasets and TPC-H data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6578</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6578</id><created>2012-01-31</created><authors><author><keyname>Alpert</keyname><forenames>Hannah</forenames></author><author><keyname>Iglesias</keyname><forenames>Jennifer</forenames></author></authors><title>Length 3 Edge-Disjoint Paths and Partial Orientation</title><categories>cs.CC math.CO</categories><comments>5 pages, 2 figures</comments><msc-class>68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2003, it was claimed that the following problem was solvable in polynomial
time: do there exist k edge-disjoint paths of length exactly 3 between vertices
s and t in a given graph? The proof was flawed, and we show that this problem
is NP-hard even if we disallow multiple edges. We use a reduction from Partial
Orientation, a problem recently shown by P\'alv\&quot;olgyi to be NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6583</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6583</id><created>2012-01-31</created><authors><author><keyname>Jung</keyname><forenames>Tobias</forenames></author><author><keyname>Polani</keyname><forenames>Daniel</forenames></author><author><keyname>Stone</keyname><forenames>Peter</forenames></author></authors><title>Empowerment for Continuous Agent-Environment Systems</title><categories>cs.AI cs.LG</categories><journal-ref>Adaptive Behavior 19(1),2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops generalizations of empowerment to continuous states.
Empowerment is a recently introduced information-theoretic quantity motivated
by hypotheses about the efficiency of the sensorimotor loop in biological
organisms, but also from considerations stemming from curiosity-driven
learning. Empowemerment measures, for agent-environment systems with stochastic
transitions, how much influence an agent has on its environment, but only that
influence that can be sensed by the agent sensors. It is an
information-theoretic generalization of joint controllability (influence on
environment) and observability (measurement by sensors) of the environment by
the agent, both controllability and observability being usually defined in
control theory as the dimensionality of the control/observation spaces. Earlier
work has shown that empowerment has various interesting and relevant
properties, e.g., it allows us to identify salient states using only the
dynamics, and it can act as intrinsic reward without requiring an external
reward. However, in this previous work empowerment was limited to the case of
small-scale and discrete domains and furthermore state transition probabilities
were assumed to be known. The goal of this paper is to extend empowerment to
the significantly more important and relevant case of continuous vector-valued
state spaces and initially unknown state transition probabilities. The
continuous state space is addressed by Monte-Carlo approximation; the unknown
transitions are addressed by model learning and prediction for which we apply
Gaussian processes regression with iterated forecasting. In a number of
well-known continuous control tasks we examine the dynamics induced by
empowerment and include an application to exploration and online model
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6604</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6604</id><created>2012-01-31</created><authors><author><keyname>Jung</keyname><forenames>Tobias</forenames></author><author><keyname>Stone</keyname><forenames>Peter</forenames></author></authors><title>Gaussian Processes for Sample Efficient Reinforcement Learning with
  RMAX-like Exploration</title><categories>cs.AI cs.LG</categories><comments>European Conference on Machine Learning (ECML'2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an implementation of model-based online reinforcement learning
(RL) for continuous domains with deterministic transitions that is specifically
designed to achieve low sample complexity. To achieve low sample complexity,
since the environment is unknown, an agent must intelligently balance
exploration and exploitation, and must be able to rapidly generalize from
observations. While in the past a number of related sample efficient RL
algorithms have been proposed, to allow theoretical analysis, mainly
model-learners with weak generalization capabilities were considered. Here, we
separate function approximation in the model learner (which does require
samples) from the interpolation in the planner (which does not require
samples). For model-learning we apply Gaussian processes regression (GP) which
is able to automatically adjust itself to the complexity of the problem (via
Bayesian hyperparameter selection) and, in practice, often able to learn a
highly accurate model from very little data. In addition, a GP provides a
natural way to determine the uncertainty of its predictions, which allows us to
implement the &quot;optimism in the face of uncertainty&quot; principle used to
efficiently control exploration. Our method is evaluated on four common
benchmark domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6615</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6615</id><created>2012-01-31</created><authors><author><keyname>Jung</keyname><forenames>Tobias</forenames></author><author><keyname>Stone</keyname><forenames>Peter</forenames></author></authors><title>Feature Selection for Value Function Approximation Using Bayesian Model
  Selection</title><categories>cs.AI cs.LG</categories><comments>European Conference on Machine Learning (ECML'09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection in reinforcement learning (RL), i.e. choosing basis
functions such that useful approximations of the unkown value function can be
obtained, is one of the main challenges in scaling RL to real-world
applications. Here we consider the Gaussian process based framework GPTD for
approximate policy evaluation, and propose feature selection through marginal
likelihood optimization of the associated hyperparameters. Our approach has two
appealing benefits: (1) given just sample transitions, we can solve the policy
evaluation problem fully automatically (without looking at the learning task,
and, in theory, independent of the dimensionality of the state space), and (2)
model selection allows us to consider more sophisticated kernels, which in turn
enable us to identify relevant subspaces and eliminate irrelevant state
variables such that we can achieve substantial computational savings and
improved prediction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6626</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6626</id><created>2012-01-31</created><authors><author><keyname>Jung</keyname><forenames>Tobias</forenames></author><author><keyname>Polani</keyname><forenames>Daniel</forenames></author></authors><title>Learning RoboCup-Keepaway with Kernels</title><categories>cs.AI cs.LG cs.MA</categories><journal-ref>JMLR Workshop and Conference Proceedings (1st Gaussian Processes
  in Practice Workshop, 2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply kernel-based methods to solve the difficult reinforcement learning
problem of 3vs2 keepaway in RoboCup simulated soccer. Key challenges in
keepaway are the high-dimensionality of the state space (rendering conventional
discretization-based function approximation like tilecoding infeasible), the
stochasticity due to noise and multiple learning agents needing to cooperate
(meaning that the exact dynamics of the environment are unknown) and real-time
learning (meaning that an efficient online implementation is required). We
employ the general framework of approximate policy iteration with
least-squares-based policy evaluation. As underlying function approximator we
consider the family of regularization networks with subset of regressors
approximation. The core of our proposed solution is an efficient recursive
implementation with automatic supervised selection of relevant basis functions.
Simulation results indicate that the behavior learned through our approach
clearly outperforms the best results obtained earlier with tilecoding by Stone
et al. (2005).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6652</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6652</id><created>2012-01-31</created><updated>2012-11-05</updated><authors><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Lenzen</keyname><forenames>Christoph</forenames></author><author><keyname>Peled</keyname><forenames>Shir</forenames></author></authors><title>&quot;Tri, Tri again&quot;: Finding Triangles and Small Subgraphs in a Distributed
  Setting</title><categories>cs.DC</categories><comments>22 pages, no figures, extended abstract published at DISC'12</comments><msc-class>68M14, 68R10</msc-class><acm-class>C.2.4; F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G = (V,E) be an n-vertex graph and M_d a d-vertex graph, for some
constant d. Is M_d a subgraph of G? We consider this problem in a model where
all n processes are connected to all other processes, and each message contains
up to O(log n) bits. A simple deterministic algorithm that requires
O(n^((d-2)/d) / log n) communication rounds is presented. For the special case
that M_d is a triangle, we present a probabilistic algorithm that requires an
expected O(ceil(n^(1/3) / (t^(2/3) + 1))) rounds of communication, where t is
the number of triangles in the graph, and O(min{n^(1/3) log^(2/3) n / (t^(2/3)
+ 1), n^(1/3)}) with high probability.
  We also present deterministic algorithms specially suited for sparse graphs.
In any graph of maximum degree Delta, we can test for arbitrary subgraphs of
diameter D in O(ceil(Delta^(D+1) / n)) rounds. For triangles, we devise an
algorithm featuring a round complexity of O(A^2 / n + log_(2+n/A^2) n), where A
denotes the arboricity of G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6655</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6655</id><created>2012-01-31</created><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Pennock</keyname><forenames>David</forenames></author></authors><title>Learning Performance of Prediction Markets with Kelly Bettors</title><categories>cs.AI q-fin.GN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In evaluating prediction markets (and other crowd-prediction mechanisms),
investigators have repeatedly observed a so-called &quot;wisdom of crowds&quot; effect,
which roughly says that the average of participants performs much better than
the average participant. The market price---an average or at least aggregate of
traders' beliefs---offers a better estimate than most any individual trader's
opinion. In this paper, we ask a stronger question: how does the market price
compare to the best trader's belief, not just the average trader. We measure
the market's worst-case log regret, a notion common in machine learning theory.
To arrive at a meaningful answer, we need to assume something about how traders
behave. We suppose that every trader optimizes according to the Kelly criteria,
a strategy that provably maximizes the compound growth of wealth over an
(infinite) sequence of market interactions. We show several consequences.
First, the market prediction is a wealth-weighted average of the individual
participants' beliefs. Second, the market learns at the optimal rate, the
market price reacts exactly as if updating according to Bayes' Law, and the
market prediction has low worst-case log regret to the best individual
participant. We simulate a sequence of markets where an underlying true
probability exists, showing that the market converges to the true objective
frequency as if updating a Beta distribution, as the theory predicts. If agents
adopt a fractional Kelly criteria, a common practical variant, we show that
agents behave like full-Kelly agents with beliefs weighted between their own
and the market's, and that the market price converges to a time-discounted
frequency. Our analysis provides a new justification for fractional Kelly
betting, a strategy widely used in practice for ad-hoc reasons. Finally, we
propose a method for an agent to learn her own optimal Kelly fraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6675</identifier>
 <datestamp>2013-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6675</id><created>2012-01-31</created><authors><author><keyname>G&#xf6;&#xf6;s</keyname><forenames>Mika</forenames></author><author><keyname>Hirvonen</keyname><forenames>Juho</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>Lower Bounds for Local Approximation</title><categories>cs.DC cs.DM</categories><comments>28 pages, 9 figures</comments><journal-ref>Journal of the ACM 60 (2013), issue 5, article 39</journal-ref><doi>10.1145/2528405</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the study of deterministic distributed algorithms it is commonly assumed
that each node has a unique $O(\log n)$-bit identifier. We prove that for a
general class of graph problems, local algorithms (constant-time distributed
algorithms) do not need such identifiers: a port numbering and orientation is
sufficient.
  Our result holds for so-called simple PO-checkable graph optimisation
problems; this includes many classical packing and covering problems such as
vertex covers, edge covers, matchings, independent sets, dominating sets, and
edge dominating sets. We focus on the case of bounded-degree graphs and show
that if a local algorithm finds a constant-factor approximation of a simple
PO-checkable graph problem with the help of unique identifiers, then the same
approximation ratio can be achieved on anonymous networks.
  As a corollary of our result and by prior work, we derive a tight lower bound
on the local approximability of the minimum edge dominating set problem.
  Our main technical tool is an algebraic construction of homogeneously ordered
graphs: We say that a graph is $(\alpha,r)$-homogeneous if its nodes are
linearly ordered so that an $\alpha$ fraction of nodes have pairwise isomorphic
radius-$r$ neighbourhoods. We show that there exists a finite
$(\alpha,r)$-homogeneous $2k$-regular graph of girth at least $g$ for any
$\alpha &lt; 1$ and any $r$, $k$, and $g$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6680</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6680</id><created>2012-01-30</created><authors><author><keyname>Luboschinsky</keyname><forenames>Mikhail</forenames></author></authors><title>Nonlinear Planning Model With a Gaussian Criterion of Optimization
  (Gaussian Programming Model)</title><categories>cs.DM</categories><comments>25 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an Economic - Probabilistic analogy: the category of cost is
analogous to the category of Probability. The proposed analogy permits
construction of an informal theory of nonlinear non-convex Gaussian Utility and
Cost, which describes the real economic processes more adequately than a theory
based on a linear and convex models. Based on the proposed analogy, we build a
nonlinear non-convex planning model with a Gaussian optimality criterion -
Gaussian Programming Model. We also describe a corresponding model of
Generalized Piecewise-Linear Programming that can be used to approximate a
Gaussian Programming model, and vice verse. Proposed constructions are
illustrated on a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6681</identifier>
 <datestamp>2012-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6681</id><created>2012-01-31</created><updated>2012-11-20</updated><authors><author><keyname>Park</keyname><forenames>Sangwoo</forenames></author><author><keyname>Serpedin</keyname><forenames>Erchin</forenames></author><author><keyname>Qaraqe</keyname><forenames>Khalid</forenames></author></authors><title>An Alternative Proof of an Extremal Entropy Inequality</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper first focuses on deriving an alternative approach for proving an
extremal entropy inequality (EEI), originally presented in [11]. The proposed
approach does not rely on the channel enhancement technique, and has the
advantage that it yields an explicit description of the optimal solution as
opposed to the implicit approach of [11]. Compared with the proofs in [11], the
proposed alternative proof is also simpler, more direct, more
information-theoretic, and has the additional advantage that it offers a new
perspective for establishing novel as well as known challenging results such
the capacity of the vector Gaussian broadcast channel, the lower bound of the
achievable rate for distributed source coding with a single quadratic
distortion constraint, and the secrecy capacity of the Gaussian wire-tap
channel. The second part of this paper is devoted to some novel applications of
the proposed mathematical results. The proposed mathematical techniques are
further exploited to obtain a more simplified proof of the EEI without using
the entropy power inequality (EPI), to build the optimal solution for a special
class of broadcasting channels with private messages and to obtain a mutual
information-based performance bound for the mean square-error of a linear
Bayesian estimator of a Gaussian source embedded in an additive noise channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1201.6685</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1201.6685</id><created>2012-01-31</created><authors><author><keyname>Ahmad</keyname><forenames>Aitzaz</forenames></author><author><keyname>Zennaro</keyname><forenames>Davide</forenames></author><author><keyname>Serpedin</keyname><forenames>Erchin</forenames></author><author><keyname>Vangelista</keyname><forenames>Lorenzo</forenames></author></authors><title>A Factor Graph Approach to Clock Offset Estimation in Wireless Sensor
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of clock offset estimation in a two way timing message exchange
regime is considered when the likelihood function of the observation time
stamps is Gaussian, exponential or log-normally distributed. A parametrized
solution to the maximum likelihood (ML) estimation of clock offset, based on
convex optimization, is presented, which differs from the earlier approaches
where the likelihood function is maximized graphically. In order to capture the
imperfections in node oscillators, which may render a time-varying nature to
the clock offset, a novel Bayesian approach to the clock offset estimation is
proposed by using a factor graph representation of the posterior density.
Message passing using the max-product algorithm yields a closed form expression
for the Bayesian inference problem. Several lower bounds on the variance of an
estimator are derived for arbitrary exponential family distributed likelihood
functions which, while serving as stepping stones to benchmark the performance
of the proposed clock offset estimators, can be useful in their own right in
classical as well Bayesian parameter estimation theory. To corroborate the
theoretical findings, extensive simulation results are discussed for classical
as well as Bayesian estimators in various scenarios. It is observed that the
performance of the proposed estimators is fairly close to the fundamental
limits established by the lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0015</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0015</id><created>2012-01-31</created><updated>2012-07-22</updated><authors><author><keyname>Park</keyname><forenames>Sangwoo</forenames></author><author><keyname>Serpedin</keyname><forenames>Erchin</forenames></author><author><keyname>Qaraqe</keyname><forenames>Khalid</forenames></author></authors><title>On the equivalence between Stein and de Bruijn identities</title><categories>cs.IT math.IT</categories><comments>This is the final version, which was accepted in IEEE trans. on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on proving the equivalence between Stein's identity and de
Bruijn's identity. Given some conditions, we prove that Stein's identity is
equivalent to de Bruijn's identity. In addition, some extensions of de Bruijn's
identity are presented. For arbitrary but fixed input and noise distributions,
there exist relations between the first derivative of the differential entropy
and the posterior mean. Moreover, the second derivative of the differential
entropy is related to the Fisher information for arbitrary input and noise
distributions. Several applications are presented to support the usefulness of
the developed results in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0018</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0018</id><created>2012-01-31</created><authors><author><keyname>Mahfoud</keyname><forenames>Houari</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author><author><keyname>Imine</keyname><forenames>Abdessamad</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author></authors><title>A General Approach for Securely Querying and Updating XML Data</title><categories>cs.CR cs.DB</categories><comments>No. RR-7870 (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past years several works have proposed access control models for XML
data where only read-access rights over non-recursive DTDs are considered. A
few amount of works have studied the access rights for updates. In this paper,
we present a general model for specifying access control on XML data in the
presence of update operations of W3C XQuery Update Facility. Our approach for
enforcing such updates specifications is based on the notion of query rewriting
where each update operation defined over arbitrary DTD (recursive or not) is
rewritten to a safe one in order to be evaluated only over XML data which can
be updated by the user. We investigate in the second part of this report the
secure of XML updating in the presence of read-access rights specified by a
security views. For an XML document, a security view represents for each class
of users all and only the parts of the document these users are able to see. We
show that an update operation defined over a security view can cause disclosure
of sensitive data hidden by this view if it is not thoroughly rewritten with
respect to both read and update access rights. Finally, we propose a security
view based approach for securely updating XML in order to preserve the
confidentiality and integrity of XML data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0022</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0022</id><created>2012-01-31</created><authors><author><keyname>Ahmad</keyname><forenames>Aitzaz</forenames></author><author><keyname>Zennaro</keyname><forenames>Davide</forenames></author><author><keyname>Serpedin</keyname><forenames>Erchin</forenames></author><author><keyname>Vangelista</keyname><forenames>Lorenzo</forenames></author></authors><title>Time-varying Clock Offset Estimation in Two-way Timing Message Exchange
  in Wireless Sensor Networks Using Factor Graphs</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures, ICASSP 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of clock offset estimation in a two-way timing exchange regime is
considered when the likelihood function of the observation time stamps is
exponentially distributed. In order to capture the imperfections in node
oscillators, which render a time-varying nature to the clock offset, a novel
Bayesian approach to the clock offset estimation is proposed using a factor
graph representation of the posterior density. Message passing using the
max-product algorithm yields a closed form expression for the Bayesian
inference problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0023</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0023</id><created>2012-01-31</created><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author><author><keyname>Khachatrian</keyname><forenames>Hrant H.</forenames></author><author><keyname>Tananyan</keyname><forenames>Hovhannes G.</forenames></author></authors><title>Interval edge-colorings of Cartesian products of graphs I</title><categories>math.CO cs.DM</categories><comments>18 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An edge-coloring of a graph $G$ with colors $1,...,t$ is an interval
$t$-coloring if all colors are used, and the colors of edges incident to each
vertex of $G$ are distinct and form an interval of integers. A graph $G$ is
interval colorable if $G$ has an interval $t$-coloring for some positive
integer $t$. Let $\mathfrak{N}$ be the set of all interval colorable graphs.
For a graph $G\in \mathfrak{N}$, the least and the greatest values of $t$ for
which $G$ has an interval $t$-coloring are denoted by $w(G)$ and $W(G)$,
respectively. In this paper we first show that if $G$ is an $r$-regular graph
and $G\in \mathfrak{N}$, then $W(G\square P_{m})\geq W(G)+W(P_{m})+(m-1)r$
($m\in \mathbb{N}$) and $W(G\square C_{2n})\geq W(G)+W(C_{2n})+nr$ ($n\geq 2$).
Next, we investigate interval edge-colorings of grids, cylinders and tori. In
particular, we prove that if $G\square H$ is planar and both factors have at
least 3 vertices, then $G\square H\in \mathfrak{N}$ and $w(G\square H)\leq 6$.
Finally, we confirm the first author's conjecture on the $n$-dimensional cube
$Q_{n}$ and show that $Q_{n}$ has an interval $t$-coloring if and only if
$n\leq t\leq \frac{n(n+1)}{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0024</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0024</id><created>2012-01-31</created><updated>2012-06-15</updated><authors><author><keyname>da Silva</keyname><forenames>Renato Aparecido Pimentel</forenames></author><author><keyname>Viana</keyname><forenames>Matheus Palhares</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author></authors><title>Predicting epidemic outbreak from individual features of the spreaders</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>10 pages, 6 figures</comments><doi>10.1088/1742-5468/2012/07/P07005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowing which individuals can be more efficient in spreading a pathogen
throughout a determinate environment is a fundamental question in disease
control. Indeed, over the last years the spread of epidemic diseases and its
relationship with the topology of the involved system have been a recurrent
topic in complex network theory, taking into account both network models and
real-world data. In this paper we explore possible correlations between the
heterogeneous spread of an epidemic disease governed by the
susceptible-infected-recovered (SIR) model, and several attributes of the
originating vertices, considering Erd\&quot;os-R\'enyi (ER), Barab\'asi-Albert (BA)
and random geometric graphs (RGG), as well as a real case of study, the US Air
Transportation Network that comprises the US 500 busiest airports along with
inter-connections. Initially, the heterogeneity of the spreading is achieved
considering the RGG networks, in which we analytically derive an expression for
the distribution of the spreading rates among the established contacts, by
assuming that such rates decay exponentially with the distance that separates
the individuals. Such distribution is also considered for the ER and BA models,
where we observe topological effects on the correlations. In the case of the
airport network, the spreading rates are empirically defined, assumed to be
directly proportional to the seat availability. Among both the theoretical and
the real networks considered, we observe a high correlation between the total
epidemic prevalence and the degree, as well as the strength and the
accessibility of the epidemic sources. For attributes such as the betweenness
centrality and the $k$-shell index, however, the correlation depends on the
topology considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0031</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0031</id><created>2012-01-31</created><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Social Dynamics of Digg</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>arXiv admin note: text overlap with arXiv:1010.0237</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online social media provide multiple ways to find interesting content. One
important method is highlighting content recommended by user's friends. We
examine this process on one such site, the news aggregator Digg. With a
stochastic model of user behavior, we distinguish the effects of the content
visibility and interestingness to users. We find a wide range of interest and
distinguish stories primarily of interest to a users' friends from those of
interest to the entire user community. We show how this model predicts a
story's eventual popularity from users' early reactions to it, and estimate the
prediction reliability. This modeling framework can help evaluate alternative
design choices for displaying content on the site.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0042</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0042</id><created>2012-01-31</created><updated>2012-02-03</updated><authors><author><keyname>Connamacher</keyname><forenames>Harold</forenames></author><author><keyname>Molloy</keyname><forenames>Michael</forenames></author></authors><title>The Satisfiability Threshold for a Seemingly Intractable Random
  Constraint Satisfaction Problem</title><categories>cs.DM</categories><comments>This is the long version of a paper that will be published in the
  SIAM Journal on Discrete Mathematics. This long version includes an appendix
  and a computer program. The contents of the paper are unchanged in the latest
  version. The format of the arxiv submission was changed so that the computer
  program will appear as an ancillary file. Some comments in the computer
  program were updated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the exact threshold of satisfiability for random instances of a
particular NP-complete constraint satisfaction problem (CSP). This is the first
random CSP model for which we have determined a precise linear satisfiability
threshold, and for which random instances with density near that threshold
appear to be computationally difficult. More formally, it is the first random
CSP model for which the satisfiability threshold is known and which shares the
following characteristics with random k-SAT for k &gt;= 3. The problem is
NP-complete, the satisfiability threshold occurs when there is a linear number
of clauses, and a uniformly random instance with a linear number of clauses
asymptotically almost surely has exponential resolution complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0055</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0055</id><created>2012-01-31</created><authors><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Gershman</keyname><forenames>Alex B.</forenames></author></authors><title>Moving Target Parameters Estimation in Non-Coherent MIMO Radar Systems</title><categories>cs.IT math.IT stat.AP</categories><comments>17 pages, 4 figures, Submitted to the IEEE Trans. Signal Processing
  in Aug. 2011</comments><journal-ref>A. Hassanien, S.A. Vorobyov, and A.B. Gershman, &quot;Moving target
  parameters estimation in non-coherent MIMO radar systems,&quot; IEEE Trans. Signal
  Processing, vol. 60, no. 5, pp. 2354-2361, May 2012</journal-ref><doi>10.1109/TSP.2012.2187290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of estimating the parameters of a moving target in multiple-input
multiple-output (MIMO) radar is considered and a new approach for estimating
the moving target parameters by making use of the phase information associated
with each transmit-receive path is introduced. It is required for this
technique that different receive antennas have the same time reference, but no
synchronization of initial phases of the receive antennas is needed and,
therefore, the estimation process is non-coherent. We model the target motion
within a certain processing interval as a polynomial of general order. The
first three coefficients of such a polynomial correspond to the initial
location, velocity, and acceleration of the target, respectively. A new maximum
likelihood (ML) technique for estimating the target motion coefficients is
developed. It is shown that the considered ML problem can be interpreted as the
classic &quot;overdetermined&quot; nonlinear least-squares problem. The proposed ML
estimator requires multi-dimensional search over the unknown polynomial
coefficients. The Cram\'er-Rao Bound (CRB) for the proposed parameter
estimation problem is derived. The performance of the proposed estimator is
validated by simulation results and is shown to achieve the CRB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0077</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0077</id><created>2012-01-31</created><updated>2012-07-24</updated><authors><author><keyname>Armano</keyname><forenames>Giuliano</forenames></author><author><keyname>Javarone</keyname><forenames>Marco Alberto</forenames></author></authors><title>Datasets as Interacting Particle Systems: a Framework for Clustering</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>13 pages, 5 figures. Submitted to ACS - Advances in Complex Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a framework inspired by interacting particle physics
and devised to perform clustering on multidimensional datasets. To this end,
any given dataset is modeled as an interacting particle system, under the
assumption that each element of the dataset corresponds to a different particle
and that particle interactions are rendered through gaussian potentials.
Moreover, the way particle interactions are evaluated depends on a parameter
that controls the shape of the underlying gaussian model. In principle,
different clusters of proximal particles can be identified, according to the
value adopted for the parameter. This degree of freedom in gaussian potentials
has been introduced with the goal of allowing multiresolution analysis. In
particular, upon the adoption of a standard community detection algorithm,
multiresolution analysis is put into practice by repeatedly running the
algorithm on a set of adjacency matrices, each dependent on a specific value of
the parameter that controls the shape of gaussian potentials. As a result,
different partitioning schemas are obtained on the given dataset, so that the
information thereof can be better highlighted, with the goal of identifying the
most appropriate number of clusters. Solutions achieved in synthetic datasets
allowed to identify a repetitive pattern, which appear to be useful in the task
of identifying optimal solutions while analysing other synthetic and real
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0082</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0082</id><created>2012-01-31</created><authors><author><keyname>Gao</keyname><forenames>Jianhang</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Ren</keyname><forenames>Wei</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author><author><keyname>Ramanathan</keyname><forenames>Ram</forenames></author><author><keyname>Bar-Noy</keyname><forenames>Amotz</forenames></author></authors><title>Dynamic Shortest Path Algorithms for Hypergraphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hypergraph is a set V of vertices and a set of non-empty subsets of V,
called hyperedges. Unlike graphs, hypergraphs can capture higher-order
interactions in social and communication networks that go beyond a simple union
of pairwise relationships. In this paper, we consider the shortest path problem
in hypergraphs. We develop two algorithms for finding and maintaining the
shortest hyperpaths in a dynamic network with both weight and topological
changes. These two algorithms are the first to address the fully dynamic
shortest path problem in a general hypergraph. They complement each other by
partitioning the application space based on the nature of the change dynamics
and the type of the hypergraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0085</identifier>
 <datestamp>2014-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0085</id><created>2012-01-31</created><updated>2012-06-05</updated><authors><author><keyname>Lopez</keyname><forenames>Hiram H.</forenames></author><author><keyname>Renteria</keyname><forenames>Carlos</forenames></author><author><keyname>Villarreal</keyname><forenames>Rafael H.</forenames></author></authors><title>Affine cartesian codes</title><categories>math.AC cs.IT math.AG math.IT</categories><comments>Designs, Codes and Cryptography, to appear</comments><msc-class>13P25, 14G50, 94B27, 11T71</msc-class><journal-ref>Des. Codes Cryptogr. 71 (2014), no. 1, 5--19</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute the basic parameters (dimension, length, minimum distance) of
affine evaluation codes defined on a cartesian product of finite sets. Given a
sequence of positive integers, we construct an evaluation code, over a
degenerate torus, with prescribed parameters. As an application of our results,
we recover the formulas for the minimum distance of various families of
evaluation codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0097</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0097</id><created>2012-01-31</created><authors><author><keyname>Geng</keyname><forenames>Yanlin</forenames></author><author><keyname>Nair</keyname><forenames>Chandra</forenames></author></authors><title>The capacity region of the two-receiver vector Gaussian broadcast
  channel with private and common messages</title><categories>cs.IT math.IT</categories><comments>20 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new method for showing the optimality of the Gaussian
distribution in multiterminal information theory problems. As an application of
this method we show that Marton's inner bound achieves the capacity of the
vector Gaussian broadcast channels with common message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0108</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0108</id><created>2012-02-01</created><authors><author><keyname>Fricker</keyname><forenames>Christine</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Roberts</keyname><forenames>James</forenames></author><author><keyname>Sbihi</keyname><forenames>Nada</forenames></author></authors><title>Impact of traffic mix on caching performance in a content-centric
  network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a realistic traffic mix, we evaluate the hit rates attained in a
two-layer cache hierarchy designed to reduce Internet bandwidth requirements.
The model identifies four main types of content, web, file sharing, user
generated content and video on demand, distinguished in terms of their traffic
shares, their population and object sizes and their popularity distributions.
Results demonstrate that caching VoD in access routers offers a highly
favorable bandwidth memory tradeoff but that the other types of content would
likely be more efficiently handled in very large capacity storage devices in
the core. Evaluations are based on a simple approximation for LRU cache
performance that proves highly accurate in relevant configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0116</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0116</id><created>2012-02-01</created><authors><author><keyname>Ostapov</keyname><forenames>Yuriy</forenames></author></authors><title>Inference and Plausible Reasoning in a Natural Language Understanding
  System Based on Object-Oriented Semantics</title><categories>cs.CL</categories><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms of inference in a computer system oriented to input and semantic
processing of text information are presented. Such inference is necessary for
logical questions when the direct comparison of objects from a question and
database can not give a result. The following classes of problems are
considered: a check of hypotheses for persons and non-typical actions, the
determination of persons and circumstances for non-typical actions, planning
actions, the determination of event cause and state of persons. To form an
answer both deduction and plausible reasoning are used. As a knowledge domain
under consideration is social behavior of persons, plausible reasoning is based
on laws of social psychology. Proposed algorithms of inference and plausible
reasoning can be realized in computer systems closely connected with text
processing (criminology, operation of business, medicine, document systems).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0119</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0119</id><created>2012-02-01</created><updated>2012-07-16</updated><authors><author><keyname>Kampeas</keyname><forenames>Joseph</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Gurewitz</keyname><forenames>Omer</forenames></author></authors><title>Opportunistic Scheduling in Heterogeneous Networks: Distributed
  Algorithms and System Capacity</title><categories>cs.IT cs.NI math.IT</categories><comments>33 pages; 12 figures. Parts of this work will appear at the
  Information Theory and Applications Workshop, San Diego, CA, ITA 2012, and
  submitted to the IEEE International Symposium on Information Theory,
  Cambridge, MA, ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we design and analyze novel distributed scheduling algorithms
for multi-user MIMO systems. In particular, we consider algorithms which do not
require sending channel state information to a central processing unit, nor do
they require communication between the users themselves, yet, we prove their
performance closely approximates that of a centrally-controlled system, which
is able to schedule the strongest user in each time-slot.
  Our analysis is based on a novel application of the Point-Process
approximation. This novel technique allows us to examine non-homogeneous cases,
such as non-identically distributed users, or handling various QoS
considerations, and give exact expressions for the capacity of the system under
these schemes, solving analytically problems which to date had been open.
Possible application include, but are not limited to, modern 4G networks such
as 3GPP LTE, or random access protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0135</identifier>
 <datestamp>2012-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0135</id><created>2012-02-01</created><updated>2012-06-11</updated><authors><author><keyname>Aggarwal</keyname><forenames>Rohit</forenames></author><author><keyname>Koksal</keyname><forenames>Can Emre</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>On the Design of Large Scale Wireless Systems (with detailed proofs)</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the downlink of large OFDMA-based networks and
study their performance bounds as a function of the number of - transmitters
$B$, users $K$, and resource-blocks $N$. Here, a resource block is a collection
of subcarriers such that all such collections, that are disjoint have
associated independently fading channels. In particular, we analyze the
expected achievable sum-rate as a function of above variables and derive novel
upper and lower bounds for a general spatial geometry of transmitters, a
truncated path-loss model, and a variety of fading models. We establish the
associated scaling laws for dense and extended networks, and propose design
guidelines for the regulators to guarantee various QoS constraints and, at the
same time, maximize revenue for the service providers. Thereafter, we develop a
distributed resource allocation scheme that achieves the same sum-rate scaling
as that of the proposed upper bound for a wide range of $K, B, N$. Based on it,
we compare low-powered peer-to-peer networks to high-powered single-transmitter
networks and give an additional design principle. Finally, we also show how our
results can be extended to the scenario where each of the $B$ transmitters have
$M (&gt;1)$ co-located antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0136</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0136</id><created>2012-02-01</created><updated>2013-01-24</updated><authors><author><keyname>Charalambous</keyname><forenames>Themistoklis</forenames></author><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author></authors><title>Variable Length Lossless Coding for Variational Distance Class: An
  Optimal Merging Algorithm</title><categories>cs.IT math.IT</categories><comments>28 pages, 4 figures. arXiv admin note: substantial text overlap with
  arXiv:1112.1715</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider lossless source coding for a class of sources
specified by the total variational distance ball centred at a fixed nominal
probability distribution. The objective is to find a minimax average length
source code, where the minimizers are the codeword lengths -- real numbers for
arithmetic or Shannon codes -- while the maximizers are the source
distributions from the total variational distance ball. Firstly, we examine the
maximization of the average codeword length by converting it into an equivalent
optimization problem, and we give the optimal codeword lenghts via a
waterfilling solution. Secondly, we show that the equivalent optimization
problem can be solved via an optimal partition of the source alphabet, and
re-normalization and merging of the fixed nominal probabilities. For the
computation of the optimal codeword lengths we also develop a fast algorithm
with a computational complexity of order ${\cal O}(n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0137</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0137</id><created>2012-02-01</created><authors><author><keyname>Kartzow</keyname><forenames>Alexander</forenames></author></authors><title>First-Order Model Checking on Generalisations of Pushdown Graphs</title><categories>math.LO cs.FL cs.LO</categories><comments>phd thesis, 255 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the first-order model checking problem on two generalisations of
pushdown graphs. The first class is the class of nested pushdown trees. The
other is the class of collapsible pushdown graphs. Our main results are the
following. First-order logic with reachability is uniformly decidable on nested
pushdown trees. Considering first-order logic without reachability, we prove
decidability in doubly exponential alternating time with linearly many
alternations. First-order logic with regular reachability predicates is
uniformly decidable on level 2 collapsible pushdown graphs. Moreover, nested
pushdown trees are first-order interpretable in collapsible pushdown graphs of
level 2. This interpretation can be extended to an interpretation of the class
of higher-order nested pushdown trees in the collapsible pushdown graph
hierarchy. We prove that the second level of this new hierarchy of nested trees
has decidable first-order model checking. Our decidability result for
collapsible pushdown graph relies on the fact that level 2 collapsible pushdown
graphs are uniform tree-automatic. Our last result concerns tree-automatic
structures in general. We prove that first-order logic extended by Ramsey
quantifiers is decidable on all tree-automatic structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0139</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0139</id><created>2012-02-01</created><updated>2012-05-09</updated><authors><author><keyname>Heged&#xfc;s</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Schicho</keyname><forenames>Josef</forenames></author><author><keyname>Schr&#xf6;cker</keyname><forenames>Hans-Peter</forenames></author></authors><title>Factorization of Rational Curves in the Study Quadric and Revolute
  Linkages</title><categories>math.RA cs.RO math.AG</categories><comments>Changed arxiv abstract, corrected some types</comments><msc-class>12D05, 51J15, 68T40</msc-class><journal-ref>Mech. Machine Theory, Vol. 69, No. 1, pp. 142-152, 2013</journal-ref><doi>10.1016/j.mechmachtheory.2013.05.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a generic rational curve $C$ in the group of Euclidean displacements we
construct a linkage such that the constrained motion of one of the links is
exactly $C$. Our construction is based on the factorization of polynomials over
dual quaternions. Low degree examples include the Bennett mechanisms and
contain new types of overconstrained 6R-chains as sub-mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0153</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0153</id><created>2012-02-01</created><authors><author><keyname>Bagchi</keyname><forenames>Bhaskar</forenames></author><author><keyname>Datta</keyname><forenames>Basudeb</forenames></author></authors><title>Higher dimensional analogues of the map colouring problem</title><categories>math.CO cs.CG</categories><comments>4 pages</comments><msc-class>05C15, 05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After a brief discussion of the history of the problem, we propose a
generalization of the map colouring problem to higher dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0163</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0163</id><created>2012-02-01</created><authors><author><keyname>Noam</keyname><forenames>Yair</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Spatial MAC in MIMO Communications and its Application to Underlay
  Cognitive Radio</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a learning technique for MIMO secondary users (SU) to spatially
coexist with Primary Users (PU). By learning the null space of the interference
channel to the PU, the SU can utilize idle degrees of freedom that otherwise
would be unused by the PU. This learning process does not require any handshake
or explicit information exchange between the PU and the SU. The only
requirement is that the PU broadcasts a periodic beacon that is a function of
its noise plus interference power, through a low rate control channel. The
learning process is based on energy measurements, independent of the
transmission schemes of both the PU and SU, i.e. independent of their
modulation, coding etc.. The proposed learning technique also provides a novel
spatial division multiple access mechanism for equal-priority MIMO users
sharing a common channel that highly increases the spectrum utilization
compared to time based or frequency multiple access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0168</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0168</id><created>2012-02-01</created><updated>2012-09-30</updated><authors><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Riegler</keyname><forenames>Erwin</forenames></author></authors><title>On the Capacity of Large-MIMO Block-Fading Channels</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Journal on Selected Areas in Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the capacity of Rayleigh block-fading multiple-input
multiple-output (MIMO) channels in the noncoherent setting where transmitter
and receiver have no a priori knowledge of the realizations of the fading
channel. We prove that unitary space-time modulation (USTM) is not
capacity-achieving in the high signal-to-noise ratio (SNR) regime when the
total number of antennas exceeds the coherence time of the fading channel
(expressed in multiples of the symbol duration), a situation that is relevant
for MIMO systems with large antenna arrays (large-MIMO systems). This result
settles a conjecture by Zheng &amp; Tse (2002) in the affirmative. The
capacity-achieving input signal, which we refer to as Beta-variate space-time
modulation (BSTM), turns out to be the product of a unitary isotropically
distributed random matrix, and a diagonal matrix whose nonzero entries are
distributed as the square-root of the eigenvalues of a Beta-distributed random
matrix of appropriate size. Numerical results illustrate that using BSTM
instead of USTM in large-MIMO systems yields a rate gain as large as 13% for
SNR values of practical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0179</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0179</id><created>2012-02-01</created><authors><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames></author><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames></author><author><keyname>Spaenlehauer</keyname><forenames>Pierre-Jean</forenames></author></authors><title>Critical Points and Gr\&quot;obner Bases: the Unmixed Case</title><categories>cs.SC</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing critical points of the restriction of a
polynomial map to an algebraic variety. This is of first importance since the
global minimum of such a map is reached at a critical point. Thus, these points
appear naturally in non-convex polynomial optimization which occurs in a wide
range of scientific applications (control theory, chemistry, economics,...).
Critical points also play a central role in recent algorithms of effective real
algebraic geometry. Experimentally, it has been observed that Gr\&quot;obner basis
algorithms are efficient to compute such points. Therefore, recent software
based on the so-called Critical Point Method are built on Gr\&quot;obner bases
engines. Let $f_1,..., f_p$ be polynomials in $ \Q[x_1,..., x_n]$ of degree
$D$, $V\subset\C^n$ be their complex variety and $\pi_1$ be the projection map
$(x_1,.., x_n)\mapsto x_1$. The critical points of the restriction of $\pi_1$
to $V$ are defined by the vanishing of $f_1,..., f_p$ and some maximal minors
of the Jacobian matrix associated to $f_1,..., f_p$. Such a system is
algebraically structured: the ideal it generates is the sum of a determinantal
ideal and the ideal generated by $f_1,..., f_p$. We provide the first
complexity estimates on the computation of Gr\&quot;obner bases of such systems
defining critical points. We prove that under genericity assumptions on
$f_1,..., f_p$, the complexity is polynomial in the generic number of critical
points, i.e. $D^p(D-1)^{n-p}{{n-1}\choose{p-1}}$. More particularly, in the
quadratic case D=2, the complexity of such a Gr\&quot;obner basis computation is
polynomial in the number of variables $n$ and exponential in $p$. We also give
experimental evidence supporting these theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0186</identifier>
 <datestamp>2014-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0186</id><created>2012-02-01</created><updated>2014-01-15</updated><authors><author><keyname>Gonzalez</keyname><forenames>Oscar</forenames></author><author><keyname>Beltran</keyname><forenames>Carlos</forenames></author><author><keyname>Santamaria</keyname><forenames>Ignacio</forenames></author></authors><title>A Feasibility Test for Linear Interference Alignment in MIMO Channels
  with Constant Coefficients</title><categories>cs.IT math.IT</categories><comments>To be published in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol.60, no.3, pp.
  1840-1856, March 2014</journal-ref><doi>10.1109/TIT.2014.2301440</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the feasibility of linear interference alignment
(IA) for multiple-input multiple-output (MIMO) channels with constant
coefficients for any number of users, antennas and streams per user; and
propose a polynomial-time test for this problem. Combining algebraic geometry
techniques with differential topology ones, we first prove a result that
generalizes those previously published on this topic. Specifically, we consider
the input set (complex projective space of MIMO interference channels), the
output set (precoder and decoder Grassmannians) and the solution set (channels,
decoders and precoders satisfying the IA polynomial equations), not only as
algebraic sets but also as smooth compact manifolds. Using this mathematical
framework, we prove that the linear alignment problem is feasible when the
algebraic dimension of the solution variety is larger than or equal to the
dimension of the input space and the linear mapping between the tangent spaces
of both smooth manifolds given by the first projection is generically
surjective. If that mapping is not surjective, then the solution variety
projects into the input space in a singular way and the projection is a
zero-measure set. This result naturally yields a simple feasibility test, which
amounts to checking the rank of a matrix. We also provide an exact arithmetic
version of the test, which proves that testing the feasibility of IA for
generic MIMO channels belongs to the bounded-error probabilistic polynomial
(BPP) complexity class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0191</identifier>
 <datestamp>2014-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0191</id><created>2012-02-01</created><updated>2012-02-02</updated><authors><author><keyname>Mones</keyname><forenames>Enys</forenames></author><author><keyname>Vicsek</keyname><forenames>Lilla</forenames></author><author><keyname>Vicsek</keyname><forenames>Tam&#xe1;s</forenames></author></authors><title>Hierarchy measure for complex networks</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.SI</categories><comments>29 pages, 9 figures, 4 tables</comments><journal-ref>PLoS ONE 7(3): e33799 (2012)</journal-ref><doi>10.1371/journal.pone.0033799</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nature, technology and society are full of complexity arising from the
intricate web of the interactions among the units of the related systems (e.g.,
proteins, computers, people). Consequently, one of the most successful recent
approaches to capturing the fundamental features of the structure and dynamics
of complex systems has been the investigation of the networks associated with
the above units (nodes) together with their relations (edges). Most complex
systems have an inherently hierarchical organization and, correspondingly, the
networks behind them also exhibit hierarchical features. Indeed, several papers
have been devoted to describing this essential aspect of networks, however,
without resulting in a widely accepted, converging concept concerning the
quantitative characterization of the level of their hierarchy. Here we develop
an approach and propose a quantity (measure) which is simple enough to be
widely applicable, reveals a number of universal features of the organization
of real-world networks and, as we demonstrate, is capable of capturing the
essential features of the structure and the degree of hierarchy in a complex
network. The measure we introduce is based on a generalization of the m-reach
centrality, which we first extend to directed/partially directed graphs. Then,
we define the global reaching centrality (GRC), which is the difference between
the maximum and the average value of the generalized reach centralities over
the network. We investigate the behavior of the GRC considering both a
synthetic model with an adjustable level of hierarchy and real networks.
Results for real networks show that our hierarchy measure is related to the
controllability of the given system. We also propose a visualization procedure
for large complex networks that can be used to obtain an overall qualitative
picture about the nature of their hierarchical structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0200</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0200</id><created>2012-02-01</created><authors><author><keyname>Chitikela</keyname><forenames>Sindhu</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Increasing Randomness Using Permutations on Blocks</title><categories>cs.CR</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the effect of permutations on blocks of a prime
reciprocal sequence on its randomness. A relationship between the number of
permutations used and the improvement of performance is presented. This can be
used as a method for increasing the cryptographic strength of pseudorandom
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0204</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0204</id><created>2012-02-01</created><authors><author><keyname>Mirmohseni</keyname><forenames>Mahtab</forenames></author><author><keyname>Akhbari</keyname><forenames>Bahareh</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>On the Capacity of Interference Channel with Causal and Non-causal
  Generalized Feedback at the Cognitive Transmitter</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory, 2012. arXiv
  admin note: substantial text overlap with arXiv:1001.2892</comments><doi>10.1109/TIT.2012.2184844.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, taking into account the effect of link delays, we investigate
the capacity region of the Cognitive Interference Channel (C-IFC), where
cognition can be obtained from either causal or non-causal generalized
feedback. For this purpose, we introduce the Causal Cognitive Interference
Channel With Delay (CC-IFC-WD) in which the cognitive user's transmission can
depend on $L$ future received symbols as well as the past ones. We show that
the CC-IFC-WD model is equivalent to a classical Causal C-IFC (CC-IFC) with
link delays. Moreover, CC-IFC-WD extends both genie-aided and causal cognitive
radio channels and bridges the gap between them. First, we derive an outer
bound on the capacity region for the arbitrary value of $L$ and specialize this
general outer bound to the strong interference case. Then, under strong
interference conditions, we tighten the outer bound. To derive the achievable
rate regions, we concentrate on three special cases: 1) Classical CC-IFC (L=0),
2) CC-IFC without delay (L=1), and 3) CC-IFC with unlimited look-ahead in which
the cognitive user non-causally knows its entire received sequence. In each
case, we obtain a new inner bound on the capacity region. Moreover, we show
that the coding strategy which we use to derive an achievable rate region for
the classical CC-IFC achieves the capacity for the classes of degraded and
semi-deterministic classical CC-IFC under strong interference conditions.
Furthermore, we extend our achievable rate regions to the Gaussian case.
Providing some numerical examples for Gaussian CC-IFC-WD, we compare the
performances of the different strategies and investigate the rate gain of the
cognitive link for different delay values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0206</identifier>
 <datestamp>2014-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0206</id><created>2012-02-01</created><updated>2014-03-05</updated><authors><author><keyname>Chan</keyname><forenames>Chun Lam</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author></authors><title>Non-adaptive Group Testing: Explicit bounds and novel algorithms</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Transactions on Information
  Theory; current version, Oct. 9, 2012. Main change from v4 to v5: fixed some
  typos, corrected details of the LP decoding algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider some computationally efficient and provably correct algorithms
with near-optimal sample-complexity for the problem of noisy non-adaptive group
testing. Group testing involves grouping arbitrary subsets of items into pools.
Each pool is then tested to identify the defective items, which are usually
assumed to be &quot;sparse&quot;. We consider non-adaptive randomly pooling measurements,
where pools are selected randomly and independently of the test outcomes. We
also consider a model where noisy measurements allow for both some false
negative and some false positive test outcomes (and also allow for asymmetric
noise, and activation noise). We consider three classes of algorithms for the
group testing problem (we call them specifically the &quot;Coupon Collector
Algorithm&quot;, the &quot;Column Matching Algorithms&quot;, and the &quot;LP Decoding Algorithms&quot;
-- the last two classes of algorithms (versions of some of which had been
considered before in the literature) were inspired by corresponding algorithms
in the Compressive Sensing literature. The second and third of these algorithms
have several flavours, dealing separately with the noiseless and noisy
measurement scenarios. Our contribution is novel analysis to derive explicit
sample-complexity bounds -- with all constants expressly computed -- for these
algorithms as a function of the desired error probability; the noise
parameters; the number of items; and the size of the defective set (or an upper
bound on it). We also compare the bounds to information-theoretic lower bounds
for sample complexity based on Fano's inequality and show that the upper and
lower bounds are equal up to an explicitly computable universal constant factor
(independent of problem parameters).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0207</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0207</id><created>2012-02-01</created><authors><author><keyname>Bulakci</keyname><forenames>Omer</forenames></author></authors><title>Multi-hop Moving Relays for IMT-Advanced and Beyond</title><categories>cs.NI</categories><comments>This work was presented as a part of Licentiate Seminar, Department
  of Communications and Networking, Aalto University, 2010. 4 pages. Seminar
  paper</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Relaying is a promising enhancement to current radio technologies, which has
been considered in IMT-Advanced candidate technologies such as 3GPP
LTE-Advanced and IEEE 802.16m. Relay enhanced networks are expected to fulfill
the demanding coverage and capacity requirements in a cost efficient way. Among
various relaying architectures multi-hop moving relays can provide additional
capacity for the cases when fixed relays are inaccessible or not able to
provide adequate solutions in terms of cost. In this paper, an overview of
multi-hop moving relays along with some of the envisioned deployment scenarios
is presented. Furthermore, different types of multi-hop moving relays are
discussed and the challenges are addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0212</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0212</id><created>2012-02-01</created><authors><author><keyname>Bulakci</keyname><forenames>Omer</forenames></author></authors><title>On Backhauling of Relay Enhanced Networks in LTE-Advanced</title><categories>cs.NI</categories><comments>This work was presented as a part of Licentiate Seminar, Department
  of Communications and Networking, Aalto University, 2010. 4 pages. Seminar
  paper</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Relaying is considered a promising cost-efficient solution in 3GPP
LTE-Advanced for coverage extension and throughput enhancement. The compact
physical characteristics and low power requirements of the relay nodes offer
more flexible deployment options than traditional macro evolved Node Bs. This
paper provides an overview of general relaying concepts and presents the relay
deployment within the LTE-Advanced framework. Furthermore, the impact of relay
backhauling on envisioned relaying gains is discussed and the methods to
improve the performance of the backhauling are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0213</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0213</id><created>2012-02-01</created><authors><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Saad</keyname><forenames>David</forenames></author></authors><title>The Competition for Shortest Paths on Sparse Graphs</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.NI physics.soc-ph</categories><comments>4 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 108, 208701 (2012)</journal-ref><doi>10.1103/PhysRevLett.108.208701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal paths connecting randomly selected network nodes and fixed routers
are studied analytically in the presence of non-linear overlap cost that
penalizes congestion. Routing becomes increasingly more difficult as the number
of selected nodes increases and exhibits ergodicity breaking in the case of
multiple routers. A distributed linearly-scalable routing algorithm is devised.
The ground state of such systems reveals non-monotonic complex behaviors in
both average path-length and algorithmic convergence, depending on the network
topology, and densities of communicating nodes and routers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0216</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0216</id><created>2012-02-01</created><authors><author><keyname>Meyer</keyname><forenames>Fernand</forenames></author></authors><title>The watershed concept and its use in segmentation : a brief history</title><categories>cs.CV</categories><msc-class>68U10, 05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The watershed is one of the most used tools in image segmentation. We present
how its concept is born and developed over time. Its implementation as an
algorithm or a hardwired device evolved together with the technology which
allowed it. We present also how it is used in practice, first together with
markers, and later introduced in a multiscale framework, in order to produce
not a unique partition but a complete hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0223</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0223</id><created>2012-02-01</created><authors><author><keyname>Ella</keyname><forenames>V. Spoorthy</forenames></author></authors><title>Randomization Using Quasigroups, Hadamard and Number Theoretic
  Transforms</title><categories>cs.CR</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of quasigroups, Hadamard transforms and
Number Theoretic Transforms for use in sequence randomization. This can also be
used to generate hash functions for sequence encryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0224</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0224</id><created>2012-02-01</created><updated>2012-06-07</updated><authors><author><keyname>Bagrow</keyname><forenames>James P.</forenames></author><author><keyname>Lin</keyname><forenames>Yu-Ru</forenames></author></authors><title>Mesoscopic structure and social aspects of human mobility</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.data-an</categories><comments>7 pages, 5 figures (main text); 11 pages, 9 figures, 1 table
  (supporting information)</comments><journal-ref>PLoS ONE 7(5): e37676, 2012</journal-ref><doi>10.1371/journal.pone.0037676</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The individual movements of large numbers of people are important in many
contexts, from urban planning to disease spreading. Datasets that capture human
mobility are now available and many interesting features have been discovered,
including the ultra-slow spatial growth of individual mobility. However, the
detailed substructures and spatiotemporal flows of mobility - the sets and
sequences of visited locations - have not been well studied. We show that
individual mobility is dominated by small groups of frequently visited,
dynamically close locations, forming primary &quot;habitats&quot; capturing typical daily
activity, along with subsidiary habitats representing additional travel. These
habitats do not correspond to typical contexts such as home or work. The
temporal evolution of mobility within habitats, which constitutes most motion,
is universal across habitats and exhibits scaling patterns both distinct from
all previous observations and unpredicted by current models. The delay to enter
subsidiary habitats is a primary factor in the spatiotemporal growth of human
travel. Interestingly, habitats correlate with non-mobility dynamics such as
communication activity, implying that habitats may influence processes such as
information spreading and revealing new connections between human mobility and
social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0225</identifier>
 <datestamp>2012-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0225</id><created>2012-02-01</created><updated>2012-04-22</updated><authors><author><keyname>Viet</keyname><forenames>Nguyen Tien</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author></authors><title>Generating Functionals of Random Packing Point Processes: From Hard-Core
  to Carrier Sensing</title><categories>math.PR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the generating functionals of several random packing
processes: the classical Mat\'ern hard-core model; its extensions, the
$k$-Mat\'ern models and the $\infty$-Mat\'ern model, which is an example of
random sequential packing process. We first give a sufficient condition for the
$\infty$-Mat\'ern model to be well-defined (unlike the other two, the latter
may not be well-defined on unbounded spaces). Then the generating functional of
the resulting point process is given for each of the three models as the
solution of a differential equation. Series representations and bounds on the
generating functional of the packing models are also derived. Last but not
least, we obtain moment measures and Palm distributions of the considered
packing models departing from their generating functionals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0241</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0241</id><created>2012-02-01</created><updated>2012-06-05</updated><authors><author><keyname>Lim</keyname><forenames>Fabian</forenames></author><author><keyname>Hagiwara</keyname><forenames>Manabu</forenames></author></authors><title>Linear Programming Upper Bounds on Permutation Code Sizes From Coherent
  Configurations Related to the Kendall Tau Distance Metric</title><categories>cs.IT math.IT</categories><comments>IEEE Intl. Symp. on Inform. Theory 2012. Final Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent interest on permutation rank modulation shows the Kendall tau metric
as an important distance metric. This note documents our first efforts to
obtain upper bounds on optimal code sizes (for said metric) ala Delsarte's
approach. For the Hamming metric, Delsarte's seminal work on powerful linear
programming (LP) bounds have been extended to permutation codes, via
association scheme theory. For the Kendall tau metric, the same extension needs
the more general theory of coherent configurations, whereby the optimal code
size problem can be formulated as an extremely huge semidefinite programming
(SDP) problem. Inspired by recent algebraic techniques for solving SDP's, we
consider the dual problem, and propose an LP to search over a subset of dual
feasible solutions. We obtain modest improvement over a recent Singleton bound
due to Barg and Mazumdar. We regard this work as a starting point, towards
fully exploiting the power of Delsarte's method, which are known to give some
of the best bounds in the context of binary codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0242</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0242</id><created>2012-02-01</created><authors><author><keyname>Zinn</keyname><forenames>Daniel</forenames></author></authors><title>Weak Forms of Monotonicity and Coordination-Freeness</title><categories>cs.DB cs.DC</categories><comments>Early Research Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our earlier work titled: &quot;Win-move is Coordination-Free (Sometimes)&quot; has
shown that the classes of queries that can be distributedly computed in a
coordination-free manner form a strict hierarchy depending on the assumptions
of the model for distributed computations. In this paper, we further
characterize these classes by revealing a tight relationship between them and
novel weakened forms of monotonicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0253</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0253</id><created>2012-02-01</created><authors><author><keyname>Karaman</keyname><forenames>Sertac</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>High-speed Flight in an Ergodic Forest</title><categories>cs.RO cs.SY</categories><comments>Manuscript submitted to the IEEE Transactions on Robotics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by birds flying through cluttered environments such as dense
forests, this paper studies the theoretical foundations of a novel motion
planning problem: high-speed navigation through a randomly-generated obstacle
field when only the statistics of the obstacle generating process are known a
priori. Resembling a planar forest environment, the obstacle generating process
is assumed to determine the locations and sizes of disk-shaped obstacles. When
this process is ergodic, and under mild technical conditions on the dynamics of
the bird, it is shown that the existence of an infinite collision-free
trajectory through the forest exhibits a phase transition. On one hand, if the
bird flies faster than a certain critical speed, then, with probability one,
there is no infinite collision-free trajectory, i.e., the bird will eventually
collide with some tree, almost surely, regardless of the planning algorithm
governing the bird's motion. On the other hand, if the bird flies slower than
this critical speed, then there exists at least one infinite collision-free
trajectory, almost surely. Lower and upper bounds on the critical speed are
derived for the special case of a homogeneous Poisson forest considering a
simple model for the bird's dynamics. For the same case, an equivalent
percolation model is provided. Using this model, the phase diagram is
approximated in Monte-Carlo simulations. This paper also establishes novel
connections between robot motion planning and statistical physics through
ergodic theory and percolation theory, which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0255</identifier>
 <datestamp>2012-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0255</id><created>2012-02-01</created><updated>2012-05-03</updated><authors><author><keyname>White</keyname><forenames>Graham</forenames></author></authors><title>Reasoning about Unreliable Actions</title><categories>math.LO cs.AI math.CT</categories><msc-class>18C50</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the philosopher Davidson's semantics of actions, using a strongly
typed logic with contexts given by sets of partial equations between the
outcomes of actions. This provides a perspicuous and elegant treatment of
reasoning about action, analogous to Reiter's work on artificial intelligence.
We define a sequent calculus for this logic, prove cut elimination, and give a
semantics based on fibrations over partial cartesian categories: we give a
structure theory for such fibrations. The existence of lax comma objects is
necessary for the proof of cut elimination, and we give conditions on the
domain fibration of a partial cartesian category for such comma objects to
exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0296</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0296</id><created>2012-02-01</created><updated>2012-07-03</updated><authors><author><keyname>Pappi</keyname><forenames>Koralia N.</forenames></author><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Error Performance of Multidimensional Lattice Constellations-Part I: A
  Parallelotope Geometry Based Approach for the AWGN Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional lattice constellations which present signal space diversity
(SSD) have been extensively studied for single-antenna transmission over fading
channels, with focus on their optimal design for achieving high diversity gain.
In this two-part series of papers we present a novel combinatorial geometrical
approach based on parallelotope geometry, for the performance evaluation of
multidimensional finite lattice constellations with arbitrary structure,
dimension and rank. In Part I, we present an analytical expression for the
exact symbol error probability (SEP) of multidimensional signal sets, and two
novel closed-form bounds, named Multiple Sphere Lower Bound (MLSB) and Multiple
Sphere Upper Bound (MSUB). Part II extends the analysis to the transmission
over fading channels, where multidimensional signal sets are commonly used to
combat fading degradation. Numerical and simulation results show that the
proposed geometrical approach leads to accurate and tight expressions, which
can be efficiently used for the performance evaluation and the design of
multidimensional lattice constellations, both in Additive White Gaussian Noise
(AWGN) and fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0298</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0298</id><created>2012-02-01</created><updated>2012-07-03</updated><authors><author><keyname>Pappi</keyname><forenames>Koralia N.</forenames></author><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Error Performance of Multidimensional Lattice Constellations-Part II:
  Evaluation over Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second part of a two-part series of papers, where the error
performance of multidimensional lattice constellations with signal space
diversity (SSD) is investigated. In Part I, following a novel combinatorial
geometrical approach which is based on parallelotope geometry, we have
presented an exact analytical expression and two closed-form bounds for the
symbol error probability (SEP) in Additive White Gaussian Noise (AWGN). In the
present Part II, we extend the analysis and present a novel analytical
expression for the Frame Error Probability (FEP) of multidimensional lattice
constellations over Nakagami-m fading channels. As the FEP of infinite lattice
constellations is lower bounded by the Sphere Lower Bound (SLB), we propose the
Sphere Upper Bound (SUB) for block fading channels. Furthermore, two novel
bounds for the FEP of multidimensional lattice constellations over block fading
channels, named Multiple Sphere Lower Bound (MSLB) and Multiple Sphere Upper
Bound (MSUB), are presented. The expressions for the SLB and SUB are given in
closed form, while the corresponding ones for MSLB and MSUB are given in closed
form for unitary block length. Numerical and simulation results illustrate the
tightness of the proposed bounds and demonstrate that they can be efficiently
used to set the performance limits on the FEP of lattice constellations of
arbitrary structure, dimension and rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0302</identifier>
 <datestamp>2012-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0302</id><created>2012-02-01</created><updated>2012-12-05</updated><authors><author><keyname>Sutherland</keyname><forenames>Dougal J.</forenames></author><author><keyname>Xiong</keyname><forenames>Liang</forenames></author><author><keyname>P&#xf3;czos</keyname><forenames>Barnab&#xe1;s</forenames></author><author><keyname>Schneider</keyname><forenames>Jeff</forenames></author></authors><title>Kernels on Sample Sets via Nonparametric Divergence Estimates</title><categories>cs.LG stat.ML</categories><comments>Substantially updated version as submitted to T-PAMI. 15 pages
  including appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most machine learning algorithms, such as classification or regression, treat
the individual data point as the object of interest. Here we consider extending
machine learning algorithms to operate on groups of data points. We suggest
treating a group of data points as an i.i.d. sample set from an underlying
feature distribution for that group. Our approach employs kernel machines with
a kernel on i.i.d. sample sets of vectors. We define certain kernel functions
on pairs of distributions, and then use a nonparametric estimator to
consistently estimate those functions based on sample sets. The projection of
the estimated Gram matrix to the cone of symmetric positive semi-definite
matrices enables us to use kernel machines for classification, regression,
anomaly detection, and low-dimensional embedding in the space of distributions.
We present several numerical experiments both on real and simulated datasets to
demonstrate the advantages of our new approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0305</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0305</id><created>2012-02-01</created><updated>2012-08-15</updated><authors><author><keyname>Dar</keyname><forenames>Ronen</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author><author><keyname>Shtaif</keyname><forenames>Mark</forenames></author></authors><title>The Jacobi MIMO Channel</title><categories>cs.IT math.IT</categories><comments>27 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new fading model for MIMO channels, the Jacobi fading
model. It asserts that $H$, the transfer matrix which couples the $m_t$ inputs
into $m_r$ outputs, is a sub-matrix of an $m\times m$ random (Haar-distributed)
unitary matrix. The (squared) singular values of $H$ follow the law of the
classical Jacobi ensemble of random matrices; hence the name of the channel.
One motivation to define such a channel comes from multimode/multicore optical
fiber communication. It turns out that this model can be qualitatively
different than the Rayleigh model, leading to interesting practical and
theoretical results. This work first evaluates the ergodic capacity of the
channel. Then, it considers the non-ergodic case, where it analyzes the outage
probability and the diversity-multiplexing tradeoff. In the case where
$k=m_t+m_r-m &gt; 0$ it is shown that at least $k$ degrees of freedom are
guaranteed not to fade for any channel realization, enabling a zero outage
probability or infinite diversity order at the corresponding rates. A simple
scheme utilizing (a possibly outdated) channel state feedback is provided,
attaining the no-outage guarantee. Finally, noting that as $m$ increases, the
Jacobi model approaches the Rayleigh model, the paper discusses the
applicability of the model in other communication scenaria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0307</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0307</id><created>2012-02-01</created><authors><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Utkovski</keyname><forenames>Zoran</forenames></author></authors><title>Protocol Coding through Reordering of User Resources, Part I: Capacity
  Results</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Communications. arXiv admin note: text
  overlap with arXiv:1011.5739</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast existing wireless infrastructure features a variety of systems and
standards. It is of significant practical value to introduce new features and
devices without changing the physical layer/hardware infrastructure, but
upgrade it only in software. A way to achieve it is to apply protocol coding:
encode information in the actions taken by a certain (existing) communication
protocol. In this work we investigate strategies for protocol coding via
combinatorial ordering of the labelled user resources (packets, channels) in an
existing, primary system. Such a protocol coding introduces a new secondary
communication channel in the existing system, which has been considered in the
prior work exclusively in a steganographic context. Instead, we focus on the
use of secondary channel for reliable communication with newly introduced
secondary devices, that are low-complexity versions of the primary devices,
capable only to decode the robustly encoded header information in the primary
signals. We introduce a suitable communication model, capable to capture the
constraints that the primary system operation puts on protocol coding. We have
derived the capacity of the secondary channel under arbitrary error models. The
insights from the information-theoretic analysis are used in Part II of this
work to design practical error-correcting mechanisms for secondary channels
with protocol coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0309</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0309</id><created>2012-02-01</created><authors><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Utkovski</keyname><forenames>Zoran</forenames></author><author><keyname>Trillingsgaard</keyname><forenames>Kasper F.</forenames></author></authors><title>Protocol Coding through Reordering of User Resources, Part II: Practical
  Coding Strategies</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the term protocol coding to denote the communication strategies in
which information is encoded through the actions taken by a certain
communication protocol. In this work we investigate strategies for protocol
coding via combinatorial ordering of the labelled user resources (packets,
channels) in an existing, primary system. This introduces a new, secondary
communication channel in the existing system, which has been considered in the
prior work exclusively in a steganographic context. Instead, we focus on the
use of secondary channel for reliable communication with newly introduced
secondary devices, that are low-complexity versions of the primary devices,
capable only to decode the robustly encoded header information in the primary
signals. In Part I of the work we have characterized the capacity of the
secondary channel through information-theoretic analysis. In this paper we
consider practical strategies for protocol coding inspired by the
information-theoretic analysis. It turns out that the insights from Part I are
instrumental for devising superior design of error-control codes. This is
demonstrated by comparing the error performance to the &quot;na&quot;{\i}ve&quot; strategy
which is presumably available without carrying out the analysis in Part I.
These results are clearly outlining both the conceptual novelty behind the
discussed concept of secondary channel as well as its practical applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0313</identifier>
 <datestamp>2014-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0313</id><created>2012-02-01</created><updated>2014-10-08</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>The Complexity of Computing the Sign of the Tutte Polynomial</title><categories>cs.CC math.CO</categories><comments>minor updates. This is the final version (to appear in SICOMP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of computing the sign of the Tutte polynomial of a
graph. As there are only three possible outcomes (positive, negative, and
zero), this seems at first sight more like a decision problem than a counting
problem. Surprisingly, however, there are large regions of the parameter space
for which computing the sign of the Tutte polynomial is actually #P-hard. As a
trivial consequence, approximating the polynomial is also #P-hard in this case.
Thus, approximately evaluating the Tutte polynomial in these regions is as hard
as exactly counting the satisfying assignments to a CNF Boolean formula. For
most other points in the parameter space, we show that computing the sign of
the polynomial is in FP, whereas approximating the polynomial can be done in
polynomial time with an NP oracle. As a special case, we completely resolve the
complexity of computing the sign of the chromatic polynomial - this is easily
computable at q=2 and when q is less than or equal to 32/27, and is NP-hard to
compute for all other values of the parameter q.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0314</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0314</id><created>2012-02-01</created><updated>2013-05-10</updated><authors><author><keyname>Cabello</keyname><forenames>Sergio</forenames></author><author><keyname>Chambers</keyname><forenames>Erin Wolf</forenames></author><author><keyname>Erickson</keyname><forenames>Jeff</forenames></author></authors><title>Multiple-Source Shortest Paths in Embedded Graphs</title><categories>cs.DS cs.CG</categories><comments>31 pages, 3 figures. Accepted to SIAM Journal on Computing.
  Preliminary version, without the third author's contributions, in Proceedings
  of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms, 89-97, 2007. In
  this revision we provide a careful treatment of non-generic weights</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a directed graph with n vertices and non-negative weights in its
directed edges, embedded on a surface of genus g, and let f be an arbitrary
face of G. We describe a randomized algorithm to preprocess the graph in O(gn
log n) time with high probability, so that the shortest-path distance from any
vertex on the boundary of f to any other vertex in G can be retrieved in O(log
n) time. Our result directly generalizes the O(n log n)-time algorithm of Klein
[SODA 2005] for multiple-source shortest paths in planar graphs. Intuitively,
our preprocessing algorithm maintains a shortest-path tree as its source point
moves continuously around the boundary of f. As an application of our
algorithm, we describe algorithms to compute a shortest non-contractible or
non-separating cycle in embedded, undirected graphs in O(g^2 n log n) time with
high probability. Our high-probability time bounds hold in the worst-case for
generic edge weights, or with an additional O(log n) factor for arbitrary edge
weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0319</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0319</id><created>2012-02-01</created><authors><author><keyname>Ausiello</keyname><forenames>Giorgio</forenames></author><author><keyname>Firmani</keyname><forenames>Donatella</forenames></author><author><keyname>Laura</keyname><forenames>Luigi</forenames></author></authors><title>Real-Time Monitoring of Undirected Networks: Articulation Points,
  Bridges, and Connected and Biconnected Components</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the first algorithm in the streaming model to
characterize completely the biconnectivity properties of undirected networks:
articulation points, bridges, and connected and biconnected components. The
motivation of our work was the development of a real-time algorithm to monitor
the connectivity of the Autonomous Systems (AS) Network, but the solution
provided is general enough to be applied to any network.
  The network structure is represented by a graph, and the algorithm is
analyzed in the datastream framework. Here, as in the \emph{on-line} model, the
input graph is revealed one item (i.e., graph edge) after the other, in an
on-line fashion; but, if compared to traditional on-line computation, there are
stricter requirements for both memory occupation and per item processing time.
Our algorithm works by properly updating a forest over the graph nodes. All the
graph (bi)connectivity properties are stored in this forest. We prove the
correctness of the algorithm, together with its space ($O(n\,\log n)$, with $n$
being the number of nodes in the graph) and time bounds.
  We also present the results of a brief experimental evaluation against
real-world graphs, including many samples of the AS network, ranging from
medium to massive size. These preliminary experimental results confirm the
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0322</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0322</id><created>2012-02-01</created><updated>2013-09-16</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Large deviation analysis for quantum security via smoothing of Renyi
  entropy of order 2</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>The results for the classical case have been removed. This part was
  moved to the recent paper arXiv:1309.1596</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the security evaluation can be done by smoothing of
R\'{e}nyi entropy of order 2 in the classical and quantum settings when we
apply universal$_2$ hash functions. Using the smoothing of Renyi entropy of
order 2, we derive security bounds for $L_1$ distinguishability and modified
mutual information criterion under the classical and quantum setting, and have
derived these exponential decreasing rates. These results are extended to the
case when we apply $\varepsilon$-almost dual universal$_2$ hash functions.
Further, we apply this analysis to the secret key generation with error
correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0325</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0325</id><created>2012-02-01</created><updated>2013-09-16</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Quantum wiretap channel with non-uniform random number and its exponent
  and equivocation rate of leaked information</title><categories>quant-ph cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A usual code for quantum wiretap channel requires an auxiliary random
variable subject to the perfect uniform distribution. However, it is difficult
to prepare such an auxiliary random variable. We propose a code that requires
only an auxiliary random variable subject to a non-uniform distribution instead
of the perfect uniform distribution. Further, we evaluate the exponential
decreasing rate of leaked information and derive its equivocation rate. For
practical constructions, we also discuss the security when our code consists of
a linear error correcting code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0327</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0327</id><created>2012-02-01</created><authors><author><keyname>Yu</keyname><forenames>Louis</forenames></author><author><keyname>Asur</keyname><forenames>Sitaram</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Artificial Inflation: The True Story of Trends in Sina Weibo</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>arXiv admin note: text overlap with arXiv:1107.3522</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a tremendous rise in the growth of online social networks all
over the world in recent years. This has facilitated users to generate a large
amount of real-time content at an incessant rate, all competing with each other
to attract enough attention and become trends. While Western online social
networks such as Twitter have been well studied, characteristics of the popular
Chinese microblogging network Sina Weibo have not been. In this paper, we
analyze in detail the temporal aspect of trends and trend-setters in Sina
Weibo, constrasting it with earlier observations on Twitter. First, we look at
the formation, persistence and decay of trends and examine the key topics that
trend in Sina Weibo. One of our key findings is that retweets are much more
common in Sina Weibo and contribute a lot to creating trends. When we look
closer, we observe that a large percentage of trends in Sina Weibo are due to
the continuous retweets of a small amount of fraudulent accounts. These fake
accounts are set up to artificially inflate certain posts causing them to shoot
up into Sina Weibo's trending list, which are in turn displayed as the most
popular topics to users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0331</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0331</id><created>2012-02-01</created><authors><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author></authors><title>Topological Features of Online Social Networks</title><categories>cs.SI cs.CY physics.soc-ph</categories><msc-class>91D30, 05C82, 68R10, 90B10, 90C35</msc-class><journal-ref>Communications on Applied and Industrial Mathematics, 2(2):1-20,
  2011</journal-ref><doi>10.1685/journal.caim.381</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of modeling and analyzing Social Networks is a consequence of
the success of Online Social Networks during last years. Several models of
networks have been proposed, reflecting the different characteristics of Social
Networks. Some of them fit better to model specific phenomena, such as the
growth and the evolution of the Social Networks; others are more appropriate to
capture the topological characteristics of the networks. Because these networks
show unique and different properties and features, in this work we describe and
exploit several models in order to capture the structure of popular Online
Social Networks, such as Arxiv, Facebook, Wikipedia and YouTube. Our
experimentation aims at verifying the structural characteristics of these
networks, in order to understand what model better depicts their structure, and
to analyze the inner community structure, to illustrate how members of these
Online Social Networks interact and group together into smaller communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0332</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0332</id><created>2012-02-01</created><authors><author><keyname>Bandari</keyname><forenames>Roja</forenames></author><author><keyname>Asur</keyname><forenames>Sitaram</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>The Pulse of News in Social Media: Forecasting Popularity</title><categories>cs.CY cs.NI cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  News articles are extremely time sensitive by nature. There is also intense
competition among news items to propagate as widely as possible. Hence, the
task of predicting the popularity of news items on the social web is both
interesting and challenging. Prior research has dealt with predicting eventual
online popularity based on early popularity. It is most desirable, however, to
predict the popularity of items prior to their release, fostering the
possibility of appropriate decision making to modify an article and the manner
of its publication. In this paper, we construct a multi-dimensional feature
space derived from properties of an article and evaluate the efficacy of these
features to serve as predictors of online popularity. We examine both
regression and classification algorithms and demonstrate that despite
randomness in human behavior, it is possible to predict ranges of popularity on
twitter with an overall 84% accuracy. Our study also serves to illustrate the
differences between traditionally prominent sources and those immensely popular
on the social web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0338</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0338</id><created>2012-02-01</created><authors><author><keyname>Mahdavifar</keyname><forenames>Hessam</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Algebraic List-decoding of Subspace Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subspace codes were introduced in order to correct errors and erasures for
randomized network coding, in the case where network topology is unknown (the
noncoherent case). Subspace codes are indeed collections of subspaces of a
certain vector space over a finite field. The Koetter-Kschischang construction
of subspace codes are similar to Reed-Solomon codes in that codewords are
obtained by evaluating certain (linearized) polynomials. In this paper, we
consider the problem of list-decoding the Koetter-Kschischang subspace codes.
In a sense, we are able to achieve for these codes what Sudan was able to
achieve for Reed-Solomon codes. In order to do so, we have to modify and
generalize the original Koetter-Kschischang construction in many important
respects. The end result is this: for any integer $L$, our list-$L$ decoder
guarantees successful recovery of the message subspace provided that the
normalized dimension of the error is at most $ L - \frac{L(L+1)}{2}R $ where
$R$ is the normalized packet rate. Just as in the case of Sudan's list-decoding
algorithm, this exceeds the previously best known error-correction radius
$1-R$, demonstrated by Koetter and Kschischang, for low rates $R$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0343</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0343</id><created>2012-02-01</created><authors><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>How Fast Can Dense Codes Achieve the Min-Cut Capacity of Line Networks?</title><categories>cs.IT math.IT</categories><comments>15 pages, submitted to IEEE ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the coding delay and the average coding delay of
random linear network codes (dense codes) over line networks with deterministic
regular and Poisson transmission schedules. We consider both lossless networks
and networks with Bernoulli losses. The upper bounds derived in this paper,
which are in some cases more general, and in some other cases tighter, than the
existing bounds, provide a more clear picture of the speed of convergence of
dense codes to the min-cut capacity of line networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0349</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0349</id><created>2012-02-01</created><authors><author><keyname>Romanov</keyname><forenames>Alexander M.</forenames></author></authors><title>On the admissible families of components of Hamming codes</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe the properties of the $i$-components of Hamming
codes. We suggest constructions of the admissible families of components of
Hamming codes. It is shown that every $q$-ary code of length $m$ and minimum
distance 5 (for $q = 3$ the minimum distance is 3) can be embedded in a $q$-ary
1-perfect code of length $n = (q^{m}-1)/(q-1)$. It is also shown that every
binary code of length $m + k$ and minimum distance $3k + 3$ can be embedded in
a binary 1-perfect code of length $n = 2^{m}-1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0351</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0351</id><created>2012-02-01</created><authors><author><keyname>Ma</keyname><forenames>Ying-Hong</forenames></author><author><keyname>Li</keyname><forenames>Huijia</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao-Dong</forenames></author></authors><title>The weighted tunable clustering in local-world networks with incremental
  behaviors</title><categories>physics.soc-ph cs.SI</categories><comments>21 pages, 10 figures, 39 references</comments><msc-class>05C82</msc-class><journal-ref>JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since some realistic networks are influenced not only by increment behavior
but also by tunable clustering mechanism with new nodes to be added to
networks, it is interesting to characterize the model for those actual
networks. In this paper, a weighted local-world model, which incorporates
increment behavior and tunable clustering mechanism, is proposed and its
properties are investigated, such as degree distribution and clustering
coefficient. Numerical simulations are fit to the model characters and also
display good right skewed scale-free properties. Furthermore, the correlation
of vertices in our model is studied which shows the assortative property.
Epidemic spreading process by weighted transmission rate on the model shows
that the tunable clustering behavior has a great impact on the epidemic
dynamic. Keywords: Weighted network, increment behavior, tun- able cluster,
epidemic spreading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0357</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0357</id><created>2012-02-01</created><authors><author><keyname>Xie</keyname><forenames>Yixuan</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Malaney</keyname><forenames>Robert</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author></authors><title>Channel Identification and its Impact on Quantum LDPC Code Performance</title><categories>cs.IT math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we probe the impact of channel estimation on the performance of
quantum LDPC codes. Our channel estimation is based on an optimal estimate of
the relevant decoherence parameter via its quantum Fisher information. Using
state-of-the art quantum LDPC codes designed for the quantum depolarization
channel, and utilizing various quantum probes with different entanglement
properties, we show how the performance of such codes can deteriorate by an
order of magnitude when optimal channel identification is fed into a belief
propagation decoding algorithm. Our work highlights the importance in quantum
communications of a viable channel identification campaign prior to decoding,
and highlights the trade-off between entanglement consumption and quantum LDPC
code performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0359</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0359</id><created>2012-02-01</created><authors><author><keyname>Ganesh</keyname><forenames>Vijay</forenames></author><author><keyname>Carbin</keyname><forenames>Michael</forenames></author><author><keyname>Rinard</keyname><forenames>Martin</forenames></author></authors><title>Cryptographic Path Hardening: Hiding Vulnerabilities in Software through
  Cryptography</title><categories>cs.SE cs.CR cs.PL</categories><comments>Accepted as part of Off-the-beaten track at POPL 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach to improving software security called
Cryptographic Path Hardening, which is aimed at hiding security vulnerabilities
in software from attackers through the use of provably secure and obfuscated
cryptographic devices to harden paths in programs.
  By &quot;harden&quot; we mean that certain error-checking if-conditionals in a given
program P are replaced by equivalent&quot; we mean that adversaries cannot use
semi-automatic program analysis techniques to reason about the hardened program
paths and thus cannot discover as-yet-unknown errors along those paths, except
perhaps through black-box dictionary attacks or random testing (which we can
never prevent).
  Other than these unpreventable attack methods, we can make program analysis
aimed at error-finding &quot;provably hard&quot; for a resource-bounded attacker, in the
same sense that cryptographic schemes are hard to break. Unlike
security-through-obscurity, in Cryptographic Path Hardening we use
provably-secure crypto devices to hide errors and our mathematical arguments of
security are the same as the standard ones used in cryptography.
  One application of Cryptographic Path Hardening is that software patches or
filters often reveal enough information to an attacker that they can be used to
construct error-revealing inputs to exploit an unpatched version of the
program. By &quot;hardening&quot; the patch we make it difficult for the attacker to
analyze the patched program to construct error-revealing inputs, and thus
prevent him from potentially constructing exploits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0364</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0364</id><created>2012-02-02</created><authors><author><keyname>Kloks</keyname><forenames>Ton</forenames></author></authors><title>A note on probe cographs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a graph and let N_1, ..., N_k be k independent sets in G. The graph
G is a k-probe cograph if G can be embedded into a cograph by adding edges
between vertices that are contained in the same independent set. We show that
there exists an O(k n^5) algorithm to check if a graph G is a k-probe cograph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0366</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0366</id><created>2012-02-02</created><authors><author><keyname>Noam</keyname><forenames>Yair</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Blind Null-Space Learning for MIMO Underlay Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a blind technique for MIMO cognitive radio Secondary
Users (SU) to transmit in the same band simultaneously with a Primary User (PU)
under a maximum interference constraint. In the proposed technique, the SU is
able to meet the interference constraint of the PU without explicitly
estimating the interference channel matrix to the PU and without burdening the
PU with any interaction with the SU.
  The only condition required of the PU is that for a short time interval it
uses a power control scheme such that its transmitted power is a monotonic
function of the interference inflicted by the SU. During this time interval,
the SU iteratively modifies the spatial orientation of its transmitted signal
and measures the effect of this modification on the PU's total transmit power.
The entire process is based on energy measurements which is very desirable from
an implementation point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0372</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0372</id><created>2012-02-02</created><updated>2012-05-19</updated><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author></authors><title>Analog Network Coding in General SNR Regime</title><categories>cs.IT math.IT</categories><comments>11 pages. Revised Section 2 and more accurate analysis in Section 5.
  A shorter version to appear in ISIT-2012. arXiv admin note: substantial text
  overlap with arXiv:1203.2297</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of maximum rate achievable with analog network coding for a
unicast communication over a layered wireless relay network with directed links
is considered. A relay node performing analog network coding scales and
forwards the signals received at its input. Recently this problem has been
considered under two assumptions: (A) each relay node scales its received
signal to the upper bound of its transmit power constraint, (B) the relay nodes
in specific subsets of the network operate in the high-SNR regime. We establish
that assumption (A), in general, leads to suboptimal end-to-end rate. We also
characterize the performance of analog network coding in class of symmetric
layered networks without assumption (B).
  The key contribution of this work is a lemma that states that a globally
optimal set of scaling factors for the nodes in a layered relay network that
maximizes the end-to-end rate can be computed layer-by-layer. Specifically, a
rate-optimal set of scaling factors for the nodes in a layer is the one that
maximizes the sum-rate of the nodes in the next layer. This critical insight
allows us to characterize analog network coding performance in network
scenarios beyond those that can be analyzed using the existing approaches. We
illustrate this by computing the maximum rate achievable with analog network
coding in one particular layered network, in various communication scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0401</identifier>
 <datestamp>2013-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0401</id><created>2012-02-02</created><updated>2013-01-23</updated><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author></authors><title>Bipartite graphs related to mutually disjoint S-permutation matrices</title><categories>math.CO cs.DM</categories><comments>18 pages, 13 figures. arXiv admin note: text overlap with
  arXiv:1211.1628</comments><msc-class>05C30, 05B20, 05C50</msc-class><journal-ref>ISRN Discrete Mathematics, Volume 2012, Article ID 384068</journal-ref><doi>10.5402/2012/384068</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some numerical characteristics of bipartite graphs in relation to the problem
of finding all disjoint pairs of S-permutation matrices in the general $n^2
\times n^2$ case are discussed in this paper. All bipartite graphs of the type
$g=&lt;R_g \cup C_g, E_g&gt;$, where $|R_g |=|C_g |=2$ or $|R_g |=|C_g |=3$ are
provided. The cardinality of the sets of mutually disjoint S-permutation
matrices in both the $4 \times 4$ and $9 \times 9$ cases are calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0404</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0404</id><created>2012-02-02</created><authors><author><keyname>Lungu</keyname><forenames>Eliza-Olivia</forenames></author><author><keyname>Zamfir</keyname><forenames>Ana-Maria</forenames></author><author><keyname>Militaru</keyname><forenames>Eva</forenames></author><author><keyname>Mocanu</keyname><forenames>Cristina</forenames></author></authors><title>Occupational mobility network of the Romanian higher education graduates</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although there is a rich literature on the rate of occupational mobility,
there are important gaps in understanding patterns of movement among
occupations. We employ a network based approach to explore occupational
mobility of the Romanian university graduates in the first years after
graduation (2003 - 2008). We use survey data on their career mobility to build
an empirical occupational mobility network (OMN) that covers all their job
movements in the considered period. We construct the network as directed and
weighted. The nodes are represented by the occupations (post coded at 3 digits
according to ISCO-88) and the links are weighted with the number of persons
switching from one occupation to another. This representation of data permits
us to use the novel statistical techniques developed in the framework of
weighted directed networks in order to extract a set of stylized facts that
highlight patterns of occupational mobility: centrality, network motifs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0414</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0414</id><created>2012-02-02</created><authors><author><keyname>Sbeity</keyname><forenames>Ihab</forenames></author><author><keyname>Brenner</keyname><forenames>Leonardo</forenames></author><author><keyname>Dbouk</keyname><forenames>Mohamed</forenames></author></authors><title>Generating a Performance Stochastic Model from UML Specifications</title><categories>cs.SE cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its initiation by Connie Smith, the process of Software Performance
Engineering (SPE) is becoming a growing concern. The idea is to bring
performance evaluation into the software design process. This suitable
methodology allows software designers to determine the performance of software
during design. Several approaches have been proposed to provide such
techniques. Some of them propose to derive from a UML (Unified Modeling
Language) model a performance model such as Stochastic Petri Net (SPN) or
Stochastic process Algebra (SPA) models. Our work belongs to the same category.
We propose to derive from a UML model a Stochastic Automata Network (SAN) in
order to obtain performance predictions. Our approach is more flexible due to
the SAN modularity and its high resemblance to UML' state-chart diagram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0417</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0417</id><created>2012-02-02</created><updated>2013-03-20</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Universal communication part II: channels with memory</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider communication over a channel whose probabilistic model is completely
unknown vector-wise and is not assumed to be stationary. Communication over
such channels is challenging because knowing the past does not indicate
anything about the future. The existence of reliable feedback and common
randomness is assumed. In a previous paper it was shown that the Shannon
capacity cannot be attained, in general, if the channel is not known. An
alternative notion of &quot;capacity&quot; was defined, as the maximum rate of reliable
communication by any block-coding system used over consecutive blocks. This
rate was shown to be achievable for the modulo-additive channel with an
individual, unknown noise sequence, and not achievable for some channels with
memory. In this paper this &quot;capacity&quot; is shown to be achievable for general
channel models possibly including memory, as long as this memory fades with
time. In other words, there exists a system with feedback and common randomness
that, without knowledge of the channel, asymptotically performs as well as any
block code, which may be designed knowing the channel. For non-fading memory
channels a weaker type of &quot;capacity&quot; is shown to be achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0425</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0425</id><created>2012-02-02</created><authors><author><keyname>Esquivel</keyname><forenames>Alcides Viamontes</forenames></author><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author></authors><title>Comparing network covers using mutual information</title><categories>math-ph cs.IT math.IT math.MP physics.data-an</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In network science, researchers often use mutual information to understand
the difference between network partitions produced by community detection
methods. Here we extend the use of mutual information to covers, that is, the
cases where a node can belong to more than one module. In our proposed
solution, the underlying stochastic process used to compare partitions is
extended to deal with covers, and the random variables of the new process are
simply fed into the usual definition of mutual information. With partitions,
our extended process behaves exactly as the conventional approach for
partitions, and thus, the mutual information values obtained are the same. We
also describe how to perform sampling and do error estimation for our extended
process, as both are necessary steps for a practical application of this
measure. The stochastic process that we define here is not only applicable to
networks, but can also be used to compare more general set-to-set binary
relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0436</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0436</id><created>2012-02-02</created><updated>2012-03-29</updated><authors><author><keyname>Diaz</keyname><forenames>Josep</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author><author><keyname>Serna</keyname><forenames>Maria</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>On the Fixation Probability of Superstars</title><categories>cs.CE cs.SI q-bio.PE</categories><comments>Technical content remains the same but we have revised our
  interpretation of the experimental data and changed the title accordingly. We
  have included, as ancillary files, our c code (superstar.c) and also
  documentation demonstrating its correctness (superstarfixprob-ancillary.pdf):
  download the paper source package to view these</comments><journal-ref>Proceedings of the Royal Society A vol 469 no 2156 paper 20130193,
  2013</journal-ref><doi>10.1098/rspa.2013.0193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Moran process models the spread of genetic mutations through a
population. A mutant with relative fitness $r$ is introduced into a population
and the system evolves, either reaching fixation (in which every individual is
a mutant) or extinction (in which none is). In a widely cited paper (Nature,
2005), Lieberman, Hauert and Nowak generalize the model to populations on the
vertices of graphs. They describe a class of graphs (called &quot;superstars&quot;), with
a parameter $k$. Superstars are designed to have an increasing fixation
probability as $k$ increases. They state that the probability of fixation tends
to $1-r^{-k}$ as graphs get larger but we show that this claim is untrue as
stated. Specifically, for $k=5$, we show that the true fixation probability (in
the limit, as graphs get larger) is at most $1-1/j(r)$ where
$j(r)=\Theta(r^4)$, contrary to the claimed result. We do believe that the
qualitative claim of Lieberman et al.\ --- that the fixation probability of
superstars tends to 1 as $k$ increases --- is correct, and that it can probably
be proved along the lines of their sketch. We were able to run larger computer
simulations than the ones presented in their paper. However, simulations on
graphs of around 40,000 vertices do not support their claim. Perhaps these
graphs are too small to exhibit the limiting behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0440</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0440</id><created>2012-02-02</created><authors><author><keyname>Hoffmann</keyname><forenames>Matej</forenames></author><author><keyname>Pfeifer</keyname><forenames>Rolf</forenames></author></authors><title>The implications of embodiment for behavior and cognition: animal and
  robotic case studies</title><categories>cs.AI</categories><comments>Book chapter in W. Tschacher &amp; C. Bergomi, ed., 'The Implications of
  Embodiment: Cognition and Communication', Exeter: Imprint Academic, pp. 31-58</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will argue that if we want to understand the function of
the brain (or the control in the case of robots), we must understand how the
brain is embedded into the physical system, and how the organism interacts with
the real world. While embodiment has often been used in its trivial meaning,
i.e. 'intelligence requires a body', the concept has deeper and more important
implications, concerned with the relation between physical and information
(neural, control) processes. A number of case studies are presented to
illustrate the concept. These involve animals and robots and are concentrated
around locomotion, grasping, and visual perception. A theoretical scheme that
can be used to embed the diverse case studies will be presented. Finally, we
will establish a link between the low-level sensory-motor processes and
cognition. We will present an embodied view on categorization, and propose the
concepts of 'body schema' and 'forward models' as a natural extension of the
embodied approach toward first representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0445</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0445</id><created>2012-02-02</created><authors><author><keyname>Zhu</keyname><forenames>Yang</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Iterative Mode-Dropping for the Sum Capacity of MIMO-MAC with
  Per-Antenna Power Constraint</title><categories>cs.IT math.IT</categories><comments>6 pages double-column, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an iterative mode-dropping algorithm that optimizes input signals
to achieve the sum capacity of the MIMO-MAC with per-antenna power constraint.
The algorithm successively optimizes each user's input covariance matrix by
applying mode-dropping to the equivalent single-user MIMO rate maximization
problem. Both analysis and simulation show fast convergence. We then use the
algorithm to briefly highlight the difference in MIMO-MAC capacities under sum
and per-antenna power constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0452</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0452</id><created>2012-02-02</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Game Theoretic Methods for the Smart Grid</title><categories>cs.IT cs.GT cs.NI math.IT</categories><comments>IEEE Signal Processing Magazine, Special Issue on Signal Processing
  Techniques for the Smart Grid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future smart grid is envisioned as a large-scale cyber-physical system
encompassing advanced power, communications, control, and computing
technologies. In order to accommodate these technologies, it will have to build
on solid mathematical tools that can ensure an efficient and robust operation
of such heterogeneous and large-scale cyber-physical systems. In this context,
this paper is an overview on the potential of applying game theory for
addressing relevant and timely open problems in three emerging areas that
pertain to the smart grid: micro-grid systems, demand-side management, and
communications. In each area, the state-of-the-art contributions are gathered
and a systematic treatment, using game theory, of some of the most relevant
problems for future power systems is provided. Future opportunities for
adopting game theoretic methodologies in the transition from legacy systems
toward smart and intelligent grids are also discussed. In a nutshell, this
article provides a comprehensive account of the application of game theory in
smart grid systems tailored to the interdisciplinary characteristics of these
systems that integrate components from power systems, networking,
communications, and control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0453</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0453</id><created>2012-02-02</created><authors><author><keyname>Beelen</keyname><forenames>Peter</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>Bounding the number of points on a curve using a generalization of
  Weierstrass semigroups</title><categories>math.AG cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we use techniques from coding theory to derive upper bounds
for the number of rational places of the function field of an algebraic curve
defined over a finite field. The used techniques yield upper bounds if the
(generalized) Weierstrass semigroup [P. Beelen, N. Tuta\c{s}: A generalization
of the Weierstrass semigroup, J. Pure Appl. Algebra, 207(2), 2006] for an
$n$-tuple of places is known, even if the exact defining equation of the curve
is not known. As shown in examples, this sometimes enables one to get an upper
bound for the number of rational places for families of function fields. Our
results extend results in [O. Geil, R. Matsumoto: Bounding the number of
$\mathbb{F}_q$-rational places in algebraic function fields using Weierstrass
semigroups. Pure Appl. Algebra, 213(6), 2009].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0455</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0455</id><created>2012-02-02</created><authors><author><keyname>Haimovich</keyname><forenames>Hernan</forenames></author><author><keyname>Seron</keyname><forenames>Maria M.</forenames></author></authors><title>Bounds and Invariant Sets for a Class of Switching Systems with
  Delayed-state-dependent Perturbations</title><categories>cs.SY math.OC</categories><comments>Submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method to compute componentwise transient bounds, ultimate
bounds, and invariant regions for a class of switching continuous-time linear
systems with perturbation bounds that may depend nonlinearly on a delayed
state. The main advantage of the method is its componentwise nature, i.e. the
fact that it allows each component of the perturbation vector to have an
independent bound and that the bounds and sets obtained are also given
componentwise. This componentwise method does not employ a norm for bounding
either the perturbation or state vectors, avoids the need for scaling the
different state vector components in order to obtain useful results, and may
also reduce conservativeness in some cases. We give conditions for the derived
bounds to be of local or semi-global nature. In addition, we deal with the case
of perturbation bounds whose dependence on a delayed state is of affine form as
a particular case of nonlinear dependence for which the bounds derived are
shown to be globally valid. A sufficient condition for practical stability is
also provided. The present paper builds upon and extends to switching systems
with delayed-state-dependent perturbations previous results by the authors. In
this sense, the contribution is three-fold: the derivation of the
aforementioned extension; the elucidation of the precise relationship between
the class of switching linear systems to which the proposed method can be
applied and those that admit a common quadratic Lyapunov function (a question
that was left open in our previous work); and the derivation of a technique to
compute a common quadratic Lyapunov function for switching linear systems with
perturbations bounded componentwise by affine functions of the absolute value
of the state vector components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0457</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0457</id><created>2012-02-02</created><authors><author><keyname>Scouarnec</keyname><forenames>Nicolas Le</forenames></author></authors><title>Exact Scalar Minimum Storage Coordinated Regenerating Codes</title><categories>cs.IT cs.DC math.IT</categories><comments>9 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the exact and optimal repair of multiple failures in codes for
distributed storage. More particularly, we examine the use of interference
alignment to build exact scalar minimum storage coordinated regenerating codes
(MSCR). We show that it is possible to build codes for the case of k = 2 and d
&gt; k by aligning interferences independently but that this technique cannot be
applied as soon as k &gt; 2 and d &gt; k. Our results also apply to adaptive
regenerating codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0460</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0460</id><created>2012-02-02</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author><author><keyname>Song</keyname><forenames>Ju Bin</forenames></author></authors><title>A Cooperative Bayesian Nonparametric Framework for Primary User Activity
  Monitoring in Cognitive Radio Network</title><categories>cs.IT cs.GT math.IT</categories><comments>IEEE Journal on Selected Areas in Communications (JSAC), to appear,
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel approach that enables a number of cognitive
radio devices that are observing the availability pattern of a number of
primary users(PUs), to cooperate and use \emph{Bayesian nonparametric}
techniques to estimate the distributions of the PUs' activity pattern, assumed
to be completely unknown. In the proposed model, each cognitive node may have
its own individual view on each PU's distribution, and, hence, seeks to find
partners having a correlated perception. To address this problem, a coalitional
game is formulated between the cognitive devices and an algorithm for
cooperative coalition formation is proposed. It is shown that the proposed
coalition formation algorithm allows the cognitive nodes that are experiencing
a similar behavior from some PUs to self-organize into disjoint, independent
coalitions. Inside each coalition, the cooperative cognitive nodes use a
combination of Bayesian nonparametric models such as the Dirichlet process and
statistical goodness of fit techniques in order to improve the accuracy of the
estimated PUs' activity distributions. Simulation results show that the
proposed algorithm significantly improves the estimates of the PUs'
distributions and yields a performance advantage, in terms of reduction of the
average achieved Kullback-Leibler distance between the real and the estimated
distributions, reaching up to 36.5% relative the non-cooperative estimates. The
results also show that the proposed algorithm enables the cognitive nodes to
adapt their cooperative decisions when the actual PUs' distributions change due
to, for example, PU mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0463</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0463</id><created>2012-02-02</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Network Formation Games Among Relay Stations in Next Generation Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Communications, vol. 59, no. 9, pp. 2528-2542,
  September 2011</comments><journal-ref>IEEE Transactions on Communications, vol. 59, no. 9, pp.
  2528-2542, September 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The introduction of relay station (RS) nodes is a key feature in next
generation wireless networks such as 3GPP's long term evolution advanced
(LTE-Advanced), or the forthcoming IEEE 802.16j WiMAX standard. This paper
presents, using game theory, a novel approach for the formation of the tree
architecture that connects the RSs and their serving base station in the
\emph{uplink} of the next generation wireless multi-hop systems. Unlike
existing literature which mainly focused on performance analysis, we propose a
distributed algorithm for studying the \emph{structure} and \emph{dynamics} of
the network. We formulate a network formation game among the RSs whereby each
RS aims to maximize a cross-layer utility function that takes into account the
benefit from cooperative transmission, in terms of reduced bit error rate, and
the costs in terms of the delay due to multi-hop transmission. For forming the
tree structure, a distributed myopic algorithm is devised. Using the proposed
algorithm, each RS can individually select the path that connects it to the BS
through other RSs while optimizing its utility. We show the convergence of the
algorithm into a Nash tree network, and we study how the RSs can adapt the
network's topology to environmental changes such as mobility or the deployment
of new mobile stations. Simulation results show that the proposed algorithm
presents significant gains in terms of average utility per mobile station which
is at least 17.1% better relatively to the case with no RSs and reaches up to
40.3% improvement compared to a nearest neighbor algorithm (for a network with
10 RSs). The results also show that the average number of hops does not exceed
3 even for a network with up to 25 RSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0467</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0467</id><created>2012-02-02</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Coalitional Games in Partition Form for Joint Spectrum Sensing and
  Access in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>IEEE Journal on Selected Topics in Signal Processing (JSTSP), Special
  Issue on Game Theory, to appear, 2012</comments><doi>10.1109/JSTSP.2011.2175699</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlicensed secondary users (SUs) in cognitive radio networks are subject to
an inherent tradeoff between spectrum sensing and spectrum access. Although
each SU has an incentive to sense the primary user (PU) channels for locating
spectrum holes, this exploration of the spectrum can come at the expense of a
shorter transmission time, and, hence, a possibly smaller capacity for data
transmission. This paper investigates the impact of this tradeoff on the
cooperative strategies of a network of SUs that seek to cooperate in order to
improve their view of the spectrum (sensing), reduce the possibility of
interference among each other, and improve their transmission capacity
(access). The problem is modeled as a coalitional game in partition form and an
algorithm for coalition formation is proposed. Using the proposed algorithm,
the SUs can make individual distributed decisions to join or leave a coalition
while maximizing their utilities which capture the average time spent for
sensing as well as the capacity achieved while accessing the spectrum. It is
shown that, by using the proposed algorithm, the SUs can self-organize into a
network partition composed of disjoint coalitions, with the members of each
coalition cooperating to jointly optimize their sensing and access performance.
Simulation results show the performance improvement that the proposed algorithm
yields with respect to the non-cooperative case. The results also show how the
algorithm allows the SUs to self-adapt to changes in the environment such as
the change in the traffic of the PUs, or slow mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0474</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0474</id><created>2012-02-02</created><updated>2012-02-07</updated><authors><author><keyname>Kelly</keyname><forenames>Philip</forenames></author><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Relational Semantics for Databases and Predicate Calculus</title><categories>cs.DB cs.LO</categories><comments>18 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:cs/0607039</comments><report-no>University of Victoria Department of Computer Science report number
  DCS-343-IR</report-no><acm-class>F.4.1; H.2.1; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relational data model requires a theory of relations in which tuples are
not only many-sorted, but can also have indexes that are not necessarily
numerical. In this paper we develop such a theory and define operations on
relations that are adequate for database use. The operations are similar to
those of Codd's relational algebra, but differ in being based on a
mathematically adequate theory of relations. The semantics of predicate
calculus, being oriented toward the concept of satisfiability, is not suitable
for relational databases. We develop an alternative semantics that assigns
relations as meaning to formulas with free variables. This semantics makes the
classical predicate calculus suitable as a query language for relational
databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0477</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0477</id><created>2012-02-02</created><authors><author><keyname>Wang</keyname><forenames>Kehao</forenames></author><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Liu</keyname><forenames>Quan</forenames></author><author><keyname>Agha</keyname><forenames>Khaldoun Al</forenames></author></authors><title>On Optimality of Myopic Sensing Policy with Imperfect Sensing in
  Multi-channel Opportunistic Access</title><categories>cs.NI</categories><comments>21 pages regular paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the channel access problem under imperfect sensing of channel
state in a multi-channel opportunistic communication system, where the state of
each channel evolves as an independent and identically distributed Markov
process. The considered problem can be cast into a restless multi-armed bandit
(RMAB) problem that is of fundamental importance in decision theory. It is
well-known that solving the RMAB problem is PSPACE-hard, with the optimal
policy usually intractable due to the exponential computation complexity. A
natural alternative is to consider the easily implementable myopic policy that
maximizes the immediate reward but ignores the impact of the current strategy
on the future reward. In this paper, we perform an analytical study on the
optimality of the myopic policy under imperfect sensing for the considered RMAB
problem. Specifically, for a family of generic and practically important
utility functions, we establish the closed-form conditions under which the
myopic policy is guaranteed to be optimal even under imperfect sensing. Despite
our focus on the opportunistic channel access, the obtained results are generic
in nature and are widely applicable in a wide range of engineering domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0480</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0480</id><created>2012-02-02</created><authors><author><keyname>Yan</keyname><forenames>Bowen</forenames></author><author><keyname>Gregory</keyname><forenames>Steve</forenames></author></authors><title>Detecting Communities in Networks by Merging Cliques</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 7 figures</comments><journal-ref>2009 IEEE International Conference on Intelligent Computing and
  Intelligent Systems (ICIS 2009), pp. 832--836</journal-ref><doi>10.1109/ICICISYS.2009.5358036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many algorithms have been proposed for detecting disjoint communities
(relatively densely connected subgraphs) in networks. One popular technique is
to optimize modularity, a measure of the quality of a partition in terms of the
number of intracommunity and intercommunity edges. Greedy approximate
algorithms for maximizing modularity can be very fast and effective. We propose
a new algorithm that starts by detecting disjoint cliques and then merges these
to optimize modularity. We show that this performs better than other similar
algorithms in terms of both modularity and execution speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0492</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0492</id><created>2012-02-02</created><updated>2012-03-02</updated><authors><author><keyname>Abeles</keyname><forenames>Peter</forenames></author></authors><title>Resolving Implementation Ambiguity and Improving SURF</title><categories>cs.CV</categories><comments>Fixed incorrect contact information contained in previous version and
  clarified publication information. Additional small changes for grammar and
  clarity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speeded Up Robust Features (SURF) has emerged as one of the more popular
feature descriptors and detectors in recent years. Performance and algorithmic
details vary widely between implementations due to SURF's complexity and
ambiguities found in its description. To resolve these ambiguities, a set of
general techniques for feature stability is defined based on the smoothness
rule. Additional improvements to SURF are proposed for speed and stability. To
illustrate the importance of these implementation details, a performance study
of popular SURF implementations is done. By utilizing all the suggested
improvements, it is possible to create a SURF implementation that is several
times faster and more stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0500</identifier>
 <datestamp>2014-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0500</id><created>2012-02-02</created><updated>2014-10-01</updated><authors><author><keyname>Salganik</keyname><forenames>Matthew J.</forenames></author><author><keyname>Levy</keyname><forenames>Karen E. C.</forenames></author></authors><title>Wiki surveys: Open and quantifiable social data collection</title><categories>stat.AP cs.CY</categories><comments>24 pages, 8 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the social sciences, there is a longstanding tension between data
collection methods that facilitate quantification and those that are open to
unanticipated information. Advances in technology now enable new, hybrid
methods that combine some of the benefits of both approaches. Drawing
inspiration from online information aggregation systems like Wikipedia and from
traditional survey research, we propose a new class of research instruments
called wiki surveys. Just as Wikipedia evolves over time based on contributions
from participants, we envision an evolving survey driven by contributions from
respondents. We develop three general principles that underlie wiki surveys:
they should be greedy, collaborative, and adaptive. Building on these
principles, we develop methods for data collection and data analysis for one
type of wiki survey, a pairwise wiki survey. Using two proof-of-concept case
studies involving our free and open-source website www.allourideas.org, we show
that pairwise wiki surveys can yield insights that would be difficult to obtain
with other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0501</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0501</id><created>2012-02-02</created><authors><author><keyname>Lahti</keyname><forenames>Leo</forenames></author><author><keyname>Knuuttila</keyname><forenames>Juha E. A.</forenames></author><author><keyname>Kaski</keyname><forenames>Samuel</forenames></author></authors><title>Global modeling of transcriptional responses in interaction networks</title><categories>q-bio.MN cs.CE q-bio.QM stat.AP stat.ML</categories><comments>19 pages, 13 figures</comments><journal-ref>Global modeling of transcriptional responses in interaction
  networks. Leo Lahti, Juha E.A. Knuuttila, and Samuel Kaski. Bioinformatics
  26(21):2713-2720, 2010</journal-ref><doi>10.1093/bioinformatics/btq500</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Motivation: Cell-biological processes are regulated through a complex network
of interactions between genes and their products. The processes, their
activating conditions, and the associated transcriptional responses are often
unknown. Organism-wide modeling of network activation can reveal unique and
shared mechanisms between physiological conditions, and potentially as yet
unknown processes. We introduce a novel approach for organism-wide discovery
and analysis of transcriptional responses in interaction networks. The method
searches for local, connected regions in a network that exhibit coordinated
transcriptional response in a subset of conditions. Known interactions between
genes are used to limit the search space and to guide the analysis. Validation
on a human pathway network reveals physiologically coherent responses,
functional relatedness between physiological conditions, and coordinated,
context-specific regulation of the genes. Availability: Implementation is
freely available in R and Matlab at http://netpro.r-forge.r-project.org
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0515</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0515</id><created>2012-02-02</created><updated>2013-08-21</updated><authors><author><keyname>Yamada</keyname><forenames>Makoto</forenames></author><author><keyname>Jitkrittum</keyname><forenames>Wittawat</forenames></author><author><keyname>Sigal</keyname><forenames>Leonid</forenames></author><author><keyname>Xing</keyname><forenames>Eric P.</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author></authors><title>High-Dimensional Feature Selection by Feature-Wise Non-Linear Lasso</title><categories>stat.ML cs.AI stat.ME</categories><comments>18 pages. To appear in Neural Computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of supervised feature selection is to find a subset of input
features that are responsible for predicting output values. The least absolute
shrinkage and selection operator (Lasso) allows computationally efficient
feature selection based on linear dependency between input features and output
values. In this paper, we consider a feature-wise kernelized Lasso for
capturing non-linear input-output dependency. We first show that, with
particular choices of kernel functions, non-redundant features with strong
statistical dependence on output values can be found in terms of kernel-based
independence measures. We then show that the globally optimal solution can be
efficiently computed; this makes the approach scalable to high-dimensional
problems. The effectiveness of the proposed method is demonstrated through
feature selection experiments with thousands of features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0518</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0518</id><created>2012-02-02</created><updated>2012-05-01</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Tan</keyname><forenames>Si-Hui</forenames></author><author><keyname>Lloyd</keyname><forenames>Seth</forenames></author></authors><title>Explicit capacity-achieving receivers for optical communication and
  quantum reading</title><categories>quant-ph cs.IT math.IT</categories><comments>7 pages, submission to the 2012 International Symposium on
  Information Theory (ISIT 2012), Boston, MA, USA; v2: Accepted</comments><journal-ref>Proceedings of the 2012 IEEE International Symposium on
  Information Theory (ISIT 2012, Cambridge, MA, USA), pages 551-555</journal-ref><doi>10.1109/ISIT.2012.6284251</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important practical open question has been to design explicit, structured
optical receivers that achieve the Holevo limit in the contexts of optical
communication and &quot;quantum reading.&quot; The Holevo limit is an achievable rate
that is higher than the Shannon limit of any known optical receiver. We
demonstrate how a sequential decoding approach can achieve the Holevo limit for
both of these settings. A crucial part of our scheme for both settings is a
non-destructive &quot;vacuum-or-not&quot; measurement that projects an n-symbol modulated
codeword onto the n-fold vacuum state or its orthogonal complement, such that
the post-measurement state is either the n-fold vacuum or has the vacuum
removed from the support of the n symbols' joint quantum state. The sequential
decoder for optical communication requires the additional ability to perform
multimode optical phase-space displacements---realizable using a beamsplitter
and a laser, while the sequential decoder for quantum reading also requires the
ability to perform phase-shifting (realizable using a phase plate) and online
squeezing (a phase-sensitive amplifier).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0521</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0521</id><created>2012-02-02</created><updated>2012-02-05</updated><authors><author><keyname>Hagiwara</keyname><forenames>Manabu</forenames></author></authors><title>On ML-Certificate Linear Constraints for Rank Modulation with Linear
  Programming Decoding and its Application to Compact Graphs</title><categories>math.CO cs.IT math.IT</categories><comments>Submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear constraints for a matrix polytope with no fractional vertex are
investigated as intersecting research among permutation codes, rank
modulations, and linear programming methods. By focusing the discussion to the
block structure of matrices, new classes of such polytopes are obtained from
known small polytopes. This concept, called &quot;consolidation&quot;, is applied to find
a new compact graph which is known as an approach for the graph isomorphism
problem. Encoding and decoding algorithms for our new permutation codes are
obtained from existing algorithms for small polytopes. The minimum distances
associated with Kendall-tau distance and the minimum Euclidean distance of a
code obtained by changing the basis of a permutation code may be larger than
the original one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0533</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0533</id><created>2012-02-02</created><updated>2012-05-22</updated><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Polar coding to achieve the Holevo capacity of a pure-loss optical
  channel</title><categories>cs.IT math.IT quant-ph</categories><comments>5 pages, submission to the 2012 International Symposium on
  Information Theory (ISIT 2012), Boston, MA, USA; v2 accepted to ISIT 2012</comments><journal-ref>Proceedings of the 2012 IEEE International Symposium on
  Information Theory (ISIT 2012), pages 546-550, Cambridge, MA, USA</journal-ref><doi>10.1109/ISIT.2012.6284250</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the low-energy high-energy-efficiency regime of classical optical
communications---relevant to deep-space optical channels---there is a big gap
between reliable communication rates achievable via conventional optical
receivers and the ultimate (Holevo) capacity. Achieving the Holevo capacity
requires not only optimal codes but also receivers that make collective
measurements on long (modulated) codeword waveforms, and it is impossible to
implement these collective measurements via symbol-by-symbol detection along
with classical postprocessing. Here, we apply our recent results on the
classical-quantum polar code---the first near-explicit, linear,
symmetric-Holevo-rate achieving code---to the lossy optical channel, and we
show that it almost closes the entire gap to the Holevo capacity in the low
photon number regime. In contrast, Arikan's original polar codes, applied to
the DMC induced by the physical optical channel paired with any conceivable
structured optical receiver (including optical homodyne, heterodyne, or
direct-detection) fails to achieve the ultimate Holevo limit to channel
capacity. However, our polar code construction (which uses the quantum fidelity
as a channel parameter rather than the classical Bhattacharyya quantity to
choose the &quot;good channels&quot; in the polar-code construction), paired with a
quantum successive-cancellation receiver---which involves a sequence of
collective non-destructive binary projective measurements on the joint quantum
state of the received codeword waveform---can attain the Holevo limit, and can
hence in principle achieve higher rates than Arikan's polar code and decoder
directly applied to the optical channel. However, even a theoretical recipe for
construction of an optical realization of the quantum successive-cancellation
receiver remains an open question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0534</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0534</id><created>2012-02-02</created><authors><author><keyname>Forney,</keyname><forenames>G. David</forenames><suffix>Jr.</suffix></author><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author></authors><title>Observability, Controllability and Local Reducibility of Linear Codes on
  Graphs</title><categories>cs.IT cs.SY math.IT</categories><comments>5 pages; submitted to the 2012 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the local reducibility properties of linear
realizations of codes on finite graphs.
  Trimness and properness are dual properties of constraint codes. A linear
realization is locally reducible if any constraint code is not both trim and
proper. On a finite cycle-free graph, a linear realization is minimal if and
only if every constraint code is both trim and proper.
  A linear realization is called observable if it is one-to-one, and
controllable if all constraints are independent. Observability and
controllability are dual properties. An unobservable or uncontrollable
realization is locally reducible. A parity-check realization is uncontrollable
if and only if it has redundant parity checks. A tail-biting trellis
realization is uncontrollable if and only if its trajectories partition into
disconnected subrealizations. General graphical realizations do not share this
property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0535</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0535</id><created>2012-02-02</created><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Narayanan</keyname><forenames>Srivatsan</forenames></author><author><keyname>Wang</keyname><forenames>Carol</forenames></author></authors><title>List decoding subspace codes from insertions and deletions</title><categories>cs.IT cs.CC math.IT</categories><comments>13 pages. A conference version appeared at ITCS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a construction of subspace codes along with an efficient algorithm
for list decoding from both insertions and deletions, handling an
information-theoretically maximum fraction of these with polynomially small
rate. Our construction is based on a variant of the folded Reed-Solomon codes
in the world of linearized polynomials, and the algorithm is inspired by the
recent linear-algebraic approach to list decoding. Ours is the first list
decoding algorithm for subspace codes that can handle deletions; even one
deletion can totally distort the structure of the basis of a subspace and is
thus challenging to handle. When there are only insertions, we also present
results for list decoding subspace codes that are the linearized analog of
Reed-Solomon codes (proposed previously, and closely related to the Gabidulin
codes for rank-metric), obtaining some improvements over similar results in
previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0536</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0536</id><created>2012-02-02</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>An Outer Bound for the Vector Gaussian CEO Problem</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, Feb. 2012. A
  shorter version submitted to IEEE International Symposium on Information
  Theory, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the vector Gaussian CEO problem, where there are an arbitrary number
of agents each having a noisy observation of a vector Gaussian source. The goal
of the agents is to describe the source to a central unit, which wants to
reconstruct the source within a given distortion. The rate-distortion region of
the vector Gaussian CEO problem is unknown in general. Here, we provide an
outer bound for the rate-distortion region of the vector Gaussian CEO problem.
We obtain our outer bound by evaluating an outer bound for the multi-terminal
source coding problem by means of a technique relying on the de Bruijn identity
and the properties of the Fisher information. Next, we show that our outer
bound strictly improves upon the existing outer bounds for all system
parameters. We show this strict improvement by providing a specific example,
and showing that there exists a gap between our outer bound and the existing
outer bounds. Although our outer bound improves upon the existing outer bounds,
we show that our outer bound does not provide the exact rate-distortion region
in general. To this end, we provide an example and show that the
rate-distortion region is strictly contained in our outer bound for this
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0549</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0549</id><created>2012-01-29</created><authors><author><keyname>Thakur</keyname><forenames>Gautam S.</forenames></author><author><keyname>Ali</keyname><forenames>Mohsen</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>Comparing Background Subtraction Algorithms and Method of Car Counting</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we compare various image background subtraction algorithms
with the ground truth of cars counted. We have given a sample of thousand
images, which are the snap shots of current traffic as records at various
intersections and highways. We have also counted an approximate number of cars
that are visible in these images. In order to ascertain the accuracy of
algorithms to be used for the processing of million images, we compare them on
many metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0567</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0567</id><created>2012-02-02</created><authors><author><keyname>Kieffer</keyname><forenames>Steven A.</forenames></author></authors><title>ProofFlow: Flow Diagrams for Proofs</title><categories>cs.DL</categories><comments>15 pages, 2 figures</comments><acm-class>I.7.2; H.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a light formalism for proofs that encodes their inferential
structure, along with a system that transforms these representations into
flow-chart diagrams. Such diagrams should improve the comprehensibility of
proofs. We discuss language syntax, diagram semantics, and our goal of building
a repository of diagrammatic representations of proofs from canonical
mathematical literature. The repository will be available online in the form of
a wiki at proofflow.org, where the flow chart drawing software will be
deployable through the wiki editor. We also consider the possibility of a
semantic tagging of the assertions in a proof, to permit data mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0568</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0568</id><created>2012-02-02</created><updated>2012-05-04</updated><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author><author><keyname>Freitas</keyname><forenames>Robert A.</forenames><suffix>Jr</suffix></author></authors><title>Acoustic Communication for Medical Nanorobots</title><categories>cs.RO physics.bio-ph physics.med-ph</categories><comments>added discussion of communication channel capacity in section 7</comments><journal-ref>Nano Communication Networks 3:83-102 (2012)</journal-ref><doi>10.1016/j.nancom.2012.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication among microscopic robots (nanorobots) can coordinate their
activities for biomedical tasks. The feasibility of in vivo ultrasonic
communication is evaluated for micron-size robots broadcasting into various
types of tissues. Frequencies between 10MHz and 300MHz give the best tradeoff
between efficient acoustic generation and attenuation for communication over
distances of about 100 microns. Based on these results, we find power available
from ambient oxygen and glucose in the bloodstream can readily support
communication rates of about 10,000 bits/second between micron-sized robots. We
discuss techniques, such as directional acoustic beams, that can increase this
rate. The acoustic pressure fields enabling this communication are unlikely to
damage nearby tissue, and short bursts at considerably higher power could be of
therapeutic use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0569</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0569</id><created>2012-02-02</created><updated>2012-02-07</updated><authors><author><keyname>Souza</keyname><forenames>Alexander</forenames></author></authors><title>A Constructive Proof of the Cycle Double Cover Conjecture</title><categories>cs.DM cs.DS math.CO</categories><comments>Due to a flaw in Lemma 9, the paper has been withdrawn</comments><acm-class>G.2.2; G.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cycle double cover conjecture states that a graph is bridge-free if and
only if there is a family of edge-simple cycles such that each edge is
contained in exactly two of them. It was formulated independently by Szekeres
(1973) and Seymour (1979). In this paper, we settle the conjecture in the
affirmative. In particular, we give an algorithm, which inductively constructs
a cycle double cover in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0582</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0582</id><created>2012-02-02</created><authors><author><keyname>Hosseinabadi</keyname><forenames>Ghazale</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Token-DCF: An Opportunistic MAC protocol for Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IEEE 802.11 DCF is the MAC protocol currently used in wireless LANs. 802.11
DCF is inefficient due to two types of overhead; channel idle time and
collision time. This paper presents the design and performance evaluation of an
efficient MAC protocol for wireless networks, called Token-DCF. Token-DCF
decreases both idle time and collision time. In Token-DCF, each station keeps
track of neighboring links' queue length by overhearing of transmitted packets
on the wireless medium. The result is then used to assign privileges to the
network stations. A privileged station does not follow the backoff mechanism
and transmits immediately after the channel is sensed idle. Our simulation
results show that Token-DCF can significantly improve channel utilization,
system throughput and channel access delay over 802.11 DCF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0589</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0589</id><created>2012-02-02</created><authors><author><keyname>Zakhour</keyname><forenames>Randa</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen V.</forenames></author></authors><title>Min-max fair coordinated beamforming in cellular systems via large
  systems analysis</title><categories>cs.IT math.IT</categories><comments>22 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers base station (BS) cooperation in the form of coordinated
beamforming, focusing on min-max fairness in the power usage subject to target
SINR constraints. We show that the optimal beamforming strategies have an
interesting nested zero-forcing structure. In the asymptotic regime where the
number of antennas at each BS and the number of users in each cell both grow
large with their ratio tending to a finite constant, the dimensionality of the
optimization is greatly reduced, and only knowledge of statistics is required
to solve it. The optimal solution is characterized in general, and an algorithm
is proposed that converges to the optimal transmit parameters, for feasible
SINR targets. For the two cell case, a simple single parameter characterization
is obtained. These asymptotic results provide insights into the average
performance, as well as simple but efficient beamforming strategies for the
finite system case. In particular, the optimal beamforming strategy from the
large systems analysis only requires the base stations to have local
instantaneous channel state information; the remaining parameters of the
beamformer can be calculated using channel statistics which can easily be
shared amongst the base stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0592</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0592</id><created>2012-02-02</created><updated>2012-03-08</updated><authors><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author></authors><title>On Parameterized Gallager's First Bounds for Binary Linear Codes over
  AWGN Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, nested Gallager regions with a single parameter is introduced
to exploit Gallager's first bounding technique (GFBT). We present a necessary
and sufficient condition on the optimal parameter. We also present a sufficient
condition (with a simple geometrical explanation) under which the optimal
parameter does not depend on the signal-to-noise ratio (SNR). With this general
framework, three existing upper bounds are revisited, including the tangential
bound (TB) of Berlekamp, the sphere bound (SB) of Herzberg and Poltyrev, and
the tangential-sphere bound (TSB) of Poltyrev. This paper also reveals that the
SB of Herzberg and Poltyrev is equivalent to the SB of Kasami et al., which was
rarely cited in literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0598</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0598</id><created>2012-02-02</created><authors><author><keyname>Goldfeld</keyname><forenames>Dorian</forenames></author><author><keyname>Gunnells</keyname><forenames>Paul E.</forenames></author></authors><title>Defeating the Kalka--Teicher--Tsaban linear algebra attack on the
  Algebraic Eraser</title><categories>cs.CR</categories><msc-class>94A60, 20F36</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Algebraic Eraser (AE) is a public key protocol for sharing information
over an insecure channel using commutative and noncommutative groups; a
concrete realization is given by Colored Burau Key Agreement Protocol (CBKAP).
In this paper, we describe how to choose data in CBKAP to thwart an attack by
Kalka--Teicher--Tsaban.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0601</identifier>
 <datestamp>2012-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0601</id><created>2012-02-02</created><updated>2012-10-11</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Precise evaluation of leaked information with universal2 privacy
  amplification in the presence of quantum attacker</title><categories>quant-ph cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We treat secret key extraction when the eavesdropper has correlated quantum
states. We propose quantum privacy amplification theorems different from
Renner's, which are based on quantum conditional R\'{e}nyi entropy of order
1+s. Using those theorems, we derive an exponential decreasing rate for leaked
information and the asymptotic equivocation rate, which have not been derived
hitherto in the quantum setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0607</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0607</id><created>2012-02-03</created><updated>2012-05-04</updated><authors><author><keyname>Huang</keyname><forenames>Chuan</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On the Alternative Relaying Diamond Channel with Conferencing Links</title><categories>cs.IT math.IT</categories><comments>29 pages, submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the diamond relay channel is considered, which consists of one
source-destination pair and two relay nodes connected with rate-limited
out-of-band conferencing links. In particular, we focus on the half-duplex
alternative relaying strategy, in which the two relays operate alternatively
over time. With different amounts of delay, two conferencing strategies are
proposed, each of which can be implemented by either a general two-side
conferencing scheme (for which both of the two conferencing links are used) or
a special-case one-side conferencing scheme (for which only one of the two
conferencing links is used). Based on the most general two-side conferencing
scheme, we derive the achievable rates by using the decode-and-forward (DF) and
amplify-and-forward (AF) relaying schemes, and show that these rate
maximization problems are convex. By further exploiting the properties of the
optimal solutions, the simpler one-side conferencing is shown to be equally
good as the two-side conferencing in term of the achievable rates under
arbitrary channel conditions. Based on this, the DF rate in closed-form is
obtained, and the principle to use which one of the two conferencing links for
one-side conferencing is also established. Moreover, the DF scheme is shown to
be capacity-achieving under certain conditions with even one-side conferencing.
For the AF relaying scheme, one-side conferencing is shown to be sub-optimal in
general. Finally, numerical results are provided to validate our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0609</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0609</id><created>2012-02-03</created><authors><author><keyname>Herrera</keyname><forenames>Roberto Henry</forenames></author><author><keyname>Orozco</keyname><forenames>Rub&#xe9;n</forenames></author><author><keyname>Rodr&#xed;guez</keyname><forenames>Manuel</forenames></author></authors><title>Wavelet-based deconvolution of ultrasonic signals in nondestructive
  evaluation</title><categories>cs.CV</categories><journal-ref>J Zhejiang Univ SCIENCE A 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the inverse problem of reconstructing reflectivity function of
a medium is examined within a blind deconvolution framework. The ultrasound
pulse is estimated using higher-order statistics, and Wiener filter is used to
obtain the ultrasonic reflectivity function through wavelet-based models. A new
approach to the parameter estimation of the inverse filtering step is proposed
in the nondestructive evaluation field, which is based on the theory of
Fourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be
viewed as a solution to the open problem of adaptation of the ForWaRD framework
to perform the convolution kernel estimation and deconvolution
interdependently. The results indicate stable solutions of the estimated pulse
and an improvement in the radio-frequency (RF) signal taking into account its
signal-to-noise ratio (SNR) and axial resolution. Simulations and experiments
showed that the proposed approach can provide robust and optimal estimates of
the reflectivity function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0612</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0612</id><created>2012-02-03</created><authors><author><keyname>Rastogi</keyname><forenames>Ravi</forenames></author><author><keyname>Nitin</keyname></author><author><keyname>Chauhan</keyname><forenames>Durg Singh</forenames></author><author><keyname>Govil</keyname><forenames>Mahesh Chandra</forenames></author></authors><title>Disjoint Paths Multi-stage Interconnection Networks Stability Problem</title><categories>cs.DC cs.NI</categories><comments>12 pages, 16 figures</comments><report-no>IJCSI-8-4-1-260-271</report-no><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, No 1, pages 260-271, July 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research paper emphasizes that the Stable Matching problems are the same
as the problems of stable configurations of Multi-stage Interconnection
Networks (MIN). The authors have solved the Stability Problem of Existing
Regular Gamma Multi-stage Interconnection Network (GMIN), 3-Disjoint Gamma
Multi-stage Interconnection Network (3DGMIN) and 3-Disjoint Path Cyclic Gamma
Multi-stage Interconnection Network (3DCGMIN) using the approaches and
solutions provided by the Stable Matching Problem. Specifically Stable Marriage
Problem is used as an example of Stable Matching. For MINs to prove Stable two
existing algorithms are used:-the first algorithm generates the MINs
Preferences List in time and second algorithm produces a set of most Optimal
Pairs of the Switching Elements (SEs) (derived from the MINs Preferences List)
in time. Moreover, the paper also solves the problem of Ties that occurs
between the Optimal Pairs. The results are promising as the comparison of the
MINs based on their stability shows that the ASEN, ABN, CLN, GMIN, 3DCGMIN are
highly stable in comparison to HZTN, QTN, DGMIN. However, on comparing the
irregular and regular MINs in totality upon their stability the regular MINs
comes out to be more stable than the irregular MINs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0613</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0613</id><created>2012-02-03</created><authors><author><keyname>Mittal</keyname><forenames>Shaily</forenames></author><author><keyname>Nitin</keyname></author></authors><title>A Resolution for Shared Memory Conflict in Multiprocessor
  System-on-a-Chip</title><categories>cs.AR</categories><comments>5 pages, 4 figures</comments><report-no>IJCSI-8-4-1-503-507</report-no><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, No 1, July 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now days, manufacturers are focusing on increasing the concurrency in
multiprocessor system-on-a-chip (MPSoC) architecture instead of increasing
clock speed, for embedded systems. Traditionally lock-based synchronization is
provided to support concurrency; as managing locks can be very difficult and
error prone. Transactional memories and lock based systems have been
extensively used to provide synchronization between multiple processors [1] in
general-purpose systems. It has been shown that locks have numerous
shortcomings over transactional memory in terms of power consumption, ease of
programming and performance. In this paper, we propose a new semaphore scheme
for synchronization in shared cache memory in an MPSoC. Moreover, we have
evaluated and compared our scheme with locks and transactions in terms of
energy consumption and cache miss rate using SimpleScalar functional simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0616</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0616</id><created>2012-02-03</created><authors><author><keyname>Rastogi</keyname><forenames>Ravi</forenames></author><author><keyname>Singh</keyname><forenames>Amit</forenames></author><author><keyname>Singhal</keyname><forenames>Nikhil</forenames></author><author><keyname>Nitin</keyname></author><author><keyname>Chauhan</keyname><forenames>Durg Singh</forenames></author></authors><title>Case Tool: Fast Interconnections with New 3-Disjoint Paths MIN
  Simulation Module</title><categories>cs.DC</categories><comments>6 pages, 6 figures</comments><report-no>pxc3873110</report-no><journal-ref>International Journal of Computer Applications (0975 - 8887),
  Volume 19 - No.6, April 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-stage interconnection networks (MIN) can be designed to achieve fault
tolerance and collision solving by providing a set of disjoint paths. In this
paper, we are discussing the new simulator added to the tool designed for
developing fault tolerant MINs. The designed tool is one of its own kind and
will help the user in developing 2 and 3-disjoint path networks. The java
technology has been used to design the tool and have been tested on different
software platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0617</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0617</id><created>2012-02-03</created><updated>2012-02-17</updated><authors><author><keyname>Nitin</keyname></author><author><keyname>Bansal</keyname><forenames>Ankush</forenames></author><author><keyname>Sharma</keyname><forenames>Siddhartha Mahadev</forenames></author><author><keyname>Kumar</keyname><forenames>Kapil</forenames></author><author><keyname>Aggarwal</keyname><forenames>Anuj</forenames></author><author><keyname>Goyal</keyname><forenames>Sheenu</forenames></author><author><keyname>Choudhary</keyname><forenames>Kanika</forenames></author><author><keyname>Chawla</keyname><forenames>Kunal</forenames></author><author><keyname>Jain</keyname><forenames>Kunal</forenames></author><author><keyname>Bhasin</keyname><forenames>Manav</forenames></author></authors><title>Classification of Flames in Computer Mediated Communications</title><categories>cs.SI cs.CL</categories><comments>6 pages, 4 figures</comments><report-no>pxc3872505</report-no><journal-ref>International Journal of Computer Applications (0975-8887), Volume
  14 - No.6, February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer Mediated Communication (CMC) has brought about a revolution in the
way the world communicates with each other. With the increasing number of
people, interacting through the internet and the rise of new platforms and
technologies has brought together the people from different social, cultural
and geographical backgrounds to present their thoughts, ideas and opinions on
topics of their interest. CMC has, in some cases, gave users more freedom to
express themselves as compared to Face-to-face communication. This has also led
to rise in the use of hostile and aggressive language and terminologies
uninhibitedly. Since such use of language is detrimental to the discussion
process and affects the audience and individuals negatively, efforts are being
taken to control them. The research sees the need to understand the concept of
flaming and hence attempts to classify them in order to give a better
understanding of it. The classification is done on the basis of type of flame
content being presented and the Style in which they are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0621</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0621</id><created>2012-02-03</created><authors><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Zhuang</keyname><forenames>and Qiutao</forenames></author></authors><title>New Geometrical Spectra of Linear Codes with Applications to Performance
  Analysis</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, new enumerating functions for linear codes are defined,
including the triangle enumerating function and the tetrahedron enumerating
function, both of which can be computed using a trellis-based algorithm over
polynomial rings. The computational complexity is dominated by the complexity
of the trellis. In addition, we show that these new enumerating functions can
be used to improve existing performance bounds on the maximum likelihood
decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0652</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0652</id><created>2012-02-03</created><authors><author><keyname>Cunningham</keyname><forenames>Hamish</forenames></author></authors><title>Agile Research</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper discusses the application of agile software development methods in
software-based research environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0655</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0655</id><created>2012-02-03</created><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Central Approximation in Statistical Physics and Information Theory</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>5 pages, submitted to ISIT2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In statistical physics and information theory, although the exponent of the
partition function is often of our primary interest, there are cases where one
needs more detailed information. In this paper, we present a general framework
to study more precise asymptotic behaviors of the partition function, using the
central approximation in conjunction with the method of types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0664</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0664</id><created>2012-02-03</created><authors><author><keyname>Larsson</keyname><forenames>Urban</forenames></author><author><keyname>W&#xe4;stlund</keyname><forenames>Johan</forenames></author></authors><title>From heaps of matches to the limits of computability</title><categories>cs.CC cs.LO math.CO</categories><comments>13 pages, 7 figures</comments><msc-class>91A46, 68Q80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study so-called invariant games played with a fixed number $d$ of heaps of
matches. A game is described by a finite list $\mathcal{M}$ of integer vectors
of length $d$ specifying the legal moves. A move consists in changing the
current game-state by adding one of the vectors in $\mathcal{M}$, provided all
elements of the resulting vector are nonnegative. For instance, in a two-heap
game, the vector $(1,-2)$ would mean adding one match to the first heap and
removing two matches from the second heap. If $(1,-2) \in \mathcal{M}$, such a
move would be permitted provided there are at least two matches in the second
heap. Two players take turns, and a player unable to make a move loses. We show
that these games embrace computational universality, and that therefore a
number of basic questions about them are algorithmically undecidable. In
particular, we prove that there is no algorithm that takes two games
$\mathcal{M}$ and $\mathcal{M}'$ (with the same number of heaps) as input, and
determines whether or not they are equivalent in the sense that every
starting-position which is a first player win in one of the games is a first
player win in the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0666</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0666</id><created>2012-02-03</created><updated>2012-09-04</updated><authors><author><keyname>Csisz&#xe1;r</keyname><forenames>Imre</forenames></author><author><keyname>Mat&#xfa;&#x161;</keyname><forenames>Franti&#x161;ek</forenames></author></authors><title>Generalized minimizers of convex integral functionals, Bregman distance,
  Pythagorean identities</title><categories>math.OC cs.IT math.IT math.PR math.ST stat.TH</categories><msc-class>94A17, 49J53, 49K30, 62B10, 65K10, 90C46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integral functionals based on convex normal integrands are minimized subject
to finitely many moment constraints. The integrands are finite on the positive
and infinite on the negative numbers, strictly convex but not necessarily
differentiable. The minimization is viewed as a primal problem and studied
together with a dual one in the framework of convex duality. The effective
domain of the value function is described by a conic core, a modification of
the earlier concept of convex core. Minimizers and generalized minimizers are
explicitly constructed from solutions of modified dual problems, not assuming
the primal constraint qualification. A generalized Pythagorean identity is
presented using Bregman distance and a correction term for lack of essential
smoothness in integrands. Results are applied to minimization of Bregman
distances. Existence of a generalized dual solution is established whenever the
dual value is finite, assuming the dual constraint qualification. Examples of
`irregular' situations are included, pointing to the limitations of generality
of certain key results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0670</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0670</id><created>2012-02-03</created><authors><author><keyname>Junnila</keyname><forenames>Ville</forenames></author><author><keyname>Laihonen</keyname><forenames>Tero</forenames></author></authors><title>Optimal lower bound for 2-identifying code in the hexagonal grid</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $r$-identifying code in a graph $G = (V,E)$ is a subset $C \subseteq V$
such that for each $u \in V$ the intersection of $C$ and the ball of radius $r$
centered at $u$ is non-empty and unique. Previously, $r$-identifying codes have
been studied in various grids. In particular, it has been shown that there
exists a 2-identifying code in the hexagonal grid with density 4/19 and that
there are no 2-identifying codes with density smaller than 2/11. Recently, the
lower bound has been improved to 1/5 by Martin and Stanton (2010). In this
paper, we prove that the 2-identifying code with density 4/19 is optimal, i.e.
that there does not exist a 2-identifying code in the hexagonal grid with
smaller density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0671</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0671</id><created>2012-02-03</created><updated>2012-10-22</updated><authors><author><keyname>Junnila</keyname><forenames>Ville</forenames></author></authors><title>New lower bound for 2-identifying code in the square grid</title><categories>math.CO cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:1202.0670</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $r$-identifying code in a graph $G = (V,E)$ is a subset $C \subseteq V$
such that for each $u \in V$ the intersection of $C$ and the ball of radius $r$
centered at $u$ is nonempty and unique. Previously, $r$-identifying codes have
been studied in various grids. In particular, it has been shown that there
exists a 2-identifying code in the square grid with density $5/29 \approx
0.172$ and that there are no 2-identifying codes with density smaller than
$3/20 = 0.15$. Recently, the lower bound has been improved to $6/37 \approx
0.162$ by Martin and Stanton (2010). In this paper, we further improve the
lower bound by showing that there are no 2-identifying codes in the square grid
with density smaller than $6/35 \approx 0.171$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0675</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0675</id><created>2012-02-03</created><authors><author><keyname>Ernvall</keyname><forenames>Toni</forenames></author><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author></authors><title>Construction of MIMO MAC Codes Achieving the Pigeon Hole Bound</title><categories>math.RA cs.IT math.IT</categories><comments>5 pages, nofigures, conference</comments><msc-class>68P30</msc-class><journal-ref>2012 IEEE ISIT, pages 21-25 (Cambridge, MA)</journal-ref><doi>10.1109/ISIT.2012.6283843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a general construction method for multiple-input
multiple-output multiple access channel codes (MIMO MAC codes) that have so
called generalized full rank property. The achieved constructions give a
positive answer to the question whether it is generally possible to reach the
so called pigeon hole bound, that is an upper bound for the decay of
determinants of MIMO-MAC channel codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0678</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0678</id><created>2012-02-03</created><updated>2012-02-08</updated><authors><author><keyname>De Felice</keyname><forenames>Matteo</forenames></author><author><keyname>Meloni</keyname><forenames>Sandro</forenames></author><author><keyname>Panzieri</keyname><forenames>Stefano</forenames></author></authors><title>Influence of Topological Features on Spatially-Structured Evolutionary
  Algorithms Dynamics</title><categories>cs.NE</categories><comments>Submitted to IEEE Transactions on Evolutionary Computation, 14 pages,
  14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last decades, complex networks theory significantly influenced other
disciplines on the modeling of both static and dynamic aspects of systems
observed in nature. This work aims to investigate the effects of networks'
topological features on the dynamics of an evolutionary algorithm, considering
in particular the ability to find a large number of optima on multi-modal
problems. We introduce a novel spatially-structured evolutionary algorithm and
we apply it on two combinatorial problems: ONEMAX and the multi-modal NMAX.
Considering three different network models we investigate the relationships
between their features, algorithm's convergence and its ability to find
multiple optima (for the multi-modal problem). In order to perform a deeper
analysis we investigate the introduction of weighted graphs with time-varying
weights. The results show that networks with a large Average Path Length lead
to an higher number of optima and a consequent slow exploration dynamics (i.e.
low First Hitting Time). Furthermore, the introduction of weighted networks
shows the possibility to tune algorithm's dynamics during its execution with
the parameter related with weights' change. This work gives a first answer
about the effects of various graph topologies on the diversity of evolutionary
algorithms and it describes a simple but powerful algorithmic framework which
allows to investigate many aspects of ssEAs dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0681</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0681</id><created>2012-02-03</created><updated>2012-08-10</updated><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>On maximum matchings in almost regular graphs</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In 2010, Mkrtchyan, Petrosyan and Vardanyan proved that every graph $G$ with
$2\leq \delta(G)\leq \Delta(G)\leq 3$ contains a maximum matching whose
unsaturated vertices do not have a common neighbor, where $\Delta(G)$ and
$\delta(G)$ denote the maximum and minimum degrees of vertices in $G$,
respectively. In the same paper they suggested the following conjecture: every
graph $G$ with $\Delta(G)-\delta(G)\leq 1$ contains a maximum matching whose
unsaturated vertices do not have a common neighbor. Recently, Picouleau
disproved this conjecture by constructing a bipartite counterexample $G$ with
$\Delta(G)=5$ and $\delta(G)=4$. In this note we show that the conjecture is
false for graphs $G$ with $\Delta(G)-\delta(G)=1$ and $\Delta(G)\geq 4$, and
for $r$-regular graphs when $r\geq 7$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0690</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0690</id><created>2012-02-03</created><updated>2012-07-31</updated><authors><author><keyname>Ozcelik</keyname><forenames>F. Mehmet</forenames></author><author><keyname>Uctu</keyname><forenames>Goksel</forenames></author><author><keyname>Uysal-Biyikoglu</keyname><forenames>Elif</forenames></author></authors><title>Minimization of Transmission Duration of Data Packets over an Energy
  Harvesting Fading Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The offline problem of transmission completion time minimization for an
energy harvesting transmitter under fading is extended to allow packet arrivals
during transmission. A method for computing an optimal power and rate
allocation (i.e., an optimal offline schedule) is developed and studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0693</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0693</id><created>2012-02-03</created><updated>2012-07-09</updated><authors><author><keyname>Gazeau</keyname><forenames>Ivan</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Miller</keyname><forenames>Dale</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Palamidessi</keyname><forenames>Catuscia</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author></authors><title>A non-local method for robustness analysis of floating point programs</title><categories>cs.PL</categories><comments>QAPL - Tenth Workshop on Quantitative Aspects of Programming
  Languages (2012)</comments><proxy>ccsd</proxy><doi>10.4204/EPTCS.85.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness is a standard correctness property which intuitively means that if
the input to the program changes less than a fixed small amount then the output
changes only slightly. This notion is useful in the analysis of rounding error
for floating point programs because it helps to establish bounds on output
errors introduced by both measurement errors and by floating point computation.
Compositional methods often do not work since key constructs---like the
conditional and the while-loop---are not robust. We propose a method for
proving the robustness of a while-loop. This method is non-local in the sense
that instead of breaking the analysis down to single lines of code, it checks
certain global properties of its structure. We show the applicability of our
method on two standard algorithms: the CORDIC computation of the cosine and
Dijkstra's shortest path algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0695</identifier>
 <datestamp>2015-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0695</id><created>2012-02-03</created><authors><author><keyname>Rhoads</keyname><forenames>Glenn C.</forenames></author><author><keyname>Bartholdi</keyname><forenames>Laurent</forenames></author></authors><title>The Game of Pure Strategy is solved!</title><categories>cs.GT</categories><journal-ref>Games 3 (2012), 150--156</journal-ref><doi>10.3390/g3040150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the classical &quot;Game of Pure Strategy&quot; using linear programming. We
notice an intricate even-odd behavior in the results of our computations, that
seems to encourage odd or maximal bids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0702</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0702</id><created>2012-02-03</created><authors><author><keyname>Huang</keyname><forenames>Qin</forenames></author><author><keyname>Liu</keyname><forenames>Keke</forenames></author><author><keyname>Wang</keyname><forenames>Zulin</forenames></author></authors><title>Low-Density Arrays of Circulant Matrices: Rank and Row-Redundancy
  Analysis, and Quasi-Cyclic LDPC Codes</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1004.1184</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with general analysis on the rank and row-redundancy
of an array of circulants whose null space defines a QC-LDPC code. Based on the
Fourier transform and the properties of conjugacy classes and Hadamard products
of matrices, we derive tight upper bounds on rank and row-redundancy for
general array of circulants, which make it possible to consider row-redundancy
in constructions of QC-LDPC codes to achieve better performance. We further
investigate the rank of two types of construction of QC-LDPC codes:
constructions based on Vandermonde Matrices and Latin Squares and give
combinatorial expression of the exact rank in some specific cases, which
demonstrates the tightness of the bound we derive. Moreover, several types of
new construction of QC-LDPC codes with large row-redundancy are presented and
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0723</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0723</id><created>2012-02-02</created><updated>2012-02-08</updated><authors><author><keyname>Granell</keyname><forenames>Carlos</forenames></author><author><keyname>D&#xed;az</keyname><forenames>Laura</forenames></author><author><keyname>Tamayo</keyname><forenames>Alain</forenames></author><author><keyname>Huerta</keyname><forenames>Joaqu&#xed;n</forenames></author></authors><title>Assessment of OGC Web Processing Services for REST principles</title><categories>cs.SE</categories><comments>23 pages, 3 Figures, 2 Tables. Paper accepted to International
  Journal of Data Mining, Modelling and Management</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent distributed computing trends advocate the use of Representational
State Transfer (REST) to alleviate the inherent complexity of the Web services
standards in building service-oriented web applications. In this paper we focus
on the particular case of geospatial services interfaced by the OGC Web
Processing Service (WPS) specification in order to assess whether WPS-based
geospatial services can be viewed from the architectural principles exposed in
REST. Our concluding remarks suggest that the adoption of REST principles, to
specially harness the built-in mechanisms of the HTTP application protocol, may
be beneficial in scenarios where ad hoc composition of geoprocessing services
are required, common for most non-expert users of geospatial information
infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0747</identifier>
 <datestamp>2013-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0747</id><created>2012-02-03</created><updated>2013-01-09</updated><authors><author><keyname>Xu</keyname><forenames>Li</forenames></author><author><keyname>Shang</keyname><forenames>Weiping</forenames></author><author><keyname>Han</keyname><forenames>Guangyue</forenames></author></authors><title>A Graph Theoretical Approach to Network Encoding Complexity</title><categories>cs.IT math.IT</categories><comments>44 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an acyclic directed network $G$ with sources $S_1, S_2,..., S_l$ and
distinct sinks $R_1, R_2,..., R_l$. For $i=1, 2,..., l$, let $c_i$ denote the
min-cut between $S_i$ and $R_i$. Then, by Menger's theorem, there exists a
group of $c_i$ edge-disjoint paths from $S_i$ to $R_i$, which will be referred
to as a group of Menger's paths from $S_i$ to $R_i$ in this paper. Although
within the same group they are edge-disjoint, the Menger's paths from different
groups may have to merge with each other. It is known that by choosing Menger's
paths appropriately, the number of mergings among different groups of Menger's
paths is always bounded by a constant, which is independent of the size and the
topology of $G$. The tightest such constant for the all the above-mentioned
networks is denoted by $\mathcal{M}(c_1, c_2,..., c_2)$ when all $S_i$'s are
distinct, and by $\mathcal{M}^*(c_1, c_2,..., c_2)$ when all $S_i$'s are in
fact identical. It turns out that $\mathcal{M}$ and $\mathcal{M}^*$ are closely
related to the network encoding complexity for a variety of networks, such as
multicast networks, two-way networks and networks with multiple sessions of
unicast. Using this connection, we compute in this paper some exact values and
bounds in network encoding complexity using a graph theoretical approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0753</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0753</id><created>2012-02-03</created><updated>2012-11-10</updated><authors><author><keyname>Fagiano</keyname><forenames>Lorenzo</forenames></author><author><keyname>Khammash</keyname><forenames>Mustafa</forenames></author></authors><title>Simulation of stochastic systems via polynomial chaos expansions and
  convex optimization</title><categories>stat.CO cs.SY math-ph math.DS math.MP math.OC</categories><comments>This manuscript is a preprint of a paper published on Physical
  Reviews E and is subject to American Physical Society copyright. The copy of
  record is available at http://pre.aps.org.
  http://link.aps.org/doi/10.1103/PhysRevE.86.036702</comments><journal-ref>Physical Reviews E, Volume 86, Issue 3, 036702, 2012</journal-ref><doi>10.1103/PhysRevE.86.036702</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polynomial Chaos Expansions represent a powerful tool to simulate stochastic
models of dynamical systems. Yet, deriving the expansion's coefficients for
complex systems might require a significant and non-trivial manipulation of the
model, or the computation of large numbers of simulation runs, rendering the
approach too time consuming and impracticable for applications with more than a
handful of random variables. We introduce a novel computationally tractable
technique for computing the coefficients of polynomial chaos expansions. The
approach exploits a regularization technique with a particular choice of
weighting matrices, which allow to take into account the specific features of
Polynomial Chaos expansions. The method, completely based on convex
optimization, can be applied to problems with a large number of random
variables and uses a modest number of Monte Carlo simulations, while avoiding
model manipulations. Additional information on the stochastic process, when
available, can be also incorporated in the approach by means of convex
constraints. We show the effectiveness of the proposed technique in three
applications in diverse fields, including the analysis of a nonlinear electric
circuit, a chaotic model of organizational behavior, finally a chemical
oscillator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0754</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0754</id><created>2012-02-03</created><authors><author><keyname>Wei</keyname><forenames>Lu</forenames></author><author><keyname>Tirkkonen</keyname><forenames>Olav</forenames></author><author><keyname>Dharmawansa</keyname><forenames>Prathapasinghe</forenames></author><author><keyname>McKay</keyname><forenames>Matthew</forenames></author></authors><title>On the Exact Distribution of the Scaled Largest Eigenvalue</title><categories>cs.IT math.IT</categories><comments>to appear in ICC 2012, accepted on 09.Jan.2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the distribution of the scaled largest eigenvalue of
complexWishart matrices, which has diverse applications both in statistics and
wireless communications. Exact expressions, valid for any matrix dimensions,
have been derived for the probability density function and the cumulative
distribution function. The derived results involve only finite sums of
polynomials. These results are obtained by taking advantage of properties of
the Mellin transform for products of independent random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0773</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0773</id><created>2012-02-03</created><authors><author><keyname>Cai</keyname><forenames>Minglai</forenames></author><author><keyname>Cai</keyname><forenames>Ning</forenames></author><author><keyname>Deppe</keyname><forenames>Christian</forenames></author></authors><title>Capacities of classical compound quantum wiretap and classical quantum
  compound wiretap channels</title><categories>quant-ph cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the capacity of the classical compound quantum wiretapper
channel with channel state information at the transmitter. Moreover we derive a
lower bound on the capacity of this channel without channel state information
and determine the capacity of the classical quantum compound wiretap channel
with channel state information at the transmitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0784</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0784</id><created>2012-02-03</created><authors><author><keyname>Zeng</keyname><forenames>Weifei</forenames></author><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Joint Coding and Scheduling Optimization in Wireless Systems with
  Varying Delay Sensitivities</title><categories>cs.NI</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Throughput and per-packet delay can present strong trade-offs that are
important in the cases of delay sensitive applications.We investigate such
trade-offs using a random linear network coding scheme for one or more
receivers in single hop wireless packet erasure broadcast channels. We capture
the delay sensitivities across different types of network applications using a
class of delay metrics based on the norms of packet arrival times. With these
delay metrics, we establish a unified framework to characterize the rate and
delay requirements of applications and optimize system parameters. In the
single receiver case, we demonstrate the trade-off between average packet
delay, which we view as the inverse of throughput, and maximum ordered
inter-arrival delay for various system parameters. For a single broadcast
channel with multiple receivers having different delay constraints and feedback
delays, we jointly optimize the coding parameters and time-division scheduling
parameters at the transmitters. We formulate the optimization problem as a
Generalized Geometric Program (GGP). This approach allows the transmitters to
adjust adaptively the coding and scheduling parameters for efficient allocation
of network resources under varying delay constraints. In the case where the
receivers are served by multiple non-interfering wireless broadcast channels,
the same optimization problem is formulated as a Signomial Program, which is
NP-hard in general. We provide approximation methods using successive
formulation of geometric programs and show the convergence of approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0786</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0786</id><created>2012-02-03</created><updated>2012-02-05</updated><authors><author><keyname>Vu</keyname><forenames>Vincent Q.</forenames></author><author><keyname>Lei</keyname><forenames>Jing</forenames></author></authors><title>Minimax Rates of Estimation for Sparse PCA in High Dimensions</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>To appear in Proceedings of the 15th International Conference on
  Artificial Intelligence and Statistics (AISTATS) 2012, La Palma, Canary
  Islands. Volume 22 of JMLR: W&amp;CP 22</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study sparse principal components analysis in the high-dimensional
setting, where $p$ (the number of variables) can be much larger than $n$ (the
number of observations). We prove optimal, non-asymptotic lower and upper
bounds on the minimax estimation error for the leading eigenvector when it
belongs to an $\ell_q$ ball for $q \in [0,1]$. Our bounds are sharp in $p$ and
$n$ for all $q \in [0, 1]$ over a wide class of distributions. The upper bound
is obtained by analyzing the performance of $\ell_q$-constrained PCA. In
particular, our results provide convergence rates for $\ell_1$-constrained PCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0788</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0788</id><created>2012-02-03</created><authors><author><keyname>Obdr&#x17e;&#xe1;lek</keyname><forenames>Jan</forenames></author><author><keyname>Slab&#xfd;</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Trt&#xed;k</keyname><forenames>Marek</forenames></author></authors><title>STANSE: Bug-finding Framework for C Programs</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  STANSE is a free (available under the GPLv2 license) modular framework for
finding bugs in C programs using static analysis. Its two main design goals are
1) ability to process large software projects like the Linux kernel and 2)
extensibility with new bug-finding techniques with a minimal effort. Currently
there are four bug-finding algorithms implemented within STANSE:
AutomatonChecker checks properties described in an automata-based formalism,
ThreadChecker detects deadlocks among multiple threads, LockChecker finds
locking errors based on statistics, and ReachabilityChecker looks for
unreachable code. STANSE has been tested on the Linux kernel, where it has
found dozens of previously undiscovered bugs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0789</identifier>
 <datestamp>2012-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0789</id><created>2012-02-03</created><updated>2012-08-21</updated><authors><author><keyname>Eshete</keyname><forenames>Addisu Tadesse</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>Protection from Unresponsive Flows with Geometric CHOKe</title><categories>cs.NI</categories><comments>Paper withdrawn since the paper is published in IEEE ISCC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a simple and stateless active queue management (AQM)
scheme, called geometric CHOKe (gCHOKe), to protect responsive flows from
unresponsive ones. The proposed gCHOKe has its root on and is a generalization
of the original CHOKe. It provides an extended power of flow protection,
achieved by introducing an extra flow matching trial upon each successful
matching of packets. Compared to the plain CHOKe, analysis and simulation show
that gCHOKe can achieve over 20% improvement in the bounds of both bandwidth
and buffer space used by an aggressive flow. In addition, up to 14% of the
total link capacity can be saved from the unresponsive flow, allowing
responsive or rate-adaptive flows to obtain a better share of resources in the
router.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0796</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0796</id><created>2012-02-03</created><updated>2012-05-31</updated><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author><author><keyname>Novotn&#xfd;</keyname><forenames>Petr</forenames></author></authors><title>Efficient Controller Synthesis for Consumption Games with Multiple
  Resource Types</title><categories>cs.GT cs.SY math.OC</categories><comments>Revised version, 38 pages. This is a full version of a paper accepted
  for publication in the proceedings of CAV 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce consumption games, a model for discrete interactive system with
multiple resources that are consumed or reloaded independently. More precisely,
a consumption game is a finite-state graph where each transition is labeled by
a vector of resource updates, where every update is a non-positive number or
omega. The omega updates model the reloading of a given resource. Each vertex
belongs either to player \Box or player \Diamond, where the aim of player \Box
is to play so that the resources are never exhausted. We consider several
natural algorithmic problems about consumption games, and show that although
these problems are computationally hard in general, they are solvable in
polynomial time for every fixed number of resource types (i.e., the dimension
of the update vectors).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0798</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0798</id><created>2012-02-03</created><updated>2012-03-25</updated><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>On Coding Efficiency for Flash Memories</title><categories>cs.IT math.IT</categories><comments>accepted for publication in the Proceeding of the 35th IEEE Sarnoff
  Symposium, Newark, New Jersey, May 21-22, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, flash memories have become a competitive solution for mass storage.
The flash memories have rather different properties compared with the rotary
hard drives. That is, the writing of flash memories is constrained, and flash
memories can endure only limited numbers of erases. Therefore, the design goals
for the flash memory systems are quite different from these for other memory
systems. In this paper, we consider the problem of coding efficiency. We define
the &quot;coding-efficiency&quot; as the amount of information that one flash memory cell
can be used to record per cost. Because each flash memory cell can endure a
roughly fixed number of erases, the cost of data recording can be well-defined.
We define &quot;payload&quot; as the amount of information that one flash memory cell can
represent at a particular moment. By using information-theoretic arguments, we
prove a coding theorem for achievable coding rates. We prove an upper and lower
bound for coding efficiency. We show in this paper that there exists a
fundamental trade-off between &quot;payload&quot; and &quot;coding efficiency&quot;. The results in
this paper may provide useful insights on the design of future flash memory
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0800</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0800</id><created>2012-02-03</created><updated>2012-07-15</updated><authors><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author><author><keyname>Rawat</keyname><forenames>Ankit Singh</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Error Resilience in Distributed Storage via Rank-Metric Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel coding scheme for distributed storage systems
containing nodes with adversarial errors. The key challenge in such systems is
the propagation of erroneous data from a single corrupted node to the rest of
the system during a node repair process. This paper presents a concatenated
coding scheme which is based on two types of codes: maximum rank distance (MRD)
code as an outer code and optimal repair maximal distance separable (MDS) array
code as an inner code. Given this, two different types of adversarial errors
are considered: the first type considers an adversary that can replace the
content of an affected node only once; while the second attack-type considers
an adversary that can pollute data an unbounded number of times. This paper
proves that the proposed coding scheme attains a suitable upper bound on
resilience capacity for the first type of error. Further, the paper presents
mechanisms that combine this code with subspace signatures to achieve error
resilience for the second type of errors. Finally, the paper concludes by
presenting a construction based on MRD codes for optimal locally repairable
scalar codes that can tolerate adversarial errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0813</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0813</id><created>2012-02-03</created><updated>2012-02-10</updated><authors><author><keyname>Hamidi-Sepehr</keyname><forenames>Fatemeh</forenames></author><author><keyname>Chamberland</keyname><forenames>Jean-Francois</forenames></author><author><keyname>Pfister</keyname><forenames>Henry</forenames></author></authors><title>On The Performance of Random Block Codes over Finite-State Fading
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the mobile application landscape expands, wireless networks are tasked
with supporting various connection profiles, including real-time communications
and delay-sensitive traffic. Among many ensuing engineering challenges is the
need to better understand the fundamental limits of forward error correction in
non-asymptotic regimes. This article seeks to characterize the performance of
block codes over finite-state channels with memory. In particular, classical
results from information theory are revisited in the context of channels with
rate transitions, and bounds on the probabilities of decoding failure are
derived for random codes. This study offers new insights about the potential
impact of channel correlation over time on overall performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0835</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0835</id><created>2012-02-03</created><authors><author><keyname>Thakur</keyname><forenames>Mohit</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Reducibility of joint relay positioning and flow optimization problem</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how to reduce the otherwise hard joint relay positioning and
flow optimization problem into a sequence a two simpler decoupled problems. We
consider a class of wireless multicast hypergraphs mainly characterized by
their hyperarc rate functions, that are increasing and convex in power, and
decreasing in distance between the transmit node and the farthest end node of
the hyperarc. The set-up consists of a single multicast flow session involving
a source, multiple destinations and a relay that can be positioned freely. The
first problem formulates the relay positioning problem in a purely geometric
sense, and once the optimal relay position is obtained the second problem
addresses the flow optimization. Furthermore, we present simple and efficient
algorithms to solve these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0837</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0837</id><created>2012-02-03</created><authors><author><keyname>Insa-Cabrera</keyname><forenames>Javier</forenames></author><author><keyname>Benacloch-Ayuso</keyname><forenames>Jose-Luis</forenames></author><author><keyname>Hernandez-Orallo</keyname><forenames>Jose</forenames></author></authors><title>On the influence of intelligence in (social) intelligence testing
  environments</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyses the influence of including agents of different degrees of
intelligence in a multiagent system. The goal is to better understand how we
can develop intelligence tests that can evaluate social intelligence. We
analyse several reinforcement algorithms in several contexts of cooperation and
competition. Our experimental setting is inspired by the recently developed
Darwin-Wallace distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0840</identifier>
 <datestamp>2015-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0840</id><created>2012-02-03</created><updated>2015-12-18</updated><authors><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Joseph</keyname><forenames>Antony</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Lossy Compression via Sparse Linear Regression: Performance under
  Minimum-distance Encoding</title><categories>cs.IT math.IT stat.ML</categories><comments>This version corrects a typo in the statement of Theorem 2 of the
  published paper</comments><journal-ref>IEEE Transactions on Information Theory, vol. 60, no. 6, pp.
  3254-3264, June 2014</journal-ref><doi>10.1109/TIT.2014.2313085</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a new class of codes for lossy compression with the squared-error
distortion criterion, designed using the statistical framework of
high-dimensional linear regression. Codewords are linear combinations of
subsets of columns of a design matrix. Called a Sparse Superposition or Sparse
Regression codebook, this structure is motivated by an analogous construction
proposed recently by Barron and Joseph for communication over an AWGN channel.
For i.i.d Gaussian sources and minimum-distance encoding, we show that such a
code can attain the Shannon rate-distortion function with the optimal error
exponent, for all distortions below a specified value. It is also shown that
sparse regression codes are robust in the following sense: a codebook designed
to compress an i.i.d Gaussian source of variance $\sigma^2$ with
(squared-error) distortion $D$ can compress any ergodic source of variance less
than $\sigma^2$ to within distortion $D$. Thus the sparse regression ensemble
retains many of the good covering properties of the i.i.d random Gaussian
ensemble, while having having a compact representation in terms of a matrix
whose size is a low-order polynomial in the block-length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0847</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0847</id><created>2012-02-03</created><updated>2012-03-01</updated><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author><author><keyname>Kyn&#x10d;l</keyname><forenames>Jan</forenames></author><author><keyname>M&#xe9;sz&#xe1;ros</keyname><forenames>Viola</forenames></author><author><keyname>Stola&#x159;</keyname><forenames>Rudolf</forenames></author><author><keyname>Valtr</keyname><forenames>Pavel</forenames></author></authors><title>Graph sharing games: complexity and connectivity</title><categories>cs.DM cs.CC</categories><comments>22 pages, 11 figures; updated references, minor stylistical changes</comments><msc-class>05C22, 05C40, 05C57, 91A43</msc-class><journal-ref>Theoretical Computer Science 494 (2013), 49-62</journal-ref><doi>10.1016/j.tcs.2012.12.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the following combinatorial game played by two players, Alice and
Bob, which generalizes the Pizza game considered by Brown, Winkler and others.
Given a connected graph G with nonnegative weights assigned to its vertices,
the players alternately take one vertex of G in each turn. The first turn is
Alice's. The vertices are to be taken according to one (or both) of the
following two rules: (T) the subgraph of G induced by the taken vertices is
connected during the whole game, (R) the subgraph of G induced by the remaining
vertices is connected during the whole game. We show that if rules (T) and/or
(R) are required then for every epsilon &gt; 0 and for every positive integer k
there is a k-connected graph G for which Bob has a strategy to obtain
(1-epsilon) of the total weight of the vertices. This contrasts with the
original Pizza game played on a cycle, where Alice is known to have a strategy
to obtain 4/9 of the total weight.
  We show that the problem of deciding whether Alice has a winning strategy
(i.e., a strategy to obtain more than half of the total weight) is
PSPACE-complete if condition (R) or both conditions (T) and (R) are required.
We also consider a game played on connected graphs (without weights) where the
first player who violates condition (T) or (R) loses the game. We show that
deciding who has the winning strategy is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0854</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0854</id><created>2012-02-03</created><updated>2012-02-07</updated><authors><author><keyname>Hong</keyname><forenames>Song-Nam</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Reverse Compute and Forward: A Low-Complexity Architecture for Downlink
  Distributed Antenna Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submission to the 2012 IEEE International
  Symposium on Information Theory (ISIT 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a distributed antenna system where $L$ antenna terminals (ATs)
are connected to a Central Processor (CP) via digital error-free links of
finite capacity $R_0$, and serve $L$ user terminals (UTs). This system model
has been widely investigated both for the uplink and the downlink, which are
instances of the general multiple-access relay and broadcast relay networks. In
this work we focus on the downlink, and propose a novel downlink precoding
scheme nicknamed &quot;Reverse Quantized Compute and Forward&quot; (RQCoF). For this
scheme we obtain achievable rates and compare with the state of the art
available in the literature. We also provide simulation results for a realistic
network with fading and pathloss with $K &gt; L$ UTs, and show that channel-based
user selection produces large benefits and essentially removes the problem of
rank deficiency in the system matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0855</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0855</id><created>2012-02-03</created><authors><author><keyname>Qian</keyname><forenames>Buyue</forenames></author><author><keyname>Wang</keyname><forenames>Xiang</forenames></author><author><keyname>Davidson</keyname><forenames>Ian</forenames></author></authors><title>A Reconstruction Error Formulation for Semi-Supervised Multi-task and
  Multi-view Learning</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant challenge to make learning techniques more suitable for general
purpose use is to move beyond i) complete supervision, ii) low dimensional
data, iii) a single task and single view per instance. Solving these challenges
allows working with &quot;Big Data&quot; problems that are typically high dimensional
with multiple (but possibly incomplete) labelings and views. While other work
has addressed each of these problems separately, in this paper we show how to
address them together, namely semi-supervised dimension reduction for
multi-task and multi-view learning (SSDR-MML), which performs optimization for
dimension reduction and label inference in semi-supervised setting. The
proposed framework is designed to handle both multi-task and multi-view
learning settings, and can be easily adapted to many useful applications.
Information obtained from all tasks and views is combined via reconstruction
errors in a linear fashion that can be efficiently solved using an alternating
optimization scheme. Our formulation has a number of advantages. We explicitly
model the information combining mechanism as a data structure (a
weight/nearest-neighbor matrix) which allows investigating fundamental
questions in multi-task and multi-view learning. We address one such question
by presenting a general measure to quantify the success of simultaneous
learning of multiple tasks or from multiple views. We show that our SSDR-MML
approach can outperform many state-of-the-art baseline methods and demonstrate
the effectiveness of connecting dimension reduction and learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0859</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0859</id><created>2012-02-03</created><updated>2014-10-12</updated><authors><author><keyname>Cheng</keyname><forenames>Fan</forenames></author><author><keyname>Yeung</keyname><forenames>Raymond W.</forenames></author><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author></authors><title>Imperfect Secrecy in Wiretap Channel II</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a point-to-point communication system which consists of a sender, a
receiver and a set of noiseless channels, the sender wishes to transmit a
private message to the receiver through the channels which may be eavesdropped
by a wiretapper. The set of wiretap sets is arbitrary. The wiretapper can
access any one but not more than one wiretap set. From each wiretap set, the
wiretapper can obtain some partial information about the private message which
is measured by the equivocation of the message given the symbols obtained by
the wiretapper. The security strategy is to encode the message with some random
key at the sender. Only the message is required to be recovered at the
receiver. Under this setting, we define an achievable rate tuple consisting of
the size of the message, the size of the key, and the equivocation for each
wiretap set. We first prove a tight rate region when both the message and the
key are required to be recovered at the receiver. Then we extend the result to
the general case when only the message is required to be recovered at the
receiver. Moreover, we show that even if stochastic encoding is employed at the
sender, the message rate cannot be increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0862</identifier>
 <datestamp>2014-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0862</id><created>2012-02-03</created><updated>2014-09-12</updated><authors><author><keyname>Aravamuthan</keyname><forenames>Sarang</forenames></author><author><keyname>Ganguly</keyname><forenames>Biswajit</forenames></author></authors><title>e-Valuate: A Two-player Game on Arithmetic Expressions -- An Update</title><categories>math.CO cs.AI</categories><comments>18 pages, 3 figures</comments><msc-class>91A05, 91A43 (Primary), 91A46 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  e-Valuate is a game on arithmetic expressions. The players have contrasting
roles of maximizing and minimizing the given expression. The maximizer proposes
values and the minimizer substitutes them for variables of his choice. When the
expression is fully instantiated, its value is compared with a certain minimax
value that would result if the players played to their optimal strategies. The
winner is declared based on this comparison.
  We use a game tree to represent the state of the game and show how the
minimax value can be computed efficiently using backward induction and
alpha-beta pruning. The efficacy of alpha-beta pruning depends on the order in
which the nodes are evaluated. Further improvements can be obtained by using
transposition tables to prevent reevaluation of the same nodes. We propose a
heuristic for node ordering. We show how the use of the heuristic and
transposition tables lead to improved performance by comparing the number of
nodes pruned by each method.
  We describe some domain-specific variants of this game. The first is a graph
theoretic formulation wherein two players share a set of elements of a graph by
coloring a related set with each player looking to maximize his share. The set
being shared could be either the set of vertices, edges or faces (for a planar
graph). An application of this is the sharing of regions enclosed by a planar
graph where each player's aim is to maximize the area of his share. Another
variant is a tiling game where the players alternately place dominoes on a $8
\times 8$ checkerboard to construct a maximal partial tiling. We show that the
size of the tiling $x$ satisfies $22 \le x \le 32$ by proving that any maximal
partial tiling requires at least $22$ dominoes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0863</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0863</id><created>2012-02-03</created><updated>2012-02-21</updated><authors><author><keyname>Sahebi</keyname><forenames>Aria G.</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>Asymptotically Good Codes Over Non-Abelian Groups</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown that good structured codes over non-Abelian groups do
exist. Specifically, we construct codes over the smallest non-Abelian group
$\mathds{D}_6$ and show that the performance of these codes is superior to the
performance of Abelian group codes of the same alphabet size. This promises the
possibility of using non-Abelian codes for multi-terminal settings where the
structure of the code can be exploited to gain performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0864</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0864</id><created>2012-02-03</created><updated>2012-03-17</updated><authors><author><keyname>Sahebi</keyname><forenames>Aria G.</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>Nested Lattice Codes for Arbitrary Continuous Sources and Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that nested lattice codes achieve the capacity of
arbitrary channels with or without non-casual state information at the
transmitter. We also show that nested lattice codes are optimal for source
coding with or without non-causal side information at the receiver for
arbitrary continuous sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0865</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0865</id><created>2012-02-03</created><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>A Compression Algorithm Using Mis-aligned Side-information</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, 1 table. A shorter version is submitted to IEEE
  International Symposium on Information Theory (ISIT), 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of compressing a source sequence in the presence of
side-information that is related to the source via insertions, deletions and
substitutions. We propose a simple algorithm to compress the source sequence
when the side-information is present at both the encoder and decoder. A key
attribute of the algorithm is that it encodes the edits contained in runs of
different extents separately. For small insertion and deletion probabilities,
the compression rate of the algorithm is shown to be asymptotically optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0866</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0866</id><created>2012-02-03</created><authors><author><keyname>Mahdavifar</keyname><forenames>Hessam</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>List-decoding of Subspace Codes and Rank-Metric Codes up to Singleton
  Bound</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subspace codes and rank-metric codes can be used to correct errors and
erasures in network, with linear network coding. Subspace codes were introduced
by Koetter and Kschischang to correct errors and erasures in networks where
topology is unknown (the noncoherent case). In a previous work, we have
developed a family of subspace codes, based upon the Koetter-Kschichang
construction, which are efficiently list decodable. Using these codes, we
achieved a better decoding radius than Koetter-Kschischiang codes at low rates.
Herein, we introduce a new family of subspace codes based upon a different
approach which leads to a linear-algebraic list-decoding algorithm. The
resulting error correction radius can be expressed as follows: for any integer
$s$, our list-decoder using $s+1$-interpolation polynomials guarantees
successful recovery of the message subspace provided the normalized dimension
of errors is at most $s(1-sR)$. The same list-decoding algorithm can be used to
correct erasures as well as errors. The size of output list is at most
$Q^{s-1}$, where $Q$ is the size of the field that message symbols are chosen
from. Rank-metric codes are suitable for error correction in the case where the
network topology and the underlying network code are known (the coherent case).
Gabidulin codes are a well-known class of algebraic rank-metric codes that meet
the Singleton bound on the minimum rank metric of a code. In this paper, we
introduce a folded version of Gabidulin codes analogous to the folded
Reed-Solomon codes of Guruswami and Rudra along with a list-decoding algorithm
for such codes. Our list-decoding algorithm makes it possible to recover the
message provided that the normalized rank of error is at most $1-R-\epsilon$,
for any $\epsilon &gt; 0$. Notably this achieves the information theoretic bound
on the decoding radius of a rank-metric code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0867</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0867</id><created>2012-02-03</created><updated>2012-03-25</updated><authors><author><keyname>Canas</keyname><forenames>Guillermo D.</forenames></author></authors><title>Practical Conditions for Well-behaved-ness of Anisotropic Voronoi
  Diagrams</title><categories>cs.CG</categories><comments>11 pages, 0 figures</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, simple conditions for well-behaved-ness of anisotropic Voronoi
diagrams have been proposed. While these conditions ensure well-behaved-ness of
two types of practical anisotropic Voronoi diagrams, as well as the
geodesic-distance one, in any dimension, they are both prohibitively expensive
to evaluate, and not well-suited for typical problems in approximation or
optimization. We propose simple conditions that can be efficiently evaluated,
and are better suited to practical problems of approximation and optimization.
The practical utility of this analysis is enhanced by the fact that orphan-free
anisotropic Voronoi diagrams have embedded triangulations as duals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0871</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0871</id><created>2012-02-04</created><updated>2012-05-18</updated><authors><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>Channel Capacity under General Nonuniform Sampling</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in IEEE International Symposium on Information
  Theory (ISIT), 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops the fundamental capacity limits of a sampled analog
channel under a sub-Nyquist sampling rate constraint. In particular, we derive
the capacity of sampled analog channels over a general class of time-preserving
sampling methods including irregular nonuniform sampling. Our results indicate
that the optimal sampling structures extract out the set of frequencies that
exhibits the highest SNR among all spectral sets of support size equal to the
sampling rate. The capacity under sub-Nyquist sampling can be attained through
filter-bank sampling, or through a single branch of modulation and filtering
followed by uniform sampling. The capacity under sub-Nyquist sampling is a
monotone function of the sampling rate. These results indicate that the optimal
sampling schemes suppress aliasing, and that employing irregular nonuniform
sampling does not provide capacity gain over uniform sampling sets with
appropriate preprocessing for a large class of channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0876</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0876</id><created>2012-02-04</created><authors><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author><author><keyname>Fujii</keyname><forenames>Yuki</forenames></author></authors><title>A Coding Theoretic Approach for Evaluating Accumulate Distribution on
  Minimum Cut Capacity of Weighted Random Graphs</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to IEEE ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multicast capacity of a directed network is closely related to the
$s$-$t$ maximum flow, which is equal to the $s$-$t$ minimum cut capacity due to
the max-flow min-cut theorem. If the topology of a network (or link capacities)
is dynamically changing or have stochastic nature, it is not so trivial to
predict statistical properties on the maximum flow. In this paper, we present a
coding theoretic approach for evaluating the accumulate distribution of the
minimum cut capacity of weighted random graphs. The main feature of our
approach is to utilize the correspondence between the cut space of a graph and
a binary LDGM (low-density generator-matrix) code with column weight 2. The
graph ensemble treated in the paper is a weighted version of
Erd\H{o}s-R\'{e}nyi random graph ensemble. The main contribution of our work is
a combinatorial lower bound for the accumulate distribution of the minimum cut
capacity. From some computer experiments, it is observed that the lower bound
derived here reflects the actual statistical behavior of the minimum cut
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0884</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0884</id><created>2012-02-04</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author></authors><title>Cyber-Insurance in Internet Security: A Dig into the Information
  Asymmetry Problem</title><categories>cs.CR</categories><comments>arXiv admin note: substantial text overlap with arXiv:1103.1552</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet users such as individuals and organizations are subject to different
types of epidemic risks such as worms, viruses, spams, and botnets. To reduce
the probability of risk, an Internet user generally invests in traditional
security mechanisms like anti-virus and anti-spam software, sometimes also
known as \emph{self-defense} mechanisms. However, according to security
experts, such software (and their subsequent advancements) will not completely
eliminate risk. Recent research efforts have considered the problem of residual
risk elimination by proposing the idea of \emph{cyber-insurance}. In this
regard, an important research problem is resolving information asymmetry issues
associated with cyber-insurance contracts. In this paper we propose
\emph{three} mechanisms to resolve information asymmetry in cyber-insurance.
Our mechanisms are based on the \emph{Principal-Agent} (PA) model in
microeconomic theory. We show that (1) optimal cyber-insurance contracts
induced by our mechanisms only provide partial coverage to the insureds. This
ensures greater self-defense efforts on the part of the latter to protect their
computing systems, which in turn increases overall network security, (2) the
level of deductible per network user contract increases in a concave manner
with the topological degree of the user, and (3) a market for cyber-insurance
can be made to exist in the presence of monopolistic insurers under effective
mechanism design. Our methodology is applicable to any distributed network
scenario in which a framework for cyber-insurance can be implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0885</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0885</id><created>2012-02-04</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author></authors><title>The Impact of Secure OSs on Internet Security: What Cyber-Insurers Need
  to Know</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, researchers have proposed \emph{cyber-insurance} as a
suitable risk-management technique for enhancing security in Internet-like
distributed systems. However, amongst other factors, information asymmetry
between the insurer and the insured, and the inter-dependent and correlated
nature of cyber risks have contributed in a big way to the failure of
cyber-insurance markets. Security experts have argued in favor of operating
system (OS) platform switching (ex., from Windows to Unix-based OSs) or secure
OS adoption as being one of the techniques that can potentially mitigate the
problems posing a challenge to successful cyber-insurance markets. In this
regard we model OS platform switching dynamics using a \emph{social gossip}
mechanism and study three important questions related to the nature of the
dynamics, for Internet-like distributed systems: (i) which type of networks
should cyber-insurers target for insuring?, (ii) what are the bounds on the
asymptotic performance level of a network, where the performance parameter is
an average function of the long-run individual user willingness to adopt secure
OSs?, and (iii) how can cyber-insurers use the topological information of their
clients to incentivize/reward them during offering contracts? Our analysis is
important to a profit-minded cyber-insurer, who wants to target the right
network, design optimal contracts to resolve information asymmetry problems,
and at the same time promote the increase of overall network security through
increasing secure OS adoption amongst users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0895</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0895</id><created>2012-02-04</created><authors><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Kourtellaris</keyname><forenames>Christos K.</forenames></author></authors><title>Causal Rate Distortion Function on Abstract Alphabets: Optimal
  Reconstruction and Properties</title><categories>cs.IT math.FA math.IT math.PR</categories><comments>5 pages, Submitted to Internation Symposium on Information
  Theory(ISIT) 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A causal rate distortion function with a general fidelity criterion is
formulated on abstract alphabets and a coding theorem is derived. Existence of
the minimizing kernel is shown using the topology of weak convergence of
probability measures. The optimal reconstruction kernel is derived, which is
causal, and certain properties of the causal rate distortion function are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0898</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0898</id><created>2012-02-04</created><authors><author><keyname>Gohari</keyname><forenames>Amin</forenames></author><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>On Marton's inner bound for broadcast channels</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Marton's inner bound is the best known achievable region for a general
discrete memoryless broadcast channel. To compute Marton's inner bound one has
to solve an optimization problem over a set of joint distributions on the input
and auxiliary random variables. The optimizers turn out to be structured in
many cases. Finding properties of optimizers not only results in efficient
evaluation of the region, but it may also help one to prove factorization of
Marton's inner bound (and thus its optimality). The first part of this paper
formulates this factorization approach explicitly and states some conjectures
and results along this line. The second part of this paper focuses primarily on
the structure of the optimizers. This section is inspired by a new binary
inequality that recently resulted in a very simple characterization of the
sum-rate of Marton's inner bound for binary input broadcast channels. This
prompted us to investigate whether this inequality can be extended to larger
cardinality input alphabets. We show that several of the results for the binary
input case do carry over for higher cardinality alphabets and we present a
collection of results that help restrict the search space of probability
distributions to evaluate the boundary of Marton's inner bound in the general
case. We also prove a new inequality for the binary skew-symmetric broadcast
channel that yields a very simple characterization of the entire Marton inner
bound for this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0904</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0904</id><created>2012-02-04</created><authors><author><keyname>Gabbay</keyname><forenames>Murdoch</forenames></author><author><keyname>Nanevski</keyname><forenames>Aleksandar</forenames></author></authors><title>Denotation of syntax and metaprogramming in contextual modal type theory
  (CMTT)</title><categories>cs.LO math.LO</categories><msc-class>03B70, 03B45, 68Q55</msc-class><acm-class>F.4.1; F.3.2</acm-class><doi>10.1016/j.jal.2012.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modal logic S4 can be used via a Curry-Howard style correspondence to
obtain a lambda-calculus. Modal (boxed) types are intuitively interpreted as
`closed syntax of the calculus'. This lambda-calculus is called modal type
theory --- this is the basic case of a more general contextual modal type
theory, or CMTT.
  CMTT has never been given a denotational semantics in which modal types are
given denotation as closed syntax. We show how this can indeed be done, with a
twist. We also use the denotation to prove some properties of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0911</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0911</id><created>2012-02-04</created><updated>2012-07-06</updated><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Daniel</forenames></author><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames></author></authors><title>Toroidal maps : Schnyder woods, orthogonal surfaces and straight-line
  representations</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Schnyder wood is an orientation and coloring of the edges of a planar map
satisfying a simple local property. We propose a generalization of Schnyder
woods to graphs embedded on the torus with application to graph drawing. We
prove several properties on this new object. Among all we prove that a graph
embedded on the torus admits such a Schnyder wood if and only if it is an
essentially 3-connected toroidal map. We show that these Schnyder woods can be
used to embed the universal cover of an essentially 3-connected toroidal map on
an infinite and periodic orthogonal surface. Finally we use this embedding to
obtain a straight-line flat torus representation of any toroidal map in a
polynomial size grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0914</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0914</id><created>2012-02-04</created><updated>2012-02-23</updated><authors><author><keyname>Rudolph</keyname><forenames>Sebastian</forenames><affiliation>Karlsruhe Institute of Technology</affiliation></author><author><keyname>Kr&#xf6;tzsch</keyname><forenames>Markus</forenames><affiliation>Oxford University</affiliation></author><author><keyname>Hitzler</keyname><forenames>Pascal</forenames><affiliation>Wright State University, Dayton, Ohio</affiliation></author></authors><title>Type-elimination-based reasoning for the description logic SHIQbs using
  decision diagrams and disjunctive datalog</title><categories>cs.LO cs.AI math.LO</categories><comments>38 pages, 3 figures, camera ready version of paper accepted for
  publication in Logical Methods in Computer Science</comments><proxy>LMCS</proxy><acm-class>I.2.4, I.2.3, F.4.3, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  27, 2012) lmcs:806</journal-ref><doi>10.2168/LMCS-8(1:12)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel, type-elimination-based method for reasoning in the
description logic SHIQbs including DL-safe rules. To this end, we first
establish a knowledge compilation method converting the terminological part of
an ALCIb knowledge base into an ordered binary decision diagram (OBDD) which
represents a canonical model. This OBDD can in turn be transformed into
disjunctive Datalog and merged with the assertional part of the knowledge base
in order to perform combined reasoning. In order to leverage our technique for
full SHIQbs, we provide a stepwise reduction from SHIQbs to ALCIb that
preserves satisfiability and entailment of positive and negative ground facts.
The proposed technique is shown to be worst case optimal w.r.t. combined and
data complexity and easily admits extensions with ground conjunctive queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0915</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0915</id><created>2012-02-04</created><authors><author><keyname>Hofmann</keyname><forenames>Dirk</forenames></author><author><keyname>Martins</keyname><forenames>Manuel A.</forenames></author></authors><title>On a coalgebraic view on Logic</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present methods of transition from one perspective on logic
to others, and apply this in particular to obtain a coalgebraic presentation of
logic. The central ingredient in this process is to view consequence relations
as morphisms in a category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0919</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0919</id><created>2012-02-04</created><authors><author><keyname>Dang</keyname><forenames>Wenbing</forenames></author><author><keyname>Pezeshki</keyname><forenames>Ali</forenames></author><author><keyname>Howard</keyname><forenames>Stephen</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Coordinating Complementary Waveforms for Sidelobe Suppression</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general method for constructing radar transmit pulse trains and
receive filters for which the radar point-spread function in delay and Doppler,
given by the cross-ambiguity function of the transmit pulse train and the pulse
train used in the receive filter, is essentially free of range sidelobes inside
a Doppler interval around the zero-Doppler axis. The transmit pulse train is
constructed by coordinating the transmission of a pair of Golay complementary
waveforms across time according to zeros and ones in a binary sequence P. The
pulse train used to filter the received signal is constructed in a similar way,
in terms of sequencing the Golay waveforms, but each waveform in the pulse
train is weighted by an element from another sequence Q. We show that a
spectrum jointly determined by P and Q sequences controls the size of the range
sidelobes of the cross-ambiguity function and by properly choosing P and Q we
can clear out the range sidelobes inside a Doppler interval around the zero-
Doppler axis. The joint design of P and Q enables a tradeoff between the order
of the spectral null for range sidelobe suppression and the signal-to-noise
ratio at the receiver output. We establish this trade-off and derive a
necessary and sufficient condition for the construction of P and Q sequences
that produce a null of a desired order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0920</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0920</id><created>2012-02-04</created><updated>2012-04-17</updated><authors><author><keyname>Boisberranger</keyname><forenames>J&#xe9;r&#xe9;mie Du</forenames><affiliation>PRISM</affiliation></author><author><keyname>Gardy</keyname><forenames>Dani&#xe8;le</forenames><affiliation>PRISM</affiliation></author><author><keyname>Ponty</keyname><forenames>Yann</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author></authors><title>The weighted words collector</title><categories>cs.DM</categories><proxy>ccsd</proxy><journal-ref>AOFA - 23rd International Meeting on Probabilistic, Combinatorial
  and Asymptotic Methods for the Analysis of Algorithms - 2012 (2012) TBA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications in bioinformatics, we consider the word collector
problem, i.e. the expected number of calls to a random weighted generator of
words of length $n$ before the full collection is obtained. The originality of
this instance of the non-uniform coupon collector lies in the, potentially
large, multiplicity of the words/coupons of a given probability/composition. We
obtain a general theorem that gives an asymptotic equivalent for the expected
waiting time of a general version of the Coupon Collector. This theorem is
especially well-suited for classes of coupons featuring high multiplicities.
Its application to a given language essentially necessitates some knowledge on
the number of words of a given composition/probability. We illustrate the
application of our theorem, in a step-by-step fashion, on three exemplary
languages, revealing asymptotic regimes in $\Theta(\mu(n)\cdot n)$ and
$\Theta(\mu(n)\cdot \log n)$, where $\mu(n)$ is the sum of weights over words
of length $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0922</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0922</id><created>2012-02-04</created><updated>2014-08-14</updated><authors><author><keyname>Abraham</keyname><forenames>Ittai</forenames></author><author><keyname>Chechik</keyname><forenames>Shiri</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Low-distortion Inference of Latent Similarities from a Multiplex Social
  Network</title><categories>cs.SI cs.DS physics.soc-ph</categories><comments>51 pages. Compared to the previous version: many small changes to
  improve presentation and clarity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of social network analysis is - implicitly or explicitly - predicated on
the assumption that individuals tend to be more similar to their friends than
to strangers. Thus, an observed social network provides a noisy signal about
the latent underlying &quot;social space:&quot; the way in which individuals are similar
or dissimilar. Many research questions frequently addressed via social network
analysis are in reality questions about this social space, raising the question
of inverting the process: Given a social network, how accurately can we
reconstruct the social structure of similarities and dissimilarities?
  We begin to address this problem formally. Observed social networks are
usually multiplex, in the sense that they reflect (dis)similarities in several
different &quot;categories,&quot; such as geographical proximity, kinship, or similarity
of professions/hobbies. We assume that each such category is characterized by a
latent metric capturing (dis)similarities in this category. Each category gives
rise to a separate social network: a random graph parameterized by this metric.
For a concrete model, we consider Kleinberg's small world model and some
variations thereof. The observed social network is the unlabeled union of these
graphs, i.e., the presence or absence of edges can be observed, but not their
origins. Our main result is an algorithm which reconstructs each metric with
provably low distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0925</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0925</id><created>2012-02-04</created><authors><author><keyname>Farnoud</keyname><forenames>Farzad</forenames><affiliation>Hassanzadeh</affiliation></author><author><keyname>Santhanam</keyname><forenames>Narayana P.</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Alternating Markov Chains for Distribution Estimation in the Presence of
  Errors</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of small-sample distribution estimators over noisy
channels. Our estimators are designed for repetition channels, and rely on
properties of the runs of the observed sequences. These runs are modeled via a
special type of Markov chains, termed alternating Markov chains. We show that
alternating chains have redundancy that scales sub-linearly with the lengths of
the sequences, and describe how to use a distribution estimator for alternating
chains for the purpose of distribution estimation over repetition channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0932</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0932</id><created>2012-02-04</created><updated>2013-04-21</updated><authors><author><keyname>Farnoud</keyname><forenames>Farzad</forenames><affiliation>Hassanzadeh</affiliation></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Error-Correction in Flash Memories via Codes in the Ulam Metric</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider rank modulation codes for flash memories that allow for handling
arbitrary charge-drop errors. Unlike classical rank modulation codes used for
correcting errors that manifest themselves as swaps of two adjacently ranked
elements, the proposed \emph{translocation rank codes} account for more general
forms of errors that arise in storage systems. Translocations represent a
natural extension of the notion of adjacent transpositions and as such may be
analyzed using related concepts in combinatorics and rank modulation coding.
Our results include derivation of the asymptotic capacity of translocation rank
codes, construction techniques for asymptotically good codes, as well as simple
decoding methods for one class of constructed codes. As part of our exposition,
we also highlight the close connections between the new code family and
permutations with short common subsequences, deletion and insertion
error-correcting codes for permutations, and permutation codes in the Hamming
distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0934</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0934</id><created>2012-02-04</created><authors><author><keyname>Choudhuri</keyname><forenames>Chiranjib</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Action Dependent Strictly Causal State Communication</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of communication and state estimation is considered in the
context of channels with actiondependent states. Given the message to be
communicated, the transmitter chooses an action sequence that affects the
formation of the channel states, and then creates the channel input sequence
based on the state sequence. The decoder estimates the channel to some
distortion as well as decodes the message. The capacity-distortion tradeoff of
such a channel is characterized for the case when the state information is
available strictly causally at the channel encoder. The problem setting extends
the action dependent framework of [1] and as a special case recovers the
results of few previously considered joint communication and estimation
scenarios in [2], [3], [4]. The scenario when the action is also allowed to
depend on the past observed states (adaptive action) is also considered. It is
shown that such adaptive action yields an improved capacity-distortion
function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0936</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0936</id><created>2012-02-04</created><authors><author><keyname>Ghosh</keyname><forenames>Abhishek</forenames></author><author><keyname>Pamarti</keyname><forenames>Sudhakar</forenames></author></authors><title>Dithered quantizers with negligible in-band dither power</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subtractive dithered quantizers are examined to minimize the signal-band
dither power. The design of finite impulse response(FIR) filters that shape
most of the dither-power out of the signal band while maintaining the benefits
of dithering are dealt with in detail. Simulation results for low-medium
resolution quantizers are presented to highlight the overall design
consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0937</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0937</id><created>2012-02-04</created><updated>2012-05-30</updated><authors><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Arias-Castro</keyname><forenames>Ery</forenames></author></authors><title>Compressive binary search</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of locating a nonzero entry in a
high-dimensional vector from possibly adaptive linear measurements. We consider
a recursive bisection method which we dub the compressive binary search and
show that it improves on what any nonadaptive method can achieve. We also
establish a non-asymptotic lower bound that applies to all methods, regardless
of their computational complexity. Combined, these results show that the
compressive binary search is within a double logarithmic factor of the optimal
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0940</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0940</id><created>2012-02-04</created><authors><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author><author><keyname>Maan</keyname><forenames>Akshay</forenames></author></authors><title>Improving feature selection algorithms using normalised feature
  histograms</title><categories>cs.AI cs.CV</categories><journal-ref>Electronics Letters,47, 8, 490-491, 2011</journal-ref><doi>10.1049/el.2010.3672</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The proposed feature selection method builds a histogram of the most stable
features from random subsets of a training set and ranks the features based on
a classifier based cross-validation. This approach reduces the instability of
features obtained by conventional feature selection methods that occur with
variation in training data and selection criteria. Classification results on
four microarray and three image datasets using three major feature selection
criteria and a naive Bayes classifier show considerable improvement over
benchmark results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0946</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0946</id><created>2012-02-05</created><authors><author><keyname>Vladimirov</keyname><forenames>Igor G.</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Gaussian Stochastic Linearization for Open Quantum Systems Using
  Quadratic Approximation of Hamiltonians</title><categories>quant-ph cs.SY math.OC math.PR</categories><comments>27 pages, 1 figure, 5 appendices, submitted (in a brief form) to MTNS
  2012, Melbourne, Victoria</comments><msc-class>81S22, 81S25, 81S30, 93B18, 93B28, 93E24</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the energy-based version of the stochastic linearization
method, known for classical nonlinear systems, to open quantum systems with
canonically commuting dynamic variables governed by quantum stochastic
differential equations with non-quadratic Hamiltonians. The linearization
proceeds by approximating the actual Hamiltonian of the quantum system by a
quadratic function of its observables which corresponds to the Hamiltonian of a
quantum harmonic oscillator. This approximation is carried out in a mean square
optimal sense with respect to a Gaussian reference quantum state and leads to a
self-consistent linearization procedure where the mean vector and quantum
covariance matrix of the system observables evolve in time according to the
effective linear dynamics. We demonstrate the proposed Hamiltonian-based
Gaussian linearization for the quantum Duffing oscillator whose Hamiltonian is
a quadro-quartic polynomial of the momentum and position operators. The results
of the paper are applicable to the design of suboptimal controllers and filters
for nonlinear quantum systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0958</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0958</id><created>2012-02-05</created><updated>2012-05-19</updated><authors><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author></authors><title>Directed Information on Abstract spaces: Properties and Extremum
  Problems</title><categories>cs.IT math.FA math.IT math.PR</categories><comments>5 pages, to appear in proceedings of International Symposium on
  Information Theory (ISIT), 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper describes a framework in which directed information is defined on
abstract spaces. The framework is employed to derive properties of directed
information such as convexity, concavity, lower semicontinuity, by using the
topology of weak convergence of probability measures on Polish spaces. Two
extremum problems of directed information related to capacity of channels with
memory and feedback, and non-anticipative and sequential rate distortion are
analyzed showing existence of maximizing and minimizing distributions,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0959</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0959</id><created>2012-02-05</created><updated>2012-02-07</updated><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author></authors><title>A New Random Coding Technique that Generalizes Superposition Coding and
  Binning</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proving capacity for networks without feedback or cooperation usually
involves two fundamental random coding techniques: superposition coding and
binning. Although conceptually very different, these two techniques often
achieve the same performance, suggesting an underlying similarity. In this
correspondence we propose a new random coding technique that generalizes
superposition coding and binning and provides new insight on relationship among
the two With this new theoretical tool, we derive new achievable regions for
three classical information theoretical models: multi-access channel, broadcast
channel, the interference channel, and show that, unfortunately, it does not
improve over the largest known achievable regions for these cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0961</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0961</id><created>2012-02-05</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author></authors><title>On the Capacity of a General Multiple-Access Channel and of a Cognitive
  Network in the Very Strong Interference Regime</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of the multiple-access channel with any distribution of messages
among the transmitting nodes was determined by Han in 1979 and the expression
of the capacity region contains a number of rate bounds and that grows
exponentially with the number of messages. We derive a more compact expression
for the capacity region of this channel in which the number of rate bounds
depends on the distribution of the messages at the encoders. Using this
expression we prove capacity for a class of general cognitive network that we
denote as &quot;very strong interference&quot; regime. In this regime there is no rate
loss in having all the receivers decode all the messages and the capacity
region reduces to the capacity of the compound multiple-access channel. This
result generalizes the &quot;very strong interference&quot; capacity results for the
interference channel, the cognitive interference channel, the interference
channel with a cognitive relay and many others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0969</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0969</id><created>2012-02-05</created><updated>2012-04-04</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Tamuz</keyname><forenames>Omer</forenames></author></authors><title>Bundling Customers: How to Exploit Trust Among Customers to Maximize
  Seller Profit</title><categories>cs.GT</categories><comments>11 pages, 1 figure. After posting the first version of this paper we
  learned that much of its mathematical content already appears in the
  literature, for example in &quot;Multiproduct nonlinear pricing&quot; by Armstrong
  (1996), although in a slightly different context of bundling products, rather
  than customers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an auction of identical digital goods to customers whose
valuations are drawn independently from known distributions. Myerson's classic
result identifies the truthful mechanism that maximizes the seller's expected
profit.
  Under the assumption that in small groups customers can learn each others'
valuations, we show how Myerson's result can be improved to yield a higher
payoff to the seller using a mechanism that offers groups of customers to buy
bundles of items.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0970</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0970</id><created>2012-02-05</created><authors><author><keyname>Spillner</keyname><forenames>Josef</forenames></author><author><keyname>Schill</keyname><forenames>Alexander</forenames></author></authors><title>{\pi}-Control: A Personal Cloud Control Centre</title><categories>cs.DC</categories><comments>Position paper: 4 pages, 5 figures; Russian translation available in
  the source archive</comments><acm-class>C.2.4; H.3.5; K.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consumption of online services and cloud computing offerings is on the rise,
largely due to compelling advantages over traditional local applications. From
a user perspective, these include zero-maintenance of software, the always-on
nature of such services, mashups of different applications and the networking
effect with other users. Associated disadvantages are known, but effective
means and tools to limit their effect are not yet well-established and not yet
generally available to service users. We propose (1) a user-centric model of
cloud elements beyond the conventional &lt;SPI&gt;aaS layers, including activities
across trust zones, and (2) a personal control console for all individual and
collaborative user activities in the cloud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0977</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0977</id><created>2012-02-05</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Huppert</keyname><forenames>Carolin</forenames></author></authors><title>The Capacity of the Semi-Deterministic Cognitive Interference Channel
  with a Common Cognitive Message and Approximate Capacity for the Gaussian
  Case</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the study of the cognitive interference channel with a common
message, a variation of the classical cognitive interference channel in which
the cognitive message is decoded at both receivers. We derive the capacity for
the semideterministic channel in which the output at the cognitive decoder is a
deterministic function of the channel inputs. We also show capacity to within a
constant gap and a constant factor for the Gaussian channel in which the
outputs are linear combinations of the channel inputs plus an additive Gaussian
noise term. Most of these results are shown using an interesting transmission
scheme in which the cognitive message, decoded at both receivers, is also
pre-coded against the interference experienced at the cognitive decoder. The
pre-coding of the cognitive message does not allow the primary decoder to
reconstruct the interfering signal. The cognitive message acts instead as a
side information at the primary receiver when decoding its intended message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0979</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0979</id><created>2012-02-05</created><updated>2012-05-20</updated><authors><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Nozaki</keyname><forenames>Takayuki</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Spatially-Coupled Binary MacKay-Neal Codes for Channels with Non-Binary
  Inputs and Affine Subspace Outputs</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study LDPC codes for the channel with $2^m$-ary input $\underline{x}\in
\mathbb{F}_2^m$ and output $\underline{y}=\underline{x}+\underline{z}\in
\mathbb{F}_2^m$. The receiver knows a subspace $V\subset \mathbb{F}_2^m$ from
which $\underline{z}=\underline{y}-\underline{x}$ is uniformly chosen. Or
equivalently, the receiver receives an affine subspace $\underline{y}-V$ where
$\underline{x}$ lies. We consider a joint iterative decoder involving the
channel detector and the LDPC decoder. The decoding system considered in this
paper can be viewed as a simplified model of the joint iterative decoder over
non-binary modulated signal inputs e.g., $2^m$-QAM. We evaluate the performance
of binary spatially-coupled MacKay-Neal codes by density evolution. The
iterative decoding threshold is seriously degraded by increasing $m$. EXIT-like
function curve calculations reveal that this degradation is caused by wiggles
and can be mitigated by increasing the randomized window size. The resultant
iterative decoding threshold values are very close to the Shannon limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0984</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0984</id><created>2012-02-01</created><authors><author><keyname>Glimm</keyname><forenames>Birte</forenames></author><author><keyname>Hogan</keyname><forenames>Aidan</forenames></author><author><keyname>Kr&#xf6;tzsch</keyname><forenames>Markus</forenames></author><author><keyname>Polleres</keyname><forenames>Axel</forenames></author></authors><title>OWL: Yet to arrive on the Web of Data?</title><categories>cs.DL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seven years on from OWL becoming a W3C recommendation, and two years on from
the more recent OWL 2 W3C recommendation, OWL has still experienced only patchy
uptake on the Web. Although certain OWL features (like owl:sameAs) are very
popular, other features of OWL are largely neglected by publishers in the
Linked Data world. This may suggest that despite the promise of easy
implementations and the proposal of tractable profiles suggested in OWL's
second version, there is still no &quot;right&quot; standard fragment for the Linked Data
community. In this paper, we (1) analyse uptake of OWL on the Web of Data, (2)
gain insights into the OWL fragment that is actually used/usable on the Web,
where we arrive at the conclusion that this fragment is likely to be a
simplified profile based on OWL RL, (3) propose and discuss such a new
fragment, which we call OWL LD (for Linked Data).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0988</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0988</id><created>2012-02-05</created><updated>2012-02-06</updated><authors><author><keyname>Di Pierro</keyname><forenames>Massimo</forenames></author></authors><title>Improving non-linear fits</title><categories>cs.NA hep-lat</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this notes we describe an algorithm for non-linear fitting which
incorporates some of the features of linear least squares into a general
minimum $\chi^2$ fit and provide a pure Python implementation of the algorithm.
It consists of the variable projection method (varpro), combined with a Newton
optimizer and stabilized using the steepest descent with an adaptative step.
The algorithm includes a term to account for Bayesian priors. We performed
tests of the algorithm using simulated data. This method is suitable, for
example, for fitting with sums of exponentials as often needed in Lattice
Quantum Chromodynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.0992</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.0992</id><created>2012-02-05</created><authors><author><keyname>Han</keyname><forenames>Sunghyu</forenames></author><author><keyname>Kim</keyname><forenames>Jon-Lark</forenames></author></authors><title>Computational Results of Duadic Double Circulant Codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>12 pages, 5 tabels, to appear in J. of Applied Mathematics and
  Computing</comments><msc-class>94B05 (Primary) 11T71, 05E99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadratic residue codes have been one of the most important classes of
algebraic codes. They have been generalized into duadic codes and quadratic
double circulant codes. In this paper we introduce a new subclass of double
circulant codes, called {\em{duadic double circulant codes}}, which is a
generalization of quadratic double circulant codes for prime lengths. This
class generates optimal self-dual codes, optimal linear codes, and linear codes
with the best known parameters in a systematic way. We describe a method to
construct duadic double circulant codes using 4-cyclotomic cosets and give
certain duadic double circulant codes over $\mathbb F_2, \mathbb F_3, \mathbb
F_4, \mathbb F_5$, and $\mathbb F_7$. In particular, we find a new ternary
self-dual $[76,38,18]$ code and easily rediscover optimal binary self-dual
codes with parameters $[66,33,12]$, $[68,34,12]$, $[86,43,16]$, and
$[88,44,16]$ as well as a formally self-dual binary $[82,41,14]$ code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1041</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1041</id><created>2012-02-05</created><authors><author><keyname>Kloks</keyname><forenames>Ton</forenames></author></authors><title>Packing interval graphs with vertex-disjoint triangles</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there exists a polynomial algorithm to pack interval graphs with
vertex-disjoint triangles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1046</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1046</id><created>2012-02-05</created><authors><author><keyname>Akbari</keyname><forenames>Saieed</forenames></author><author><keyname>Kim</keyname><forenames>Jaehoon</forenames></author><author><keyname>Kostochka</keyname><forenames>Alexandr</forenames></author></authors><title>Harmonious Coloring of Trees with Large Maximum Degree</title><categories>math.CO cs.DM</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A harmonious coloring of $G$ is a proper vertex coloring of $G$ such that
every pair of colors appears on at most one pair of adjacent vertices. The
harmonious chromatic number of $G$, $h(G)$, is the minimum number of colors
needed for a harmonious coloring of $G$. We show that if $T$ is a forest of
order $n$ with maximum degree $\Delta(T)\geq \frac{n+2}{3}$, then $$h(T)=
  \Delta(T)+2, &amp; if $T$ has non-adjacent vertices of degree $\Delta(T)$;
  \Delta(T)+1, &amp; otherwise.
  $$ Moreover, the proof yields a polynomial-time algorithm for an optimal
harmonious coloring of such a forest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1050</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1050</id><created>2012-02-06</created><updated>2012-05-23</updated><authors><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Regenerating Codes for Errors and Erasures in Distributed Storage</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regenerating codes are a class of codes proposed for providing reliability of
data and efficient repair of failed nodes in distributed storage systems. In
this paper, we address the fundamental problem of handling errors and erasures
during the data-reconstruction and node-repair operations. We provide explicit
regenerating codes that are resilient to errors and erasures, and show that
these codes are optimal with respect to storage and bandwidth requirements. As
a special case, we also establish the capacity of a class of distributed
storage systems in the presence of malicious adversaries. While our code
constructions are based on previously constructed Product-Matrix codes, we also
provide necessary and sufficient conditions for introducing resilience in any
regenerating code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1054</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1054</id><created>2012-02-06</created><authors><author><keyname>Rudnick</keyname><forenames>Alex</forenames></author></authors><title>Considering a resource-light approach to learning verb valencies</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Here we describe work on learning the subcategories of verbs in a
morphologically rich language using only minimal linguistic resources. Our goal
is to learn verb subcategorizations for Quechua, an under-resourced
morphologically rich language, from an unannotated corpus. We compare results
from applying this approach to an unannotated Arabic corpus with those achieved
by processing the same text in treebank form. The original plan was to use only
a morphological analyzer and an unannotated corpus, but experiments suggest
that this approach by itself will not be effective for learning the
combinatorial potential of Arabic verbs in general. The lower bound on
resources for acquiring this information is somewhat higher, apparently
requiring a a part-of-speech tagger and chunker for most languages, and a
morphological disambiguater for Arabic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1055</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1055</id><created>2012-02-06</created><authors><author><keyname>McKerns</keyname><forenames>M.</forenames></author><author><keyname>Owhadi</keyname><forenames>H.</forenames></author><author><keyname>Scovel</keyname><forenames>C.</forenames></author><author><keyname>Sullivan</keyname><forenames>T. J.</forenames></author><author><keyname>Ortiz</keyname><forenames>M.</forenames></author></authors><title>The Optimal Uncertainty Algorithm in the Mystic Framework</title><categories>cs.DM cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have recently proposed a rigorous framework for Uncertainty Quantification
(UQ) in which UQ objectives and assumption/information set are brought into the
forefront, providing a framework for the communication and comparison of UQ
results. In particular, this framework does not implicitly impose inappropriate
assumptions nor does it repudiate relevant information. This framework, which
we call Optimal Uncertainty Quantification (OUQ), is based on the observation
that given a set of assumptions and information, there exist bounds on
uncertainties obtained as values of optimization problems and that these bounds
are optimal. It provides a uniform environment for the optimal solution of the
problems of validation, certification, experimental design, reduced order
modeling, prediction, extrapolation, all under aleatoric and epistemic
uncertainties. OUQ optimization problems are extremely large, and even though
under general conditions they have finite-dimensional reductions, they must
often be solved numerically. This general algorithmic framework for OUQ has
been implemented in the mystic optimization framework. We describe this
implementation, and demonstrate its use in the context of the Caltech surrogate
model for hypervelocity impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1056</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1056</id><created>2012-02-06</created><authors><author><keyname>McKerns</keyname><forenames>Michael M.</forenames></author><author><keyname>Strand</keyname><forenames>Leif</forenames></author><author><keyname>Sullivan</keyname><forenames>Tim</forenames></author><author><keyname>Fang</keyname><forenames>Alta</forenames></author><author><keyname>Aivazis</keyname><forenames>Michael A. G.</forenames></author></authors><title>Building a Framework for Predictive Science</title><categories>cs.MS cs.DC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key questions that scientists and engineers typically want to address can be
formulated in terms of predictive science. Questions such as: &quot;How well does my
computational model represent reality?&quot;, &quot;What are the most important
parameters in the problem?&quot;, and &quot;What is the best next experiment to perform?&quot;
are fundamental in solving scientific problems. Mystic is a framework for
massively-parallel optimization and rigorous sensitivity analysis that enables
these motivating questions to be addressed quantitatively as global
optimization problems. Often realistic physics, engineering, and materials
models may have hundreds of input parameters, hundreds of constraints, and may
require execution times of seconds or longer. In more extreme cases, realistic
models may be multi-scale, and require the use of high-performance computing
clusters for their evaluation. Predictive calculations, formulated as a global
optimization over a potential surface in design parameter space, may require an
already prohibitively large simulation to be performed hundreds, if not
thousands, of times. The need to prepare, schedule, and monitor thousands of
model evaluations, and dynamically explore and analyze results, is a
challenging problem that requires a software infrastructure capable of
distributing and managing computations on large-scale heterogeneous resources.
In this paper, we present the design behind an optimization framework, and also
a framework for heterogeneous computing, that when utilized together, can make
computationally intractable sensitivity and optimization problems much more
tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1060</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1060</id><created>2012-02-06</created><authors><author><keyname>Hsu</keyname><forenames>Yen-Cheng</forenames></author><author><keyname>Chang</keyname><forenames>Tofar C. -Y.</forenames></author><author><keyname>Su</keyname><forenames>Yu T.</forenames></author><author><keyname>Weng</keyname><forenames>Jian-Jia</forenames></author></authors><title>A Non-Disjoint Group Shuffled Decoding for LDPC Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, submitted to ISIT2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To reduce the implementation complexity of a belief propagation (BP) based
low-density parity-check (LDPC) decoder, shuffled BP decoding schedules, which
serialize the decoding process by dividing a complete parallel message-passing
iteration into a sequence of sub-iterations, have been proposed. The so-called
group horizontal shuffled BP algorithm partitions the check nodes of the code
graph into groups to perform group-by-group message-passing decoding. This
paper proposes a new grouping technique to accelerate the message-passing rate.
Performance of the proposed algorithm is analyzed by a Gaussian approximation
approach. Both analysis and numerical experiments verify that the new algorithm
does yield a convergence rate faster than that of existing conventional or
group shuffled BP decoder with the same computing complexity constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1062</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1062</id><created>2012-02-06</created><authors><author><keyname>Rastogi</keyname><forenames>Ravi</forenames></author><author><keyname>Nitin</keyname></author><author><keyname>Chauhan</keyname><forenames>Durg Singh</forenames></author><author><keyname>Govil</keyname><forenames>Mahesh Chandra</forenames></author></authors><title>On Stability Problems of Omega and 3-Disjoint Paths Omega Multi-stage
  Interconnection Networks</title><categories>cs.DC</categories><report-no>IJCSI-8-4-2-66-76</report-no><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, No 2, July 2011, 66-76</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research paper emphasizes that the Stable Matching problems are the same
as the problems of stable configurations of Multi-stage Interconnection
Networks (MIN). We have discusses the Stability Problems of Existing Regular
Omega Multi-stage Interconnection Network (OMIN) and Proposed 3-Disjoint Paths
Omega Multi-stage Interconnection Network (3DON) using the approaches and
solutions provided by the Stable Matching Problem. Specifically, Stable
Marriage Problem is used as an example of Stable Matching. On application of
the concept of the Stable Marriage over the MINs states that OMIN is highly
stable in comparison to 3DON.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1081</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1081</id><created>2012-02-06</created><authors><author><keyname>Lazich</keyname><forenames>Dejan E.</forenames></author><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>Some Comments on the Strong Simplex Conjecture</title><categories>cs.IT math.IT</categories><comments>Submitted to the 2012 IEEE International Symposium on Information
  Theory, Cambridge, MA, USA, July 1 - 6, 2012. 5 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the disproof of the Strong Simplex Conjecture presented in [Steiner,
1994], a counterexample signal set was found that has higher average
probability of correct optimal decoding than the corresponding regular simplex
signal set, when compared at small values of the signal-to-noise ratio. The
latter was defined as the quotient of average signal energy and average noise
power. In this paper, it is shown that this interpretation of the
signal-to-noise ratio is inappropriate for a comparison of signal sets, since
it leads to a contradiction with the Channel Coding Theorem. A modified
counterexample signal set is proposed and examined using the classical
interpretation of the signal-to-noise ratio, i.e., as the quotient of average
signal energy and average noise energy. This signal set outperforms the regular
simplex signal set for small signal-to-noise ratios without contradicting the
Channel Coding Theorem, hence the Strong Simplex Conjecture remains proven
false.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1083</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1083</id><created>2012-02-06</created><authors><author><keyname>Draief</keyname><forenames>Moez</forenames></author><author><keyname>Vojnovic</keyname><forenames>Milan</forenames></author></authors><title>Convergence Speed of Binary Interval Consensus</title><categories>math.PR cs.DM math.OC</categories><comments>To appear in SIAM Optimization and Control. Short version appeared in
  INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the convergence time for solving the binary consensus problem
using the interval consensus algorithm proposed by B\' en\' ezit, Thiran and
Vetterli (2009). In the binary consensus problem, each node initially holds one
of two states and the goal for each node is to correctly decide which one of
these two states was initially held by a majority of nodes.
  We derive an upper bound on the expected convergence time that holds for
arbitrary connected graphs, which is based on the location of eigenvalues of
some contact rate matrices. We instantiate our bound for particular networks of
interest, including complete graphs, paths, cycles, star-shaped networks, and
Erd\&quot; os-R\' enyi random graphs; for these graphs, we compare our bound with
alternative computations. We find that for all these examples our bound is
tight, yielding the exact order with respect to the number of nodes.
  We pinpoint the fact that the expected convergence time critically depends on
the voting margin defined as the difference between the fraction of nodes that
initially held the majority and the minority states, respectively. The
characterization of the expected convergence time yields exact relation between
the expected convergence time and the voting margin, for some of these graphs,
which reveals how the expected convergence time goes to infinity as the voting
margin approaches zero.
  Our results provide insights into how the expected convergence time depends
on the network topology which can be used for performance evaluation and
network design. The results are of interest in the context of networked
systems, in particular, peer-to-peer networks, sensor networks and distributed
databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1089</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1089</id><created>2012-02-06</created><authors><author><keyname>Draief</keyname><forenames>Moez</forenames></author><author><keyname>Vojnovic</keyname><forenames>Milan</forenames></author></authors><title>Bargaining Dynamics in Exchange Networks</title><categories>cs.GT math.OC</categories><comments>Short version appeared in Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dynamical system for computing Nash bargaining solutions on
graphs and focus on its rate of convergence. More precisely, we analyze the
edge-balanced dynamical system by Azar et al and fully specify its convergence
for an important class of elementary graph structures that arise in Kleinberg
and Tardos' procedure for computing a Nash bargaining solution on general
graphs. We show that all these dynamical systems are either linear or
eventually become linear and that their convergence times are quadratic in the
number of matched edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1090</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1090</id><created>2012-02-06</created><authors><author><keyname>Sen</keyname><forenames>Sandeep</forenames></author><author><keyname>Muralidhara</keyname><forenames>V. N.</forenames></author></authors><title>The covert set-cover problem with application to Network Discovery</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address a version of the set-cover problem where we do not know the sets
initially (and hence referred to as covert) but we can query an element to find
out which sets contain this element as well as query a set to know the
elements. We want to find a small set-cover using a minimal number of such
queries. We present a Monte Carlo randomized algorithm that approximates an
optimal set-cover of size $OPT$ within $O(\log N)$ factor with high probability
using $O(OPT \cdot \log^2 N)$ queries where $N$ is the input size.
  We apply this technique to the network discovery problem that involves
certifying all the edges and non-edges of an unknown $n$-vertices graph based
on layered-graph queries from a minimal number of vertices. By reducing it to
the covert set-cover problem we present an $O(\log^2 n)$-competitive Monte
Carlo randomized algorithm for the covert version of network discovery problem.
The previously best known algorithm has a competitive ratio of $\Omega
(\sqrt{n\log n})$ and therefore our result achieves an exponential improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1095</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1095</id><created>2012-02-06</created><authors><author><keyname>Bulakci</keyname><forenames>Omer</forenames></author></authors><title>Towards 100 Gbps Ethernet: Development of Ethernet / Physical Layer
  Aspects</title><categories>cs.NI</categories><comments>This work was presented as a part of Seminar on Topics in
  Communications Engineering, Technische Universit\&quot;at M\&quot;unchen, January 11,
  2008. 4 pages. Seminar paper</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Physical layer features of Ethernet from the first realization towards the
100 Gb Ethernet (100 GbE) development have been considered. Comparisons of
these features are made according to the standardized data rates. Feasible
physical layer options are then discussed for high data rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1098</identifier>
 <datestamp>2012-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1098</id><created>2012-02-06</created><updated>2012-05-08</updated><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>Dowek</keyname><forenames>Gilles</forenames></author></authors><title>Causal graph dynamics</title><categories>cs.DM cs.FL gr-qc math-ph math.MP</categories><comments>25 pages, 9 figures, LaTeX, v2: Minor presentation improvements, v3:
  Typos corrected, figure added</comments><msc-class>37B15, 68Q80, 37N20, 05C82, 83C27, 90B10</msc-class><acm-class>B.6.1; F.1.1; F.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the theory of Cellular Automata to arbitrary, time-varying graphs.
In other words we formalize, and prove theorems about, the intuitive idea of a
labelled graph which evolves in time - but under the natural constraint that
information can only ever be transmitted at a bounded speed, with respect to
the distance given by the graph. The notion of translation-invariance is also
generalized. The definition we provide for these &quot;causal graph dynamics&quot; is
simple and axiomatic. The theorems we provide also show that it is robust. For
instance, causal graph dynamics are stable under composition and under
restriction to radius one. In the finite case some fundamental facts of
Cellular Automata theory carry through: causal graph dynamics admit a
characterization as continuous functions, and they are stable under inversion.
The provided examples suggest a wide range of applications of this mathematical
object, from complex systems science to theoretical physics. KEYWORDS:
Dynamical networks, Boolean networks, Generative networks automata, Cayley
cellular automata, Graph Automata, Graph rewriting automata, Parallel graph
transformations, Amalgamated graph transformations, Time-varying graphs, Regge
calculus, Local, No-signalling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1100</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1100</id><created>2012-02-06</created><authors><author><keyname>Bulakci</keyname><forenames>Omer</forenames></author></authors><title>Wavelets for Single Carrier Communications</title><categories>cs.NI cs.IT math.IT</categories><comments>This work was presented as a part of Postgraduate Seminar Course:
  Wavelets in Communications, Aalto University School of Electrical
  Engineering, February 2, 2011. Three-page report followed by a presentation
  file. Seminar contribution</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper and the following presentation aim to provide a report regarding
the seminar presentation given on 23.02.2011 as a part of the postgraduate
seminar course S-88.4223 Wavelets in Communications lectured by Dr. Sumesh
Parameswaran at Aalto University School of Electrical Engineering. In
particular, the topic on &quot;wavelets for single carrier communications&quot; has been
considered herein. Furthermore, a summary of wavelets in Single Carrier
(SC)-FDMA Systems is as well provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1111</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1111</id><created>2012-02-06</created><updated>2012-02-15</updated><authors><author><keyname>Loh</keyname><forenames>Po-Shen</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>Thresholds for Extreme Orientability</title><categories>cs.DS math.CO</categories><comments>Corrected description of relationship to the work of LeLarge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-choice load balancing has been a topic of intense study since the
seminal paper of Azar, Broder, Karlin, and Upfal. Questions in this area can be
phrased in terms of orientations of a graph, or more generally a k-uniform
random hypergraph. A (d,b)-orientation is an assignment of each edge to d of
its vertices, such that no vertex has more than b edges assigned to it.
Conditions for the existence of such orientations have been completely
documented except for the &quot;extreme&quot; case of (k-1,1)-orientations. We consider
this remaining case, and establish:
  - The density threshold below which an orientation exists with high
probability, and above which it does not exist with high probability.
  - An algorithm for finding an orientation that runs in linear time with high
probability, with explicit polynomial bounds on the failure probability.
  Previously, the only known algorithms for constructing (k-1,1)-orientations
worked for k&lt;=3, and were only shown to have expected linear running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1112</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1112</id><created>2012-02-06</created><authors><author><keyname>L&#xfc;</keyname><forenames>Linyuan</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Recommender Systems</title><categories>physics.soc-ph cond-mat.stat-mech cs.IR cs.SI</categories><comments>97 pages, 20 figures (To appear in Physics Reports)</comments><journal-ref>Physics Reports Vol. 519 (1), P. 1-49 (2012)</journal-ref><doi>10.1016/j.physrep.2012.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ongoing rapid expansion of the Internet greatly increases the necessity
of effective recommender systems for filtering the abundant information.
Extensive research for recommender systems is conducted by a broad range of
communities including social and computer scientists, physicists, and
interdisciplinary researchers. Despite substantial theoretical and practical
achievements, unification and comparison of different approaches are lacking,
which impedes further advances. In this article, we review recent developments
in recommender systems and discuss the major challenges. We compare and
evaluate available algorithms and examine their roles in the future
developments. In addition to algorithms, physical aspects are described to
illustrate macroscopic behavior of recommender systems. Potential impacts and
future directions are discussed. We emphasize that recommendation has a great
scientific depth and combines diverse research fields which makes it of
interests for physicists as well as interdisciplinary researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1119</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1119</id><created>2012-02-06</created><updated>2012-10-18</updated><authors><author><keyname>Prasad</keyname><forenames>Ranjitha</forenames></author><author><keyname>Murthy</keyname><forenames>Chandra R.</forenames></author></authors><title>Cramer Rao-Type Bounds for Sparse Bayesian Learning</title><categories>cs.LG stat.ML</categories><comments>Accepted for publication in the IEEE Transactions on Signal
  Processing, 11 pages, 10 figures</comments><doi>10.1109/TSP.2012.2226165</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive Hybrid, Bayesian and Marginalized Cram\'{e}r-Rao
lower bounds (HCRB, BCRB and MCRB) for the single and multiple measurement
vector Sparse Bayesian Learning (SBL) problem of estimating compressible
vectors and their prior distribution parameters. We assume the unknown vector
to be drawn from a compressible Student-t prior distribution. We derive CRBs
that encompass the deterministic or random nature of the unknown parameters of
the prior distribution and the regression noise variance. We extend the MCRB to
the case where the compressible vector is distributed according to a general
compressible prior distribution, of which the generalized Pareto distribution
is a special case. We use the derived bounds to uncover the relationship
between the compressibility and Mean Square Error (MSE) in the estimates.
Further, we illustrate the tightness and utility of the bounds through
simulations, by comparing them with the MSE performance of two popular
SBL-based estimators. It is found that the MCRB is generally the tightest among
the bounds derived and that the MSE performance of the Expectation-Maximization
(EM) algorithm coincides with the MCRB for the compressible vector. Through
simulations, we demonstrate the dependence of the MSE performance of SBL based
estimators on the compressibility of the vector for several values of the
number of observations and at different signal powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1120</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1120</id><created>2012-02-06</created><authors><author><keyname>Davoodi</keyname><forenames>Arash Gholami</forenames></author><author><keyname>Emadi</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Optimum Power Allocations for Fading Decode-and-Forward Relay Channel</title><categories>cs.IT math.IT</categories><comments>30 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for a fading decode-and-forward full-duplex relay channel, we
analytically derive optimum power allocations. Individual power constraints for
the source and the relay are assumed and the related optimization problem is
analyzed for two scenarios. First, optimization is taken over the source power,
the relay power, and the correlation coefficient between the transmitted
signals of the source and the relay. Then, for a fixed value of correlation
coefficient, the optimization problem is analyzed. It is also proven that the
optimization problems are convex for these two scenarios. Finally, implications
of theoretical results are discussed through simulations for each scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1121</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1121</id><created>2012-02-06</created><updated>2014-11-14</updated><authors><author><keyname>Kursa</keyname><forenames>Miron B.</forenames></author></authors><title>rFerns: An Implementation of the Random Ferns Method for General-Purpose
  Machine Learning</title><categories>cs.LG stat.ML</categories><journal-ref>Journal of Statistical Software, 61(10), 1-13</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I present an extended implementation of the Random ferns
algorithm contained in the R package rFerns. It differs from the original by
the ability of consuming categorical and numerical attributes instead of only
binary ones. Also, instead of using simple attribute subspace ensemble it
employs bagging and thus produce error approximation and variable importance
measure modelled after Random forest algorithm. I also present benchmarks'
results which show that although Random ferns' accuracy is mostly smaller than
achieved by Random forest, its speed and good quality of importance measure it
provides make rFerns a reasonable choice for a specific applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1125</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1125</id><created>2012-02-06</created><updated>2012-06-17</updated><authors><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author><author><keyname>Tusn&#xe1;dy</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Information Divergence is more chi squared distributed than the chi
  squared statistics</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>5 pages, accepted for presentation at ISIT 2012</comments><msc-class>62E15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For testing goodness of fit it is very popular to use either the chi square
statistic or G statistics (information divergence). Asymptotically both are chi
square distributed so an obvious question is which of the two statistics that
has a distribution that is closest to the chi square distribution.
Surprisingly, when there is only one degree of freedom it seems like the
distribution of information divergence is much better approximated by a chi
square distribution than the chi square statistic. For random variables we
introduce a new transformation that transform several important distributions
into new random variables that are almost Gaussian. For the binomial
distributions and the Poisson distributions we formulate a general conjecture
about how close their transform are to the Gaussian. The conjecture is proved
for Poisson distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1144</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1144</id><created>2012-02-06</created><authors><author><keyname>Chang</keyname><forenames>Ling-Hua</forenames></author><author><keyname>Wu</keyname><forenames>Jwo-Yuh</forenames></author></authors><title>Achievable Angles Between two Compressed Sparse Vectors Under
  Norm/Distance Constraints Imposed by the Restricted Isometry Property: A
  Plane Geometry Approach</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The angle between two compressed sparse vectors subject to the norm/distance
constraints imposed by the restricted isometry property (RIP) of the sensing
matrix plays a crucial role in the studies of many compressive sensing (CS)
problems. Assuming that (i) u and v are two sparse vectors separated by an
angle thetha, and (ii) the sensing matrix Phi satisfies RIP, this paper is
aimed at analytically characterizing the achievable angles between Phi*u and
Phi*v. Motivated by geometric interpretations of RIP and with the aid of the
well-known law of cosines, we propose a plane geometry based formulation for
the study of the considered problem. It is shown that all the RIP-induced
norm/distance constraints on Phi*u and Phi*v can be jointly depicted via a
simple geometric diagram in the two-dimensional plane. This allows for a joint
analysis of all the considered algebraic constraints from a geometric
perspective. By conducting plane geometry analyses based on the constructed
diagram, closed-form formulae for the maximal and minimal achievable angles are
derived. Computer simulations confirm that the proposed solution is tighter
than an existing algebraic-based estimate derived using the polarization
identity. The obtained results are used to derive a tighter restricted isometry
constant of structured sensing matrices of a certain kind, to wit, those in the
form of a product of an orthogonal projection matrix and a random sensing
matrix. Follow-up applications to three CS problems, namely, compressed-domain
interference cancellation, RIP-based analysis of the orthogonal matching
pursuit algorithm, and the study of democratic nature of random sensing
matrices are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1145</identifier>
 <datestamp>2012-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1145</id><created>2012-02-06</created><authors><author><keyname>Krings</keyname><forenames>Gautier</forenames></author><author><keyname>Karsai</keyname><forenames>M&#xe1;rton</forenames></author><author><keyname>Bernharsson</keyname><forenames>Sebastian</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>Jari</forenames></author></authors><title>Effects of time window size and placement on the structure of aggregated
  networks</title><categories>physics.soc-ph cs.SI</categories><comments>19 pages, 11 figures</comments><journal-ref>EPJ Data Science, 2012, Volume 1, Number 1, 4</journal-ref><doi>10.1140/epjds4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks are often constructed by aggregating empirical data over
time, such that a link represents the existence of interactions between the
endpoint nodes and the link weight represents the intensity of such
interactions within the aggregation time window. The resulting networks are
then often considered static. More often than not, the aggregation time window
is dictated by the availability of data, and the effects of its length on the
resulting networks are rarely considered. Here, we address this question by
studying the structural features of networks emerging from aggregating
empirical data over different time intervals, focussing on networks derived
from time-stamped, anonymized mobile telephone call records. Our results show
that short aggregation intervals yield networks where strong links associated
with dense clusters dominate; the seeds of such clusters or communities become
already visible for intervals of around one week. The degree and weight
distributions are seen to become stationary around a few days and a few weeks,
respectively. An aggregation interval of around 30 days results in the stablest
similar networks when consecutive windows are compared. For longer intervals,
the effects of weak or random links become increasingly stronger, and the
average degree of the network keeps growing even for intervals up to 180 days.
The placement of the time window is also seen to affect the outcome: for short
windows, different behavioural patterns play a role during weekends and
weekdays, and for longer windows it is seen that networks aggregated during
holiday periods are significantly different.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1146</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1146</id><created>2012-02-06</created><authors><author><keyname>Khoshkhah</keyname><forenames>Kaveh</forenames></author><author><keyname>Soltani</keyname><forenames>Hossein</forenames></author><author><keyname>Zaker</keyname><forenames>Manouchehr</forenames></author></authors><title>On dynamic monopolies of graphs: the average and strict majority
  thresholds</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a graph and ${\mathcal{\tau}}: V(G)\rightarrow \Bbb{N}\cup \{0\}$
be an assignment of thresholds to the vertices of $G$. A subset of vertices $D$
is said to be a dynamic monopoly corresponding to $(G, \tau)$ if the vertices
of $G$ can be partitioned into subsets $D_0, D_1,..., D_k$ such that $D_0=D$
and for any $i\in {0, ..., k-1}$, each vertex $v$ in $D_{i+1}$ has at least
$\tau(v)$ neighbors in $D_0\cup ... \cup D_i$. Dynamic monopolies are in fact
modeling the irreversible spread of influence in social networks. In this paper
we first obtain a lower bound for the smallest size of any dynamic monopoly in
terms of the average threshold and the order of graph. Also we obtain an upper
bound in terms of the minimum vertex cover of graphs. Then we derive the upper
bound $|G|/2$ for the smallest size of any dynamic monopoly when the graph $G$
contains at least one odd vertex, where the threshold of any vertex $v$ is set
as $\lceil (deg(v)+1)/2 \rceil$ (i.e. strict majority threshold). This bound
improves the best known bound for strict majority threshold. We show that the
latter bound can be achieved by a polynomial time algorithm. We also show that
$\alpha'(G)+1$ is an upper bound for the size of strict majority dynamic
monopoly, where $\alpha'(G)$ stands for the matching number of $G$. Finally, we
obtain a basic upper bound for the smallest size of any dynamic monopoly, in
terms of the average threshold and vertex degrees. Using this bound we derive
some other upper bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1148</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1148</id><created>2012-02-06</created><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Reinhardt</keyname><forenames>Klaus</forenames></author><author><keyname>Walter</keyname><forenames>Tobias</forenames></author></authors><title>Regular Languages are Church-Rosser Congruential</title><categories>cs.FL</categories><msc-class>68Q42 (Primary) 68Q45, 68Q70 (Secondary)</msc-class><acm-class>F.4.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proves a long standing conjecture in formal language theory. It
shows that all regular languages are Church-Rosser congruential. The class of
Church-Rosser congruential languages was introduced by McNaughton, Narendran,
and Otto in 1988. A language L is Church-Rosser congruential, if there exists a
finite confluent, and length-reducing semi-Thue system S such that L is a
finite union of congruence classes modulo S. It was known that there are
deterministic linear context-free languages which are not Church-Rosser
congruential, but on the other hand it was strongly believed that all regular
language are of this form. Actually, this paper proves a more general result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1150</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1150</id><created>2012-02-06</created><updated>2013-03-18</updated><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>Optimal Index Codes with Near-Extreme Rates</title><categories>cs.IT math.IT</categories><comments>15 pages, submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The min-rank of a digraph was shown by Bar-Yossef et al. (2006) to represent
the length of an optimal scalar linear solution of the corresponding instance
of the Index Coding with Side Information (ICSI) problem. In this work, the
graphs and digraphs of near-extreme min-ranks are characterized. Those graphs
and digraphs correspond to the ICSI instances having near-extreme transmission
rates when using optimal scalar linear index codes. In particular, it is shown
that the decision problem whether a digraph has min-rank two is NP-complete. By
contrast, the same question for graphs can be answered in polynomial time.
  Additionally, a new upper bound on the min-rank of a digraph, the
circuit-packing bound, is presented. This bound is often tighter than the
previously known bounds. By employing this new bound, we present several
families of digraphs whose min-ranks can be found in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1163</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1163</id><created>2012-02-06</created><updated>2012-02-27</updated><authors><author><keyname>Hong</keyname><forenames>Dohy</forenames></author></authors><title>D-iteration method or how to improve Gauss-Seidel method</title><categories>math.NA cs.DM</categories><comments>7 pages</comments><acm-class>G.1.3; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to present the recently proposed fluid diffusion
based algorithm in the general context of the matrix inversion problem
associated to the Gauss-Seidel method. We explain the simple intuitions that
are behind this diffusion method and how it can outperform existing methods.
Then we present some theoretical problems that are associated to this
representation as open research problems. We also illustrate some connected
problems such as the graph transformation and the PageRank problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1174</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1174</id><created>2012-02-06</created><updated>2012-06-27</updated><authors><author><keyname>Pollakis</keyname><forenames>Emmanuel</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato Luis Garrido</forenames></author><author><keyname>Sta&#x144;czak</keyname><forenames>Slawomir</forenames></author></authors><title>Base station selection for energy efficient network operation with the
  majorization-minimization algorithm</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of reducing the energy consumption in a
mobile communication network; we select the smallest set of active base
stations that can preserve the quality of service (the minimum data rate)
required by the users. In more detail, we start by posing this problem as an
integer programming problem, the solution of which shows the optimal assignment
(in the sense of minimizing the total energy consumption) between base stations
and users. In particular, this solution shows which base stations can then be
switched off or put in idle mode to save energy. However, solving this problem
optimally is intractable in general, so in this study we develop a suboptimal
approach that builds upon recent techniques that have been successfully applied
to, among other problems, sparse signal reconstruction, portfolio optimization,
statistical estimation, and error correction. More precisely, we relax the
original integer programming problem as a minimization problem where the
objective function is concave and the constraint set is convex. The resulting
relaxed problem is still intractable in general, but we can apply the
majorization-minimization algorithm to find good solutions (i.e., solutions
attaining low objective value) with a low-complexity algorithm. In contrast to
state-of-the-art approaches, the proposed algorithm can take into account
inter-cell interference, is suitable for large-scale problems, and can be
applied to heterogeneous networks (networks where base station consume
different amounts of energy)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1178</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1178</id><created>2012-02-06</created><authors><author><keyname>Sarikaya</keyname><forenames>Yunus</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author><author><keyname>Koksal</keyname><forenames>Emre C.</forenames></author></authors><title>Wireless Network Control with Privacy Using Hybrid ARQ</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of resource allocation in a wireless cellular
network, in which nodes have both open and private information to be
transmitted to the base station over block fading uplink channels. We develop a
cross-layer solution, based on hybrid ARQ transmission with incremental
redundancy. We provide a scheme that combines power control, flow control, and
scheduling in order to maximize a global utility function, subject to the
stability of the data queues, an average power constraint, and a constraint on
the privacy outage probability. Our scheme is based on the assumption that each
node has an estimate of its uplink channel gain at each block, while only the
distribution of the cross channel gains is available. We prove that our scheme
achieves a utility, arbitrarily close to the maximum achievable utility given
the available channel state information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1186</identifier>
 <datestamp>2012-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1186</id><created>2012-02-06</created><updated>2012-04-05</updated><authors><author><keyname>Emek</keyname><forenames>Yuval</forenames></author><author><keyname>Smula</keyname><forenames>Jasmin</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>Stone Age Distributed Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional models of distributed computing focus mainly on networks of
computer-like devices that can exchange large messages with their neighbors and
perform arbitrary local computations. Recently, there is a trend to apply
distributed computing methods to networks of sub-microprocessor devices, e.g.,
biological cellular networks or networks of nano-devices. However, the
suitability of the traditional distributed computing models to these types of
networks is questionable: do tiny bio/nano nodes &quot;compute&quot; and/or &quot;communicate&quot;
essentially the same as a computer? In this paper, we introduce a new model
that depicts a network of randomized finite state machines operating in an
asynchronous environment. Although the computation and communication
capabilities of each individual device in the new model are, by design, much
weaker than those of a computer, we show that some of the most important and
extensively studied distributed computing problems can still be solved
efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1194</identifier>
 <datestamp>2012-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1194</id><created>2012-02-06</created><updated>2012-10-14</updated><authors><author><keyname>Kobayashi</keyname><forenames>Koji</forenames></author></authors><title>Topological approach to solve P versus NP</title><categories>cs.CC</categories><comments>7 pages, English and Japanese (see Other formats - Source)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper talks about difference between P and NP by using topological space
that mean resolution principle. I pay attention to restrictions of antecedent
and consequent in resolution, and show what kind of influence the restrictions
have for difference of structure between P and NP regarding relations of
relation.
  First, I show the restrictions of antecedent and consequent in resolution
principle. Antecedents connect each other, and consequent become a linkage
between these antecedents. And we can make consequent as antecedents product by
using some resolutions which have same joint variable. We can determine these
consequents reducible and irreducible.
  Second, I introduce RCNF that mean topology of resolution principle in CNF.
RCNF is HornCNF and that variable values are presence of restrictions of CNF
formula clauses. RCNF is P-Complete.
  Last, I introduce TCNF that have 3CNF's character which relate 2 variables
relations with 1 variable. I show CNF complexity by using CCNF that combine
some TCNF. TCNF is NP-Complete and product irreducible. I introduce CCNF that
connect TCNF like Moore graph. We cannot reduce CCNF to RCNF with polynomial
size. Therefore, TCNF is not in P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1201</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1201</id><created>2012-02-06</created><updated>2012-06-24</updated><authors><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author><author><keyname>Behera</keyname><forenames>Laxmidhar</forenames></author></authors><title>Optimal migration promotes the outbreak of cooperation in heterogeneous
  populations</title><categories>physics.soc-ph cs.GT nlin.AO</categories><comments>29 pp. Submitted to ACS - Advances in Complex Systems (2012)</comments><journal-ref>ACS - Advances in Complex Systems, vol. 15, Suppl. No. 1 (2012)
  1250059 (27 pages)</journal-ref><doi>10.1142/S0219525912500592</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a population of agents that are heterogeneous with respect to (i)
their strategy when interacting $n_{g}$ times with other agents in an iterated
prisoners dilemma game, (ii) their spatial location on $K$ different islands.
After each generation, agents adopt strategies proportional to their average
payoff received. Assuming a mix of two cooperating and two defecting
strategies, we first investigate for isolated islands the conditions for an
exclusive domination of each of these strategies and their possible
coexistence. This allows to define a threshold frequency for cooperation that,
dependent on $n_{g}$ and the initial mix of strategies, describes the outbreak
of cooperation in the absense of migration. We then allow migration of a fixed
fraction of the population after each generation. Assuming a worst case
scenario where all islands are occupied by defecting strategies, whereas only
one island is occupied by cooperators at the threshold frequency, we determine
the optimal migration rate that allows the outbreak of cooperation on
\emph{all} islands. We further find that the threshold frequency divided by the
number of islands, i.e. the relative effort for invading defecting islands with
cooperators decreeses with the number of islands. We also show that there is
only a small bandwidth of migration rates, to allow the outbreak of
cooperation. Larger migration rates destroy cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1209</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1209</id><created>2012-02-06</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Wyner-Ziv Type Versus Noisy Network Coding For a State-Dependent MAC</title><categories>cs.IT math.IT</categories><comments>Submitted for publication to the 2012 IEEE International Symposium on
  Information Theory, 5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-user state-dependent multiaccess channel in which the
states of the channel are known non-causally to one of the encoders and only
strictly causally to the other encoder. Both encoders transmit a common message
and, in addition, the encoder that knows the states non-causally transmits an
individual message. We find explicit characterizations of the capacity region
of this communication model in both discrete memoryless and memoryless Gaussian
cases. The analysis also reveals optimal ways of exploiting the knowledge of
the state only strictly causally at the encoder that sends only the common
message when such a knowledge is beneficial. The encoders collaborate to convey
to the decoder a lossy version of the state, in addition to transmitting the
information messages through a generalized Gel'fand-Pinsker binning.
Particularly important in this problem are the questions of 1) optimal ways of
performing the state compression and 2) whether or not the compression indices
should be decoded uniquely. We show that both compression \`a-la noisy network
coding, i.e., with no binning, and compression using Wyner-Ziv binning are
optimal. The scheme that uses Wyner-Ziv binning shares elements with Cover and
El Gamal original compress-and-forward, but differs from it mainly in that
backward decoding is employed instead of forward decoding and the compression
indices are not decoded uniquely. Finally, by exploring the properties of our
outer bound, we show that, although not required in general, the compression
indices can in fact be decoded uniquely essentially without altering the
capacity region, but at the expense of larger alphabets sizes for the auxiliary
random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1212</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1212</id><created>2012-02-06</created><updated>2012-07-19</updated><authors><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author><author><keyname>Vershynin</keyname><forenames>Roman</forenames></author></authors><title>Robust 1-bit compressed sensing and sparse logistic regression: A convex
  programming approach</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>25 pages, 1 figure, error fixed in Lemma 4.1</comments><msc-class>94A12 (Primary) 60D05, 90C25 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops theoretical results regarding noisy 1-bit compressed
sensing and sparse binomial regression. We show that a single convex program
gives an accurate estimate of the signal, or coefficient vector, for both of
these models. We demonstrate that an s-sparse signal in R^n can be accurately
estimated from m = O(slog(n/s)) single-bit measurements using a simple convex
program. This remains true even if each measurement bit is flipped with
probability nearly 1/2. Worst-case (adversarial) noise can also be accounted
for, and uniform results that hold for all sparse inputs are derived as well.
In the terminology of sparse logistic regression, we show that O(slog(n/s))
Bernoulli trials are sufficient to estimate a coefficient vector in R^n which
is approximately s-sparse. Moreover, the same convex program works for
virtually all generalized linear models, in which the link function may be
unknown. To our knowledge, these are the first results that tie together the
theory of sparse logistic regression to 1-bit compressed sensing. Our results
apply to general signal structures aside from sparsity; one only needs to know
the size of the set K where signals reside. The size is given by the mean width
of K, a computable quantity whose square serves as a robust extension of the
dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1223</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1223</id><created>2012-02-06</created><authors><author><keyname>Mir</keyname><forenames>Arnau</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Rotger</keyname><forenames>Lucia</forenames></author></authors><title>A new balance index for phylogenetic trees</title><categories>q-bio.PE cs.DM q-bio.QM</categories><comments>24 pages, 2 figures, preliminary version presented at the JBI 2012</comments><journal-ref>Math. Biosc. 241 (2013) 125-136</journal-ref><doi>10.1016/j.mbs.2012.10.005</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Several indices that measure the degree of balance of a rooted phylogenetic
tree have been proposed so far in the literature. In this work we define and
study a new index of this kind, which we call the total cophenetic index: the
sum, over all pairs of different leaves, of the depth of their least common
ancestor. This index makes sense for arbitrary trees, can be computed in linear
time and it has a larger range of values and a greater resolution power than
other indices like Colless' or Sackin's. We compute its maximum and minimum
values for arbitrary and binary trees, as well as exact formulas for its
expected value for binary trees under the Yule and the uniform models of
evolution. As a byproduct of this study, we obtain an exact formula for the
expected value of the Sackin index under the uniform model, a result that seems
to be new in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1229</identifier>
 <datestamp>2014-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1229</id><created>2012-02-06</created><updated>2014-09-29</updated><authors><author><keyname>Portmann</keyname><forenames>Christopher</forenames></author></authors><title>Key recycling in authentication</title><categories>cs.IT cs.CR math.IT quant-ph</categories><comments>17+3 pages. 11 figures. v3: Rewritten with AC instead of UC. Extended
  the main result to both synchronous and asynchronous networks. Matches
  published version up to layout and updated references. v2: updated
  introduction and references</comments><journal-ref>IEEE Trans. Inf. Th., 60(7):4383-4396, 2014</journal-ref><doi>10.1109/TIT.2014.2317312</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In their seminal work on authentication, Wegman and Carter propose that to
authenticate multiple messages, it is sufficient to reuse the same hash
function as long as each tag is encrypted with a one-time pad. They argue that
because the one-time pad is perfectly hiding, the hash function used remains
completely unknown to the adversary.
  Since their proof is not composable, we revisit it using a composable
security framework. It turns out that the above argument is insufficient: if
the adversary learns whether a corrupted message was accepted or rejected,
information about the hash function is leaked, and after a bounded finite
amount of rounds it is completely known. We show however that this leak is very
small: Wegman and Carter's protocol is still $\epsilon$-secure, if
$\epsilon$-almost strongly universal$_2$ hash functions are used. This implies
that the secret key corresponding to the choice of hash function can be reused
in the next round of authentication without any additional error than this
$\epsilon$.
  We also show that if the players have a mild form of synchronization, namely
that the receiver knows when a message should be received, the key can be
recycled for any arbitrary task, not only new rounds of authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1231</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1231</id><created>2012-02-06</created><updated>2012-02-09</updated><authors><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>In Defense of Bureaucracy in the Metric Facility Location Problem</title><categories>cs.GT math.CO</categories><comments>This paper has been withdrawn by the authors. Very similar results
  were obtained earlier in http://www.softlab.ntua.gr/~fotakis/data/wine10.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work is devoted to the metric facility location problem and addresses the
selfish behavior of the players. It contributes to the line of work initiated
by Procaccia and Tennenholtz [EC09] on approximate mechanism design without
money. We explore and argue for an intuitive and simple rule of complexity
O(nk),a so-called proportionality mechanism. The mechanism works in k
consecutive rounds,each time choosing a random player at whose position to
place the next facility; each time the probabilities of players to be picked
are distributed proportionally to their distances to the current set of the
facilities. Lu et al. [EC10] showed that the proportionality rule is incentive
compatible for k=1,2, but fails to be so for k&gt;2.
  We tweak the model slightly such that for any k, the proportionality
mechanism becomes incentive compatible. In the new model we allow the
government to be bureaucratic, i.e., to have the power of to force each player
to choose from only a specific set of available facilities. In the
proportionality mechanism, we force every player that receives a facility at
his reported location to connect to exactly that facility. We extend the
proportionality mechanism to a more general setting with a private network of
facilities already present in the metric space and show that it is truthful as
well.
  We further show that for any fixed k, the proportionality rule achieves in
expectation a constant approximation guarantee to the optimal solution; namely
at most a ratio of 4k. On the other hand, we show a lower bound of ln
k(1+o(1)), and we suspect the truth to be closer to this lower bound. Thus, our
work is the first among those on incentive compatible facility location that
treats effectively (with a constant factor of approximation) the general case
of an arbitrary number of facilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1238</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1238</id><created>2012-02-06</created><updated>2013-04-12</updated><authors><author><keyname>Hernando</keyname><forenames>Fernando</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>List decoding of repeated codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assuming that we have a soft-decision list decoding algorithm of a linear
code, a new hard-decision list decoding algorithm of its repeated code is
proposed in this article. Although repeated codes are not used for encoding
data, due to their parameters, we show that they have a good performance with
this algorithm. We compare, by computer simulations, our algorithm for the
repeated code of a Reed-Solomon code against a decoding algorithm of a
Reed-Solomon code. Finally, we estimate the decoding capability of the
algorithm for Reed-Solomon codes and show that performance is somewhat better
than our estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1254</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1254</id><created>2012-02-06</created><updated>2012-05-14</updated><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Optimal Sum-Rate of the Vector Gaussian CEO Problem</title><categories>cs.IT math.IT</categories><comments>This document is withdrawn due to an error in Lemma 4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document is withdrawn due to an error in Lemma 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1303</identifier>
 <datestamp>2013-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1303</id><created>2012-02-06</created><updated>2013-03-15</updated><authors><author><keyname>Burdis</keyname><forenames>Joseph M.</forenames></author><author><keyname>Kogan</keyname><forenames>Irina A.</forenames></author></authors><title>Object-image correspondence for curves under projections</title><categories>math.AG cs.CG</categories><comments>A significantly improved version of this paper (corrected and
  completed) has been posted arXiv:1303.3358</comments><msc-class>14H50, 14Q05, 68T45, 03C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel algorithm for deciding whether a given planar curve is an
image of a given spatial curve, obtained by a central or a parallel projection
with unknown parameters. A straightforward approach to this problem consists of
setting up a system of conditions on the projection parameters and then
checking whether or not this system has a solution. The main advantage of the
algorithm presented here, in comparison to algorithms based on the
straightforward approach, lies in a significant reduction of a number of real
parameters that need to be eliminated in order to establish existence or
non-existence of a projection that maps a given spatial curve to a given planar
curve. Our algorithm is based on projection criteria that reduce the projection
problem to a certain modification of the equivalence problem of planar curves
under affine and projective transformations. The latter problem is then solved
by differential signature construction based on Cartan's moving frame method. A
similar approach can be used to decide whether a given finite set of ordered
points on a plane is an image of a given finite set of ordered points in R^3.
The motivation comes from the problem of establishing a correspondence between
an object and an image, taken by a camera with unknown position and parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1307</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1307</id><created>2012-02-06</created><updated>2012-07-10</updated><authors><author><keyname>Ulusoy</keyname><forenames>Alphan</forenames></author><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Robust Multi-Robot Optimal Path Planning with Temporal Logic Constraints</title><categories>cs.RO</categories><comments>Extended version of the ICRA 2012 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a method for automatically planning robust optimal
paths for a group of robots that satisfy a common high level mission
specification. Each robot's motion in the environment is modeled as a weighted
transition system, and the mission is given as a Linear Temporal Logic (LTL)
formula over a set of propositions satisfied by the regions of the environment.
In addition, an optimizing proposition must repeatedly be satisfied. The goal
is to minimize the maximum time between satisfying instances of the optimizing
proposition while ensuring that the LTL formula is satisfied even with
uncertainty in the robots' traveling times. We characterize a class of LTL
formulas that are robust to robot timing errors, for which we generate optimal
paths if no timing errors are present, and we present bounds on the deviation
from the optimal values in the presence of errors. We implement and
experimentally evaluate our method considering a persistent monitoring task in
a road network environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1309</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1309</id><created>2012-02-06</created><updated>2012-06-12</updated><authors><author><keyname>Mogavero</keyname><forenames>Fabio</forenames></author><author><keyname>Murano</keyname><forenames>Aniello</forenames></author><author><keyname>Perelli</keyname><forenames>Giuseppe</forenames></author><author><keyname>Vardi</keyname><forenames>Moshe Y.</forenames></author></authors><title>A Decidable Fragment of Strategy Logic</title><categories>cs.LO math.LO</categories><comments>arXiv admin note: text overlap with arXiv:1112.6275</comments><msc-class>68Q60 (Primary) 03B70 (Secondary) 03B44, 03B60</msc-class><acm-class>F.3.1; F.4.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Strategy Logic (SL, for short) has been recently introduced by Mogavero,
Murano, and Vardi as a useful formalism for reasoning explicitly about
strategies, as first-order objects, in multi-agent concurrent games. This logic
turns to be very powerful, subsuming all major previously studied modal logics
for strategic reasoning, including ATL, ATL*, and the like. Unfortunately, due
to its expressiveness, SL has a non-elementarily decidable model-checking
problem and a highly undecidable satisfiability problem, specifically,
$\Sigma_{1}^{1}$-Hard. In order to obtain a decidable sublogic, we introduce
and study here One-Goal Strategy Logic (SL[1G], for short). This logic is a
syntactic fragment of SL, strictly subsuming ATL*, which encompasses formulas
in prenex normal form having a single temporal goal at a time, for every
strategy quantification of agents. SL[1G] is known to have an elementarily
decidable model-checking problem. Here we prove that, unlike SL, it has the
bounded tree-model property and its satisfiability problem is decidable in
2ExpTime, thus not harder than the one for ATL*.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1325</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1325</id><created>2012-02-06</created><authors><author><keyname>Wang</keyname><forenames>Jiadong</forenames></author><author><keyname>Dong</keyname><forenames>Guiqiang</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author><author><keyname>Wesel</keyname><forenames>Richard</forenames></author></authors><title>Mutual-Information Optimized Quantization for LDPC Decoding of
  Accurately Modeled Flash Data</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-capacity NAND flash memories use multi-level cells (MLCs) to store
multiple bits per cell and achieve high storage densities. Higher densities
cause increased raw bit error rates (BERs), which demand powerful error
correcting codes. Low-density parity-check (LDPC) codes are a well-known class
of capacity-approaching codes in AWGN channels. However, LDPC codes
traditionally use soft information while the flash read channel provides only
hard information. Low resolution soft information may be obtained by performing
multiple reads per cell with distinct word-line voltages.
  We select the values of these word-line voltages to maximize the mutual
information between the input and output of the equivalent multiple-read
channel under any specified noise model. Our results show that maximum
mutual-information (MMI) quantization provides better soft information for LDPC
decoding given the quantization level than the constant-pdf-ratio quantization
approach. We also show that adjusting the LDPC code degree distribution for the
quantized setting provides a significant performance improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1327</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1327</id><created>2012-02-06</created><authors><author><keyname>Treleaven</keyname><forenames>Kyle</forenames></author><author><keyname>Pavone</keyname><forenames>Marco</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Asymptotically Optimal Algorithms for Pickup and Delivery Problems with
  Application to Large-Scale Transportation Systems</title><categories>cs.SY</categories><comments>27 pages, plus Appendix, 7 figures, extended version of paper being
  submitted to IEEE Transactions of Automatic Control</comments><doi>10.1109/TAC.2013.2259993</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Stacker Crane Problem is NP-Hard and the best known approximation
algorithm only provides a 9/5 approximation ratio. The objective of this paper
is threefold. First, by embedding the problem within a stochastic framework, we
present a novel algorithm for the SCP that: (i) is asymptotically optimal,
i.e., it produces, almost surely, a solution approaching the optimal one as the
number of pickups/deliveries goes to infinity; and (ii) has computational
complexity $O(n^{2+\eps})$, where $n$ is the number of pickup/delivery pairs
and $\eps$ is an arbitrarily small positive constant. Second, we asymptotically
characterize the length of the optimal SCP tour. Finally, we study a dynamic
version of the SCP, whereby pickup and delivery requests arrive according to a
Poisson process, and which serves as a model for large-scale demand-responsive
transport (DRT) systems. For such a dynamic counterpart of the SCP, we derive a
necessary and sufficient condition for the existence of stable vehicle routing
policies, which depends only on the workspace geometry, the stochastic
distributions of pickup and delivery points, the arrival rate of requests, and
the number of vehicles. Our results leverage a novel connection between the
Euclidean Bipartite Matching Problem and the theory of random permutations,
and, for the dynamic setting, exhibit novel features that are absent in
traditional spatially-distributed queueing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1330</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1330</id><created>2012-02-06</created><authors><author><keyname>Wang</keyname><forenames>Ru</forenames></author><author><keyname>Wang</keyname><forenames>Qiuping Alexandre</forenames></author></authors><title>A dual modelling of evolving political opinion networks</title><categories>physics.soc-ph cs.SI stat.CO</categories><journal-ref>Physics Review E 84, 036108 (2011)</journal-ref><doi>10.1103/PhysRevE.84.036108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the result of a dual modeling of opinion network. The model
complements the agent-based opinion models by attaching to the social agent
(voters) network a political opinion (party) network having its own intrinsic
mechanisms of evolution. These two sub-networks form a global network which can
be either isolated from or dependent on the external influence. Basically, the
evolution of the agent network includes link adding and deleting, the opinion
changes influenced by social validation, the political climate, the
attractivity of the parties and the interaction between them. The opinion
network is initially composed of numerous nodes representing opinions or
parties which are located on a one dimensional axis according to their
political positions. The mechanism of evolution includes union, splitting,
change of position and of attractivity, taken into account the pairwise node
interaction decaying with node distance in power law. The global evolution ends
in a stable distribution of the social agents over a quasi-stable and
fluctuating stationary number of remaining parties. Empirical study on the
lifetime distribution of numerous parties and vote results is carried out to
verify numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1332</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1332</id><created>2012-02-06</created><updated>2016-02-01</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>Secure Multiplex Coding with Dependent and Non-Uniform Multiple Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>We made several changes to improve the presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secure multiplex coding (SMC) is a technique to remove rate loss in the
coding for wire-tap channels and broadcast channels with confidential messages
caused by the inclusion of random bits into transmitted signals. SMC replaces
the random bits by other meaningful secret messages, and a collection of secret
messages serves as the random bits to hide the rest of messages. In the
previous researches, multiple secret messages were assumed to have independent
and uniform distributions, which is difficult to be ensured in practice. We
remove this restrictive assumption by a generalization of the channel
resolvability technique.
  We also give practical construction techniques for SMC by using an arbitrary
given error-correcting code as an ingredient, and channel-universal coding of
SMC. By using the same principle as the channel-universal SMC, we give coding
for the broadcast channel with confidential messages universal to both channel
and source distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1334</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1334</id><created>2012-02-06</created><updated>2012-03-02</updated><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Dud&#xed;k</keyname><forenames>Miroslav</forenames></author><author><keyname>Kale</keyname><forenames>Satyen</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Schapire</keyname><forenames>Robert E.</forenames></author></authors><title>Contextual Bandit Learning with Predictable Rewards</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contextual bandit learning is a reinforcement learning problem where the
learner repeatedly receives a set of features (context), takes an action and
receives a reward based on the action and context. We consider this problem
under a realizability assumption: there exists a function in a (known) function
class, always capable of predicting the expected reward, given the action and
context. Under this assumption, we show three things. We present a new
algorithm---Regressor Elimination--- with a regret similar to the agnostic
setting (i.e. in the absence of realizability assumption). We prove a new lower
bound showing no algorithm can achieve superior performance in the worst case
even with the realizability assumption. However, we do show that for any set of
policies (mapping contexts to actions), there is a distribution over rewards
(given context) such that our new algorithm has constant regret unlike the
previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1336</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1336</id><created>2012-02-06</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Forney,</keyname><forenames>G. David</forenames><suffix>Jr</suffix></author></authors><title>Reducing complexity of tail-biting trellises</title><categories>cs.IT cs.SY math.IT</categories><comments>5 pages; submitted to the 2012 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that a trellis realization can be locally reduced if it is not
state-trim, branch-trim, proper, observable, and controllable. These conditions
are not sufficient for local irreducibility. Making use of notions that amount
to &quot;almost unobservability/uncontrollability&quot;, a necessary and sufficient
criterion of local irreducibility for tail-biting trellises is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1337</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1337</id><created>2012-02-06</created><updated>2012-07-19</updated><authors><author><keyname>Planjery</keyname><forenames>Shiva Kumar</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Enhancing the Error Correction of Finite Alphabet Iterative Decoders via
  Adaptive Decimation</title><categories>cs.IT math.IT</categories><comments>Presented at International Symposium on Information theory (ISIT)
  2012, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite alphabet iterative decoders (FAIDs) for LDPC codes were recently shown
to be capable of surpassing the Belief Propagation (BP) decoder in the error
floor region on the Binary Symmetric channel (BSC). More recently, the
technique of decimation which involves fixing the values of certain bits during
decoding, was proposed for FAIDs in order to make them more amenable to
analysis while maintaining their good performance. In this paper, we show how
decimation can be used adaptively to further enhance the guaranteed error
correction capability of FAIDs that are already good on a given code. The new
adaptive decimation scheme proposed has marginally added complexity but can
significantly improve the slope of the error floor performance of a particular
FAID. We describe the adaptive decimation scheme particularly for 7-level FAIDs
which propagate only 3-bit messages and provide numerical results for
column-weight three codes. Analysis suggests that the failures of the new
decoders are linked to stopping sets of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1340</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1340</id><created>2012-02-06</created><authors><author><keyname>Huang</keyname><forenames>Yi</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author></authors><title>An Energy Efficient Semi-static Power Control and Link Adaptation Scheme
  in UMTS HSDPA</title><categories>cs.IT math.IT</categories><comments>9 pages, 11 figures, accepted in EURASIP Journal on Wireless
  Communications and Networking, special issue on Green Radio</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High speed downlink packet access (HSDPA) has been successfully applied in
commercial systems and improves user experience significantly. However, it
incurs substantial energy consumption. In this paper, we address this issue by
proposing a novel energy efficient semi-static power control and link
adaptation scheme in HSDPA. Through estimating the EE under different
modulation and coding schemes (MCSs) and corresponding transmit power, the
proposed scheme can determine the most energy efficient MCS level and transmit
power at the Node B. And then the Node B configure the optimal MCS level and
transmit power. In order to decrease the signaling overhead caused by the
configuration, a dual trigger mechanism is employed. After that, we extend the
proposed scheme to the multiple input multiple output (MIMO) scenarios.
Simulation results confirm the significant EE improvement of our proposed
scheme. Finally, we give a discussion on the potential EE gain and challenge of
the energy efficient mode switching between single input multiple output (SIMO)
and MIMO configuration in HSDPA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1342</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1342</id><created>2012-02-06</created><updated>2013-12-05</updated><authors><author><keyname>Broutin</keyname><forenames>Nicolas</forenames></author><author><keyname>Neininger</keyname><forenames>Ralph</forenames></author><author><keyname>Sulzbach</keyname><forenames>Henning</forenames></author></authors><title>A limit process for partial match queries in random quadtrees and $2$-d
  trees</title><categories>math.PR cs.DS math.CO</categories><comments>Published in at http://dx.doi.org/10.1214/12-AAP912 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org). arXiv admin note: text
  overlap with arXiv:1107.2231</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP912</report-no><journal-ref>Annals of Applied Probability 2013, Vol. 23, No. 6, 2560-2603</journal-ref><doi>10.1214/12-AAP912</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering items matching a partially specified
pattern in multidimensional trees (quadtrees and $k$-d trees). We assume the
traditional model where the data consist of independent and uniform points in
the unit square. For this model, in a structure on $n$ points, it is known that
the number of nodes $C_n(\xi )$ to visit in order to report the items matching
a random query $\xi$, independent and uniformly distributed on $[0,1]$,
satisfies $\mathbf {E}[{C_n(\xi )}]\sim\kappa n^{\beta}$, where $\kappa$ and
$\beta$ are explicit constants. We develop an approach based on the analysis of
the cost $C_n(s)$ of any fixed query $s\in[0,1]$, and give precise estimates
for the variance and limit distribution of the cost $C_n(x)$. Our results
permit us to describe a limit process for the costs $C_n(x)$ as $x$ varies in
$[0,1]$; one of the consequences is that $\mathbf
{E}[{\max_{x\in[0,1]}C_n(x)}]\sim \gamma n^{\beta}$; this settles a question of
Devroye [Pers. Comm., 2000].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1348</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1348</id><created>2012-02-06</created><updated>2012-05-21</updated><authors><author><keyname>Nguyen</keyname><forenames>Dung Viet</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael W.</forenames></author></authors><title>Selecting Two-Bit Bit Flipping Algorithms for Collective Error
  Correction</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, accepted for presentation at the IEEE
  International Symposium on Information Theory (ISIT) 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of two-bit bit flipping algorithms for decoding low-density
parity-check codes over the binary symmetric channel was proposed in [1].
Initial results showed that decoders which employ a group of these algorithms
operating in parallel can offer low error floor decoding for high-speed
applications. As the number of two-bit bit flipping algorithms is large,
designing such a decoder is not a trivial task. In this paper, we describe a
procedure to select collections of algorithms that work well together. This
procedure relies on a recursive process which enumerates error configurations
that are uncorrectable by a given algorithm. The error configurations
uncorrectable by a given algorithm form its trapping set profile. Based on
their trapping set profiles, algorithms are selected so that in parallel, they
can correct a fixed number of errors with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1350</identifier>
 <datestamp>2012-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1350</id><created>2012-02-06</created><updated>2012-02-21</updated><authors><author><keyname>Thaler</keyname><forenames>Justin</forenames></author><author><keyname>Roberts</keyname><forenames>Mike</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Pfister</keyname><forenames>Hanspeter</forenames></author></authors><title>Verifiable Computation with Massively Parallel Interactive Proofs</title><categories>cs.DC cs.CR</categories><comments>17 pages, 6 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the cloud computing paradigm has gained prominence, the need for
verifiable computation has grown increasingly urgent. The concept of verifiable
computation enables a weak client to outsource difficult computations to a
powerful, but untrusted, server. Protocols for verifiable computation aim to
provide the client with a guarantee that the server performed the requested
computations correctly, without requiring the client to perform the
computations herself. By design, these protocols impose a minimal computational
burden on the client. However, existing protocols require the server to perform
a large amount of extra bookkeeping in order to enable a client to easily
verify the results. Verifiable computation has thus remained a theoretical
curiosity, and protocols for it have not been implemented in real cloud
computing systems.
  Our goal is to leverage GPUs to reduce the server-side slowdown for
verifiable computation. To this end, we identify abundant data parallelism in a
state-of-the-art general-purpose protocol for verifiable computation,
originally due to Goldwasser, Kalai, and Rothblum, and recently extended by
Cormode, Mitzenmacher, and Thaler. We implement this protocol on the GPU,
obtaining 40-120x server-side speedups relative to a state-of-the-art
sequential implementation. For benchmark problems, our implementation reduces
the slowdown of the server to factors of 100-500x relative to the original
computations requested by the client. Furthermore, we reduce the already small
runtime of the client by 100x. Similarly, we obtain 20-50x server-side and
client-side speedups for related protocols targeted at specific streaming
problems. We believe our results demonstrate the immediate practicality of
using GPUs for verifiable computation, and more generally that protocols for
verifiable computation have become sufficiently mature to deploy in real cloud
computing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1354</identifier>
 <datestamp>2012-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1354</id><created>2012-02-07</created><updated>2012-11-01</updated><authors><author><keyname>Zhang</keyname><forenames>Zhenliang</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author><author><keyname>Pezeshki</keyname><forenames>Ali</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Howard</keyname><forenames>Stephen D.</forenames></author></authors><title>Error Probability Bounds for M-ary Relay Trees</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the detection error probabilities associated with an M-ary relay
tree, where the leaves of the tree correspond to identical and independent
sensors. Only these leaves are sensors. The root of the tree represents a
fusion center that makes the overall detection decision. Each of the other
nodes in the tree is a relay node that combines M summarized messages from its
immediate child nodes to form a single output message using the majority
dominance rule. We derive tight upper and lower bounds for the Type I and II
error probabilities at the fusion center as explicit functions of the number of
sensors in the case of binary message alphabets. These bounds characterize how
fast the error probabilities converge to 0 with respect to the number of
sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1359</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1359</id><created>2012-02-07</created><authors><author><keyname>Huang</keyname><forenames>Longbo</forenames></author><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Codes Can Reduce Queueing Delay in Data Centers</title><categories>math.OC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we quantify how much codes can reduce the data retrieval
latency in storage systems. By combining a simple linear code with a novel
request scheduling algorithm, which we call Blocking-one Scheduling (BoS), we
show analytically that it is possible to reduce data retrieval delay by up to
17% over currently popular replication-based strategies. Although in this work
we focus on a simplified setting where the storage system stores a single
content, the methodology developed can be applied to more general settings with
multiple contents. The results also offer insightful guidance to the design of
storage systems in data centers and content distribution networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1366</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1366</id><created>2012-02-07</created><authors><author><keyname>Bansal</keyname><forenames>Nidhi</forenames></author></authors><title>Investigation to implicate data on clouds</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing can and does mean different things to different people. The
common characteristics most shares are on-demand secure access to metered
services from nearly anywhere and dislocation of data from inside to outside
the organization. Vision of cloud computing as a new IT procurement model. The
system lifecycle, risks that are identified must be carefully balanced against
the security and privacy controls available and the expected benefits from
their utilization. Too many controls can be inefficient and ineffective, if the
benefits outweigh the costs and associated risks. In this micro research, we
characterize the problems related to security challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1367</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1367</id><created>2012-02-07</created><authors><author><keyname>McKelvey</keyname><forenames>Karissa</forenames></author><author><keyname>Rudnick</keyname><forenames>Alex</forenames></author><author><keyname>Conover</keyname><forenames>Michael D.</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Visualizing Communication on Social Media: Making Big Data Accessible</title><categories>cs.SI physics.soc-ph</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The broad adoption of the web as a communication medium has made it possible
to study social behavior at a new scale. With social media networks such as
Twitter, we can collect large data sets of online discourse. Social science
researchers and journalists, however, may not have tools available to make
sense of large amounts of data or of the structure of large social networks. In
this paper, we describe our recent extensions to Truthy, a system for
collecting and analyzing political discourse on Twitter. We introduce several
new analytical perspectives on online discourse with the goal of facilitating
collaboration between individuals in the computational and social sciences. The
design decisions described in this article are motivated by real-world use
cases developed in collaboration with colleagues at the Indiana University
School of Journalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1370</identifier>
 <datestamp>2015-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1370</id><created>2012-02-07</created><updated>2015-09-09</updated><authors><author><keyname>Neininger</keyname><forenames>Ralph</forenames></author><author><keyname>Sulzbach</keyname><forenames>Henning</forenames></author></authors><title>On a functional contraction method</title><categories>math.PR cs.DS</categories><comments>Published at http://dx.doi.org/10.1214/14-AOP919 in the Annals of
  Probability (http://www.imstat.org/aop/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOP-AOP919</report-no><journal-ref>Annals of Probability 2015, Vol. 43, No. 4, 1777-1822</journal-ref><doi>10.1214/14-AOP919</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for proving functional limit laws are developed for sequences of
stochastic processes which allow a recursive distributional decomposition
either in time or space. Our approach is an extension of the so-called
contraction method to the space $\mathcal{C}[0,1]$ of continuous functions
endowed with uniform topology and the space $\mathcal {D}[0,1]$ of
c\`{a}dl\`{a}g functions with the Skorokhod topology. The contraction method
originated from the probabilistic analysis of algorithms and random trees where
characteristics satisfy natural distributional recurrences. It is based on
stochastic fixed-point equations, where probability metrics can be used to
obtain contraction properties and allow the application of Banach's fixed-point
theorem. We develop the use of the Zolotarev metrics on the spaces
$\mathcal{C}[0,1]$ and $\mathcal{D}[0,1]$ in this context. Applications are
given, in particular, a short proof of Donsker's functional limit theorem is
derived and recurrences arising in the probabilistic analysis of algorithms are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1372</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1372</id><created>2012-02-07</created><updated>2013-05-09</updated><authors><author><keyname>Pola</keyname><forenames>Giordano</forenames></author><author><keyname>Di Benedetto</keyname><forenames>Maria D.</forenames></author></authors><title>Symbolic Models and Control of Discrete-Time Piecewise Affine Systems:
  An Approximate Simulation Approach</title><categories>cs.SY</categories><comments>11 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symbolic models have been recently used as a sound mathematical formalism for
the formal verification and control design of purely continuous and hybrid
systems. In this paper we propose a sequence of symbolic models that
approximates a discrete-time Piecewise Affine (PWA) system in the sense of
approximate simulation and converges to the PWA system in the so-called
simulation metric. Symbolic control design is then addressed with
specifications expressed in terms of non-deterministic finite automata. A
sequence of symbolic control strategies is derived which converges, in the
sense of simulation metric, to the maximal controller solving the given
specification on the PWA system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1387</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1387</id><created>2012-02-07</created><updated>2013-05-07</updated><authors><author><keyname>Salimi</keyname><forenames>Somayeh</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author><author><keyname>Salmasizadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Successive Secret Key Agreement over Generalized Multiple Access and
  Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to the fact that an
  extended version is accepted in IEEE J-SAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A secret key agreement framework between three users is considered in which
each of the users 1 and 2 intends to share a secret key with user 3 and users 1
and 2 are eavesdroppers with respect to each other. There is a generalized
discrete memoryless multiple access channel (GDMMAC) from users 1 and 2 to user
3 where the three users receive outputs from the channel. Furthermore, there is
a broadcast channel (BC) from user 3 to users 1 and 2. Secret key sharing is
intended where GDMMAC and BC can be successively used. In this framework, an
inner bound of the secret key capacity region is derived. Moreover, for a
special case where the channel inputs and outputs of the GDMAC and the BC form
Markov chains in some order, the secret key capacity region is derived. Also
the results are discussed through a binary example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1395</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1395</id><created>2012-02-07</created><authors><author><keyname>Yousefikhoshbakht</keyname><forenames>Majid</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Rahmati</keyname><forenames>Farhad</forenames></author></authors><title>Modification of the Elite Ant System in Order to Avoid Local Optimum
  Points in the Traveling Salesman Problem</title><categories>cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a new algorithm which is a modified version of the
elite ant system (EAS) algorithm. The new version utilizes an effective
criterion for escaping from the local optimum points. In contrast to the
classical EAC algorithms, the proposed algorithm uses only a global updating,
which will increase pheromone on the edges of the best (i.e. the shortest)
route and will at the same time decrease the amount of pheromone on the edges
of the worst (i.e. the longest) route. In order to assess the efficiency of the
new algorithm, some standard traveling salesman problems (TSPs) were studied
and their results were compared with classical EAC and other well-known
meta-heuristic algorithms. The results indicate that the proposed algorithm has
been able to improve the efficiency of the algorithms in all instances and it
is competitive with other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1398</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1398</id><created>2012-02-07</created><authors><author><keyname>Huemer</keyname><forenames>Mario</forenames></author><author><keyname>Onic</keyname><forenames>Alexander</forenames></author><author><keyname>Hofbauer</keyname><forenames>Christian</forenames></author></authors><title>Classical and Bayesian Linear Data Estimators for Unique Word OFDM</title><categories>cs.IT math.IT</categories><comments>Preprint, 13 pages</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 59, pp. 6073-6085,
  Dec. 2011</journal-ref><doi>10.1109/TSP.2011.2164912</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unique word - orthogonal frequency division multiplexing (UW-OFDM) is a novel
OFDM signaling concept, where the guard interval is built of a deterministic
sequence - the so-called unique word - instead of the conventional random
cyclic prefix. In contrast to previous attempts with deterministic sequences in
the guard interval the addressed UW-OFDM signaling approach introduces
correlations between the subcarrier symbols, which can be exploited by the
receiver in order to improve the bit error ratio performance. In this paper we
develop several linear data estimators specifically designed for UW-OFDM, some
based on classical and some based on Bayesian estimation theory. Furthermore,
we derive complexity optimized versions of these estimators, and we study their
individual complex multiplication count in detail. Finally, we evaluate the
estimators' performance for the additive white Gaussian noise channel as well
as for selected indoor multipath channel scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1409</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1409</id><created>2012-02-07</created><authors><author><keyname>Sebastiani</keyname><forenames>Roberto</forenames></author><author><keyname>Tomasi</keyname><forenames>Silvia</forenames></author></authors><title>Optimization in SMT with LA(Q) Cost Functions</title><categories>cs.AI cs.LO</categories><comments>A shorter version is currently under submission</comments><report-no>Technical report # DISI-12-003, DISI, University of Trento, Italy</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the contexts of automated reasoning and formal verification, important
decision problems are effectively encoded into Satisfiability Modulo Theories
(SMT). In the last decade efficient SMT solvers have been developed for several
theories of practical interest (e.g., linear arithmetic, arrays, bit-vectors).
Surprisingly, very few work has been done to extend SMT to deal with
optimization problems; in particular, we are not aware of any work on SMT
solvers able to produce solutions which minimize cost functions over
arithmetical variables. This is unfortunate, since some problems of interest
require this functionality.
  In this paper we start filling this gap. We present and discuss two general
procedures for leveraging SMT to handle the minimization of LA(Q) cost
functions, combining SMT with standard minimization techniques. We have
implemented the proposed approach within the MathSAT SMT solver. Due to the
lack of competitors in AR and SMT domains, we experimentally evaluated our
implementation against state-of-the-art tools for the domain of linear
generalized disjunctive programming (LGDP), which is closest in spirit to our
domain, on sets of problems which have been previously proposed as benchmarks
for the latter tools. The results show that our tool is very competitive with,
and often outperforms, these tools on these problems, clearly demonstrating the
potential of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1424</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1424</id><created>2012-02-07</created><updated>2012-10-07</updated><authors><author><keyname>Wei</keyname><forenames>Li</forenames></author><author><keyname>Qi</keyname><forenames>Wangdong</forenames></author></authors><title>Optimization in Multi-Frequency Interferometry Ranging: Theory and
  Experiment</title><categories>cs.IT math.IT</categories><comments>42 pages,16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-frequency interferometry (MFI) is well known as an accurate phase-based
measurement scheme. The paper reveals the inherent relationship of the
unambiguous measurement range (UMR), the outlier probability, the MSE
performance with the frequency pattern in MFI system, and then provides the
corresponding criterion for choosing the frequency pattern. We point out that
the theoretical rigorous UMR of MFI deduced in the literature is usually
optimistic for practical application and derive a more practical expression .
It is found that the least-square (LS) estimator of MFI has a distinguished
&quot;double threshold effect&quot;. Distinct difference is observed for the MSE in
moderate and high signal-to-noise ratio (SNR) region (denoted by MMSE and HMSE
respectively) and the second threshold effect occurs during the rapid
transition from MMSE to HMSE with increasing SNR. The closed-form expressions
for the MMSE, HMSE and Cramer-Rao bound (CRB) are further derived, with HMSE
coinciding with CRB. Since the HMSE is insensitive to frequency pattern, we
focus on MMSE minimization by proper frequency optimization. We show that a
prime-based frequency interval can be exploited for the purpose of both outlier
suppression and UMR extension and design a special optimal rearrangement for
any set of frequency interval, in the sense of MMSE minimization. An extremely
simple frequency design method is finally developed. Simulation and field
experiment verified that the proposed scheme considerably outperforms the
existing method in UMR as well as MSE performance, especially in the transition
from MMSE to HMSE, for Gaussian and non-Gaussian channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1444</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1444</id><created>2012-02-07</created><updated>2013-01-30</updated><authors><author><keyname>Salazar</keyname><forenames>Augusto</forenames></author><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author><author><keyname>Shu</keyname><forenames>Chang</forenames></author><author><keyname>Prieto</keyname><forenames>Flavio</forenames></author></authors><title>Fully Automatic Expression-Invariant Face Correspondence</title><categories>cs.CV cs.GR</categories><journal-ref>Machine Vision and Applications, 25(4):859-879, 2014</journal-ref><doi>10.1007/s00138-013-0579-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing accurate point-to-point correspondences
among a set of human face scans with varying expressions. Our fully automatic
approach does not require any manually placed markers on the scan. Instead, the
approach learns the locations of a set of landmarks present in a database and
uses this knowledge to automatically predict the locations of these landmarks
on a newly available scan. The predicted landmarks are then used to compute
point-to-point correspondences between a template model and the newly available
scan. To accurately fit the expression of the template to the expression of the
scan, we use as template a blendshape model. Our algorithm was tested on a
database of human faces of different ethnic groups with strongly varying
expressions. Experimental results show that the obtained point-to-point
correspondence is both highly accurate and consistent for most of the tested 3D
face models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1449</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1449</id><created>2012-02-07</created><authors><author><keyname>Adhikary</keyname><forenames>Ansuman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>On the Coexistence of Macrocell Spatial Multiplexing and Cognitive
  Femtocells</title><categories>cs.IT math.IT</categories><comments>Submitted to the 1st International Workshop on Small Cell Wireless
  Networks (SmallNets), ICC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a two-tier macrocell/femtocell system where the macrocell base
station is equipped with multiple antennas and makes use of multiuser MIMO
(spatial multiplexing), and the femtocells are &quot;cognitive&quot;. In particular, we
assume that the femtocells are aware of the locations of scheduled macrocell
users on every time-frequency slot, so that they can make decisions on their
transmission opportunities accordingly. Femtocell base stations are also
equipped with multiple antennas. We propose a scheme where the macrocell
downlink (macro- DL) is aligned with the femtocells uplink (femto-UL) and, Vice
Versa, the macrocell uplink (macro-UL) is aligned with the femtocells downlink
femto-DL). Using a simple &quot;interference temperature&quot; power control in the
macro-DL/femto-UL direction, and exploiting uplink/downlink duality and the
Yates, Foschini and Miljanic distributed power control algorithm in the macro-
UL/femto-DL direction, we can achieve an extremely attractive macro/femto
throughput tradeoff region in both directions. We investigate the impact of
multiuser MIMO spatial multiplexing in the macrocell under the proposed scheme,
and find that large gains are achievable by letting the macrocell schedule
groups of co-located users, such that the number of femtocells affected by the
interference temperature power constraint is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1456</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1456</id><created>2012-02-07</created><authors><author><keyname>Eshete</keyname><forenames>Addisu</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>On the Transient Behavior of CHOKe</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CHOKe is a simple and stateless active queue management (AQM) scheme. Apart
from low operational overhead, a highly attractive property of CHOKe is that it
can protect responsive TCP flows from unresponsive UDP flows. Particularly,
previous works have proven that CHOKe is able to bound both bandwidth share and
buffer share of (a possible aggregate) UDP traffic (flow) on a link. However,
these studies consider, and pertain only to, a steady state where the queue
reaches equilibrium in the presence of many (long-lived) TCP flows and an
unresponsive UDP flow of fixed arrival rate. If the steady state conditions are
perturbed, particularly when UDP traffic rate changes over time, it is unclear
whether the protection property of CHOKe still holds. Indeed, it can be
examined, for example, that when UDP rate suddenly becomes 0 (i.e., flow
stops), the unresponsive flow may assume close to full utilization in sub-RTT
scales, potentially starving out the TCP flows. To explain this apparent
discrepancy, this paper investigates CHOKe queue properties in a transient
regime, which is the time period of transition between two steady states of the
queue, initiated when the rate of the unresponsive flow changes. Explicit
expressions that characterize flow throughputs in transient regimes are
derived. These results provide additional understanding of CHOKe, and give some
explanation on its intriguing behavior in the transient regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1458</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1458</id><created>2012-02-07</created><updated>2012-05-20</updated><authors><author><keyname>Williamson</keyname><forenames>Adam R.</forenames></author><author><keyname>Chen</keyname><forenames>Tsung-Yi</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>A Rate-Compatible Sphere-Packing Analysis of Feedback Coding with
  Limited Retransmissions</title><categories>cs.IT math.IT</categories><comments>To be published at the 2012 IEEE International Symposium on
  Information Theory, Cambridge, MA, USA. Updated to incorporate reviewers'
  comments and add new figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work by Polyanskiy et al. and Chen et al. has excited new interest in
using feedback to approach capacity with low latency. Polyanskiy showed that
feedback identifying the first symbol at which decoding is successful allows
capacity to be approached with surprisingly low latency. This paper uses Chen's
rate-compatible sphere-packing (RCSP) analysis to study what happens when
symbols must be transmitted in packets, as with a traditional hybrid ARQ
system, and limited to relatively few (six or fewer) incremental transmissions.
  Numerical optimizations find the series of progressively growing cumulative
block lengths that enable RCSP to approach capacity with the minimum possible
latency. RCSP analysis shows that five incremental transmissions are sufficient
to achieve 92% of capacity with an average block length of fewer than 101
symbols on the AWGN channel with SNR of 2.0 dB.
  The RCSP analysis provides a decoding error trajectory that specifies the
decoding error rate for each cumulative block length. Though RCSP is an
idealization, an example tail-biting convolutional code matches the RCSP
decoding error trajectory and achieves 91% of capacity with an average block
length of 102 symbols on the AWGN channel with SNR of 2.0 dB. We also show how
RCSP analysis can be used in cases where packets have deadlines associated with
them (leading to an outage probability).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1464</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1464</id><created>2012-02-07</created><authors><author><keyname>Frank</keyname><forenames>Benjamin</forenames></author><author><keyname>Poese</keyname><forenames>Ingmar</forenames></author><author><keyname>Smaragdakis</keyname><forenames>Georgios</forenames></author><author><keyname>Uhlig</keyname><forenames>Steve</forenames></author><author><keyname>Feldmann</keyname><forenames>Anja</forenames></author></authors><title>Content-aware Traffic Engineering</title><categories>cs.NI</categories><comments>Also appears as TU-Berlin technical report 2012-3, ISSN: 1436-9915</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, a large fraction of Internet traffic is originated by Content
Providers (CPs) such as content distribution networks and hyper-giants. To cope
with the increasing demand for content, CPs deploy massively distributed
infrastructures. This poses new challenges for CPs as they have to dynamically
map end-users to appropriate servers, without being fully aware of network
conditions within an ISP as well as the end-users network locations.
Furthermore, ISPs struggle to cope with rapid traffic shifts caused by the
dynamic server selection process of CPs.
  In this paper, we argue that the challenges that CPs and ISPs face separately
today can be turned into an opportunity. We show how they can jointly take
advantage of the deployed distributed infrastructures to improve their
operation and end-user performance. We propose Content-aware Traffic
Engineering (CaTE), which dynamically adapts the traffic demand for content
hosted on CPs by utilizing ISP network information and end-user location during
the server selection process. As a result, CPs enhance their end-user to server
mapping and improve end-user experience, thanks to the ability of
network-informed server selection to circumvent network bottlenecks. In
addition, ISPs gain the ability to partially influence the traffic demands in
their networks. Our results with operational data show improvements in path
length and delay between end-user and the assigned CP server, network wide
traffic reduction of up to 15%, and a decrease in ISP link utilization of up to
40% when applying CaTE to traffic delivered by a small number of major CPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1467</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1467</id><created>2012-02-07</created><updated>2012-07-23</updated><authors><author><keyname>Badiu</keyname><forenames>Mihai-Alin</forenames></author><author><keyname>Kirkelund</keyname><forenames>Gunvor Elisabeth</forenames></author><author><keyname>Manch&#xf3;n</keyname><forenames>Carles Navarro</forenames></author><author><keyname>Riegler</keyname><forenames>Erwin</forenames></author><author><keyname>Fleury</keyname><forenames>Bernard Henri</forenames></author></authors><title>Message-Passing Algorithms for Channel Estimation and Decoding Using
  Approximate Inference</title><categories>cs.IT math.IT stat.ML</categories><comments>Accepted for publication in the Proceedings of 2012 IEEE
  International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design iterative receiver schemes for a generic wireless communication
system by treating channel estimation and information decoding as an inference
problem in graphical models. We introduce a recently proposed inference
framework that combines belief propagation (BP) and the mean field (MF)
approximation and includes these algorithms as special cases. We also show that
the expectation propagation and expectation maximization algorithms can be
embedded in the BP-MF framework with slight modifications. By applying the
considered inference algorithms to our probabilistic model, we derive four
different message-passing receiver schemes. Our numerical evaluation
demonstrates that the receiver based on the BP-MF framework and its variant
based on BP-EM yield the best compromise between performance, computational
complexity and numerical stability among all candidate algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1483</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1483</id><created>2012-02-07</created><authors><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author><author><keyname>Sheffet</keyname><forenames>Or</forenames></author></authors><title>Send Mixed Signals -- Earn More, Work Less</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emek et al. presented a model of probabilistic single-item second price
auctions where an auctioneer who is informed about the type of an item for
sale, broadcasts a signal about this type to uninformed bidders. They proved
that finding the optimal (for the purpose of generating revenue) {\em pure}
signaling scheme is strongly NP-hard. In contrast, we prove that finding the
optimal {\em mixed} signaling scheme can be done in polynomial time using
linear programming. For the proof, we show that the problem is strongly related
to a problem of optimally bundling divisible goods for auctioning. We also
prove that a mixed signaling scheme can in some cases generate twice as much
revenue as the best pure signaling scheme and we prove a generally applicable
lower bound on the revenue generated by the best mixed signaling scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1484</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1484</id><created>2012-02-07</created><authors><author><keyname>Kittichokechai</keyname><forenames>Kittipong</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias J.</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Coding With Action-dependent Side Information and Additional
  Reconstruction Requirements</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constrained lossy source coding and channel coding with side information
problems which extend the classic Wyner-Ziv and Gel'fand-Pinsker problems are
considered. Inspired by applications in sensor networking and control, we first
consider lossy source coding with two-sided partial side information where the
quality/availability of the side information can be influenced by a
cost-constrained action sequence. A decoder reconstructs a source sequence
subject to the distortion constraint, and at the same time, an encoder is
additionally required to be able to estimate the decoder's reconstruction.
Next, we consider the channel coding &quot;dual&quot; where the channel state is assumed
to depend on the action sequence, and the decoder is required to decode both
the transmitted message and channel input reliably. Implications on the
fundamental limits of communication in discrete memoryless systems due to the
additional reconstruction constraints are investigated. Single-letter
expressions for the rate-distortion-cost function and channel capacity for the
respective source and channel coding problems are derived. The dual relation
between the two problems is discussed. Additionally, based on the two-stage
coding structure and the additional reconstruction constraint of the channel
coding problem, we discuss and give an interpretation of the two-stage coding
condition which appears in the channel capacity expression. Besides the rate
constraint on the message, this condition is a necessary and sufficient
condition for reliable transmission of the channel input sequence over the
channel in our &quot;two-stage&quot; communication problem. It is also shown in one
example that there exists a case where the two-stage coding condition can be
active in computing the capacity, and it thus can actively restrict the set of
capacity achieving input distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1490</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1490</id><created>2012-02-07</created><authors><author><keyname>Krishnamoorthy</keyname><forenames>Aravindh</forenames></author><author><keyname>Kocagoez</keyname><forenames>Kenan</forenames></author></authors><title>Singular Values using Cholesky Decomposition</title><categories>cs.MS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two ways to compute singular values are presented which use
Cholesky decomposition as their basic operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1498</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1498</id><created>2012-02-07</created><authors><author><keyname>Samalam</keyname><forenames>Vijay K</forenames></author></authors><title>Preferential attachment alone is not sufficient to generate scale free
  random networks</title><categories>physics.soc-ph cs.SI</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many networks exhibit scale free behavior where their degree distribution
obeys a power law for large vertex degrees. Models constructed to explain this
phenomena have relied on preferential attachment where the networks grow by the
addition of both vertices and edges, and the edges attach themselves to a
vertex with a probability proportional to its degree. Simulations hint, though
not conclusively, that both growth and preferential attachment are necessary
for scale free behavior. We derive analytic expressions for degree
distributions for networks that grow by the addition of edges to a fixed number
of vertices, based on both linear and non-linear preferential attachment, and
show that they fall off exponentially as would be expected for purely random
networks. From this we conclude that preferential attachment alone might be
necessary but is certainly not a sufficient condition for generating scale free
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1523</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1523</id><created>2012-02-07</created><authors><author><keyname>Yi</keyname><forenames>Zhao</forenames></author><author><keyname>Soatto</keyname><forenames>Stefano</forenames></author><author><keyname>Dewan</keyname><forenames>Maneesh</forenames></author><author><keyname>Zhan</keyname><forenames>Yiqiang</forenames></author></authors><title>Information Forests</title><categories>cs.LG stat.ML</categories><comments>Proceedings of the Information Theory and Applications (ITA)
  Workshop, 2/7/2012</comments><report-no>UCLA CSD TR120002</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe Information Forests, an approach to classification that
generalizes Random Forests by replacing the splitting criterion of non-leaf
nodes from a discriminative one -- based on the entropy of the label
distribution -- to a generative one -- based on maximizing the information
divergence between the class-conditional distributions in the resulting
partitions. The basic idea consists of deferring classification until a measure
of &quot;classification confidence&quot; is sufficiently high, and instead breaking down
the data so as to maximize this measure. In an alternative interpretation,
Information Forests attempt to partition the data into subsets that are &quot;as
informative as possible&quot; for the purpose of the task, which is to classify the
data. Classification confidence, or informative content of the subsets, is
quantified by the Information Divergence. Our approach relates to active
learning, semi-supervised learning, mixed generative/discriminative learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1542</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1542</id><created>2012-02-07</created><authors><author><keyname>Albert</keyname><forenames>Michael</forenames></author><author><keyname>Atkinson</keyname><forenames>M. D.</forenames></author></authors><title>Pattern classes and priority queues</title><categories>math.CO cs.DM</categories><msc-class>05A05, 68P05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a set of permutations comprising a pattern class C is submitted as input
to a priority queue the resulting output is again a pattern class C'. The basis
of C' is determined for pattern classes C whose basis elements have length 3,
and is finite in these cases. An example is given of a class C with basis 2431
for which C is not finitely based.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1547</identifier>
 <datestamp>2015-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1547</id><created>2012-02-07</created><updated>2014-02-16</updated><authors><author><keyname>Hernandez</keyname><forenames>Penelope</forenames></author><author><keyname>von Stengel</keyname><forenames>Bernhard</forenames></author></authors><title>Nash Codes for Noisy Channels</title><categories>cs.GT cs.IT math.IT</categories><comments>More general main Theorem 6.5 with better proof. New examples and
  introduction</comments><msc-class>91A28</msc-class><journal-ref>Operations Research 62:6, 1221-1235 (2014)</journal-ref><doi>10.1287/opre.2014.1311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the stability of communication protocols that deal with
transmission errors. We consider a coordination game between an informed sender
and an uninformed decision maker, the receiver, who communicate over a noisy
channel. The sender's strategy, called a code, maps states of nature to
signals. The receiver's best response is to decode the received channel output
as the state with highest expected receiver payoff. Given this decoding, an
equilibrium or &quot;Nash code&quot; results if the sender encodes every state as
prescribed. We show two theorems that give sufficient conditions for Nash
codes. First, a receiver-optimal code defines a Nash code. A second, more
surprising observation holds for communication over a binary channel which is
used independently a number of times, a basic model of information
transmission: Under a minimal &quot;monotonicity&quot; requirement for breaking ties when
decoding, which holds generically, EVERY code is a Nash code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1552</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1552</id><created>2012-02-07</created><authors><author><keyname>Zaier</keyname><forenames>Aida</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Channel Estimation Study for Block - Pilot Insertion in OFDM Systems
  under Slowly Time Varying Conditions</title><categories>cs.OH</categories><comments>16 pages, 10 figures; International Journal of Computer Networks &amp;
  Communications (IJCNC) Vol.3, No.6, November 2011, 39-54</comments><doi>10.5121/ijcnc.2011.3603</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a study of performance of the channel estimation
using LS, MMSE, LMMSE and Lr-LMMSE algorithms in OFDM (Orthogonal Frequency
Division Multiplexing) system which, as known suffers from the time variation
of the channel under high mobility conditions, using block pilot insertion. The
loss of sub channel orthogonality leads to inter-carrier interference (ICI).
Using many algorithms for channel estimation, we will show that, for a 16- QAM
modulation, the LMMSE algorithm performs well to achieve this estimation but
when the SNR (Signal Noise Rate) is high, the four algorithms (LS, MMSE, LMMSE
and Lr-LMMSE) perform similarly, this is not always the case for another scheme
of modulation. We will improve also the mean squared error for these
algorithms. It will be illustrious in this paper that the LMMSE algorithm
performs well with the block- pilot insertion as well as its low rank version
which behave very good even when the size of FFT is very high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1558</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1558</id><created>2012-02-07</created><authors><author><keyname>Ratia</keyname><forenames>H&#xe9;ctor</forenames></author><author><keyname>Montesano</keyname><forenames>Luis</forenames></author><author><keyname>Martinez-Cantin</keyname><forenames>Ruben</forenames></author></authors><title>On the Performance of Maximum Likelihood Inverse Reinforcement Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inverse reinforcement learning (IRL) addresses the problem of recovering a
task description given a demonstration of the optimal policy used to solve such
a task. The optimal policy is usually provided by an expert or teacher, making
IRL specially suitable for the problem of apprenticeship learning. The task
description is encoded in the form of a reward function of a Markov decision
process (MDP). Several algorithms have been proposed to find the reward
function corresponding to a set of demonstrations. One of the algorithms that
has provided best results in different applications is a gradient method to
optimize a policy squared error criterion. On a parallel line of research,
other authors have presented recently a gradient approximation of the maximum
likelihood estimate of the reward signal. In general, both approaches
approximate the gradient estimate and the criteria at different stages to make
the algorithm tractable and efficient. In this work, we provide a detailed
description of the different methods to highlight differences in terms of
reward estimation, policy similarity and computational costs. We also provide
experimental results to evaluate the differences in performance of the methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1565</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1565</id><created>2012-02-07</created><updated>2012-02-28</updated><authors><author><keyname>Cs&#xf3;ka</keyname><forenames>Endre</forenames></author></authors><title>Random local algorithms</title><categories>math.CO cs.DC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem when we want to construct some structure on a bounded
degree graph, e.g. an almost maximum matching, and we want to decide about each
edge depending only on its constant radius neighbourhood. We show that the
information about the local statistics of the graph does not help here. Namely,
if there exists a random local algorithm which can use any local statistics
about the graph, and produces an almost optimal structure, then the same can be
achieved by a random local algorithm using no statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1567</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1567</id><created>2012-02-07</created><authors><author><keyname>Nix</keyname><forenames>Robert</forenames></author><author><keyname>Kantarcioglu</keyname><forenames>Murat</forenames></author></authors><title>Efficient Query Verification on Outsourced Data: A Game-Theoretic
  Approach</title><categories>cs.GT cs.DC</categories><comments>13 pages, 8 figures, pre-publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To save time and money, businesses and individuals have begun outsourcing
their data and computations to cloud computing services. These entities would,
however, like to ensure that the queries they request from the cloud services
are being computed correctly. In this paper, we use the principles of economics
and competition to vastly reduce the complexity of query verification on
outsourced data. We consider two cases: First, we consider the scenario where
multiple non-colluding data outsourcing services exist, and then we consider
the case where only a single outsourcing service exists. Using a game theoretic
model, we show that given the proper incentive structure, we can effectively
deter dishonest behavior on the part of the data outsourcing services with very
few computational and monetary resources. We prove that the incentive for an
outsourcing service to cheat can be reduced to zero. Finally, we show that a
simple verification method can achieve this reduction through extensive
experimental evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1568</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1568</id><created>2012-02-07</created><updated>2013-08-08</updated><authors><author><keyname>Kim</keyname><forenames>Seungyeon</forenames></author><author><keyname>Li</keyname><forenames>Fuxin</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author><author><keyname>Essa</keyname><forenames>Irfan</forenames></author></authors><title>Beyond Sentiment: The Manifold of Human Emotions</title><categories>cs.CL</categories><comments>15 pages, 7 figures</comments><journal-ref>Proceedings of the 16 International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2013, Scottsdale, AZ, USA. Volume 31 of
  JMLR: W&amp;CP 31</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sentiment analysis predicts the presence of positive or negative emotions in
a text document. In this paper we consider higher dimensional extensions of the
sentiment concept, which represent a richer set of human emotions. Our approach
goes beyond previous work in that our model contains a continuous manifold
rather than a finite set of human emotions. We investigate the resulting model,
compare it to psychological observations, and explore its predictive
capabilities. Besides obtaining significant improvements over a baseline
without manifold, we are also able to visualize different notions of positive
sentiment in different domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1569</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1569</id><created>2012-02-07</created><updated>2012-02-16</updated><authors><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Nonrepetitive Colourings of Planar Graphs with $O(\log n)$ Colours</title><categories>math.CO cs.DM</categories><journal-ref>Electronic Journal of Combinatorics, 20/1:P51, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vertex colouring of a graph is \emph{nonrepetitive} if there is no path for
which the first half of the path is assigned the same sequence of colours as
the second half. The \emph{nonrepetitive chromatic number} of a graph $G$ is
the minimum integer $k$ such that $G$ has a nonrepetitive $k$-colouring.
Whether planar graphs have bounded nonrepetitive chromatic number is one of the
most important open problems in the field. Despite this, the best known upper
bound is $O(\sqrt{n})$ for $n$-vertex planar graphs. We prove a $O(\log n)$
upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1572</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1572</id><created>2012-02-07</created><authors><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Appaiah</keyname><forenames>Kumar</forenames></author><author><keyname>Si</keyname><forenames>Hongbo</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Expansion coding: Achieving the capacity of an AEN channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general method of coding over expansions is proposed, which allows one to
reduce the highly non-trivial problem of coding over continuous channels to a
much simpler discrete ones. More specifically, the focus is on the additive
exponential noise (AEN) channel, for which the (binary) expansion of the
(exponential) noise random variable is considered. It is shown that each of the
random variables in the expansion corresponds to independent Bernoulli random
variables. Thus, each of the expansion levels (of the underlying channel)
corresponds to a binary symmetric channel (BSC), and the coding problem is
reduced to coding over these parallel channels while satisfying the channel
input constraint. This optimization formulation is stated as the achievable
rate result, for which a specific choice of input distribution is shown to
achieve a rate which is arbitrarily close to the channel capacity in the high
SNR regime. Remarkably, the scheme allows for low-complexity capacity-achieving
codes for AEN channels, using the codes that are originally designed for BSCs.
Extensions to different channel models and applications to other coding
problems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1574</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1574</id><created>2012-02-07</created><updated>2012-07-03</updated><authors><author><keyname>Huang</keyname><forenames>Dayu</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author></authors><title>Classification with High-Dimensional Sparse Samples</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>final draft submitted to ISIT 2012</comments><msc-class>62G10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of the binary classification problem is to determine which of two
distributions has generated a length-$n$ test sequence. The two distributions
are unknown; two training sequences of length $N$, one from each distribution,
are observed. The distributions share an alphabet of size $m$, which is
significantly larger than $n$ and $N$. How does $N,n,m$ affect the probability
of classification error? We characterize the achievable error rate in a
high-dimensional setting in which $N,n,m$ all tend to infinity, under the
assumption that probability of any symbol is $O(m^{-1})$. The results are:
  1. There exists an asymptotically consistent classifier if and only if
$m=o(\min\{N^2,Nn\})$. This extends the previous consistency result in [1] to
the case $N\neq n$.
  2. For the sparse sample case where $\max\{n,N\}=o(m)$, finer results are
obtained: The best achievable probability of error decays as $-\log(P_e)=J
\min\{N^2, Nn\}(1+o(1))/m$ with $J&gt;0$.
  3. A weighted coincidence-based classifier has non-zero generalized error
exponent $J$.
  4. The $\ell_2$-norm based classifier has J=0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1584</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1584</id><created>2012-02-07</created><updated>2012-02-19</updated><authors><author><keyname>Han</keyname><forenames>Kai</forenames></author><author><keyname>Xiang</keyname><forenames>Liu</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author></authors><title>MEGCOM: Min-Energy Group COMmunication in Multi-hop Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the increasing demand from wireless applications, designing
energy-efficient group communication protocols is of great importance to
multi-hop wireless networks. A group communication session involves a set of
member nodes, each of them needs to send a certain number of data packets to
all other members. In this paper, we consider the problem of building a shared
multicast tree spanning the member nodes such that the total energy consumption
of a group communication session using the shared multicast tree is minimized.
Since this problem was proven as NP-complete, we propose, under our Min-Energy
Group COMmunication (MEGCOM) framework, three distributed approximation
algorithms with provable approximation ratios. When the transmission power of
each wireless node is fixed, our first two algorithms have the approximation
ratios of O(ln(\Delta+ 1)) and O(1), respectively, where \Delta is the maximum
node degree in the network. When the transmission power of each wireless node
is adjustable, our third algorithm again delivers a constant approximation
ratio. We also use extensive simulations to verify the practical performance of
our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1585</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1585</id><created>2012-02-07</created><authors><author><keyname>Pavan</keyname><forenames>K. Karteeka</forenames></author><author><keyname>Rao</keyname><forenames>Allam Appa</forenames></author><author><keyname>Rao</keyname><forenames>A. V. Dattatreya</forenames></author><author><keyname>Sridhar</keyname><forenames>G. R.</forenames></author></authors><title>Robust seed selection algorithm for k-means type algorithms</title><categories>cs.CV cs.CE</categories><comments>17 pages, 5 tables, 9figures</comments><msc-class>62H30</msc-class><acm-class>I.5.3</acm-class><journal-ref>International Journal of Computer Science and Technology (IJCSIT),
  Vol 3, No 5, Oct 2011 pp 147-163</journal-ref><doi>10.5121/ijcsit.2011.3513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selection of initial seeds greatly affects the quality of the clusters and in
k-means type algorithms. Most of the seed selection methods result different
results in different independent runs. We propose a single, optimal, outlier
insensitive seed selection algorithm for k-means type algorithms as extension
to k-means++. The experimental results on synthetic, real and on microarray
data sets demonstrated that effectiveness of the new algorithm in producing the
clustering results
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1587</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1587</id><created>2012-02-07</created><authors><author><keyname>Pavan</keyname><forenames>K. Karteeka</forenames></author><author><keyname>Rao</keyname><forenames>Allam Appa</forenames></author><author><keyname>Rao</keyname><forenames>A. V. Dattatreya</forenames></author></authors><title>Automatic Clustering with Single Optimal Solution</title><categories>cs.CV</categories><comments>13 pages,4 Tables, 3 figures</comments><msc-class>62H30</msc-class><acm-class>I.5.3</acm-class><journal-ref>Computer Engineering and Intelligent Systems, 2011, vol no.2 no.4
  pp149-161</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining optimal number of clusters in a dataset is a challenging task.
Though some methods are available, there is no algorithm that produces unique
clustering solution. The paper proposes an Automatic Merging for Single Optimal
Solution (AMSOS) which aims to generate unique and nearly optimal clusters for
the given datasets automatically. The AMSOS is iteratively merges the closest
clusters automatically by validating with cluster validity measure to find
single and nearly optimal clusters for the given data set. Experiments on both
synthetic and real data have proved that the proposed algorithm finds single
and nearly optimal clustering structure in terms of number of clusters,
compactness and separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1590</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1590</id><created>2012-02-07</created><updated>2012-04-24</updated><authors><author><keyname>Emek</keyname><forenames>Yuval</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Gamzu</keyname><forenames>Iftah</forenames></author><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Signaling Schemes for Revenue Maximization</title><categories>cs.GT</categories><comments>accepted to EC'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signaling is an important topic in the study of asymmetric information in
economic settings. In particular, the transparency of information available to
a seller in an auction setting is a question of major interest. We introduce
the study of signaling when conducting a second price auction of a
probabilistic good whose actual instantiation is known to the auctioneer but
not to the bidders. This framework can be used to model impressions selling in
display advertising. We study the problem of computing a signaling scheme that
maximizes the auctioneer's revenue in a Bayesian setting. While the general
case is proved to be computationally hard, several cases of interest are shown
to be polynomially solvable. In addition, we establish a tight bound on the
minimum number of signals required to implement an optimal signaling scheme and
show that at least half of the maximum social welfare can be preserved within
such a scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1595</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1595</id><created>2012-02-07</created><updated>2012-06-08</updated><authors><author><keyname>Hegde</keyname><forenames>Chinmay</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Signal Recovery on Incoherent Manifolds</title><categories>cs.IT math.IT stat.ML</categories><comments>20 pages, 3 figures. Submitted to IEEE Trans. Inform. Theory. Revised
  version (June 2012) : fixed typos in proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that we observe noisy linear measurements of an unknown signal that
can be modeled as the sum of two component signals, each of which arises from a
nonlinear sub-manifold of a high dimensional ambient space. We introduce SPIN,
a first order projected gradient method to recover the signal components.
Despite the nonconvex nature of the recovery problem and the possibility of
underdetermined measurements, SPIN provably recovers the signal components,
provided that the signal manifolds are incoherent and that the measurement
operator satisfies a certain restricted isometry property. SPIN significantly
extends the scope of current recovery models and algorithms for low dimensional
linear inverse problems and matches (or exceeds) the current state of the art
in terms of performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1596</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1596</id><created>2012-02-07</created><authors><author><keyname>Ntranos</keyname><forenames>Vasileios</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author></authors><title>Allocations for Heterogenous Distributed Storage</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of storing a data object in a set of data nodes that
fail independently with given probabilities. Our problem is a natural
generalization of a homogenous storage allocation problem where all the nodes
had the same reliability and is naturally motivated for peer-to-peer and cloud
storage systems with different types of nodes. Assuming optimal erasure coding
(MDS), the goal is to find a storage allocation (i.e, how much to store in each
node) to maximize the probability of successful recovery. This problem turns
out to be a challenging combinatorial optimization problem. In this work we
introduce an approximation framework based on large deviation inequalities and
convex optimization. We propose two approximation algorithms and study the
asymptotic performance of the resulting allocations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1612</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1612</id><created>2012-02-08</created><authors><author><keyname>Milosavljevic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Data Exchange Problem with Helpers</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we construct a deterministic polynomial time algorithm for the
problem where a set of users is interested in gaining access to a common file,
but where each has only partial knowledge of the file. We further assume the
existence of another set of terminals in the system, called helpers, who are
not interested in the common file, but who are willing to help the users. Given
that the collective information of all the terminals is sufficient to allow
recovery of the entire file, the goal is to minimize the (weighted) sum of bits
that these terminals need to exchange over a noiseless public channel in order
achieve this goal. Based on established connections to the multi-terminal
secrecy problem, our algorithm also implies a polynomial-time method for
constructing the largest shared secret key in the presence of an eavesdropper.
We consider the following side-information settings: (i) side-information in
the form of uncoded packets of the file, where the terminals' side-information
consists of subsets of the file; (ii) side-information in the form of linearly
correlated packets, where the terminals have access to linear combinations of
the file packets; and (iii) the general setting where the the terminals'
side-information has an arbitrary (i.i.d.) correlation structure. We provide a
polynomial-time algorithm (in the number of terminals) that finds the optimal
rate allocations for these terminals, and then determines an explicit optimal
transmission scheme for cases (i) and (ii).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1618</identifier>
 <datestamp>2015-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1618</id><created>2012-02-08</created><updated>2012-11-15</updated><authors><author><keyname>Sutter</keyname><forenames>Tobias</forenames></author><author><keyname>Chatterjee</keyname><forenames>Debasish</forenames></author><author><keyname>Ramponi</keyname><forenames>Federico</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>Isospectral flows on a class of finite-dimensional Jacobi matrices</title><categories>math.DS cs.SY math.OC</categories><comments>19 pages, 3 figures, conjecture from previous version is added as
  assertion (iv) of the main theorem including a proof; other major changes</comments><msc-class>37C10</msc-class><doi>10.1016/j.sysconle.2013.02.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new matrix-valued isospectral ordinary differential equation
that asymptotically block-diagonalizes $n\times n$ zero-diagonal Jacobi
matrices employed as its initial condition. This o.d.e.\ features a right-hand
side with a nested commutator of matrices, and structurally resembles the
double-bracket o.d.e.\ studied by R.W.\ Brockett in 1991. We prove that its
solutions converge asymptotically, that the limit is block-diagonal, and above
all, that the limit matrix is defined uniquely as follows: For $n$ even, a
block-diagonal matrix containing $2\times 2$ blocks, such that the
super-diagonal entries are sorted by strictly increasing absolute value.
Furthermore, the off-diagonal entries in these $2\times 2$ blocks have the same
sign as the respective entries in the matrix employed as initial condition. For
$n$ odd, there is one additional $1\times 1$ block containing a zero that is
the top left entry of the limit matrix. The results presented here extend some
early work of Kac and van Moerbeke.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1639</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1639</id><created>2012-02-08</created><authors><author><keyname>Antulov-Fantulin</keyname><forenames>Nino</forenames></author><author><keyname>Lancic</keyname><forenames>Alen</forenames></author><author><keyname>Stefancic</keyname><forenames>Hrvoje</forenames></author><author><keyname>Sikic</keyname><forenames>Mile</forenames></author></authors><title>FastSIR Algorithm: A Fast Algorithm for simulation of epidemic spread in
  large networks by using SIR compartment model</title><categories>cs.DS cs.SI physics.soc-ph</categories><comments>8 figures</comments><acm-class>G.3; I.6; F.2</acm-class><doi>10.1016/j.ins.2013.03.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The epidemic spreading on arbitrary complex networks is studied in SIR
(Susceptible Infected Recovered) compartment model. We propose our
implementation of a Naive SIR algorithm for epidemic simulation spreading on
networks that uses data structures efficiently to reduce running time. The
Naive SIR algorithm models full epidemic dynamics and can be easily upgraded to
parallel version. We also propose novel algorithm for epidemic simulation
spreading on networks called the FastSIR algorithm that has better average case
running time than the Naive SIR algorithm. The FastSIR algorithm uses novel
approach to reduce average case running time by constant factor by using
probability distributions of the number of infected nodes. Moreover, the
FastSIR algorithm does not follow epidemic dynamics in time, but still captures
all infection transfers. Furthermore, we also propose an efficient recursive
method for calculating probability distributions of the number of infected
nodes. Average case running time of both algorithms has also been derived and
experimental analysis was made on five different empirical complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1641</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1641</id><created>2012-02-08</created><authors><author><keyname>Accattoli</keyname><forenames>Beniamino</forenames></author><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author></authors><title>On the Invariance of the Unitary Cost Model for Head Reduction (Long
  Version)</title><categories>cs.LO cs.PL</categories><comments>22 pages</comments><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lambda calculus is a widely accepted computational model of higher-order
functional pro- grams, yet there is not any direct and universally accepted
cost model for it. As a consequence, the computational difficulty of reducing
lambda terms to their normal form is typically studied by reasoning on concrete
implementation algorithms. In this paper, we show that when head reduction is
the underlying dynamics, the unitary cost model is indeed invariant. This
improves on known results, which only deal with weak (call-by-value or
call-by-name) reduction. Invariance is proved by way of a linear calculus of
explicit substitutions, which allows to nicely decompose any head reduction
step in the lambda calculus into more elementary substitution steps, thus
making the combinatorics of head-reduction easier to reason about. The
technique is also a promising tool to attack what we see as the main open
problem, namely understanding for which normalizing strategies derivation
complexity is an invariant cost model, if any.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1643</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1643</id><created>2012-02-08</created><authors><author><keyname>Rajpaul</keyname><forenames>Vinesh</forenames></author></authors><title>Genetic algorithms in astronomy and astrophysics</title><categories>astro-ph.IM cs.NE</categories><comments>6 pages, 3 figures. Review paper in Proc. SAIP2011 (ISBN:
  978-1-86888-688-3), ed. I. Basson and A. E. Botha, available online at
  http://www.saip.org.za</comments><journal-ref>Proceedings of SAIP2011, the 56th Annual Conference of the South
  African Institute of Physics, pp. 519-524</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic algorithms (GAs) emulate the process of biological evolution, in a
computational setting, in order to generate good solutions to difficult search
and optimisation problems. GA-based optimisers tend to be extremely robust and
versatile compared to most traditional techniques used to solve optimisation
problems. This review paper provides a very brief introduction to GAs and
outlines their utility in astronomy and astrophysics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1644</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1644</id><created>2012-02-08</created><authors><author><keyname>Liron</keyname><forenames>Y.</forenames></author><author><keyname>Langberg</keyname><forenames>M.</forenames></author></authors><title>A characterization of the number of subsequences obtained via the
  deletion channel</title><categories>cs.IT math.IT</categories><comments>9 pages, 4 figures, a short version submitted to ISIT2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the study of deletion channels, this work presents improved
bounds on the number of subsequences obtained from a binary sting X of length n
under t deletions. It is known that the number of subsequences in this setting
strongly depends on the number of runs in the string X; where a run is a
maximal sequence of the same character. Our improved bounds are obtained by a
structural analysis of the family of r-run strings X, an analysis in which we
identify the extremal strings with respect to the number of subsequences.
Specifically, for every r, we present r-run strings with the minimum
(respectively maximum) number of subsequences under any t deletions; and
perform an exact analysis of the number of subsequences of these extremal
strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1656</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1656</id><created>2012-02-08</created><authors><author><keyname>Kienle</keyname><forenames>Holger M.</forenames></author></authors><title>Open Data: Reverse Engineering and Maintenance Perspective</title><categories>cs.SE cs.DL cs.IR</categories><comments>7 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Open data is an emerging paradigm to share large and diverse datasets --
primarily from governmental agencies, but also from other organizations -- with
the goal to enable the exploitation of the data for societal, academic, and
commercial gains. There are now already many datasets available with diverse
characteristics in terms of size, encoding and structure. These datasets are
often created and maintained in an ad-hoc manner. Thus, open data poses many
challenges and there is a need for effective tools and techniques to manage and
maintain it. In this paper we argue that software maintenance and reverse
engineering have an opportunity to contribute to open data and to shape its
future development. From the perspective of reverse engineering research, open
data is a new artifact that serves as input for reverse engineering techniques
and processes. Specific challenges of open data are document scraping, image
processing, and structure/schema recognition. From the perspective of
maintenance research, maintenance has to accommodate changes of open data
sources by third-party providers, traceability of data transformation
pipelines, and quality assurance of data and transformations. We believe that
the increasing importance of open data and the research challenges that it
brings with it may possibly lead to the emergence of new research streams for
reverse engineering as well as for maintenance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1663</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1663</id><created>2012-02-08</created><authors><author><keyname>Savu</keyname><forenames>Laura</forenames></author></authors><title>Signcryption scheme based on schnorr digital signature</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This article presents a new signcryption scheme which is based on the Schnorr
digital signature algorithm. The new scheme represents my personal contribution
to signcryption area. I have been implemented the algorithm in a program and
here are provided the steps of the algorithm, the results and some examples.
The paper also contains the presentation of the original Signcryption scheme,
based on ElGamal digital signature and discusses the practical applications of
Signcryption in real life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1664</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1664</id><created>2012-02-08</created><authors><author><keyname>Subramanian</keyname><forenames>Sridhar</forenames></author><author><keyname>Ramachandran</keyname><forenames>Baskaran</forenames></author></authors><title>Trust Based Scheme for QoS Assurance in Mobile Ad-Hoc Networks</title><categories>cs.NI</categories><doi>10.5121/ijnsa.2012.4108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad-hoc network (MANET) is a peer-to-peer wireless network where
nodes can communicate with each other without the use of infrastructure such as
access points or base stations. These networks are self-configuring, capable of
self-directed operation and hastily deployable. Nodes cooperate to provide
connectivity, operates without centralized administration. Nodes are itinerant,
topology can be very dynamic and nodes must be able to relay traffic since
communicating nodes might be out of range. The dynamic nature of MANET makes
network open to attacks and unreliability. Routing is always the most
significant part for any networks. Each node should not only work for itself,
but should be cooperative with other nodes. Node misbehaviour due to selfish or
malicious intention could significantly degrade the performance of MANET. The
Qos parameters like PDR, throughput and delay are affected directly due to such
misbehaving nodes. We focus on trust management framework, which is intended to
cope with misbehaviour problem of node and increase the performance of MANETs.
A trust-based system can be used to track this misbehaving of nodes, spot them
and isolate them from routing and provide reliability. In this paper a Trust
Based Reliable AODV [TBRAODV] protocol is presented which implements a trust
value for each node. For every node trust value is calculated and based trust
value nodes are allowed to participate in routing or else identified to become
a misbehaving node. This enhances reliability in AODV routing and results in
increase of PDR, decrease in delay and throughput is maintained. This work is
implemented and simulated on NS-2. Based on simulation results, the proposed
protocol provides more consistent and reliable data transfer compared with
general AODV, if there are misbehaving nodes in the MANET
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1677</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1677</id><created>2012-02-08</created><authors><author><keyname>Rhattoy</keyname><forenames>A.</forenames></author><author><keyname>Zatni</keyname><forenames>A.</forenames></author></authors><title>The impact of propagation environment and traffic load on the
  performance of routing protocols in ad hoc networks</title><categories>cs.NI</categories><comments>13 pages, 5 figures, International Journal of Distributed and
  Parallel Systems (IJDPS) Vol.3, No.1, January 2012</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.3, No.1, January 2012, 75-87</journal-ref><doi>10.5121/ijdps.2012.3106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networks are characterized by a dynamic topology triggered by the
nodes mobility. Thus, the wireless multi-hops connection and the channel do not
have a determinist behaviour such as: interference or multiple paths. Moreover,
the nodes' invisibility makes the wireless channel difficult to detect. This
wireless networks' behaviour should be scrutinized. In our study, we mainly
focus on radio propagation models by observing the evolution of the routing
layer's performances in terms of the characteristics of the physical layer. For
this purpose, we first examine and then display the simulation findings of the
impact of different radio propagation models on the performance of ad hoc
networks. To fully understand how these various radio models influence the
networks performance, we have compared the performances of several routing
protocols (DSR, AODV, and DSDV) for each propagation model. To complete our
study, a comparison of energy performance based routing protocols and
propagation models are presented. In order to reach credible results, we
focused on the notion of nodes' speed and the number of connections by using
the well known network simulator NS-2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1680</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1680</id><created>2012-02-08</created><authors><author><keyname>Patil</keyname><forenames>D. D. Kadam</forenames><affiliation>Department of E&amp;TC Vidya Pratishthan's CoE, Baramati, Maharashtra, India</affiliation></author><author><keyname>Shastri</keyname><forenames>R. K.</forenames><affiliation>Department of E&amp;TC Vidya Pratishthan's CoE, Baramati, Maharashtra, India</affiliation></author></authors><title>Design of wireless electronic stethoscope based on zigbee</title><categories>cs.OH</categories><comments>9 pages,7 figures, IJDPS journal; Published in journl IJDPS,January
  2012 issue</comments><doi>10.5121/ijdps.2012.3130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heart sound stethoscope is primary stage to access diseases. In this paper
design of an electronic stethoscope with the functions of wireless transmission
is discussed. This electronic stethoscope based on embedded processor. The data
can be transmitted through wireless transmission using Zigbee module. A
microphone is used to pick up the sound of the heart beat. Acoustic stethoscope
can be changed into a digital stethoscope by inserting an electric capacity
microphone into its head. The signal is processed and amplified to play with or
without earphone. Heart sounds are processed, sampled and sent wirelessly using
Zigbee module so that multiple doctors can do auscultation. PC connectivity is
provided through serial port where from audio and video can be made available
through LAN and internet for telemedicine consultation. Heart beat signals are
sensed, sent, displayed, monitored, stored, reviewed, and analysed with ease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1683</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1683</id><created>2012-02-08</created><authors><author><keyname>Mathews</keyname><forenames>Emi</forenames></author><author><keyname>Mathew</keyname><forenames>Ciby</forenames></author></authors><title>Deployment of mobile routers ensuring coverage and connectivity</title><categories>cs.RO cs.NI</categories><comments>International Journal of Computer Networks &amp; Communications (IJCNC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintaining connectivity among a group of autonomous agents exploring an area
is very important, as it promotes cooperation between the agents and also helps
message exchanges which are very critical for their mission. Creating an
underlying Ad-hoc Mobile Router Network (AMRoNet) using simple robotic routers
is an approach that facilitates communication between the agents without
restricting their movements. We address the following question in our paper:
How to create an AMRoNet with local information and with minimum number of
routers? We propose two new localized and distributed algorithms 1)
agent-assisted router deployment and 2) a self-spreading for creating AMRoNet.
The algorithms use a greedy deployment strategy for deploying routers
effectively into the area maximizing coverage and a triangular deployment
strategy to connect different connected component of routers from different
base stations. Empirical analysis shows that the proposed algorithms are the
two best localized approaches to create AMRoNets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1685</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1685</id><created>2012-02-08</created><authors><author><keyname>Balas</keyname><forenames>Valentina E.</forenames></author><author><keyname>Motoc</keyname><forenames>Iulia M.</forenames></author><author><keyname>Barbulescu</keyname><forenames>Alina</forenames></author></authors><title>Combined Haar-Hilbert and Log-Gabor Based Iris Encoders</title><categories>cs.CV</categories><comments>28 pages, 8 figures, 2 tables, book chapter</comments><msc-class>68T10</msc-class><acm-class>I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris
recognition performance leading to a less ambiguous biometric decision
landscape in which the overlap between the experimental intra- and interclass
score distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and
combined Haar-Hilbert and Log-Gabor encoders are tested here both for single
and dual iris approach. The experimental results confirm that the best
performance is obtained for the dual iris approach when the iris code is
generated using the combined Haar-Hilbert and Log-Gabor encoder, and when the
matching score fuses the information from both Haar-Hilbert and Log-Gabor
channels of the combined encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1691</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1691</id><created>2012-02-08</created><authors><author><keyname>Monisha</keyname><forenames>J. Hannah</forenames></author><author><keyname>Uthariaraj</keyname><forenames>V. Rhymend</forenames></author></authors><title>User profile based proportional share scheduling and mac protocol for
  manets</title><categories>cs.NI</categories><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.3, No.1, January 2012, 269-283</journal-ref><doi>10.5121/ijdps.2012.3123</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality of Service(QoS) in Mobile Ad Hoc Networks (MANETs) though a
challenge, becomes a necessity because of its applications in critical
scenarios. Providing QoS for users belonging to various profiles and playing
different roles, becomes the need of the hour. In this paper, we propose
proportional share scheduling and MAC protocol (PS2-MAC) model. It classifies
users based on their profile as High Profiled users (HP), Medium Profiled users
(MP) and Low profiled users (LP) and assigns proportional weights. Service
Differentiation for these three service classes is achieved through, rationed
dequeuing algorithm, variable inter frame space, proportionate prioritized
backoff timers and enhanced RTS/CTS control packets. Differentiated services is
simulated in ns2 and results show that 9.5% control overhead is reduced in our
proposed scheme than the existing scheme and results also justify that,
differentiated services have been achieved for the different profiles of users
with proportionate shares and thereby reducing starvation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1692</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1692</id><created>2012-02-08</created><authors><author><keyname>Wachter-Zeh</keyname><forenames>Antonia</forenames></author><author><keyname>Stinner</keyname><forenames>Markus</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>Efficient Decoding of Partial Unit Memory Codes of Arbitrary Rate</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial Unit Memory (PUM) codes are a special class of convolutional codes,
which are often constructed by means of block codes. Decoding of PUM codes may
take advantage of existing decoders for the block code. The Dettmar--Sorger
algorithm is an efficient decoding algorithm for PUM codes, but allows only low
code rates. The same restriction holds for several known PUM code
constructions. In this paper, an arbitrary-rate construction, the analysis of
its distance parameters and a generalized decoding algorithm for PUM codes of
arbitrary rate are provided. The correctness of the algorithm is proven and it
is shown that its complexity is cubic in the length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1694</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1694</id><created>2012-02-08</created><authors><author><keyname>Jiang</keyname><forenames>Yun</forenames></author><author><keyname>Lim</keyname><forenames>Marcus</forenames></author><author><keyname>Zheng</keyname><forenames>Changxi</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Learning to Place New Objects in a Scene</title><categories>cs.RO</categories><comments>This paper is to be appeared in IJRR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Placing is a necessary skill for a personal robot to have in order to perform
tasks such as arranging objects in a disorganized room. The object placements
should not only be stable but also be in their semantically preferred placing
areas and orientations. This is challenging because an environment can have a
large variety of objects and placing areas that may not have been seen by the
robot before.
  In this paper, we propose a learning approach for placing multiple objects in
different placing areas in a scene. Given point-clouds of the objects and the
scene, we design appropriate features and use a graphical model to encode
various properties, such as the stacking of objects, stability, object-area
relationship and common placing constraints. The inference in our model is an
integer linear program, which we solve efficiently via an LP relaxation. We
extensively evaluate our approach on 98 objects from 16 categories being placed
into 40 areas. Our robotic experiments show a success rate of 98% in placing
known objects and 82% in placing new objects stably. We use our method on our
robots for performing tasks such as loading several dish-racks, a bookshelf and
a fridge with multiple items.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1708</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1708</id><created>2012-02-08</created><updated>2014-04-22</updated><authors><author><keyname>Mitavskiy</keyname><forenames>Boris</forenames></author><author><keyname>He</keyname><forenames>Jun</forenames></author></authors><title>A Polynomial Time Approximation Scheme for a Single Machine Scheduling
  Problem Using a Hybrid Evolutionary Algorithm</title><categories>cs.NE</categories><doi>10.1109/CEC.2012.6256166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays hybrid evolutionary algorithms, i.e, heuristic search algorithms
combining several mutation operators some of which are meant to implement
stochastically a well known technique designed for the specific problem in
question while some others playing the role of random search, have become
rather popular for tackling various NP-hard optimization problems. While
empirical studies demonstrate that hybrid evolutionary algorithms are
frequently successful at finding solutions having fitness sufficiently close to
the optimal, many fewer articles address the computational complexity in a
mathematically rigorous fashion. This paper is devoted to a mathematically
motivated design and analysis of a parameterized family of evolutionary
algorithms which provides a polynomial time approximation scheme for one of the
well-known NP-hard combinatorial optimization problems, namely the &quot;single
machine scheduling problem without precedence constraints&quot;. The authors hope
that the techniques and ideas developed in this article may be applied in many
other situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1709</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1709</id><created>2012-02-08</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>A family of weakly universal cellular automata in the hyperbolic plane
  with two states</title><categories>cs.FL</categories><comments>83 pages, 38 figures, 53 tables. arXiv admin note: text overlap with
  arXiv:0903.2108</comments><msc-class>68R05</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct a family of weakly universal rotation invariant
cellular automaton for all grids $\{p,3\}$ of the hyperbolic plane for $p\geq
13$. The scheme is general for $p\geq 17$ and for $13\leq p&lt;17$, we give such a
cellular automaton for $p=13$, which is enough. Also, an important property of
this family is that the set of cells of the cellular automaton which are
subject to changes is actually a planar set. The problem for $p&lt;13$ for a truly
planar construction is still open. The best result, for $p=7$, is four states
and was obtained by the same author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1712</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1712</id><created>2012-02-08</created><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Sami</keyname><forenames>Rahul</forenames></author></authors><title>Multi-outcome and Multidimensional Market Scoring Rules</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hanson's market scoring rules allow us to design a prediction market that
still gives useful information even if we have an illiquid market with a
limited number of budget-constrained agents. Each agent can &quot;move&quot; the current
price of a market towards their prediction.
  While this movement still occurs in multi-outcome or multidimensional markets
we show that no market-scoring rule, under reasonable conditions, always moves
the price directly towards beliefs of the agents. We present a modified version
of a market scoring rule for budget-limited traders, and show that it does have
the property that, from any starting position, optimal trade by a
budget-limited trader will result in the market being moved towards the
trader's true belief. This mechanism also retains several attractive strategic
properties of the market scoring rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1715</identifier>
 <datestamp>2012-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1715</id><created>2012-02-08</created><updated>2012-12-21</updated><authors><author><keyname>Iyer</keyname><forenames>Ravi S.</forenames></author></authors><title>Improve the Practice of Software Development in India by Having a
  Software Development Career Track in Indian CS &amp; IT Academia</title><categories>cs.CY</categories><comments>21 pages, 0 figures</comments><acm-class>K.3.2; D.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many, but not all, Indian CS &amp; IT academics tend to have a focus on theory
and research. They do not give much importance to the practice of software
development. This paper proposes an additional software development career
track for Indian CS &amp; IT academics different from the existing research
oriented career track. A measure of software contribution record is suggested.
It opines that adoption of such changes to academic regulations will result in
significant improvement of software development skill set in Indian CS &amp; IT
academia which, in turn, will result in better software development skill set
in Indian CS &amp; IT graduates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1717</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1717</id><created>2012-02-08</created><authors><author><keyname>Shaikh</keyname><forenames>Murtaza Hussain</forenames></author></authors><title>Collaboration for enhancing the system development process in open
  source diligence</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to different opponents and commercial giants in software
industries, the open source style software development has enough capacity to
complete successfully the large scale projects. But we have seen many flaws and
loops in collaboration and handling of mega scale projects in open source
environment. Perhaps the collaboration is a key of successful project
development. In this article we have tries to identify different feasible and
reliable solution to a better collaboration ways in the open source system
development. Some of the issues also that are found in the development phase of
the open source have been identified and a proposed solution by explaining
Successful communities such as GNU, the Apache Software Foundation, and Eclipse
Foundation is discusses in this research article. It must be kept in mind that
to improvement the collaboration in open source environment both the
development community and the people should be more creative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1718</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1718</id><created>2012-02-08</created><authors><author><keyname>Harbouche</keyname><forenames>Ahmed</forenames></author><author><keyname>Erradi</keyname><forenames>Mohammed</forenames></author><author><keyname>Mokhtari</keyname><forenames>Aicha</forenames></author></authors><title>A transformation approach for collaboration based requirement models</title><categories>cs.SE</categories><comments>14 pages</comments><acm-class>D.2.1; D.2.2</acm-class><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.3, No.1, January 2012, 47-60</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed software engineering is widely recognized as a complex task.
Among the inherent complexities is the process of obtaining a system design
from its global requirement specification. This paper deals with such
transformation process and suggests an approach to derive the behavior of a
given system components, in the form of distributed Finite State Machines, from
the global system requirements, in the form of an augmented UML Activity
Diagrams notation. The process of the suggested approach is summarized in three
steps: the definition of the appropriate source Meta-Model (requirements
Meta-Model), the definition of the target Design Meta-Model and the definition
of the rules to govern the transformation during the derivation process. The
derivation process transforms the global system requirements described as UML
diagram activities (extended with collaborations) to system roles behaviors
represented as UML finite state machines. The approach is implemented using
Atlas Transformation Language (ATL).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1720</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1720</id><created>2012-02-08</created><authors><author><keyname>Sharma</keyname><forenames>Manish</forenames><affiliation>Department of Physics, Govt. College, Dhaliara, H.P., India</affiliation></author><author><keyname>Singh</keyname><forenames>Gurpadam</forenames><affiliation>Deparment of ECE, B.C.E.T., Gurdaspur, Punjab, India</affiliation></author></authors><title>Performance evaluation aodv, dymo, olsr and zrpad hoc routing protocol
  for ieee 802.11 mac and 802.11 dcf in vanet using qualnet</title><categories>cs.NI</categories><comments>12 Pages. 5 Figures; International Journal on AdHoc Networking
  Systems (IJANS) Vol. 2, No. 1, January 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In VANET high speed is the real characteristics which leads to frequent
breakdown, interference etc. Therefore Performance of adhoc routing protocols
is helpful to improve the Quality of Service (QOS). In this paper we studied
various adhoc routing protocols, Reactive, Proactive &amp; Hybrid, taking in to
consideration parameters like speed, altitude, mobility etc in real VANET
scenario. The AODV and DYMO (Reactive), OLSR (Proactive) and ZRP (hybrid)
protocols are compared for IEEE 802.11(MAC) and IEEE 802.11(DCF) standard using
Qualnet as a Simulation tool. Since IEEE 802.11, covers both physical and data
link layer. Hence performance of the protocols in these layers helps to make a
right selection of Protocol for high speed mobility. Varying parameters of
VANET shows that in the real traffic scenarios proactive protocol performs more
efficiently for IEEE 802.11 (MAC) and IEEE 802.11(DCF).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1733</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1733</id><created>2012-02-08</created><authors><author><keyname>Hassane</keyname><forenames>Abdoul Aziz Issaka</forenames></author><author><keyname>Renfa</keyname><forenames>Li</forenames></author><author><keyname>Fanzi</keyname><forenames>Zeng</forenames></author></authors><title>Handover Necessity Estimation for 4G Heterogeneous Networks</title><categories>cs.NI</categories><journal-ref>International Journal of Information Sciences and Techniques
  (IJIST) Vol.2, No.1, January 2012</journal-ref><doi>10.5121/ijist.2012.2101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most challenges of 4G network is to have a unified network of
heterogeneous wireless networks. To achieve seamless mobility in such a diverse
environment, vertical hand off is still a challenging problem. In many
situations handover failures and unnecessary handoffs are triggered causing
degradation of services, reduction in throughput and increase the blocking
probability and packet loss. In this paper a new vertical handoff decision
algorithm handover necessity estimation (HNE), is proposed to minimize the
number of handover failure and unnecessary handover in heterogeneous wireless
networks. we have proposed a multi criteria vertical handoff decision algorithm
based on two parts: traveling time estimation and time threshold calculation.
Our proposed methods are compared against two other methods: (a) the fixed RSS
threshold based method, in which handovers between the cellular network and the
WLAN are initiated when the RSS from the WLAN reaches a fixed threshold, and
(b) the hysteresis based method, in which a hysteresis is introduced to prevent
the ping-pong effect. Simulation results show that, this method reduced the
number of handover failures and unnecessary handovers up to 80% and 70%,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1734</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1734</id><created>2012-02-08</created><updated>2012-06-20</updated><authors><author><keyname>Knabe</keyname><forenames>Frederic</forenames></author><author><keyname>Mohamed</keyname><forenames>Omar</forenames></author><author><keyname>Huppert</keyname><forenames>Carolin</forenames></author></authors><title>Superiority of TDMA in a Class of Gaussian Multiple-Access Channels with
  a MIMO-AF-Relay</title><categories>cs.IT math.IT</categories><comments>accepted for 9th International Symposium on Wireless Communication
  Systems (ISWCS), Paris, France, August 2012. 5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Gaussian multiple-access channel (MAC) with an
amplify-and-forward (AF) relay, where all nodes except the receiver have
multiple antennas and the direct links between transmitters and receivers are
neglected. Thus, spatial processing can be applied both at the transmitters and
at the relay, which is subject to optimization for increasing the data rates.
In general, this optimization problem is non-convex and hard to solve. While in
prior work on this problem, it is assumed that all transmitters access the
channel jointly, we propose a solution where each transmitter accesses the
channel exclusively, using a time-division multiple-access (TDMA) scheme. It is
shown that this scheme provides higher achievable sum rates, which raises the
question of the need for TDMA to achieve the general capacity region of MACs
with AF relay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1740</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1740</id><created>2012-02-08</created><updated>2012-04-03</updated><authors><author><keyname>Nafea</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Hamza</keyname><forenames>D.</forenames></author><author><keyname>Seddik</keyname><forenames>Karim G.</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>A Diversity-Multiplexing-Delay Tradeoff of ARQ Protocols in The
  Z-interference Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to International Symposium on Information Theory (ISIT)
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we analyze the fundamental performance tradeoff of the
single-antenna Automatic Retransmission reQuest (ARQ) Z-interference channel
(ZIC). Specifically, we characterize the achievable three-dimensional tradeoff
between diversity (reliability), multiplexing (throughput), and delay (maximum
number of retransmissions) of two ARQ protocols: A non-cooperative protocol and
a cooperative one. Considering no cooperation exists, we study the achievable
tradeoff of the fixed-power split Han-Kobayashi (HK) approach. Interestingly,
we demonstrate that if the second user transmits the common part only of its
message in the event of its successful decoding and a decoding failure at the
first user, communication is improved over that achieved by keeping or stopping
the transmission of both the common and private messages. We obtain closed-form
expressions for the achievable tradeoff under the HK splitting. Under
cooperation, two special cases of the HK are considered for static and dynamic
decoders. The difference between the two decoders lies in the ability of the
latter to dynamically choose which HK special-case decoding to apply.
Cooperation is shown to dramatically increase the achievable first user
diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1742</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1742</id><created>2012-02-08</created><authors><author><keyname>Rhif</keyname><forenames>Ahmed</forenames></author></authors><title>Stabilizing sliding mode control design and application for a dc motor:
  Speed control</title><categories>cs.SY</categories><comments>10 pages; 13 figures, international journal</comments><doi>10.5121/ijics.2012.2104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The regulation by sliding mode control (SMC) is recognized for its qualities
of robustness and dynamic response. This article will briefly talk about the
regulation principles by sliding mode as well as the application of this
approach to the adjustment of a speed control DC motor bench using the TY36A/EV
unit. This unit, from Electronica Veneta products, uses a PID controller to
control the speed and position of the DC motor. Our purpose is to improve the
set time answer and the robustness of the system when disturbances take place.
The experimental results show very good performances of the proposed approach
relatively to the PID.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1747</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1747</id><created>2012-02-08</created><updated>2012-02-14</updated><authors><author><keyname>Whitney</keyname><forenames>Daniel E.</forenames></author></authors><title>Growth Patterns of Subway/Metro Systems Tracked by Degree Correlation</title><categories>physics.soc-ph cs.SI</categories><comments>Updated ref [6]. Added equation to Appendix 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urban transportation systems grow over time as city populations grow and move
and their transportation needs evolve. Typical network growth models, such as
preferential attachment, grow the network node by node whereas rail and metro
systems grow by adding entire lines with all their nodes. The objective of this
paper is to see if any canonical regular network forms such as stars or grids
capture the growth patterns of urban metro systems for which we have historical
data in terms of old maps. Data from these maps reveal that the systems'
Pearson degree correlation grows increasingly from initially negative values
toward positive values over time and in some cases becomes decidedly positive.
We have derived closed form expressions for degree correlation and clustering
coefficient for a variety of canonical forms that might be similar to metro
systems. Of all those examined, only a few types patterned after a wide area
network (WAN) with a &quot;core-periphery&quot; structure show similar positive-trending
degree correlation as network size increases. This suggests that large metro
systems either are designed or evolve into the equivalent of message carriers
that seek to balance travel between arbitrary node-destination pairs with
avoidance of congestion in the central regions of the network.
  Keywords: metro, subway, urban transport networks, degree correlation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1761</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1761</id><created>2012-02-08</created><authors><author><keyname>Manna</keyname><forenames>Mehdi Ebady</forenames></author><author><keyname>Amphawan</keyname><forenames>Angela</forenames></author></authors><title>Review of syn-flooding attack detection mechanism</title><categories>cs.CR</categories><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.3, No.1, January 2012, 99-117</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denial of Service (DoS) is a security threat which compromises the
confidentiality of information stored in Local Area Networks (LANs) due to
unauthorized access by spoofed IP addresses. SYN Flooding is a type of DoS
which is harmful to network as the flooding of packets may delay other users
from accessing the server and in severe cases, the server may need to be shut
down, wasting valuable resources, especially in critical real-time services
such as in e-commerce and the medical field. The objective of this paper is to
review the state-of-the art of detection mechanisms for SYN flooding. The
detection schemes for SYN Flooding attacks have been classified broadly into
three categories - detection schemes based on the router data structure,
detection schemes based on statistical analysis of the packet flow and
detection schemes based on artificial intelligence. The advantages and
disadvantages for various detection schemes under each category have been
critically examined. The performance measures of the categories have also been
compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1777</identifier>
 <datestamp>2015-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1777</id><created>2012-02-08</created><updated>2012-05-26</updated><authors><author><keyname>Vasil'ev</keyname><forenames>Oleg O.</forenames></author></authors><title>Counting and computing regions of $D$-decomposition: algebro-geometric
  approach</title><categories>math.OC cs.SC</categories><comments>16 pages, 8 figures</comments><msc-class>93D09, 93B27, 93B25</msc-class><doi>10.1134/S0005117912120041</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  New methods for $D$-decomposition analysis are presented. They are based on
topology of real algebraic varieties and computational real algebraic geometry.
The estimate of number of root invariant regions for polynomial parametric
families of polynomial and matrices is given. For the case of two parametric
family more sharp estimate is proven. Theoretic results are supported by
various numerical simulations that show higher precision of presented methods
with respect to traditional ones. The presented methods are inherently global
and could be applied for studying $D$-decomposition for the space of parameters
as a whole instead of some prescribed regions. For symbolic computations the
Maple v.14 software and its package RegularChains are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1779</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1779</id><created>2012-02-08</created><authors><author><keyname>Netrapalli</keyname><forenames>Praneeth</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Finding the Graph of Epidemic Cascades</title><categories>cs.SI physics.soc-ph stat.ML</categories><comments>To appear in Proc. ACM SIGMETRICS/Performance 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding the graph on which an epidemic cascade
spreads, given only the times when each node gets infected. While this is a
problem of importance in several contexts -- offline and online social
networks, e-commerce, epidemiology, vulnerabilities in infrastructure networks
-- there has been very little work, analytical or empirical, on finding the
graph. Clearly, it is impossible to do so from just one cascade; our interest
is in learning the graph from a small number of cascades.
  For the classic and popular &quot;independent cascade&quot; SIR epidemics, we
analytically establish the number of cascades required by both the global
maximum-likelihood (ML) estimator, and a natural greedy algorithm. Both results
are based on a key observation: the global graph learning problem decouples
into $n$ local problems -- one for each node. For a node of degree $d$, we show
that its neighborhood can be reliably found once it has been infected $O(d^2
\log n)$ times (for ML on general graphs) or $O(d\log n)$ times (for greedy on
trees). We also provide a corresponding information-theoretic lower bound of
$\Omega(d\log n)$; thus our bounds are essentially tight. Furthermore, if we
are given side-information in the form of a super-graph of the actual graph (as
is often the case), then the number of cascade samples required -- in all cases
-- becomes independent of the network size $n$.
  Finally, we show that for a very general SIR epidemic cascade model, the
Markov graph of infection times is obtained via the moralization of the network
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1782</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1782</id><created>2012-02-08</created><authors><author><keyname>Zhao</keyname><forenames>Weisheng</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Sumanta</forenames></author><author><keyname>Accoto</keyname><forenames>Celso</forenames></author><author><keyname>Klein</keyname><forenames>Jacques-Olivier</forenames></author><author><keyname>Chappert</keyname><forenames>Claude</forenames></author><author><keyname>Mazoyer</keyname><forenames>Pascale</forenames></author></authors><title>Cross-point architecture for spin transfer torque magnetic random access
  memory</title><categories>cs.ET cs.AR physics.class-ph</categories><doi>10.1109/TNANO.2012.2206051</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spin transfer torque magnetic random access memory (STT-MRAM) is considered
as one of the most promising candidates to build up a true universal memory
thanks to its fast write/read speed, infinite endurance and non-volatility.
However the conventional access architecture based on 1 transistor + 1 memory
cell limits its storage density as the selection transistor should be large
enough to ensure the write current higher than the critical current for the STT
operation. This paper describes a design of cross-point architecture for
STT-MRAM. The mean area per word corresponds to only two transistors, which are
shared by a number of bits (e.g. 64). This leads to significant improvement of
data density (e.g. 1.75 F2/bit). Special techniques are also presented to
address the sneak currents and low speed issues of conventional cross-point
architecture, which are difficult to surmount and few efficient design
solutions have been reported in the literature. By using a STT-MRAM SPICE model
including precise experimental parameters and STMicroelectronics 65 nm
technology, some chip characteristic results such as cell area, data access
speed and power have been calculated or simulated to demonstrate the expected
performances of this new memory architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1801</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1801</id><created>2012-02-08</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Network Coded Gossip with Correlated Data</title><categories>cs.IT cs.DC cs.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design and analyze gossip algorithms for networks with correlated data. In
these networks, either the data to be distributed, the data already available
at the nodes, or both, are correlated. This model is applicable for a variety
of modern networks, such as sensor, peer-to-peer and content distribution
networks.
  Although coding schemes for correlated data have been studied extensively,
the focus has been on characterizing the rate region in static memory-free
networks. In a gossip-based scheme, however, nodes communicate among each other
by continuously exchanging packets according to some underlying communication
model. The main figure of merit in this setting is the stopping time -- the
time required until nodes can successfully decode. While Gossip schemes are
practical, distributed and scalable, they have only been studied for
uncorrelated data.
  We wish to close this gap by providing techniques to analyze network coded
gossip in (dynamic) networks with correlated data. We give a clean framework
for oblivious network models that applies to a multitude of network and
communication scenarios, specify a general setting for distributed correlated
data, and give tight bounds on the stopping times of network coded protocols in
this wide range of scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1808</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1808</id><created>2012-02-08</created><authors><author><keyname>Zacharia</keyname><forenames>Kurien</forenames></author><author><keyname>Elias</keyname><forenames>Eldo P.</forenames></author><author><keyname>Varghese</keyname><forenames>Surekha Mariam</forenames></author></authors><title>Personalised product design using virtual interactive techniques</title><categories>cs.MM cs.CV cs.GR</categories><comments>10 pages; International Journal of Computer Graphics &amp; Animation
  (IJCGA) Vol.2, No.1, January 2012</comments><msc-class>68u05, 68u20</msc-class><acm-class>H.5.2; I.3.7</acm-class><doi>10.5121/ijcga.2012.2101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of Virtual Interactive Techniques for personalized product design is
described in this paper. Usually products are designed and built by considering
general usage patterns and Prototyping is used to mimic the static or working
behaviour of an actual product before manufacturing the product. The user does
not have any control on the design of the product. Personalized design
postpones design to a later stage. It allows for personalized selection of
individual components by the user. This is implemented by displaying the
individual components over a physical model constructed using Cardboard or
Thermocol in the actual size and shape of the original product. The components
of the equipment or product such as screen, buttons etc. are then projected
using a projector connected to the computer into the physical model. Users can
interact with the prototype like the original working equipment and they can
select, shape, position the individual components displayed on the interaction
panel using simple hand gestures. Computer Vision techniques as well as sound
processing techniques are used to detect and recognize the user gestures
captured using a web camera and microphone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1820</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1820</id><created>2012-02-08</created><updated>2012-02-14</updated><authors><author><keyname>Murri</keyname><forenames>Riccardo</forenames></author></authors><title>Fatgraph Algorithms and the Homology of the Kontsevich Complex</title><categories>math.AG cs.CG cs.MS math.GT</categories><comments>61 pages, 12 figures. Corrected attributions, claims, and
  bibliography</comments><msc-class>32G15, 05C30, 05C85</msc-class><acm-class>F.2.2; I.3.5</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Fatgraphs are multigraphs enriched with a cyclic order of the edges incident
to a vertex. This paper presents algorithms to: (1) generate the set of all
fatgraphs having a given genus and number of boundary cycles; (2) compute
automorphisms of any given fatgraph; (3) compute the homology of the fatgraph
complex. The algorithms are suitable for effective computer implementation.
  In particular, this allows us to compute the rational homology of the moduli
space of Riemann surfaces with marked points. We thus compute the Betti numbers
of $M_{g,n}$ with $(2g + n) \leq 6$, corroborating known results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1837</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1837</id><created>2012-02-08</created><authors><author><keyname>Naghavi</keyname><forenames>Mehdi</forenames></author><author><keyname>Sharifi</keyname><forenames>Mohsen</forenames></author></authors><title>A Proposed Architecture for Continuous Web Monitoring Through Online
  Crawling of Blogs</title><categories>cs.IR cs.SI</categories><comments>10 pages, 2 figures</comments><journal-ref>International Journal of UbiComp (IJU), Vol.3, No.1, January 2012</journal-ref><doi>10.5121/iju.2012.3102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Getting informed of what is registered in the Web space on time, can greatly
help the psychologists, marketers and political analysts to familiarize,
analyse, make decision and act correctly based on the society`s different
needs. The great volume of information in the Web space hinders us to
continuously online investigate the whole space of the Web. Focusing on the
considered blogs limits our working domain and makes the online crawling in the
Web space possible. In this article, an architecture is offered which
continuously online crawls the related blogs, using focused crawler, and
investigates and analyses the obtained data. The online fetching is done based
on the latest announcements of the ping server machines. A weighted graph is
formed based on targeting the important key phrases, so that a focused crawler
can do the fetching of the complete texts of the related Web pages, based on
the weighted graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1841</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1841</id><created>2012-02-08</created><authors><author><keyname>Kboubi</keyname><forenames>F&#xe9;rihane</forenames></author><author><keyname>Chaibi</keyname><forenames>Anja Habacha</forenames></author><author><keyname>BenAhmed</keyname><forenames>Mohamed</forenames></author></authors><title>Semantic Visualization and Navigation in Textual Corpus</title><categories>cs.IR cs.DL cs.GR cs.SI</categories><comments>11 pages, 6 figures</comments><journal-ref>International Journal of Information Sciences and Techniques
  (IJIST) Vol.2, No.1, January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives a survey of related work on the information visualization
domain and study the real integration of the cartography paradigms in actual
information search systems. Based on this study, we propose a semantic
visualization and navigation approach which offer to users three search modes:
precise search, connotative search and thematic search. The objective is to
propose to the users of an information search system, new interaction paradigms
which support the semantic aspect of the considered information space and guide
users in their searches by assisting them to locate their interest center and
to improve serendipity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1842</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1842</id><created>2012-02-08</created><updated>2012-02-16</updated><authors><author><keyname>Ruan</keyname><forenames>Ning</forenames></author><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Wang</keyname><forenames>Guan</forenames></author><author><keyname>Huang</keyname><forenames>Kun</forenames></author></authors><title>Network Backbone Discovery Using Edge Clustering</title><categories>cs.SI cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we investigate the problem of network backbone discovery. In
complex systems, a &quot;backbone&quot; takes a central role in carrying out the system
functionality and carries the bulk of system traffic. It also both simplifies
and highlight underlying networking structure. Here, we propose an integrated
graph theoretical and information theoretical network backbone model. We
develop an efficient mining algorithm based on Kullback-Leibler divergence
optimization procedure and maximal weight connected subgraph discovery
procedure. A detailed experimental evaluation demonstrates both the
effectiveness and efficiency of our approach. The case studies in the real
world domain further illustrates the usefulness of the discovered network
backbones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1865</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1865</id><created>2012-02-08</created><authors><author><keyname>Odagiri</keyname><forenames>Kazuya</forenames></author><author><keyname>Shimizu</keyname><forenames>Shogo</forenames></author><author><keyname>Ishii</keyname><forenames>Naohiro</forenames></author><author><keyname>Takizawa</keyname><forenames>Makoto</forenames></author></authors><title>Principle of Virtual Use Method in Common Gateway Interface Program on
  the DACS Scheme</title><categories>cs.NI</categories><comments>15 pages</comments><journal-ref>International Journal of Computer Networks &amp; Communications,
  Vol.4, No.1, pp.147-161, January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the world of the Internet, Web Servers such as Apache and Internet
Information Server (IIS) were developed to exchange information among client
computers having different Operation System. They have only the function of
displaying static information such as HTML files and image files into the Web
Browser. However, when the information is updated, the administrator updates it
by manual operation. In some cases, because it is necessary to update several
places about the same information, the work load becomes high than it is assume
and update error and update omission may occur. These problems were solved by
use of a Common Gateway Interface (CGI) program such as a bulletin board system
and a Blog system. However, these programs opened to Internet have often no
user authentication mechanism and no access control mechanism. That is, they
have the problem that user can access it freely only by getting the URL and
inputting it to a Web Browser. Therefore, in this paper, we show a method to
add the user authentication and access control mechanism for them. It is called
virtual use method of CGI and is realized in the case of introducing the
Destination Addressing Control System (DACS) Scheme, which is a kind of Policy
Based Network Management Scheme (PBNM). As the result, this kind of the CGI
program can be used in the organization with the above two functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1877</identifier>
 <datestamp>2012-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1877</id><created>2012-02-08</created><updated>2012-03-20</updated><authors><author><keyname>Aziz</keyname><forenames>Md. Tariq</forenames><affiliation>Blekinge Institute of Technology, Karlskrona, Sweden</affiliation></author><author><keyname>Islam</keyname><forenames>Mohammad Saiful</forenames><affiliation>Blekinge Institute of Technology, Karlskrona, Sweden</affiliation></author><author><keyname>khan</keyname><forenames>Md. Nazmul Islam</forenames><affiliation>Presidency University, Dhaka, Bangladesh</affiliation></author><author><keyname>Popescu</keyname><forenames>Adrian</forenames><affiliation>Blekinge Institute of Technology, Karlskrona, Sweden</affiliation></author></authors><title>Effect of Packet Delay Variation on Video-Voice over DiffServ-MPLS in
  IPv4-IPv6 Networks</title><categories>cs.NI cs.PF</categories><comments>21 Pages, 8 Figures; January 2012, Volume 3, Number 1 (IJDPS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last years, we have witnessed a rapid deployment of real-time
applications on the Internet as well as many research works about Quality of
Service (QoS), in particular IPv4 (Internet Protocol version 4). The inevitable
exhaustion of the remaining IPv4 address pool has become progressively evident.
As the evolution of Internet Protocol (IP) continues, the deployment of IPv6
QoS is underway. Today, there is limited experience in the deployment of QoS
for IPv6 traffic in MPLS backbone networks in conjunction with DiffServ
(Differentiated Services) support. DiffServ itself does not have the ability to
control the traffic which has been taken for end-to-end path while a number of
links of the path are congested. In contrast, MPLS Traffic Engineering (TE) is
accomplished to control the traffic and can set up end-to-end routing path
before data has been forwarded. From the evolution of IPv4 QoS solutions, we
know that the integration of DiffServ and MPLS TE satisfies the guaranteed QoS
requirement for real-time applications. This paper presents a QoS performance
study of real-time applications such as voice and video conferencing in terms
of Packet Delay Variation (PDV) over DiffServ with or without MPLS TE in
IPv4/IPv6 networks using Optimized Network Engineering Tool (OPNET). We also
study the interaction of Expedited Forwarding (EF), Assured Forwarding (AF)
traffic aggregation, link congestion, as well as the effect of performance
metric such as PDV. The effectiveness of DiffServ and MPLS TE integration in
IPv4/IPv6 network is illustrated and analyzed. This paper shows that IPv6
experiences more PDV than their IPv4 counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1881</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1881</id><created>2012-02-08</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>A personalized web page content filtering model based on segmentation</title><categories>cs.IR</categories><comments>11 Pages, 6 Figures</comments><msc-class>68P20 Information storage and retrieval</msc-class><journal-ref>International Journal of Information Sciences and Techniques
  (IJIST) Vol.2, No.1, January 2012</journal-ref><doi>10.5121/ijist.2012.2104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the view of massive content explosion in World Wide Web through diverse
sources, it has become mandatory to have content filtering tools. The filtering
of contents of the web pages holds greater significance in cases of access by
minor-age people. The traditional web page blocking systems goes by the Boolean
methodology of either displaying the full page or blocking it completely. With
the increased dynamism in the web pages, it has become a common phenomenon that
different portions of the web page holds different types of content at
different time instances. This paper proposes a model to block the contents at
a fine-grained level i.e. instead of completely blocking the page it would be
efficient to block only those segments which holds the contents to be blocked.
The advantages of this method over the traditional methods are fine-graining
level of blocking and automatic identification of portions of the page to be
blocked. The experiments conducted on the proposed model indicate 88% of
accuracy in filtering out the segments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1882</identifier>
 <datestamp>2013-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1882</id><created>2012-02-08</created><updated>2012-11-19</updated><authors><author><keyname>Pritchard</keyname><forenames>Geoffrey</forenames></author><author><keyname>Reyhani</keyname><forenames>Reyhaneh</forenames></author><author><keyname>Wilson</keyname><forenames>Mark C.</forenames></author></authors><title>Power measures derived from the sequential query process</title><categories>math.CO cs.GT</categories><comments>13 pages, to appear in Mathematical Social Sciences</comments><msc-class>91B12</msc-class><journal-ref>Mathematical Social Sciences 65, 174-180, 2013</journal-ref><doi>10.1016/j.mathsocsci.2012.11.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a basic sequential model for the discovery of winning coalitions in
a simple game, well known from its use in defining the Shapley-Shubik power
index. We derive in a uniform way a family of measures of collective and
individual power in simple games, and show that, as for the Shapley-Shubik
index, they extend naturally to measures for TU-games. In particular, the
individual measures include all weighted semivalues.
  We single out the simplest measure in our family for more investigation, as
it is new to the literature as far as we know. Although it is very different
from the Shapley value, it is closely related in several ways, and is the
natural analogue of the Shapley value under a nonstandard, but natural,
definition of simple game. We illustrate this new measure by calculating its
values on some standard examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1886</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1886</id><created>2012-02-08</created><authors><author><keyname>Ugtakhbayar</keyname><forenames>N.</forenames></author><author><keyname>Battulga</keyname><forenames>D.</forenames></author><author><keyname>Sodbileg</keyname><forenames>Sh.</forenames></author></authors><title>Classification of artificial intelligence ids for smurf attack</title><categories>cs.AI</categories><comments>6 pages, 5 figures, 1 table</comments><journal-ref>IJAIA (2012);</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many methods have been developed to secure the network infrastructure and
communication over the Internet. Intrusion detection is a relatively new
addition to such techniques. Intrusion detection systems (IDS) are used to find
out if someone has intrusion into or is trying to get it the network. One big
problem is amount of Intrusion which is increasing day by day. We need to know
about network attack information using IDS, then analysing the effect. Due to
the nature of IDSs which are solely signature based, every new intrusion cannot
be detected; so it is important to introduce artificial intelligence (AI)
methods / techniques in IDS. Introduction of AI necessitates the importance of
normalization in intrusions. This work is focused on classification of AI based
IDS techniques which will help better design intrusion detection systems in the
future. We have also proposed a support vector machine for IDS to detect Smurf
attack with much reliable accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1888</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1888</id><created>2012-02-09</created><updated>2012-06-19</updated><authors><author><keyname>Yuan</keyname><forenames>Fang</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author></authors><title>Equivalence of SLNR Precoder and RZF Precoder in Downlink MU-MIMO
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The signal-to-leakage-and-noise ratio (SLNR) precoder is widely used for
MU-MIMO systems in many works, and observed with improved performance from
zeroforcing (ZF) precoder. Our work proofs SLNR precoder is completely
equivalent to conventional regulated ZF (RZF) precoder, which has significant
gain over ZF precoder at low SNRs. Therefore, with our conclusion, the existing
performance analysis about RZF precoder can be readily applicable to SLNR
precoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1891</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1891</id><created>2012-02-09</created><authors><author><keyname>Sin</keyname><forenames>Ei Shwe</forenames></author><author><keyname>Kham</keyname><forenames>Nang Saing Moon</forenames></author></authors><title>Hyper heuristic based on great deluge and its variants for exam
  timetabling problem</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Today, University Timetabling problems are occurred annually and they are
often hard and time consuming to solve. This paper describes Hyper Heuristics
(HH) method based on Great Deluge (GD) and its variants for solving large,
highly constrained timetabling problems from different domains. Generally, in
hyper heuristic framework, there are two main stages: heuristic selection and
move acceptance. This paper emphasizes on the latter stage to develop Hyper
Heuristic (HH) framework. The main contribution of this paper is that Great
Deluge (GD) and its variants: Flex Deluge(FD), Non-linear(NLGD), Extended Great
Deluge(EGD) are used as move acceptance method in HH by combining Reinforcement
learning (RL).These HH methods are tested on exam benchmark timetabling problem
and best results and comparison analysis are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1892</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1892</id><created>2012-02-09</created><authors><author><keyname>R</keyname><forenames>Rathna.</forenames></author><author><keyname>A</keyname><forenames>Sivasubramanian.</forenames></author></authors><title>Improving energy efficiency in wireless sensor networks through
  scheduling and routing</title><categories>cs.NI</categories><comments>7 Pages, 2 Figures and 1 Table</comments><journal-ref>International Journal Of Advanced Smart Sensor Network Systems (
  IJASSN ), Vol 2, No.1, January 2012</journal-ref><doi>10.5121/ijassn.2012.2103</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper is about the wireless sensor network in environmental monitoring
applications. A Wireless Sensor Network consists of many sensor nodes and a
base station. The number and type of sensor nodes and the design protocols for
any wireless sensor network is application specific. The sensor data in this
application may be light intensity, temperature, pressure, humidity and their
variations .Clustering and routing are the two areas which are given more
attention in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1895</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1895</id><created>2012-02-09</created><authors><author><keyname>Kumar</keyname><forenames>D. Sravana</forenames></author><author><keyname>Suneetha</keyname><forenames>CH.</forenames></author><author><keyname>Chandrasekhar</keyname><forenames>A.</forenames></author></authors><title>Encryption of Data using Elliptic Curve over Finite fields</title><categories>cs.CR</categories><journal-ref>International Journal of Distributed and Parallel Sysstems(IJDPS)
  Vol.3 No.1 January 2012</journal-ref><doi>10.5121/ijdps.2012.3125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptography is the study of techniques for ensuring the secrecy and
authentication of the information. Public-key encryption schemes are secure
only if the authenticity of the public-key is assured. Elliptic curve
arithmetic can be used to develop a variety of elliptic curve cryptography
(ECC) schemes including key exchange, encryption and digital signature. The
principal attraction of elliptic curve cryptography compared to RSA is that it
offers equal security for a smaller key-size, thereby reducing the processing
overhead. In the present paper we propose a new encryption algorithm using some
Elliptic Curve over finite fields
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1896</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1896</id><created>2012-02-09</created><updated>2012-03-17</updated><authors><author><keyname>Kloks</keyname><forenames>Ton</forenames></author><author><keyname>Poon</keyname><forenames>Sheung-Hung</forenames></author><author><keyname>Wang</keyname><forenames>Yue-Li</forenames></author></authors><title>The black-and-white coloring problem on circle graphs</title><categories>cs.DM</categories><comments>This paper has been withdrawn by the author due to a critical mistake
  in the circle graph algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G and integers b and w. The black-and-white coloring problem
asks if there exist disjoint sets of vertices B and W with |B|=b and |W|=w such
that no two vertices x in B and y in W are adjacent. In this paper we show that
the problem is polynomial when restricted to permutation graphs and, more
generally, to circle graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1898</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1898</id><created>2012-02-09</created><authors><author><keyname>Kumar</keyname><forenames>D. Sravana</forenames></author><author><keyname>Suneetha</keyname><forenames>CH.</forenames></author><author><keyname>Chandrasekhar</keyname><forenames>A.</forenames></author></authors><title>A Block Cipher using Rotation and Logical XOR Operations</title><categories>cs.CR</categories><journal-ref>International Journal of Computer Science Issues, Vol.8, Issue.6,
  No.1, November 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptography is the study of methods of sending messages in disguised form so
that only the intended recipients can remove the disguise and read the
messages. Information security has become a very critical aspect of modern
communication systems. With the global acceptance of the Internet as a medium
of communication, virtually every computer in the world is connected to every
other. It has created a new risk for the users of the computers with a constant
threat of being hacked and being victims of data theft. In this connection data
encryption has become an essential part of secure communication of the
messages. In the present paper we propose a new method of encryption of data in
blocks using the operations Rotation and Logical XOR
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1909</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1909</id><created>2012-02-09</created><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Yang</keyname><forenames>Sheng</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author><author><keyname>Yi</keyname><forenames>Xinping</forenames></author></authors><title>On the Degrees of Freedom of time correlated MISO broadcast channel with
  delayed CSIT</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure, submitted to ISIT 2012, extended version with
  detailed proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the time correlated MISO broadcast channel where the transmitter
has partial knowledge on the current channel state, in addition to delayed
channel state information (CSI). Rather than exploiting only the current CSI,
as the zero-forcing precoding, or only the delayed CSI, as the Maddah-Ali-Tse
(MAT) scheme, we propose a seamless strategy that takes advantage of both. The
achievable degrees of freedom of the proposed scheme is characterized in terms
of the quality of the current channel knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1914</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1914</id><created>2012-02-09</created><updated>2012-05-18</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Carley</keyname><forenames>Stephen</forenames></author><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author></authors><title>Global Maps of Science based on the new Web-of-Science Categories</title><categories>cs.DL cs.SI</categories><comments>Scientometrics, in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In August 2011, Thomson Reuters launched version 5 of the Science and Social
Science Citation Index in the Web of Science (WoS). Among other things, the 222
ISI Subject Categories (SCs) for these two databases in version 4 of WoS were
renamed and extended to 225 WoS Categories (WCs). A new set of 151 Subject
Categories (SCs) was added, but at a higher level of aggregation. Since we
previously used the ISI SCs as the baseline for a global map in Pajek (Rafols
et al., 2010) and brought this facility online (at
http://www.leydesdorff.net/overlaytoolkit), we recalibrated this map for the
new WC categories using the Journal Citation Reports 2010. In the new
installation, the base maps can also be made using VOSviewer (Van Eck &amp;
Waltman, 2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1918</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1918</id><created>2012-02-09</created><authors><author><keyname>Alam</keyname><forenames>Md. Golam Rabiul</forenames></author><author><keyname>Biswas</keyname><forenames>Chayan</forenames></author><author><keyname>Nower</keyname><forenames>Naushin</forenames></author><author><keyname>Khan</keyname><forenames>Mohammed Shafiul Alam</forenames></author></authors><title>A Reliable Semi-Distributed Load Balancing Architecture of Heterogeneous
  Wireless Networks</title><categories>cs.NI</categories><comments>Page 15 No of figure: 8</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.4, No.1, January 2012</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Now a day's Heterogeneous wireless network is a promising field of research
interest. Various challenges exist in this hybrid combination like load
balancing, resource management and so on. In this paper we introduce a reliable
load balancing architecture for heterogeneous wireless communications to ensure
certain level of quality of service. To conquer the problem of centralized and
distributed design, a semi distributed load balancing architecture for multiple
access networks is introduced. In this grid based design multiple Load and
Mobile Agent Management Units is incorporated. To prove the compactness of the
design, integrated reliability, signalling overhead and total processing time
is calculated. And finally simulation result shows that overall system
performance is improved by enhancing reliability, reducing signalling overhead
and processing time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1925</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1925</id><created>2012-02-09</created><authors><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>F&#xfc;gger</keyname><forenames>Matthias</forenames></author><author><keyname>Lenzen</keyname><forenames>Christoph</forenames></author><author><keyname>Posch</keyname><forenames>Markus</forenames></author><author><keyname>Schmid</keyname><forenames>Ulrich</forenames></author><author><keyname>Steininger</keyname><forenames>Andreas</forenames></author></authors><title>FATAL+: A Self-Stabilizing Byzantine Fault-tolerant Clocking Scheme for
  SoCs</title><categories>cs.DC cs.AR</categories><comments>arXiv admin note: significant text overlap with arXiv:1105.4780</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present concept and implementation of a self-stabilizing Byzantine
fault-tolerant distributed clock generation scheme for multi-synchronous GALS
architectures in critical applications. It combines a variant of a recently
introduced self-stabilizing algorithm for generating low-frequency,
low-accuracy synchronized pulses with a simple non-stabilizing high-frequency,
high-accuracy clock synchronization algorithm. We provide thorough correctness
proofs and a performance analysis, which use methods from fault-tolerant
distributed computing research but also addresses hardware-related issues like
metastability. The algorithm, which consists of several concurrent
communicating asynchronous state machines, has been implemented in VHDL using
Petrify in conjunction with some extensions, and synthetisized for an Altera
Cyclone FPGA. An experimental validation of this prototype has been carried out
to confirm the skew and clock frequency bounds predicted by the theoretical
analysis, as well as the very short stabilization times (required for
recovering after excessively many transient failures) achievable in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1928</identifier>
 <datestamp>2013-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1928</id><created>2012-02-09</created><updated>2013-04-13</updated><authors><author><keyname>Sullivan</keyname><forenames>T. J.</forenames></author><author><keyname>McKerns</keyname><forenames>M.</forenames></author><author><keyname>Meyer</keyname><forenames>D.</forenames></author><author><keyname>Theil</keyname><forenames>F.</forenames></author><author><keyname>Owhadi</keyname><forenames>H.</forenames></author><author><keyname>Ortiz</keyname><forenames>M.</forenames></author></authors><title>Optimal uncertainty quantification for legacy data observations of
  Lipschitz functions</title><categories>math.PR cs.NA math.ST stat.CO stat.TH</categories><comments>38 pages</comments><msc-class>60E15, 62G99, 65C50, 90C26</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of providing optimal uncertainty quantification (UQ)
--- and hence rigorous certification --- for partially-observed functions. We
present a UQ framework within which the observations may be small or large in
number, and need not carry information about the probability distribution of
the system in operation. The UQ objectives are posed as optimization problems,
the solutions of which are optimal bounds on the quantities of interest; we
consider two typical settings, namely parameter sensitivities (McDiarmid
diameters) and output deviation (or failure) probabilities. The solutions of
these optimization problems depend non-trivially (even non-monotonically and
discontinuously) upon the specified legacy data. Furthermore, the extreme
values are often determined by only a few members of the data set; in our
principal physically-motivated example, the bounds are determined by just 2 out
of 32 data points, and the remainder carry no information and could be
neglected without changing the final answer. We propose an analogue of the
simplex algorithm from linear programming that uses these observations to offer
efficient and rigorous UQ for high-dimensional systems with high-cardinality
legacy data. These findings suggest natural methods for selecting optimal
(maximally informative) next experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1936</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1936</id><created>2012-02-09</created><updated>2012-06-29</updated><authors><author><keyname>Bl&#xe4;ser</keyname><forenames>Markus</forenames></author><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author></authors><title>Smoothed Complexity Theory</title><categories>cs.CC</categories><comments>to be presented at MFCS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smoothed analysis is a new way of analyzing algorithms introduced by Spielman
and Teng (J. ACM, 2004). Classical methods like worst-case or average-case
analysis have accompanying complexity classes, like P and AvgP, respectively.
While worst-case or average-case analysis give us a means to talk about the
running time of a particular algorithm, complexity classes allows us to talk
about the inherent difficulty of problems.
  Smoothed analysis is a hybrid of worst-case and average-case analysis and
compensates some of their drawbacks. Despite its success for the analysis of
single algorithms and problems, there is no embedding of smoothed analysis into
computational complexity theory, which is necessary to classify problems
according to their intrinsic difficulty.
  We propose a framework for smoothed complexity theory, define the relevant
classes, and prove some first hardness results (of bounded halting and tiling)
and tractability results (binary optimization problems, graph coloring,
satisfiability). Furthermore, we discuss extensions and shortcomings of our
model and relate it to semi-random models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1941</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1941</id><created>2012-02-09</created><authors><author><keyname>Sharma</keyname><forenames>A. K.</forenames></author><author><keyname>Mishra</keyname><forenames>Atul</forenames></author><author><keyname>Singh</keyname><forenames>Vijay</forenames></author></authors><title>An Intelligent Mobile-Agent Based Scalable Network Management
  Architecture for Large-Scale Enterprise System</title><categories>cs.NI cs.DC cs.MA</categories><comments>16 pages, 10 figures, published in IJCNC</comments><journal-ref>International Journal of Computer Networks and Communications
  (IJCNC), January 2012, Volume 4, Number 1, ISSN [online : 0974-9322]</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several Mobile Agent based distributed network management models have been
proposed in recent times to address the scalability and flexibility problems of
centralized (SNMP or CMIP management models) models. Though the use of Mobile
Agents to distribute and delegate management tasks comes handy in dealing with
the previously stated issues, many of the agent-based management frameworks
like initial flat bed models and static mid-level managers employing mobile
agents models cannot efficiently meet the demands of current networks which are
growing in size and complexity. Moreover, varied technologies, such as SONET,
ATM, Ethernet, DWDM etc., present at different layers of the Access, Metro and
Core (long haul) sections of the network, have contributed to the complexity in
terms of their own framing and protocol structures. Thus, controlling and
managing the traffic in these networks is a challenging task. This paper
presents an intelligent scalable hierarchical agent based model for the
management of large-scale complex networks to address aforesaid issues. The
cost estimation, carried out with a view to compute the overall management cost
in terms of management data overhead, is being presented. The results obtained
thereafter establish the usefulness of the presented architecture as compare to
centralized and flat bed agent based models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1943</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1943</id><created>2012-02-09</created><authors><author><keyname>Jayawardena</keyname><forenames>Srimal</forenames></author><author><keyname>Yang</keyname><forenames>Di</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>3D Model Assisted Image Segmentation</title><categories>cs.CV</categories><comments>18 LaTeX pages, 11 figures, 1 algorithm, 1 table</comments><journal-ref>Proc. 13th International Conf. on Digital Image Computing:
  Techniques and Applications (DICTA 2011) pages 51-58</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of segmenting a given image into coherent regions is important in
Computer Vision and many industrial applications require segmenting a known
object into its components. Examples include identifying individual parts of a
component for process control work in a manufacturing plant and identifying
parts of a car from a photo for automatic damage detection. Unfortunately most
of an object's parts of interest in such applications share the same pixel
characteristics, having similar colour and texture. This makes segmenting the
object into its components a non-trivial task for conventional image
segmentation algorithms. In this paper, we propose a &quot;Model Assisted
Segmentation&quot; method to tackle this problem. A 3D model of the object is
registered over the given image by optimising a novel gradient based loss
function. This registration obtains the full 3D pose from an image of the
object. The image can have an arbitrary view of the object and is not limited
to a particular set of views. The segmentation is subsequently performed using
a level-set based method, using the projected contours of the registered 3D
model as initialisation curves. The method is fully automatic and requires no
user interaction. Also, the system does not require any prior training. We
present our results on photographs of a real car.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1945</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1945</id><created>2012-02-09</created><authors><author><keyname>Jayabrabu</keyname><forenames>R.</forenames></author><author><keyname>Saravanan</keyname><forenames>V.</forenames></author><author><keyname>Vivekanandan</keyname><forenames>K.</forenames></author></authors><title>A framework: Cluster detection and multidimensional visualization of
  automated data mining using intelligent agents</title><categories>cs.AI</categories><comments>15 pages</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol.3, No.1, January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data Mining techniques plays a vital role like extraction of required
knowledge, finding unsuspected information to make strategic decision in a
novel way which in term understandable by domain experts. A generalized frame
work is proposed by considering non - domain experts during mining process for
better understanding, making better decision and better finding new patters in
case of selecting suitable data mining techniques based on the user profile by
means of intelligent agents. KEYWORDS: Data Mining Techniques, Intelligent
Agents, User Profile, Multidimensional Visualization, Knowledge Discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1953</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1953</id><created>2012-02-09</created><authors><author><keyname>Shaikh</keyname><forenames>Murtaza Hussain</forenames></author></authors><title>Arduino Tool: For Interactive Artwork Installations</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of the digital media and computational tools has widened the
doors for creativity. The cutting edge in the digital arts and role of new
technologies can be explored for the possible creativity. This gives an
opportunity to involve arts with technologies to make creative works. The
interactive artworks are often installed in the places where multiple people
can interact with the installation, which allows the art to achieve its purpose
by allowing the people to observe and involve with the installation. The level
of engagement of the audience depends on the various factors such as aesthetic
satisfaction, how the audience constructs meaning, pleasure and enjoyment. The
method to evaluate these experiences is challenging as it depends on
integration between the artificial life and real life by means of human
computer interaction. This research investigates &quot;How Adriano fits for creative
and interactive artwork installations?&quot; using an artwork installation in the
campus of NTNU (Norwegian University of Science &amp; Technology). The main focus
of this investigation has been to get an overview on the intersection between
information technology and Arts. This gives an opportunity to understand
various attributes like creativity, cooperation and openness of processes
influencing the creative Artworks. The artwork is combination of Adriano and
other auxiliary components such as sensors, LED's and speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1971</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1971</id><created>2012-02-09</created><authors><author><keyname>Jannati</keyname><forenames>Hoda</forenames></author><author><keyname>Falahati</keyname><forenames>Abolfazl</forenames></author></authors><title>Cryptanalysis and enhancement of two low cost rfid authentication
  protocols</title><categories>cs.CR</categories><comments>9 pages, 5 figures</comments><journal-ref>International Journal of UbiComp (IJU), vol. 3, no.1, pp. 1-9,
  January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Widespread attention is recently paid upon RFID system structure considering
its ease of deployment over an extensive range of applications. Due to its
several advantages, many technical articles are published to improve its
capabilities over specific system implementations. Recently, a lightweight
anti-de-synchronization RFID authentication protocol and a lightweight binding
proof protocol to guard patient safety are proposed. This contribution provides
enough evidence to prove the first introduced protocol vulnerability to
de-synchronization attack. It also provides the other protocol's suffering from
de-synchronization attack as well as tracking the movements of the tags. This
paper also addresses appropriate solutions to fix the security flaws concerning
the two described protocols for secure RFID applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1980</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1980</id><created>2012-02-09</created><authors><author><keyname>Kartzow</keyname><forenames>Alexander</forenames></author></authors><title>First-Order Logic on Higher-Order Nested Pushdown Trees</title><categories>cs.LO cs.FL math.LO</categories><comments>41 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new hierarchy of higher-order nested pushdown trees
generalising Alur et al.'s concept of nested pushdown trees. Nested pushdown
trees are useful representations of control flows in the verification of
programs with recursive calls of first-order functions. Higher-order nested
pushdown trees are expansions of unfoldings of graphs generated by higher-order
pushdown systems. Moreover, the class of nested pushdown trees of level n is
uniformly first-order interpretable in the class of collapsible pushdown graphs
of level n+1. The relationship between the class of higher-order pushdown
graphs and the class of collapsible higher-order pushdown graphs is not very
well understood. We hope that the further study of the nested pushdown tree
hierarchy leads to a better understanding of these two hierarchies. In this
paper, we are concerned with the first-order model checking problem on
higher-order nested pushdown trees. We show that the first-order model checking
on the first two levels of this hierarchy is decidable. Moreover, we obtain an
2-EXPSPACE algorithm for the class of nested pushdown trees of level 1. The
proof technique involves a pseudo-local analysis of strategies in the
Ehrenfeucht-Fraisse games on two identical copies of a nested pushdown tree.
Ordinary locality arguments in the spirit of Gaifman's lemma do not apply here
because nested pushdown trees tend to have small diameters. We introduce the
notion of relevant ancestors which provide a sufficient description of the FO_k
-type of each element in a higher-order nested pushdown tree. The local
analysis of these ancestors allows us to prove the existence of restricted
winning strategies in the Ehrenfeucht-Fraisse game. These strategies are then
used to create a first-order model checking algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1983</identifier>
 <datestamp>2015-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1983</id><created>2012-02-09</created><updated>2015-02-24</updated><authors><author><keyname>Barenboim</keyname><forenames>Leonid</forenames></author><author><keyname>Elkin</keyname><forenames>Michael</forenames></author><author><keyname>Pettie</keyname><forenames>Seth</forenames></author><author><keyname>Schneider</keyname><forenames>Johannes</forenames></author></authors><title>The Locality of Distributed Symmetry Breaking</title><categories>cs.DC</categories><comments>In submission to J. ACM</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry breaking problems are among the most well studied in the field of
distributed computing and yet the most fundamental questions about their
complexity remain open. In this paper we work in the LOCAL model (where the
input graph and underlying distributed network are identical) and study the
randomized complexity of four fundamental symmetry breaking problems on graphs:
computing MISs (maximal independent sets), maximal matchings, vertex colorings,
and ruling sets. A small sample of our results includes
  - An MIS algorithm running in $O(\log^2\Delta + 2^{O(\sqrt{\log\log n})})$
time, where $\Delta$ is the maximum degree. This is the first MIS algorithm to
improve on the 1986 algorithms of Luby and Alon, Babai, and Itai, when $\log n
\ll \Delta \ll 2^{\sqrt{\log n}}$, and comes close to the $\Omega(\log \Delta)$
lower bound of Kuhn, Moscibroda, and Wattenhofer.
  - A maximal matching algorithm running in $O(\log\Delta + \log^4\log n)$
time. This is the first significant improvement to the 1986 algorithm of
Israeli and Itai. Moreover, its dependence on $\Delta$ is provably optimal.
  - A method for reducing symmetry breaking problems in low
arboricity/degeneracy graphs to low degree graphs. (Roughly speaking, the
arboricity or degeneracy of a graph bounds the density of any subgraph.)
Corollaries of this reduction include an $O(\sqrt{\log n})$-time maximal
matching algorithm for graphs with arboricity up to $2^{\sqrt{\log n}}$ and an
$O(\log^{2/3} n)$-time MIS algorithm for graphs with arboricity up to $2^{(\log
n)^{1/3}}$.
  Each of our algorithms is based on a simple, but powerful technique for
reducing a randomized symmetry breaking task to a corresponding deterministic
one on a poly$(\log n)$-size graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1990</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1990</id><created>2012-02-09</created><authors><author><keyname>Kumar</keyname><forenames>Upendra</forenames></author><author><keyname>Lahiri</keyname><forenames>Tapobrata</forenames></author><author><keyname>Pal</keyname><forenames>Manoj Kumar</forenames></author></authors><title>Non-parametric convolution based image-segmentation of ill-posed objects
  applying context window approach</title><categories>cs.CV</categories><comments>10 pages, 7 figures, 4 tables, not published anywhere</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-dependence in human cognition process is a well-established fact.
Following this, we introduced the image segmentation method that can use
context to classify a pixel on the basis of its membership to a particular
object-class of the concerned image. In the broad methodological steps, each
pixel was defined by its context window (CW) surrounding it the size of which
was fixed heuristically. CW texture defined by the intensities of its pixels
was convoluted with weights optimized through a non-parametric function
supported by a backpropagation network. Result of convolution was used to
classify them. The training data points (i.e., pixels) were carefully chosen to
include all variety of contexts of types, i) points within the object, ii)
points near the edge but inside the objects, iii) points at the border of the
objects, iv) points near the edge but outside the objects, v) points near or at
the edge of the image frame. Moreover the training data points were selected
from all the images within image-dataset. CW texture information for 1000
pixels from face area and background area of images were captured, out of which
700 CWs were used as training input data, and remaining 300 for testing. Our
work gives the first time foundation of quantitative enumeration of efficiency
of image-segmentation which is extendable to segment out more than 2 objects
within an image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.1992</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.1992</id><created>2012-02-09</created><authors><author><keyname>Molu</keyname><forenames>Mehdi M.</forenames></author><author><keyname>Goertz</keyname><forenames>Norbert</forenames></author></authors><title>A Comparison of Soft and Hard Coded Relaying</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Amplify and Forward&quot; and &quot;Decode and Forward&quot; are the two main relaying
functions that have been proposed since the advent of cooperative
communication. &quot;\textit{Soft} Decode and Forward&quot; is a recently introduced
relaying principle that is to combine the benefits of the classical two
relaying algorithms. In this work, we thoroughly investigate \textit{soft}
relaying algorithms when convolutional or turbo codes are applied. We study the
error performance of two cooperative scenarios employing soft-relaying. A novel
approach, the mutual information loss due to data processing, is proposed to
analyze the relay-based soft encoder. We also introduce a novel approach to
derive the estimated bit error rate and the equivalent channel SNR for the
relaying techniques considered in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2004</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2004</id><created>2012-02-09</created><updated>2012-02-16</updated><authors><author><keyname>Buono</keyname><forenames>Fabio F. G.</forenames></author></authors><title>A New Type of Cipher</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We will define a new type of cipher that doesn't use neither an easy to
calcualate and hard to invert matematical function like RSA nor a classical
mono or polyalphabetic cipher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2018</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2018</id><created>2012-02-09</created><authors><author><keyname>Karunakaran</keyname><forenames>P.</forenames></author><author><keyname>Venkatesh</keyname><forenames>Dr. C.</forenames></author></authors><title>Traffic and Security using Randomized Dispersive Routes in Heterogeneous
  Sensor Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generally traffic and the sensor network security have many challenges in the
transmission of data in the network. The existing schemes consider homogeneous
sensor networks which have poor performance and scalability. Due to many-to-one
traffic pattern, sensors may communicate with small portion of its neighbours.
Key management is the critical process in sensor nodes to secure the data. Most
existing schemes establish shared keys for all the sensors no matter whether
they are communicating or not. Hence it leads to large storage overhead.
Another problem in sensor network is compromised node attack and denial of
service attack which occurs because of its wireless nature. Existing multi path
routing algorithms are vulnerable to these attacks. So once an adversary
acquires the routing algorithm, it can compute the same routes known to the
source, and hence endanger all information sent over these routes. If an
adversary performs node compromise attack, they can easily get the encryption/
decryption keys used by that node and hence they can intercept the information
easily. In this paper we are proposing a key management scheme which only
establishes shared keys with their communicating neighbour and a mechanism to
generate randomized multipath routes for secure transmission of data to the
sink. Here we are adopting heterogeneous sensor networks and we are utilizing
elliptic curve cryptography for efficient key management which is more
efficient, scalable, and highly secure and reduces communication overhead. The
routes generated by our mechanism are highly dispersive, energy efficient and
making them quite capable of bypassing the back holes at low energy cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2024</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2024</id><created>2012-02-09</created><authors><author><keyname>Saravanan</keyname><forenames>k.</forenames></author><author><keyname>Karthik</keyname><forenames>S.</forenames></author></authors><title>Packet Score based network security and Traffic Optimization</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the critical threat to internet security is Distributed Denial of
Service (DDoS). This paper by the introduction of automated online attack
classification and attack packet discarding helps to resolve the network
security issue by certain level. The incoming packets are assigned scores based
on the priority associated with the attributes and on comparison with
probability distribution of arriving packets on per packet basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2026</identifier>
 <datestamp>2014-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2026</id><created>2012-02-09</created><updated>2013-11-21</updated><authors><author><keyname>SaiToh</keyname><forenames>Akira</forenames></author><author><keyname>Rahimi</keyname><forenames>Robabeh</forenames></author><author><keyname>Nakahara</keyname><forenames>Mikio</forenames></author></authors><title>A quantum genetic algorithm with quantum crossover and mutation
  operations</title><categories>cs.NE quant-ph</categories><comments>21 pages, 1 table, v2: typos corrected, minor modifications in
  sections 3.5 and 4, v3: minor revision, title changed (original title:
  Semiclassical genetic algorithm with quantum crossover and mutation
  operations), v4: minor revision, v5: minor grammatical corrections, to appear
  in QIP</comments><msc-class>68Q12</msc-class><journal-ref>Quantum Inf. Process. 13, 737-755 (2014)</journal-ref><doi>10.1007/s11128-013-0686-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of evolutionary quantum computing in the literal meaning, a
quantum crossover operation has not been introduced so far. Here, we introduce
a novel quantum genetic algorithm which has a quantum crossover procedure
performing crossovers among all chromosomes in parallel for each generation. A
complexity analysis shows that a quadratic speedup is achieved over its
classical counterpart in the dominant factor of the run time to handle each
generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2037</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2037</id><created>2012-02-09</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author></authors><title>Note on RIP-based Co-sparse Analysis</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past years, there are increasing interests in recovering the signals
from undersampling data where such signals are sparse under some orthogonal
dictionary or tight framework, which is referred to be sparse synthetic model.
More recently, its counterpart, i.e., the sparse analysis model, has also
attracted researcher's attentions where many practical signals which are sparse
in the truly redundant dictionary are concerned. This short paper presents
important complement to the results in existing literatures for treating sparse
analysis model. Firstly, we give the natural generalization of well-known
restricted isometry property (RIP) to deal with sparse analysis model, where
the truly arbitrary incoherent dictionary is considered. Secondly, we studied
the theoretical guarantee for the accurate recovery of signal which is sparse
in general redundant dictionaries through solving l1-norm sparsity-promoted
optimization problem. This work shows not only that compressed sensing is
viable in the context of sparse analysis, but also that accurate recovery is
possible via solving l1-minimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2075</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2075</id><created>2012-02-09</created><authors><author><keyname>Sturmel</keyname><forenames>Nicolas</forenames></author><author><keyname>Daudet</keyname><forenames>Laurent</forenames></author></authors><title>Informed Source Separation using Iterative Reconstruction</title><categories>cs.ET</categories><comments>submitted to the IEEE transactions on Audio, Speech and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a technique for Informed Source Separation (ISS) of a
single channel mixture, based on the Multiple Input Spectrogram Inversion
method. The reconstruction of the source signals is iterative, alternating
between a time- frequency consistency enforcement and a re-mixing constraint. A
dual resolution technique is also proposed, for sharper transients
reconstruction. The two algorithms are compared to a state-of-the-art
Wiener-based ISS technique, on a database of fourteen monophonic mixtures, with
standard source separation objective measures. Experimental results show that
the proposed algorithms outperform both this reference technique and the oracle
Wiener filter by up to 3dB in distortion, at the cost of a significantly
heavier computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2080</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2080</id><created>2012-02-09</created><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Carlos Pedro</forenames></author></authors><title>Quantum Financial Economics of Games of Strategy and Financial Decisions</title><categories>q-fin.GN cs.GT physics.soc-ph</categories><comments>15 pages</comments><msc-class>91A22, 91G80, 82C27, 82C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quantum financial approach to finite games of strategy is addressed, with
an extension of Nash's theorem to the quantum financial setting, allowing for
an entanglement of games of strategy with two-period financial allocation
problems that are expressed in terms of: the consumption plans' optimization
problem in pure exchange economies and the finite-state securities market
optimization problem, thus addressing, within the financial setting, the
interplay between companies' business games and financial agents' behavior.
  A complete set of quantum Arrow-Debreu prices, resulting from the game of
strategy's quantum Nash equilibrium, is shown to hold, even in the absence of
securities' market completeness, such that Pareto optimal results are obtained
without having to assume the completeness condition that the rank of the
securities' payoff matrix is equal to the number of alternative lottery states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2082</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2082</id><created>2012-02-09</created><authors><author><keyname>Chaouech</keyname><forenames>Helmi</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Multiuser Detection and Channel Estimation for Multibeam Satellite
  Communications</title><categories>cs.NI cs.IT math.IT</categories><comments>12 pages</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol.4, No.1, January 2012</journal-ref><doi>10.5121/ijcnc.2012.4112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, iterative multi-user detection techniques for multi-beam
communications are presented. The solutions are based on a successive
interference cancellation architecture and a channel decoding to treat the
co-channel interference. Beams forming and channels coefficients are estimated
and updated iteratively. A developed technique of signals combining allows
power improvement of the useful received signal; and then reduction of the bit
error rates with low signal to noise ratios. The approach is applied to a
synchronous multi-beam satellite link under an additive white Gaussian channel.
Evaluation of the techniques is done with computer simulations, where a noised
and multi-access environment is considered. The simulations results show the
good performance of the proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2086</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2086</id><created>2012-02-09</created><updated>2012-03-01</updated><authors><author><keyname>Bono</keyname><forenames>Viviana</forenames><affiliation>Universit&#xe0; di Torino</affiliation></author><author><keyname>Padovani</keyname><forenames>Luca</forenames><affiliation>Universit&#xe0; di Torino</affiliation></author></authors><title>Typing Copyless Message Passing</title><categories>cs.PL</categories><comments>50 pages</comments><proxy>LMCS</proxy><acm-class>F.1.2, F.3.3, F.3.1, D.4.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 2,
  2012) lmcs:798</journal-ref><doi>10.2168/LMCS-8(1:17)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a calculus that models a form of process interaction based on
copyless message passing, in the style of Singularity OS. The calculus is
equipped with a type system ensuring that well-typed processes are free from
memory faults, memory leaks, and communication errors. The type system is
essentially linear, but we show that linearity alone is inadequate, because it
leaves room for scenarios where well-typed processes leak significant amounts
of memory. We address these problems basing the type system upon an original
variant of session types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2088</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2088</id><created>2012-02-09</created><authors><author><keyname>Gonen</keyname><forenames>Mira</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Coded Cooperative Data Exchange Problem for General Topologies</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the &quot;coded cooperative data exchange problem&quot; for general graphs.
In this problem, given a graph G=(V,E) representing clients in a broadcast
network, each of which initially hold a (not necessarily disjoint) set of
information packets; one wishes to design a communication scheme in which
eventually all clients will hold all the packets of the network. Communication
is performed in rounds, where in each round a single client broadcasts a single
(possibly encoded) information packet to its neighbors in G. The objective is
to design a broadcast scheme that satisfies all clients with the minimum number
of broadcast rounds.
  The coded cooperative data exchange problem has seen significant research
over the last few years; mostly when the graph G is the complete broadcast
graph in which each client is adjacent to all other clients in the network, but
also on general topologies, both in the fractional and integral setting. In
this work we focus on the integral setting in general undirected topologies G.
We tie the data exchange problem on G to certain well studied combinatorial
properties of G and in such show that solving the problem exactly or even
approximately within a multiplicative factor of \log{|V|} is intractable (i.e.,
NP-Hard). We then turn to study efficient data exchange schemes yielding a
number of communication rounds comparable to our intractability result. Our
communication schemes do not involve encoding, and in such yield bounds on the
&quot;coding advantage&quot; in the setting at hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2089</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2089</id><created>2012-02-09</created><updated>2012-12-22</updated><authors><author><keyname>Xu</keyname><forenames>Jiaming</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author></authors><title>The Supermarket Game</title><categories>cs.IT cs.GT math.IT</categories><comments>Submitted to Stochastic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A supermarket game is considered with $N$ FCFS queues with unit exponential
service rate and global Poisson arrival rate $N \lambda$. Upon arrival each
customer chooses a number of queues to be sampled uniformly at random and joins
the least loaded sampled queue. Customers are assumed to have cost for both
waiting and sampling, and they want to minimize their own expected total cost.
  We study the supermarket game in a mean field model that corresponds to the
limit as $N$ converges to infinity in the sense that (i) for a fixed symmetric
customer strategy, the joint equilibrium distribution of any fixed number of
queues converges as $N \to \infty$ to a product distribution determined by the
mean field model and (ii) a Nash equilibrium for the mean field model is an
$\epsilon$-Nash equilibrium for the finite $N$ model with $N$ sufficiently
large. It is shown that there always exists a Nash equilibrium for $\lambda &lt;1$
and the Nash equilibrium is unique with homogeneous waiting cost for $\lambda^2
\le 1/2$. Furthermore, we find that the action of sampling more queues by some
customers has a positive externality on the other customers in the mean field
model, but can have a negative externality for finite $N$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2092</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2092</id><created>2012-02-09</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author><author><keyname>Sun</keyname><forenames>Zhifeng</forenames></author></authors><title>Discovery through Gossip</title><categories>cs.DC cs.DM cs.DS</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study randomized gossip-based processes in dynamic networks that are
motivated by discovery processes in large-scale distributed networks like
peer-to-peer or social networks.
  A well-studied problem in peer-to-peer networks is the resource discovery
problem. There, the goal for nodes (hosts with IP addresses) is to discover the
IP addresses of all other hosts. In social networks, nodes (people) discover
new nodes through exchanging contacts with their neighbors (friends). In both
cases the discovery of new nodes changes the underlying network - new edges are
added to the network - and the process continues in the changed network.
Rigorously analyzing such dynamic (stochastic) processes with a continuously
self-changing topology remains a challenging problem with obvious applications.
  This paper studies and analyzes two natural gossip-based discovery processes.
In the push process, each node repeatedly chooses two random neighbors and puts
them in contact (i.e., &quot;pushes&quot; their mutual information to each other). In the
pull discovery process, each node repeatedly requests or &quot;pulls&quot; a random
contact from a random neighbor. Both processes are lightweight, local, and
naturally robust due to their randomization.
  Our main result is an almost-tight analysis of the time taken for these two
randomized processes to converge. We show that in any undirected n-node graph
both processes take O(n log^2 n) rounds to connect every node to all other
nodes with high probability, whereas Omega(n log n) is a lower bound. In the
directed case we give an O(n^2 log n) upper bound and an Omega(n^2) lower bound
for strongly connected directed graphs. A key technical challenge that we
overcome is the analysis of a randomized process that itself results in a
constantly changing network which leads to complicated dependencies in every
round.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2097</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2097</id><created>2012-02-09</created><updated>2014-03-25</updated><authors><author><keyname>Borodin</keyname><forenames>Allan</forenames></author><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Oren</keyname><forenames>Joel</forenames></author></authors><title>Truthful Mechanisms for Competing Submodular Processes</title><categories>cs.GT cs.DS</categories><comments>The latest version contains a revised Section 4 and Appendix D</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications to word-of-mouth advertising, we consider a
game-theoretic scenario in which competing advertisers want to target initial
adopters in a social network. Each advertiser wishes to maximize the resulting
cascade of influence, modeled by a general network diffusion process. However,
competition between products may adversely impact the rate of adoption for any
given firm. The resulting framework gives rise to complex preferences that
depend on the specifics of the stochastic diffusion model and the network
topology.
  We study this model from the perspective of a central mechanism, such as a
social networking platform, that can optimize seed placement as a service for
the advertisers. We ask: given the reported demands of the competing firms, how
should a mechanism choose seeds to maximize overall efficiency? Beyond the
algorithmic problem, competition raises issues of strategic behaviour: rational
agents should not be incentivized to underreport their budget demands.
  We show that when there are two players, the social welfare can be
$2$-approximated by a polynomial-time strategyproof mechanism. Our mechanism is
defined recursively, randomizing the order in which advertisers are allocated
seeds according to a particular greedy method. For three or more players, we
demonstrate that under additional assumptions (satisfied by many existing
models of influence spread) there exists a simpler strategyproof
$\frac{e}{e-1}$-approximation mechanism; notably, this second mechanism is not
necessarily strategyproof when there are only two players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2111</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2111</id><created>2012-02-09</created><updated>2012-05-04</updated><authors><author><keyname>Campello</keyname><forenames>Antonio</forenames></author><author><keyname>Torezzan</keyname><forenames>Cristiano</forenames></author><author><keyname>Costa</keyname><forenames>Sueli I. R.</forenames></author></authors><title>Curves on torus layers and coding for continuous alphabet sources</title><categories>cs.IT math.DG math.IT</categories><comments>5 pages, 4 figures. Accepted for presentation at 2012 IEEE
  International Symposium on Information Theory (ISIT). 2th version: typos
  corrected. 3rd version: some typos corrected, a footnote added in Section III
  B, a comment added in the beggining of Section V and Theorem I added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of transmitting a continuous alphabet
discrete-time source over an AWGN channel. The design of good curves for this
purpose relies on geometrical properties of spherical codes and projections of
$N$-dimensional lattices. We propose a constructive scheme based on a set of
curves on the surface of a 2N-dimensional sphere and present comparisons with
some previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2112</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2112</id><created>2012-02-09</created><authors><author><keyname>Dey</keyname><forenames>Debadeepta</forenames></author><author><keyname>Liu</keyname><forenames>Tian Yu</forenames></author><author><keyname>Hebert</keyname><forenames>Martial</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Predicting Contextual Sequences via Submodular Function Maximization</title><categories>cs.AI cs.LG cs.RO</categories><comments>8 pages</comments><report-no>CMU-RI-TR-12-05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence optimization, where the items in a list are ordered to maximize some
reward has many applications such as web advertisement placement, search, and
control libraries in robotics. Previous work in sequence optimization produces
a static ordering that does not take any features of the item or context of the
problem into account. In this work, we propose a general approach to order the
items within the sequence based on the context (e.g., perceptual information,
environment description, and goals). We take a simple, efficient,
reduction-based approach where the choice and order of the items is established
by repeatedly learning simple classifiers or regressors for each &quot;slot&quot; in the
sequence. Our approach leverages recent work on submodular function
maximization to provide a formal regret reduction from submodular sequence
optimization to simple cost-sensitive prediction. We apply our contextual
sequence prediction algorithm to optimize control libraries and demonstrate
results on two robotics problems: manipulator trajectory prediction and mobile
robot path planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2113</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2113</id><created>2012-02-09</created><authors><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Decentralized Delay Optimal Control for Interference Networks with
  Limited Renewable Energy Storage</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2012.2187284</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider delay minimization for interference networks with
renewable energy source, where the transmission power of a node comes from both
the conventional utility power (AC power) and the renewable energy source. We
assume the transmission power of each node is a function of the local channel
state, local data queue state and local energy queue state only. In turn, we
consider two delay optimization formulations, namely the decentralized
partially observable Markov decision process (DEC-POMDP) and Non-cooperative
partially observable stochastic game (POSG). In DEC-POMDP formulation, we
derive a decentralized online learning algorithm to determine the control
actions and Lagrangian multipliers (LMs) simultaneously, based on the policy
gradient approach. Under some mild technical conditions, the proposed
decentralized policy gradient algorithm converges almost surely to a local
optimal solution. On the other hand, in the non-cooperative POSG formulation,
the transmitter nodes are non-cooperative. We extend the decentralized policy
gradient solution and establish the technical proof for almost-sure convergence
of the learning algorithms. In both cases, the solutions are very robust to
model variations. Finally, the delay performance of the proposed solutions are
compared with conventional baseline schemes for interference networks and it is
illustrated that substantial delay performance gain and energy savings can be
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2131</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2131</id><created>2012-02-09</created><authors><author><keyname>Michalski</keyname><forenames>Brian</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Mukkai</forenames></author><author><keyname>Lau</keyname><forenames>Tsz-Yam</forenames></author></authors><title>Temporal Analysis of Literary and Programming Prose</title><categories>cs.SE cs.DL</categories><acm-class>D.2.7; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Literary works reference a variety of globally shared themes including
well-known people, events, and time periods. It is particularly interesting to
locate patterns that are either invariant across time or exhibit a
characteristic change across time, as they could imply something important
about society that those works record. This paper suggests the use of Google
n-gram viewer as a fast prototyping method for examining time-based properties
over a rich sample of literary prose. Using this method, we find that some
repeating periods of time, like Sunday, are referenced disproportionally,
allowing us to pose questions such as why a day like Thursday is so unpopular.
Furthermore, by treating software as a work of prose, we can apply a similar
analysis to open-source software repositories and explore time-based relations
in commit logs. Doing a simple statistical analysis on a few temporal keywords
in the log records, we reinforce and weaken a few beliefs on how college
students approach open source software. Finally, we help readers working on
their own temporal analysis by comparing the fundamental differences between
literary works and code repositories, and suggest blog or wiki as
recently-emerging works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2143</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2143</id><created>2012-02-09</created><authors><author><keyname>Park</keyname><forenames>Il Memming</forenames></author><author><keyname>Nassar</keyname><forenames>Marcel</forenames></author><author><keyname>Park</keyname><forenames>Mijung</forenames></author></authors><title>Active Bayesian Optimization: Minimizing Minimizer Entropy</title><categories>stat.ME cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ultimate goal of optimization is to find the minimizer of a target
function.However, typical criteria for active optimization often ignore the
uncertainty about the minimizer. We propose a novel criterion for global
optimization and an associated sequential active learning strategy using
Gaussian processes.Our criterion is the reduction of uncertainty in the
posterior distribution of the function minimizer. It can also flexibly
incorporate multiple global minimizers. We implement a tractable approximation
of the criterion and demonstrate that it obtains the global minimizer
accurately compared to conventional Bayesian optimization criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2153</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2153</id><created>2012-02-09</created><authors><author><keyname>Valadao</keyname><forenames>Everthon</forenames></author><author><keyname>Guedes</keyname><forenames>Dorgival</forenames></author><author><keyname>Duarte</keyname><forenames>Ricardo</forenames></author></authors><title>Caracteriza\c{c}\~ao de tempos de ida-e-volta na Internet</title><categories>cs.NI cs.DC</categories><journal-ref>Revista Brasileira de Redes de Computadores e Sistemas
  Distribu\'idos, v. 3, p. 21-34, 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Round-trip times (RTTs) are an important metric for the operation of many
applications in the Internet. For instance, they are taken into account when
choosing servers or peers in streaming systems, and they impact the operation
of fault detectors and congestion control algorithms. Therefore, detailed
knowledge about RTTs is important for application and protocol developers. In
this work we present results on measuring RTTs between 81 PlanetLab nodes every
ten seconds, for ten days. The resulting dataset has over 550 million
measurements. Our analysis gives us a profile of delays in the network and
identifies a Gamma distribution as the model that best fits our data. The
average times observed are below 500 ms in more than 99% of the pairs, but
there is significant variation, not only when we compare different pairs of
hosts during the experiment, but also considering any given pair of hosts over
time. By using a clustering technique, we observe that links can be divided in
five distinct groups based on the distribution of RTTs over time and the losses
observed, ranging from groups of near, well-connected pairs, to groups of
distant hosts, with lower quality links between them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2156</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2156</id><created>2012-02-09</created><authors><author><keyname>Creed</keyname><forenames>P&#xe1;id&#xed;</forenames></author><author><keyname>Cryan</keyname><forenames>Mary</forenames></author></authors><title>The number of Euler tours of a random directed graph</title><categories>cs.DM cs.DS math.CO math.PR</categories><msc-class>05C45, 05C80, 68R05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we obtain the expectation and variance of the number of Euler
tours of a random Eulerian directed graph with fixed out-degree sequence. We
use this to obtain the asymptotic distribution of the number of Euler tours of
a random $d$-in/$d$-out graph and prove a concentration result. We are then
able to show that a very simple approach for uniform sampling or approximately
counting Euler tours yields algorithms running in expected polynomial time for
almost every $d$-in/$d$-out graph. We make use of the BEST theorem of de
Bruijn, van Aardenne-Ehrenfest, Smith and Tutte, which shows that the number of
Euler tours of an Eulerian directed graph with out-degree sequence $\mathbf{d}$
is the product of the number of arborescences and the term
$\frac{1}{n}[\prod_{v \in V}(d_v-1)!]$. Therefore most of our effort is towards
estimating the moments of the number of arborescences of a random graph with
fixed out-degree sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2158</identifier>
 <datestamp>2012-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2158</id><created>2012-02-09</created><updated>2012-04-04</updated><authors><author><keyname>Azimi</keyname><forenames>Javad</forenames></author><author><keyname>Zhang</keyname><forenames>Ruofei</forenames></author><author><keyname>Zhou</keyname><forenames>Yang</forenames></author><author><keyname>Navalpakkam</keyname><forenames>Vidhya</forenames></author><author><keyname>Mao</keyname><forenames>Jianchang</forenames></author><author><keyname>Fern</keyname><forenames>Xiaoli</forenames></author></authors><title>The Impact of Visual Appearance on User Response in Online Display
  Advertising</title><categories>cs.HC</categories><comments>This work was done while the first author was an Intern at Yahoo!
  Labs</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Display advertising has been a significant source of revenue for publishers
and ad networks in online advertising ecosystem. One of the main goals in
display advertising is to maximize user response rate for advertising
campaigns, such as click through rates (CTR) or conversion rates. Although in
the online advertising industry we believe that the visual appearance of ads
(creatives) matters for propensity of user response, there is no published work
so far to address this topic via a systematic data-driven approach. In this
paper we quantitatively study the relationship between the visual appearance
and performance of creatives using large scale data in the world's largest
display ads exchange system, RightMedia. We designed a set of 43 visual
features, some of which are novel and some are inspired by related work. We
extracted these features from real creatives served on RightMedia. We also
designed and conducted a series of experiments to evaluate the effectiveness of
visual features for CTR prediction, ranking and performance classification.
Based on the evaluation results, we selected a subset of features that have the
most important impact on CTR. We believe that the findings presented in this
paper will be very useful for the online advertising industry in designing
high-performance creatives. It also provides the research community with the
first ever data set, initial insights into visual appearance's effect on user
response propensity, and evaluation benchmarks for further study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2160</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2160</id><created>2012-02-09</created><updated>2012-07-13</updated><authors><author><keyname>Farabet</keyname><forenames>Cl&#xe9;ment</forenames></author><author><keyname>Couprie</keyname><forenames>Camille</forenames></author><author><keyname>Najman</keyname><forenames>Laurent</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Scene Parsing with Multiscale Feature Learning, Purity Trees, and
  Optimal Covers</title><categories>cs.CV cs.LG</categories><comments>9 pages, 4 figures - Published in 29th International Conference on
  Machine Learning (ICML 2012), Jun 2012, Edinburgh, United Kingdom</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene parsing, or semantic segmentation, consists in labeling each pixel in
an image with the category of the object it belongs to. It is a challenging
task that involves the simultaneous detection, segmentation and recognition of
all the objects in the image.
  The scene parsing method proposed here starts by computing a tree of segments
from a graph of pixel dissimilarities. Simultaneously, a set of dense feature
vectors is computed which encodes regions of multiple sizes centered on each
pixel. The feature extractor is a multiscale convolutional network trained from
raw pixels. The feature vectors associated with the segments covered by each
node in the tree are aggregated and fed to a classifier which produces an
estimate of the distribution of object categories contained in the segment. A
subset of tree nodes that cover the image are then selected so as to maximize
the average &quot;purity&quot; of the class distributions, hence maximizing the overall
likelihood that each segment will contain a single object. The convolutional
network feature extractor is trained end-to-end from raw pixels, alleviating
the need for engineered features. After training, the system is parameter free.
  The system yields record accuracies on the Stanford Background Dataset (8
classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170
classes) while being an order of magnitude faster than competing approaches,
producing a 320 \times 240 image labeling in less than 1 second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2167</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2167</id><created>2012-02-09</created><authors><author><keyname>Ozkural</keyname><forenames>Eray</forenames></author></authors><title>Abstract Representations and Frequent Pattern Discovery</title><categories>cs.AI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the frequent pattern mining problem in a general setting. From an
analysis of abstract representations, summarization and frequent pattern
mining, we arrive at a generalization of the problem. Then, we show how the
problem can be cast into the powerful language of algorithmic information
theory. This allows us to formulate a simple algorithm to mine for all frequent
patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2168</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2168</id><created>2012-02-09</created><authors><author><keyname>Dougherty</keyname><forenames>Daniel J.</forenames></author><author><keyname>Guttman</keyname><forenames>Joshua D.</forenames></author></authors><title>Symbolic Protocol Analysis for Diffie-Hellman</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend symbolic protocol analysis to apply to protocols using
Diffie-Hellman operations. Diffie-Hellman operations act on a cyclic group of
prime order, together with an exponentiation operator. The exponents form a
finite field. This rich algebraic structure has resisted previous symbolic
approaches. We work in an algebra defined by the normal forms of a rewriting
theory (modulo associativity and commutativity). These normal forms allow us to
define our crucial notion of indicator, a vector of integers that summarizes
how many times each secret exponent appears in a message. We prove that the
adversary can never construct a message with a new indicator in our adversary
model. Using this invariant, we prove the main security goals achieved by
several different protocols that use Diffie-Hellman operators in subtle ways.
We also give a model-theoretic justification of our rewriting theory: the
theory proves all equations that are uniformly true as the order of the cyclic
group varies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2171</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2171</id><created>2012-02-09</created><authors><author><keyname>Sampangi</keyname><forenames>Raghav V.</forenames></author><author><keyname>Dey</keyname><forenames>Saurabh</forenames></author><author><keyname>Urs</keyname><forenames>Shalini R.</forenames></author><author><keyname>Sampalli</keyname><forenames>Srinivas</forenames></author></authors><title>A security suite for wireless body area networks</title><categories>cs.CR</categories><comments>20 pages, 10 figures, 3 tables, International Journal of Network
  Security &amp; its Applications (IJNSA)</comments><journal-ref>International Journal of Network Security &amp; its Applications
  (IJNSA) 4(1) (2012) 97-116</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Body Area Networks (WBANs) have gained a lot of research attention
in recent years since they offer tremendous benefits for remote health
monitoring and continuous, real-time patient care. However, as with any
wireless communication, data security in WBANs is a challenging design issue.
Since such networks consist of small sensors placed on the human body, they
impose resource and computational restrictions, thereby making the use of
sophisticated and advanced encryption algorithms infeasible. This calls for the
design of algorithms with a robust key generation / management scheme, which
are reasonably resource optimal. This paper presents a security suite for
WBANs, comprised of IAMKeys, an independent and adaptive key management scheme
for improving the security of WBANs, and KEMESIS, a key management scheme for
security in inter-sensor communication. The novelty of these schemes lies in
the use of a randomly generated key for encrypting each data frame that is
generated independently at both the sender and the receiver, eliminating the
need for any key exchange. The simplicity of the encryption scheme, combined
with the adaptability in key management makes the schemes simple, yet secure.
The proposed algorithms are validated by performance analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2175</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2175</id><created>2012-02-09</created><updated>2014-02-21</updated><authors><author><keyname>Zhang</keyname><forenames>Huazi</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author></authors><title>On the Capacity Region of Cognitive Multiple Access over White Space
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistically sharing the white spaces, or the temporarily unoccupied
spectrum licensed to the primary user (PU), is a practical way to improve the
spectrum utilization. In this paper, we consider the fundamental problem of
rate regions achievable for multiple secondary users (SUs) which send their
information to a common receiver over such a white space channel. In
particular, the PU activities are treated as on/off side information, which can
be obtained causally or non-causally by the SUs. The system is then modeled as
a multi-switch channel and its achievable rate regions are characterized in
some scenarios. Explicit forms of outer and inner bounds of the rate regions
are derived by assuming additional side information, and they are shown to be
tight in some special cases. An optimal rate and power allocation scheme that
maximizes the sum rate is also proposed. The numerical results reveal the
impacts of side information, channel correlation and PU activity on the
achievable rates, and also verify the effectiveness of our rate and power
allocation scheme. Our work may shed some light on the fundamental limit and
design tradeoffs in practical cognitive radio systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2185</identifier>
 <datestamp>2012-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2185</id><created>2012-02-09</created><updated>2012-02-23</updated><authors><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Wang</keyname><forenames>Jing</forenames></author><author><keyname>Lahijanian</keyname><forenames>Morteza</forenames></author><author><keyname>Paschalidis</keyname><forenames>Ioannis Ch.</forenames></author><author><keyname>Belta</keyname><forenames>Calin A.</forenames></author></authors><title>Temporal Logic Motion Control using Actor-Critic Methods</title><categories>cs.RO cs.SY math.OC</categories><comments>Technical Report which accompanies an ICRA2012 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of deploying a robot from a
specification given as a temporal logic statement about some properties
satisfied by the regions of a large, partitioned environment. We assume that
the robot has noisy sensors and actuators and model its motion through the
regions of the environment as a Markov Decision Process (MDP). The robot
control problem becomes finding the control policy maximizing the probability
of satisfying the temporal logic task on the MDP. For a large environment,
obtaining transition probabilities for each state-action pair, as well as
solving the necessary optimization problem for the optimal policy are usually
not computationally feasible. To address these issues, we propose an
approximate dynamic programming framework based on a least-square temporal
difference learning method of the actor-critic type. This framework operates on
sample paths of the robot and optimizes a randomized control policy with
respect to a small set of parameters. The transition probabilities are obtained
only when needed. Hardware-in-the-loop simulations confirm that convergence of
the parameters translates to an approximately optimal policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2187</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2187</id><created>2012-02-09</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>Museum: Multidimensional web page segment evaluation model</title><categories>cs.IR</categories><comments>ISSN 2151-9617</comments><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><journal-ref>Journal of Computing Volume 3, Issue 3 (2011) 24-27</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evaluation of a web page with respect to a query is a vital task in the
web information retrieval domain. This paper proposes the evaluation of a web
page as a bottom-up process from the segment level to the page level. A model
for evaluating the relevancy is proposed incorporating six different
dimensions. An algorithm for evaluating the segments of a web page, using the
above mentioned six dimensions is proposed. The benefits of fine-granining the
evaluation process to the segment level instead of the page level are explored.
The proposed model can be incorporated for various tasks like web page
personalization, result re-ranking, mobile device page rendering etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2209</identifier>
 <datestamp>2012-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2209</id><created>2012-02-10</created><updated>2012-11-29</updated><authors><author><keyname>Simon</keyname><forenames>Sunil</forenames></author><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>Choosing Products in Social Networks</title><categories>cs.SI cs.GT physics.soc-ph</categories><comments>15 pages. Appeared in Proc. of the 8th International Workshop on
  Internet and Network Economics (WINE 2012), Lecture Notes in Computer Science
  7695, Springer, pp. 100-113</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the consequences of adopting products by agents who form a social
network. To this end we use the threshold model introduced in Apt and Markakis,
arXiv:1105.2434, in which the nodes influenced by their neighbours can adopt
one out of several alternatives, and associate with such each social network a
strategic game between the agents. The possibility of not choosing any product
results in two special types of (pure) Nash equilibria.
  We show that such games may have no Nash equilibrium and that determining the
existence of a Nash equilibrium, also of a special type, is NP-complete. The
situation changes when the underlying graph of the social network is a DAG, a
simple cycle, or has no source nodes. For these three classes we determine the
complexity of establishing whether a (special type of) Nash equilibrium exists.
  We also clarify for these categories of games the status and the complexity
of the finite improvement property (FIP). Further, we introduce a new property
of the uniform FIP which is satisfied when the underlying graph is a simple
cycle, but determining it is co-NP-hard in the general case and also when the
underlying graph has no source nodes. The latter complexity results also hold
for verifying the property of being a weakly acyclic game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2214</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2214</id><created>2012-02-10</created><authors><author><keyname>Ageyev</keyname><forenames>Dmitry</forenames></author><author><keyname>Pereverzev</keyname><forenames>Alexander</forenames></author></authors><title>Wavelength Assignment in Design DWDM Transport Network Using Algorithm
  BCO-RWA</title><categories>cs.NI</categories><comments>2 pages, 1 figure, 1 table</comments><journal-ref>Proceedings of the ??th International Conference on Modern
  Problems of Radio Engineering, Telecommunications, and Computer Science,
  TCSET'2012, 2012, pp. 277 - 278</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main problem in designing DWDM transport networks is the wavelength
assignment of light paths. One way of solving this problem is to use the
algorithm BCO-RWA. However, BCO-RWA has the following disadvantages: algorithm
not solved the problem of choosing the location of the optical convector in the
network; base algorithm ignores placement optical convector during calculating
route selecting probability; base algorithm do not take into account the
nonlinear four-wave mixing phenomenon. In this paper we present an algorithm
which takes into account a number of disadvantages due to modifications
introduced in the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2215</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2215</id><created>2012-02-10</created><authors><author><keyname>Rajyalakshmi</keyname><forenames>S.</forenames></author><author><keyname>Bagchi</keyname><forenames>Amitabha</forenames></author><author><keyname>Das</keyname><forenames>Soham</forenames></author><author><keyname>Tripathy</keyname><forenames>Rudra M.</forenames></author></authors><title>Topic Diffusion and Emergence of Virality in Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>26 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a stochastic model for the diffusion of topics entering a social
network modeled by a Watts-Strogatz graph. Our model sets into play an implicit
competition between these topics as they vie for the attention of users in the
network. The dynamics of our model are based on notions taken from real-world
OSNs like Twitter where users either adopt an exogenous topic or copy topics
from their neighbors leading to endogenous propagation. When instantiated
correctly, the model achieves a viral regime where a few topics garner
unusually good response from the network, closely mimicking the behavior of
real-world OSNs. Our main contribution is our description of how clusters of
proximate users that have spoken on the topic merge to form a large giant
component making a topic go viral. This demonstrates that it is not weak ties
but actually strong ties that play a major part in virality. We further
validate our model and our hypotheses about its behavior by comparing our
simulation results with the results of a measurement study conducted on real
data taken from Twitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2223</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2223</id><created>2012-02-10</created><updated>2012-02-17</updated><authors><author><keyname>Liu</keyname><forenames>Yulong</forenames></author><author><keyname>Li</keyname><forenames>Shidong</forenames></author><author><keyname>Mi</keyname><forenames>Tiebin</forenames></author></authors><title>Performance Analysis of $\ell_1$-synthesis with Coherent Frames</title><categories>cs.IT math.IT</categories><comments>19 pages, 7 figures</comments><journal-ref>IEEE International Symposium on Information Theory, MIT,
  pp.2042--2046, July, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signals with sparse frame representations comprise a much more realistic
model of nature than that with orthonomal bases. Studies about the signal
recovery associated with such sparsity models have been one of major focuses in
compressed sensing. In such settings, one important and widely used signal
recovery approach is known as $\ell_1$-synthesis (or Basis Pursuit). We present
in this article a more effective performance analysis (than what are available)
of this approach in which the dictionary $\Dbf$ may be highly, and even
perfectly correlated. Under suitable conditions on the sensing matrix $\Phibf$,
an error bound of the recovered signal $\hat{\fbf}$ (by the $\ell_1$-synthesis
method) is established. Such an error bound is governed by the decaying
property of $\tilde{\Dbf}_{\text{o}}^*\fbf$, where $\fbf$ is the true signal
and $\tilde{\Dbf}_{\text{o}}$ denotes the optimal dual frame of $\Dbf$ in the
sense that $\|\tilde{\Dbf}_{\text{o}}^*\hat{\fbf}\|_1$ produces the smallest
$\|\tilde{\Dbf}^*\tilde{\fbf}\|_1$ in value among all dual frames
$\tilde{\Dbf}$ of $\Dbf$ and all feasible signals $\tilde{\fbf}$. This new
performance analysis departs from the usual description of the combo
$\Phibf\Dbf$, and places the description on $\Phibf$. Examples are demonstrated
to show that when the usual analysis fails to explain the working performance
of the synthesis approach, the newly established results do.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2231</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2231</id><created>2012-02-10</created><authors><author><keyname>Liu</keyname><forenames>Liang</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Chua</keyname><forenames>Kee-Chaing</forenames></author></authors><title>Achieving Global Optimality for Weighted Sum-Rate Maximization in the
  K-User Gaussian Interference Channel with Multiple Antennas</title><categories>cs.IT math.IT</categories><comments>This is the longer version of a paper to appear in IEEE Transactions
  on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Characterizing the global maximum of weighted sum-rate (WSR) for the K-user
Gaussian interference channel (GIC), with the interference treated as Gaussian
noise, is a key problem in wireless communication. However, due to the users'
mutual interference, this problem is in general non-convex and thus cannot be
solved directly by conventional convex optimization techniques. In this paper,
by jointly utilizing the monotonic optimization and rate profile techniques, we
develop a new framework to obtain the globally optimal power control and/or
beamforming solutions to the WSR maximization problems for the GICs with
single-antenna transmitters and single-antenna receivers (SISO), single-antenna
transmitters and multi-antenna receivers (SIMO), or multi-antenna transmitters
and single-antenna receivers (MISO). Different from prior work, this paper
proposes to maximize the WSR in the achievable rate region of the GIC directly
by exploiting the facts that the achievable rate region is a &quot;normal&quot; set and
the users' WSR is a &quot;strictly increasing&quot; function over the rate region.
Consequently, the WSR maximization is shown to be in the form of monotonic
optimization over a normal set and thus can be solved globally optimally by the
existing outer polyblock approximation algorithm. However, an essential step in
the algorithm hinges on how to efficiently characterize the intersection point
on the Pareto boundary of the achievable rate region with any prescribed &quot;rate
profile&quot; vector. This paper shows that such a problem can be transformed into a
sequence of signal-to-interference-plus-noise ratio (SINR) feasibility
problems, which can be solved efficiently by existing techniques. Numerical
results validate that the proposed algorithms can achieve the global WSR
maximum for the SISO, SIMO or MISO GIC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2249</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2249</id><created>2012-02-10</created><authors><author><keyname>Sporea</keyname><forenames>Ioana</forenames></author><author><keyname>Gr&#xfc;ning</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Supervised Learning in Multilayer Spiking Neural Networks</title><categories>cs.NE q-bio.NC</categories><comments>38 pages, 4 figures</comments><journal-ref>Neural Compuation February 2013, Vol. 25, No. 2, Pages 473-509</journal-ref><doi>10.1162/NECO_a_00396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current article introduces a supervised learning algorithm for multilayer
spiking neural networks. The algorithm presented here overcomes some
limitations of existing learning algorithms as it can be applied to neurons
firing multiple spikes and it can in principle be applied to any linearisable
neuron model. The algorithm is applied successfully to various benchmarks, such
as the XOR problem and the Iris data set, as well as complex classifications
problems. The simulations also show the flexibility of this supervised learning
algorithm which permits different encodings of the spike timing patterns,
including precise spike trains encoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2251</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2251</id><created>2012-02-10</created><updated>2012-08-14</updated><authors><author><keyname>Halabi</keyname><forenames>Nissim</forenames></author><author><keyname>Even</keyname><forenames>Guy</forenames></author></authors><title>Hierarchies of Local-Optimality Characterizations in Decoding of Tanner
  Codes</title><categories>cs.IT math.IT</categories><comments>Extended abstract appears in the proceedings of the IEEE
  International Symposium on Information Theory, Cambridge, MA,USA, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent developments in decoding of Tanner codes with maximum-likelihood
certificates are based on a sufficient condition called local-optimality. We
define hierarchies of locally-optimal codewords with respect to two parameters.
One parameter is related to the minimum distance of the local codes in Tanner
codes. The second parameter is related to the finite number of iterations used
in iterative decoding. We show that these hierarchies satisfy inclusion
properties as these parameters are increased. In particular, this implies that
a codeword that is decoded with a certificate using an iterative decoder after
$h$ iterations is decoded with a certificate after $k\cdot h$ iterations, for
every integer $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2261</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2261</id><created>2012-02-10</created><authors><author><keyname>Rogge</keyname><forenames>Jonathan</forenames></author><author><keyname>Aeyels</keyname><forenames>Dirk</forenames></author></authors><title>Multi-robot coverage to locate fixed targets using formation structures</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops an algorithm that guides a multi-robot system in an
unknown environment in search of fixed targets. The area to be scanned contains
an unknown number of convex obstacles of unknown size and shape. The algorithm
covers the entire free space in a sweeping fashion and as such relies on the
use of robot formations. The geometry of the robot group is a lateral line
formation, which is allowed to split and rejoin when passing obstacles. It is
our main goal to exploit this formation structure in order to reduce robot
resources to a minimum. Each robot has a limited and finite amount of memory
available. No information of the topography is recorded. Communication between
two robots is only possible up to a maximum inter-robot distance, and if the
line-of-sight between both robots is not obstructed. Broadcasting capabilities
and indirect communication are not allowed. Supervisory control is prohibited.
The number of robots equipped with GPS is kept as small as possible.
Applications of the algorithm are mine field clearance, search-and-rescue
missions, and intercept missions. Simulations are included and made available
on the internet, demonstrating the flexibility of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2283</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2283</id><created>2012-02-10</created><authors><author><keyname>Rahaman</keyname><forenames>Ramij</forenames></author><author><keyname>Majumdar</keyname><forenames>Priyadarshi</forenames></author><author><keyname>Basu</keyname><forenames>B.</forenames></author></authors><title>Quantum Cournot equilibrium for the Hotelling-Smithies model of product
  choice</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>13 pages, 6 tables, 8 figures</comments><journal-ref>J. Phys. A: Math. Theor. 45 455301 (2012)</journal-ref><doi>10.1088/1751-8113/45/45/455301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates the quantization of a spatial Cournot duopoly model
with product choice, a two stage game focusing on non-cooperation in locations
and quantities. With quantization, the players can access a continuous set of
strategies, using continuous variable quantum mechanical approach. The presence
of quantum entanglement in the initial state identifies a quantity equilibrium
for every location pair choice with any transport cost. Also higher profit is
obtained by the firms at Nash equilibrium. Adoption of quantum strategies
rewards us by the existence of a larger quantum strategic space at equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2284</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2284</id><created>2012-02-10</created><authors><author><keyname>Lucanin</keyname><forenames>Drazen</forenames></author><author><keyname>Fabek</keyname><forenames>Ivan</forenames></author></authors><title>A visual programming language for drawing and executing flowcharts</title><categories>cs.PL cs.SE</categories><comments>6 pages, conference paper</comments><journal-ref>Proceedings of the 34th International Convention MIPRO, 23-27 May
  2011, p. 1679-1684</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  With recent advances in graphical user interfaces, more and more tasks on
computers have become easier to perform. Out of the belief that creating
computer programs can also be one of them, visual programming languages (VPLs)
have emerged. The goal of VPLs is to shift a part of work from the programmer
to the IDE so that the programmer can focus more on algorithm logic than the
syntax of the implementation programming language. In this article, the methods
required to build a VPL are presented, with an emphasis on a novel method of
code generation in a WHILE language. Also, the methods for achieving basic
principles of VPLs will be shown - suitable visual presentation of information
and guiding the programmer in the right direction using constraints. These
methods are demonstrated on an example of vIDE, a VPL based on the Eclipse
integrated development environment (IDE). The design of vIDE with respect to
the Eclipse Graphical Modeling Framework (GMF) is described. The concept of a
flowchart graphical notation is examined in contrast with the algorithm model
it maps to. Finally, the disambiguity of the model representation of an
algorithm is discussed and the methods for transforming it to an actual
implementation in a programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2287</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2287</id><created>2012-02-10</created><updated>2012-02-27</updated><authors><author><keyname>Goubault-Larrecq</keyname><forenames>Jean</forenames><affiliation>LSV, ENS Cachan, CNRS, INRIA</affiliation></author></authors><title>QRB-Domains and the Probabilistic Powerdomain</title><categories>cs.PL</categories><comments>32 pages, 7 figures. An extended abstract already appeared in Proc.
  25th Annual IEEE Symposium on Logic in Computer Science (LICS'10)</comments><proxy>LMCS</proxy><acm-class>D.3.1, F.1.2, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (February
  29, 2012) lmcs:956</journal-ref><doi>10.2168/LMCS-8(1:14)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is there any Cartesian-closed category of continuous domains that would be
closed under Jones and Plotkin's probabilistic powerdomain construction? This
is a major open problem in the area of denotational semantics of probabilistic
higher-order languages. We relax the question, and look for quasi-continuous
dcpos instead. We introduce a natural class of such quasi-continuous dcpos, the
omega-QRB-domains. We show that they form a category omega-QRB with pleasing
properties: omega-QRB is closed under the probabilistic powerdomain functor,
under finite products, under taking bilimits of expanding sequences, under
retracts, and even under so-called quasi-retracts. But... omega-QRB is not
Cartesian closed. We conclude by showing that the QRB domains are just one half
of an FS-domain, merely lacking control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2293</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2293</id><created>2012-02-10</created><updated>2012-08-14</updated><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames><affiliation>MPI for Informatics</affiliation></author><author><keyname>Mehlhorn</keyname><forenames>Kurt</forenames><affiliation>MPI for Informatics</affiliation></author><author><keyname>Neumann</keyname><forenames>Adrian</forenames><affiliation>MPI for Informatics</affiliation></author></authors><title>Remarks on Category-Based Routing in Social Networks</title><categories>cs.SI cs.DC cs.DM physics.soc-ph</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that individuals can route messages on short paths through
social networks, given only simple information about the target and using only
local knowledge about the topology. Sociologists conjecture that people find
routes greedily by passing the message to an acquaintance that has more in
common with the target than themselves, e.g. if a dentist in Saarbr\&quot;ucken
wants to send a message to a specific lawyer in Munich, he may forward it to
someone who is a lawyer and/or lives in Munich. Modelling this setting,
Eppstein et al. introduced the notion of category-based routing. The goal is to
assign a set of categories to each node of a graph such that greedy routing is
possible. By proving bounds on the number of categories a node has to be in we
can argue about the plausibility of the underlying sociological model. In this
paper we substantially improve the upper bounds introduced by Eppstein et al.
and prove new lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2296</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2296</id><created>2012-02-10</created><updated>2012-05-21</updated><authors><author><keyname>Bonet</keyname><forenames>Maria Luisa</forenames></author><author><keyname>Buss</keyname><forenames>Sam</forenames></author></authors><title>An Improved Separation of Regular Resolution from Pool Resolution and
  Clause Learning</title><categories>cs.LO math.LO</categories><msc-class>03F20, 03B35, 68T15, 68Q99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the graph tautology principles of Alekhnovich, Johannsen,
Pitassi and Urquhart have polynomial size pool resolution refutations that use
only input lemmas as learned clauses and without degenerate resolution
inferences. We also prove that these graph tautology principles can be refuted
by polynomial size DPLL proofs with clause learning, even when restricted to
greedy, unit-propagating DPLL search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2319</identifier>
 <datestamp>2012-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2319</id><created>2012-02-10</created><updated>2012-11-01</updated><authors><author><keyname>Zhang</keyname><forenames>Zhenliang</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author><author><keyname>Pezeshki</keyname><forenames>Ali</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Howard</keyname><forenames>Stephen D.</forenames></author></authors><title>Detection Performance of M-ary Relay Trees with Non-binary Message
  Alphabets</title><categories>cs.IT math.IT</categories><comments>Submitted to SSP workshop 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the detection performance of $M$-ary relay trees, where only the
leaves of the tree represent sensors making measurements. The root of the tree
represents the fusion center which makes an overall detection decision. Each of
the other nodes is a relay node which aggregates $M$ messages sent by its child
nodes into a new compressed message and sends the message to its parent node.
Building on previous work on the detection performance of $M$-ary relay trees
with binary messages, in this paper we study the case of non-binary relay
message alphabets. We characterize the exponent of the error probability with
respect to the message alphabet size $\mathcal D$, showing how the detection
performance increases with $\mathcal D$. Our method involves reducing a tree
with non-binary relay messages into an equivalent higher-degree tree with only
binary messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2335</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2335</id><created>2012-02-10</created><authors><author><keyname>Trushkowsky</keyname><forenames>Beth</forenames></author><author><keyname>Kraska</keyname><forenames>Tim</forenames></author><author><keyname>Franklin</keyname><forenames>Michael J.</forenames></author><author><keyname>Sarkar</keyname><forenames>Purnamrita</forenames></author></authors><title>Getting It All from the Crowd</title><categories>cs.DB</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid human/computer systems promise to greatly expand the usefulness of
query processing by incorporating the crowd for data gathering and other tasks.
Such systems raise many database system implementation questions. Perhaps most
fundamental is that the closed world assumption underlying relational query
semantics does not hold in such systems. As a consequence the meaning of even
simple queries can be called into question. Furthermore query progress
monitoring becomes difficult due to non-uniformities in the arrival of
crowdsourced data and peculiarities of how people work in crowdsourcing
systems. To address these issues, we develop statistical tools that enable
users and systems developers to reason about tradeoffs between time/cost and
completeness. These tools can also help drive query execution and crowdsourcing
strategies. We evaluate our techniques using experiments on a popular
crowdsourcing platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2336</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2336</id><created>2012-02-10</created><updated>2012-10-02</updated><authors><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Approximate Distance Oracles with Improved Query Time</title><categories>cs.DM</categories><comments>Minor additions and corrections. Added an extra figure. To appear at
  SODA 2013</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an undirected graph $G$ with $m$ edges, $n$ vertices, and non-negative
edge weights, and given an integer $k\geq 2$, we show that a
$(2k-1)$-approximate distance oracle for $G$ of size $O(kn^{1 + 1/k})$ and with
$O(\log k)$ query time can be constructed in $O(\min\{kmn^{1/k},\sqrt km +
kn^{1 + c/\sqrt k}\})$ time for some constant $c$. This improves the $O(k)$
query time of Thorup and Zwick. Furthermore, for any $0 &lt; \epsilon \leq 1$, we
give an oracle of size $O(kn^{1 + 1/k})$ that answers $((2 +
\epsilon)k)$-approximate distance queries in $O(1/\epsilon)$ time. At the cost
of a $k$-factor in size, this improves the $128k$ approximation achieved by the
constant query time oracle of Mendel and Naor and approaches the best possible
tradeoff between size and stretch, implied by a widely believed girth
conjecture of Erd\H{o}s. We can match the $O(n^{1 + 1/k})$ size bound of Mendel
and Naor for any constant $\epsilon &gt; 0$ and $k = O(\log n/\log\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2350</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2350</id><created>2012-02-10</created><authors><author><keyname>Masmoudi</keyname><forenames>Khaled</forenames></author><author><keyname>Antonini</keyname><forenames>Marc</forenames></author><author><keyname>Kornprobst</keyname><forenames>Pierre</forenames></author></authors><title>Streaming an image through the eye: The retina seen as a dithered
  scalable image coder</title><categories>cs.CV cs.NE</categories><comments>arXiv admin note: substantial text overlap with arXiv:1104.1550</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the design of an original scalable image coder/decoder that is
inspired from the mammalians retina. Our coder accounts for the time-dependent
and also nondeterministic behavior of the actual retina. The present work
brings two main contributions: As a first step, (i) we design a deterministic
image coder mimicking most of the retinal processing stages and then (ii) we
introduce a retinal noise in the coding process, that we model here as a dither
signal, to gain interesting perceptual features. Regarding our first
contribution, our main source of inspiration will be the biologically plausible
model of the retina called Virtual Retina. The main novelty of this coder is to
show that the time-dependent behavior of the retina cells could ensure, in an
implicit way, scalability and bit allocation. Regarding our second
contribution, we reconsider the inner layers of the retina. We emit a possible
interpretation for the non-determinism observed by neurophysiologists in their
output. For this sake, we model the retinal noise that occurs in these layers
by a dither signal. The dithering process that we propose adds several
interesting features to our image coder. The dither noise whitens the
reconstruction error and decorrelates it from the input stimuli. Furthermore,
integrating the dither noise in our coder allows a faster recognition of the
fine details of the image during the decoding process. Our present paper goal
is twofold. First, we aim at mimicking as closely as possible the retina for
the design of a novel image coder while keeping encouraging performances.
Second, we bring a new insight concerning the non-deterministic behavior of the
retina.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2368</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2368</id><created>2012-02-10</created><authors><author><keyname>Tang</keyname><forenames>Sarah</forenames></author><author><keyname>Godil</keyname><forenames>Afzal</forenames></author></authors><title>An evaluation of local shape descriptors for 3D shape retrieval</title><categories>cs.CV cs.CG cs.DL cs.IR cs.MM</categories><comments>IS&amp;T/SPIE Electronic Imaging 2012, Proceedings Vol. 8290
  Three-Dimensional Image Processing (3DIP) and Applications II, Atilla M.
  Baskurt; Robert Sitnik, Editors, 82900N Dates: Tuesday-Thursday 24 - 26
  January 2012, Paper 8290-22</comments><report-no>Paper 8290-22, Proceedings Vol. 8290</report-no><acm-class>I.2.10; I.4.8; I.5.4</acm-class><doi>10.1117/12.912153</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the usage of 3D models increases, so does the importance of developing
accurate 3D shape retrieval algorithms. A common approach is to calculate a
shape descriptor for each object, which can then be compared to determine two
objects' similarity. However, these descriptors are often evaluated
independently and on different datasets, making them difficult to compare.
Using the SHREC 2011 Shape Retrieval Contest of Non-rigid 3D Watertight Meshes
dataset, we systematically evaluate a collection of local shape descriptors. We
apply each descriptor to the bag-of-words paradigm and assess the effects of
varying the dictionary's size and the number of sample points. In addition,
several salient point detection methods are used to choose sample points; these
methods are compared to each other and to random selection. Finally,
information from two local descriptors is combined in two ways and changes in
performance are investigated. This paper presents results of these experiment
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2369</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2369</id><created>2012-02-10</created><authors><author><keyname>Byers</keyname><forenames>John W.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Zervas</keyname><forenames>Georgios</forenames></author></authors><title>The Groupon Effect on Yelp Ratings: A Root Cause Analysis</title><categories>cs.SI</categories><comments>Submitted to ACM EC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Daily deals sites such as Groupon offer deeply discounted goods and services
to tens of millions of customers through geographically targeted daily e-mail
marketing campaigns. In our prior work we observed that a negative side effect
for merchants using Groupons is that, on average, their Yelp ratings decline
significantly. However, this previous work was essentially observational,
rather than explanatory. In this work, we rigorously consider and evaluate
various hypotheses about underlying consumer and merchant behavior in order to
understand this phenomenon, which we dub the Groupon effect. We use statistical
analysis and mathematical modeling, leveraging a dataset we collected spanning
tens of thousands of daily deals and over 7 million Yelp reviews. In
particular, we investigate hypotheses such as whether Groupon subscribers are
more critical than their peers, or whether some fraction of Groupon merchants
provide significantly worse service to customers using Groupons. We suggest an
additional novel hypothesis: reviews from Groupon subscribers are lower on
average because such reviews correspond to real, unbiased customers, while the
body of reviews on Yelp contain some fraction of reviews from biased or even
potentially fake sources. Although we focus on a specific question, our work
provides broad insights into both consumer and merchant behavior within the
daily deals marketplace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2393</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2393</id><created>2012-02-10</created><authors><author><keyname>Hong</keyname><forenames>Dohy</forenames></author></authors><title>Statistical reliability and path diversity based PageRank algorithm
  improvements</title><categories>cs.IR cs.DM</categories><comments>8 pages</comments><acm-class>G.2.2; F.2.2; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present new improvement ideas of the original PageRank
algorithm. The first idea is to introduce an evaluation of the statistical
reliability of the ranking score of each node based on the local graph property
and the second one is to introduce the notion of the path diversity. The path
diversity can be exploited to dynamically modify the increment value of each
node in the random surfer model or to dynamically adapt the damping factor. We
illustrate the impact of such modifications through examples and simple
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2407</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2407</id><created>2012-02-10</created><authors><author><keyname>Chapman</keyname><forenames>James</forenames><affiliation>Institute of Cybernetics, Tallinn</affiliation></author><author><keyname>Levy</keyname><forenames>Paul Blain</forenames><affiliation>University of Birmingham</affiliation></author></authors><title>Proceedings Fourth Workshop on Mathematically Structured Functional
  Programming</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>D.3.3; F.3.3</acm-class><journal-ref>EPTCS 76, 2012</journal-ref><doi>10.4204/EPTCS.76</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Fourth Workshop on Mathematically
Structured Functional Programming (MSFP 2012), taking place on 25 March, 2012
in Tallinn, Estonia, as a satellite event of the European Joint Conferences on
Theory and Practice of Software, ETAPS 2012.
  MSFP is devoted to the derivation of functionality from structure. It
highlights concepts from algebra, semantics and type theory as they are
increasingly reflected in programming practice, especially functional
programming. The workshop consists of two invited presentations and eight
contributed papers on a range of topics at that interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2408</identifier>
 <datestamp>2013-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2408</id><created>2012-02-10</created><updated>2013-11-22</updated><authors><author><keyname>Shaghaghi</keyname><forenames>Mahdi</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Spectral Estimation from Undersampled Data: Correlogram and Model-Based
  Least Squares</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>This paper has been withdrawn by the author because a more detailed
  paper on one of the developments reported here has been submitted
  'Finite-Length and Asymptotic Analysis of Correlogram for Undersampled Data',
  arXiv:1305.5592</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies two spectrum estimation methods for the case that the
samples are obtained at a rate lower than the Nyquist rate. The first method is
the correlogram method for undersampled data. The algorithm partitions the
spectrum into a number of segments and estimates the average power within each
spectral segment. We derive the bias and the variance of the spectrum
estimator, and show that there is a tradeoff between the accuracy of the
estimation and the frequency resolution. The asymptotic behavior of the
estimator is also investigated, and it is proved that this spectrum estimator
is consistent.
  A new algorithm for reconstructing signals with sparse spectrum from noisy
compressive measurements is also introduced. Such model-based algorithm takes
the signal structure into account for estimating the unknown parameters which
are the frequencies and the amplitudes of linearly combined sinusoidal signals.
A high-resolution spectral estimation method is used to recover the frequencies
of the signal elements, while the amplitudes of the signal components are
estimated by minimizing the squared norm of the compressed estimation error
using the least squares technique. The Cramer-Rao bound for the given system
model is also derived. It is shown that the proposed algorithm approaches the
bound at high signal to noise ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2412</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2412</id><created>2012-02-10</created><authors><author><keyname>Khabbazibasmenj</keyname><forenames>Arash</forenames></author><author><keyname>Roemer</keyname><forenames>Florian</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Haardt</keyname><forenames>Martin</forenames></author></authors><title>Sum-Rate Maximization in Two-Way AF MIMO Relaying: Polynomial Time
  Solutions to a Class of DC Programming Problems</title><categories>cs.IT math.IT math.OC</categories><comments>35 pages, 10 figures, Submitted to the IEEE Trans. Signal Processing
  in Nov. 2011</comments><journal-ref>A. Khabbazibasmenj, F. Roemer, S.A. Vorobyov, and M. Haardt,
  &quot;Sum-rate maximization in two-way AF MIMO relaying:,&quot; IEEE Trans. Signal
  Processing, vol. 60, no. 10, pp. 5478-5493, 2012</journal-ref><doi>10.1109/TSP.2012.2208635</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sum-rate maximization in two-way amplify-and-forward (AF) multiple-input
multiple-output (MIMO) relaying belongs to the class of difference-of-convex
functions (DC) programming problems. DC programming problems occur as well in
other signal processing applications and are typically solved using different
modifications of the branch-and-bound method. This method, however, does not
have any polynomial time complexity guarantees. In this paper, we show that a
class of DC programming problems, to which the sum-rate maximization in two-way
MIMO relaying belongs, can be solved very efficiently in polynomial time, and
develop two algorithms. The objective function of the problem is represented as
a product of quadratic ratios and parameterized so that its convex part (versus
the concave part) contains only one (or two) optimization variables. One of the
algorithms is called POlynomial-Time DC (POTDC) and is based on semi-definite
programming (SDP) relaxation, linearization, and an iterative search over a
single parameter. The other algorithm is called RAte-maximization via
Generalized EigenvectorS (RAGES) and is based on the generalized eigenvectors
method and an iterative search over two (or one, in its approximate version)
optimization variables. We also derive an upper-bound for the optimal values of
the corresponding optimization problem and show by simulations that this
upper-bound can be achieved by both algorithms. The proposed methods for
maximizing the sum-rate in the two-way AF MIMO relaying system are shown to be
superior to other state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2414</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2414</id><created>2012-02-11</created><authors><author><keyname>Prakash</keyname><forenames>N.</forenames></author><author><keyname>Kamath</keyname><forenames>Govinda M.</forenames></author><author><keyname>Lalitha</keyname><forenames>V.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Optimal Linear Codes with a Local-Error-Correction Property</title><categories>cs.IT math.IT</categories><comments>13 pages, Shorter version submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications to distributed storage, Gopalan \textit{et al}
recently introduced the interesting notion of information-symbol locality in a
linear code. By this it is meant that each message symbol appears in a
parity-check equation associated with small Hamming weight, thereby enabling
recovery of the message symbol by examining a small number of other code
symbols. This notion is expanded to the case when all code symbols, not just
the message symbols, are covered by such &quot;local&quot; parity. In this paper, we
extend the results of Gopalan et. al. so as to permit recovery of an erased
code symbol even in the presence of errors in local parity symbols. We present
tight bounds on the minimum distance of such codes and exhibit codes that are
optimal with respect to the local error-correction property. As a corollary, we
obtain an upper bound on the minimum distance of a concatenated code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2419</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2419</id><created>2012-02-11</created><authors><author><keyname>Rhif</keyname><forenames>Ahmed</forenames></author></authors><title>A High Order Sliding Mode Control with PID Sliding Surface: Simulation
  on a Torpedo</title><categories>cs.SY</categories><comments>13 pages, 17 figures</comments><doi>10.5121/ijitca.2012.2101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Position and speed control of the torpedo present a real problem for the
actuators because of the high level of the system non linearity and because of
the external disturbances. The non linear systems control is based on several
different approaches, among it the sliding mode control. The sliding mode
control has proved its effectiveness through the different studies. The
advantage that makes such an important approach is its robustness versus the
disturbances and the model uncertainties. However, this approach implies a
disadvantage which is the chattering phenomenon caused by the discontinuous
part of this control and which can have a harmful effect on the actuators. This
paper deals with the basic concepts, mathematics, and design aspects of a
control for nonlinear systems that make the chattering effect lower. As
solution to this problem we will adopt as a starting point the high order
sliding mode approaches then the PID sliding surface. Simulation results show
that this control strategy can attain excellent control performance with no
chattering problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2420</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2420</id><created>2012-02-11</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Shaabi</keyname><forenames>Maha</forenames></author></authors><title>Cyber threats in social networking websites</title><categories>cs.CR cs.CY</categories><comments>8 pages; International Journal of Distributed and Parallel Systems
  (IJDPS) Vol.3, No.1, January 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A social network is a social structure made up of individuals or
organizations called nodes, which are connected by one or more specific types
of interdependency, such as friendship, common interest, and exchange of
finance, relationships of beliefs, knowledge or prestige. A cyber threat can be
both unintentional and intentional, targeted or non targeted, and it can come
from a variety of sources, including foreign nations engaged in espionage and
information warfare, criminals, hackers, virus writers, disgruntled employees
and contractors working within an organization. Social networking sites are not
only to communicate or interact with other people globally, but also one
effective way for business promotion. In this paper, we investigate and study
the cyber threats in social networking websites. We go through the amassing
history of online social websites, classify their types and also discuss the
cyber threats, suggest the anti-threats strategies and visualize the future
trends of such hoppy popular websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2425</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2425</id><created>2012-02-11</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Hayat</keyname><forenames>Shaukat Ali</forenames></author></authors><title>The artifacts of component-based development</title><categories>cs.SE</categories><comments>6 pages; ISSN: 1013-5316; CODEN: SINTE 8; Quarterly Publications Int,
  11-D Sabzazar, Wahdat Rd, Lahore, Pakistan</comments><journal-ref>Science International-Lahore, Vol. 19/3, 2007, pp. 187-192</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component based development idea was floated in a conference name &quot;Mass
Produced Software Components&quot; in 1968 [1]. Since then engineering and
scientific libraries are developed to reuse the previously developed functions.
This concept is now widely used in SW development as component based
development (CBD). Component-based software engineering (CBSE) is used to
develop/ assemble software from existing components [2]. Software developed
using components is called component ware [3]. This paper presents different
architectures of CBD such as ActiveX, common object request broker architecture
(CORBA), remote method invocation (RMI) and simple object access protocol
(SOAP). The overall objective of this paper is to support the practice of CBD
by comparing its advantages and disadvantages. This paper also evaluates object
oriented process model to adapt it for CBD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2427</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2427</id><created>2012-02-11</created><authors><author><keyname>Bassil</keyname><forenames>Youssef</forenames></author><author><keyname>Alwani</keyname><forenames>Mohammad</forenames></author></authors><title>Autonomic html interface generator for web applications</title><categories>cs.SE</categories><comments>LACSC - Lebanese Association for Computational Sciences
  (www.lacsc.org)</comments><journal-ref>International Journal of Web &amp; Semantic Technology (IJWesT), Vol.
  3, No. 1, January 2012, pg. 33-47</journal-ref><doi>10.5121/ijwest.2012.3104</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent advances in computing systems have led to a new digital era in which
every area of life is nearly interrelated with information technology. However,
with the trend towards large-scale IT systems, a new challenge has emerged. The
complexity of IT systems is becoming an obstacle that hampers the
manageability, operability, and maintainability of modern computing
infrastructures. Autonomic computing popped up to provide an answer to these
ever-growing pitfalls. Fundamentally, autonomic systems are self-configuring,
self-healing, self-optimizing, and self-protecting; hence, they can automate
all complex IT processes without human intervention. This paper proposes an
autonomic HTML web-interface generator based on XML Schema and Style Sheet
specifications for self-configuring graphical user interfaces of web
applications. The goal of this autonomic generator is to automate the process
of customizing GUI web-interfaces according to the ever-changing business
rules, policies, and operating environment with the least IT labor involvement.
The conducted experiments showed a successful automation of web interfaces
customization that dynamically self-adapts to keep with the always-changing
business requirements. Future research can improve upon the proposed solution
so that it supports the selfconfiguring of not only web applications but also
desktop applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2429</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2429</id><created>2012-02-11</created><authors><author><keyname>Bassil</keyname><forenames>Youssef</forenames></author></authors><title>Building sustainable ecosystem-oriented architectures</title><categories>cs.SE</categories><comments>LACSC - Lebanese Association for Computational Sciences</comments><journal-ref>International Journal in Foundations of Computer Science &amp;
  Technology,Vol. 2, No.1, January 2012, pg. 1-13</journal-ref><doi>10.5121/ijfcst.2012.2101</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Currently, organizations are transforming their business processes into
e-services and service-oriented architectures to improve coordination across
sales, marketing, and partner channels, to build flexible and scalable systems,
and to reduce integration-related maintenance and development costs. However,
this new paradigm is still fragile and lacks many features crucial for building
sustainable and progressive computing infrastructures able to rapidly respond
and adapt to the always-changing market and environmental business. This paper
proposes a novel framework for building sustainable Ecosystem- Oriented
Architectures (EOA) using e-service models. The backbone of this framework is
an ecosystem layer comprising several computing units whose aim is to deliver
universal interoperability, transparent communication, automated management,
self-integration, self-adaptation, and security to all the interconnected
services, components, and devices in the ecosystem. Overall, the proposed model
seeks to deliver a comprehensive and a generic sustainable business IT model
for developing agile e-enterprises that are constantly up to new business
constraints, trends, and requirements. Future research can improve upon the
proposed model so much so that it supports computational intelligence to help
in decision making and problem solving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2439</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2439</id><created>2012-02-11</created><updated>2012-07-05</updated><authors><author><keyname>Leckey</keyname><forenames>Kevin</forenames></author><author><keyname>Neininger</keyname><forenames>Ralph</forenames></author></authors><title>Asymptotic analysis of Hoppe trees</title><categories>math.PR cs.DM</categories><msc-class>60F05, 60C05 (Primary) 60G42, 68R05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and analyze a random tree model associated to Hoppe's urn. The
tree is built successively by adding nodes to the existing tree when starting
with the single root node. In each step a node is added to the tree as a child
of an existing node where these parent nodes are chosen randomly with
probabilities proportional to their weights. The root node has weight
$\vartheta&gt;0$, a given fixed parameter, all other nodes have weight 1. This
resembles the stochastic dynamic of Hoppe's urn. For $\vartheta=1$ the
resulting tree is the well-studied random recursive tree. We analyze the
height, internal path length and number of leaves of the Hoppe tree with $n$
nodes as well as the depth of the last inserted node asymptotically as $n\to
\infty$. Mainly expectations, variances and asymptotic distributions of these
parameters are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2449</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2449</id><created>2012-02-11</created><authors><author><keyname>Abdelwahab</keyname><forenames>Moataz M.</forenames></author><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Yousry</keyname><forenames>Islam</forenames></author></authors><title>Efficient Web-based Facial Recognition System Employing 2DHOG</title><categories>cs.CV cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a system for facial recognition to identify missing and found
people in Hajj and Umrah is described as a web portal. Explicitly, we present a
novel algorithm for recognition and classifications of facial images based on
applying 2DPCA to a 2D representation of the Histogram of oriented gradients
(2D-HOG) which maintains the spatial relation between pixels of the input
images. This algorithm allows a compact representation of the images which
reduces the computational complexity and the storage requirments, while
maintaining the highest reported recognition accuracy. This promotes this
method for usage with very large datasets. Large dataset was collected for
people in Hajj. Experimental results employing ORL, UMIST, JAFFE, and HAJJ
datasets confirm these excellent properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2461</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2461</id><created>2012-02-11</created><updated>2012-09-17</updated><authors><author><keyname>Shuai</keyname><forenames>Xin</forenames></author><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>How the Scientific Community Reacts to Newly Submitted Preprints:
  Article Downloads, Twitter Mentions, and Citations</title><categories>cs.SI cs.DL physics.soc-ph</categories><comments>15 pages, 7 Figures, 3 Tables. PLoS One, in press</comments><doi>10.1371/journal.pone.0047523</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the online response to the preprint publication of a cohort of
4,606 scientific articles submitted to the preprint database arXiv.org between
October 2010 and May 2011. We study three forms of responses to these
preprints: downloads on the arXiv.org site, mentions on the social media site
Twitter, and early citations in the scholarly record. We perform two analyses.
First, we analyze the delay and time span of article downloads and Twitter
mentions following submission, to understand the temporal configuration of
these reactions and whether one precedes or follows the other. Second, we run
regression and correlation tests to investigate the relationship between
Twitter mentions, arXiv downloads and article citations. We find that Twitter
mentions and arXiv downloads of scholarly articles follow two distinct temporal
patterns of activity, with Twitter mentions having shorter delays and narrower
time spans than arXiv downloads. We also find that the volume of Twitter
mentions is statistically correlated with arXiv downloads and early citations
just months after the publication of a preprint, with a possible bias that
favors highly mentioned articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2465</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2465</id><created>2012-02-11</created><authors><author><keyname>Xie</keyname><forenames>Jierui</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author></authors><title>Towards Linear Time Overlapping Community Detection in Social Networks</title><categories>cs.SI cs.CY cs.DS physics.soc-ph</categories><comments>PAKDD 2012</comments><journal-ref>Proc. 16th PAKDD Pacific-Asia Conference on Knowledge Discovery
  and Data Mining, Kuala Lumpur, Malaysia, 2012, Lecture Notes AI vol. 7302,
  Part II, Springer, Berlin, Germany, 2012, pp. 25-36</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Membership diversity is a characteristic aspect of social networks in which a
person may belong to more than one social group. For this reason, discovering
overlapping structures is necessary for realistic social analysis. In this
paper, we present a fast algorithm1, called SLPA, for overlapping community
detection in large-scale networks. SLPA spreads labels according to dynamic
interaction rules. It can be applied to both unipartite and bipartite networks.
It is also able to uncover overlapping nested hierarchy. The time complexity of
SLPA scales linearly with the number of edges in the network. Experiments in
both synthetic and real- world networks show that SLPA has an excellent
performance in identifying both node and community level overlapping
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2466</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2466</id><created>2012-02-11</created><updated>2012-06-06</updated><authors><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>Self-healing systems and virtual structures</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern networks are large, highly complex and dynamic. Add to that the
mobility of the agents comprising many of these networks. It is difficult or
even impossible for such systems to be managed centrally in an efficient
manner. It is imperative for such systems to attain a degree of
self-management. Self-healing i.e. the capability of a system in a good state
to recover to another good state in face of an attack, is desirable for such
systems. In this paper, we discuss the self-healing model for dynamic
reconfigurable systems. In this model, an omniscient adversary inserts or
deletes nodes from a network and the algorithm responds by adding a limited
number of edges in order to maintain invariants of the network. We look at some
of the results in this model and argue for their applicability and further
extensions of the results and the model. We also look at some of the techniques
we have used in our earlier work, in particular, we look at the idea of
maintaining virtual graphs mapped over the existing network and assert that
this may be a useful technique to use in many problem domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2468</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2468</id><created>2012-02-11</created><updated>2013-10-03</updated><authors><author><keyname>Kirkpatrick</keyname><forenames>Bonnie</forenames></author><author><keyname>Kirkpatrick</keyname><forenames>Kay</forenames></author></authors><title>Optimal State-Space Reduction for Pedigree Hidden Markov Models</title><categories>math.PR cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To analyze whole-genome genetic data inherited in families, the likelihood is
typically obtained from a Hidden Markov Model (HMM) having a state space of 2^n
hidden states where n is the number of meioses or edges in the pedigree. There
have been several attempts to speed up this calculation by reducing the
state-space of the HMM. One of these methods has been automated in a
calculation that is more efficient than the naive HMM calculation; however,
that method treats a special case and the efficiency gain is available for only
those rare pedigrees containing long chains of single-child lineages. The other
existing state-space reduction method treats the general case, but the existing
algorithm has super-exponential running time.
  We present three formulations of the state-space reduction problem, two
dealing with groups and one with partitions. One of these problems, the maximum
isometry group problem was discussed in detail by Browning and Browning. We
show that for pedigrees, all three of these problems have identical solutions.
Furthermore, we are able to prove the uniqueness of the solution using the
algorithm that we introduce. This algorithm leverages the insight provided by
the equivalence between the partition and group formulations of the problem to
quickly find the optimal state-space reduction for general pedigrees.
  We propose a new likelihood calculation which is a two-stage process: find
the optimal state-space, then run the HMM forward-backward algorithm on the
optimal state-space. In comparison with the one-stage HMM calculation, this new
method more quickly calculates the exact pedigree likelihood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2486</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2486</id><created>2012-02-11</created><authors><author><keyname>Glew</keyname><forenames>Neal</forenames></author></authors><title>Subtyping for F-Bounded Quantifiers and Equirecursive Types (Extended
  Version)</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper defines a notion of binding trees that provide a suitable model
for second-order type systems with F-bounded quantifiers and equirecursive
types. It defines a notion of regular binding trees that correspond in the
right way to notions of regularity in the first-order case. It defines a notion
of subtyping on these trees and proves various properties of the subtyping
relation. It defines a mapping from types to trees and shows that types produce
regular binding trees. It presents a set of type equality and subtyping rules,
and proves them sound and complete with respect to the tree interpretation. It
defines a notion of binding-tree automata and how these generate regular
binding trees. It gives a polynomial-time algorithm for deciding when two
automata's trees are in the subtyping relation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2498</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2498</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>Rizwan Jameel</forenames></author><author><keyname>Sandhu</keyname><forenames>M. E.</forenames></author></authors><title>Survey-Based Analysis of the Proposed Component-Based Development
  Process</title><categories>cs.SE</categories><comments>5 Pages; ISSN: 1013-5316, CODEN: SINTE 8</comments><journal-ref>Science International-Lahore, Vol. 20/3, September 2008, pp.
  169-173</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of component-based development (CBD) is widely practiced in
software (SW) development. CBD is based on reuse of the existing components
with the new ones. The objective of this paper is to propose a novel process
model for CBD. Importance of repository has also been discussed. A survey has
been conducted to evaluate the proposed model. The results of the survey show
that proposed process model can be efficiently implemented for CBD projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2499</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2499</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author></authors><title>Evaluation of the Improved XP Software Development Model</title><categories>cs.SE</categories><comments>4 pages; ISSN: 1013-5316, CODEN: SINTE 8</comments><journal-ref>Science International-Lahore, Vol. 20/2, June 2008, pp. 79-82</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of agile process models has attained great popularity in software
(SW) development community in last few years. Agile models promote fast
development. Fast development has certain drawbacks, such as weak documentation
and performance for medium and large development projects. Fast development
also promotes use of agile process models in small-scale projects. This paper
modifies and evaluates Extreme Programming (XP) process model and proposes a
novel process model based on these modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2501</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2501</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Hussain</keyname><forenames>S. A.</forenames></author></authors><title>An Improved XP Software Development Model</title><categories>cs.SE</categories><comments>3 Pages; ISSN: 1013-5316, CODEN: SINTE 8</comments><journal-ref>Science International-Lahore, Vol. 20/1, March 2008, pp. 5-7</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of agile process models has attained great popularity in software
(SW) development community in last few years. Agile models promote fast
development. Fast development has certain drawbacks, such as weak documentation
and performance for medium and large development projects. Fast development
also promotes use of agile process models in small-scale projects. This paper
modifies and evaluates Extreme Programming (XP) process model and proposes a
novel process model based on these modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2503</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2503</id><created>2012-02-12</created><authors><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Paturi</keyname><forenames>Ramamohan</forenames></author><author><keyname>Ricketts</keyname><forenames>Daniel</forenames></author></authors><title>Experimental study of the impact of historical information in human
  coordination</title><categories>cs.SI physics.soc-ph</categories><comments>Presented at the Workshop of Information in Networks (WIN), New York,
  USA, September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform laboratory experiments to elucidate the role of historical
information in games involving human coordination. Our approach follows prior
work studying human network coordination using the task of graph coloring. We
first motivate this research by showing empirical evidence that the resolution
of coloring conflicts is dependent upon the recent local history of that
conflict. We also conduct two tailored experiments to manipulate the game
history that can be used by humans in order to determine (i) whether humans use
historical information, and (ii) whether they use it effectively. In the first
variant, during the course of each coloring task, the network positions of the
subjects were periodically swapped while maintaining the global coloring state
of the network. In the second variant, participants completed a series of
2-coloring tasks, some of which were restarts from checkpoints of previous
tasks. Thus, the participants restarted the coloring task from a point in the
middle of a previous task without knowledge of the history that led to that
point. We report on the game dynamics and average completion times for the
diverse graph topologies used in the swap and restart experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2504</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2504</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>M. R. J.</forenames></author><author><keyname>Kashif</keyname><forenames>Muhammad</forenames></author></authors><title>Seamless Long Term Learning in Agile Teams for Sustainable Leadership</title><categories>cs.SE</categories><comments>6 Pages; 5th IEEE International Conference on Emerging Technologies,
  17-18 October 2009 (ICET 2009), FAST Islamabad Pakistan</comments><doi>10.1109/ICET.2009.5353140</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seamless and continuous support for long term organizational learning needs
is essential for long lasting progress of the organization. Agile process model
provides an excellent opportunity to cater that specific problem and also helps
in motivation, satisfaction, coordination, presentation and technical skills
enhancement of agile teams. This long term learning process makes organization
to sustain their current successes and lead both organization and team members
to successful and dynamic market leaders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2506</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2506</id><created>2012-02-12</created><authors><author><keyname>Iqbal</keyname><forenames>Nayyar</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author></authors><title>Improvement of Key Problems of Software Testing in Quality Assurance</title><categories>cs.SE</categories><comments>4 Pages; ISSN: 1013-5316, CODEN: SINTE 8</comments><journal-ref>Science International-Lahore, Vol. 21/1, March 2009, pp. 25-28</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality assurance makes sure the project will be completed based on the
previously approved specifications, standards and functionality. It is required
without defects and possible problems. It monitors and tries to progress the
development process from the start of the project. Software Quality Assurance
(SQA) is the combination of the entire software development process, which
includes software design, coding, source code control, code review, change
management, configuration management and release management. In this paper we
describe the solution for the key problems of software testing in quality
assurance. The existing software practices have some problems such as testing
practices, attitude of users and culture of organizations. All these tree
problems have some combined problems such as shortcuts in testing, reduction in
testing time, poor documentation etc. In this paper we are recommending
strategies to provide solution of the said problems mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2508</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2508</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Sandhu</keyname><forenames>M. E.</forenames></author></authors><title>A Validation of the Proposed Component-Based Development Process</title><categories>cs.SE</categories><comments>5 Pages; ISSN: 1013-5316, CODEN: SINTE 8</comments><journal-ref>Science International-Lahore, Vol. 21/2, June 2009, pp. 131-135</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component-based development (CBD) is a name, with which software development
professionals are quite familiar. There are several models which have been
proposed for CBD in last few years. They contain good features but there are
some improvement possibilities in them. The objective of this paper is to
propose a process for CBD and to evaluate the effects of quality parameters on
reusability. The validations of the proposed CBD model provide positive
indication for software (SW) industry that it can be successfully implemented
for CBD projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2509</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2509</id><created>2012-02-12</created><authors><author><keyname>Calcavecchia</keyname><forenames>Nicolo M.</forenames></author><author><keyname>Caprarescu</keyname><forenames>Bogdan Alexandru</forenames></author><author><keyname>Di Nitto</keyname><forenames>Elisabetta</forenames></author><author><keyname>Dubois</keyname><forenames>Daniel J.</forenames></author><author><keyname>Petcu</keyname><forenames>Dana</forenames></author></authors><title>DEPAS: A Decentralized Probabilistic Algorithm for Auto-Scaling</title><categories>cs.DC</categories><comments>Submitted to Springer Computing</comments><report-no>Technical Report 2012.5, Politecnico di Milano</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic provisioning of virtualized resources offered by cloud computing
infrastructures allows applications deployed in a cloud environment to
automatically increase and decrease the amount of used resources. This
capability is called auto-scaling and its main purpose is to automatically
adjust the scale of the system that is running the application to satisfy the
varying workload with minimum resource utilization. The need for auto-scaling
is particularly important during workload peaks, in which applications may need
to scale up to extremely large-scale systems.
  Both the research community and the main cloud providers have already
developed auto-scaling solutions. However, most research solutions are
centralized and not suitable for managing large-scale systems, moreover cloud
providers' solutions are bound to the limitations of a specific provider in
terms of resource prices, availability, reliability, and connectivity.
  In this paper we propose DEPAS, a decentralized probabilistic auto-scaling
algorithm integrated into a P2P architecture that is cloud provider
independent, thus allowing the auto-scaling of services over multiple cloud
infrastructures at the same time. Our simulations, which are based on real
service traces, show that our approach is capable of: (i) keeping the overall
utilization of all the instantiated cloud resources in a target range, (ii)
maintaining service response times close to the ones obtained using optimal
centralized auto-scaling approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2510</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2510</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Asim</keyname><forenames>Muhammad Rafiq</forenames></author><author><keyname>Nadeem</keyname><forenames>Muhammad</forenames></author><author><keyname>Mehmood</keyname><forenames>Asif</forenames></author></authors><title>A New Teaching Model For The Subject Of Software Project Management</title><categories>cs.SE</categories><comments>9 Pages; ISSN: 1013-5316, CODEN: SINTE 8</comments><journal-ref>Science International-Lahore, Vol. 22/1, March 2010, pp. 295-303</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software (SW) development is a very tough task which requires a skilled
project leader for its success. If the project leader is not skilled enough
then project may fail. In the real world of SW engineering 65% of the SW
projects fail to meet their objectives as in [1]. The main reason is lack of
training of the project mangers. This extreme ratio of failure can be reduced
by teaching SW project management (SPM) to the future project managers in the
practical manner, so that they may be skillful enough to handle the project in
a better way. This paper intends to propose a model to be used to teach SPM to
the student of SW engineering to reduce the failure rate of projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2511</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2511</id><created>2012-02-12</created><authors><author><keyname>Ahmed</keyname><forenames>Nadeem</forenames></author><author><keyname>Asim</keyname><forenames>M. Rafiq</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author></authors><title>A Step Forward To Component-based Software Cost Estimation in
  Object-oriented Environment</title><categories>cs.SE</categories><comments>ISSN: 0030-9877</comments><journal-ref>Pakistan Journal of Science, Vol. 62/4, December 2010, pp. 250-257</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software cost estimation (SCE) of a project is pivotal to the acceptance or
rejection of the development of software project. Various SCE techniques have
been in practice with their own strengths and limitations. The latest of these
is object-oriented one. Currently object-oriented approach for SCE is based on
Line of Code (LOC), function points, functions and classes etc. Relatively less
attention has been paid to the SCE in component-based software engineering
(CBSE). So there is a pressing need to search parameters/variables that have a
vital role for the SCE using CBSE which is taken up in this paper. This paper
further looks at level of significance of all the parameters/variables thus
searched. The time is being used as an independent variable because time is a
parameter which is almost, all previous in one. Therefore this approach may be
in a way an alternate of all previous approaches. Infact the underlying
research ultimately may lead towards SCE of complex systems, using CBSE, in a
scientific, systematic and comprehensive way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2513</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2513</id><created>2012-02-12</created><authors><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author></authors><title>Empirical Evaluation of the Proposed eXScrum Model: Results of a Case
  Study</title><categories>cs.SE</categories><comments>8 Pages; ISSN: 1694-0814</comments><journal-ref>International Journal of Computer Science and Issues, Vol. 8/3,
  May 2011, pp. 150-157</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agile models promote fast development. XP and Scrum are the most widely used
agile models. This paper investigates the phases of XP and Scrum models in
order to identify their potentials and drawbacks. XP model has certain
drawbacks, such as not suitable for maintenance projects and poor performance
for medium and large-scale development projects. Scrum model has certain
limitations, such as lacked in engineering practices. Since, both XP and Scrum
models contain good features and strengths but still there are improvement
possibilities in these models. Majority of the software development companies
are reluctant to switch from traditional methodologies to agile methodologies
for development of industrial projects. A fine integration, of software
management of the Scrum model and engineering practices of XP model, is very
much required to accumulate the strengths and remove the limitations of both
models. This is achieved by proposing an eXScrum model. The proposed model is
validated by conducting a controlled case study. The results of case study show
that the proposed integrated eXScrum model enriches the potentials of both XP
and Scrum models and eliminates their drawbacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2514</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2514</id><created>2012-02-12</created><authors><author><keyname>Khan</keyname><forenames>Asif Irshad</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Khan</keyname><forenames>Usman Ali</forenames></author></authors><title>A Comprehensive Study of Commonly Practiced Heavy &amp; Light Weight
  Software Methodologies</title><categories>cs.SE</categories><comments>10 Pages; ISSN: 1694-0814</comments><journal-ref>International Journal of Computer Science and Issues, Vol. 8/4,
  June 2011, pp. 441-450</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software has been playing a key role in the development of modern society.
Software industry has an option to choose suitable methodology/process model
for its current needs to provide solutions to give problems. Though some
companies have their own customized methodology for developing their software
but majority agrees that software methodologies fall under two categories that
are heavyweight and lightweight. Heavyweight methodologies (Waterfall Model,
Spiral Model) are also known as the traditional methodologies, and their
focuses are detailed documentation, inclusive planning, and extroverted design.
Lightweight methodologies (XP, SCRUM) are, referred as agile methodologies.
Light weight methodologies focused mainly on short iterative cycles, and rely
on the knowledge within a team. The aim of this paper is to describe the
characteristics of popular heavyweight and lightweight methodologies that are
widely practiced in software industries. We have discussed the strengths and
weakness of the selected models. Further we have discussed the strengths and
weakness between the two opponent methodologies and some criteria is also
illustrated that help project managers for the selection of suitable model for
their projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2515</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2515</id><created>2012-02-12</created><authors><author><keyname>Barnawi</keyname><forenames>Ahmed</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Khan</keyname><forenames>Asif Irshad</forenames></author></authors><title>A Framework for Next Generation Mobile and Wireless Networks Application
  Development using Hybrid Component Based Development Model</title><categories>cs.SE</categories><comments>8 Pages; ISSN: 2046-6897</comments><journal-ref>International Journal of Research and Reviews in Next Generation
  Networks (IJRRNGN), UK, Vol. 2/1, 2011, pp. 51-58</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The IP Multimedia Subsystems (IMS) that features in Next Generation Networks
(NGN) offers the application developer (third party) abilities to map out
applications over mobile telecommunication infrastructure. The IMS comes about
with APIs useful for mobile application developers to create applications to
meet end-users' demands and comply with the provider's infrastructure set up at
the same time. Session Initiation Protocol (SIP) is a signaling protocol for
this architecture. It is used for establishing sessions in IP network, making
it an ideal candidate for supporting terminal mobility in to deliver the
services with improved Quality of Services (QOS). The realization of IMS's
virtues as far as software design is concerned is faced by lack of
standardizations and methodologies throughout application development process.
In this paper, we report on progress on ongoing research by our group toward
putting together a platform as a testbed used for NGN application development.
We examine a novel component based development model used for SIP based mobile
applications. The developed model is to be used as framework for general
purpose application development over the testbed. We apply this model on MObile
Mass EXamination (MOMEX) system that is an application attracting the interest
of educational authorities around the world due to its potential convenience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2516</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2516</id><created>2012-02-12</created><authors><author><keyname>Barnawi</keyname><forenames>Ahmed</forenames></author><author><keyname>Al-Talhi</keyname><forenames>Abdurrahman H.</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Khan</keyname><forenames>Asif Irshad</forenames></author></authors><title>Novel Component Based Development Model For Sip-Based Mobile Application</title><categories>cs.SE</categories><comments>15 Pages; ISSN: 0975-9018</comments><journal-ref>International Journal of Software Engineering and Applications,
  India, Vol: 3/1, January 2012, pp. 85-99</journal-ref><doi>10.5121/ijsea.2012.3107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universities and Institutions these days' deals with issues related to with
assessment of large number of students. Various evaluation methods have been
adopted by examiners in different institutions to examining the ability of an
individual, starting from manual means of using paper and pencil to electronic,
from oral to written, practical to theoretical and many others. There is a need
to expedite the process of examination in order to meet the increasing
enrolment of students at the universities and institutes. Sip Based Mass Mobile
Examination System (SiBMMES) expedites the examination process by automating
various activities in an examination such as exam paper setting, Scheduling and
allocating examination time and evaluation (auto-grading for objective
questions) etc. SiBMMES uses the IP Multimedia Subsystem (IMS) that is an IP
communications framework providing an environment for the rapid development of
innovative and reusable services Session Initial Protocol (SIP) is a signalling
(request-response) protocol for this architecture and it is used for
establishing sessions in an IP network, making it an ideal candidate for
supporting terminal mobility in the IMS to deliver the services, with the
extended services available in IMS like open APIs, common network services,
Quality of Services (QoS) like multiple sessions per call, Push to Talk etc
often requiring multiple types of media (including voice, video, pictures, and
text). SiBMMES is an effective solution for mass education evaluation using
mobile and web technology. In this paper, a novel hybrid component based
development (CBD) model is proposed for SiBMMES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2518</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2518</id><created>2012-02-12</created><updated>2013-06-22</updated><authors><author><keyname>Liang</keyname><forenames>Wang</forenames></author></authors><title>Segmenting DNA sequence into `words'</title><categories>q-bio.GN cs.CL</categories><comments>12 pages,2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel method to segment/decode DNA sequences based on
n-grams statistical language model. Firstly, we find the length of most DNA
'words' is 12 to 15 bps by analyzing the genomes of 12 model species. Then we
design an unsupervised probability based approach to segment the DNA sequences.
The benchmark of segmenting method is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2523</identifier>
 <datestamp>2012-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2523</id><created>2012-02-12</created><updated>2012-04-10</updated><authors><author><keyname>Guti&#xe9;rrez</keyname><forenames>Jos&#xe9; A. Garc&#xed;a</forenames></author><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>Fern&#xe1;ndez-Leiva</keyname><forenames>Antonio J.</forenames></author></authors><title>Evolutionary Computation in Astronomy and Astrophysics: A Review</title><categories>cs.AI astro-ph.IM cs.NE</categories><comments>* PRE-PRINT *</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general Evolutionary Computation (EC) includes a number of optimization
methods inspired by biological mechanisms of evolution. The methods catalogued
in this area use the Darwinian principles of life evolution to produce
algorithms that returns high quality solutions to hard-to-solve optimization
problems. The main strength of EC is precisely that they provide good solutions
even if the computational resources (e.g., running time) are limited. Astronomy
and Astrophysics are two fields that often require optimizing problems of high
complexity or analyzing a huge amount of data and the so-called complete
optimization methods are inherently limited by the size of the problem/data.
For instance, reliable analysis of large amounts of data is central to modern
astrophysics and astronomical sciences in general. EC techniques perform well
where other optimization methods are inherently limited (as complete methods
applied to NP-hard problems), and in the last ten years, numerous proposals
have come up that apply with greater or lesser success methodologies of
evolutional computation to common engineering problems. Some of these problems,
such as the estimation of non-lineal parameters, the development of automatic
learning techniques, the implementation of control systems, or the resolution
of multi-objective optimization problems, have had (and have) a special
repercussion in the fields. For these reasons EC emerges as a feasible
alternative for traditional methods. In this paper, we discuss some promising
applications in this direction and a number of recent works in this area; the
paper also includes a general description of EC to provide a global perspective
to the reader and gives some guidelines of application of EC techniques for
future research
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2525</identifier>
 <datestamp>2012-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2525</id><created>2012-02-12</created><updated>2012-11-20</updated><authors><author><keyname>Javanmard</keyname><forenames>Adel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Subsampling at Information Theoretically Optimal Rates</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>5 pages, 4 figures, minor corrections</comments><journal-ref>Proc. of IEEE Intl. Symp. on Information Theory (2012), pages
  2431-2435</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of sampling a random signal with sparse support in
frequency domain. Shannon famously considered a scheme that instantaneously
samples the signal at equispaced times. He proved that the signal can be
reconstructed as long as the sampling rate exceeds twice the bandwidth (Nyquist
rate). Cand\`es, Romberg, Tao introduced a scheme that acquires instantaneous
samples of the signal at random times. They proved that the signal can be
uniquely and efficiently reconstructed, provided the sampling rate exceeds the
frequency support of the signal, times logarithmic factors.
  In this paper we consider a probabilistic model for the signal, and a
sampling scheme inspired by the idea of spatial coupling in coding theory.
Namely, we propose to acquire non-instantaneous samples at random times.
Mathematically, this is implemented by acquiring a small random subset of Gabor
coefficients. We show empirically that this scheme achieves correct
reconstruction as soon as the sampling rate exceeds the frequency support of
the signal, thus reaching the information theoretic limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2528</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2528</id><created>2012-02-12</created><authors><author><keyname>Mader</keyname><forenames>Kevin</forenames></author><author><keyname>Reese</keyname><forenames>Gil</forenames></author></authors><title>Using Covariance Matrices as Feature Descriptors for Vehicle Detection
  from a Fixed Camera</title><categories>cs.CV</categories><comments>Written as part of the requirements for the SC/EC520 course in
  Digital Image Processing at Boston University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is developed to distinguish between cars and trucks present in a
video feed of a highway. The method builds upon previously done work using
covariance matrices as an accurate descriptor for regions. Background
subtraction and other similar proven image processing techniques are used to
identify the regions where the vehicles are most likely to be, and a distance
metric comparing the vehicle inside the region to a fixed library of vehicles
is used to determine the class of vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2536</identifier>
 <datestamp>2012-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2536</id><created>2012-02-12</created><authors><author><keyname>Zhang</keyname><forenames>Pan</forenames></author><author><keyname>Ramezanpour</keyname><forenames>Abolfazl</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author><author><keyname>Zecchina</keyname><forenames>Riccardo</forenames></author></authors><title>Message passing for quantified Boolean formulas</title><categories>cs.AI cond-mat.dis-nn</categories><comments>14 pages, 7 figures</comments><journal-ref>J. Stat. Mech. (2012) P05025</journal-ref><doi>10.1088/1742-5468/2012/05/P05025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two types of message passing algorithms for quantified Boolean
formulas (QBF). The first type is a message passing based heuristics that can
prove unsatisfiability of the QBF by assigning the universal variables in such
a way that the remaining formula is unsatisfiable. In the second type, we use
message passing to guide branching heuristics of a Davis-Putnam
Logemann-Loveland (DPLL) complete solver. Numerical experiments show that on
random QBFs our branching heuristics gives robust exponential efficiency gain
with respect to the state-of-art solvers. We also manage to solve some
previously unsolved benchmarks from the QBFLIB library. Apart from this our
study sheds light on using message passing in small systems and as subroutines
in complete solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2551</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2551</id><created>2012-02-12</created><authors><author><keyname>Dobre</keyname><forenames>Ciprian</forenames></author><author><keyname>Pop</keyname><forenames>Florin</forenames></author><author><keyname>Cristea</keyname><forenames>Valentin</forenames></author></authors><title>A Simulation Model for Evaluating Distributed Systems Dependability</title><categories>cs.DC</categories><comments>Please cite this as &quot;Ciprian Dobre, Florin Pop, Valentin Cristea, A
  Simulation Model for Evaluating Distributed Systems Dependability, 23rd
  annual European Simulation and Modelling Conference (ESM'2009), 2009, pp.
  62-69, ISBN: 978-90-77381-52-6, EUROSIS-ETI&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new simulation model designed to evaluate the
dependability in distributed systems. This model extends the MONARC simulation
model with new capabilities for capturing reliability, safety, availability,
security, and maintainability requirements. The model has been implemented as
an extension of the multithreaded, process oriented simulator MONARC, which
allows the realistic simulation of a wide-range of distributed system
technologies, with respect to their specific components and characteristics.
The extended simulation model includes the necessary components to inject
various failure events, and provides the mechanisms to evaluate different
strategies for replication, redundancy procedures, and security enforcement
mechanisms, as well. The results obtained in simulation experiments presented
in this paper probe that the use of discrete-event simulators, such as MONARC,
in the design and development of distributed systems is appealing due to their
efficiency and scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2561</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2561</id><created>2012-02-12</created><updated>2012-04-03</updated><authors><author><keyname>Nafea</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Seddik</keyname><forenames>Karim G.</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On the Diversity Gain Region of the Z-interference Channels</title><categories>cs.IT math.IT</categories><comments>Has been accepted by IEEE ICC 2012 - Communications Theory
  symposium(CT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we analyze the diversity gain region (DGR) of the
single-antenna Rayleigh fading Z-Interference channel (ZIC). More specifically,
we characterize the achievable DGR of the fixed-power split Han-Kobayashi (HK)
approach under these assumptions. Our characterization comes in a closed form
and demonstrates that the HK scheme with only a common message is a singular
case, which achieves the best DGR among all HK schemes for certain multiplexing
gains. Finally, we show that generalized time sharing, with variable rate and
power assignments for the common and private messages, does not improve the
achievable DGR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2564</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2564</id><created>2012-02-12</created><updated>2013-08-01</updated><authors><author><keyname>Hand</keyname><forenames>David J.</forenames></author><author><keyname>Anagnostopoulos</keyname><forenames>Christoforos</forenames></author></authors><title>A better Beta for the H measure of classification performance</title><categories>stat.ME cs.CV stat.ML</categories><comments>Preprint. Keywords: supervised classification, classifier
  performance, AUC, ROC curve, H measure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The area under the ROC curve is widely used as a measure of performance of
classification rules. However, it has recently been shown that the measure is
fundamentally incoherent, in the sense that it treats the relative severities
of misclassifications differently when different classifiers are used. To
overcome this, Hand (2009) proposed the $H$ measure, which allows a given
researcher to fix the distribution of relative severities to a
classifier-independent setting on a given problem. This note extends the
discussion, and proposes a modified standard distribution for the $H$ measure,
which better matches the requirements of researchers, in particular those faced
with heavily unbalanced datasets, the $Beta(\pi_1+1,\pi_0+1)$ distribution.
[Preprint submitted at Pattern Recognition Letters]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2571</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2571</id><created>2012-02-12</created><authors><author><keyname>Ciobanu</keyname><forenames>Radu</forenames></author><author><keyname>Dobre</keyname><forenames>Ciprian</forenames></author></authors><title>Data Dissemination in Opportunistic Networks</title><categories>cs.NI</categories><comments>Please cite this as &quot;Radu Ciobanu, Ciprian Dobre, Data Dissemination
  in Opportunistic Networks, in Proc. of 18th International Conference on
  Control Systems and Computer Science (CSCS-18), Bucharest, Romania, 2011, pp.
  529-536, ISSN: 2066-4451, Politehnica Press&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile devices integrating wireless short-range communication technologies
make possible new applications for spontaneous communication, interaction and
collaboration. An interesting approach is to use collaboration to facilitate
communication when mobile devices are not able to establish direct
communication paths. Opportunistic networks, formed when mobile devices
communicate with each other while users are in close proximity, can help
applications still exchange data in such cases. In opportunistic networks
routes are built dynamically, as each mobile device acts according to the
store-carry-and-forward paradigm. Thus, contacts between mobile devices are
seen as opportunities to move data towards destination. In such networks data
dissemination is done using forwarding and is usually based on a
publish/subscribe model. Opportunistic data dissemination also raises questions
concerning user privacy and incentives. Such problems are addressed di?erently
by various opportunistic data dissemination techniques. In this paper we
analyze existing relevant work in the area of data dissemination in
opportunistic networks. We present the categories of a proposed taxonomy that
captures the capabilities of data dissemination techniques used in such
networks. Moreover, we survey relevant data dissemination techniques and
analyze them using the proposed taxonomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2572</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2572</id><created>2012-02-12</created><updated>2013-01-19</updated><authors><author><keyname>Negreanu</keyname><forenames>Lorina</forenames></author><author><keyname>Giumale</keyname><forenames>Cristian</forenames></author><author><keyname>Agache</keyname><forenames>Alexandru</forenames></author><author><keyname>Muraru</keyname><forenames>Mihnea</forenames></author><author><keyname>Popovici</keyname><forenames>Matei</forenames></author><author><keyname>Dobre</keyname><forenames>Ciprian</forenames></author></authors><title>A Formal Approach for the Development of Service-Oriented Applications</title><categories>cs.SE</categories><comments>This article has been withdrawn by the author due to copyright
  incompatibilities raised by the original publisher. The author(s) ask all
  interested readers to contact either the authors, or check directly the
  Proceedings published by the Politehnica Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Please cite this as &quot;Lorina Negreanu, Cristian Giumale, Alexandru Agache,
Mihnea Muraru, Matei Popovici, Ciprian Dobre, A Formal Approach for the
Development of Service-Oriented Applications, in Proc. of 18th International
Conference on Control Systems and Computer Science (CSCS-18), Bucharest,
Romania, 2011, pp. 804-810, ISSN: 2066-4451, Politehnica Press&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2573</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2573</id><created>2012-02-12</created><authors><author><keyname>Dobre</keyname><forenames>Ciprian</forenames></author><author><keyname>Tudor</keyname><forenames>George Cristian</forenames></author></authors><title>Mobile Advertisement in Vehicular Ad-Hoc Networks</title><categories>cs.NI</categories><comments>Please cite this as &quot;Ciprian Dobre, George Cristian Tudor, Mobile
  Advertisement in Vehicular Ad-Hoc Networks, in Proc. of 16th Annual
  Conference on Web Technology, New Media, Communications and Telematics
  Theory, Methods, Tools and Applications (Euromedia'2011), London, UK, 2011,
  pp. 43-49, ISBN: 978-90-77381-61-7, EUROSIS-ETI&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Advertisement is a location-aware dissemination solution built on top
of a vehicular ad-hoc network. We envision a network of WiFi access points that
dynamically disseminate data to clients running on the car's smart device. The
approach can be considered an alternative to the static advertisement
billboards and can be useful to business companies wanting to dynamically
advertise their products and offers to people driving their car. The clients
can subscribe to information based on specific topics. We present design
solutions that use access points as emitters for transmitting messages to
wireless-enabled devices equipped on vehicles. We also present implementation
details for the evaluation of the proposed solution using a simulator designed
for VANET application. The results show that the application can be used for
transferring a significant amount of data even under difficult conditions, such
as when cars are moving at increased speeds, or the congested Wi-Fi network
causes significant packet loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2576</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2576</id><created>2012-02-12</created><updated>2012-07-18</updated><authors><author><keyname>Ansari</keyname><forenames>Imran Shafique</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Kucur</keyname><forenames>O&#x11f;uz</forenames></author></authors><title>New Results on the Sum of Gamma Random Variates With Application to the
  Performance of Wireless Communication Systems over Nakagami-m Fading Channels</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>5 figures, 4 tables, Accepted in SPAWC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The probability density function (PDF) and cumulative distribution function
of the sum of L independent but not necessarily identically distributed Gamma
variates, applicable to the output statistics of maximal ratio combining (MRC)
receiver operating over Nakagami-m fading channels or in other words to the
statistical analysis of the scenario where the sum of squared Nakagami-m
distributions are user-of-interest, is presented in closed-form in terms of
well-known Meijer's G function and easily computable Fox's H-bar function for
integer valued and non-integer valued m fading parameters. Further analysis,
particularly on bit error rate via a PDF-based approach is also offered in
closed form in terms of Meijer's G function and Fox's H-bar function for
integer valued fading parameters, and extended Fox's H-bar function (H-hat) for
non-integer valued fading parameters. Our proposed results complement previous
known results that are either expressed in terms of infinite sums, nested sums,
or higher order derivatives of the fading parameter m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2577</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2577</id><created>2012-02-12</created><authors><author><keyname>Christian</keyname><forenames>Carol</forenames></author><author><keyname>Lintott</keyname><forenames>Chris</forenames></author><author><keyname>Smith</keyname><forenames>Arfon</forenames></author><author><keyname>Fortson</keyname><forenames>Lucy</forenames></author><author><keyname>Bamford</keyname><forenames>Steven</forenames></author></authors><title>Citizen Science: Contributions to Astronomy Research</title><categories>astro-ph.IM cs.AI</categories><comments>12 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The contributions of everyday individuals to significant research has grown
dramatically beyond the early days of classical birdwatching and endeavors of
amateurs of the 19th century. Now people who are casually interested in science
can participate directly in research covering diverse scientific fields.
Regarding astronomy, volunteers, either as individuals or as networks of
people, are involved in a variety of types of studies. Citizen Science is
intuitive, engaging, yet necessarily robust in its adoption of sci-entific
principles and methods. Herein, we discuss Citizen Science, focusing on fully
participatory projects such as Zooniverse (by several of the au-thors CL, AS,
LF, SB), with mention of other programs. In particular, we make the case that
citizen science (CS) can be an important aspect of the scientific data analysis
pipelines provided to scientists by observatories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2585</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2585</id><created>2012-02-12</created><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames></author><author><keyname>Frongillo</keyname><forenames>Rafael M.</forenames></author><author><keyname>Wibisono</keyname><forenames>Andre</forenames></author></authors><title>Minimax Option Pricing Meets Black-Scholes in the Limit</title><categories>q-fin.CP cs.GT q-fin.PR</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Option contracts are a type of financial derivative that allow investors to
hedge risk and speculate on the variation of an asset's future market price. In
short, an option has a particular payout that is based on the market price for
an asset on a given date in the future. In 1973, Black and Scholes proposed a
valuation model for options that essentially estimates the tail risk of the
asset price under the assumption that the price will fluctuate according to
geometric Brownian motion. More recently, DeMarzo et al., among others, have
proposed more robust valuation schemes, where we can even assume an adversary
chooses the price fluctuations. This framework can be considered as a
sequential two-player zero-sum game between the investor and Nature. We analyze
the value of this game in the limit, where the investor can trade at smaller
and smaller time intervals. Under weak assumptions on the actions of Nature (an
adversary), we show that the minimax option price asymptotically approaches
exactly the Black-Scholes valuation. The key piece of our analysis is showing
that Nature's minimax optimal dual strategy converges to geometric Brownian
motion in the limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2586</identifier>
 <datestamp>2014-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2586</id><created>2012-02-12</created><updated>2014-02-25</updated><authors><author><keyname>Zhang</keyname><forenames>Huazi</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author></authors><title>Gossip-based Information Spreading in Mobile Networks</title><categories>cs.SI cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile networks receive increasing research interest recently due to their
increasingly wide applications in various areas; mobile ad hoc networks (MANET)
and Vehicular ad hoc networks (VANET) are two prominent examples. Mobility
introduces challenges as well as opportunities: it is known to improve the
network throughput as shown in [1]. In this paper, we analyze the effect of
mobility on the information spreading based on gossip algorithms. Our
contributions are twofold. Firstly, we propose a new performance metric, mobile
conductance, which allows us to separate the details of mobility models from
the study of mobile spreading time. Secondly, we explore the mobile
conductances of several popular mobility models, and offer insights on the
corresponding results. Large scale network simulation is conducted to verify
our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2591</identifier>
 <datestamp>2014-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2591</id><created>2012-02-12</created><updated>2013-05-13</updated><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author></authors><title>Database queries and constraints via lifting problems</title><categories>math.CT cs.DB math.AT</categories><msc-class>18A05, 55U35, 55P05, 55R10, 68P15</msc-class><acm-class>E.0; G.0; H.1.0</acm-class><doi>10.1017/S0960129513000479</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Previous work has demonstrated that categories are useful and expressive
models for databases. In the present paper we build on that model, showing that
certain queries and constraints correspond to lifting problems, as found in
modern approaches to algebraic topology. In our formulation, each so-called
SPARQL graph pattern query corresponds to a category-theoretic lifting problem,
whereby the set of solutions to the query is precisely the set of lifts. We
interpret constraints within the same formalism and then investigate some basic
properties of queries and constraints. In particular, to any database $\pi$ we
can associate a certain derived database $\Qry(\pi)$ of queries on $\pi$. As an
application, we explain how giving users access to certain parts of
$\Qry(\pi)$, rather than direct access to $\pi$, improves ones ability to
manage the impact of schema evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2595</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2595</id><created>2012-02-12</created><authors><author><keyname>Fill</keyname><forenames>James Allen</forenames></author><author><keyname>Janson</keyname><forenames>Svante</forenames></author></authors><title>The number of bit comparisons used by Quicksort: an average-case
  analysis</title><categories>math.PR cs.DS</categories><msc-class>60C05 (Primary) 68W40 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analyses of many algorithms and data structures (such as digital search
trees) for searching and sorting are based on the representation of the keys
involved as bit strings and so count the number of bit comparisons. On the
other hand, the standard analyses of many other algorithms (such as Quicksort)
are performed in terms of the number of key comparisons. We introduce the
prospect of a fair comparison between algorithms of the two types by providing
an average-case analysis of the number of bit comparisons required by
Quicksort. Counting bit comparisons rather than key comparisons introduces an
extra logarithmic factor to the asymptotic average total. We also provide a new
algorithm, &quot;BitsQuick&quot;, that reduces this factor to constant order by
eliminating needless bit comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2599</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2599</id><created>2012-02-12</created><updated>2012-09-20</updated><authors><author><keyname>Fill</keyname><forenames>James Allen</forenames></author><author><keyname>Nakama</keyname><forenames>Takehiko</forenames></author></authors><title>Distributional convergence for the number of symbol comparisons used by
  QuickSelect</title><categories>math.PR cs.DS</categories><comments>The first paragraph in the proof of Theorem 3.1 has been corrected in
  this revision, and references have been updated</comments><msc-class>60F25 (Primary) 68W40 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When the search algorithm QuickSelect compares keys during its execution in
order to find a key of target rank, it must operate on the keys'
representations or internal structures, which were ignored by the previous
studies that quantified the execution cost for the algorithm in terms of the
number of required key comparisons. In this paper, we analyze running costs for
the algorithm that take into account not only the number of key comparisons but
also the cost of each key comparison. We suppose that keys are represented as
sequences of symbols generated by various probabilistic sources and that
QuickSelect operates on individual symbols in order to find the target key. We
identify limiting distributions for the costs and derive integral and series
expressions for the expectations of the limiting distributions. These
expressions are used to recapture previously obtained results on the number of
key comparisons required by the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2600</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2600</id><created>2012-02-12</created><updated>2012-12-26</updated><authors><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author><author><keyname>Zhao</keyname><forenames>Xishun</forenames></author></authors><title>On Davis-Putnam reductions for minimally unsatisfiable clause-sets</title><categories>cs.DM math.CO</categories><comments>31 pages; editorial improvements for the third version, two technical
  corrections, more examples and making some aspects more explicit for the
  fourth version, more discussions, examples and details and some small
  corrections for fifth version. This is the underlying (extended and
  corrected) report for the paper at SAT 2012 (LNCS 7317); journal version to
  appear in Theoretical Computer Science</comments><msc-class>03F07, 68R05</msc-class><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Theoretical Computer Science Volume 492, Year 2013, Pages 70-87</journal-ref><doi>10.1007/978-3-642-31612-8_21 10.1016/j.tcs.2013.04.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For investigations into the structure of MU, i.e., minimally unsatisfiable
clause-sets or conjunctive normal forms, singular DP-reduction is a fundamental
tool, applying DP-reduction F -&gt; DP_v(F) in case variable v occurs in one
polarity only once. Recall, in general DP_v(F) replaces all clauses containing
variable v by their resolvents on v (another name is &quot;variable elimination&quot;).
We consider sDP(F), the set of all results of applying singular DP-reduction to
F in MU as long as possible, obtaining non-singular F' in MU with the same
deficiency, i.e., delta(F') = delta(F). (In general, delta(F) is the difference
c(F) - n(F) of the number of clauses and the number of variables.) Our main
results are: 1. For all F', F&quot; in sDP(F) we have n(F') = n(F&quot;). 2. If F is
saturated (F in SMU), then we have |sDP(F)| = 1. 3. If F is &quot;eventually
saturated&quot;, that is, sDP(F) &lt;= SMU, then for F', F&quot; in sDP(F) we have F'
isomorphic F&quot; (establishing &quot;confluence modulo isomorphism&quot;). The results are
obtained by a detailed analysis of singular DP-reduction for F in MU. As an
application we obtain that singular DP-reduction for F in MU(2) (i.e., delta(F)
= 2) is confluent modulo isomorphism (using the fundamental characterisation of
MU(2) by Kleine Buening). The background for these considerations is the
general project of the classification of MU in terms of the deficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2601</identifier>
 <datestamp>2013-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2601</id><created>2012-02-12</created><updated>2013-03-13</updated><authors><author><keyname>Fill</keyname><forenames>James Allen</forenames></author></authors><title>Distributional convergence for the number of symbol comparisons used by
  QuickSort</title><categories>math.PR cs.DS</categories><comments>Published in at http://dx.doi.org/10.1214/12-AAP866 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP866</report-no><journal-ref>Annals of Applied Probability 2013, Vol. 23, No. 3, 1129-1147</journal-ref><doi>10.1214/12-AAP866</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most previous studies of the sorting algorithm QuickSort have used the number
of key comparisons as a measure of the cost of executing the algorithm. Here we
suppose that the n independent and identically distributed (i.i.d.) keys are
each represented as a sequence of symbols from a probabilistic source and that
QuickSort operates on individual symbols, and we measure the execution cost as
the number of symbol comparisons. Assuming only a mild &quot;tameness&quot; condition on
the source, we show that there is a limiting distribution for the number of
symbol comparisons after normalization: first centering by the mean and then
dividing by n. Additionally, under a condition that grows more restrictive as p
increases, we have convergence of moments of orders p and smaller. In
particular, we have convergence in distribution and convergence of moments of
every order whenever the source is memoryless, that is, whenever each key is
generated as an infinite string of i.i.d. symbols. This is somewhat surprising;
even for the classical model that each key is an i.i.d. string of unbiased
(&quot;fair&quot;) bits, the mean exhibits periodic fluctuations of order n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2614</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2614</id><created>2012-02-12</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>Semantic snippet construction for search engine results based on segment
  evaluation</title><categories>cs.IR</categories><msc-class>68P20 Information storage and retrieval</msc-class><acm-class>H.3.3</acm-class><journal-ref>International Journal of Information Technology and Knowledge
  Management, July-December 2011, Volume 4, No. 2, pp. 581-583</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The result listing from search engines includes a link and a snippet from the
web page for each result item. The snippet in the result listing plays a vital
role in assisting the user to click on it. This paper proposes a novel approach
to construct the snippets based on a semantic evaluation of the segments in the
page. The target segment(s) is/are identified by applying a model to evaluate
segments present in the page and selecting the segments with top scores. The
proposed model makes the user judgment to click on a result item easier since
the snippet is constructed semantically after a critical evaluation based on
multiple factors. A prototype implementation of the proposed model confirms the
empirical validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2615</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2615</id><created>2012-02-12</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>Live-marker: A personalized web page content marking tool</title><categories>cs.IR</categories><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><journal-ref>International Journal of Information Technology and Knowledge
  Management July-December 2011, Volume 4, No. 2, pp. 485-488</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tremendous amount of increase in the quantity of information resources
available on the web has made the total time that the user spends on a single
page very minimal. Users revisiting the same page would be able to fetch the
required information much faster if the information that they consumed during
the previous visit(s) gets presented to them with a special style. This paper
proposes a model which empowers the users to mark the content interesting to
them, so that it can be identified easily during successive visits. In addition
to the explicit marking by the users, the model facilitates implicit marking
based on the user preferences. The prototype implementation based on proposed
model validates the model's efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2617</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2617</id><created>2012-02-12</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>Segmentation Based Approach to Dynamic Page Construction from Search
  Engine Results</title><categories>cs.IR</categories><comments>9 Pages, 7 Figures; ISSN : 0975-3397; International Journal on
  Computer Science and Engineering (IJCSE), Vol. 3 No. 3 Mar 2011</comments><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The results rendered by the search engines are mostly a linear snippet list.
With the prolific increase in the dynamism of web pages there is a need for
enhanced result lists from search engines in order to cope-up with the
expectations of the users. This paper proposes a model for dynamic construction
of a resultant page from various results fetched by the search engine, based on
the web page segmentation approach. With the incorporation of personalization
through user profile during the candidate segment selection, the enriched
resultant page is constructed. The benefits of this approach include instant,
one-shot navigation to relevant portions from various result items, in contrast
to a linear page-by-page visit approach. The experiments conducted on the
prototype model with various levels of users, quantifies the improvements in
terms of amount of relevant information fetched.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2619</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2619</id><created>2012-02-12</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>We.I.Pe: Web Identification of People using e-mail ID</title><categories>cs.IR</categories><comments>7 Pages, 4 Figures; ISSN : 0975-3397</comments><msc-class>68P20 Information storage and retrieval</msc-class><acm-class>H.3.3</acm-class><journal-ref>International Journal on Computer Science and Engineering (IJCSE),
  Vol. 3 No. 6 June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the phenomenal growth of content in the World Wide Web, the diversity of
user supplied queries have become vivid. Searching for people on the web has
become an important type of search activity in the web search engines. This
paper proposes a model named &quot;We.I.Pe&quot; to identify people on the World Wide Web
using e-mail Id as the primary input. The approach followed in this research
work provides the collected information, based on the user supplied e-mail id,
in an easier to navigate manner. The grouping of collected information based on
various sources makes the result visualization process more effective. The
proposed model is validated by a prototype implementation. Experiments
conducted on the prototype implementation provide encouraging results
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2622</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2622</id><created>2012-02-12</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>A Model for Web Page Usage Mining Based on Segmentation</title><categories>cs.IR</categories><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><journal-ref>International Journal of Computer Science and Information
  Technologies, Vol. 2, No 2 , 2011, 1144-1148</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The web page usage mining plays a vital role in enriching the page's content
and structure based on the feedbacks received from the user's interactions with
the page. This paper proposes a model for micro-managing the tracking
activities by fine-tuning the mining from the page level to the segment level.
The proposed model enables the web-master to identify the segments which
receives more focus from users comparing with others. The segment level
analytics of user actions provides an important metric to analyse the factors
which facilitate the increase in traffic for the page. The empirical validation
of the model is performed through prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2624</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2624</id><created>2012-02-12</created><updated>2013-04-23</updated><authors><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Harvey</keyname><forenames>Daniel J.</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Reed</keyname><forenames>Bruce</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>A linear-time algorithm for finding a complete graph minor in a dense
  graph</title><categories>math.CO cs.DM cs.DS</categories><comments>6 pages, 0 figures; Clarification added in several places, no change
  to arguments or results</comments><msc-class>05C83, 05C85</msc-class><journal-ref>SIAM Journal on Discrete Mathematics, 27/4:1770--1774, 2013</journal-ref><doi>10.1137/120866725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let g(t) be the minimum number such that every graph G with average degree
d(G) \geq g(t) contains a K_{t}-minor. Such a function is known to exist, as
originally shown by Mader. Kostochka and Thomason independently proved that
g(t) \in \Theta(t*sqrt{log t}). This article shows that for all fixed \epsilon
&gt; 0 and fixed sufficiently large t \geq t(\epsilon), if d(G) \geq
(2+\epsilon)g(t) then we can find this K_{t}-minor in linear time. This
improves a previous result by Reed and Wood who gave a linear-time algorithm
when d(G) \geq 2^{t-2}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2634</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2634</id><created>2012-02-13</created><authors><author><keyname>Murty</keyname><forenames>M. Sreerama</forenames></author><author><keyname>Veeraiah</keyname><forenames>A.</forenames></author><author><keyname>Rao</keyname><forenames>Srinivas</forenames></author></authors><title>&quot;Performance Evaluation of Wi-Fi comparison with WiMAX Networks&quot;</title><categories>cs.NI</categories><comments>9</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.3, No.1, January 2012</journal-ref><doi>10.5121/ijdps.2012.3127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networking has become an important area of research in academic and
industry. The main objectives of this paper is to gain in-depth knowledge about
the Wi-Fi- WiMAX technology and how it works and understand the problems about
the WiFi- WiMAX technology in maintaining and deployment. The challenges in
wireless networks include issues like security, seamless handover, location and
emergency services, cooperation, and QoS.The performance of the WiMAX is better
than the Wi-Fi and also it provide the good response in the access. It's
evaluated the Quality of Service (Qos) in Wi-Fi compare with WiMAX and provides
the various kinds of security Mechanisms. Authentication to verify the identity
of the authorized communicating client stations. Confidentiality (Privacy) to
secure that the wirelessly conveyed information will remain private and
protected. Take necessary actions and configurations that are needed in order
to deploy Wi-Fi -WiMAX with increased levels of security and privacy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2638</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2638</id><created>2012-02-13</created><updated>2013-07-31</updated><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Yan</keyname><forenames>Jinyun</forenames></author></authors><title>Scienceography: the study of how science is written</title><categories>cs.DL</categories><comments>13 pages,16 figures. Sixth International Conference on FUN WITH
  ALGORITHMS, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientific literature has itself been the subject of much scientific study,
for a variety of reasons: understanding how results are communicated, how ideas
spread, and assessing the influence of areas or individuals. However, most
prior work has focused on extracting and analyzing citation and stylistic
patterns. In this work, we introduce the notion of 'scienceography', which
focuses on the writing of science. We provide a first large scale study using
data derived from the arXiv e-print repository. Crucially, our data includes
the &quot;source code&quot; of scientific papers-the LaTEX source-which enables us to
study features not present in the &quot;final product&quot;, such as the tools used and
private comments between authors. Our study identifies broad patterns and
trends in two example areas-computer science and mathematics-as well as
highlighting key differences in the way that science is written in these
fields. Finally, we outline future directions to extend the new topic of
scienceography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2651</identifier>
 <datestamp>2012-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2651</id><created>2012-02-13</created><updated>2012-05-23</updated><authors><author><keyname>Zheng</keyname><forenames>Shenggen</forenames></author><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Gruska</keyname><forenames>Jozef</forenames></author><author><keyname>Li</keyname><forenames>Lvzhou</forenames></author><author><keyname>Mateus</keyname><forenames>Paulo</forenames></author></authors><title>State succinctness of two-way finite automata with quantum and classical
  states</title><categories>quant-ph cs.FL</categories><comments>26pages, comments and suggestions are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  {\it Two-way quantum automata with quantum and classical states} (2QCFA) were
introduced by Ambainis and Watrous in 2002. In this paper we study state
succinctness of 2QCFA.
  For any $m\in {\mathbb{Z}}^+$ and any $\epsilon&lt;1/2$, we show that:
{enumerate} there is a promise problem $A^{eq}(m)$ which can be solved by a
2QCFA with one-sided error $\epsilon$ in a polynomial expected running time
with a constant number (that depends neither on $m$ nor on $\varepsilon$) of
quantum states and $\mathbf{O}(\log{\frac{1}{\epsilon})}$ classical states,
whereas the sizes of the corresponding {\it deterministic finite automata}
(DFA), {\it two-way nondeterministic finite automata} (2NFA) and polynomial
expected running time {\it two-way probabilistic finite automata} (2PFA) are at
least $2m+2$, $\sqrt{\log{m}}$, and $\sqrt[3]{(\log m)/b}$, respectively; there
exists a language $L^{twin}(m)=\{wcw| w\in\{a,b\}^*\}$ over the alphabet
$\Sigma=\{a,b,c\}$ which can be recognized by a 2QCFA with one-sided error
$\epsilon$ in an exponential expected running time with a constant number of
quantum states and $\mathbf{O}(\log{\frac{1}{\epsilon})}$ classical states,
whereas the sizes of the corresponding DFA, 2NFA and polynomial expected
running time 2PFA are at least $2^m$, $\sqrt{m}$, and $\sqrt[3]{m/b}$,
respectively; {enumerate} where $b$ is a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2684</identifier>
 <datestamp>2013-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2684</id><created>2012-02-13</created><updated>2013-04-02</updated><authors><author><keyname>Rombach</keyname><forenames>M. Puck</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Fowler</keyname><forenames>James H.</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author></authors><title>Core-Periphery Structure in Networks</title><categories>cs.SI cond-mat.stat-mech physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intermediate-scale (or `meso-scale') structures in networks have received
considerable attention, as the algorithmic detection of such structures makes
it possible to discover network features that are not apparent either at the
local scale of nodes and edges or at the global scale of summary statistics.
Numerous types of meso-scale structures can occur in networks, but
investigations of such features have focused predominantly on the
identification and study of community structure. In this paper, we develop a
new method to investigate the meso-scale feature known as core-periphery
structure, which entails identifying densely-connected core nodes and
sparsely-connected periphery nodes. In contrast to communities, the nodes in a
core are also reasonably well-connected to those in the periphery. Our new
method of computing core-periphery structure can identify multiple cores in a
network and takes different possible cores into account. We illustrate the
differences between our method and several existing methods for identifying
which nodes belong to a core, and we use our technique to examine
core-periphery structure in examples of friendship, collaboration,
transportation, and voting networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2687</identifier>
 <datestamp>2013-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2687</id><created>2012-02-13</created><updated>2013-01-29</updated><authors><author><keyname>Shomorony</keyname><forenames>Ilan</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>Worst-Case Additive Noise in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Several proofs were improved. New examples and figures were added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classical result in Information Theory states that the Gaussian noise is
the worst-case additive noise in point-to-point channels, meaning that, for a
fixed noise variance, the Gaussian noise minimizes the capacity of an additive
noise channel. In this paper, we significantly generalize this result and show
that the Gaussian noise is also the worst-case additive noise in wireless
networks with additive noises that are independent from the transmit signals.
More specifically, we show that, if we fix the noise variance at each node,
then the capacity region with Gaussian noises is a subset of the capacity
region with any other set of noise distributions. We prove this result by
showing that a coding scheme that achieves a given set of rates on a network
with Gaussian additive noises can be used to construct a coding scheme that
achieves the same set of rates on a network that has the same topology and
traffic demands, but with non-Gaussian additive noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2703</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2703</id><created>2012-02-13</created><authors><author><keyname>Berar</keyname><forenames>Maxime</forenames><affiliation>LITIS</affiliation></author><author><keyname>Tilotta</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>MAP5</affiliation></author><author><keyname>Glaun&#xe8;s</keyname><forenames>Joan Alexis</forenames><affiliation>MAP5</affiliation></author><author><keyname>Rozenholc</keyname><forenames>Yves</forenames><affiliation>MAP5</affiliation></author></authors><title>Craniofacial reconstruction as a prediction problem using a Latent Root
  Regression model</title><categories>cs.LG q-bio.TO</categories><proxy>ccsd</proxy><journal-ref>Forensic Science International 210, 1-3 (2011) 228 - 236</journal-ref><doi>10.1016/j.forsciint.2011.03.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a computer-assisted method for facial
reconstruction. This method provides an estimation of the facial shape
associated with unidentified skeletal remains. Current computer-assisted
methods using a statistical framework rely on a common set of extracted points
located on the bone and soft-tissue surfaces. Most of the facial reconstruction
methods then consist of predicting the position of the soft-tissue surface
points, when the positions of the bone surface points are known. We propose to
use Latent Root Regression for prediction. The results obtained are then
compared to those given by Principal Components Analysis linear models. In
conjunction, we have evaluated the influence of the number of skull landmarks
used. Anatomical skull landmarks are completed iteratively by points located
upon geodesics which link these anatomical landmarks, thus enabling us to
artificially increase the number of skull points. Facial points are obtained
using a mesh-matching algorithm between a common reference mesh and individual
soft-tissue surface meshes. The proposed method is validated in term of
accuracy, based on a leave-one-out cross-validation test applied to a
homogeneous database. Accuracy measures are obtained by computing the distance
between the original face surface and its reconstruction. Finally, these
results are discussed referring to current computer-assisted reconstruction
facial techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2709</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2709</id><created>2012-02-13</created><updated>2013-07-30</updated><authors><author><keyname>Zhang</keyname><forenames>Qian-Ming</forenames></author><author><keyname>L&#xfc;</keyname><forenames>Linyuan</forenames></author><author><keyname>Wang</keyname><forenames>Wen-Qiang</forenames></author><author><keyname>Zhu</keyname><forenames>Yu-Xiao</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Potential Theory for Directed Networks</title><categories>physics.data-an cs.IR cs.SI physics.soc-ph</categories><comments>8 pages, 6 figures</comments><journal-ref>PLoS ONE, volume 8, number 2, pages e55437, year 2013</journal-ref><doi>10.1371/journal.pone.0055437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncovering factors underlying the network formation is a long-standing
challenge for data mining and network analysis. In particular, the microscopic
organizing principles of directed networks are less understood than those of
undirected networks. This article proposes a hypothesis named potential theory,
which assumes that every directed link corresponds to a decrease of a unit
potential and subgraphs with definable potential values for all nodes are
preferred. Combining the potential theory with the clustering and homophily
mechanisms, it is deduced that the Bi-fan structure consisting of 4 nodes and 4
directed links is the most favored local structure in directed networks. Our
hypothesis receives strongly positive supports from extensive experiments on 15
directed networks drawn from disparate fields, as indicated by the most
accurate and robust performance of Bi-fan predictor within the link prediction
framework. In summary, our main contribution is twofold: (i) We propose a new
mechanism for the local organization of directed networks; (ii) We design the
corresponding link prediction algorithm, which can not only testify our
hypothesis, but also find out direct applications in missing link prediction
and friendship recommendation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2731</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2731</id><created>2012-02-13</created><authors><author><keyname>Gupta</keyname><forenames>Rashmi</forenames></author><author><keyname>Raghav</keyname><forenames>Shalini</forenames></author></authors><title>Risk Assessment Techniques and Survey Method for COTS Components</title><categories>cs.SE</categories><comments>International Journal of Software Engineering &amp; Applications (IJSEA),
  Vol.3, No.1, January 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Rational Unified Process a software engineering process is gaining
popularity nowadays. RUP delivers best software practices for component
software Development life cycle It supports component based software
development. Risk is involved in every component development phase .neglecting
those risks sometimes hampers the software growth and leads to negative
outcome. In Order to provide appropriate security and protection levels,
identifying various risks is very vital. Therefore Risk identification plays a
very crucial role in the component based software development This report
addresses incorporation of component based software development cycle into RUP
phases, assess several category of risk encountered in the component based
software. It also entails a survey method to identify the risk factor and
evaluating the overall severity of the component software development in terms
of the risk. Formula for determining risk prevention cost and finding the risk
probability is also been included. The overall goal of the paper is to provide
a theoretical foundation that facilitates a good understanding of risk in
relation to componentbased system development
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2736</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2736</id><created>2012-02-13</created><authors><author><keyname>Gaul</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Function call overhead benchmarks with MATLAB, Octave, Python, Cython
  and C</title><categories>cs.PL cs.MS math.NA</categories><comments>The benchmark's source code is available under GPL3 at
  https://bitbucket.org/andrenarchy/funcall</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the overhead of function calls in the programming languages
MATLAB/Octave, Python, Cython and C. In many applications a function has to be
called very often inside a loop. One such application in numerical analysis is
the finite element method where integrals have to be computed on each element
in a loop. The called functions can often be evaluated efficiently but the
function call itself may be time-consuming. We present a benchmark whose goal
is to identify and quantify optimization potentials with respect to time
consumption caused by function calls in the mentioned programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2745</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2745</id><created>2012-02-13</created><authors><author><keyname>Cire&#x15f;an</keyname><forenames>Dan</forenames></author><author><keyname>Meier</keyname><forenames>Ueli</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Multi-column Deep Neural Networks for Image Classification</title><categories>cs.CV cs.AI</categories><comments>20 pages, 14 figures, 8 tables</comments><report-no>IDSIA-04-12</report-no><journal-ref>CVPR 2012, p. 3642-3649</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional methods of computer vision and machine learning cannot match
human performance on tasks such as the recognition of handwritten digits or
traffic signs. Our biologically plausible deep artificial neural network
architectures can. Small (often minimal) receptive fields of convolutional
winner-take-all neurons yield large network depth, resulting in roughly as many
sparsely connected neural layers as found in mammals between retina and visual
cortex. Only winner neurons are trained. Several deep neural columns become
experts on inputs preprocessed in different ways; their predictions are
averaged. Graphics cards allow for fast training. On the very competitive MNIST
handwriting benchmark, our method is the first to achieve near-human
performance. On a traffic sign recognition benchmark it outperforms humans by a
factor of two. We also improve the state-of-the-art on a plethora of common
image classification benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2759</identifier>
 <datestamp>2015-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2759</id><created>2012-02-13</created><updated>2015-09-15</updated><authors><author><keyname>Fletcher</keyname><forenames>Alyson K.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Iterative Reconstruction of Rank-One Matrices in Noise</title><categories>cs.IT math.IT</categories><comments>28 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating a rank-one matrix in Gaussian noise
under a probabilistic model for the left and right factors of the matrix. The
probabilistic model can impose constraints on the factors including sparsity
and positivity that arise commonly in learning problems. We propose a family of
algorithms that reduce the problem to a sequence of scalar estimation
computations. These algorithms are similar to approximate message passing
techniques based on Gaussian approximations of loopy belief propagation that
have been used recently in compressed sensing. Leveraging analysis methods by
Bayati and Montanari, we show that the asymptotic behavior of the algorithm is
described by a simple scalar equivalent model, where the distribution of the
estimates at each iteration is identical to certain scalar estimates of the
variables in Gaussian noise. Moreover, the effective Gaussian noise level is
described by a set of state evolution equations. The proposed approach to
deriving algorithms thus provides a computationally simple and general method
for rank-one estimation problems with a precise analysis in certain
high-dimensional settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2770</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2770</id><created>2012-02-13</created><updated>2012-06-21</updated><authors><author><keyname>Salavati</keyname><forenames>Amir Hesam</forenames></author><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author></authors><title>Multi-Level Error-Resilient Neural Networks with Learning</title><categories>cs.NE cs.AI cs.IT math.IT</categories><comments>Part of this draft has been submitted to International Symposium on
  Information Theory (ISIT) 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of neural network association is to retrieve a previously
memorized pattern from its noisy version using a network of neurons. An ideal
neural network should include three components simultaneously: a learning
algorithm, a large pattern retrieval capacity and resilience against noise.
Prior works in this area usually improve one or two aspects at the cost of the
third.
  Our work takes a step forward in closing this gap. More specifically, we show
that by forcing natural constraints on the set of learning patterns, we can
drastically improve the retrieval capacity of our neural network. Moreover, we
devise a learning algorithm whose role is to learn those patterns satisfying
the above mentioned constraints. Finally we show that our neural network can
cope with a fair amount of noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2771</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2771</id><created>2012-02-13</created><updated>2013-05-28</updated><authors><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Brautbar</keyname><forenames>Michael</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Multi-Scale Matrix Sampling and Sublinear-Time PageRank Computation</title><categories>cs.DS cs.SI</categories><comments>Accepted to Internet Mathematics journal for publication. An extended
  abstract of this paper appeared in WAW 2012 under the title &quot;A Sublinear Time
  Algorithm for PageRank Computations&quot;</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A fundamental problem arising in many applications in Web science and social
network analysis is, given an arbitrary approximation factor $c&gt;1$, to output a
set $S$ of nodes that with high probability contains all nodes of PageRank at
least $\Delta$, and no node of PageRank smaller than $\Delta/c$. We call this
problem {\sc SignificantPageRanks}. We develop a nearly optimal, local
algorithm for the problem with runtime complexity $\tilde{O}(n/\Delta)$ on
networks with $n$ nodes. We show that any algorithm for solving this problem
must have runtime of ${\Omega}(n/\Delta)$, rendering our algorithm optimal up
to logarithmic factors.
  Our algorithm comes with two main technical contributions. The first is a
multi-scale sampling scheme for a basic matrix problem that could be of
interest on its own. In the abstract matrix problem it is assumed that one can
access an unknown {\em right-stochastic matrix} by querying its rows, where the
cost of a query and the accuracy of the answers depend on a precision parameter
$\epsilon$. At a cost propositional to $1/\epsilon$, the query will return a
list of $O(1/\epsilon)$ entries and their indices that provide an
$\epsilon$-precision approximation of the row. Our task is to find a set that
contains all columns whose sum is at least $\Delta$, and omits any column whose
sum is less than $\Delta/c$. Our multi-scale sampling scheme solves this
problem with cost $\tilde{O}(n/\Delta)$, while traditional sampling algorithms
would take time $\Theta((n/\Delta)^2)$.
  Our second main technical contribution is a new local algorithm for
approximating personalized PageRank, which is more robust than the earlier ones
developed in \cite{JehW03,AndersenCL06} and is highly efficient particularly
for networks with large in-degrees or out-degrees. Together with our multiscale
sampling scheme we are able to optimally solve the {\sc SignificantPageRanks}
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2773</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2773</id><created>2012-02-13</created><authors><author><keyname>Komenda</keyname><forenames>Anton&#xed;n</forenames></author><author><keyname>Nov&#xe1;k</keyname><forenames>Peter</forenames></author><author><keyname>P&#x11b;chou&#x10d;ek</keyname><forenames>Michal</forenames></author></authors><title>Decentralized Multi-agent Plan Repair in Dynamic Environments</title><categories>cs.AI cs.MA</categories><comments>21 pages, 5 algorithms, 3 figures. This is the full version of an
  extended abstract published in Proceedings of the 11th International
  Conference on Autonomous Agents and Multiagent Systems (AAMAS 2012),
  Conitzer, Winikoff, Padgham, and van der Hoek (eds.), June, 4--8, 2012,
  Valencia, Spain</comments><acm-class>I.2.11; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving joint objectives by teams of cooperative planning agents requires
significant coordination and communication efforts. For a single-agent system
facing a plan failure in a dynamic environment, arguably, attempts to repair
the failed plan in general do not straightforwardly bring any benefit in terms
of time complexity. However, in multi-agent settings the communication
complexity might be of a much higher importance, possibly a high communication
overhead might be even prohibitive in certain domains. We hypothesize that in
decentralized systems, where coordination is enforced to achieve joint
objectives, attempts to repair failed multi-agent plans should lead to lower
communication overhead than replanning from scratch.
  The contribution of the presented paper is threefold. Firstly, we formally
introduce the multi-agent plan repair problem and formally present the core
hypothesis underlying our work. Secondly, we propose three algorithms for
multi-agent plan repair reducing the problem to specialized instances of the
multi-agent planning problem. Finally, we present results of experimental
validation confirming the core hypothesis of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2774</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2774</id><created>2012-02-13</created><authors><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Vuffray</keyname><forenames>Marc</forenames></author></authors><title>Beyond the Bethe Free Energy of LDPC Codes via Polymer Expansions</title><categories>cs.IT cond-mat.stat-mech math-ph math.IT math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The loop series provides a formal way to write down corrections to the Bethe
entropy (and/or free energy) of graphical models. We provide methods to
rigorously control such expansions for low-density parity-check codes used over
a highly noisy binary symmetric channel. We prove that in the asymptotic limit
of large size, with high probability, the Bethe expression gives an exact
formula for the entropy (per bit) of the input word conditioned on the output
of the channel. Our methods also apply to more general models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2778</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2778</id><created>2012-02-13</created><authors><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Vuffray</keyname><forenames>Marc</forenames></author></authors><title>Polymer Expansions for Cycle LDPC Codes</title><categories>cs.IT cond-mat.stat-mech math-ph math.IT math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the Bethe expression for the conditional input-output entropy
of cycle LDPC codes on binary symmetric channels above the MAP threshold is
exact in the large block length limit. The analysis relies on methods from
statistical physics. The finite size corrections to the Bethe expression are
expressed through a polymer expansion which is controlled thanks to expander
and counting arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2789</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2789</id><created>2012-02-13</created><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Vondrak</keyname><forenames>Jan</forenames></author></authors><title>The Computational Complexity of Truthfulness in Combinatorial Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental questions of Algorithmic Mechanism Design is whether
there exists an inherent clash between truthfulness and computational
tractability: in particular, whether polynomial-time truthful mechanisms for
combinatorial auctions are provably weaker in terms of approximation ratio than
non-truthful ones. This question was very recently answered for universally
truthful mechanisms for combinatorial auctions \cite{D11}, and even for
truthful-in-expectation mechanisms \cite{DughmiV11}. However, both of these
results are based on information-theoretic arguments for valuations given by a
value oracle, and leave open the possibility of polynomial-time truthful
mechanisms for succinctly described classes of valuations.
  This paper is the first to prove {\em computational hardness} results for
truthful mechanisms for combinatorial auctions with succinctly described
valuations. We prove that there is a class of succinctly represented submodular
valuations for which no deterministic truthful mechanism provides an
$m^{1/2-\epsilon}$-approximation for a constant $\epsilon&gt;0$, unless $NP=RP$
($m$ denotes the number of items). Furthermore, we prove that even
truthful-in-expectation mechanisms cannot approximate combinatorial auctions
with certain succinctly described submodular valuations better than within
$n^\gamma$, where $n$ is the number of bidders and $\gamma&gt;0$ some absolute
constant, unless $NP \subseteq P/poly$. In addition, we prove computational
hardness results for two related problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2792</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2792</id><created>2012-02-13</created><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Vondrak</keyname><forenames>Jan</forenames></author></authors><title>On the Hardness of Welfare Maximization in Combinatorial Auctions with
  Submodular Valuations</title><categories>cs.DS cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new type of monotone submodular functions: \emph{multi-peak
submodular functions}. Roughly speaking, given a family of sets $\cF$, we
construct a monotone submodular function $f$ with a high value $f(S)$ for every
set $S \in {\cF}$ (a &quot;peak&quot;), and a low value on every set that does not
intersect significantly any set in $\cF$.
  We use this construction to show that a better than
$(1-\frac{1}{2e})$-approximation ($\simeq 0.816$) for welfare maximization in
combinatorial auctions with submodular valuations is (1) impossible in the
communication model, (2) NP-hard in the computational model where valuations
are given explicitly. Establishing a constant approximation hardness for this
problem in the communication model was a long-standing open question. The
valuations we construct for the hardness result in the computational model
depend only on a constant number of items, and hence the result holds even if
the players can answer arbitrary queries about their valuation, including
demand queries.
  We also study two other related problems that received some attention
recently: max-min allocation (for which we also get hardness of $(1-\frac 1
{2e}+\epsilon)$-approximation, in both models), and combinatorial public
projects (for which we prove hardness of $(3/4+\epsilon)$-approximation in the
communication model, and hardness of $(1 -\frac 1 e+\epsilon)$-approximation in
the computational model, using constant size valuations).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2794</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2794</id><created>2012-02-13</created><authors><author><keyname>Vaishampayan</keyname><forenames>Vinay Anant</forenames></author></authors><title>Query Matrices for Retrieving Binary Vectors Based on the Hamming
  Distance Oracle</title><categories>cs.DM cs.IR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hamming oracle returns the Hamming distance between an unknown binary
$n$-vector $x$ and a binary query $n$-vector y. The objective is to determine
$x$ uniquely using a sequence of $m$ queries. What are the minimum number of
queries required in the worst case? We consider the query ratio $m/n$ to be our
figure of merit and derive upper bounds on the query ratio by explicitly
constructing $(m,n)$ query matrices. We show that our recursive and algebraic
construction results in query ratios arbitrarily close to zero. Our
construction is based on codes of constant weight. A decoding algorithm for
recovering the unknown binary vector is also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2803</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2803</id><created>2012-02-13</created><authors><author><keyname>Maham</keyname><forenames>Behrouz</forenames></author><author><keyname>Behnad</keyname><forenames>Aydin</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Efficient Relay Selection Scheme for Delay-Limited Non-Orthogonal
  Hybrid-ARQ Relay Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a half-duplex wireless relay network with hybrid-automatic
retransmission request (HARQ) and Rayleigh fading channels. In this paper, we
analyze the outage probability of the multi-relay delay-limited HARQ system
with opportunistic relaying scheme in decode-and-forward mode, in which the
\emph{best} relay is selected to transmit the source's regenerated signal. A
simple and distributed relay selection strategy is proposed for multi-relay
HARQ channels. Then, we utilize the non-orthogonal cooperative transmission
between the source and selected relay for retransmitting of the source data
toward the destination if needed, using space-time codes or beamforming
techniques. We analyze the performance of the system. We first derive the
cumulative density function (CDF) and probability density function (PDF) of the
selected relay HARQ channels. Then, the CDF and PDF are used to determine the
outage probability in the $l$-th round of HARQ. The outage probability is
required to compute the throughput-delay performance of this half-duplex
opportunistic relaying protocol. The packet delay constraint is represented by
$L$, the maximum number of HARQ rounds. An outage is declared if the packet is
unsuccessful after $L$ HARQ rounds. Furthermore, closed-form upper-bounds on
outage probability are derived and subsequently are used to investigate the
diversity order of the system. Based on the derived upper-bound expressions, it
is shown that the proposed schemes achieve the full spatial diversity order of
$N+1$, where $N$ is the number of potential relays. Our analytical results are
confirmed by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2820</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2820</id><created>2012-02-13</created><authors><author><keyname>Boucher</keyname><forenames>Christina</forenames></author><author><keyname>Landau</keyname><forenames>Gad M.</forenames></author><author><keyname>Levy</keyname><forenames>Avivit</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>On Approximating String Selection Problems with Outliers</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems in bioinformatics are about finding strings that approximately
represent a collection of given strings. We look at more general problems where
some input strings can be classified as outliers. The Close to Most Strings
problem is, given a set S of same-length strings, and a parameter d, find a
string x that maximizes the number of &quot;non-outliers&quot; within Hamming distance d
of x. We prove this problem has no PTAS unless ZPP=NP, correcting a decade-old
mistake. The Most Strings with Few Bad Columns problem is to find a
maximum-size subset of input strings so that the number of non-identical
positions is at most k; we show it has no PTAS unless P=NP. We also observe
Closest to k Strings has no EPTAS unless W[1]=FPT. In sum, outliers help model
problems associated with using biological data, but we show the problem of
finding an approximate solution is computationally difficult.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2826</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2826</id><created>2012-02-13</created><updated>2013-06-09</updated><authors><author><keyname>Butler</keyname><forenames>Brian K.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Error Floor Approximation for LDPC Codes in the AWGN Channel</title><categories>cs.IT math.IT</categories><comments>24 pages, 15 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the prediction of error floors of low-density
parity-check (LDPC) codes with variable nodes of constant degree in the
additive white Gaussian noise (AWGN) channel. Specifically, we focus on the
performance of the sum-product algorithm (SPA) decoder formulated in the
log-likelihood ratio (LLR) domain. We hypothesize that several published error
floor levels are due to the manner in which decoder implementations handled the
LLRs at high SNRs. We employ an LLR-domain SPA decoder that does not saturate
near-certain messages and find the error rates of our decoder to be lower by at
least several orders of magnitude. We study the behavior of trapping sets (or
near-codewords) that are the dominant cause of the reported error floors.
  We develop a refined linear model, based on the work of Sun and others, that
accurately predicts error floors caused by elementary tapping sets for
saturating decoders. Performance results of several codes at several levels of
decoder saturation are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2840</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2840</id><created>2012-02-13</created><updated>2012-07-24</updated><authors><author><keyname>Chalermsook</keyname><forenames>Parinya</forenames></author><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Sun</keyname><forenames>He</forenames></author></authors><title>Geometric Pricing: How Low Dimensionality Helps in Approximability</title><categories>cs.GT cs.CG cs.DS</categories><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following toy problem. There are $m$ rectangles and $n$ points
on the plane. Each rectangle $R$ is a consumer with budget $B_R$, who is
interested in purchasing the cheapest item (point) inside R, given that she has
enough budget. Our job is to price the items to maximize the revenue. This
problem can also be defined on higher dimensions. We call this problem the
geometric pricing problem.
  In this paper, we study a new class of problems arising from a geometric
aspect of the pricing problem. It intuitively captures typical real-world
assumptions that have been widely studied in marketing research, healthcare
economics, etc. It also helps classify other well-known pricing problems, such
as the highway pricing problem and the graph vertex pricing problem on planar
and bipartite graphs. Moreover, this problem turns out to have close
connections to other natural geometric problems such as the geometric versions
of the unique coverage and maximum feasible subsystem problems.
  We show that the low dimensionality arising in this pricing problem does lead
to improved approximation ratios, by presenting sublinear-approximation
algorithms for two central versions of the problem: unit-demand uniform-budget
min-buying and single-minded pricing problems. Our algorithm is obtained by
combining algorithmic pricing and geometric techniques. These results suggest
that considering geometric aspect might be a promising research direction in
obtaining improved approximation algorithms for such pricing problems. To the
best of our knowledge, this is one of very few problems in the intersection
between geometry and algorithmic pricing areas. Thus its study may lead to new
algorithmic techniques that could benefit both areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2868</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2868</id><created>2012-02-10</created><authors><author><keyname>Lucanin</keyname><forenames>Drazen</forenames></author></authors><title>Visual definition of procedures for automatic virtual scene generation</title><categories>cs.GR cs.PL</categories><comments>Master's thesis</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  With more and more digital media, especially in the field of virtual reality
where detailed and convincing scenes are much required, procedural scene
generation is a big helping tool for artists. A problem is that defining scene
descriptions through these procedures usually requires a knowledge in formal
language grammars, programming theory and manually editing textual files using
a strict syntax, making it less intuitive to use. Luckily, graphical user
interfaces has made a lot of tasks on computers easier to perform and out of
the belief that creating computer programs can also be one of them, visual
programming languages (VPLs) have emerged. The goal in VPLs is to shift more
work from the programmer to the integrated development environment (IDE),
making programming an user-friendlier task.
  In this thesis, an approach of using a VPL for defining procedures that
automatically generate virtual scenes is presented. The methods required to
build a VPL are presented, including a novel method of generating readable code
in a structured programming language. Also, the methods for achieving basic
principles of VPLs will be shown -- suitable visual presentation of information
and guiding the programmer in the right direction using constraints. On the
other hand, procedural generation methods are presented in the context of
visual programming -- adapting the application programming interface (API) of
these methods to better serve the user. The main focus will be on the methods
for urban modeling, such as building, city layout and details generation with
random number generation used to create non-deterministic scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2875</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2875</id><created>2012-02-13</created><updated>2012-06-29</updated><authors><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Duong</keyname><forenames>Trung Q.</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Uplink Performance Analysis of Multicell MU-MIMO Systems with ZF
  Receivers</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the uplink of a multicell multiuser multiple-input
multiple-output system where the channel experiences both small and large-scale
fading. The data detection is done by using the linear zero-forcing technique,
assuming the base station (BS) has perfect channel state information. We derive
new, exact closed-form expressions for the uplink rate, symbol error rate, and
outage probability per user, as well as a lower bound on the achievable rate.
This bound is very tight and becomes exact in the large-number-of-antennas
limit. We further study the asymptotic system performance in the regimes of
high signal-to-noise ratio (SNR), large number of antennas, and large number of
users per cell. We show that at high SNRs, the system is interference-limited
and hence, we cannot improve the system performance by increasing the transmit
power of each user. Instead, by increasing the number of BS antennas, the
effects of interference and noise can be reduced, thereby improving the system
performance. We demonstrate that, with very large antenna arrays at the BS, the
transmit power of each user can be made inversely proportional to the number of
BS antennas while maintaining a desired quality-of-service. Numerical results
are presented to verify our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2877</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2877</id><created>2012-02-13</created><updated>2013-01-08</updated><authors><author><keyname>Christodoulou</keyname><forenames>George</forenames></author><author><keyname>Mehlhorn</keyname><forenames>Kurt</forenames></author><author><keyname>Pyrga</keyname><forenames>Evangelia</forenames></author></authors><title>Improving the Price of Anarchy for Selfish Routing via Coordination
  Mechanisms</title><categories>cs.GT</categories><comments>17 pages, 2 figures, preliminary version appeared at ESA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reconsider the well-studied Selfish Routing game with affine latency
functions. The Price of Anarchy for this class of games takes maximum value
4/3; this maximum is attained already for a simple network of two parallel
links, known as Pigou's network. We improve upon the value 4/3 by means of
Coordination Mechanisms.
  We increase the latency functions of the edges in the network, i.e., if
$\ell_e(x)$ is the latency function of an edge $e$, we replace it by
$\hat{\ell}_e(x)$ with $\ell_e(x) \le \hat{\ell}_e(x)$ for all $x$. Then an
adversary fixes a demand rate as input. The engineered Price of Anarchy of the
mechanism is defined as the worst-case ratio of the Nash social cost in the
modified network over the optimal social cost in the original network.
Formally, if $\CM(r)$ denotes the cost of the worst Nash flow in the modified
network for rate $r$ and $\Copt(r)$ denotes the cost of the optimal flow in the
original network for the same rate then [\ePoA = \max_{r \ge 0}
\frac{\CM(r)}{\Copt(r)}.]
  We first exhibit a simple coordination mechanism that achieves for any
network of parallel links an engineered Price of Anarchy strictly less than
4/3. For the case of two parallel links our basic mechanism gives 5/4 = 1.25.
Then, for the case of two parallel links, we describe an optimal mechanism; its
engineered Price of Anarchy lies between 1.191 and 1.192.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2880</identifier>
 <datestamp>2012-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2880</id><created>2012-02-13</created><updated>2012-10-23</updated><authors><author><keyname>Webber</keyname><forenames>William</forenames></author></authors><title>Approximate Recall Confidence Intervals</title><categories>cs.IR</categories><comments>To appear in ACM Transactions on Information Systems</comments><acm-class>G.3; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recall, the proportion of relevant documents retrieved, is an important
measure of effectiveness in information retrieval, particularly in the legal,
patent, and medical domains. Where document sets are too large for exhaustive
relevance assessment, recall can be estimated by assessing a random sample of
documents; but an indication of the reliability of this estimate is also
required. In this article, we examine several methods for estimating two-tailed
recall confidence intervals. We find that the normal approximation in current
use provides poor coverage in many circumstances, even when adjusted to correct
its inappropriate symmetry. Analytic and Bayesian methods based on the ratio of
binomials are generally more accurate, but are inaccurate on small populations.
The method we recommend derives beta-binomial posteriors on retrieved and
unretrieved yield, with fixed hyperparameters, and a Monte Carlo estimate of
the posterior distribution of recall. We demonstrate that this method gives
mean coverage at or near the nominal level, across several scenarios, while
being balanced and stable. We offer advice on sampling design, including the
allocation of assessments to the retrieved and unretrieved segments, and
compare the proposed beta-binomial with the officially reported normal
intervals for recent TREC Legal Track iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2887</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2887</id><created>2012-02-13</created><updated>2012-05-20</updated><authors><author><keyname>Emad</keyname><forenames>Amin</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Semi-Quantitative Group Testing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a novel group testing procedure, termed semi-quantitative group
testing, motivated by a class of problems arising in genome sequence
processing. Semi-quantitative group testing (SQGT) is a non-binary pooling
scheme that may be viewed as a combination of an adder model followed by a
quantizer. For the new testing scheme we define the capacity and evaluate the
capacity for some special choices of parameters using information theoretic
methods. We also define a new class of disjunct codes suitable for SQGT, termed
SQ-disjunct codes. We also provide both explicit and probabilistic code
construction methods for SQGT with simple decoding algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2888</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2888</id><created>2012-02-13</created><authors><author><keyname>Sekar</keyname><forenames>Shreyas</forenames></author><author><keyname>Maill&#xe9;</keyname><forenames>Patrick</forenames></author></authors><title>Exploiting the `Web of Trust' to improve efficiency in collaborative
  networks</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintaining high quality content is one of the foremost objectives of any
web-based collaborative service that depends on a large number of users. In
such systems, it is nearly impossible for automated scripts to judge semantics
as it is to expect all editors to review the content. This catalyzes the need
for trust-based mechanisms to ensure quality of an article immediately after an
edit. In this paper, we build on previous work and develop a framework based on
the `web of trust' concept to calculate satisfaction scores for all users
without the need for perusing the article. We derive some bounds for systems
based on our mechanism and show that the optimization problem of selecting the
best users to review an article is NP-Hard. Extensive simulations validate our
model and results, and show that trust-based mechanisms are essential to
improve efficiency in any online collaborative editing platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2892</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2892</id><created>2012-02-13</created><authors><author><keyname>Ignatov</keyname><forenames>Dmitry I.</forenames></author><author><keyname>Poelmans</keyname><forenames>Jonas</forenames></author><author><keyname>Zaharchuk</keyname><forenames>Vasily</forenames></author></authors><title>Recommender System Based on Algorithm of Bicluster Analysis RecBi</title><categories>cs.AI cs.IR stat.ML</categories><msc-class>68T05</msc-class><acm-class>H.2.8</acm-class><journal-ref>CEUR Workshop proceedings Vol-757, CDUD'11 - Concept Discovery in
  Unstructured Data, pp. 122-126, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose two new algorithms based on biclustering analysis,
which can be used at the basis of a recommender system for educational
orientation of Russian School graduates. The first algorithm was designed to
help students make a choice between different university faculties when some of
their preferences are known. The second algorithm was developed for the special
situation when nothing is known about their preferences. The final version of
this recommender system will be used by Higher School of Economics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2895</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2895</id><created>2012-02-13</created><authors><author><keyname>Poelmans</keyname><forenames>Jonas</forenames></author><author><keyname>Elzinga</keyname><forenames>Paul</forenames></author><author><keyname>Neznanov</keyname><forenames>Alexey</forenames></author><author><keyname>Viaene</keyname><forenames>Stijn</forenames></author><author><keyname>Kuznetsov</keyname><forenames>Sergei O.</forenames></author><author><keyname>Ignatov</keyname><forenames>Dmitry</forenames></author><author><keyname>Dedene</keyname><forenames>Guido</forenames></author></authors><title>Concept Relation Discovery and Innovation Enabling Technology (CORDIET)</title><categories>cs.AI cs.IR stat.ML</categories><msc-class>68T05</msc-class><acm-class>H.2.8; H.3.1; I.2.6</acm-class><journal-ref>In CEUR Workshop proceedings Vol-757, CDUD'11 - Concept Discovery
  in Unstructured Data, pp. 53-62, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concept Relation Discovery and Innovation Enabling Technology (CORDIET), is a
toolbox for gaining new knowledge from unstructured text data. At the core of
CORDIET is the C-K theory which captures the essential elements of innovation.
The tool uses Formal Concept Analysis (FCA), Emergent Self Organizing Maps
(ESOM) and Hidden Markov Models (HMM) as main artifacts in the analysis
process. The user can define temporal, text mining and compound attributes. The
text mining attributes are used to analyze the unstructured text in documents,
the temporal attributes use these document's timestamps for analysis. The
compound attributes are XML rules based on text mining and temporal attributes.
The user can cluster objects with object-cluster rules and can chop the data in
pieces with segmentation rules. The artifacts are optimized for efficient data
analysis; object labels in the FCA lattice and ESOM map contain an URL on which
the user can click to open the selected document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2903</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2903</id><created>2012-02-13</created><authors><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Scaling Laws in Human Language</title><categories>physics.data-an cs.IR physics.soc-ph</categories><comments>6 pages, 4 figures</comments><journal-ref>Scientific Reports 3 (2013) 1082</journal-ref><doi>10.1038/srep01082</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zipf's law on word frequency is observed in English, French, Spanish,
Italian, and so on, yet it does not hold for Chinese, Japanese or Korean
characters. A model for writing process is proposed to explain the above
difference, which takes into account the effects of finite vocabulary size.
Experiments, simulations and analytical solution agree well with each other.
The results show that the frequency distribution follows a power law with
exponent being equal to 1, at which the corresponding Zipf's exponent diverges.
Actually, the distribution obeys exponential form in the Zipf's plot. Deviating
from the Heaps' law, the number of distinct words grows with the text length in
three stages: It grows linearly in the beginning, then turns to a logarithmical
form, and eventually saturates. This work refines previous understanding about
Zipf's law and Heaps' law in language systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2907</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2907</id><created>2012-02-13</created><updated>2013-09-04</updated><authors><author><keyname>Song</keyname><forenames>Yun</forenames></author><author><keyname>Li</keyname><forenames>Zhihui</forenames></author></authors><title>The weight Enumerator of some irreducible cyclic codes</title><categories>cs.CR cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to the inaccurate
  expression of Lemma 2.5(ii) and Theorem 3.12(i), and the first equation in
  (4) is wrong</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Irreducible cyclic codes are one of the largest known classes of block codes
which have been investigated for a long time. However, their weight
distributions are known only for a few cases. In this paper, a class of
irreducible cyclic codes are studied and their weight distributions are
determined. Moreover, all codewords of some irreducible cyclic codes are
obtained through programming in order to explain their distributions. The
number of distinct nonzero weights in these codes dealt with in this paper
varies among 1,2,3,6,8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2910</identifier>
 <datestamp>2015-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2910</id><created>2012-02-13</created><updated>2012-05-26</updated><authors><author><keyname>Butterfield</keyname><forenames>Jane V.</forenames></author><author><keyname>Cranston</keyname><forenames>Daniel W.</forenames></author><author><keyname>Puleo</keyname><forenames>Gregory J.</forenames></author><author><keyname>West</keyname><forenames>Douglas B.</forenames></author><author><keyname>Zamani</keyname><forenames>Reza</forenames></author></authors><title>Revolutionaries and spies: Spy-good and spy-bad graphs</title><categories>cs.DM math.CO</categories><comments>34 pages, 2 figures. The most important changes in this revision are
  improvements of the results on hypercubes and random graphs. The proof of the
  previous hypercube result has been deleted, but the statement remains because
  it is stronger for m&lt;52. In the random graph section we added a spy-strategy
  result</comments><journal-ref>Theoretical Computer Science, Vol. 463, 2012, pp. 35-53</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a game on a graph $G$ played by $r$ {\it revolutionaries} and $s$
{\it spies}. Initially, revolutionaries and then spies occupy vertices. In each
subsequent round, each revolutionary may move to a neighboring vertex or not
move, and then each spy has the same option. The revolutionaries win if $m$ of
them meet at some vertex having no spy (at the end of a round); the spies win
if they can avoid this forever.
  Let $\sigma(G,m,r)$ denote the minimum number of spies needed to win. To
avoid degenerate cases, assume $|V(G)|\ge r-m+1\ge\floor{r/m}\ge 1$. The easy
bounds are then $\floor{r/m}\le \sigma(G,m,r)\le r-m+1$. We prove that the
lower bound is sharp when $G$ has a rooted spanning tree $T$ such that every
edge of $G$ not in $T$ joins two vertices having the same parent in $T$. As a
consequence, $\sigma(G,m,r)\le\gamma(G)\floor{r/m}$, where $\gamma(G)$ is the
domination number; this bound is nearly sharp when $\gamma(G)\le m$.
  For the random graph with constant edge-probability $p$, we obtain constants
$c$ and $c'$ (depending on $m$ and $p$) such that $\sigma(G,m,r)$ is near the
trivial upper bound when $r&lt;c\ln n$ and at most $c'$ times the trivial lower
bound when $r&gt;c'\ln n$. For the hypercube $Q_d$ with $d\ge r$, we have
$\sigma(G,m,r)=r-m+1$ when $m=2$, and for $m\ge 3$ at least $r-39m$ spies are
needed.
  For complete $k$-partite graphs with partite sets of size at least $2r$, the
leading term in $\sigma(G,m,r)$ is approximately $\frac{k}{k-1}\frac{r}{m}$
when $k\ge m$. For $k=2$, we have
$\sigma(G,2,r)=\bigl\lceil{\frac{\floor{7r/2}-3}5}\bigr\rceil$ and
$\sigma(G,3,r)=\floor{r/2}$, and in general $\frac{3r}{2m}-3\le
\sigma(G,m,r)\le\frac{(1+1/\sqrt3)r}{m}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2914</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2914</id><created>2012-02-13</created><authors><author><keyname>Wang</keyname><forenames>Yue</forenames></author></authors><title>On Effectiveness of Backlog Bounds Using Stochastic Network Calculus in
  802.11</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network calculus is a powerful methodology of characterizing queueing
processes and has wide applications, but few works on applying it to 802.11 by
far. In this paper, we take one of the first steps to analyze the backlog
bounds of an 802.11 wireless LAN using stochastic network calculus. In
particular, we want to address its effectiveness on bounding backlogs. We model
a wireless node as a single server with impairment service based on two
best-known models in stochastic network calculus: Jiang's and Ciucu's.
Interestingly, we find that the two models can derive equivalent stochastic
service curves and backlog bounds in our studied case. We prove that the
network-calculus bounds imply stable backlogs as long as the average rate of
traffic arrival is less than that of service, indicating the theoretical
effectiveness of stochastic network calculus in bounding backlogs. From A.
Kumar's 802.11 model, we derive the concrete stochastic service curve of an
802.11 node and its backlog bounds. We compare the derived bounds with ns-2
simulations and find that the former are very loose and we discuss the reasons.
And we show that the martingale and independent case analysis techniques can
improve the bounds significantly. Our work offers a good reference to applying
stochastic network calculus to practical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2917</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2917</id><created>2012-02-13</created><authors><author><keyname>Bahr</keyname><forenames>Patrick</forenames><affiliation>Department of Computer Science, University of Copenhagen</affiliation></author><author><keyname>Hvitved</keyname><forenames>Tom</forenames><affiliation>Department of Computer Science, University of Copenhagen</affiliation></author></authors><title>Parametric Compositional Data Types</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 76, 2012, pp. 3-24</journal-ref><doi>10.4204/EPTCS.76.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work we have illustrated the benefits that compositional data
types (CDTs) offer for implementing languages and in general for dealing with
abstract syntax trees (ASTs). Based on Swierstra's data types \'a la carte,
CDTs are implemented as a Haskell library that enables the definition of
recursive data types and functions on them in a modular and extendable fashion.
Although CDTs provide a powerful tool for analysing and manipulating ASTs, they
lack a convenient representation of variable binders. In this paper we remedy
this deficiency by combining the framework of CDTs with Chlipala's parametric
higher-order abstract syntax (PHOAS). We show how a generalisation from
functors to difunctors enables us to capture PHOAS while still maintaining the
features of the original implementation of CDTs, in particular its modularity.
Unlike previous approaches, we avoid so-called exotic terms without resorting
to abstract types: this is crucial when we want to perform transformations on
CDTs that inspect the recursively computed CDTs, e.g. constant folding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2918</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2918</id><created>2012-02-13</created><authors><author><keyname>Casinghino</keyname><forenames>Chris</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Sj&#xf6;berg</keyname><forenames>Vilhelm</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Weirich</keyname><forenames>Stephanie</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Step-Indexed Normalization for a Language with General Recursion</title><categories>cs.PL cs.LO</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 76, 2012, pp. 25-39</journal-ref><doi>10.4204/EPTCS.76.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Trellys project has produced several designs for practical dependently
typed languages. These languages are broken into two
fragments-a_logical_fragment where every term normalizes and which is
consistent when interpreted as a logic, and a_programmatic_fragment with
general recursion and other convenient but unsound features. In this paper, we
present a small example language in this style. Our design allows the
programmer to explicitly mention and pass information between the two
fragments. We show that this feature substantially complicates the metatheory
and present a new technique, combining the traditional Girard-Tait method with
step-indexed logical relations, which we use to show normalization for the
logical fragment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2919</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2919</id><created>2012-02-13</created><authors><author><keyname>Jaskelioff</keyname><forenames>Mauro</forenames><affiliation>Centro Internacional Franco Argentino de Ciencias de la Informaci&#xf3;n y de Sistemas/Universidad Nacional de Rosario, Rosario, Argentina</affiliation></author><author><keyname>Rypacek</keyname><forenames>Ondrej</forenames><affiliation>King's College, London, UK</affiliation></author></authors><title>An Investigation of the Laws of Traversals</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 76, 2012, pp. 40-49</journal-ref><doi>10.4204/EPTCS.76.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traversals of data structures are ubiquitous in programming. Consequently, it
is important to be able to characterise those structures that are traversable
and understand their algebraic properties. Traversable functors have been
characterised by McBride and Paterson as those equipped with a distributive law
over arbitrary applicative functors; however, laws that fully capture the
intuition behind traversals are missing. This article is an attempt to remedy
this situation by proposing laws for characterising traversals that capture the
intuition behind them. To support our claims, we prove that finitary containers
are traversable in our sense and argue that elements in a traversable structure
are visited exactly once.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2920</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2920</id><created>2012-02-13</created><authors><author><keyname>Magalh&#xe3;es</keyname><forenames>Jos&#xe9; Pedro</forenames></author><author><keyname>L&#xf6;h</keyname><forenames>Andres</forenames></author></authors><title>A Formal Comparison of Approaches to Datatype-Generic Programming</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><acm-class>D.1.1</acm-class><journal-ref>EPTCS 76, 2012, pp. 50-67</journal-ref><doi>10.4204/EPTCS.76.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Datatype-generic programming increases program abstraction and reuse by
making functions operate uniformly across different types. Many approaches to
generic programming have been proposed over the years, most of them for
Haskell, but recently also for dependently typed languages such as Agda.
Different approaches vary in expressiveness, ease of use, and implementation
techniques.
  Some work has been done in comparing the different approaches informally.
However, to our knowledge there have been no attempts to formally prove
relations between different approaches. We thus present a formal comparison of
generic programming libraries. We show how to formalise different approaches in
Agda, including a coinductive representation, and then establish theorems that
relate the approaches to each other. We provide constructive proofs of
inclusion of one approach in another that can be used to convert between
approaches, helping to reduce code duplication across different libraries. Our
formalisation also helps in providing a clear picture of the potential of each
approach, especially in relating different generic views and their
expressiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2921</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2921</id><created>2012-02-13</created><authors><author><keyname>Petricek</keyname><forenames>Tomas</forenames><affiliation>University of Cambridge</affiliation></author></authors><title>Evaluation strategies for monadic computations</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><acm-class>I.1.3; D.3.2</acm-class><journal-ref>EPTCS 76, 2012, pp. 68-89</journal-ref><doi>10.4204/EPTCS.76.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monads have become a powerful tool for structuring effectful computations in
functional programming, because they make the order of effects explicit. When
translating pure code to a monadic version, we need to specify evaluation order
explicitly. Two standard translations give call-by-value and call-by-name
semantics. The resulting programs have different structure and types, which
makes revisiting the choice difficult.
  In this paper, we translate pure code to monadic using an additional
operation malias that abstracts out the evaluation strategy. The malias
operation is based on computational comonads; we use a categorical framework to
specify the laws that are required to hold about the operation.
  For any monad, we show implementations of malias that give call-by-value and
call-by-name semantics. Although we do not give call-by-need semantics for all
monads, we show how to turn certain monads into an extended monad with
call-by-need semantics, which partly answers an open question. Moreover, using
our unified translation, it is possible to change the evaluation strategy of
functional code translated to the monadic form without changing its structure
or types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2922</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2922</id><created>2012-02-13</created><authors><author><keyname>Pir&#xf3;g</keyname><forenames>Maciej</forenames><affiliation>Department of Computer Science, University of Oxford</affiliation></author><author><keyname>Gibbons</keyname><forenames>Jeremy</forenames><affiliation>Department of Computer Science, University of Oxford</affiliation></author></authors><title>Tracing monadic computations and representing effects</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><acm-class>D.1.1; D.3.3</acm-class><journal-ref>EPTCS 76, 2012, pp. 90-111</journal-ref><doi>10.4204/EPTCS.76.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In functional programming, monads are supposed to encapsulate computations,
effectfully producing the final result, but keeping to themselves the means of
acquiring it. For various reasons, we sometimes want to reveal the internals of
a computation. To make that possible, in this paper we introduce monad
transformers that add the ability to automatically accumulate observations
about the course of execution as an effect. We discover that if we treat the
resulting trace as the actual result of the computation, we can find new
functionality in existing monads, notably when working with non-terminating
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2923</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2923</id><created>2012-02-13</created><authors><author><keyname>Sj&#xf6;berg</keyname><forenames>Vilhelm</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Casinghino</keyname><forenames>Chris</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Ahn</keyname><forenames>Ki Yung</forenames><affiliation>Portland State University</affiliation></author><author><keyname>Collins</keyname><forenames>Nathan</forenames><affiliation>Portland State University</affiliation></author><author><keyname>Eades</keyname><forenames>Harley D.</forenames><suffix>III</suffix><affiliation>University of Iowa</affiliation></author><author><keyname>Fu</keyname><forenames>Peng</forenames><affiliation>University of Iowa</affiliation></author><author><keyname>Kimmell</keyname><forenames>Garrin</forenames><affiliation>University of Iowa</affiliation></author><author><keyname>Sheard</keyname><forenames>Tim</forenames><affiliation>Portland State University</affiliation></author><author><keyname>Stump</keyname><forenames>Aaron</forenames><affiliation>University of Iowa</affiliation></author><author><keyname>Weirich</keyname><forenames>Stephanie</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Irrelevance, Heterogeneous Equality, and Call-by-value Dependent Type
  Systems</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><acm-class>D.3.1</acm-class><journal-ref>EPTCS 76, 2012, pp. 112-162</journal-ref><doi>10.4204/EPTCS.76.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a full-spectrum dependently typed core language which includes
both nontermination and computational irrelevance (a.k.a. erasure), a
combination which has not been studied before. The two features interact: to
protect type safety we must be careful to only erase terminating expressions.
Our language design is strongly influenced by the choice of CBV evaluation, and
by our novel treatment of propositional equality which has a heterogeneous,
completely erased elimination form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2924</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2924</id><created>2012-02-13</created><authors><author><keyname>Swierstra</keyname><forenames>Wouter</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>From Mathematics to Abstract Machine: A formal derivation of an
  executable Krivine machine</title><categories>cs.PL</categories><comments>In Proceedings MSFP 2012, arXiv:1202.2407</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 76, 2012, pp. 163-177</journal-ref><doi>10.4204/EPTCS.76.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the derivation of an executable Krivine abstract machine
from a small step interpreter for the simply typed lambda calculus in the
dependently typed programming language Agda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2926</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2926</id><created>2012-02-13</created><authors><author><keyname>Mahanta</keyname><forenames>Anjana K.</forenames></author><author><keyname>Dutta</keyname><forenames>Mala</forenames></author></authors><title>Detection of Calendar-Based Periodicities of Interval-Based Temporal
  Patterns</title><categories>cs.DB</categories><journal-ref>International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP) Vol.2, No.1, pp. 17-31,January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel technique to identify calendar-based (annual, monthly and
daily) periodicities of an interval-based temporal pattern. An interval-based
temporal pattern is a pattern that occurs across a time-interval, then
disappears for some time, again recurs across another time-interval and so on
and so forth. Given the sequence of time-intervals in which an interval-based
temporal pattern has occurred, we propose a method for identifying the extent
to which the pattern is periodic with respect to a calendar cycle. In
comparison to previous work, our method is asymptotically faster. We also show
an interesting relationship between periodicities across different levels of
any hierarchical timestamp (year/month/day, hour/minute/second etc.).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2928</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2928</id><created>2012-02-13</created><updated>2012-11-26</updated><authors><author><keyname>Goldberg</keyname><forenames>Sharon</forenames></author><author><keyname>Liu</keyname><forenames>Zhenming</forenames></author></authors><title>The Diffusion of Networking Technologies</title><categories>cs.SI cs.DS cs.NI physics.soc-ph</categories><acm-class>G.1.6; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been significant interest in the networking community on the impact
of cascade effects on the diffusion of networking technology upgrades in the
Internet. Thinking of the global Internet as a graph, where each node
represents an economically-motivated Internet Service Provider (ISP), a key
problem is to determine the smallest set of nodes that can trigger a cascade
that causes every other node in the graph to adopt the protocol. We design the
first approximation algorithm with a provable performance guarantee for this
problem, in a model that captures the following key issue: a node's decision to
upgrade should be influenced by the decisions of the remote nodes it wishes to
communicate with.
  Given an internetwork G(V,E) and threshold function \theta, we assume that
node $u$ activates (upgrades to the new technology) when it is adjacent to a
connected component of active nodes in G of size exceeding node $u$'s threshold
\theta(u). Our objective is to choose the smallest set of nodes that can cause
the rest of the graph to activate. Our main contribution is an approximation
algorithm based on linear programming, which we complement with computational
hardness results and a near-optimum integrality gap. Our algorithm, which does
not rely on submodular optimization techniques, also highlights the substantial
algorithmic difference between our problem and similar questions studied in the
context of social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2944</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2944</id><created>2012-02-14</created><authors><author><keyname>Duyck</keyname><forenames>Dieter</forenames></author><author><keyname>Heindlmaier</keyname><forenames>Michael</forenames></author><author><keyname>Capirone</keyname><forenames>Daniele</forenames></author><author><keyname>Moeneclaey</keyname><forenames>Marc</forenames></author></authors><title>Diversity Analysis, Code Design and Tight Error Rate Lower Bound for
  Binary Joint Network-Channel Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to Eurasip Journ. on Wir. Comm. and Netw</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint network-channel codes (JNCC) can improve the performance of
communication in wireless networks, by combining, at the physical layer, the
channel codes and the network code as an overall error-correcting code. JNCC is
increasingly proposed as an alternative to a standard layered construction,
such as the OSI-model. The main performance metrics for JNCCs are scalability
to larger networks and error rate. The diversity order is one of the most
important parameters determining the error rate. The literature on JNCC is
growing, but a rigorous diversity analysis is lacking, mainly because of the
many degrees of freedom in wireless networks, which makes it very hard to prove
general statements on the diversity order. In this paper, we consider a network
with slowly varying fading point-to-point links, where all sources also act as
relay and additional non-source relays may be present. We propose a general
structure for JNCCs to be applied in such network. In the relay phase, each
relay transmits a linear transform of a set of source codewords. Our main
contributions are the proposition of an upper and lower bound on the diversity
order, a scalable code design and a new lower bound on the word error rate to
asses the performance of the network code. The lower bound on the diversity
order is only valid for JNCCs where the relays transform only two source
codewords. We then validate this analysis with an example which compares the
JNCC performance to that of a standard layered construction. Our numerical
results suggest that as networks grow, it is difficult to perform significantly
better than a standard layered construction, both on a fundamental level,
expressed by the outage probability, as on a practical level, expressed by the
word error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2963</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2963</id><created>2012-02-14</created><authors><author><keyname>Zhou</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Xia</keyname><forenames>Shu-Tao</forenames></author><author><keyname>Jiang</keyname><forenames>Yong</forenames></author><author><keyname>Zheng</keyname><forenames>Hai-Tao</forenames></author></authors><title>Maximum Multiflow in Wireless Network Coding</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multihop wireless network, wireless interference is crucial to the
maximum multiflow (MMF) problem, which studies the maximum throughput between
multiple pairs of sources and sinks. In this paper, we observe that network
coding could help to decrease the impacts of wireless interference, and propose
a framework to study the MMF problem for multihop wireless networks with
network coding. Firstly, a network model is set up to describe the new conflict
relations modified by network coding. Then, we formulate a linear programming
problem to compute the maximum throughput and show its superiority over one in
networks without coding. Finally, the MMF problem in wireless network coding is
shown to be NP-hard and a polynomial approximation algorithm is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2981</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2981</id><created>2012-02-14</created><authors><author><keyname>Caprarescu</keyname><forenames>Bogdan Alexandru</forenames></author><author><keyname>Kaslik</keyname><forenames>Eva</forenames></author><author><keyname>Petcu</keyname><forenames>Dana</forenames></author></authors><title>Theoretical Analysis and Tuning of Decentralized Probabilistic
  Auto-Scaling</title><categories>cs.DC</categories><comments>Submitted to Journal of Computer and System Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major impediment towards the industrial adoption of decentralized
distributed systems comes from the difficulty to theoretically prove that these
systems exhibit the required behavior. In this paper, we use probability theory
to analyze a decentralized auto-scaling algorithm in which each node
probabilistically decides to scale in or out. We prove that, in the context of
dynamic workloads, the average load of the system is maintained within a
variation interval with a given probability, provided that the number of nodes
and the variation interval length are higher than certain bounds. The paper
also proposes numerical algorithms for approximating these minimum bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.2998</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.2998</id><created>2012-02-14</created><updated>2012-04-29</updated><authors><author><keyname>Wu</keyname><forenames>Huasen</forenames></author><author><keyname>Zhu</keyname><forenames>Chenxi</forenames></author><author><keyname>La</keyname><forenames>Richard J.</forenames></author><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Zhang</keyname><forenames>Youguang</forenames></author></authors><title>Fast Adaptive S-ALOHA Scheme for Event-driven Machine-to-Machine
  Communications</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, accepted to IEEE VTC2012-Fall</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Machine-to-Machine (M2M) communication is now playing a market-changing role
in a wide range of business world. However, in event-driven M2M communications,
a large number of devices activate within a short period of time, which in turn
causes high radio congestions and severe access delay. To address this issue,
we propose a Fast Adaptive S-ALOHA (FASA) scheme for M2M communication systems
with bursty traffic. The statistics of consecutive idle and collision slots,
rather than the observation in a single slot, are used in FASA to accelerate
the tracking process of network status. Furthermore, the fast convergence
property of FASA is guaranteed by using drift analysis. Simulation results
demonstrate that the proposed FASA scheme achieves near-optimal performance in
reducing access delay, which outperforms that of traditional additive schemes
such as PB-ALOHA. Moreover, compared to multiplicative schemes, FASA shows its
robustness even under heavy traffic load in addition to better delay
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3013</identifier>
 <datestamp>2015-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3013</id><created>2012-02-14</created><authors><author><keyname>Cain</keyname><forenames>Alan J.</forenames></author><author><keyname>Maltcev</keyname><forenames>Victor</forenames></author></authors><title>Markov semigroups, monoids, and groups</title><categories>math.GR cs.FL</categories><comments>40 pages; 3 figures</comments><msc-class>20M35 (Primary) 68Q45, 20M05 (Secondary)</msc-class><journal-ref>International Journal of Algebra and Computation, 24, no. 5
  (August 2014)</journal-ref><doi>10.1142/S021819671450026X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A group is Markov if it admits a prefix-closed regular language of unique
representatives with respect to some generating set, and strongly Markov if it
admits such a language of unique minimal-length representatives over every
generating set. This paper considers the natural generalizations of these
concepts to semigroups and monoids. Two distinct potential generalizations to
monoids are shown to be equivalent. Various interesting examples are presented,
including an example of a non-Markov monoid that nevertheless admits a regular
language of unique representatives over any generating set. It is shown that
all finitely generated commutative semigroups are strongly Markov, but that
finitely generated subsemigroups of virtually abelian or polycyclic groups need
not be. Potential connections with word-hyperbolic semigroups are investigated.
A study is made of the interaction of the classes of Markov and strongly Markov
semigroups with direct products, free products, and finite-index subsemigroups
and extensions. Several questions are posed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3018</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3018</id><created>2012-02-14</created><authors><author><keyname>Ellings&#xe6;ter</keyname><forenames>Brage</forenames></author><author><keyname>Bezabih</keyname><forenames>Hemdan</forenames></author><author><keyname>Noll</keyname><forenames>Josef</forenames></author><author><keyname>Maseng</keyname><forenames>Torleiv</forenames></author></authors><title>Using TV Receiver Information to Increase Cognitive White Space Spectrum</title><categories>cs.NI</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the usage of cognitive radio devices within the
service area of TV broadcast stations. Until now the main approach for a
cognitive radio to operate in the TV bands has been to register TV broadcast
stations locations and thus protecting the broadcast stations service area.
Through information about TV receivers location, we show that a cognitive radio
should be able to operate within this service area without causing harmful
interference to the TV receivers as defined by Ofcom and FCC. We provide
simulations based on real statistics from Norway that show that especially in
rural areas TV receiver registration can provide a substantial gain in terms of
exploitable frequencies for a cognitive radio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3021</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3021</id><created>2012-02-14</created><authors><author><keyname>Gabarda</keyname><forenames>Salvador</forenames></author><author><keyname>Cristobal</keyname><forenames>Gabriel</forenames></author></authors><title>No-reference image quality assessment through the von Mises distribution</title><categories>cs.CV</categories><comments>29 pages, 11 figures</comments><doi>10.1364/JOSAA.29.002058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An innovative way of calculating the von Mises distribution (VMD) of image
entropy is introduced in this paper. The VMD's concentration parameter and some
fitness parameter that will be later defined, have been analyzed in the
experimental part for determining their suitability as a image quality
assessment measure in some particular distortions such as Gaussian blur or
additive Gaussian noise. To achieve such measure, the local R\'{e}nyi entropy
is calculated in four equally spaced orientations and used to determine the
parameters of the von Mises distribution of the image entropy. Considering
contextual images, experimental results after applying this model show that the
best-in-focus noise-free images are associated with the highest values for the
von Mises distribution concentration parameter and the highest approximation of
image data to the von Mises distribution model. Our defined von Misses fitness
parameter experimentally appears also as a suitable no-reference image quality
assessment indicator for no-contextual images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3046</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3046</id><created>2012-02-14</created><authors><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Chitrita</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak K.</forenames></author></authors><title>Segmentation of Offline Handwritten Bengali Script</title><categories>cs.CV cs.AI</categories><comments>Proceedings of 28th IEEE ACE, pp. 171-174, December 2002, Science
  City, Kolkata</comments><journal-ref>Proceedings of 28th IEEE ACE, pp. 171-174, December 2002, Science
  City, Kolkata</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Character segmentation has long been one of the most critical areas of
optical character recognition process. Through this operation, an image of a
sequence of characters, which may be connected in some cases, is decomposed
into sub-images of individual alphabetic symbols. In this paper, segmentation
of cursive handwritten script of world's fourth popular language, Bengali, is
considered. Unlike English script, Bengali handwritten characters and its
components often encircle the main character, making the conventional
segmentation methodologies inapplicable. Experimental results, using the
proposed segmentation technique, on sample cursive handwritten data containing
218 ideal segmentation points show a success rate of 97.7%. Further
feature-analysis on these segments may lead to actual recognition of
handwritten cursive Bengali script.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3048</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3048</id><created>2012-02-14</created><authors><author><keyname>Chaudhuri</keyname><forenames>Ritesh Ray</forenames></author><author><keyname>Basu</keyname><forenames>Joydeep</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Tarun Kanti</forenames></author></authors><title>Design and Fabrication of Micromachined Resonators</title><categories>cs.OH</categories><comments>7 pages, 12 figures</comments><journal-ref>Proceedings of the 6th International Conference on Smart
  Materials, Structures and Systems, January 04-07, 2012, Bangalore, India</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microelectromechanical system (MEMS) based on-chip resonators offer great
potential for sensing and high frequency signal processing applications due to
their exceptional features like small size, large frequency-quality factor
product, integrability with CMOS ICs, low power consumption etc. This work is
mainly aimed at the design, modeling, simulation, and fabrication of
micromachined polysilicon disk resonators exhibiting radial-contour mode
vibrations. A few other bulk mode modified resonator geometries are also being
explored. The resonator structures have been designed and simulated in
CoventorWare finite-element platform and fabricated by the PolyMUMPs surface
micromachining process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3052</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3052</id><created>2012-02-14</created><authors><author><keyname>Nielsen</keyname><forenames>Jesper Buus</forenames></author><author><keyname>Nordholt</keyname><forenames>Peter Sebastian</forenames></author><author><keyname>Orlandi</keyname><forenames>Claudio</forenames></author><author><keyname>Burra</keyname><forenames>Sai Sheshank</forenames></author></authors><title>A New Approach to Practical Active-Secure Two-Party Computation</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach to practical two-party computation secure against
an active adversary. All prior practical protocols were based on Yao's garbled
circuits. We use an OT-based approach and get efficiency via OT extension in
the random oracle model. To get a practical protocol we introduce a number of
novel techniques for relating the outputs and inputs of OTs in a larger
construction.
  We also report on an implementation of this approach, that shows that our
protocol is more efficient than any previous one: For big enough circuits, we
can evaluate more than 20000 Boolean gates per second. As an example,
evaluating one oblivious AES encryption (~34000 gates) takes 64 seconds, but
when repeating the task 27 times it only takes less than 3 seconds per
instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3059</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3059</id><created>2012-02-14</created><authors><author><keyname>La Rocca</keyname><forenames>Cristian E.</forenames></author><author><keyname>Braunstein</keyname><forenames>Lidia A.</forenames></author><author><keyname>Macri</keyname><forenames>Pablo A.</forenames></author></authors><title>Synchronization in Scale Free networks with degree correlation</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>11 pages, 6 figures</comments><journal-ref>Physica A 390 (2011) 2840-2844</journal-ref><doi>10.1016/j.physa.2011.03.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a model of synchronization process on scale free
networks with degree-degree correlations. This model was already studied on
this kind of networks without correlations by Pastore y Piontti {\it et al.},
Phys. Rev. E {\bf 76}, 046117 (2007). Here, we study the effects of the
degree-degree correlation on the behavior of the load fluctuations $W_s$ in the
steady state. We found that for assortative networks there exist a specific
correlation where the system is optimal synchronized. In addition, we found
that close to this optimally value the fluctuations does not depend on the
system size and therefore the system becomes fully scalable. This result could
be very important for some technological applications. On the other hand, far
from the optimal correlation, $W_s$ scales logarithmically with the system
size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3062</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3062</id><created>2012-02-14</created><authors><author><keyname>Karsai</keyname><forenames>M&#xe1;rton</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Correlated dynamics in egocentric communication networks</title><categories>physics.soc-ph cs.SI</categories><comments>7 pages, 6 figures</comments><doi>10.1371/journal.pone.0040612</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the communication sequences of millions of people through two
different channels and analyze the fine grained temporal structure of
correlated event trains induced by single individuals. By focusing on
correlations between the heterogeneous dynamics and the topology of egocentric
networks we find that the bursty trains usually evolve for pairs of individuals
rather than for the ego and his/her several neighbors thus burstiness is a
property of the links rather than of the nodes. We compare the directional
balance of calls and short messages within bursty trains to the average on the
actual link and show that for the trains of voice calls the imbalance is
significantly enhanced, while for short messages the balance within the trains
increases. These effects can be partly traced back to the technological
constrains (for short messages) and partly to the human behavioral features
(voice calls). We define a model that is able to reproduce the empirical
results and may help us to understand better the mechanisms driving technology
mediated human communication dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3074</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3074</id><created>2012-02-14</created><authors><author><keyname>Rothkegel</keyname><forenames>Alexander</forenames></author><author><keyname>Lehnertz</keyname><forenames>Klaus</forenames></author></authors><title>Conedy: a scientific tool to investigate Complex Network Dynamics</title><categories>physics.comp-ph cs.SI physics.soc-ph</categories><doi>10.1063/1.3685527</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Conedy, a performant scientific tool to numerically investigate
dynamics on complex networks. Conedy allows to create networks and provides
automatic code generation and compilation to ensure performant treatment of
arbitrary node dynamics. Conedy can be interfaced via an internal script
interpreter or via a Python module.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3079</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3079</id><created>2012-02-14</created><authors><author><keyname>Bubeck</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Cesa-Bianchi</keyname><forenames>Nicol&#xf2;</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author></authors><title>Towards minimax policies for online linear optimization with bandit
  feedback</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the online linear optimization problem with bandit feedback. Our
contribution is twofold. First, we provide an algorithm (based on exponential
weights) with a regret of order $\sqrt{d n \log N}$ for any finite action set
with $N$ actions, under the assumption that the instantaneous loss is bounded
by 1. This shaves off an extraneous $\sqrt{d}$ factor compared to previous
works, and gives a regret bound of order $d \sqrt{n \log n}$ for any compact
set of actions. Without further assumptions on the action set, this last bound
is minimax optimal up to a logarithmic factor. Interestingly, our result also
shows that the minimax regret for bandit linear optimization with expert advice
in $d$ dimension is the same as for the basic $d$-armed bandit with expert
advice. Our second contribution is to show how to use the Mirror Descent
algorithm to obtain computationally efficient strategies with minimax optimal
regret bounds in specific examples. More precisely we study two canonical
action sets: the hypercube and the Euclidean ball. In the former case, we
obtain the first computationally efficient algorithm with a $d \sqrt{n}$
regret, thus improving by a factor $\sqrt{d \log n}$ over the best known result
for a computationally efficient algorithm. In the latter case, our approach
gives the first algorithm with a $\sqrt{d n \log n}$ regret, again shaving off
an extraneous $\sqrt{d}$ compared to previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3082</identifier>
 <datestamp>2014-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3082</id><created>2012-02-14</created><authors><author><keyname>Karpov</keyname><forenames>D. V.</forenames></author></authors><title>Spanning trees with many leaves: new lower bounds in terms of number of
  vertices of degree~3 and at least~4</title><categories>math.CO cs.DM</categories><comments>33 pages, 15 figures</comments><msc-class>05C05</msc-class><journal-ref>Journal of Mathematical Sciences, Volume 196, Issue 6 (2014), pp
  747-767</journal-ref><doi>10.1007/s10958-014-1691-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove, that every connected graph with $s$ vertices of degree 3 and $t$
vertices of degree at least~4 has a spanning tree with at least ${2\over 5}t
+{1\over 5}s+\alpha$ leaves, where $\alpha \ge {8\over 5}$. Moreover, $\alpha
\ge 2$ for all graphs besides three exclusions. All exclusion are regular
graphs of degree~4, they are explicitly described in the paper.
  We present infinite series of graphs, containing only vertices of degrees~3
and~4, for which the maximal number of leaves in a spanning tree is equal for
${2\over 5}t +{1\over 5}s+2$. Therefore we prove that our bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3084</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3084</id><created>2012-02-14</created><updated>2013-05-15</updated><authors><author><keyname>Guerraoui</keyname><forenames>Rachid</forenames></author><author><keyname>Huc</keyname><forenames>Florian</forenames></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames></author></authors><title>On Dynamic Distributed Computing</title><categories>cs.DC</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows for the first time that distributed computing can be both
reliable and efficient in an environment that is both highly dynamic and
hostile. More specifically, we show how to maintain clusters of size $O(\log
N)$, each containing more than two thirds of honest nodes with high
probability, within a system whose size can vary \textit{polynomially} with
respect to its initial size. Furthermore, the communication cost induced by
each node arrival or departure is polylogarithmic with respect to $N$, the
maximal size of the system. Our clustering can be achieved despite the presence
of a Byzantine adversary controlling a fraction $\bad \leq \{1}{3}-\epsilon$ of
the nodes, for some fixed constant $\epsilon &gt; 0$, independent of $N$. So far,
such a clustering could only be performed for systems who size can vary
constantly and it was not clear whether that was at all possible for polynomial
variances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3097</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3097</id><created>2012-02-14</created><updated>2012-05-05</updated><authors><author><keyname>Slivovsky</keyname><forenames>Friedrich</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Computing Resolution-Path Dependencies in Linear Time</title><categories>cs.DS</categories><comments>14 pages, SAT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The alternation of existential and universal quantifiers in a quantified
boolean formula (QBF) generates dependencies among variables that must be
respected when evaluating the formula. Dependency schemes provide a general
framework for representing such dependencies. Since it is generally intractable
to determine dependencies exactly, a set of potential dependencies is computed
instead, which may include false positives. Among the schemes proposed so far,
resolution-path dependencies introduce the fewest spurious dependencies. In
this work, we describe an algorithm that detects resolution-path dependencies
in linear time, resolving a problem posed by Van Gelder (CP 2011).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3102</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3102</id><created>2012-02-14</created><authors><author><keyname>Gangopadhyay</keyname><forenames>Kausik</forenames></author><author><keyname>Basu</keyname><forenames>Banasri</forenames></author></authors><title>Evolution of Zipf's Law for Indian Urban Agglomerations vis-\`{a}-vis
  Chinese Urban Agglomerations</title><categories>physics.soc-ph cs.SI</categories><comments>11 eps figures</comments><doi>10.1007/978-88-470-2553-0_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate into the rank-size distributions of urban agglomerations for
India between 1981 to 2011. The incidence of a power law tail is prominent. A
relevant question persists regarding the evolution of the power tail
coefficient. We have developed a methodology to meaningfully track the power
law coefficient over time, when a country experience population growth. A
relevant dynamic law, Gibrat's law, is empirically tested in this connection.
We argue that these empirical findings for India goes in contrast with the
findings in case of China, another country with population growth but
monolithic political system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3108</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3108</id><created>2012-02-14</created><authors><author><keyname>Hong</keyname><forenames>Dohy</forenames></author></authors><title>D-iteration based asynchronous distributed computation</title><categories>cs.DC cs.NA</categories><comments>4 pages</comments><acm-class>G.1.0; G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to explain how the D-iteration can be used for an
efficient asynchronous distributed computation. We present the main ideas of
the method and illustrate them through very simple examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3110</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3110</id><created>2012-02-14</created><updated>2014-01-11</updated><authors><author><keyname>Lund</keyname><forenames>Ben D.</forenames></author><author><keyname>Purdy</keyname><forenames>George B.</forenames></author><author><keyname>Smith</keyname><forenames>Justin W.</forenames></author></authors><title>A Pseudoline Counterexample to the Strong Dirac Conjecture</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate an infinite family of pseudoline arrangements, in which an
arrangement of n pseudolines has no member incident to more than 4n/9 points of
intersection. This shows the &quot;Strong Dirac&quot; conjecture to be false for
pseudolines.
  We also raise a number of open problems relating to possible differences
between the structure of incidences between points and lines versus the
structure of incidences between points and pseudolines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3119</identifier>
 <datestamp>2013-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3119</id><created>2012-02-14</created><updated>2013-10-16</updated><authors><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Romero</keyname><forenames>Alfonso E.</forenames></author></authors><title>Scientific impact evaluation and the effect of self-citations:
  mitigating the bias by discounting h-index</title><categories>cs.DL</categories><journal-ref>Journal of the American Society for Information Science and
  Technology, 64(11):2332-2339, 2013</journal-ref><doi>10.1002/asi.22976</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a measure to assess scientific impact that
discounts self-citations and does not require any prior knowledge on the their
distribution among publications. This index can be applied to both researchers
and journals. In particular, we show that it fills the gap of h-index and
similar measures that do not take into account the effect of self-citations for
authors or journals impact evaluation. The paper provides with two real-world
examples: in the former, we evaluate the research impact of the most productive
scholars in Computer Science (according to DBLP); in the latter, we revisit the
impact of the journals ranked in the 'Computer Science Applications' section of
SCImago. We observe how self-citations, in many cases, affect the rankings
obtained according to different measures (including h-index and ch-index), and
show how the proposed measure mitigates this effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3162</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3162</id><created>2012-02-14</created><updated>2013-08-12</updated><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Surachawala</keyname><forenames>Tawan</forenames></author></authors><title>Social Contagion: An Empirical Study of Information Spread on Digg and
  Twitter Follower Graphs</title><categories>cs.SI cs.CY physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks have emerged as a critical factor in information
dissemination, search, marketing, expertise and influence discovery, and
potentially an important tool for mobilizing people. Social media has made
social networks ubiquitous, and also given researchers access to massive
quantities of data for empirical analysis. These data sets offer a rich source
of evidence for studying dynamics of individual and group behavior, the
structure of networks and global patterns of the flow of information on them.
However, in most previous studies, the structure of the underlying networks was
not directly visible but had to be inferred from the flow of information from
one individual to another. As a result, we do not yet understand dynamics of
information spread on networks or how the structure of the network affects it.
We address this gap by analyzing data from two popular social news sites.
Specifically, we extract follower graphs of active Digg and Twitter users and
track how interest in news stories cascades through the graph. We compare and
contrast properties of information cascades on both sites and elucidate what
they tell us about dynamics of information flow on networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3173</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3173</id><created>2012-02-14</created><authors><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Lipshitz</keyname><forenames>Benjamin</forenames></author><author><keyname>Schwartz</keyname><forenames>Oded</forenames></author></authors><title>Communication-Optimal Parallel Algorithm for Strassen's Matrix
  Multiplication</title><categories>cs.DS cs.CC cs.DC cs.NA math.CO math.NA</categories><comments>13 pages, 3 figures</comments><msc-class>68W40, 68W10</msc-class><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel matrix multiplication is one of the most studied fundamental
problems in distributed and high performance computing. We obtain a new
parallel algorithm that is based on Strassen's fast matrix multiplication and
minimizes communication. The algorithm outperforms all known parallel matrix
multiplication algorithms, classical and Strassen-based, both asymptotically
and in practice.
  A critical bottleneck in parallelizing Strassen's algorithm is the
communication between the processors. Ballard, Demmel, Holtz, and Schwartz
(SPAA'11) prove lower bounds on these communication costs, using expansion
properties of the underlying computation graph. Our algorithm matches these
lower bounds, and so is communication-optimal. It exhibits perfect strong
scaling within the maximum possible range.
  Benchmarking our implementation on a Cray XT4, we obtain speedups over
classical and Strassen-based algorithms ranging from 24% to 184% for a fixed
matrix dimension n=94080, where the number of nodes ranges from 49 to 7203.
  Our parallelization approach generalizes to other fast matrix multiplication
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3174</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3174</id><created>2012-02-14</created><authors><author><keyname>Miller</keyname><forenames>Dale</forenames><affiliation>INRIA-Saclay, France</affiliation></author><author><keyname>&#xc9;sik</keyname><forenames>Zolt&#xe1;n</forenames><affiliation>University of Szeged, Hungary</affiliation></author></authors><title>Proceedings 8th Workshop on Fixed Points in Computer Science</title><categories>cs.LO cs.FL cs.PL</categories><comments>For more information about FICS 2012, please visit the webpage of the
  conference: http://www.inf.u-szeged.hu/fics2012/</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 77, 2012</journal-ref><doi>10.4204/EPTCS.77</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Eighth Workshop on Fixed Points
in Computer Science which took place on 24 March 2012 in Tallinn, Estonia as an
ETAPS-affiliated workshop. Past workshops have been held in Brno (1998,
MFCS/CSL workshop), Paris (2000, LC workshop), Florence (2001, PLI workshop),
Copenhagen (2002, LICS (FLoC) workshop), Warsaw (2003, ETAPS workshop), Coimbra
(2009, CSL workshop), and Brno (2010, MFCS-CSL workshop).
  Fixed points play a fundamental role in several areas of computer science and
logic by justifying induction and recursive definitions. The construction and
properties of fixed points have been investigated in many different frameworks
such as: design and implementation of programming languages, program logics,
and databases. The aim of this workshop is to provide a forum for researchers
to present their results to those members of the computer science and logic
communities who study or apply the theory of fixed points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3177</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3177</id><created>2012-02-14</created><authors><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Lipshitz</keyname><forenames>Benjamin</forenames></author><author><keyname>Schwartz</keyname><forenames>Oded</forenames></author></authors><title>Strong Scaling of Matrix Multiplication Algorithms and
  Memory-Independent Communication Lower Bounds</title><categories>cs.DS cs.CC cs.DC cs.NA math.CO math.NA</categories><comments>4 pages, 1 figure</comments><msc-class>68W10, 68W40</msc-class><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A parallel algorithm has perfect strong scaling if its running time on P
processors is linear in 1/P, including all communication costs.
Distributed-memory parallel algorithms for matrix multiplication with perfect
strong scaling have only recently been found. One is based on classical matrix
multiplication (Solomonik and Demmel, 2011), and one is based on Strassen's
fast matrix multiplication (Ballard, Demmel, Holtz, Lipshitz, and Schwartz,
2012). Both algorithms scale perfectly, but only up to some number of
processors where the inter-processor communication no longer scales.
  We obtain a memory-independent communication cost lower bound on classical
and Strassen-based distributed-memory matrix multiplication algorithms. These
bounds imply that no classical or Strassen-based parallel matrix multiplication
algorithm can strongly scale perfectly beyond the ranges already attained by
the two parallel algorithms mentioned above. The memory-independent bounds and
the strong scaling bounds generalize to other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3179</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3179</id><created>2012-02-14</created><authors><author><keyname>Wang</keyname><forenames>Ke</forenames><affiliation>School of Computing Science Simon Fraser University</affiliation></author><author><keyname>Han</keyname><forenames>Chao</forenames><affiliation>School of Computing Science Simon Fraser University</affiliation></author><author><keyname>Fu</keyname><forenames>Ada Waichee</forenames><affiliation>Department of Computer Science and Engineering Chinese University of Hong Kong</affiliation></author></authors><title>Randomization Resilient To Sensitive Reconstruction</title><categories>cs.DB</categories><comments>12 pages, 5 figures</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the randomization approach, sensitive data items of records are
randomized to protect privacy of individuals while allowing the distribution
information to be reconstructed for data analysis. In this paper, we
distinguish between reconstruction that has potential privacy risk, called
micro reconstruction, and reconstruction that does not, called aggregate
reconstruction. We show that the former could disclose sensitive information
about a target individual, whereas the latter is more useful for data analysis
than for privacy breaches. To limit the privacy risk of micro reconstruction,
we propose a privacy definition, called (epsilon,delta)-reconstruction-privacy.
Intuitively, this privacy notion requires that micro reconstruction has a large
error with a large probability. The promise of this approach is that micro
reconstruction is more sensitive to the number of independent trials in the
randomization process than aggregate reconstruction is; therefore, reducing the
number of independent trials helps achieve
(epsilon,delta)-reconstruction-privacy while preserving the accuracy of
aggregate reconstruction. We present an algorithm based on this idea and
evaluate the effectiveness of this approach using real life data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3184</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3184</id><created>2012-02-14</created><updated>2012-11-16</updated><authors><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author><author><keyname>Whiting</keyname><forenames>Philip A.</forenames></author></authors><title>Asymptotic Behavior of the Maximum and Minimum Singular Value of Random
  Vandermonde Matrices</title><categories>math.PR cs.IT math.IT</categories><comments>Accepted for publication at Journal of Theoretical Probability</comments><msc-class>15B52, 15B51, 60B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work examines various statistical distributions in connection with
random Vandermonde matrices and their extension to $d$--dimensional phase
distributions. Upper and lower bound asymptotics for the maximum singular value
are found to be $O(\log^{1/2}{N^{d}})$ and $\Omega((\log N^{d} /(\log \log
N^d))^{1/2})$ respectively where $N$ is the dimension of the matrix,
generalizing the results in \cite{TW}. We further study the behavior of the
minimum singular value of these random matrices. In particular, we prove that
the minimum singular value is at most $N\exp(-C\sqrt{N}))$ with high
probability where $C$ is a constant independent on $N$. Furthermore, the value
of the constant $C$ is determined explicitly. The main result is obtained in
two different ways. One approach uses techniques from stochastic processes and
in particular, a construction related to the Brownian bridge. The other one is
a more direct analytical approach involving combinatorics and complex analysis.
As a consequence, we obtain a lower bound for the maximum absolute value of a
random complex polynomial on the unit circle, which may be of independent
mathematical interest. Lastly, for each sequence of positive integers
${k_p}_{p=1}^{\infty}$ we present a generalized version of the previously
discussed matrices. The classical random Vandermonde matrix corresponds to the
sequence $k_{p}=p-1$. We find a combinatorial formula for their moments and we
show that the limit eigenvalue distribution converges to a probability measure
supported on $[0,\infty)$. Finally, we show that for the sequence $k_p=2^{p}$
the limit eigenvalue distribution is the famous Marchenko--Pastur distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3185</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3185</id><created>2012-02-14</created><updated>2012-03-09</updated><authors><author><keyname>Shuai</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Xiaozhong</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>Improving News Ranking by Community Tweets</title><categories>cs.IR cs.SI</categories><comments>6 pages, 3 figures, 4 tables</comments><acm-class>H.3.3</acm-class><journal-ref>workshop on mining social network dynamics @www2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Users frequently express their information needs by means of short and
general queries that are difficult for ranking algorithms to interpret
correctly. However, users' social contexts can offer important additional
information about their information needs which can be leveraged by ranking
algorithms to provide augmented, personalized results. Existing methods mostly
rely on users' individual behavioral data such as clickstream and log data, but
as a result suffer from data sparsity and privacy issues. Here, we propose a
Community Tweets Voting Model (CTVM) to re-rank Google and Yahoo news search
results on the basis of open, large-scale Twitter community data. Experimental
results show that CTVM outperforms baseline rankings from Google and Yahoo for
certain online communities. We propose an application scenario of CTVM and
provide an agenda for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3188</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3188</id><created>2012-02-14</created><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>Clustering assortativity, communities and functional modules in
  real-world networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>21 pages, 15 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks of real-world systems are believed to be controlled by
common phenomena, producing structures far from regular or random. Clustering,
community structure and assortative mixing by degree are perhaps among most
prominent examples of the latter. Although generally accepted for social
networks, these properties only partially explain the structure of other
networks. We first show that degree-corrected clustering is in contrast to
standard definition highly assortative. Yet interesting on its own, we further
note that non-social networks contain connected regions with very low
clustering. Hence, the structure of real-world networks is beyond communities.
We here investigate the concept of functional modules---groups of regularly
equivalent nodes---and show that such structures could explain for the
properties observed in non-social networks. Real-world networks might be
composed of functional modules that are overlaid by communities. We support the
latter by proposing a simple network model that generates scale-free
small-world networks with tunable clustering and degree mixing. Model has a
natural interpretation in many real-world networks, while it also gives
insights into an adequate community extraction framework. We also present an
algorithm for detection of arbitrary structural modules without any prior
knowledge. Algorithm is shown to be superior to state-of-the-art, while
application to real-world networks reveals well supported composites of
different structural modules that are consistent with the underlying systems.
Clear functional modules are identified in all types of networks including
social. Our findings thus expose functional modules as another key ingredient
of complex real-world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3192</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3192</id><created>2012-02-14</created><authors><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author><author><keyname>Thomas</keyname><forenames>Robert J.</forenames></author></authors><title>From Packet to Power Switching: Digital Direct Load Scheduling</title><categories>math.OC cs.NI</categories><comments>Accepted by the IEEE journal of Selected Areas in Communications
  (JSAC): Smart Grid Communications series, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, the power grid has tight control over its dispatchable generation
capacity but a very coarse control on the demand. Energy consumers are shielded
from making price-aware decisions, which degrades the efficiency of the market.
This state of affairs tends to favor fossil fuel generation over renewable
sources. Because of the technological difficulties of storing electric energy,
the quest for mechanisms that would make the demand for electricity
controllable on a day-to-day basis is gaining prominence. The goal of this
paper is to provide one such mechanisms, which we call Digital Direct Load
Scheduling (DDLS). DDLS is a direct load control mechanism in which we unbundle
individual requests for energy and digitize them so that they can be
automatically scheduled in a cellular architecture. Specifically, rather than
storing energy or interrupting the job of appliances, we choose to hold
requests for energy in queues and optimize the service time of individual
appliances belonging to a broad class which we refer to as &quot;deferrable loads&quot;.
The function of each neighborhood scheduler is to optimize the time at which
these appliances start to function. This process is intended to shape the
aggregate load profile of the neighborhood so as to optimize an objective
function which incorporates the spot price of energy, and also allows
distributed energy resources to supply part of the generation dynamically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3205</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3205</id><created>2012-02-15</created><authors><author><keyname>Blelloch</keyname><forenames>Guy</forenames></author><author><keyname>Fineman</keyname><forenames>Jeremy</forenames></author><author><keyname>Shun</keyname><forenames>Julian</forenames></author></authors><title>Greedy Sequential Maximal Independent Set and Matching are Parallel on
  Average</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The greedy sequential algorithm for maximal independent set (MIS) loops over
the vertices in arbitrary order adding a vertex to the resulting set if and
only if no previous neighboring vertex has been added. In this loop, as in many
sequential loops, each iterate will only depend directly on a subset of the
previous iterates (i.e. knowing that any one of a vertices neighbors is in the
MIS or knowing that it has no previous neighbors is sufficient to decide its
fate). This leads to a dependence structure among the iterates. If this
structure is shallow then running the iterates in parallel while respecting the
dependencies can lead to an efficient parallel implementation mimicking the
sequential algorithm.
  In this paper, we show that for any graph, and for a random ordering of the
vertices, the dependence depth of the sequential greedy MIS algorithm is
polylogarithmic (O(log^2 n) with high probability). Our results extend previous
results that show polylogarithmic bounds only for random graphs. We show
similar results for a greedy maximal matching (MM). For both problems we
describe simple linear work parallel algorithms based on the approach. The
algorithms allow for a smooth tradeoff between more parallelism and reduced
work, but always return the same result as the sequential greedy algorithms. We
present experimental results that demonstrate efficiency and the tradeoff
between work and parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3208</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3208</id><created>2012-02-15</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Gawrychowski</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>Linear-Space Substring Range Counting over Polylogarithmic Alphabets</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bille and G{\o}rtz (2011) recently introduced the problem of substring range
counting, for which we are asked to store compactly a string $S$ of $n$
characters with integer labels in ([0, u]), such that later, given an interval
([a, b]) and a pattern $P$ of length $m$, we can quickly count the occurrences
of $P$ whose first characters' labels are in ([a, b]). They showed how to store
$S$ in $\Oh{n \log n / \log \log n}$ space and answer queries in $\Oh{m + \log
\log u}$ time. We show that, if $S$ is over an alphabet of size (\polylog (n)),
then we can achieve optimal linear space. Moreover, if (u = n \polylog (n)),
then we can also reduce the time to $\Oh{m}$. Our results give linear space and
time bounds for position-restricted substring counting and the counting
versions of indexing substrings with intervals, indexing substrings with gaps
and aligned pattern matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3215</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3215</id><created>2012-02-15</created><authors><author><keyname>Vizhi</keyname><forenames>J. Malar</forenames></author><author><keyname>Bhuvaneswari</keyname><forenames>T.</forenames></author></authors><title>Data quality measurement on categorical data using genetic algorithm</title><categories>cs.DB</categories><comments>10 pages. arXiv admin note: text overlap with arXiv:1011.0328 by
  other authors</comments><journal-ref>International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP) Vol.2, No.1, January 2012</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Data quality on categorical attribute is a difficult problem that has not
received as much attention as numerical counterpart. Our basic idea is to
employ association rule for the purpose of data quality measurement. Strong
rule generation is an important area of data mining. Association rule mining
problems can be considered as a multi objective problem rather than as a single
objective one. The main area of concentration was the rules generated by
association rule mining using genetic algorithm. The advantage of using genetic
algorithm is to discover high level prediction rules is that they perform a
global search and cope better with attribute interaction than the greedy rule
induction algorithm often used in data mining. Genetic algorithm based approach
utilizes the linkage between association rule and feature selection. In this
paper, we put forward a Multi objective genetic algorithm approach for data
quality on categorical attributes. The result shows that our approach is
outperformed by the objectives like accuracy, completeness, comprehensibility
and interestingness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3247</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3247</id><created>2012-02-15</created><authors><author><keyname>Kerneis</keyname><forenames>Gabriel</forenames><affiliation>PPS</affiliation></author><author><keyname>Chroboczek</keyname><forenames>Juliusz</forenames><affiliation>PPS</affiliation></author></authors><title>Lambda-lifting and CPS conversion in an imperative language</title><categories>cs.PL</categories><comments>arXiv admin note: substantial text overlap with arXiv:1011.4558</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a companion technical report to the article
&quot;Continuation-Passing C: from threads to events through continuations&quot;. It
contains the complete version of the proofs of correctness of lambda-lifting
and CPS-conversion presented in the article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3253</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3253</id><created>2012-02-15</created><authors><author><keyname>Fu</keyname><forenames>Ada Wai-Chee</forenames></author><author><keyname>Wang</keyname><forenames>Jia</forenames></author><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Wong</keyname><forenames>Raymond Chi-Wing</forenames></author></authors><title>Small Count Privacy and Large Count Utility in Data Publishing</title><categories>cs.DB</categories><comments>12 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the introduction of differential privacy has been a major breakthrough
in the study of privacy preserving data publication, some recent work has
pointed out a number of cases where it is not possible to limit inference about
individuals. The dilemma that is intrinsic in the problem is the simultaneous
requirement of data utility in the published data. Differential privacy does
not aim to protect information about an individual that can be uncovered even
without the participation of the individual. However, this lack of coverage may
violate the principle of individual privacy. Here we propose a solution by
providing protection to sensitive information, by which we refer to the answers
for aggregate queries with small counts. Previous works based on
$\ell$-diversity can be seen as providing a special form of this kind of
protection. Our method is developed with another goal which is to provide
differential privacy guarantee, and for that we introduce a more refined form
of differential privacy to deal with certain practical issues. Our empirical
studies show that our method can preserve better utilities than a number of
state-of-the-art methods although these methods do not provide the protections
that we provide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3254</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3254</id><created>2012-02-15</created><authors><author><keyname>Wang</keyname><forenames>Xiumin</forenames></author><author><keyname>Wang</keyname><forenames>Jianping</forenames></author><author><keyname>Zheng</keyname><forenames>Zeyu</forenames></author><author><keyname>Xu</keyname><forenames>Yinlong</forenames></author><author><keyname>Yang</keyname><forenames>Mei</forenames></author></authors><title>Service Composition in Service-Oriented Wireless Sensor Networks with
  Persistent Queries</title><categories>cs.NI</categories><comments>IEEE CCNC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-oriented wireless sensor network(WSN) has been recently proposed as
an architecture to rapidly develop applications in WSNs. In WSNs, a query task
may require a set of services and may be carried out repetitively with a given
frequency during its lifetime. A service composition solution shall be provided
for each execution of such a persistent query task. Due to the energy saving
strategy, some sensors may be scheduled to be in sleep mode periodically. Thus,
a service composition solution may not always be valid during the lifetime of a
persistent query. When a query task needs to be conducted over a new service
composition solution, a routing update procedure is involved which consumes
energy. In this paper, we study service composition design which minimizes the
number of service composition solutions during the lifetime of a persistent
query. We also aim to minimize the total service composition cost when the
minimum number of required service composition solutions is derived. A greedy
algorithm and a dynamic programming algorithm are proposed to complete these
two objectives respectively. The optimality of both algorithms provides the
service composition solutions for a persistent query with minimum energy
consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3255</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3255</id><created>2012-02-15</created><updated>2012-11-05</updated><authors><author><keyname>Stojanovski</keyname><forenames>Toni</forenames></author><author><keyname>Velinov</keyname><forenames>Ivan</forenames></author><author><keyname>Vu&#x10d;kovik</keyname><forenames>Marko</forenames></author></authors><title>Scalability of Data Binding in ASP.NET Web Applications</title><categories>cs.DB cs.SE</categories><comments>CITYR Conference, September 2012, Skopje, Macedonia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ASP.NET web applications typically employ server controls to provide dynamic
web pages, and data-bound server controls to display and maintain database
data. Most developers use default properties of ASP.NET server controls when
developing web applications, which allows for rapid development of workable
applications. However, creating a high-performance, multi-user, and scalable
web application requires enhancement of server controls using custom-made code.
In this empirical study we evaluate the impact of various technical approaches
for paging and sorting functionality in data-driven ASP.NET web applications:
automatic data paging and sorting in web server controls on web server; paging
and sorting on database server; indexed and non-indexed database columns;
clustered vs. non-clustered indices. We observed significant performance
improvements when custom paging based on SQL stored procedure and clustered
index is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3258</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3258</id><created>2012-02-15</created><authors><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness matrix of manipulators with passive joints: computational
  aspects</title><categories>cs.RO</categories><comments>arXiv admin note: substantial text overlap with arXiv:1107.4496</comments><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Robotics 28, 4 (2012) 1-4</journal-ref><doi>10.1109/TRO.2012.2187395</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on stiffness matrix computation for manipulators with
passive joints, compliant actuators and flexible links. It proposes both
explicit analytical expressions and an efficient recursive procedure that are
applicable in the general case and allow obtaining the desired matrix either in
analytical or numerical form. Advantages of the developed technique and its
ability to produce both singular and non-singular stiffness matrices are
illustrated by application examples that deal with stiffness modeling of two
Stewart-Gough platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3261</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3261</id><created>2012-02-15</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Litvak</keyname><forenames>Nelly</forenames><affiliation>EEMCS</affiliation></author><author><keyname>Sokol</keyname><forenames>Marina</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Quick Detection of Nodes with Large Degrees</title><categories>cs.DS cs.SI physics.soc-ph</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our goal is to quickly find top $k$ lists of nodes with the largest degrees
in large complex networks. If the adjacency list of the network is known (not
often the case in complex networks), a deterministic algorithm to find a node
with the largest degree requires an average complexity of O(n), where $n$ is
the number of nodes in the network. Even this modest complexity can be very
high for large complex networks. We propose to use the random walk based
method. We show theoretically and by numerical experiments that for large
networks the random walk method finds good quality top lists of nodes with high
probability and with computational savings of orders of magnitude. We also
propose stopping criteria for the random walk method which requires very little
knowledge about the structure of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3264</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3264</id><created>2012-02-15</created><authors><author><keyname>Venema</keyname><forenames>Yde</forenames></author><author><keyname>Vickers</keyname><forenames>Steve</forenames></author><author><keyname>Vosmaer</keyname><forenames>Jacob</forenames></author></authors><title>Generalized powerlocales via relation lifting</title><categories>cs.LO math.LO</categories><comments>44 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an endofunctor $\VT$ on the category of frames,
parametrized by an endofunctor $\T$ on the category $\Set$ that satisfies
certain constraints. This generalizes Johnstone's construction of the Vietoris
powerlocale, in the sense that his construction is obtained by taking for $\T$
the finite covariant power set functor. Our construction of the
$\T$-powerlocale $\VT \bbL$ out of a frame $\bbL$ is based on ideas from
coalgebraic logic and makes explicit the connection between the Vietoris
construction and Moss's coalgebraic cover modality.
  We show how to extend certain natural transformations between set functors to
natural transformations between $\T$-powerlocale functors. Finally, we prove
that the operation $\VT$ preserves some properties of frames, such as
regularity, zero-dimensionality, and the combination of zero-dimensionality and
compactness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3294</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3294</id><created>2012-02-15</created><updated>2013-06-21</updated><authors><author><keyname>Nixon</keyname><forenames>Anthony</forenames></author></authors><title>A Constructive Characterisation of Circuits in the Simple (2,2)-sparsity
  Matroid</title><categories>math.CO cs.DM</categories><comments>22 pages, 6 figures. Changes to presentation</comments><msc-class>52C25, 05B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a constructive characterisation of circuits in the simple
(2,2)-sparsity matroid. A circuit is a simple graph G=(V,E) with |E|=2|V|-1 and
the number of edges induced by any $X \subsetneq V$ is at most 2|X|-2.
Insisting on simplicity results in the Henneberg operation being enough only
when the graph is sufficiently connected. Thus we introduce 3 different join
operations to complete the characterisation. Extensions are discussed to when
the sparsity matroid is connected and this is applied to the theory of
frameworks on surfaces to provide a conjectured characterisation of when
frameworks on an infinite circular cylinder are generically globally rigid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3311</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3311</id><created>2012-02-15</created><authors><author><keyname>Goto</keyname><forenames>Keisuke</forenames></author><author><keyname>Bannai</keyname><forenames>Hideo</forenames></author><author><keyname>Inenaga</keyname><forenames>Shunsuke</forenames></author><author><keyname>Takeda</keyname><forenames>Masayuki</forenames></author></authors><title>Speeding-up $q$-gram mining on grammar-based compressed texts</title><categories>cs.DS</categories><doi>10.1007/978-3-642-31265-6_18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient algorithm for calculating $q$-gram frequencies on
strings represented in compressed form, namely, as a straight line program
(SLP). Given an SLP $\mathcal{T}$ of size $n$ that represents string $T$, the
algorithm computes the occurrence frequencies of all $q$-grams in $T$, by
reducing the problem to the weighted $q$-gram frequencies problem on a
trie-like structure of size $m = |T|-\mathit{dup}(q,\mathcal{T})$, where
$\mathit{dup}(q,\mathcal{T})$ is a quantity that represents the amount of
redundancy that the SLP captures with respect to $q$-grams. The reduced problem
can be solved in linear time. Since $m = O(qn)$, the running time of our
algorithm is $O(\min\{|T|-\mathit{dup}(q,\mathcal{T}),qn\})$, improving our
previous $O(qn)$ algorithm when $q = \Omega(|T|/n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3317</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3317</id><created>2012-02-15</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Toldin</keyname><forenames>Paolo Parisen</forenames></author></authors><title>An Higher-Order Characterization of Probabilistic Polynomial Time (Long
  Version)</title><categories>cs.LO cs.CC</categories><comments>32 pages</comments><acm-class>F.1.1; F.1.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present RSLR, an implicit higher-order characterization of the class PP of
those problems which can be decided in probabilistic polynomial time with error
probability smaller than 1/2. Analogously, a (less implicit) characterization
of the class BPP can be obtained. RSLR is an extension of Hofmann's SLR with a
probabilistic primitive, which enjoys basic properties such as subject
reduction and confluence. Polynomial time soundness of RSLR is obtained by
syntactical means, as opposed to the standard literature on SLR-derived
systems, which use semantics in an essential way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3321</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3321</id><created>2012-02-15</created><authors><author><keyname>Chunsheng</keyname><forenames>Gu</forenames></author></authors><title>Attack on Fully Homomorphic Encryption over the Integers</title><categories>cs.CR</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a heuristic attack on the fully homomorphic encryption
over the integers by using lattice reduction algorithm. Our result shows that
the FHE in [DGHV10] is not secure for some parameter settings. We also present
an improvement scheme to avoid the lattice attack in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3323</identifier>
 <datestamp>2012-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3323</id><created>2012-02-15</created><updated>2012-09-27</updated><authors><author><keyname>Cesa-Bianchi</keyname><forenames>Nicol&#xf2;</forenames><affiliation>INRIA Paris - Rocquencourt, DMA</affiliation></author><author><keyname>Gaillard</keyname><forenames>Pierre</forenames><affiliation>INRIA Paris - Rocquencourt, DMA</affiliation></author><author><keyname>Lugosi</keyname><forenames>Gabor</forenames><affiliation>ICREA</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>INRIA Paris - Rocquencourt, DMA, GREGH</affiliation></author></authors><title>Mirror Descent Meets Fixed Share (and feels no regret)</title><categories>cs.LG stat.ML</categories><proxy>ccsd</proxy><journal-ref>NIPS 2012, Lake Tahoe : United States (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mirror descent with an entropic regularizer is known to achieve shifting
regret bounds that are logarithmic in the dimension. This is done using either
a carefully designed projection or by a weight sharing technique. Via a novel
unified analysis, we show that these two approaches deliver essentially
equivalent bounds on a notion of regret generalizing shifting, adaptive,
discounted, and other related regrets. Our analysis also captures and extends
the generalized weight sharing technique of Bousquet and Warmuth, and can be
refined in several ways, including improvements for small losses and adaptive
tuning of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3335</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3335</id><created>2012-02-15</created><authors><author><keyname>Rogatch</keyname><forenames>Sarge</forenames></author></authors><title>An efficient high-quality hierarchical clustering algorithm for
  automatic inference of software architecture from the source code of a
  software system</title><categories>cs.AI cs.LG cs.SE</categories><comments>130 pages. I am looking for someone serious about investing into
  development of a commercial tool on the basis of my algorithm and my
  prototype. arXiv admin note: text overlap with arXiv:0803.4025 by other
  authors</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  It is a high-quality algorithm for hierarchical clustering of large software
source code. This effectively allows to break the complexity of tens of
millions lines of source code, so that a human software engineer can comprehend
a software system at high level by means of looking at its architectural
diagram that is reconstructed automatically from the source code of the
software system. The architectural diagram shows a tree of subsystems having
OOP classes in its leaves (in the other words, a nested software
decomposition). The tool reconstructs the missing
(inconsistent/incomplete/inexistent) architectural documentation for a software
system from its source code. This facilitates software maintenance: change
requests can be performed substantially faster. Simply speaking, this unique
tool allows to lift the comprehensible grain of object-oriented software
systems from OOP class-level to subsystem-level. It is estimated that a
commercial tool, developed on the basis of this work, will reduce software
maintenance expenses 10 times on the current needs, and will allow to implement
next-generation software systems which are currently too complex to be within
the range of human comprehension, therefore can't yet be designed or
implemented. Implemented prototype in Open Source:
http://sourceforge.net/p/insoar/code-0/1/tree/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3338</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3338</id><created>2012-02-15</created><authors><author><keyname>Andriyanova</keyname><forenames>Iryna</forenames></author><author><keyname>Maurice</keyname><forenames>Denise</forenames></author><author><keyname>Tillich</keyname><forenames>Jean-Pierre</forenames></author></authors><title>New constructions of CSS codes obtained by moving to higher alphabets</title><categories>quant-ph cs.IT math.IT</categories><comments>9 pages, 9 figures, full version of a paper submitted to the IEEE
  Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize a construction of non-binary quantum LDPC codes over $\F_{2^m}$
due to \cite{KHIS11a} and apply it in particular to toric codes. We obtain in
this way not only codes with better rates than toric codes but also improve
dramatically the performance of standard iterative decoding. Moreover, the new
codes obtained in this fashion inherit the distance properties of the
underlying toric codes and have therefore a minimum distance which grows as the
square root of the length of the code for fixed $m$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3355</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3355</id><created>2012-02-15</created><updated>2012-03-09</updated><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Lauser</keyname><forenames>Alexander</forenames></author></authors><title>Lattices of Logical Fragments over Words</title><categories>cs.FL cs.LO</categories><report-no>TR no. 2012/03</report-no><acm-class>F.4.0; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an abstract notion of fragments of monadic second-order
logic. This concept is based on purely syntactic closure properties. We show
that over finite words, every logical fragment defines a lattice of languages
with certain closure properties. Among these closure properties are residuals
and inverse C-morphisms. Here, depending on certain closure properties of the
fragment, C is the family of arbitrary, non-erasing, length-preserving,
length-multiplying, or length-reducing morphisms. In particular, definability
in a certain fragment can often be characterized in terms of the syntactic
morphism. This work extends a result of Straubing in which he investigated
certain restrictions of first-order logic formulae. In contrast to Straubing's
model-theoretic approach, our notion of a logical fragment is purely syntactic
and it does not rely on Ehrenfeucht-Fraisse games.
  As motivating examples, we present (1) a fragment which captures the
stutter-invariant part of piecewise-testable languages and (2) an acyclic
fragment of Sigma_2. As it turns out, the latter has the same expressive power
as two-variable first-order logic FO^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3367</identifier>
 <datestamp>2012-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3367</id><created>2012-02-15</created><updated>2012-05-07</updated><authors><author><keyname>Kelner</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Miller</keyname><forenames>Gary</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author></authors><title>Faster Approximate Multicommodity Flow Using Quadratically Coupled Flows</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum multicommodity flow problem is a natural generalization of the
maximum flow problem to route multiple distinct flows. Obtaining a $1-\epsilon$
approximation to the multicommodity flow problem on graphs is a well-studied
problem. In this paper we present an adaptation of recent advances in
single-commodity flow algorithms to this problem. As the underlying linear
systems in the electrical problems of multicommodity flow problems are no
longer Laplacians, our approach is tailored to generate specialized systems
which can be preconditioned and solved efficiently using Laplacians. Given an
undirected graph with m edges and k commodities, we give algorithms that find
$1-\epsilon$ approximate solutions to the maximum concurrent flow problem and
the maximum weighted multicommodity flow problem in time
$\tilde{O}(m^{4/3}\poly(k,\epsilon^{-1}))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3385</identifier>
 <datestamp>2015-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3385</id><created>2012-02-15</created><authors><author><keyname>Rivera-Campo</keyname><forenames>Eduardo</forenames></author><author><keyname>Urrutia-Galicia</keyname><forenames>Virginia</forenames></author></authors><title>A sufficient condition for the existence of plane spanning trees on
  geometric graphs</title><categories>math.CO cs.CG cs.DM</categories><comments>Accepted for publication in Computational Geometry: Theory and
  Applications</comments><msc-class>05C62</msc-class><journal-ref>Comput. Geom. 46(1) (2013), 1 - 6</journal-ref><doi>10.1016/j.comgeo.2012.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let P be a set of n &gt; 2 points in general position in the plane and let G be
a geometric graph with vertex set P. If the number of empty triangles uvw in P
for which the subgraph of G induced by {u,v,w} is not connected is at most n-3,
then G contains a non-self intersecting spanning tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3386</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3386</id><created>2012-02-15</created><authors><author><keyname>Padma</keyname><forenames>S.</forenames></author><author><keyname>Seshasaayee</keyname><forenames>Ananthi</forenames></author></authors><title>Towards Maximum Spanning Tree Model in Web 3.0 Design and Development
  for Students using Discriminant Analysis</title><categories>cs.OH</categories><comments>ISSN (Online): 1694-0814 http://www.IJCSI.org</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 5, No 2, September 2011, 420-425</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web 3.0 is an evolving extension of the web 2.0 scenario. The perceptions
regarding web 3.0 is different from person to person . Web 3.0 Architecture
supports ubiquitous connectivity, network computing, open identity, intelligent
web, distributed databases and intelligent applications. Some of the
technologies which lead to the design and development of web 3.0 applications
are Artificial intelligence, Automated reasoning, Cognitive architecture,
Semantic web . An attempt is made to capture the requirements of Students
inline with web 3.0 so as to bridge the gap between the design and development
of web 3.0 applications and requirements among Students. Maximum Spanning Tree
modeling of the requirements facilitate the identification of key areas and key
attributes in the design and development of software products for Students in
Web 3.0 using Discriminant analysis. Keywords : Web 3.0, Discriminant analysis,
Design and Development, Model, Maximum Spanning Tree 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3399</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3399</id><created>2012-02-15</created><updated>2012-12-17</updated><authors><author><keyname>Li</keyname><forenames>Chao</forenames></author><author><keyname>Miklau</keyname><forenames>Gerome</forenames></author></authors><title>Optimal error of query sets under the differentially-private matrix
  mechanism</title><categories>cs.DB cs.CR</categories><comments>35 pages; Short version to appear in the 16th International
  Conference on Database Theory (ICDT), 2013</comments><acm-class>H.2.8; F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common goal of privacy research is to release synthetic data that satisfies
a formal privacy guarantee and can be used by an analyst in place of the
original data. To achieve reasonable accuracy, a synthetic data set must be
tuned to support a specified set of queries accurately, sacrificing fidelity
for other queries.
  This work considers methods for producing synthetic data under differential
privacy and investigates what makes a set of queries &quot;easy&quot; or &quot;hard&quot; to
answer. We consider answering sets of linear counting queries using the matrix
mechanism, a recent differentially-private mechanism that can reduce error by
adding complex correlated noise adapted to a specified workload.
  Our main result is a novel lower bound on the minimum total error required to
simultaneously release answers to a set of workload queries. The bound reveals
that the hardness of a query workload is related to the spectral properties of
the workload when it is represented in matrix form. The bound is most
informative for $(\epsilon,\delta)$-differential privacy but also applies to
$\epsilon$-differential privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3405</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3405</id><created>2012-02-15</created><updated>2012-05-18</updated><authors><author><keyname>Meng</keyname><forenames>Chun</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Abinesh</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Jafar</keyname><forenames>Syed Ali</forenames></author></authors><title>On the Feasibility of Precoding-Based Network Alignment for Three
  Unicast Sessions</title><categories>cs.IT math.IT</categories><comments>Technical report for ISIT 2012, 10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of network coding across three unicast sessions over
a directed acyclic graph, when each session has min-cut one. Previous work by
Das et al. adapted a precoding-based interference alignment technique,
originally developed for the wireless interference channel, specifically to
this problem. We refer to this approach as precoding-based network alignment
(PBNA). Similar to the wireless setting, PBNA asymptotically achieves half the
minimum cut; different from the wireless setting, its feasibility depends on
the graph structure. Das et al. provided a set of feasibility conditions for
PBNA with respect to a particular precoding matrix. However, the set consisted
of an infinite number of conditions, which is impossible to check in practice.
Furthermore, the conditions were purely algebraic, without interpretation with
regards to the graph structure. In this paper, we first prove that the set of
conditions provided by Das. et al are also necessary for the feasibility of
PBNA with respect to any precoding matrix. Then, using two graph-related
properties and a degree-counting technique, we reduce the set to just four
conditions. This reduction enables an efficient algorithm for checking the
feasibility of PBNA on a given graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3451</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3451</id><created>2012-02-15</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Contreras</keyname><forenames>Pedro</forenames></author></authors><title>The Future of Search and Discovery in Big Data Analytics: Ultrametric
  Information Spaces</title><categories>cs.IR stat.ML</categories><comments>10 pages</comments><msc-class>11Z05</msc-class><acm-class>I.5.3; H.3.3; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider observation data, comprised of n observation vectors with values on
a set of attributes. This gives us n points in attribute space. Having data
structured as a tree, implied by having our observations embedded in an
ultrametric topology, offers great advantage for proximity searching. If we
have preprocessed data through such an embedding, then an observation's nearest
neighbor is found in constant computational time, i.e. O(1) time. A further
powerful approach is discussed in this work: the inducing of a hierarchy, and
hence a tree, in linear computational time, i.e. O(n) time for n observations.
It is with such a basis for proximity search and best match that we can address
the burgeoning problems of processing very large, and possibly also very high
dimensional, data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3455</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3455</id><created>2012-02-15</created><authors><author><keyname>Bautista-Santiago</keyname><forenames>Crevel</forenames></author><author><keyname>Cano</keyname><forenames>Javier</forenames></author><author><keyname>Fabila-Monroy</keyname><forenames>Ruy</forenames></author><author><keyname>Flores-Pe&#xf1;aloza</keyname><forenames>David</forenames></author><author><keyname>Gonz&#xe1;lez-Aguilar</keyname><forenames>Hern&#xe1;n</forenames></author><author><keyname>Lara</keyname><forenames>Dolores</forenames></author><author><keyname>Sarmiento</keyname><forenames>Eliseo</forenames></author><author><keyname>Urrutia</keyname><forenames>Jorge</forenames></author></authors><title>On the Connectedness and Diameter of a Geometric Johnson Graph</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of $n$ points in general position in the plane. A subset $I$
of $P$ is called an \emph{island} if there exists a convex set $C$ such that $I
= P \cap C$. In this paper we define the \emph{generalized island Johnson
graph} of $P$ as the graph whose vertex consists of all islands of $P$ of
cardinality $k$, two of which are adjacent if their intersection consists of
exactly $l$ elements. We show that for large enough values of $n$, this graph
is connected, and give upper and lower bounds on its diameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3461</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3461</id><created>2012-02-15</created><updated>2013-01-04</updated><authors><author><keyname>Fan</keyname><forenames>Liyue</forenames></author><author><keyname>Xiong</keyname><forenames>Li</forenames></author></authors><title>Adaptively Sharing Time-Series with Differential Privacy</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sharing real-time aggregate statistics of private data is of great value to
the public to perform data mining for understanding important phenomena, such
as Influenza outbreaks and traffic congestion. However, releasing time-series
data with standard differential privacy mechanism has limited utility due to
high correlation between data values. We propose FAST, a novel framework to
release real-time aggregate statistics under differential privacy based on
filtering and adaptive sampling. To minimize the overall privacy cost, FAST
adaptively samples long time-series according to the detected data dynamics. To
improve the accuracy of data release per time stamp, FAST predicts data values
at non-sampling points and corrects noisy observations at sampling points. Our
experiments with real-world as well as synthetic data sets confirm that FAST
improves the accuracy of released aggregates even under small privacy cost and
can be used to enable a wide range of monitoring applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3466</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3466</id><created>2012-02-15</created><authors><author><keyname>Barnawi</keyname><forenames>Ahmed</forenames></author><author><keyname>Altalhi</keyname><forenames>Abdulrahman H.</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Rizwan Jameel</forenames></author><author><keyname>Khan</keyname><forenames>Asif Irshad</forenames></author></authors><title>Novel Component-Based Development Model for SIP-Based Mobile Application
  (1202)</title><categories>cs.SE</categories><comments>15 pages</comments><doi>10.5121/ijsea.2012.3107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universities and Institutions these days' deals with issues related to with
assessment of large number of students. Various evaluation methods have been
adopted by examiners in different institutions to examining the ability of an
individual, starting from manual means of using paper and pencil to electronic,
from oral to written, practical to theoretical and many others. There is a need
to expedite the process of examination in order to meet the increasing
enrolment of students at the universities and institutes. Sip Based Mass Mobile
Examination System (SiBMMES) expedites the examination process by automating
various activities in an examination such as exam paper setting, Scheduling and
allocating examination time and evaluation (auto-grading for objective
questions) etc. SiBMMES uses the IP Multimedia Subsystem (IMS) that is an IP
communications framework providing an environment for the rapid development of
innovative and reusable services Session Initial Protocol (SIP) is a signalling
(request-response) protocol for this architecture and it is used for
establishing sessions in an IP network, making it an ideal candidate for
supporting terminal mobility in the IMS to deliver the services, with the
extended services available in IMS like open APIs, common network services,
Quality of Services (QoS) like multiple sessions per call, Push to Talk etc
often requiring multiple types of media (including voice, video, pictures, and
text). SiBMMES is an effective solution for mass education evaluation using
mobile and web technology. In this paper, a novel hybrid component based
development (CBD) model is proposed for SiBMMES. A Component based Hybrid Model
is selected to the fact that IMS takes the concept of layered architecture one
step further by defining a horizontal architecture where service enablers and
common functions can be reused for multiple applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3467</identifier>
 <datestamp>2012-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3467</id><created>2012-02-15</created><updated>2012-09-18</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Savov</keyname><forenames>Ivan</forenames></author></authors><title>Joint source-channel coding for a quantum multiple access channel</title><categories>quant-ph cs.IT math.IT</categories><comments>21 pages, v2: minor changes, accepted into Journal of Physics A</comments><journal-ref>Journal of Physics A: Mathematical and Theoretical vol. 45, no.
  43, p. 435302 (October 2012)</journal-ref><doi>10.1088/1751-8113/45/43/435302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that two senders each obtain one share of the output of a classical,
bivariate, correlated information source. They would like to transmit the
correlated source to a receiver using a quantum multiple access channel. In
prior work, Cover, El Gamal, and Salehi provided a combined source-channel
coding strategy for a classical multiple access channel which outperforms the
simpler &quot;separation&quot; strategy where separate codebooks are used for the source
coding and the channel coding tasks. In the present paper, we prove that a
coding strategy similar to the Cover-El Gamal-Salehi strategy and a
corresponding quantum simultaneous decoder allow for the reliable transmission
of a source over a quantum multiple access channel, as long as a set of
information inequalities involving the Holevo quantity hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3468</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3468</id><created>2012-02-15</created><authors><author><keyname>Abdallah</keyname><forenames>Saeed</forenames></author><author><keyname>Psaromiligkos</keyname><forenames>Ioannis N.</forenames></author></authors><title>Partially-blind Estimation of Reciprocal Channels for AF Two-Way Relay
  Networks Employing M-PSK Modulation</title><categories>cs.IT math.IT stat.OT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of channel estimation for amplify-and-forward two-way
relays assuming channel reciprocity and M-PSK modulation. In an earlier work, a
partially-blind maximum-likelihood estimator was derived by treating the data
as deterministic unknowns. We prove that this estimator approaches the true
channel with high probability at high signal-to-noise ratio (SNR) but is not
consistent. We then propose an alternative estimator which is consistent and
has similarly favorable high SNR performance. We also derive the Cramer-Rao
bound on the variance of unbiased estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3470</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3470</id><created>2012-02-15</created><updated>2012-04-25</updated><authors><author><keyname>Clifford</keyname><forenames>Raphael</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Sach</keyname><forenames>Benjamin</forenames></author></authors><title>Pattern Matching in Multiple Streams</title><categories>cs.DS</categories><comments>13 pages, 1 figure</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of deterministic pattern matching in multiple
streams. In this model, one symbol arrives at a time and is associated with one
of s streaming texts. The task at each time step is to report if there is a new
match between a fixed pattern of length m and a newly updated stream. As is
usual in the streaming context, the goal is to use as little space as possible
while still reporting matches quickly. We give almost matching upper and lower
space bounds for three distinct pattern matching problems. For exact matching
we show that the problem can be solved in constant time per arriving symbol and
O(m+s) words of space. For the k-mismatch and k-difference problems we give
O(k) time solutions that require O(m+ks) words of space. In all three cases we
also give space lower bounds which show our methods are optimal up to a single
logarithmic factor. Finally we set out a number of open problems related to
this new model for pattern matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3471</identifier>
 <datestamp>2012-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3471</id><created>2012-02-15</created><updated>2012-09-05</updated><authors><author><keyname>S&#xe1;nchez-Burillo</keyname><forenames>Eduardo</forenames></author><author><keyname>Duch</keyname><forenames>Jordi</forenames></author><author><keyname>G&#xf3;mez-Gardenes</keyname><forenames>Jes&#xfa;s</forenames></author><author><keyname>Zueco</keyname><forenames>David</forenames></author></authors><title>Quantum Navigation and Ranking in Complex Networks</title><categories>quant-ph cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>title changed, more real networks analyzed, version published in
  scientific reports</comments><doi>10.1038/srep00605</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Complex networks are formal frameworks capturing the interdependencies
between the elements of large systems and databases. This formalism allows to
use network navigation methods to rank the importance that each constituent has
on the global organization of the system. A key example is Pagerank navigation
which is at the core of the most used search engine of the World Wide Web.
Inspired in this classical algorithm, we define a quantum navigation method
providing a unique ranking of the elements of a network. We analyze the
convergence of quantum navigation to the stationary rank of networks and show
that quantumness decreases the number of navigation steps before convergence.
In addition, we show that quantum navigation allows to solve degeneracies found
in classical ranks. By implementing the quantum algorithm in real networks, we
confirm these improvements and show that quantum coherence unveils new
hierarchical features about the global organization of complex systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3473</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3473</id><created>2012-02-15</created><authors><author><keyname>Ray</keyname><forenames>Jaideep</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Are we there yet? When to stop a Markov chain while generating random
  graphs</title><categories>cs.SI physics.data-an physics.soc-ph</categories><comments>12 pages, 4 figures, 1 table. Submitted to 9th Workshop on Algorithms
  and Models for the Web Graph, Dalhousie University in Halifax, Nova Scotia,
  Canada, June 22-23, 2012, http://www.mathstat.dal.ca/~mominis/WAW2012/</comments><report-no>SAND2012-1169C</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Markov chains are a convenient means of generating realizations of networks,
since they require little more than a procedure for rewiring edges. If a
rewiring procedure exists for generating new graphs with specified statistical
properties, then a Markov chain sampler can generate an ensemble of graphs with
prescribed characteristics. However, successive graphs in a Markov chain cannot
be used when one desires independent draws from the distribution of graphs; the
realizations are correlated. Consequently, one runs a Markov chain for N
iterations before accepting the realization as an independent sample. In this
work, we devise two methods for calculating N. They are both based on the
binary &quot;time-series&quot; denoting the occurrence/non-occurrence of edge (u, v)
between vertices u and v in the Markov chain of graphs generated by the
sampler. They differ in their underlying assumptions. We test them on the
generation of graphs with a prescribed joint degree distribution. We find the N
proportional |E|, where |E| is the number of edges in the graph. The two
methods are compared by sampling on real, sparse graphs with 10^3 - 10^4
vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3479</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3479</id><created>2012-02-15</created><updated>2013-08-24</updated><authors><author><keyname>Hatami</keyname><forenames>Pooya</forenames></author></authors><title>Lower Bounds on Testing Functions of Low Fourier Degree</title><categories>cs.CC</categories><comments>This paper has been withdrawn in order to be replaced with a new
  joint paper with a coauthor</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of testing whether a Boolean function has Fourier
degree $\leq k$ or it is $\epsilon$-far from any Boolean function with Fourier
degree $\leq k$. We improve the known lower bound of $\Omega(k)$
\cite{BBM11,CGM10}, to $\Omega(k/\sqrt{\epsilon})$. The lower bound uses the
recently discovered connections between property testing and communication
complexity by Blais \textit{et. al.} \cite{BBM11}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3480</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3480</id><created>2012-02-15</created><authors><author><keyname>Ghosh</keyname><forenames>Arpita</forenames></author><author><keyname>Hummel</keyname><forenames>Patrick</forenames></author></authors><title>Implementing Optimal Outcomes in Social Computing: A Game-Theoretic
  Approach</title><categories>cs.GT</categories><comments>Proceedings of the 21st International World Wide Web Conference (WWW)
  (2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many social computing applications such as online Q&amp;A forums, the best
contribution for each task receives some high reward, while all remaining
contributions receive an identical, lower reward irrespective of their actual
qualities. Suppose a mechanism designer (site owner) wishes to optimize an
objective that is some function of the number and qualities of received
contributions. When potential contributors are strategic agents, who decide
whether to contribute or not to selfishly maximize their own utilities, is such
a &quot;best contribution&quot; mechanism, M_B, adequate to implement an outcome that is
optimal for the mechanism designer?
  We first show that in settings where a contribution's value is determined
primarily by an agent's expertise, and agents only strategically choose whether
to contribute or not, contests can implement optimal outcomes: for any
reasonable objective, the rewards for the best and remaining contributions in
M_B can always be chosen so that the outcome in the unique symmetric
equilibrium of M_B maximizes the mechanism designer's utility. We also show how
the mechanism designer can learn these optimal rewards when she does not know
the parameters of the agents' utilities, as might be the case in practice. We
next consider settings where a contribution's value depends on both the
contributor's expertise as well as her effort, and agents endogenously choose
how much effort to exert in addition to deciding whether to contribute. Here,
we show that optimal outcomes can never be implemented by contests if the
system can rank the qualities of contributions perfectly. However, if there is
noise in the contributions' rankings, then the mechanism designer can again
induce agents to follow strategies that maximize his utility. Thus imperfect
rankings can actually help achieve implementability of optimal outcomes when
effort is endogenous and influences quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3484</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3484</id><created>2012-02-15</created><updated>2012-02-20</updated><authors><author><keyname>Feng</keyname><forenames>Yuan</forenames></author><author><keyname>Deng</keyname><forenames>Yuxin</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Symbolic bisimulation for quantum processes</title><categories>cs.LO</categories><comments>30 pages, 7 figures, comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the previous notions of bisimulation presented in literature, to check
if two quantum processes are bisimilar, we have to instantiate the free quantum
variables of them with arbitrary quantum states, and verify the bisimilarity of
resultant configurations. This makes checking bisimilarity infeasible from an
algorithmic point of view because quantum states constitute a continuum. In
this paper, we introduce a symbolic operational semantics for quantum processes
directly at the quantum operation level, which allows us to describe the
bisimulation between quantum processes without resorting to quantum states. We
show that the symbolic bisimulation defined here is equivalent to the open
bisimulation for quantum processes in the previous work, when strong
bisimulations are considered. An algorithm for checking symbolic ground
bisimilarity is presented. We also give a modal logical characterisation for
quantum bisimilarity based on an extension of Hennessy-Milner logic to quantum
processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3492</identifier>
 <datestamp>2015-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3492</id><created>2012-02-10</created><updated>2014-12-20</updated><authors><author><keyname>Simkin</keyname><forenames>M. V.</forenames></author><author><keyname>Roychowdhury</keyname><forenames>V. P.</forenames></author></authors><title>Why does attention to web articles fall with time?</title><categories>cs.IR physics.soc-ph</categories><comments>To appear in JASIST</comments><journal-ref>Journal of the Association for Information Science and Technology,
  66(9):1847-1856, 2015</journal-ref><doi>10.1002/asi.23289</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze access statistics of a hundred and fifty blog entries and news
articles, for periods of up to three years. Access rate falls as an inverse
power of time passed since publication. The power law holds for periods of up
to thousand days. The exponents are different for different blogs and are
distributed between 0.6 and 3.2. We argue that the decay of attention to a web
article is caused by the link to it first dropping down the list of links on
the website's front page, and then disappearing from the front page and its
subsequent movement further into background. The other proposed explanations
that use a decaying with time novelty factor, or some intricate theory of human
dynamics cannot explain all of the experimental observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3496</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3496</id><created>2012-02-15</created><authors><author><keyname>Abel</keyname><forenames>Andreas</forenames><affiliation>Department of Computer Science, Ludwig-Maximilians-University Munich</affiliation></author></authors><title>Type-Based Termination, Inflationary Fixed-Points, and Mixed
  Inductive-Coinductive Types</title><categories>cs.LO cs.PL</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><acm-class>F.3.3.e; F.4.1.c</acm-class><journal-ref>EPTCS 77, 2012, pp. 1-11</journal-ref><doi>10.4204/EPTCS.77.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type systems certify program properties in a compositional way. From a bigger
program one can abstract out a part and certify the properties of the resulting
abstract program by just using the type of the part that was abstracted away.
Termination and productivity are non-trivial yet desired program properties,
and several type systems have been put forward that guarantee termination,
compositionally. These type systems are intimately connected to the definition
of least and greatest fixed-points by ordinal iteration. While most type
systems use conventional iteration, we consider inflationary iteration in this
article. We demonstrate how this leads to a more principled type system, with
recursion based on well-founded induction. The type system has a prototypical
implementation, MiniAgda, and we show in particular how it certifies
productivity of corecursive and mixed recursive-corecursive functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3497</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3497</id><created>2012-02-15</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames></author><author><keyname>Ing&#xf3;lfsd&#xf3;ttir</keyname><forenames>Anna</forenames></author></authors><title>Characteristic Formulae for Relations with Nested Fixed Points</title><categories>cs.LO</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 77, 2012, pp. 15-22</journal-ref><doi>10.4204/EPTCS.77.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general framework for the connection between characteristic formulae and
behavioral semantics is described in [2]. This approach does not suitably cover
semantics defined by nested fixed points, such as the n-nested simulation
semantics for n greater than 2. In this study we address this deficiency and
give a description of nested fixed points that extends the approach for single
fixed points in an intuitive and comprehensive way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3498</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3498</id><created>2012-02-15</created><authors><author><keyname>Haddad</keyname><forenames>Axel</forenames><affiliation>LIGM &amp; LIAFA</affiliation></author></authors><title>IO vs OI in Higher-Order Recursion Schemes</title><categories>cs.LO</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 77, 2012, pp. 23-30</journal-ref><doi>10.4204/EPTCS.77.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a study of the modes of derivation of higher-order recursion
schemes, proving that value trees obtained from schemes using
innermost-outermost derivations (IO) are the same as those obtained using
unrestricted derivations. Given that higher-order recursion schemes can be used
as a model of functional programs, innermost-outermost derivations policy
represents a theoretical view point of call by value evaluation strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3499</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3499</id><created>2012-02-15</created><authors><author><keyname>Hirschowitz</keyname><forenames>Andr&#xe9;</forenames><affiliation>Laboratoire J.-A. Dieudonn&#xe9;, Universit&#xe9; de Nice - Sophia Antipolis</affiliation></author><author><keyname>Maggesi</keyname><forenames>Marco</forenames><affiliation>Dipartimento di Matematica &quot;U. Dini&quot;, Universit&#xe0; degli Studi di Firenze</affiliation></author></authors><title>Initial Semantics for Strengthened Signatures</title><categories>cs.PL cs.LO</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 77, 2012, pp. 31-38</journal-ref><doi>10.4204/EPTCS.77.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new general definition of arity, yielding the companion notions of
signature and associated syntax. This setting is modular in the sense requested
by Ghani and Uustalu: merging two extensions of syntax corresponds to building
an amalgamated sum. These signatures are too general in the sense that we are
not able to prove the existence of an associated syntax in this general
context. So we have to select arities and signatures for which there exists the
desired initial monad. For this, we follow a track opened by Matthes and
Uustalu: we introduce a notion of strengthened arity and prove that the
corresponding signatures have initial semantics (i.e. associated syntax). Our
strengthened arities admit colimits, which allows the treatment of the
\lambda-calculus with explicit substitution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3500</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3500</id><created>2012-02-15</created><authors><author><keyname>Lange</keyname><forenames>Martin</forenames><affiliation>School of Electrical Engineering and Computer Science, University of Kassel, Germany</affiliation></author><author><keyname>Lozes</keyname><forenames>Etienne</forenames><affiliation>School of Electrical Engineering and Computer Science, University of Kassel, Germany</affiliation></author></authors><title>Model-Checking the Higher-Dimensional Modal mu-Calculus</title><categories>cs.LO cs.FL</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><acm-class>F.4.1, F.2.m, F.3.0</acm-class><journal-ref>EPTCS 77, 2012, pp. 39-46</journal-ref><doi>10.4204/EPTCS.77.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The higher-dimensional modal mu-calculus is an extension of the mu-calculus
in which formulas are interpreted in tuples of states of a labeled transition
system. Every property that can be expressed in this logic can be checked in
polynomial time, and conversely every polynomial-time decidable problem that
has a bisimulation-invariant encoding into labeled transition systems can also
be defined in the higher-dimensional modal mu-calculus. We exemplify the latter
connection by giving several examples of decision problems which reduce to
model checking of the higher-dimensional modal mu-calculus for some fixed
formulas. This way generic model checking algorithms for the logic can then be
used via partial evaluation in order to obtain algorithms for theses problems
which may benefit from improvements that are well-established in the field of
program verification, namely on-the-fly and symbolic techniques. The aim of
this work is to extend such techniques to other fields as well, here
exemplarily done for process equivalences, automata theory, parsing, string
problems, and games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3501</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3501</id><created>2012-02-15</created><authors><author><keyname>Mints</keyname><forenames>Grigori</forenames></author><author><keyname>Studer</keyname><forenames>Thomas</forenames></author></authors><title>Cut-elimination for the mu-calculus with one variable</title><categories>cs.LO</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 77, 2012, pp. 47-54</journal-ref><doi>10.4204/EPTCS.77.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish syntactic cut-elimination for the one-variable fragment of the
modal mu-calculus. Our method is based on a recent cut-elimination technique by
Mints that makes use of Buchholz' Omega-rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3502</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3502</id><created>2012-02-15</created><authors><author><keyname>Uustalu</keyname><forenames>Tarmo</forenames></author></authors><title>Structured general corecursion and coinductive graphs [extended
  abstract]</title><categories>cs.LO cs.PL</categories><comments>In Proceedings FICS 2012, arXiv:1202.3174</comments><proxy>EPTCS</proxy><acm-class>F.3.2; D.3.3</acm-class><journal-ref>EPTCS 77, 2012, pp. 55-61</journal-ref><doi>10.4204/EPTCS.77.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bove and Capretta's popular method for justifying function definitions by
general recursive equations is based on the observation that any structured
general recursion equation defines an inductive subset of the intended domain
(the &quot;domain of definedness&quot;) for which the equation has a unique solution. To
accept the definition, it is hence enough to prove that this subset contains
the whole intended domain.
  This approach works very well for &quot;terminating&quot; definitions. But it fails to
account for &quot;productive&quot; definitions, such as typical definitions of
stream-valued functions. We argue that such definitions can be treated in a
similar spirit, proceeding from a different unique solvability criterion. Any
structured recursive equation defines a coinductive relation between the
intended domain and intended codomain (the &quot;coinductive graph&quot;). This relation
in turn determines a subset of the intended domain and a quotient of the
intended codomain with the property that the equation is uniquely solved for
the subset and quotient. The equation is therefore guaranteed to have a unique
solution for the intended domain and intended codomain whenever the subset is
the full set and the quotient is by equality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3504</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3504</id><created>2012-02-15</created><authors><author><keyname>Jahanbakhsh</keyname><forenames>Kazem</forenames></author><author><keyname>King</keyname><forenames>Valerie</forenames></author><author><keyname>Shoja</keyname><forenames>Gholamali C.</forenames></author></authors><title>They Know Where You Live!</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we demonstrate the possibility of predicting people's
hometowns by using their geotagged photos posted on Flickr website. We employ
Kruskal's algorithm to cluster photos taken by a user and predict the user's
hometown. Our results prove that using social profiles of photographers allows
researchers to predict the locations of their taken photos with higher
accuracies. This in return can improve the previous methods which were purely
based on visual features of photos \cite{Hays:im2gps}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3505</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3505</id><created>2012-02-15</created><updated>2013-06-21</updated><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author><author><keyname>Drineas</keyname><forenames>Petros</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Near-optimal Coresets For Least-Squares Regression</title><categories>cs.DS cs.LG</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study (constrained) least-squares regression as well as multiple response
least-squares regression and ask the question of whether a subset of the data,
a coreset, suffices to compute a good approximate solution to the regression.
We give deterministic, low order polynomial-time algorithms to construct such
coresets with approximation guarantees, together with lower bounds indicating
that there is not much room for improvement upon our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3510</identifier>
 <datestamp>2012-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3510</id><created>2012-02-15</created><updated>2012-06-08</updated><authors><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author></authors><title>Energy Efficiency Optimization for MIMO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>submitted for possible publication, 26 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Characterizing the fundamental energy efficiency (EE) limits of MIMO
broadcast channels (BC) is significant for the development of green wireless
communications. We address the EE optimization problem for MIMO-BC in this
paper and consider a practical power model, i.e., taking into account a
transmit independent power which is related to the number of active transmit
antennas. Under this setup, we propose a new optimization approach, in which
the transmit covariance is optimized under fixed active transmit antenna sets,
and then active transmit antenna selection (ATAS) is utilized. During the
transmit covariance optimization, we propose a globally optimal energy
efficient iterative water-filling scheme through solving a series of concave
fractional programs based on the block-coordinate ascent algorithm. After that,
ATAS is employed to determine the active transmit antenna set. Since activating
more transmit antennas can achieve higher sum-rate but at the cost of larger
transmit independent power consumption, there exists a tradeoff between the
sum-rate gain and the power consumption. Here ATAS can exploit the best
tradeoff and thus further improve the EE. Optimal exhaustive search and
low-complexity norm based ATAS schemes are developed. Through simulations, we
discuss the effect of different parameters on the EE of the MIMO-BC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3514</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3514</id><created>2012-02-16</created><updated>2012-05-06</updated><authors><author><keyname>Tang</keyname><forenames>Chunming</forenames></author><author><keyname>Qi</keyname><forenames>Yanfeng</forenames></author><author><keyname>Xu</keyname><forenames>Maozhi</forenames></author><author><keyname>Wang</keyname><forenames>Baocheng</forenames></author><author><keyname>Yang</keyname><forenames>Yixian</forenames></author></authors><title>A Note on Weight Distributions of Irreducible Cyclic Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Usually, it is difficult to determine the weight distribution of an
irreducible cyclic code. In this paper, we discuss the case when an irreducible
cyclic code has the maximal number of distinct nonzero weights and give a
necessary and sufficient condition. In this case, we also obtain a divisible
property for the weight of a codeword. Further, we present a necessary and
sufficient condition for an irreducible cyclic code with only one nonzero
weight. Finally, we determine the weight distribution of an irreducible cyclic
code for some cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3531</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3531</id><created>2012-02-16</created><authors><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Recovering Jointly Sparse Signals via Joint Basis Pursuit</title><categories>cs.IT math.IT math.OC</categories><comments>8 pages, 1 figure, submitted to ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers recovery of signals that are sparse over two bases. For
instance, a signal might be sparse in both time and frequency, or a matrix can
be low rank and sparse simultaneously. To facilitate recovery, we consider
minimizing the sum of the $\ell_1$-norms that correspond to each basis, which
is a tractable convex approach. We find novel optimality conditions which
indicates a gain over traditional approaches where $\ell_1$ minimization is
done over only one basis. Next, we analyze these optimality conditions for the
particular case of time-frequency bases. Denoting sparsity in the first and
second bases by $k_1,k_2$ respectively, we show that, for a general class of
signals, using this approach, one requires as small as
$O(\max\{k_1,k_2\}\log\log n)$ measurements for successful recovery hence
overcoming the classical requirement of
$\Theta(\min\{k_1,k_2\}\log(\frac{n}{\min\{k_1,k_2\}}))$ for $\ell_1$
minimization when $k_1\approx k_2$. Extensive simulations show that, our
analysis is approximately tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3538</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3538</id><created>2012-02-16</created><updated>2013-12-25</updated><authors><author><keyname>Bozzelli</keyname><forenames>Laura</forenames></author><author><keyname>van Ditmarsch</keyname><forenames>Hans</forenames></author><author><keyname>French</keyname><forenames>Tim</forenames></author><author><keyname>Hales</keyname><forenames>James</forenames></author><author><keyname>Pinchinat</keyname><forenames>Sophie</forenames></author></authors><title>Refinement Modal Logic</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present {\em refinement modal logic}. A refinement is like a
bisimulation, except that from the three relational requirements only `atoms'
and `back' need to be satisfied. Our logic contains a new operator 'all' in
addition to the standard modalities 'box' for each agent. The operator 'all'
acts as a quantifier over the set of all refinements of a given model. As a
variation on a bisimulation quantifier, this refinement operator or refinement
quantifier 'all' can be seen as quantifying over a variable not occurring in
the formula bound by it. The logic combines the simplicity of multi-agent modal
logic with some powers of monadic second-order quantification. We present a
sound and complete axiomatization of multi-agent refinement modal logic. We
also present an extension of the logic to the modal mu-calculus, and an
axiomatization for the single-agent version of this logic. Examples and
applications are also discussed: to software verification and design (the set
of agents can also be seen as a set of actions), and to dynamic epistemic
logic. We further give detailed results on the complexity of satisfiability,
and on succinctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3549</identifier>
 <datestamp>2012-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3549</id><created>2012-02-16</created><updated>2012-04-18</updated><authors><author><keyname>Aboulker</keyname><forenames>Pierre</forenames></author></authors><title>Excluding 4-wheels</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 4-wheel is a graph formed by a cycle C and a vertex not in C that has at
least four neighbors in C. We prove that a graph G that does not contain a
4-wheel as a subgraph is 4-colorable and we describe some structural properties
of such a graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3562</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3562</id><created>2012-02-16</created><authors><author><keyname>Bas</keyname><forenames>Patrick</forenames></author><author><keyname>Furon</keyname><forenames>Teddy</forenames></author></authors><title>The Effective Key Length of Watermarking Schemes</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Whereas the embedding distortion, the payload and the robustness of digital
watermarking schemes are well understood, the notion of security is still not
completely well defined. The approach proposed in the last five years is too
theoretical and solely considers the embedding process, which is half of the
watermarking scheme. This paper proposes a new measurement of watermarking
security, called the effective key length, which captures the difficulty for
the adversary to get access to the watermarking channel. This new methodology
is applied to additive spread spectrum schemes where theoretical and practical
computations of the effective key length are proposed. It shows that these
schemes are not secure as soon as the adversary gets observations in the Known
Message Attack context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3572</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3572</id><created>2012-02-16</created><authors><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>Calculation of statistical entropic measures in a model of solids</title><categories>nlin.AO cond-mat.other cs.IT math.IT</categories><comments>9 pages, 4 figures</comments><doi>10.1016/j.physleta.2012.05.052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a one-dimensional model of crystalline solids based on the
Dirac comb limit of the Kronig-Penney model is considered. From the wave
functions of the valence electrons, we calculate a statistical measure of
complexity and the Fisher-Shannon information for the lower energy electronic
bands appearing in the system. All these magnitudes present an extremal value
for the case of solids having half-filled bands, a configuration where in
general a high conductivity is attained in real solids, such as it happens with
the monovalent metals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3576</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3576</id><created>2012-02-16</created><authors><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Yue</keyname><forenames>On-Ching</forenames></author></authors><title>A Tutorial of 802.11 Implementation in NS-2</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By analyzing the source codes of ns-2, we discuss the simulated
implementations of wireless channels, network interfaces and mostly the 802.11
MAC protocol in ns-2. We also notice the &quot;bugs&quot; of the 802.11 simulation
compared with the reality, and present an extension to fading channels as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3602</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3602</id><created>2012-02-16</created><authors><author><keyname>Hoehndorf</keyname><forenames>Robert</forenames></author><author><keyname>Dumontier</keyname><forenames>Michel</forenames></author><author><keyname>Gkoutos</keyname><forenames>Georgios V.</forenames></author></authors><title>Towards quantitative measures in applied ontology</title><categories>cs.AI q-bio.QM</categories><comments>Initial manuscript, submitted to FOIS 2012</comments><doi>10.1093/bib/bbs053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applied ontology is a relatively new field which aims to apply theories and
methods from diverse disciplines such as philosophy, cognitive science,
linguistics and formal logics to perform or improve domain-specific tasks. To
support the development of effective research methodologies for applied
ontology, we critically discuss the question how its research results should be
evaluated. We propose that results in applied ontology must be evaluated within
their domain of application, based on some ontology-based task within the
domain, and discuss quantitative measures which would facilitate the objective
evaluation and comparison of research results in applied ontology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3625</identifier>
 <datestamp>2014-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3625</id><created>2012-02-16</created><updated>2014-04-11</updated><authors><author><keyname>Plesken</keyname><forenames>Wilhelm</forenames></author><author><keyname>B&#xe4;chler</keyname><forenames>Thomas</forenames></author></authors><title>From Linear Codes to Hyperplane Arrangements via Thomas Decomposition</title><categories>cs.IT math.IT</categories><comments>This has been rejected since it contains some mistakes. A similar
  work has been publish in Documenta Math. vol. 19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a connection between linear codes and hyperplane arrangements
using the Thomas decomposition of polynomial systems and the resulting counting
polynomial. This yields both a generalization and a refinement of the weight
enumerator of a linear code. In particular, one can deal with infinitely many
finite fields simultaneously by defining a weight enumerator for codes over
infinite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3639</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3639</id><created>2012-02-16</created><updated>2013-09-07</updated><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Karp</keyname><forenames>Richard</forenames></author></authors><title>Finding a most biased coin with fewest flips</title><categories>cs.DS cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of learning a most biased coin among a set of coins by
tossing the coins adaptively. The goal is to minimize the number of tosses
until we identify a coin i* whose posterior probability of being most biased is
at least 1-delta for a given delta. Under a particular probabilistic model, we
give an optimal algorithm, i.e., an algorithm that minimizes the expected
number of future tosses. The problem is closely related to finding the best arm
in the multi-armed bandit problem using adaptive strategies. Our algorithm
employs an optimal adaptive strategy -- a strategy that performs the best
possible action at each step after observing the outcomes of all previous coin
tosses. Consequently, our algorithm is also optimal for any starting history of
outcomes. To our knowledge, this is the first algorithm that employs an optimal
adaptive strategy under a Bayesian setting for this problem. Our proof of
optimality employs tools from the field of Markov games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3641</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3641</id><created>2012-02-16</created><updated>2012-10-23</updated><authors><author><keyname>Erhard</keyname><forenames>Michael</forenames></author><author><keyname>Strauch</keyname><forenames>Hans</forenames></author></authors><title>Control of Towing Kites for Seagoing Vessels</title><categories>cs.SY</categories><comments>12 pages, 18 figures; submitted to IEEE Trans. on Control Systems
  Technology; revision: Fig. 15 corrected, minor text changes</comments><doi>10.1109/TCST.2012.2221093</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the basic features of the flight control of the
SkySails towing kite system. After introduction of coordinate definitions and
basic system dynamics we introduce a novel model used for controller design and
justify its main dynamics with results from system identification based on
numerous sea trials. We then present the controller design which we
successfully use for operational flights for several years. Finally we explain
the generation of dynamical flight patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3643</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3643</id><created>2012-02-16</created><updated>2012-05-02</updated><authors><author><keyname>Yasseri</keyname><forenames>Taha</forenames></author><author><keyname>Sumi</keyname><forenames>Robert</forenames></author><author><keyname>Rung</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Kornai</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Dynamics of conflicts in Wikipedia</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>Supporting information added</comments><journal-ref>PLoS ONE 7(6): e38869 (2012)</journal-ref><doi>10.1371/journal.pone.0038869</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the dynamical features of editorial wars in Wikipedia
(WP). Based on our previously established algorithm, we build up samples of
controversial and peaceful articles and analyze the temporal characteristics of
the activity in these samples. On short time scales, we show that there is a
clear correspondence between conflict and burstiness of activity patterns, and
that memory effects play an important role in controversies. On long time
scales, we identify three distinct developmental patterns for the overall
behavior of the articles. We are able to distinguish cases eventually leading
to consensus from those cases where a compromise is far from achievable.
Finally, we analyze discussion networks and conclude that edit wars are mainly
fought by few editors only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3653</identifier>
 <datestamp>2014-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3653</id><created>2012-02-16</created><updated>2014-10-07</updated><authors><author><keyname>Yousefi</keyname><forenames>Mansoor I.</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Information Transmission using the Nonlinear Fourier Transform, Part I:
  Mathematical Tools</title><categories>cs.IT math.IT</categories><comments>This version contains minor updates of IEEE Transactions on
  Information Theory, vol. 60, no. 7, pp. 4312--4328, July 2014</comments><journal-ref>IEEE Transactions on Information Theory, vol. 60, no. 7, pp.
  4312--4328, July 2014</journal-ref><doi>10.1109/TIT.2014.2321143</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nonlinear Fourier transform (NFT), a powerful tool in soliton theory and
exactly solvable models, is a method for solving integrable partial
differential equations governing wave propagation in certain nonlinear media.
The NFT decorrelates signal degrees-of-freedom in such models, in much the same
way that the Fourier transform does for linear systems. In this three-part
series of papers, this observation is exploited for data transmission over
integrable channels such as optical fibers, where pulse propagation is governed
by the nonlinear Schr\&quot;odinger equation. In this transmission scheme, which can
be viewed as a nonlinear analogue of orthogonal frequency-division multiplexing
commonly used in linear channels, information is encoded in the nonlinear
frequencies and their spectral amplitudes. Unlike most other fiber-optic
transmission schemes, this technique deals with both dispersion and
nonlinearity directly and unconditionally without the need for dispersion or
nonlinearity compensation methods. This first paper explains the mathematical
tools that underlie the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3663</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3663</id><created>2012-02-16</created><updated>2013-11-18</updated><authors><author><keyname>Ames</keyname><forenames>Brendan P. W.</forenames></author></authors><title>Guaranteed clustering and biclustering via semidefinite programming</title><categories>math.OC cs.LG</categories><doi>10.1007/s10107-013-0729-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying clusters of similar objects in data plays a significant role in a
wide range of applications. As a model problem for clustering, we consider the
densest k-disjoint-clique problem, whose goal is to identify the collection of
k disjoint cliques of a given weighted complete graph maximizing the sum of the
densities of the complete subgraphs induced by these cliques. In this paper, we
establish conditions ensuring exact recovery of the densest k cliques of a
given graph from the optimal solution of a particular semidefinite program. In
particular, the semidefinite relaxation is exact for input graphs corresponding
to data consisting of k large, distinct clusters and a smaller number of
outliers. This approach also yields a semidefinite relaxation for the
biclustering problem with similar recovery guarantees. Given a set of objects
and a set of features exhibited by these objects, biclustering seeks to
simultaneously group the objects and features according to their expression
levels. This problem may be posed as partitioning the nodes of a weighted
bipartite complete graph such that the sum of the densities of the resulting
bipartite complete subgraphs is maximized. As in our analysis of the densest
k-disjoint-clique problem, we show that the correct partition of the objects
and features can be recovered from the optimal solution of a semidefinite
program in the case that the given data consists of several disjoint sets of
objects exhibiting similar features. Empirical evidence from numerical
experiments supporting these theoretical guarantees is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3667</identifier>
 <datestamp>2012-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3667</id><created>2012-02-16</created><updated>2012-02-22</updated><authors><author><keyname>Sequeda</keyname><forenames>Juan F.</forenames></author><author><keyname>Arenas</keyname><forenames>Marcelo</forenames></author><author><keyname>Miranker</keyname><forenames>Daniel P.</forenames></author></authors><title>On Directly Mapping Relational Databases to RDF and OWL (Extended
  Version)</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mapping relational databases to RDF is a fundamental problem for the
development of the Semantic Web. We present a solution, inspired by draft
methods defined by the W3C where relational databases are directly mapped to
RDF and OWL. Given a relational database schema and its integrity constraints,
this direct mapping produces an OWL ontology, which, provides the basis for
generating RDF instances. The semantics of this mapping is defined using
Datalog. Two fundamental properties are information preservation and query
preservation. We prove that our mapping satisfies both conditions, even for
relational databases that contain null values. We also consider two desirable
properties: monotonicity and semantics preservation. We prove that our mapping
is monotone and also prove that no monotone mapping, including ours, is
semantic preserving. We realize that monotonicity is an obstacle for semantic
preservation and thus present a non-monotone direct mapping that is semantics
preserving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3669</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3669</id><created>2012-02-16</created><updated>2012-05-16</updated><authors><author><keyname>Al-Kiswany</keyname><forenames>Samer</forenames></author><author><keyname>Gharaibeh</keyname><forenames>Abdullah</forenames></author><author><keyname>Ripeanu</keyname><forenames>Matei</forenames></author></authors><title>GPUs as Storage System Accelerators</title><categories>cs.DC</categories><comments>IEEE Transactions on Parallel and Distributed Systems, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massively multicore processors, such as Graphics Processing Units (GPUs),
provide, at a comparable price, a one order of magnitude higher peak
performance than traditional CPUs. This drop in the cost of computation, as any
order-of-magnitude drop in the cost per unit of performance for a class of
system components, triggers the opportunity to redesign systems and to explore
new ways to engineer them to recalibrate the cost-to-performance relation. This
project explores the feasibility of harnessing GPUs' computational power to
improve the performance, reliability, or security of distributed storage
systems. In this context, we present the design of a storage system prototype
that uses GPU offloading to accelerate a number of computationally intensive
primitives based on hashing, and introduce techniques to efficiently leverage
the processing power of GPUs. We evaluate the performance of this prototype
under two configurations: as a content addressable storage system that
facilitates online similarity detection between successive versions of the same
file and as a traditional system that uses hashing to preserve data integrity.
Further, we evaluate the impact of offloading to the GPU on competing
applications' performance. Our results show that this technique can bring
tangible performance gains without negatively impacting the performance of
concurrently running applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3672</identifier>
 <datestamp>2015-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3672</id><created>2012-02-16</created><updated>2015-08-16</updated><authors><author><keyname>Czajka</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Higher-order illative combinatory logic</title><categories>math.LO cs.LO</categories><journal-ref>Journal of Symbolic Logic, vol. 78, issue 3, pp. 837-872, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a model construction for a system of higher-order illative
combinatory logic $\mathcal{I}_\omega$, thus establishing its strong
consistency. We also use a variant of this construction to provide a complete
embedding of first-order intuitionistic predicate logic with second-order
propositional quantifiers into the system $\mathcal{I}_0$ of Barendregt, Bunder
and Dekkers, which gives a partial answer to a question posed by these authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3683</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3683</id><created>2012-02-16</created><authors><author><keyname>Dutta</keyname><forenames>Debojyoti</forenames></author><author><keyname>Kapralov</keyname><forenames>Michael</forenames></author><author><keyname>Post</keyname><forenames>Ian</forenames></author><author><keyname>Shinde</keyname><forenames>Rajendra</forenames></author></authors><title>Optimal bandwidth-aware VM allocation for Infrastructure-as-a-Service</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infrastructure-as-a-Service (IaaS) providers need to offer richer services to
be competitive while optimizing their resource usage to keep costs down. Richer
service offerings include new resource request models involving bandwidth
guarantees between virtual machines (VMs). Thus we consider the following
problem: given a VM request graph (where nodes are VMs and edges represent
virtual network connectivity between the VMs) and a real data center topology,
find an allocation of VMs to servers that satisfies the bandwidth guarantees
for every virtual network edge---which maps to a path in the physical
network---and minimizes congestion of the network.
  Previous work has shown that for arbitrary networks and requests, finding the
optimal embedding satisfying bandwidth requests is $\mathcal{NP}$-hard.
However, in most data center architectures, the routing protocols employed are
based on a spanning tree of the physical network. In this paper, we prove that
the problem remains $\mathcal{NP}$-hard even when the physical network topology
is restricted to be a tree, and the request graph topology is also restricted.
We also present a dynamic programming algorithm for computing the optimal
embedding in a tree network which runs in time $O(3^kn)$, where $n$ is the
number of nodes in the physical topology and $k$ is the size of the request
graph, which is well suited for practical requests which have small $k$. Such
requests form a large class of web-service and enterprise workloads. Also, if
we restrict the requests topology to a clique (all VMs connected to a virtual
switch with uniform bandwidth requirements), we show that the dynamic
programming algorithm can be modified to output the minimum congestion
embedding in time $O(k^2n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3684</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3684</id><created>2012-02-16</created><authors><author><keyname>Leordeanu</keyname><forenames>Marius</forenames></author><author><keyname>Sukthankar</keyname><forenames>Rahul</forenames></author><author><keyname>Sminchisescu</keyname><forenames>Cristian</forenames></author></authors><title>Generalized Boundaries from Multiple Image Interpretations</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boundary detection is essential for a variety of computer vision tasks such
as segmentation and recognition. In this paper we propose a unified formulation
and a novel algorithm that are applicable to the detection of different types
of boundaries, such as intensity edges, occlusion boundaries or object category
specific boundaries. Our formulation leads to a simple method with
state-of-the-art performance and significantly lower computational cost than
existing methods. We evaluate our algorithm on different types of boundaries,
from low-level boundaries extracted in natural images, to occlusion boundaries
obtained using motion cues and RGB-D cameras, to boundaries from
soft-segmentation. We also propose a novel method for figure/ground
soft-segmentation that can be used in conjunction with our boundary detection
method and improve its accuracy at almost no extra computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3686</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3686</id><created>2012-02-16</created><authors><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Fu</keyname><forenames>Ada Waichee</forenames></author><author><keyname>Wong</keyname><forenames>Raywong Chi-Wing</forenames></author></authors><title>Inferential or Differential: Privacy Laws Dictate</title><categories>cs.DB</categories><comments>13 pages and 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  So far, privacy models follow two paradigms. The first paradigm, termed
inferential privacy in this paper, focuses on the risk due to statistical
inference of sensitive information about a target record from other records in
the database. The second paradigm, known as differential privacy, focuses on
the risk to an individual when included in, versus when not included in, the
database. The contribution of this paper consists of two parts. The first part
presents a critical analysis on differential privacy with two results: (i) the
differential privacy mechanism does not provide inferential privacy, (ii) the
impossibility result about achieving Dalenius's privacy goal [5] is based on an
adversary simulated by a Turing machine, but a human adversary may behave
differently; consequently, the practical implication of the impossibility
result remains unclear. The second part of this work is devoted to a solution
addressing three major drawbacks in previous approaches to inferential privacy:
lack of flexibility for handling variable sensitivity, poor utility, and
vulnerability to auxiliary information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3698</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3698</id><created>2012-02-14</created><authors><author><keyname>Apsel</keyname><forenames>Udi</forenames></author><author><keyname>Brafman</keyname><forenames>Ronen I.</forenames></author></authors><title>Extended Lifted Inference with Joint Formulas</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-11-18</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The First-Order Variable Elimination (FOVE) algorithm allows exact inference
to be applied directly to probabilistic relational models, and has proven to be
vastly superior to the application of standard inference methods on a grounded
propositional model. Still, FOVE operators can be applied under restricted
conditions, often forcing one to resort to propositional inference. This paper
aims to extend the applicability of FOVE by providing two new model conversion
operators: the first and the primary is joint formula conversion and the second
is just-different counting conversion. These new operations allow efficient
inference methods to be applied directly on relational models, where no
existing efficient method could be applied hitherto. In addition, aided by
these capabilities, we show how to adapt FOVE to provide exact solutions to
Maximum Expected Utility (MEU) queries over relational models for decision
under uncertainty. Experimental evaluations show our algorithms to provide
significant speedup over the alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3699</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3699</id><created>2012-02-14</created><authors><author><keyname>Asmuth</keyname><forenames>John</forenames></author><author><keyname>Littman</keyname><forenames>Michael L.</forenames></author></authors><title>Learning is planning: near Bayes-optimal reinforcement learning via
  Monte-Carlo tree search</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-19-26</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayes-optimal behavior, while well-defined, is often difficult to achieve.
Recent advances in the use of Monte-Carlo tree search (MCTS) have shown that it
is possible to act near-optimally in Markov Decision Processes (MDPs) with very
large or infinite state spaces. Bayes-optimal behavior in an unknown MDP is
equivalent to optimal behavior in the known belief-space MDP, although the size
of this belief-space MDP grows exponentially with the amount of history
retained, and is potentially infinite. We show how an agent can use one
particular MCTS algorithm, Forward Search Sparse Sampling (FSSS), in an
efficient way to act nearly Bayes-optimally for all but a polynomial number of
steps, assuming that FSSS can be used to act efficiently in any possible
underlying MDP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3700</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3700</id><created>2012-02-14</created><authors><author><keyname>Bachrach</keyname><forenames>Yoram</forenames></author><author><keyname>Meir</keyname><forenames>Reshef</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Solving Cooperative Reliability Games</title><categories>cs.GT cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-27-34</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative games model the allocation of profit from joint actions,
following considerations such as stability and fairness. We propose the
reliability extension of such games, where agents may fail to participate in
the game. In the reliability extension, each agent only &quot;survives&quot; with a
certain probability, and a coalition's value is the probability that its
surviving members would be a winning coalition in the base game. We study
prominent solution concepts in such games, showing how to approximate the
Shapley value and how to compute the core in games with few agent types. We
also show that applying the reliability extension may stabilize the game,
making the core non-empty even when the base game has an empty core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3701</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3701</id><created>2012-02-14</created><authors><author><keyname>Bellala</keyname><forenames>Gowtham</forenames></author><author><keyname>Stanley</keyname><forenames>Jason</forenames></author><author><keyname>Scott</keyname><forenames>Clayton</forenames></author><author><keyname>Bhavnani</keyname><forenames>Suresh K.</forenames></author></authors><title>Active Diagnosis via AUC Maximization: An Efficient Approach for
  Multiple Fault Identification in Large Scale, Noisy Networks</title><categories>cs.LG cs.AI stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-35-42</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of active diagnosis arises in several applications such as
disease diagnosis, and fault diagnosis in computer networks, where the goal is
to rapidly identify the binary states of a set of objects (e.g., faulty or
working) by sequentially selecting, and observing, (noisy) responses to binary
valued queries. Current algorithms in this area rely on loopy belief
propagation for active query selection. These algorithms have an exponential
time complexity, making them slow and even intractable in large networks. We
propose a rank-based greedy algorithm that sequentially chooses queries such
that the area under the ROC curve of the rank-based output is maximized. The
AUC criterion allows us to make a simplifying assumption that significantly
reduces the complexity of active query selection (from exponential to near
quadratic), with little or no compromise on the performance quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3702</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3702</id><created>2012-02-14</created><authors><author><keyname>Bijral</keyname><forenames>Avleen S.</forenames></author><author><keyname>Ratliff</keyname><forenames>Nathan</forenames></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author></authors><title>Semi-supervised Learning with Density Based Distances</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-43-50</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple, yet effective, approach to Semi-Supervised Learning. Our
approach is based on estimating density-based distances (DBD) using a shortest
path calculation on a graph. These Graph-DBD estimates can then be used in any
distance-based supervised learning method, such as Nearest Neighbor methods and
SVMs with RBF kernels. In order to apply the method to very large data sets, we
also present a novel algorithm which integrates nearest neighbor computations
into the shortest path search and can find exact shortest paths even in
extremely large dense graphs. Significant runtime improvement over the commonly
used Laplacian regularization method is then shown on a large scale dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3703</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3703</id><created>2012-02-14</created><authors><author><keyname>Celikkaya</keyname><forenames>E. Busra</forenames></author><author><keyname>Shelton</keyname><forenames>Christian R.</forenames></author><author><keyname>Lam</keyname><forenames>William</forenames></author></authors><title>Factored Filtering of Continuous-Time Systems</title><categories>cs.SY cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-61-68</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider filtering for a continuous-time, or asynchronous, stochastic
system where the full distribution over states is too large to be stored or
calculated. We assume that the rate matrix of the system can be compactly
represented and that the belief distribution is to be approximated as a product
of marginals. The essential computation is the matrix exponential. We look at
two different methods for its computation: ODE integration and uniformization
of the Taylor expansion. For both we consider approximations in which only a
factored belief state is maintained. For factored uniformization we demonstrate
that the KL-divergence of the filtering is bounded. Our experimental results
confirm our factored uniformization performs better than previously suggested
uniformization methods and the mean field algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3704</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3704</id><created>2012-02-14</created><authors><author><keyname>Chakraborty</keyname><forenames>Mithun</forenames></author><author><keyname>Das</keyname><forenames>Sanmay</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Near-Optimal Target Learning With Stochastic Binary Signals</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-69-76</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study learning in a noisy bisection model: specifically, Bayesian
algorithms to learn a target value V given access only to noisy realizations of
whether V is less than or greater than a threshold theta. At step t = 0, 1, 2,
..., the learner sets threshold theta t and observes a noisy realization of
sign(V - theta t). After T steps, the goal is to output an estimate V^ which is
within an eta-tolerance of V . This problem has been studied, predominantly in
environments with a fixed error probability q &lt; 1/2 for the noisy realization
of sign(V - theta t). In practice, it is often the case that q can approach
1/2, especially as theta -&gt; V, and there is little known when this happens. We
give a pseudo-Bayesian algorithm which provably converges to V. When the true
prior matches our algorithm's Gaussian prior, we show near-optimal expected
performance. Our methods extend to the general multiple-threshold setting where
the observation noisily indicates which of k &gt;= 2 regions V belongs to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3705</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3705</id><created>2012-02-14</created><authors><author><keyname>Chapman</keyname><forenames>Archie C.</forenames></author><author><keyname>Williamson</keyname><forenames>Simon A.</forenames></author><author><keyname>Jennings</keyname><forenames>Nicholas R.</forenames></author></authors><title>Filtered Fictitious Play for Perturbed Observation Potential Games and
  Decentralised POMDPs</title><categories>cs.GT cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-77-85</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Potential games and decentralised partially observable MDPs (Dec-POMDPs) are
two commonly used models of multi-agent interaction, for static optimisation
and sequential decisionmaking settings, respectively. In this paper we
introduce filtered fictitious play for solving repeated potential games in
which each player's observations of others' actions are perturbed by random
noise, and use this algorithm to construct an online learning method for
solving Dec-POMDPs. Specifically, we prove that noise in observations prevents
standard fictitious play from converging to Nash equilibrium in potential
games, which also makes fictitious play impractical for solving Dec-POMDPs. To
combat this, we derive filtered fictitious play, and provide conditions under
which it converges to a Nash equilibrium in potential games with noisy
observations. We then use filtered fictitious play to construct a solver for
Dec-POMDPs, and demonstrate our new algorithm's performance in a box pushing
problem. Our results show that we consistently outperform the state-of-the-art
Dec-POMDP solver by an average of 100% across the range of noise in the
observation function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3706</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3706</id><created>2012-02-14</created><authors><author><keyname>Charlin</keyname><forenames>Laurent</forenames></author><author><keyname>Zemel</keyname><forenames>Richard S.</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author></authors><title>A Framework for Optimizing Paper Matching</title><categories>cs.IR cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-86-95</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the heart of many scientific conferences is the problem of matching
submitted papers to suitable reviewers. Arriving at a good assignment is a
major and important challenge for any conference organizer. In this paper we
propose a framework to optimize paper-to-reviewer assignments. Our framework
uses suitability scores to measure pairwise affinity between papers and
reviewers. We show how learning can be used to infer suitability scores from a
small set of provided scores, thereby reducing the burden on reviewers and
organizers. We frame the assignment problem as an integer program and propose
several variations for the paper-to-reviewer matching domain. We also explore
how learning and matching interact. Experiments on two conference data sets
examine the performance of several learning methods as well as the
effectiveness of the matching formulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3707</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3707</id><created>2012-02-14</created><authors><author><keyname>Chatterjee</keyname><forenames>Shaunak</forenames></author><author><keyname>Russell</keyname><forenames>Stuart</forenames></author></authors><title>A temporally abstracted Viterbi algorithm</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-96-104</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hierarchical problem abstraction, when applicable, may offer exponential
reductions in computational complexity. Previous work on coarse-to-fine dynamic
programming (CFDP) has demonstrated this possibility using state abstraction to
speed up the Viterbi algorithm. In this paper, we show how to apply temporal
abstraction to the Viterbi problem. Our algorithm uses bounds derived from
analysis of coarse timescales to prune large parts of the state trellis at
finer timescales. We demonstrate improvements of several orders of magnitude
over the standard Viterbi algorithm, as well as significant speedups over CFDP,
for problems whose state variables evolve at widely differing rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3708</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3708</id><created>2012-02-14</created><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Lin</keyname><forenames>Qihang</forenames></author><author><keyname>Kim</keyname><forenames>Seyoung</forenames></author><author><keyname>Carbonell</keyname><forenames>Jaime G.</forenames></author><author><keyname>Xing</keyname><forenames>Eric P.</forenames></author></authors><title>Smoothing Proximal Gradient Method for General Structured Sparse
  Learning</title><categories>cs.LG stat.ML</categories><comments>arXiv admin note: substantial text overlap with arXiv:1005.4717</comments><proxy>auai</proxy><report-no>UAI-P-2011-PG-105-114</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of learning high dimensional regression models
regularized by a structured-sparsity-inducing penalty that encodes prior
structural information on either input or output sides. We consider two widely
adopted types of such penalties as our motivating examples: 1) overlapping
group lasso penalty, based on the l1/l2 mixed-norm penalty, and 2) graph-guided
fusion penalty. For both types of penalties, due to their non-separability,
developing an efficient optimization method has remained a challenging problem.
In this paper, we propose a general optimization approach, called smoothing
proximal gradient method, which can solve the structured sparse regression
problems with a smooth convex loss and a wide spectrum of
structured-sparsity-inducing penalties. Our approach is based on a general
smoothing technique of Nesterov. It achieves a convergence rate faster than the
standard first-order method, subgradient method, and is much more scalable than
the most widely used interior-point method. Numerical results are reported to
demonstrate the efficiency and scalability of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3709</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3709</id><created>2012-02-14</created><authors><author><keyname>Choi</keyname><forenames>Arthur</forenames></author><author><keyname>Refaat</keyname><forenames>Khaled S.</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>EDML: A Method for Learning Parameters in Bayesian Networks</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-115-124</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method called EDML for learning MAP parameters in binary
Bayesian networks under incomplete data. The method assumes Beta priors and can
be used to learn maximum likelihood parameters when the priors are
uninformative. EDML exhibits interesting behaviors, especially when compared to
EM. We introduce EDML, explain its origin, and study some of its properties
both analytically and empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3710</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3710</id><created>2012-02-14</created><authors><author><keyname>Chun</keyname><forenames>SangIn</forenames></author><author><keyname>Shachter</keyname><forenames>Ross D.</forenames></author></authors><title>Strictly Proper Mechanisms with Cooperating Players</title><categories>cs.GT cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-125-134</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction markets provide an efficient means to assess uncertain quantities
from forecasters. Traditional and competitive strictly proper scoring rules
have been shown to incentivize players to provide truthful probabilistic
forecasts. However, we show that when those players can cooperate, these
mechanisms can instead discourage them from reporting what they really believe.
When players with different beliefs are able to cooperate and form a coalition,
these mechanisms admit arbitrage and there is a report that will always pay
coalition members more than their truthful forecasts. If the coalition were
created by an intermediary, such as a web portal, the intermediary would be
guaranteed a profit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3711</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3711</id><created>2012-02-14</created><authors><author><keyname>Claassen</keyname><forenames>Tom</forenames></author><author><keyname>Heskes</keyname><forenames>Tom</forenames></author></authors><title>A Logical Characterization of Constraint-Based Causal Discovery</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-135-144</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to constraint-based causal discovery, that takes
the form of straightforward logical inference, applied to a list of simple,
logical statements about causal relations that are derived directly from
observed (in)dependencies. It is both sound and complete, in the sense that all
invariant features of the corresponding partial ancestral graph (PAG) are
identified, even in the presence of latent variables and selection bias. The
approach shows that every identifiable causal relation corresponds to one of
just two fundamental forms. More importantly, as the basic building blocks of
the method do not rely on the detailed (graphical) structure of the
corresponding PAG, it opens up a range of new opportunities, including more
robust inference, detailed accountability, and application to large models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3712</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3712</id><created>2012-02-14</created><authors><author><keyname>Cortes</keyname><forenames>Corinna</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>Ensembles of Kernel Predictors</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-145-152</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the problem of learning with a finite and possibly large
set of p base kernels. It presents a theoretical and empirical analysis of an
approach addressing this problem based on ensembles of kernel predictors. This
includes novel theoretical guarantees based on the Rademacher complexity of the
corresponding hypothesis sets, the introduction and analysis of a learning
algorithm based on these hypothesis sets, and a series of experiments using
ensembles of kernel predictors with several data sets. Both convex combinations
of kernel-based hypotheses and more general Lq-regularized nonnegative
combinations are analyzed. These theoretical, algorithmic, and empirical
results are compared with those achieved by using learning kernel techniques,
which can be viewed as another approach for solving the same problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3713</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3713</id><created>2012-02-14</created><authors><author><keyname>Cussens</keyname><forenames>James</forenames></author></authors><title>Bayesian network learning with cutting planes</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-153-160</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of learning the structure of Bayesian networks from complete
discrete data with a limit on parent set size is considered. Learning is cast
explicitly as an optimisation problem where the goal is to find a BN structure
which maximises log marginal likelihood (BDe score). Integer programming,
specifically the SCIP framework, is used to solve this optimisation problem.
Acyclicity constraints are added to the integer program (IP) during solving in
the form of cutting planes. Finding good cutting planes is the key to the
success of the approach -the search for such cutting planes is effected using a
sub-IP. Results show that this is a particularly fast method for exact BN
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3714</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3714</id><created>2012-02-14</created><authors><author><keyname>Deng</keyname><forenames>Kun</forenames></author><author><keyname>Pineau</keyname><forenames>Joelle</forenames></author><author><keyname>Murphy</keyname><forenames>Susan A.</forenames></author></authors><title>Active Learning for Developing Personalized Treatment</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-161-168</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The personalization of treatment via bio-markers and other risk categories
has drawn increasing interest among clinical scientists. Personalized treatment
strategies can be learned using data from clinical trials, but such trials are
very costly to run. This paper explores the use of active learning techniques
to design more efficient trials, addressing issues such as whom to recruit, at
what point in the trial, and which treatment to assign, throughout the duration
of the trial. We propose a minimax bandit model with two different optimization
criteria, and discuss the computational challenges and issues pertaining to
this approach. We evaluate our active learning policies using both simulated
data, and data modeled after a clinical trial for treating depressed
individuals, and contrast our methods with other plausible active learning
policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3715</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3715</id><created>2012-02-14</created><authors><author><keyname>Dvijotham</keyname><forenames>Krishnamurthy</forenames></author><author><keyname>Todorov</keyname><forenames>Emanuel</forenames></author></authors><title>A Unifying Framework for Linearly Solvable Control</title><categories>cs.SY math.OC</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-179-186</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has led to the development of an elegant theory of Linearly
Solvable Markov Decision Processes (LMDPs) and related Path-Integral Control
Problems. Traditionally, MDPs have been formulated using stochastic policies
and a control cost based on the KL divergence. In this paper, we extend this
framework to a more general class of divergences: the Renyi divergences. These
are a more general class of divergences parameterized by a continuous parameter
that include the KL divergence as a special case. The resulting control
problems can be interpreted as solving a risk-sensitive version of the LMDP
problem. For a &gt; 0, we get risk-averse behavior (the degree of risk-aversion
increases with a) and for a &lt; 0, we get risk-seeking behavior. We recover LMDPs
in the limit as a -&gt; 0. This work generalizes the recently developed
risk-sensitive path-integral control formalism which can be seen as the
continuous-time limit of results obtained in this paper. To the best of our
knowledge, this is a general theory of linearly solvable control and includes
all previous work as a special case. We also present an alternative
interpretation of these results as solving a 2-player (cooperative or
competitive) Markov Game. From the linearity follow a number of nice properties
including compositionality of control laws and a path-integral representation
of the value function. We demonstrate the usefulness of the framework on
control problems with noise where different values of lead to qualitatively
different control behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3716</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3716</id><created>2012-02-14</created><authors><author><keyname>Edakunni</keyname><forenames>Narayanan U.</forenames></author><author><keyname>Brown</keyname><forenames>Gary</forenames></author><author><keyname>Kovacs</keyname><forenames>Tim</forenames></author></authors><title>Boosting as a Product of Experts</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-187-194</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive a novel probabilistic model of boosting as a Product
of Experts. We re-derive the boosting algorithm as a greedy incremental model
selection procedure which ensures that addition of new experts to the ensemble
does not decrease the likelihood of the data. These learning rules lead to a
generic boosting algorithm - POE- Boost which turns out to be similar to the
AdaBoost algorithm under certain assumptions on the expert probabilities. The
paper then extends the POEBoost algorithm to POEBoost.CS which handles
hypothesis that produce probabilistic predictions. This new algorithm is shown
to have better generalization performance compared to other state of the art
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3717</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3717</id><created>2012-02-14</created><authors><author><keyname>Fard</keyname><forenames>Mahdi MIlani</forenames></author><author><keyname>Pineau</keyname><forenames>Joelle</forenames></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames></author></authors><title>PAC-Bayesian Policy Evaluation for Reinforcement Learning</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-195-202</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian priors offer a compact yet general means of incorporating domain
knowledge into many learning tasks. The correctness of the Bayesian analysis
and inference, however, largely depends on accuracy and correctness of these
priors. PAC-Bayesian methods overcome this problem by providing bounds that
hold regardless of the correctness of the prior distribution. This paper
introduces the first PAC-Bayesian bound for the batch reinforcement learning
problem with function approximation. We show how this bound can be used to
perform model-selection in a transfer learning scenario. Our empirical results
confirm that PAC-Bayesian policy evaluation is able to leverage prior
distributions when they are informative and, unlike standard Bayesian RL
approaches, ignore them when they are misleading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3718</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3718</id><created>2012-02-14</created><authors><author><keyname>Fargier</keyname><forenames>Helene</forenames></author><author><keyname>Amor</keyname><forenames>Nahla Ben</forenames></author><author><keyname>Guezguez</keyname><forenames>Wided</forenames></author></authors><title>On the Complexity of Decision Making in Possibilistic Decision Trees</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-203-210</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When the information about uncertainty cannot be quantified in a simple,
probabilistic way, the topic of possibilistic decision theory is often a
natural one to consider. The development of possibilistic decision theory has
lead to a series of possibilistic criteria, e.g pessimistic possibilistic
qualitative utility, possibilistic likely dominance, binary possibilistic
utility and possibilistic Choquet integrals. This paper focuses on sequential
decision making in possibilistic decision trees. It proposes a complexity study
of the problem of finding an optimal strategy depending on the monotonicity
property of the optimization criteria which allows the application of dynamic
programming that offers a polytime reduction of the decision problem. It also
shows that possibilistic Choquet integrals do not satisfy this property, and
that in this case the optimization problem is NP - hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3719</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3719</id><created>2012-02-14</created><authors><author><keyname>Fierens</keyname><forenames>Daan</forenames></author><author><keyname>Broeck</keyname><forenames>Guy Van den</forenames></author><author><keyname>Thon</keyname><forenames>Ingo</forenames></author><author><keyname>Gutmann</keyname><forenames>Bernd</forenames></author><author><keyname>De Raedt</keyname><forenames>Luc</forenames></author></authors><title>Inference in Probabilistic Logic Programs using Weighted CNF's</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-211-220</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic logic programs are logic programs in which some of the facts
are annotated with probabilities. Several classical probabilistic inference
tasks (such as MAP and computing marginals) have not yet received a lot of
attention for this formalism. The contribution of this paper is that we develop
efficient inference algorithms for these tasks. This is based on a conversion
of the probabilistic logic program and the query and evidence to a weighted CNF
formula. This allows us to reduce the inference tasks to well-studied tasks
such as weighted model counting. To solve such tasks, we employ
state-of-the-art methods. We consider multiple methods for the conversion of
the programs as well as for inference on the weighted CNF. The resulting
approach is evaluated experimentally and shown to improve upon the
state-of-the-art in probabilistic logic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3720</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3720</id><created>2012-02-14</created><authors><author><keyname>Furmston</keyname><forenames>Thomas</forenames></author><author><keyname>Barber</keyname><forenames>David</forenames></author></authors><title>Efficient Inference in Markov Control Problems</title><categories>cs.SY cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-221-229</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov control algorithms that perform smooth, non-greedy updates of the
policy have been shown to be very general and versatile, with policy gradient
and Expectation Maximisation algorithms being particularly popular. For these
algorithms, marginal inference of the reward weighted trajectory distribution
is required to perform policy updates. We discuss a new exact inference
algorithm for these marginals in the finite horizon case that is more efficient
than the standard approach based on classical forward-backward recursions. We
also provide a principled extension to infinite horizon Markov Decision
Problems that explicitly accounts for an infinite horizon. This extension
provides a novel algorithm for both policy gradients and Expectation
Maximisation in infinite horizon problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3721</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3721</id><created>2012-02-14</created><authors><author><keyname>Giang</keyname><forenames>Phan H.</forenames></author></authors><title>Dynamic consistency and decision making under vacuous belief</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-230-237</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ideas about decision making under ignorance in economics are combined
with the ideas about uncertainty representation in computer science. The
combination sheds new light on the question of how artificial agents can act in
a dynamically consistent manner. The notion of sequential consistency is
formalized by adapting the law of iterated expectation for plausibility
measures. The necessary and sufficient condition for a certainty equivalence
operator for Nehring-Puppe's preference to be sequentially consistent is given.
This result sheds light on the models of decision making under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3722</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3722</id><created>2012-02-14</created><authors><author><keyname>Givoni</keyname><forenames>Inmar</forenames></author><author><keyname>Chung</keyname><forenames>Clement</forenames></author><author><keyname>Frey</keyname><forenames>Brendan J.</forenames></author></authors><title>Hierarchical Affinity Propagation</title><categories>cs.LG cs.AI stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-238-246</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Affinity propagation is an exemplar-based clustering algorithm that finds a
set of data-points that best exemplify the data, and associates each datapoint
with one exemplar. We extend affinity propagation in a principled way to solve
the hierarchical clustering problem, which arises in a variety of domains
including biology, sensor networks and decision making in operational research.
We derive an inference algorithm that operates by propagating information up
and down the hierarchy, and is efficient despite the high-order potentials
required for the graphical model formulation. We demonstrate that our method
outperforms greedy techniques that cluster one layer at a time. We show that on
an artificial dataset designed to mimic the HIV-strain mutation dynamics, our
method outperforms related methods. For real HIV sequences, where the ground
truth is not available, we show our method achieves better results, in terms of
the underlying objective function, and show the results correspond meaningfully
to geographical location and strain subtypes. Finally we report results on
using the method for the analysis of mass spectra, showing it performs
favorably compared to state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3723</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3723</id><created>2012-02-14</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Domingos</keyname><forenames>Pedro</forenames></author></authors><title>Approximation by Quantization</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-247-255</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference in graphical models consists of repeatedly multiplying and summing
out potentials. It is generally intractable because the derived potentials
obtained in this way can be exponentially large. Approximate inference
techniques such as belief propagation and variational methods combat this by
simplifying the derived potentials, typically by dropping variables from them.
We propose an alternate method for simplifying potentials: quantizing their
values. Quantization causes different states of a potential to have the same
value, and therefore introduces context-specific independencies that can be
exploited to represent the potential more compactly. We use algebraic decision
diagrams (ADDs) to do this efficiently. We apply quantization and ADD reduction
to variable elimination and junction tree propagation, yielding a family of
bounded approximate inference schemes. Our experimental tests show that our new
schemes significantly outperform state-of-the-art approaches on many benchmark
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3724</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3724</id><created>2012-02-14</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Domingos</keyname><forenames>Pedro</forenames></author></authors><title>Probabilistic Theorem Proving</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-256-265</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many representation schemes combining first-order logic and probability have
been proposed in recent years. Progress in unifying logical and probabilistic
inference has been slower. Existing methods are mainly variants of lifted
variable elimination and belief propagation, neither of which take logical
structure into account. We propose the first method that has the full power of
both graphical model inference and first-order theorem proving (in finite
domains with Herbrand interpretations). We first define probabilistic theorem
proving, their generalization, as the problem of computing the probability of a
logical formula given the probabilities or weights of a set of formulas. We
then show how this can be reduced to the problem of lifted weighted model
counting, and develop an efficient algorithm for the latter. We prove the
correctness of this algorithm, investigate its properties, and show how it
generalizes previous approaches. Experiments show that it greatly outperforms
lifted variable elimination when logical structure is present. Finally, we
propose an algorithm for approximate probabilistic theorem proving, and show
that it can greatly outperform lifted belief propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3725</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3725</id><created>2012-02-14</created><authors><author><keyname>Gu</keyname><forenames>Quanquan</forenames></author><author><keyname>Li</keyname><forenames>Zhenhui</forenames></author><author><keyname>Han</keyname><forenames>Jiawei</forenames></author></authors><title>Generalized Fisher Score for Feature Selection</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-266-273</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fisher score is one of the most widely used supervised feature selection
methods. However, it selects each feature independently according to their
scores under the Fisher criterion, which leads to a suboptimal subset of
features. In this paper, we present a generalized Fisher score to jointly
select features. It aims at finding an subset of features, which maximize the
lower bound of traditional Fisher score. The resulting feature selection
problem is a mixed integer programming, which can be reformulated as a
quadratically constrained linear programming (QCLP). It is solved by cutting
plane algorithm, in each iteration of which a multiple kernel learning problem
is solved alternatively by multivariate ridge regression and projected gradient
descent. Experiments on benchmark data sets indicate that the proposed method
outperforms Fisher score as well as many other state-of-the-art feature
selection methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3726</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3726</id><created>2012-02-14</created><authors><author><keyname>Guillory</keyname><forenames>Andrew</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>Active Semi-Supervised Learning using Submodular Functions</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-274-282</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider active, semi-supervised learning in an offline transductive
setting. We show that a previously proposed error bound for active learning on
undirected weighted graphs can be generalized by replacing graph cut with an
arbitrary symmetric submodular function. Arbitrary non-symmetric submodular
functions can be used via symmetrization. Different choices of submodular
functions give different versions of the error bound that are appropriate for
different kinds of problems. Moreover, the bound is deterministic and holds for
adversarially chosen labels. We show exactly minimizing this error bound is
NP-complete. However, we also introduce for any submodular function an
associated active semi-supervised learning method that approximately minimizes
the corresponding error bound. We show that the error bound is tight in the
sense that there is no other bound of the same form which is better. Our
theoretical results are supported by experiments on real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3727</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3727</id><created>2012-02-14</created><authors><author><keyname>Gutmann</keyname><forenames>Michael</forenames></author><author><keyname>Hirayama</keyname><forenames>Jun-ichiro</forenames></author></authors><title>Bregman divergence as general framework to estimate unnormalized
  statistical models</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-283-290</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Bregman divergence provides a rich framework to estimate
unnormalized statistical models for continuous or discrete random variables,
that is, models which do not integrate or sum to one, respectively. We prove
that recent estimation methods such as noise-contrastive estimation, ratio
matching, and score matching belong to the proposed framework, and explain
their interconnection based on supervised learning. Further, we discuss the
role of boosting in unsupervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3728</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3728</id><created>2012-02-14</created><authors><author><keyname>Hajishirzi</keyname><forenames>Hannaneh</forenames></author><author><keyname>Hockenmaier</keyname><forenames>Julia</forenames></author><author><keyname>Mueller</keyname><forenames>Erik T.</forenames></author><author><keyname>Amir</keyname><forenames>Eyal</forenames></author></authors><title>Reasoning about RoboCup Soccer Narratives</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-291-300</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach for learning to translate simple narratives,
i.e., texts (sequences of sentences) describing dynamic systems, into coherent
sequences of events without the need for labeled training data. Our approach
incorporates domain knowledge in the form of preconditions and effects of
events, and we show that it outperforms state-of-the-art supervised learning
systems on the task of reconstructing RoboCup soccer games from their
commentaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3729</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3729</id><created>2012-02-14</created><authors><author><keyname>Hansen</keyname><forenames>Eric A.</forenames></author></authors><title>Suboptimality Bounds for Stochastic Shortest Path Problems</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-301-310</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider how to use the Bellman residual of the dynamic programming
operator to compute suboptimality bounds for solutions to stochastic shortest
path problems. Such bounds have been previously established only in the special
case that &quot;all policies are proper,&quot; in which case the dynamic programming
operator is known to be a contraction, and have been shown to be easily
computable only in the more limited special case of discounting. Under the
condition that transition costs are positive, we show that suboptimality bounds
can be easily computed even when not all policies are proper. In the general
case when there are no restrictions on transition costs, the analysis is more
complex. But we present preliminary results that show such bounds are possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3730</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3730</id><created>2012-02-14</created><authors><author><keyname>Hartikainen</keyname><forenames>Jouni</forenames></author><author><keyname>Sarkka</keyname><forenames>Simo</forenames></author></authors><title>Sequential Inference for Latent Force Models</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-311-318</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent force models (LFMs) are hybrid models combining mechanistic principles
with non-parametric components. In this article, we shall show how LFMs can be
equivalently formulated and solved using the state variable approach. We shall
also show how the Gaussian process prior used in LFMs can be equivalently
formulated as a linear statespace model driven by a white noise process and how
inference on the resulting model can be efficiently implemented using Kalman
filter and smoother. Then we shall show how the recently proposed switching LFM
can be reformulated using the state variable approach, and how we can construct
a probabilistic model for the switches by formulating a similar switching LFM
as a switching linear dynamic system (SLDS). We illustrate the performance of
the proposed methodology in simulated scenarios and apply it to inferring the
switching points in GPS data collected from car movement data in urban
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3731</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3731</id><created>2012-02-14</created><authors><author><keyname>Heinemann</keyname><forenames>Uri</forenames></author><author><keyname>Globerson</keyname><forenames>Amir</forenames></author></authors><title>What Cannot be Learned with Bethe Approximations</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-319-326</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of learning the parameters in graphical models when
inference is intractable. A common strategy in this case is to replace the
partition function with its Bethe approximation. We show that there exists a
regime of empirical marginals where such Bethe learning will fail. By failure
we mean that the empirical marginals cannot be recovered from the approximated
maximum likelihood parameters (i.e., moment matching is not achieved). We
provide several conditions on empirical marginals that yield outer and inner
bounds on the set of Bethe learnable marginals. An interesting implication of
our results is that there exists a large class of marginals that cannot be
obtained as stable fixed points of belief propagation. Taken together our
results provide a novel approach to analyzing learning with Bethe
approximations and highlight when it can be expected to work or fail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3732</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3732</id><created>2012-02-14</created><authors><author><keyname>Poon</keyname><forenames>Hoifung</forenames></author><author><keyname>Domingos</keyname><forenames>Pedro</forenames></author></authors><title>Sum-Product Networks: A New Deep Architecture</title><categories>cs.LG cs.AI stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-337-346</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key limiting factor in graphical model inference and learning is the
complexity of the partition function. We thus ask the question: what are
general conditions under which the partition function is tractable? The answer
leads to a new kind of deep architecture, which we call sum-product networks
(SPNs). SPNs are directed acyclic graphs with variables as leaves, sums and
products as internal nodes, and weighted edges. We show that if an SPN is
complete and consistent it represents the partition function and all marginals
of some graphical model, and give semantics to its nodes. Essentially all
tractable graphical models can be cast as SPNs, but SPNs are also strictly more
general. We then propose learning algorithms for SPNs, based on backpropagation
and EM. Experiments show that inference and learning with SPNs can be both
faster and more accurate than with standard deep networks. For example, SPNs
perform image completion better than state-of-the-art deep networks for this
task. SPNs also have intriguing potential connections to the architecture of
the cortex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3733</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3733</id><created>2012-02-14</created><authors><author><keyname>Honorio</keyname><forenames>Jean</forenames></author></authors><title>Lipschitz Parametrization of Probabilistic Graphical Models</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-347-354</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the log-likelihood of several probabilistic graphical models is
Lipschitz continuous with respect to the lp-norm of the parameters. We discuss
several implications of Lipschitz parametrization. We present an upper bound of
the Kullback-Leibler divergence that allows understanding methods that penalize
the lp-norm of differences of parameters as the minimization of that upper
bound. The expected log-likelihood is lower bounded by the negative lp-norm,
which allows understanding the generalization ability of probabilistic models.
The exponential of the negative lp-norm is involved in the lower bound of the
Bayes error rate, which shows that it is reasonable to use parameters as
features in algorithms that rely on metric spaces (e.g. classification,
dimensionality reduction, clustering). Our results do not rely on specific
algorithms for learning the structure or parameters. We show preliminary
results for activity recognition and temporal segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3734</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3734</id><created>2012-02-14</created><authors><author><keyname>Huang</keyname><forenames>Jonathan</forenames></author><author><keyname>Kapoor</keyname><forenames>Ashish</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos E.</forenames></author></authors><title>Efficient Probabilistic Inference with Partial Ranking Queries</title><categories>cs.LG cs.AI stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-355-362</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributions over rankings are used to model data in various settings such
as preference analysis and political elections. The factorial size of the space
of rankings, however, typically forces one to make structural assumptions, such
as smoothness, sparsity, or probabilistic independence about these underlying
distributions. We approach the modeling problem from the computational
principle that one should make structural assumptions which allow for efficient
calculation of typical probabilistic queries. For ranking models, &quot;typical&quot;
queries predominantly take the form of partial ranking queries (e.g., given a
user's top-k favorite movies, what are his preferences over remaining movies?).
In this paper, we argue that riffled independence factorizations proposed in
recent literature [7, 8] are a natural structural assumption for ranking
distributions, allowing for particularly efficient processing of partial
ranking queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3735</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3735</id><created>2012-02-14</created><authors><author><keyname>Hyttinen</keyname><forenames>Antti</forenames></author><author><keyname>Eberhardt</keyname><forenames>Frederick</forenames></author><author><keyname>Hoyer</keyname><forenames>Patrik O.</forenames></author></authors><title>Noisy-OR Models with Latent Confounding</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-363-372</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of experiments in which varying subsets of observed variables are
subject to intervention, we consider the problem of identifiability of causal
models exhibiting latent confounding. While identifiability is trivial when
each experiment intervenes on a large number of variables, the situation is
more complicated when only one or a few variables are subject to intervention
per experiment. For linear causal models with latent variables Hyttinen et al.
(2010) gave precise conditions for when such data are sufficient to identify
the full model. While their result cannot be extended to discrete-valued
variables with arbitrary cause-effect relationships, we show that a similar
result can be obtained for the class of causal models whose conditional
probability distributions are restricted to a `noisy-OR' parameterization. We
further show that identification is preserved under an extension of the model
that allows for negative influences, and present learning algorithms that we
test for accuracy, scalability and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3736</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3736</id><created>2012-02-14</created><authors><author><keyname>Inazumi</keyname><forenames>Takanori</forenames></author><author><keyname>Washio</keyname><forenames>Takashi</forenames></author><author><keyname>Shimizu</keyname><forenames>Shohei</forenames></author><author><keyname>Suzuki</keyname><forenames>Joe</forenames></author><author><keyname>Yamamoto</keyname><forenames>Akihiro</forenames></author><author><keyname>Kawahara</keyname><forenames>Yoshinobu</forenames></author></authors><title>Discovering causal structures in binary exclusive-or skew acyclic models</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-373-382</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discovering causal relations among observed variables in a given data set is
a main topic in studies of statistics and artificial intelligence. Recently,
some techniques to discover an identifiable causal structure have been explored
based on non-Gaussianity of the observed data distribution. However, most of
these are limited to continuous data. In this paper, we present a novel causal
model for binary data and propose a new approach to derive an identifiable
causal structure governing the data based on skew Bernoulli distributions of
external noise. Experimental evaluation shows excellent performance for both
artificial and real world data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3737</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3737</id><created>2012-02-14</created><authors><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Sgouritsa</keyname><forenames>Eleni</forenames></author><author><keyname>Stegle</keyname><forenames>Oliver</forenames></author><author><keyname>Peters</keyname><forenames>Jonas</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Detecting low-complexity unobserved causes</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-383-391</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a method that infers whether statistical dependences between two
observed variables X and Y are due to a &quot;direct&quot; causal link or only due to a
connecting causal path that contains an unobserved variable of low complexity,
e.g., a binary variable. This problem is motivated by statistical genetics.
Given a genetic marker that is correlated with a phenotype of interest, we want
to detect whether this marker is causal or it only correlates with a causal
one. Our method is based on the analysis of the location of the conditional
distributions P(Y|x) in the simplex of all distributions of Y. We report
encouraging results on semi-empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3738</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3738</id><created>2012-02-14</created><authors><author><keyname>Kulesza</keyname><forenames>Alex</forenames></author><author><keyname>Taskar</keyname><forenames>Ben</forenames></author></authors><title>Learning Determinantal Point Processes</title><categories>cs.LG cs.AI stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-419-427</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determinantal point processes (DPPs), which arise in random matrix theory and
quantum physics, are natural models for subset selection problems where
diversity is preferred. Among many remarkable properties, DPPs offer tractable
algorithms for exact inference, including computing marginal probabilities and
sampling; however, an important open question has been how to learn a DPP from
labeled training data. In this paper we propose a natural feature-based
parameterization of conditional DPPs, and show how it leads to a convex and
efficient learning formulation. We analyze the relationship between our model
and binary Markov random fields with repulsive potentials, which are
qualitatively similar but computationally intractable. Finally, we apply our
approach to the task of extractive summarization, where the goal is to choose a
small subset of sentences conveying the most important information from a set
of documents. In this task there is a fundamental tradeoff between sentences
that are highly relevant to the collection as a whole, and sentences that are
diverse and not repetitive. Our parameterization allows us to naturally balance
these two characteristics. We evaluate our system on data from the DUC 2003/04
multi-document summarization task, achieving state-of-the-art results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3739</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3739</id><created>2012-02-14</created><authors><author><keyname>Kumar</keyname><forenames>Akshat</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>Message-Passing Algorithms for Quadratic Programming Formulations of MAP
  Estimation</title><categories>cs.AI cs.DS stat.CO</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-428-435</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing maximum a posteriori (MAP) estimation in graphical models is an
important inference problem with many applications. We present message-passing
algorithms for quadratic programming (QP) formulations of MAP estimation for
pairwise Markov random fields. In particular, we use the concave-convex
procedure (CCCP) to obtain a locally optimal algorithm for the non-convex QP
formulation. A similar technique is used to derive a globally convergent
algorithm for the convex QP relaxation of MAP. We also show that a recently
developed expectation-maximization (EM) algorithm for the QP formulation of MAP
can be derived from the CCCP perspective. Experiments on synthetic and
real-world problems confirm that our new approach is competitive with
max-product and its variations. Compared with CPLEX, we achieve more than an
order-of-magnitude speedup in solving optimally the convex QP relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3740</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3740</id><created>2012-02-14</created><authors><author><keyname>Li</keyname><forenames>Minyi</forenames></author><author><keyname>Vo</keyname><forenames>Quoc Bao</forenames></author><author><keyname>Kowalczyk</keyname><forenames>Ryszard</forenames></author></authors><title>An Efficient Protocol for Negotiation over Combinatorial Domains with
  Incomplete Information</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-436-444</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of agent-based negotiation in combinatorial domains. It
is difficult to reach optimal agreements in bilateral or multi-lateral
negotiations when the agents' preferences for the possible alternatives are not
common knowledge. Self-interested agents often end up negotiating inefficient
agreements in such situations. In this paper, we present a protocol for
negotiation in combinatorial domains which can lead rational agents to reach
optimal agreements under incomplete information setting. Our proposed protocol
enables the negotiating agents to identify efficient solutions using
distributed search that visits only a small subspace of the whole outcome
space. Moreover, the proposed protocol is sufficiently general that it is
applicable to most preference representation models in combinatorial domains.
We also present results of experiments that demonstrate the feasibility and
computational efficiency of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3741</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3741</id><created>2012-02-14</created><authors><author><keyname>Lim</keyname><forenames>Shiau Hong</forenames></author><author><keyname>Auer</keyname><forenames>Peter</forenames></author></authors><title>Noisy Search with Comparative Feedback</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-445-452</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present theoretical results in terms of lower and upper bounds on the
query complexity of noisy search with comparative feedback. In this search
model, the noise in the feedback depends on the distance between query points
and the search target. Consequently, the error probability in the feedback is
not fixed but varies for the queries posed by the search algorithm. Our results
show that a target out of n items can be found in O(log n) queries. We also
show the surprising result that for k possible answers per query, the speedup
is not log k (as for k-ary search) but only log log k in some cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3742</identifier>
 <datestamp>2013-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3742</id><created>2012-02-14</created><authors><author><keyname>Liu</keyname><forenames>Qiang</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author></authors><title>Variational Algorithms for Marginal MAP</title><categories>cs.LG cs.AI cs.IT math.IT stat.ML</categories><comments>conference version. full journal version is at arXiv:1302.6584</comments><proxy>auai</proxy><report-no>UAI-P-2011-PG-453-462</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Marginal MAP problems are notoriously difficult tasks for graphical models.
We derive a general variational framework for solving marginal MAP problems, in
which we apply analogues of the Bethe, tree-reweighted, and mean field
approximations. We then derive a &quot;mixed&quot; message passing algorithm and a
convergent alternative using CCCP to solve the BP-type approximations.
Theoretically, we give conditions under which the decoded solution is a global
or local optimum, and obtain novel upper bounds on solutions. Experimentally we
demonstrate that our algorithms outperform related approaches. We also show
that EM and variational EM comprise a special case of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3743</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3743</id><created>2012-02-14</created><authors><author><keyname>Ma</keyname><forenames>Jianbing</forenames></author><author><keyname>Liu</keyname><forenames>Weiru</forenames></author><author><keyname>Miller</keyname><forenames>Paul</forenames></author></authors><title>Belief change with noisy sensing in the situation calculus</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-471-478</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Situation calculus has been applied widely in artificial intelligence to
model and reason about actions and changes in dynamic systems. Since actions
carried out by agents will cause constant changes of the agents' beliefs, how
to manage these changes is a very important issue. Shapiro et al. [22] is one
of the studies that considered this issue. However, in this framework, the
problem of noisy sensing, which often presents in real-world applications, is
not considered. As a consequence, noisy sensing actions in this framework will
lead to an agent facing inconsistent situation and subsequently the agent
cannot proceed further. In this paper, we investigate how noisy sensing actions
can be handled in iterated belief change within the situation calculus
formalism. We extend the framework proposed in [22] with the capability of
managing noisy sensings. We demonstrate that an agent can still detect the
actual situation when the ratio of noisy sensing actions vs. accurate sensing
actions is limited. We prove that our framework subsumes the iterated belief
change strategy in [22] when all sensing actions are accurate. Furthermore, we
prove that our framework can adequately handle belief introspection, mistaken
beliefs, belief revision and belief update even with noisy sensing, as done in
[22] with accurate sensing actions only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3744</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3744</id><created>2012-02-14</created><authors><author><keyname>Malone</keyname><forenames>Brandon</forenames></author><author><keyname>Yuan</keyname><forenames>Changhe</forenames></author><author><keyname>Hansen</keyname><forenames>Eric A.</forenames></author><author><keyname>Bridges</keyname><forenames>Susan</forenames></author></authors><title>Improving the Scalability of Optimal Bayesian Network Learning with
  External-Memory Frontier Breadth-First Branch and Bound Search</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-479-488</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work has shown that the problem of learning the optimal structure of
a Bayesian network can be formulated as a shortest path finding problem in a
graph and solved using A* search. In this paper, we improve the scalability of
this approach by developing a memory-efficient heuristic search algorithm for
learning the structure of a Bayesian network. Instead of using A*, we propose a
frontier breadth-first branch and bound search that leverages the layered
structure of the search graph of this problem so that no more than two layers
of the graph, plus solution reconstruction information, need to be stored in
memory at a time. To further improve scalability, the algorithm stores most of
the graph in external memory, such as hard disk, when it does not fit in RAM.
Experimental results show that the resulting algorithm solves significantly
larger problems than the current state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3745</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3745</id><created>2012-02-14</created><authors><author><keyname>Marinescu</keyname><forenames>Radu</forenames></author><author><keyname>Wilson</keyname><forenames>Nic</forenames></author></authors><title>Order-of-Magnitude Influence Diagrams</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-489-496</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a qualitative theory of influence diagrams that can
be used to model and solve sequential decision making tasks when only
qualitative (or imprecise) information is available. Our approach is based on
an order-of-magnitude approximation of both probabilities and utilities and
allows for specifying partially ordered preferences via sets of utility values.
We also propose a dedicated variable elimination algorithm that can be applied
for solving order-of-magnitude influence diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3746</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3746</id><created>2012-02-14</created><authors><author><keyname>Marlin</keyname><forenames>Benjamin</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Asymptotic Efficiency of Deterministic Estimators for Discrete
  Energy-Based Models: Ratio Matching and Pseudolikelihood</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-497-505</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard maximum likelihood estimation cannot be applied to discrete
energy-based models in the general case because the computation of exact model
probabilities is intractable. Recent research has seen the proposal of several
new estimators designed specifically to overcome this intractability, but
virtually nothing is known about their theoretical properties. In this paper,
we present a generalized estimator that unifies many of the classical and
recently proposed estimators. We use results from the standard asymptotic
theory for M-estimators to derive a generic expression for the asymptotic
covariance matrix of our generalized estimator. We apply these results to study
the relative statistical efficiency of classical pseudolikelihood and the
recently-proposed ratio matching estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3747</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3747</id><created>2012-02-14</created><authors><author><keyname>Mimno</keyname><forenames>David</forenames></author></authors><title>Reconstructing Pompeian Households</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-506-513</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A database of objects discovered in houses in the Roman city of Pompeii
provides a unique view of ordinary life in an ancient city. Experts have used
this collection to study the structure of Roman households, exploring the
distribution and variability of tasks in architectural spaces, but such
approaches are necessarily affected by modern cultural assumptions. In this
study we present a data-driven approach to household archeology, treating it as
an unsupervised labeling problem. This approach scales to large data sets and
provides a more objective complement to human interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3748</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3748</id><created>2012-02-14</created><authors><author><keyname>Mnih</keyname><forenames>Volodymyr</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author><author><keyname>Hinton</keyname><forenames>Geoffrey E.</forenames></author></authors><title>Conditional Restricted Boltzmann Machines for Structured Output
  Prediction</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-514-522</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic
models that have recently been applied to a wide range of problems, including
collaborative filtering, classification, and modeling motion capture data.
While much progress has been made in training non-conditional RBMs, these
algorithms are not applicable to conditional models and there has been almost
no work on training and generating predictions from conditional RBMs for
structured output problems. We first argue that standard Contrastive
Divergence-based learning may not be suitable for training CRBMs. We then
identify two distinct types of structured output prediction problems and
propose an improved learning algorithm for each. The first problem type is one
where the output space has arbitrary structure but the set of likely output
configurations is relatively small, such as in multi-label classification. The
second problem is one where the output space is arbitrarily structured but
where the output space variability is much greater, such as in image denoising
or pixel labeling. We show that the new learning algorithms can work much
better than Contrastive Divergence on both types of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3749</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3749</id><created>2012-02-14</created><authors><author><keyname>Mostafa</keyname><forenames>Hala</forenames></author><author><keyname>Lesser</keyname><forenames>Victor</forenames></author></authors><title>Compact Mathematical Programs For DEC-MDPs With Structured Agent
  Interactions</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-523-530</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To deal with the prohibitive complexity of calculating policies in
Decentralized MDPs, researchers have proposed models that exploit structured
agent interactions. Settings where most agent actions are independent except
for few actions that affect the transitions and/or rewards of other agents can
be modeled using Event-Driven Interactions with Complex Rewards (EDI-CR).
Finding the optimal joint policy can be formulated as an optimization problem.
However, existing formulations are too verbose and/or lack optimality
guarantees. We propose a compact Mixed Integer Linear Program formulation of
EDI-CR instances. The key insight is that most action sequences of a group of
agents have the same effect on a given agent. This allows us to treat these
sequences similarly and use fewer variables. Experiments show that our
formulation is more compact and leads to faster solution times and better
solutions than existing formulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3750</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3750</id><created>2012-02-14</created><authors><author><keyname>B</keyname><forenames>Ananda Narayanan</forenames></author><author><keyname>Ravindran</keyname><forenames>Balaraman</forenames></author></authors><title>Fractional Moments on Bandit Problems</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-531-538</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement learning addresses the dilemma between exploration to find
profitable actions and exploitation to act according to the best observations
already made. Bandit problems are one such class of problems in stateless
environments that represent this explore/exploit situation. We propose a
learning algorithm for bandit problems based on fractional expectation of
rewards acquired. The algorithm is theoretically shown to converge on an
eta-optimal arm and achieve O(n) sample complexity. Experimental results show
the algorithm incurs substantially lower regrets than parameter-optimized
eta-greedy and SoftMax approaches and other low sample complexity
state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3751</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3751</id><created>2012-02-14</created><authors><author><keyname>Nath</keyname><forenames>Swaprava</forenames></author><author><keyname>Zoeter</keyname><forenames>Onno</forenames></author><author><keyname>Narahari</keyname><forenames>Yadati</forenames></author><author><keyname>Dance</keyname><forenames>Christopher R.</forenames></author></authors><title>Dynamic Mechanism Design for Markets with Strategic Resources</title><categories>cs.GT cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-539-546</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The assignment of tasks to multiple resources becomes an interesting game
theoretic problem, when both the task owner and the resources are strategic. In
the classical, nonstrategic setting, where the states of the tasks and
resources are observable by the controller, this problem is that of finding an
optimal policy for a Markov decision process (MDP). When the states are held by
strategic agents, the problem of an efficient task allocation extends beyond
that of solving an MDP and becomes that of designing a mechanism. Motivated by
this fact, we propose a general mechanism which decides on an allocation rule
for the tasks and resources and a payment rule to incentivize agents'
participation and truthful reports. In contrast to related dynamic strategic
control problems studied in recent literature, the problem studied here has
interdependent values: the benefit of an allocation to the task owner is not
simply a function of the characteristics of the task itself and the allocation,
but also of the state of the resources. We introduce a dynamic extension of
Mezzetti's two phase mechanism for interdependent valuations. In this changed
setting, the proposed dynamic mechanism is efficient, within period ex-post
incentive compatible, and within period ex-post individually rational.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3752</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3752</id><created>2012-02-14</created><authors><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Perina</keyname><forenames>Alessandro</forenames></author></authors><title>Multidimensional counting grids: Inferring word order from disordered
  bags of words</title><categories>cs.IR cs.CL cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-547-556</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models of bags of words typically assume topic mixing so that the words in a
single bag come from a limited number of topics. We show here that many sets of
bag of words exhibit a very different pattern of variation than the patterns
that are efficiently captured by topic mixing. In many cases, from one bag of
words to the next, the words disappear and new ones appear as if the theme
slowly and smoothly shifted across documents (providing that the documents are
somehow ordered). Examples of latent structure that describe such ordering are
easily imagined. For example, the advancement of the date of the news stories
is reflected in a smooth change over the theme of the day as certain evolving
news stories fall out of favor and new events create new stories. Overlaps
among the stories of consecutive days can be modeled by using windows over
linearly arranged tight distributions over words. We show here that such
strategy can be extended to multiple dimensions and cases where the ordering of
data is not readily obvious. We demonstrate that this way of modeling
covariation in word occurrences outperforms standard topic models in
classification and prediction tasks in applications in biology, text modeling
and computer vision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3753</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3753</id><created>2012-02-14</created><authors><author><keyname>Niinimaki</keyname><forenames>Teppo</forenames></author><author><keyname>Parviainen</keyname><forenames>Pekka</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>Partial Order MCMC for Structure Discovery in Bayesian Networks</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-557-564</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new Markov chain Monte Carlo method for estimating posterior
probabilities of structural features in Bayesian networks. The method draws
samples from the posterior distribution of partial orders on the nodes; for
each sampled partial order, the conditional probabilities of interest are
computed exactly. We give both analytical and empirical results that suggest
the superiority of the new method compared to previous methods, which sample
either directed acyclic graphs or linear orders on the nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3754</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3754</id><created>2012-02-14</created><authors><author><keyname>Oh</keyname><forenames>Eunsoo</forenames></author><author><keyname>Kim</keyname><forenames>Kee-Eung</forenames></author></authors><title>A Geometric Traversal Algorithm for Reward-Uncertain MDPs</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-565-572</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov decision processes (MDPs) are widely used in modeling decision making
problems in stochastic environments. However, precise specification of the
reward functions in MDPs is often very difficult. Recent approaches have
focused on computing an optimal policy based on the minimax regret criterion
for obtaining a robust policy under uncertainty in the reward function. One of
the core tasks in computing the minimax regret policy is to obtain the set of
all policies that can be optimal for some candidate reward function. In this
paper, we propose an efficient algorithm that exploits the geometric properties
of the reward function associated with the policies. We also present an
approximate version of the method for further speed up. We experimentally
demonstrate that our algorithm improves the performance by orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3755</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3755</id><created>2012-02-14</created><authors><author><keyname>Osogami</keyname><forenames>Takayuki</forenames></author></authors><title>Iterated risk measures for risk-sensitive Markov decision processes with
  discounted cost</title><categories>cs.GT cs.AI q-fin.RM</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-573-580</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a limitation of discounted expected utility, a standard
approach for representing the preference to risk when future cost is
discounted. Specifically, we provide an example of the preference of a decision
maker that appears to be rational but cannot be represented with any discounted
expected utility. A straightforward modification to discounted expected utility
leads to inconsistent decision making over time. We will show that an iterated
risk measure can represent the preference that cannot be represented by any
discounted expected utility and that the decisions based on the iterated risk
measure are consistent over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3756</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3756</id><created>2012-02-14</created><authors><author><keyname>Pennock</keyname><forenames>David M.</forenames></author><author><keyname>Xia</keyname><forenames>Lirong</forenames></author></authors><title>Price Updating in Combinatorial Prediction Markets with Bayesian
  Networks</title><categories>cs.GT cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-581-588</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To overcome the #P-hardness of computing/updating prices in logarithm market
scoring rule-based (LMSR-based) combinatorial prediction markets, Chen et al.
[5] recently used a simple Bayesian network to represent the prices of
securities in combinatorial predictionmarkets for tournaments, and showed that
two types of popular securities are structure preserving. In this paper, we
significantly extend this idea by employing Bayesian networks in general
combinatorial prediction markets. We reveal a very natural connection between
LMSR-based combinatorial prediction markets and probabilistic belief
aggregation,which leads to a complete characterization of all structure
preserving securities for decomposable network structures. Notably, the main
results by Chen et al. [5] are corollaries of our characterization. We then
prove that in order for a very basic set of securities to be structure
preserving, the graph of the Bayesian network must be decomposable. We also
discuss some approximation techniques for securities that are not structure
preserving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3757</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3757</id><created>2012-02-14</created><authors><author><keyname>Peters</keyname><forenames>Jonas</forenames></author><author><keyname>Mooij</keyname><forenames>Joris</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Identifiability of Causal Graphs using Functional Models</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-589-598</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses the following question: Under what assumptions on the
data generating process can one infer the causal graph from the joint
distribution? The approach taken by conditional independence-based causal
discovery methods is based on two assumptions: the Markov condition and
faithfulness. It has been shown that under these assumptions the causal graph
can be identified up to Markov equivalence (some arrows remain undirected)
using methods like the PC algorithm. In this work we propose an alternative by
defining Identifiable Functional Model Classes (IFMOCs). As our main theorem we
prove that if the data generating process belongs to an IFMOC, one can identify
the complete causal graph. To the best of our knowledge this is the first
identifiability result of this kind that is not limited to linear functional
relationships. We discuss how the IFMOC assumption and the Markov and
faithfulness assumptions relate to each other and explain why we believe that
the IFMOC assumption can be tested more easily on given data. We further
provide a practical algorithm that recovers the causal graph from finitely many
data; experiments on simulated data support the theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3758</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3758</id><created>2012-02-14</created><authors><author><keyname>Poczos</keyname><forenames>Barnabas</forenames></author><author><keyname>Xiong</keyname><forenames>Liang</forenames></author><author><keyname>Schneider</keyname><forenames>Jeff</forenames></author></authors><title>Nonparametric Divergence Estimation with Applications to Machine
  Learning on Distributions</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-599-608</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-dimensional embedding, manifold learning, clustering, classification, and
anomaly detection are among the most important problems in machine learning.
The existing methods usually consider the case when each instance has a fixed,
finite-dimensional feature representation. Here we consider a different
setting. We assume that each instance corresponds to a continuous probability
distribution. These distributions are unknown, but we are given some i.i.d.
samples from each distribution. Our goal is to estimate the distances between
these distributions and use these distances to perform low-dimensional
embedding, clustering/classification, or anomaly detection for the
distributions. We present estimation algorithms, describe how to apply them for
machine learning tasks on distributions, and show empirical results on
synthetic data, real word images, and astronomical data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3759</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3759</id><created>2012-02-14</created><authors><author><keyname>Polatkan</keyname><forenames>Gungor</forenames></author><author><keyname>Tuzel</keyname><forenames>Oncel</forenames></author></authors><title>Compressed Inference for Probabilistic Sequential Models</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-609-618</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov models (HMMs) and conditional random fields (CRFs) are two
popular techniques for modeling sequential data. Inference algorithms designed
over CRFs and HMMs allow estimation of the state sequence given the
observations. In several applications, estimation of the state sequence is not
the end goal; instead the goal is to compute some function of it. In such
scenarios, estimating the state sequence by conventional inference techniques,
followed by computing the functional mapping from the estimate is not
necessarily optimal. A more formal approach is to directly infer the final
outcome from the observations. In particular, we consider the specific
instantiation of the problem where the goal is to find the state trajectories
without exact transition points and derive a novel polynomial time inference
algorithm that outperforms vanilla inference techniques. We show that this
particular problem arises commonly in many disparate applications and present
experiments on three of them: (1) Toy robot tracking; (2) Single stroke
character recognition; (3) Handwritten word recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3760</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3760</id><created>2012-02-14</created><authors><author><keyname>Rao</keyname><forenames>Vinayak</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Fast MCMC sampling for Markov jump processes and continuous time
  Bayesian networks</title><categories>stat.ME cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-619-626</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov jump processes and continuous time Bayesian networks are important
classes of continuous time dynamical systems. In this paper, we tackle the
problem of inferring unobserved paths in these models by introducing a fast
auxiliary variable Gibbs sampler. Our approach is based on the idea of
uniformization, and sets up a Markov chain over paths by sampling a finite set
of virtual jump times and then running a standard hidden Markov model forward
filtering-backward sampling algorithm over states at the set of extant and
virtual jump times. We demonstrate significant computational benefits over a
state-of-the-art Gibbs sampler on a number of continuous time Bayesian
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3761</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3761</id><created>2012-02-14</created><authors><author><keyname>Reyhani</keyname><forenames>Nima</forenames></author><author><keyname>Hino</keyname><forenames>Hideitsu</forenames></author><author><keyname>Vigario</keyname><forenames>Ricardo</forenames></author></authors><title>New Probabilistic Bounds on Eigenvalues and Eigenvectors of Random
  Kernel Matrices</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-627-634</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel methods are successful approaches for different machine learning
problems. This success is mainly rooted in using feature maps and kernel
matrices. Some methods rely on the eigenvalues/eigenvectors of the kernel
matrix, while for other methods the spectral information can be used to
estimate the excess risk. An important question remains on how close the sample
eigenvalues/eigenvectors are to the population values. In this paper, we
improve earlier results on concentration bounds for eigenvalues of general
kernel matrices. For distance and inner product kernel functions, e.g. radial
basis functions, we provide new concentration bounds, which are characterized
by the eigenvalues of the sample covariance matrix. Meanwhile, the obstacles
for sharper bounds are accounted for and partially addressed. As a case study,
we derive a concentration inequality for sample kernel target-alignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3762</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3762</id><created>2012-02-14</created><authors><author><keyname>Sanner</keyname><forenames>Scott</forenames></author><author><keyname>Delgado</keyname><forenames>Karina Valdivia</forenames></author><author><keyname>de Barros</keyname><forenames>Leliane Nunes</forenames></author></authors><title>Symbolic Dynamic Programming for Discrete and Continuous State MDPs</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-643-652</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world decision-theoretic planning problems can be naturally modeled
with discrete and continuous state Markov decision processes (DC-MDPs). While
previous work has addressed automated decision-theoretic planning for DCMDPs,
optimal solutions have only been defined so far for limited settings, e.g.,
DC-MDPs having hyper-rectangular piecewise linear value functions. In this
work, we extend symbolic dynamic programming (SDP) techniques to provide
optimal solutions for a vastly expanded class of DCMDPs. To address the
inherent combinatorial aspects of SDP, we introduce the XADD - a continuous
variable extension of the algebraic decision diagram (ADD) - that maintains
compact representations of the exact value function. Empirically, we
demonstrate an implementation of SDP with XADDs on various DC-MDPs, showing the
first optimal automated solutions to DCMDPs with linear and nonlinear piecewise
partitioned value functions and showing the advantages of constraint-based
pruning for XADDs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3763</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3763</id><created>2012-02-14</created><authors><author><keyname>Shpitser</keyname><forenames>Ilya</forenames></author><author><keyname>Richardson</keyname><forenames>Thomas S.</forenames></author><author><keyname>Robins</keyname><forenames>James M.</forenames></author></authors><title>An Efficient Algorithm for Computing Interventional Distributions in
  Latent Variable Causal Models</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-661-670</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic inference in graphical models is the task of computing marginal
and conditional densities of interest from a factorized representation of a
joint probability distribution. Inference algorithms such as variable
elimination and belief propagation take advantage of constraints embedded in
this factorization to compute such densities efficiently. In this paper, we
propose an algorithm which computes interventional distributions in latent
variable causal models represented by acyclic directed mixed graphs(ADMGs). To
compute these distributions efficiently, we take advantage of a recursive
factorization which generalizes the usual Markov factorization for DAGs and the
more recent factorization for ADMGs. Our algorithm can be viewed as a
generalization of variable elimination to the mixed graph case. We show our
algorithm is exponential in the mixed graph generalization of treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3764</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3764</id><created>2012-02-14</created><authors><author><keyname>Textor</keyname><forenames>Johannes</forenames></author><author><keyname>Liskiewicz</keyname><forenames>Maciej</forenames></author></authors><title>Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-681-688</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying and controlling bias is a key problem in empirical sciences.
Causal diagram theory provides graphical criteria for deciding whether and how
causal effects can be identified from observed (nonexperimental) data by
covariate adjustment. Here we prove equivalences between existing as well as
new criteria for adjustment and we provide a new simplified but still
equivalent notion of d-separation. These lead to efficient algorithms for two
important tasks in causal diagram analysis: (1) listing minimal covariate
adjustments (with polynomial delay); and (2) identifying the subdiagram
involved in biasing paths (in linear time). Our results improve upon existing
exponential-time solutions for these problems, enabling users to assess the
effects of covariate adjustment on diagrams with tens to hundreds of variables
interactively in real time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3765</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3765</id><created>2012-02-14</created><authors><author><keyname>Tur</keyname><forenames>Inma</forenames></author><author><keyname>Castelo</keyname><forenames>Robert</forenames></author></authors><title>Learning mixed graphical models from data with p larger than n</title><categories>stat.ME cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-689-697</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structure learning of Gaussian graphical models is an extensively studied
problem in the classical multivariate setting where the sample size n is larger
than the number of random variables p, as well as in the more challenging
setting when p&gt;&gt;n. However, analogous approaches for learning the structure of
graphical models with mixed discrete and continuous variables when p&gt;&gt;n remain
largely unexplored. Here we describe a statistical learning procedure for this
problem based on limited-order correlations and assess its performance with
synthetic and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3766</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3766</id><created>2012-02-14</created><authors><author><keyname>Ueno</keyname><forenames>Maomi</forenames></author></authors><title>Robust learning Bayesian networks for prior belief</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-698-707</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent reports have described that learning Bayesian networks are highly
sensitive to the chosen equivalent sample size (ESS) in the Bayesian Dirichlet
equivalence uniform (BDeu). This sensitivity often engenders some unstable or
undesirable results. This paper describes some asymptotic analyses of BDeu to
explain the reasons for the sensitivity and its effects. Furthermore, this
paper presents a proposal for a robust learning score for ESS by eliminating
the sensitive factors from the approximation of log-BDeu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3767</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3767</id><created>2012-02-14</created><authors><author><keyname>van de Ven</keyname><forenames>Joop</forenames></author><author><keyname>Ramos</keyname><forenames>Fabio</forenames></author></authors><title>Distributed Anytime MAP Inference</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-708-716</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a distributed anytime algorithm for performing MAP inference in
graphical models. The problem is formulated as a linear programming relaxation
over the edges of a graph. The resulting program has a constraint structure
that allows application of the Dantzig-Wolfe decomposition principle.
Subprograms are defined over individual edges and can be computed in a
distributed manner. This accommodates solutions to graphs whose state space
does not fit in memory. The decomposition master program is guaranteed to
compute the optimal solution in a finite number of iterations, while the
solution converges monotonically with each iteration. Formulating the MAP
inference problem as a linear program allows additional (global) constraints to
be defined; something not possible with message passing algorithms.
Experimental results show that our algorithm's solution quality outperforms
most current algorithms and it scales well to large problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3768</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3768</id><created>2012-02-14</created><authors><author><keyname>Wellman</keyname><forenames>Michael P.</forenames></author><author><keyname>Hong</keyname><forenames>Lu</forenames></author><author><keyname>Page</keyname><forenames>Scott E.</forenames></author></authors><title>The Structure of Signals: Causal Interdependence Models for Games of
  Incomplete Information</title><categories>cs.GT cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-727-735</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional economic models typically treat private information, or signals,
as generated from some underlying state. Recent work has explicated alternative
models, where signals correspond to interpretations of available information.
We show that the difference between these formulations can be sharply cast in
terms of causal dependence structure, and employ graphical models to illustrate
the distinguishing characteristics. The graphical representation supports
inferences about signal patterns in the interpreted framework, and suggests how
results based on the generated model can be extended to more general
situations. Specific insights about bidding games in classical auction
mechanisms derive from qualitative graphical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3769</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3769</id><created>2012-02-14</created><authors><author><keyname>Yan</keyname><forenames>Feng</forenames><affiliation>Alan</affiliation></author><author><keyname>Xu</keyname><forenames>Zenglin</forenames><affiliation>Alan</affiliation></author><author><keyname>Yuan</keyname><affiliation>Alan</affiliation></author><author><keyname>Qi</keyname></author></authors><title>Sparse matrix-variate Gaussian process blockmodels for network modeling</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-745-752</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We face network data from various sources, such as protein interactions and
online social networks. A critical problem is to model network interactions and
identify latent groups of network nodes. This problem is challenging due to
many reasons. For example, the network nodes are interdependent instead of
independent of each other, and the data are known to be very noisy (e.g.,
missing edges). To address these challenges, we propose a new relational model
for network data, Sparse Matrix-variate Gaussian process Blockmodel (SMGB). Our
model generalizes popular bilinear generative models and captures nonlinear
network interactions using a matrix-variate Gaussian process with latent
membership variables. We also assign sparse prior distributions on the latent
membership variables to learn sparse group assignments for individual network
nodes. To estimate the latent variables efficiently from data, we develop an
efficient variational expectation maximization method. We compared our
approaches with several state-of-the-art network models on both synthetic and
real-world network datasets. Experimental results demonstrate SMGBs outperform
the alternative approaches in terms of discovering latent classes or predicting
unknown interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3770</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3770</id><created>2012-02-14</created><authors><author><keyname>Yang</keyname><forenames>Jian-Bo</forenames></author><author><keyname>Tsang</keyname><forenames>Ivor W.</forenames></author></authors><title>Hierarchical Maximum Margin Learning for Multi-Class Classification</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-753-760</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to myriads of classes, designing accurate and efficient classifiers
becomes very challenging for multi-class classification. Recent research has
shown that class structure learning can greatly facilitate multi-class
learning. In this paper, we propose a novel method to learn the class structure
for multi-class classification problems. The class structure is assumed to be a
binary hierarchical tree. To learn such a tree, we propose a maximum separating
margin method to determine the child nodes of any internal node. The proposed
method ensures that two classgroups represented by any two sibling nodes are
most separable. In the experiments, we evaluate the accuracy and efficiency of
the proposed method over other multi-class classification methods on real world
large-scale problems. The results show that the proposed method outperforms
benchmark methods in terms of accuracy for most datasets and performs
comparably with other class structure learning methods in terms of efficiency
for all datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3771</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3771</id><created>2012-02-14</created><authors><author><keyname>Yarkony</keyname><forenames>Julian</forenames></author><author><keyname>Morshed</keyname><forenames>Ragib</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author><author><keyname>Fowlkes</keyname><forenames>Charless C.</forenames></author></authors><title>Tightening MRF Relaxations with Planar Subproblems</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-770-777</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new technique for computing lower-bounds on the minimum energy
configuration of a planar Markov Random Field (MRF). Our method successively
adds large numbers of constraints and enforces consistency over binary
projections of the original problem state space. These constraints are
represented in terms of subproblems in a dual-decomposition framework that is
optimized using subgradient techniques. The complete set of constraints we
consider enforces cycle consistency over the original graph. In practice we
find that the method converges quickly on most problems with the addition of a
few subproblems and outperforms existing methods for some interesting classes
of hard potentials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3772</identifier>
 <datestamp>2012-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3772</id><created>2012-02-14</created><updated>2012-10-09</updated><authors><author><keyname>Yu</keyname><forenames>Yao-Liang</forenames></author><author><keyname>Schuurmans</keyname><forenames>Dale</forenames></author></authors><title>Rank/Norm Regularization with Closed-Form Solutions: Application to
  Subspace Clustering</title><categories>cs.LG cs.NA stat.ML</categories><comments>11 pages, 1 figure, appeared in UAI 2011. One footnote corrected and
  appendix added</comments><proxy>auai</proxy><report-no>UAI-P-2011-PG-778-785</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When data is sampled from an unknown subspace, principal component analysis
(PCA) provides an effective way to estimate the subspace and hence reduce the
dimension of the data. At the heart of PCA is the Eckart-Young-Mirsky theorem,
which characterizes the best rank k approximation of a matrix. In this paper,
we prove a generalization of the Eckart-Young-Mirsky theorem under all
unitarily invariant norms. Using this result, we obtain closed-form solutions
for a set of rank/norm regularized problems, and derive closed-form solutions
for a general class of subspace clustering problems (where data is modelled by
unions of unknown subspaces). From these results we obtain new theoretical
insights and promising experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3773</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3773</id><created>2012-02-14</created><authors><author><keyname>Yu</keyname><forenames>Haohai</forenames></author><author><keyname>van Engelen</keyname><forenames>Robert A.</forenames></author></authors><title>Measuring the Hardness of Stochastic Sampling on Bayesian Networks with
  Deterministic Causalities: the k-Test</title><categories>cs.AI</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-786-795</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate Bayesian inference is NP-hard. Dagum and Luby defined the Local
Variance Bound (LVB) to measure the approximation hardness of Bayesian
inference on Bayesian networks, assuming the networks model strictly positive
joint probability distributions, i.e. zero probabilities are not permitted.
This paper introduces the k-test to measure the approximation hardness of
inference on Bayesian networks with deterministic causalities in the
probability distribution, i.e. when zero conditional probabilities are
permitted. Approximation by stochastic sampling is a widely-used inference
method that is known to suffer from inefficiencies due to sample rejection. The
k-test predicts when rejection rates of stochastic sampling a Bayesian network
will be low, modest, high, or when sampling is intractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3774</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3774</id><created>2012-02-14</created><authors><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author></authors><title>Risk Bounds for Infinitely Divisible Distribution</title><categories>stat.ML cs.LG</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-796-803</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the risk bounds for samples independently drawn from
an infinitely divisible (ID) distribution. In particular, based on a martingale
method, we develop two deviation inequalities for a sequence of random
variables of an ID distribution with zero Gaussian component. By applying the
deviation inequalities, we obtain the risk bounds based on the covering number
for the ID distribution. Finally, we analyze the asymptotic convergence of the
risk bound derived from one of the two deviation inequalities and show that the
convergence rate of the bound is faster than the result for the generic i.i.d.
empirical process (Mendelson, 2003).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3775</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3775</id><created>2012-02-14</created><authors><author><keyname>Zhang</keyname><forenames>Kun</forenames></author><author><keyname>Peters</keyname><forenames>Jonas</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Kernel-based Conditional Independence Test and Application in Causal
  Discovery</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-804-813</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional independence testing is an important problem, especially in
Bayesian network learning and causal discovery. Due to the curse of
dimensionality, testing for conditional independence of continuous variables is
particularly challenging. We propose a Kernel-based Conditional Independence
test (KCI-test), by constructing an appropriate test statistic and deriving its
asymptotic distribution under the null hypothesis of conditional independence.
The proposed method is computationally efficient and easy to implement.
Experimental results show that it outperforms other methods, especially when
the conditioning set is large or the sample size is not very large, in which
case other methods encounter difficulties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3776</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3776</id><created>2012-02-14</created><authors><author><keyname>Zhang</keyname><forenames>Xinhua</forenames></author><author><keyname>Saha</keyname><forenames>Ankan</forenames></author><author><keyname>Vishwanatan</keyname><forenames>S. V. N.</forenames></author></authors><title>Smoothing Multivariate Performance Measures</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-814-821</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Support Vector Method for multivariate performance measures was recently
introduced by Joachims (2005). The underlying optimization problem is currently
solved using cutting plane methods such as SVM-Perf and BMRM. One can show that
these algorithms converge to an eta accurate solution in O(1/Lambda*e)
iterations, where lambda is the trade-off parameter between the regularizer and
the loss function. We present a smoothing strategy for multivariate performance
scores, in particular precision/recall break-even point and ROCArea. When
combined with Nesterov's accelerated gradient algorithm our smoothing strategy
yields an optimization algorithm which converges to an eta accurate solution in
O(min{1/e,1/sqrt(lambda*e)}) iterations. Furthermore, the cost per iteration of
our scheme is the same as that of SVM-Perf and BMRM. Empirical evaluation on a
number of publicly available datasets shows that our method converges
significantly faster than cutting plane methods without sacrificing
generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3777</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3777</id><created>2012-02-14</created><authors><author><keyname>Zheng</keyname><forenames>Lu</forenames></author><author><keyname>Mengshoel</keyname><forenames>Ole</forenames></author><author><keyname>Chong</keyname><forenames>Jike</forenames></author></authors><title>Belief Propagation by Message Passing in Junction Trees: Computing Each
  Message Faster Using GPU Parallelization</title><categories>cs.AI cs.DC</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-822-830</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compiling Bayesian networks (BNs) to junction trees and performing belief
propagation over them is among the most prominent approaches to computing
posteriors in BNs. However, belief propagation over junction tree is known to
be computationally intensive in the general case. Its complexity may increase
dramatically with the connectivity and state space cardinality of Bayesian
network nodes. In this paper, we address this computational challenge using GPU
parallelization. We develop data structures and algorithms that extend existing
junction tree techniques, and specifically develop a novel approach to
computing each belief propagation message in parallel. We implement our
approach on an NVIDIA GPU and test it using BNs from several applications.
Experimentally, we study how junction tree parameters affect parallelization
opportunities and hence the performance of our algorithm. We achieve speedups
ranging from 0.68 to 9.18 for the BNs studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3778</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3778</id><created>2012-02-14</created><authors><author><keyname>Zhu</keyname><forenames>Jun</forenames></author><author><keyname>Xing</keyname><forenames>Eric P.</forenames></author></authors><title>Sparse Topical Coding</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-831-838</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present sparse topical coding (STC), a non-probabilistic formulation of
topic models for discovering latent representations of large collections of
data. Unlike probabilistic topic models, STC relaxes the normalization
constraint of admixture proportions and the constraint of defining a normalized
likelihood function. Such relaxations make STC amenable to: 1) directly control
the sparsity of inferred representations by using sparsity-inducing
regularizers; 2) be seamlessly integrated with a convex error function (e.g.,
SVM hinge loss) for supervised learning; and 3) be efficiently learned with a
simply structured coordinate descent algorithm. Our results demonstrate the
advantages of STC and supervised MedSTC on identifying topical meanings of
words and improving classification accuracy and time efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3779</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3779</id><created>2012-02-14</created><authors><author><keyname>Zscheischler</keyname><forenames>Jakob</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Zhang</keyname><forenames>Kun</forenames></author></authors><title>Testing whether linear equations are causal: A free probability theory
  approach</title><categories>cs.LG stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-839-846</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method that infers whether linear relations between two
high-dimensional variables X and Y are due to a causal influence from X to Y or
from Y to X. The earlier proposed so-called Trace Method is extended to the
regime where the dimension of the observed variables exceeds the sample size.
Based on previous work, we postulate conditions that characterize a causal
relation between X and Y. Moreover, we describe a statistical test and argue
that both causal directions are typically rejected if there is a common cause.
A full theoretical analysis is presented for the deterministic case but our
approach seems to be valid for the noisy case, too, for which we additionally
present an approach based on a sparsity constraint. The discussed method yields
promising results for both simulated and real world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3782</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3782</id><created>2012-02-14</created><authors><author><keyname>Amin</keyname><forenames>Kareem</forenames></author><author><keyname>Kearns</keyname><forenames>Michael</forenames></author><author><keyname>Syed</keyname><forenames>Umar</forenames></author></authors><title>Graphical Models for Bandit Problems</title><categories>cs.LG cs.AI stat.ML</categories><proxy>auai</proxy><report-no>UAI-P-2011-PG-1-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a rich class of graphical models for multi-armed bandit problems
that permit both the state or context space and the action space to be very
large, yet succinctly specify the payoffs for any context-action pair. Our main
result is an algorithm for such models whose regret is bounded by the number of
parameters and whose running time depends only on the treewidth of the graph
substructure induced by the action space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3807</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3807</id><created>2012-02-16</created><authors><author><keyname>Li</keyname><forenames>Chao</forenames></author><author><keyname>Miklau</keyname><forenames>Gerome</forenames></author></authors><title>An Adaptive Mechanism for Accurate Query Answering under Differential
  Privacy</title><categories>cs.DB</categories><comments>VLDB2012. arXiv admin note: substantial text overlap with
  arXiv:1103.1367</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel mechanism for answering sets of count- ing queries under
differential privacy. Given a workload of counting queries, the mechanism
automatically selects a different set of &quot;strategy&quot; queries to answer
privately, using those answers to derive answers to the workload. The main
algorithm proposed in this paper approximates the optimal strategy for any
workload of linear counting queries. With no cost to the privacy guarantee, the
mechanism improves significantly on prior approaches and achieves near-optimal
error for many workloads, when applied under (\epsilon, \delta)-differential
privacy. The result is an adaptive mechanism which can help users achieve good
utility without requiring that they reason carefully about the best formulation
of their task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3824</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3824</id><created>2012-02-16</created><authors><author><keyname>Zhang</keyname><forenames>Rongqing</forenames></author><author><keyname>Han</keyname><forenames>Lingyang song Zhu</forenames></author><author><keyname>Jiao</keyname><forenames>Bingli</forenames></author></authors><title>Physical Layer Security for Two-Way Untrusted Relaying with Friendly
  Jammers</title><categories>cs.GT cs.NI</categories><comments>28 pages, 11 figures, submitted to IEEE Transactions on Vehicle
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a two-way relay network where two sources can
communicate only through an untrusted intermediate relay, and investigate the
physical layer security issue of this two-way relay scenario. Specifically, we
treat the intermediate relay as an eavesdropper from which the information
transmitted by the sources needs to be kept secret, despite the fact that its
cooperation in relaying this information is essential. We indicate that a
non-zero secrecy rate is indeed achievable in this two-way relay network even
without external friendly jammers. As for the system with friendly jammers,
after further analysis, we can obtain that the secrecy rate of the sources can
be effectively improved by utilizing proper jamming power from the friendly
jammers. Then, we formulate a Stackelberg game model between the sources and
the friendly jammers as a power control scheme to achieve the optimized secrecy
rate of the sources, in which the sources are treated as the sole buyer and the
friendly jammers are the sellers. In addition, the optimal solutions of the
jamming power and the asking prices are given and a distributed updating
algorithm to obtain the Stakelberg equilibrium is provided for the proposed
game. Finally, the simulations results verify the properties and the efficiency
of the proposed Stackelberg game based scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3855</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3855</id><created>2012-02-17</created><updated>2012-03-08</updated><authors><author><keyname>Potgieter</keyname><forenames>Paul</forenames><affiliation>Unisa</affiliation></author></authors><title>The rapid points of a complex oscillation</title><categories>cs.CC math.PR</categories><comments>11 pages</comments><proxy>LMCS</proxy><acm-class>G.3, F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 9,
  2012) lmcs:1188</journal-ref><doi>10.2168/LMCS-8(1:23)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By considering a counting-type argument on Brownian sample paths, we prove a
result similar to that of Orey and Taylor on the exact Hausdorff dimension of
the rapid points of Brownian motion. Because of the nature of the proof we can
then apply the concepts to so-called complex oscillations (or 'algorithmically
random Brownian motion'), showing that their rapid points have the same
dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3856</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3856</id><created>2012-02-17</created><updated>2012-02-27</updated><authors><author><keyname>Akbudak</keyname><forenames>Kadir</forenames></author><author><keyname>Kayaaslan</keyname><forenames>Enver</forenames></author><author><keyname>Aykanat</keyname><forenames>Cevdet</forenames></author></authors><title>Technical Report on Hypergraph-Partitioning-Based Models and Methods for
  Exploiting Cache Locality in Sparse-Matrix Vector Multiplication</title><categories>cs.NA cs.PF</categories><report-no>BU-CE-1201</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sparse matrix-vector multiplication (SpMxV) is a kernel operation widely
used in iterative linear solvers. The same sparse matrix is multiplied by a
dense vector repeatedly in these solvers. Matrices with irregular sparsity
patterns make it difficult to utilize cache locality effectively in SpMxV
computations. In this work, we investigate single- and multiple-SpMxV
frameworks for exploiting cache locality in SpMxV computations. For the
single-SpMxV framework, we propose two cache-size-aware top-down
row/column-reordering methods based on 1D and 2D sparse matrix partitioning by
utilizing the column-net and enhancing the row-column-net hypergraph models of
sparse matrices. The multiple-SpMxV framework depends on splitting a given
matrix into a sum of multiple nonzero-disjoint matrices so that the SpMxV
operation is performed as a sequence of multiple input- and output- dependent
SpMxV operations. For an effective matrix splitting required in this framework,
we propose a cache- size-aware top-down approach based on 2D sparse matrix
partitioning by utilizing the row-column-net hypergraph model. For this
framework, we also propose two methods for effective ordering of individual
SpMxV operations. The primary objective in all of the three methods is to
maximize the exploitation of temporal locality. We evaluate the validity of our
models and methods on a wide range of sparse matrices using both cache-miss
simulations and actual runs by using OSKI. Experimental results show that
proposed methods and models outperform state-of-the-art schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3861</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3861</id><created>2012-02-17</created><updated>2012-04-04</updated><authors><author><keyname>Schreiber</keyname><forenames>Michael</forenames></author></authors><title>Inconsistencies of Recently Proposed Citation Impact Indicators and how
  to Avoid Them</title><categories>stat.AP cs.DL physics.soc-ph</categories><comments>14 pages, 9 figures, accepted by Journal of the American Society for
  Information Science and Technology Final version with slightly changed
  figures, new scoring rule, extended discussion</comments><journal-ref>J. Am. Soc. Inf. Sci. Techn. 63(10), 2062-2073, (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that under certain circumstances in particular for small datasets
the recently proposed citation impact indicators I3(6PR) and R(6,k) behave
inconsistently when additional papers or citations are taken into
consideration. Three simple examples are presented, in which the indicators
fluctuate strongly and the ranking of scientists in the evaluated group is
sometimes completely mixed up by minor changes in the data base. The erratic
behavior is traced to the specific way in which weights are attributed to the
six percentile rank classes, specifically for the tied papers. For 100
percentile rank classes the effects will be less serious. For the 6 classes it
is demonstrated that a different way of assigning weights avoids these
problems, although the non-linearity of the weights for the different
percentile rank classes can still lead to (much less frequent) changes in the
ranking. This behavior is not undesired, because it can be used to correct for
differences in citation behavior in different fields. Remaining deviations from
the theoretical value R(6,k) = 1.91 can be avoided by a new scoring rule, the
fractional scoring. Previously proposed consistency criteria are amended by
another property of strict independence which a performance indicator should
aim at.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3872</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3872</id><created>2012-02-17</created><authors><author><keyname>Pietrzak</keyname><forenames>Thomas</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Crossan</keyname><forenames>Andrew</forenames><affiliation>GIST</affiliation></author><author><keyname>Stephen</keyname><forenames>Brewster A.</forenames><affiliation>GIST</affiliation></author><author><keyname>Martin</keyname><forenames>Beno&#xee;t</forenames><affiliation>LITA</affiliation></author><author><keyname>Pecci</keyname><forenames>Isabelle</forenames><affiliation>LITA</affiliation></author></authors><title>Creating Usable Pin Array Tactons for Non-Visual Information</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Haptics 2, 2 (2009) 61-72</journal-ref><doi>10.1109/TOH.2009.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial information can be difficult to present to a visually impaired
computer user. In this paper we examine a new kind of tactile cueing for
non-visual interaction as a potential solution, building on earlier work on
vibrotactile Tactons. However, unlike vibrotactile Tactons, we use a pin array
to stimulate the finger tip. Here, we describe how to design static and dynamic
Tactons by defining their basic components. We then present user tests
examining how easy it is to distinguish between different forms of pin array
Tactons demonstrating accurate Tacton sets to represent directions. These
experiments demonstrate usable patterns for static, wave and blinking pin array
Tacton sets for guiding a user in one of eight directions. A study is then
described that shows the benefits of structuring Tactons to convey information
through multiple parameters of the signal. By using multiple independent
parameters for a Tacton, this study demonstrates participants perceive more
information through a single Tacton. Two applications using these Tactons are
then presented: a maze exploration application and an electric circuit
exploration application designed for use by and tested with visually impaired
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3884</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3884</id><created>2012-02-17</created><authors><author><keyname>Gaurav</keyname><forenames>Dinesh Dileep</forenames></author><author><keyname>Ramesh</keyname><forenames>Renu</forenames></author></authors><title>A feature extraction technique based on character geometry for character
  recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a geometry based technique for feature extraction
applicable to segmentation-based word recognition systems. The proposed system
extracts the geometric features of the character contour. This features are
based on the basic line types that forms the character skeleton. The system
gives a feature vector as its output. The feature vectors so generated from a
training set, were then used to train a pattern recognition engine based on
Neural Networks so that the system can be benchmarked.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3885</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3885</id><created>2012-02-17</created><updated>2014-07-21</updated><authors><author><keyname>Lekeas</keyname><forenames>Paraskevas V.</forenames></author><author><keyname>Stamatopoulos</keyname><forenames>Giorgos</forenames></author></authors><title>Cooperative oligopoly games with boundedly rational firms</title><categories>cs.GT</categories><comments>Draft version of the published ANOR paper, Annals of Operations
  Research, May 2014</comments><doi>10.1007/s10479-014-1580-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze cooperative Cournot games with boundedly rational firms. Due to
cogni- tive constraints, the members of a coalition cannot accurately predict
the coalitional structure of the non-members. Thus, they compute their value
using simple heuris- tics. In particular, they assign various non-equilibrium
probability distributions over the outsiders' set of partitions. We construct
the characteristic function of a coalition in such an environment and we
analyze the core of the corresponding games. We show that the core is non-empty
provided the number of firms in the market is sufficiently large. Moreover, we
show that if two distributions over the set of partitions are related via
first-order dominance, then the core of the game under the dominated
distribution is a subset of the core under the dominant distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3887</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3887</id><created>2012-02-17</created><authors><author><keyname>Salimi</keyname><forenames>Hamid</forenames></author><author><keyname>Giveki</keyname><forenames>Davar</forenames></author><author><keyname>Soltanshahi</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Hatami</keyname><forenames>Javad</forenames></author></authors><title>Extended Mixture of MLP Experts by Hybrid of Conjugate Gradient Method
  and Modified Cuckoo Search</title><categories>cs.AI</categories><comments>13 pages, 2 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol.3, No.1, January 2012</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper investigates a new method for improving the learning algorithm of
Mixture of Experts (ME) model using a hybrid of Modified Cuckoo Search (MCS)
and Conjugate Gradient (CG) as a second order optimization technique. The CG
technique is combined with Back-Propagation (BP) algorithm to yield a much more
efficient learning algorithm for ME structure. In addition, the experts and
gating networks in enhanced model are replaced by CG based Multi-Layer
Perceptrons (MLPs) to provide faster and more accurate learning. The CG is
considerably depends on initial weights of connections of Artificial Neural
Network (ANN), so, a metaheuristic algorithm, the so-called Modified Cuckoo
Search is applied in order to select the optimal weights. The performance of
proposed method is compared with Gradient Decent Based ME (GDME) and Conjugate
Gradient Based ME (CGME) in classification and regression problems. The
experimental results show that hybrid MSC and CG based ME (MCS-CGME) has faster
convergence and better performance in utilized benchmark data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3890</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3890</id><created>2012-02-17</created><authors><author><keyname>Lattimore</keyname><forenames>Tor</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>PAC Bounds for Discounted MDPs</title><categories>cs.LG</categories><comments>25 LaTeX pages</comments><journal-ref>Proc. 23rd International Conf. on Algorithmic Learning Theory (ALT
  2012) pages 320-334</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study upper and lower bounds on the sample-complexity of learning
near-optimal behaviour in finite-state discounted Markov Decision Processes
(MDPs). For the upper bound we make the assumption that each action leads to at
most two possible next-states and prove a new bound for a UCRL-style algorithm
on the number of time-steps when it is not Probably Approximately Correct
(PAC). The new lower bound strengthens previous work by being both more general
(it applies to all policies) and tighter. The upper and lower bounds match up
to logarithmic factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3898</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3898</id><created>2012-02-17</created><authors><author><keyname>Hansen</keyname><forenames>Kristoffer Arnsfelt</forenames></author><author><keyname>Koucky</keyname><forenames>Michal</forenames></author><author><keyname>Lauritzen</keyname><forenames>Niels</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames></author></authors><title>Exact Algorithms for Solving Stochastic Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shapley's discounted stochastic games, Everett's recursive games and
Gillette's undiscounted stochastic games are classical models of game theory
describing two-player zero-sum games of potentially infinite duration. We
describe algorithms for exactly solving these games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3910</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3910</id><created>2012-02-17</created><authors><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Khan</keyname><forenames>Fahd Ahmed</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Performance of Amplify-and-Forward Multihop Transmission over Relay
  Clusters with Different Routing Strategies</title><categories>cs.IT math.IT</categories><comments>To appear in IJAACS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We Consider a multihop relay network in which two terminals are communicating
with each other via a number of cluster of relays. Performance of such networks
depends on the routing protocols employed. In this paper, we find the
expressions for the average symbol error probability (ASEP) performance of
amplify-and-forward (AF) multihop transmission for the simplest routing
protocol in which the relay transmits using the channel having the best symbol
to noise ratio (SNR). The ASEP performance of a better protocol proposed in [1]
known as the adhoc protocol is also analyzed. The derived expressions for the
performance are a convenient tool to analyze the performance of AF multihop
transmission over relay clusters. Monte-Carlo simulations verify the
correctness of the proposed formulation and are in agreement with analytical
results. Furthermore, we propose new generalized protocols termed as last-n-hop
selection protocol, the dual path protocol, the forward- backward last-n-hop
selection protocol, and the forward-backward dual path protocol, to get
improved ASEP performances. The ASEP performance of these proposed schemes is
analysed by computer simulations. It is shown that close to optimal performance
can be achieved by using the last-n-hop selection protocol and its
forward-backward variant. The complexity of the protocols is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3913</identifier>
 <datestamp>2012-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3913</id><created>2012-02-17</created><updated>2012-08-17</updated><authors><author><keyname>Liu</keyname><forenames>Entao</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author><author><keyname>Scharf</keyname><forenames>Louis L.</forenames></author></authors><title>Greedy Adaptive Compression in Signal-Plus-Noise Models</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to examine the greedy adaptive measurement
policy in the context of a linear Guassian measurement model with an
optimization criterion based on information gain. In the special case of
sequential scalar measurements, we provide sufficient conditions under which
the greedy policy actually is optimal in the sense of maximizing the net
information gain. In the general setting, we also discuss cases where the
greedy policy is not optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3914</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3914</id><created>2012-02-17</created><updated>2013-03-10</updated><authors><author><keyname>Barletta</keyname><forenames>Luca</forenames></author><author><keyname>Borgonovo</keyname><forenames>Flaminio</forenames></author><author><keyname>Cesana</keyname><forenames>Matteo</forenames></author></authors><title>A formal proof of the optimal frame setting for Dynamic-Frame Aloha with
  known population size</title><categories>cs.IT math.IT</categories><comments>22 pages, submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Dynamic-Frame Aloha subsequent frame lengths must be optimally chosen to
maximize throughput. When the initial population size ${\cal N}$ is known,
numerical evaluations show that the maximum efficiency is achieved by setting
the frame length equal to the backlog size at each subsequent frame; however,
at best of our knowledge, a formal proof of this result is still missing, and
is provided here. As byproduct, we also prove that the asymptotical efficiency
in the optimal case is $e^{-1}$, provide upper and lower bounds for the length
of the entire transmission period and show that its asymptotical behaviour is
$\sim ne-\zeta \ln (n)$, with $\zeta=0.5/\ln(1-e^{-1})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3919</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3919</id><created>2012-02-17</created><authors><author><keyname>Malacria</keyname><forenames>Sylvain</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Pietrzak</keyname><forenames>Thomas</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Tabard</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>pIT</affiliation></author><author><keyname>Lecolinet</keyname><forenames>&#xc9;ric</forenames><affiliation>LTCI</affiliation></author></authors><title>U-Note: Capture the Class and Access it Everywhere</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>Interact 2011 (2011)</journal-ref><doi>10.1007/978-3-642-23774-4_50</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present U-Note, an augmented teaching and learning system leveraging the
advantages of paper while letting teachers and pupils benefit from the richness
that digital media can bring to a lecture. U-Note provides automatic linking
between the notes of the pupils' notebooks and various events that occurred
during the class (such as opening digital documents, changing slides, writing
text on an interactive whiteboard...). Pupils can thus explore their notes in
conjunction with the digital documents that were presented by the teacher
during the lesson. Additionally, they can also listen to what the teacher was
saying when a given note was written. Finally, they can add their own comments
and documents to their notebooks to extend their lecture notes. We interviewed
teachers and deployed questionnaires to identify both teachers and pupils'
habits: most of the teachers use (or would like to use) digital documents in
their lectures but have problems in sharing these resources with their pupils.
The results of this study also show that paper remains the primary medium used
for knowledge keeping, sharing and editing by the pupils. Based on these
observations, we designed U-Note, which is built on three modules. U-Teach
captures the context of the class: audio recordings, the whiteboard contents,
together with the web pages, videos and slideshows displayed during the lesson.
U-Study binds pupils' paper notes (taken with an Anoto digital pen) with the
data coming from U-Teach and lets pupils access the class materials at home,
through their notebooks. U-Move lets pupils browse lecture materials on their
smartphone when they are not in front of a computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3926</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3926</id><created>2012-02-17</created><authors><author><keyname>Pietrzak</keyname><forenames>Thomas</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Crossan</keyname><forenames>Andrew</forenames><affiliation>GIST</affiliation></author><author><keyname>Brewster</keyname><forenames>Stephen A.</forenames><affiliation>GIST</affiliation></author><author><keyname>Martin</keyname><forenames>Beno&#xee;t</forenames><affiliation>LITA</affiliation></author><author><keyname>Pecci</keyname><forenames>Isabelle</forenames><affiliation>LITA</affiliation></author></authors><title>Exploring Geometric Shapes with Touch</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>Interact 2009 (2009)</journal-ref><doi>10.1007/978-3-642-03655-2_18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new technique to help users to explore geometric shapes without
vision. This technique is based on a guidance using directional cues with a pin
array. This is an alternative to the usual technique that consists of raising
the pins corresponding to dark pixels around the cursor. In this paper we
compare the exploration of geometric shapes with our new technique in unimanual
and bimanual conditions. The users made fewer errors in unimanual condition
than in bimanual condition. However they did not explore the shapes more
quickly and there was no difference in confidence in their answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3941</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3941</id><created>2012-02-17</created><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>Calero-Medina</keyname><forenames>Clara</forenames></author><author><keyname>Kosten</keyname><forenames>Joost</forenames></author><author><keyname>Noyons</keyname><forenames>Ed C. M.</forenames></author><author><keyname>Tijssen</keyname><forenames>Robert J. W.</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author><author><keyname>Visser</keyname><forenames>Martijn S.</forenames></author><author><keyname>Wouters</keyname><forenames>Paul</forenames></author></authors><title>The Leiden Ranking 2011/2012: Data collection, indicators, and
  interpretation</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Leiden Ranking 2011/2012 is a ranking of universities based on
bibliometric indicators of publication output, citation impact, and scientific
collaboration. The ranking includes 500 major universities from 41 different
countries. This paper provides an extensive discussion of the Leiden Ranking
2011/2012. The ranking is compared with other global university rankings, in
particular the Academic Ranking of World Universities (commonly known as the
Shanghai Ranking) and the Times Higher Education World University Rankings.
Also, a detailed description is offered of the data collection methodology of
the Leiden Ranking 2011/2012 and of the indicators used in the ranking. Various
innovations in the Leiden Ranking 2011/2012 are presented. These innovations
include (1) an indicator based on counting a university's highly cited
publications, (2) indicators based on fractional rather than full counting of
collaborative publications, (3) the possibility of excluding non-English
language publications, and (4) the use of stability intervals. Finally, some
comments are made on the interpretation of the ranking, and a number of
limitations of the ranking are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3943</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3943</id><created>2012-02-17</created><authors><author><keyname>Katz</keyname><forenames>Daniel S.</forenames></author><author><keyname>Armstrong</keyname><forenames>Timothy G.</forenames></author><author><keyname>Zhang</keyname><forenames>Zhao</forenames></author><author><keyname>Wilde</keyname><forenames>Michael</forenames></author><author><keyname>Wozniak</keyname><forenames>Justin M.</forenames></author></authors><title>Many-Task Computing and Blue Waters</title><categories>cs.DC</categories><journal-ref>Technical Report CI-TR-13-0911. Computation Institute, University
  of Chicago &amp; Argonne National Laboratory. 2012. http://www.ci.uchicago.
  edu/research/papers/CI-TR-13-0911</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report discusses many-task computing (MTC) generically and in the
context of the proposed Blue Waters systems, which is planned to be the largest
NSF-funded supercomputer when it begins production use in 2012. The aim of this
report is to inform the BW project about MTC, including understanding aspects
of MTC applications that can be used to characterize the domain and
understanding the implications of these aspects to middleware and policies.
Many MTC applications do not neatly fit the stereotypes of high-performance
computing (HPC) or high-throughput computing (HTC) applications. Like HTC
applications, by definition MTC applications are structured as graphs of
discrete tasks, with explicit input and output dependencies forming the graph
edges. However, MTC applications have significant features that distinguish
them from typical HTC applications. In particular, different engineering
constraints for hardware and software must be met in order to support these
applications. HTC applications have traditionally run on platforms such as
grids and clusters, through either workflow systems or parallel programming
systems. MTC applications, in contrast, will often demand a short time to
solution, may be communication intensive or data intensive, and may comprise
very short tasks. Therefore, hardware and software for MTC must be engineered
to support the additional communication and I/O and must minimize task dispatch
overheads. The hardware of large-scale HPC systems, with its high degree of
parallelism and support for intensive communication, is well suited for MTC
applications. However, HPC systems often lack a dynamic resource-provisioning
feature, are not ideal for task communication via the file system, and have an
I/O system that is not optimized for MTC-style applications. Hence, additional
software support is likely to be required to gain full benefit from the HPC
hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3949</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3949</id><created>2012-02-17</created><updated>2013-08-05</updated><authors><author><keyname>de Beaudrap</keyname><forenames>Niel</forenames><affiliation>DAMTP, Centre for Mathematical Studies, University of Cambridge</affiliation></author></authors><title>On the complexity of solving linear congruences and computing nullspaces
  modulo a constant</title><categories>cs.CC</categories><comments>17 pages, one Appendix; minor corrections and revisions to
  presentation, new observations regarding the prospect of oracle closures.
  Comments welcome</comments><msc-class>11D04, 68Q25</msc-class><acm-class>F.1.3; F.2.1</acm-class><journal-ref>Chicago Journal of Theoretical Computer Science vol.2013 (#10),
  July 2013</journal-ref><doi>10.4086/cjtcs.2013.010</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the problems of determining the feasibility of a linear
congruence, producing a solution to a linear congruence, and finding a spanning
set for the nullspace of an integer matrix, where each problem is considered
modulo an arbitrary constant k&gt;1. These problems are known to be complete for
the logspace modular counting classes {Mod_k L} = {coMod_k L} in special case
that k is prime (Buntrock et al, 1992). By considering variants of standard
logspace function classes --- related to #L and functions computable by UL
machines, but which only characterize the number of accepting paths modulo k
--- we show that these problems of linear algebra are also complete for
{coMod_k L} for any constant k&gt;1.
  Our results are obtained by defining a class of functions FUL_k which are low
for {Mod_k L} and {coMod_k L} for k&gt;1, using ideas similar to those used in the
case of k prime in (Buntrock et al, 1992) to show closure of Mod_k L under NC^1
reductions (including {Mod_k L} oracle reductions). In addition to the results
above, we briefly consider the relationship of the class FUL_k for arbitrary
moduli k to the class {F.coMod_k L} of functions whose output symbols are
verifiable by {coMod_k L} algorithms; and consider what consequences such a
comparison may have for oracle closure results of the form {Mod_k L}^{Mod_k L}
= {Mod_k L} for composite k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3952</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3952</id><created>2012-02-17</created><authors><author><keyname>De Rosnay</keyname><forenames>Melanie Dulong</forenames></author></authors><title>Check Your Data Freedom: A Taxonomy to Assess Life Science Database
  Openness</title><categories>q-bio.QM cs.DL</categories><proxy>ccsd</proxy><journal-ref>Nature Precedings (2008) doi:10.1038/npre.2008.2083.1</journal-ref><doi>10.1038/npre.2008.2083.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular biology data are subject to terms of use that vary widely between
databases and curating institutions. This research presents a taxonomy of
contractual and technical restrictions applicable to databases in life science.
It builds upon research led by Science Commons demonstrating why open data and
the freedom to integrate facilitate innovation and how this openness can be
achieved. The taxonomy describes technical and legal restrictions applicable to
life science databases, and its metadata have been used to assess terms of use
of databases hosted by Life Science Resource Name (LSRN) Schema. While a few
public domain policies are standardized, most terms of use are not harmonized,
difficult to understand and impose controls that prevent others from
effectively reusing data. Identifying a small number of restrictions allows one
to quickly appreciate which databases are open. A checklist for data openness
is proposed in order to assist database curators who wish to make their data
more open to make sure they do so.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3957</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3957</id><created>2012-02-17</created><updated>2012-03-07</updated><authors><author><keyname>Figueira</keyname><forenames>Diego</forenames><affiliation>INRIA &amp; ENS Cachan, LSV</affiliation></author></authors><title>Alternating register automata on finite words and trees</title><categories>cs.DB cs.FL cs.LO</categories><proxy>LMCS</proxy><acm-class>I.7.2, H.2.3, H.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 9,
  2012) lmcs:907</journal-ref><doi>10.2168/LMCS-8(1:22)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study alternating register automata on data words and data trees in
relation to logics. A data word (resp. data tree) is a word (resp. tree) whose
every position carries a label from a finite alphabet and a data value from an
infinite domain. We investigate one-way automata with alternating control over
data words or trees, with one register for storing data and comparing them for
equality. This is a continuation of the study started by Demri, Lazic and
Jurdzinski. From the standpoint of register automata models, this work aims at
two objectives: (1) simplifying the existent decidability proofs for the
emptiness problem for alternating register automata; and (2) exhibiting
decidable extensions for these models. From the logical perspective, we show
that (a) in the case of data words, satisfiability of LTL with one register and
quantification over data values is decidable; and (b) the satisfiability
problem for the so-called forward fragment of XPath on XML documents is
decidable, even in the presence of DTDs and even of key constraints. The
decidability is obtained through a reduction to the automata model introduced.
This fragment contains the child, descendant, next-sibling and
following-sibling axes, as well as data equality and inequality tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3974</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3974</id><created>2012-02-17</created><authors><author><keyname>Fricker</keyname><forenames>Christine</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Roberts</keyname><forenames>James</forenames></author></authors><title>A versatile and accurate approximation for LRU cache performance</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a 2002 paper, Che and co-authors proposed a simple approach for estimating
the hit rates of a cache operating the least recently used (LRU) replacement
policy. The approximation proves remarkably accurate and is applicable to quite
general distributions of object popularity. This paper provides a mathematical
explanation for the success of the approximation, notably in configurations
where the intuitive arguments of Che, et al clearly do not apply. The
approximation is particularly useful in evaluating the performance of current
proposals for an information centric network where other approaches fail due to
the very large populations of cacheable objects to be taken into account and to
their complex popularity law, resulting from the mix of different content types
and the filtering effect induced by the lower layers in a cache hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3985</identifier>
 <datestamp>2014-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3985</id><created>2012-02-17</created><updated>2014-10-13</updated><authors><author><keyname>Sutherland</keyname><forenames>Andrew V.</forenames></author></authors><title>On the evaluation of modular polynomials</title><categories>math.NT cs.CR</categories><comments>19 pages, corrected a typo in equation (8) and added equation (9)</comments><msc-class>11G07 (Primary) 11Y16, 14H52, 11G15 (Secondary)</msc-class><journal-ref>Proceedings of the Tenth Algorithmic Number Theory Symposium (ANTS
  X), Open Book Series 1, Mathematical Sciences Publishers, 2013, 531-555</journal-ref><doi>10.2140/obs.2013.1.531</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two algorithms that, given a prime ell and an elliptic curve E/Fq,
directly compute the polynomial Phi_ell(j(E),Y) in Fq[Y] whose roots are the
j-invariants of the elliptic curves that are ell-isogenous to E. We do not
assume that the modular polynomial Phi_ell(X,Y) is given. The algorithms may be
adapted to handle other types of modular polynomials, and we consider
applications to point counting and the computation of endomorphism rings. We
demonstrate the practical efficiency of the algorithms by setting a new
point-counting record, modulo a prime q with more than 5,000 decimal digits,
and by evaluating a modular polynomial of level ell = 100,019.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3987</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3987</id><created>2012-02-17</created><authors><author><keyname>Edwards</keyname><forenames>Benjamin</forenames></author><author><keyname>Moore</keyname><forenames>Tyler</forenames></author><author><keyname>Stelle</keyname><forenames>George</forenames></author><author><keyname>Hofmeyr</keyname><forenames>Steven</forenames></author><author><keyname>Forrest</keyname><forenames>Stephanie</forenames></author></authors><title>Beyond the Blacklist: Modeling Malware Spread and the Effect of
  Interventions</title><categories>cs.CR cs.SI</categories><comments>13 pages, 11 figures</comments><acm-class>K.6.5; K.6.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malware spread among websites and between websites and clients is an
increasing problem. Search engines play an important role in directing users to
websites and are a natural control point for intervening, using mechanisms such
as blacklisting. The paper presents a simple Markov model of malware spread
through large populations of websites and studies the effect of two
interventions that might be deployed by a search provider: blacklisting
infected web pages by removing them from search results entirely and a
generalization of blacklisting, called depreferencing, in which a website's
ranking is decreased by a fixed percentage each time period the site remains
infected. We analyze and study the trade-offs between infection exposure and
traffic loss due to false positives (the cost to a website that is incorrectly
blacklisted) for different interventions. As expected, we find that
interventions are most effective when websites are slow to remove infections.
Surprisingly, we also find that low infection or recovery rates can increase
traffic loss due to false positives. Our analysis also shows that heavy-tailed
distributions of website popularity, as documented in many studies, leads to
high sample variance of all measured outcomes. These result implies that it
will be difficult to determine empirically whether certain website
interventions are effective, and it suggests that theoretical models such as
the one described in this paper have an important role to play in improving web
security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.3993</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.3993</id><created>2012-02-17</created><authors><author><keyname>Edwards</keyname><forenames>Benjamin</forenames></author><author><keyname>Hofmeyr</keyname><forenames>Steven</forenames></author><author><keyname>Stelle</keyname><forenames>George</forenames></author><author><keyname>Forrest</keyname><forenames>Stephanie</forenames></author></authors><title>Internet Topology over Time</title><categories>cs.NI cs.SI</categories><comments>6 pages, 5 figures</comments><acm-class>C.2.5; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are few studies that look closely at how the topology of the Internet
evolves over time; most focus on snapshots taken at a particular point in time.
In this paper, we investigate the evolution of the topology of the Autonomous
Systems graph of the Internet, examining how eight commonly-used topological
measures change from January 2002 to January 2010. We find that the
distributions of most of the measures remain unchanged, except for average path
length and clustering coefficient. The average path length has slowly and
steadily increased since 2005 and the average clustering coefficient has
steadily declined. We hypothesize that these changes are due to changes in
peering policies as the Internet evolves. We also investigate a surprising
feature, namely that the maximum degree has changed little, an aspect that
cannot be captured without modeling link deletion. Our results suggest that
evaluating models of the Internet graph by comparing steady-state generated
topologies to snapshots of the real data is reasonable for many measures.
However, accurately matching time-variant properties is more difficult, as we
demonstrate by evaluating ten well-known models against the 2010 data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4002</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4002</id><created>2012-02-17</created><authors><author><keyname>Vidal</keyname><forenames>Rene</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author><author><keyname>Sastry</keyname><forenames>Shankar</forenames></author></authors><title>Generalized Principal Component Analysis (GPCA)</title><categories>cs.CV cs.LG</categories><journal-ref>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  vol 27, no 12, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algebro-geometric solution to the problem of
segmenting an unknown number of subspaces of unknown and varying dimensions
from sample data points. We represent the subspaces with a set of homogeneous
polynomials whose degree is the number of subspaces and whose derivatives at a
data point give normal vectors to the subspace passing through the point. When
the number of subspaces is known, we show that these polynomials can be
estimated linearly from data; hence, subspace segmentation is reduced to
classifying one point per subspace. We select these points optimally from the
data set by minimizing certain distance function, thus dealing automatically
with moderate noise in the data. A basis for the complement of each subspace is
then recovered by applying standard PCA to the collection of derivatives
(normal vectors). Extensions of GPCA that deal with data in a high- dimensional
space and with an unknown number of subspaces are also presented. Our
experiments on low-dimensional data show that GPCA outperforms existing
algebraic algorithms based on polynomial factorization and provides a good
initialization to iterative techniques such as K-subspaces and Expectation
Maximization. We also present applications of GPCA to computer vision problems
such as face clustering, temporal video segmentation, and 3D motion
segmentation from point correspondences in multiple affine views.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4008</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4008</id><created>2012-02-17</created><authors><author><keyname>Hofmeyr</keyname><forenames>Steven</forenames></author><author><keyname>Moore</keyname><forenames>Tyler</forenames></author><author><keyname>Forrest</keyname><forenames>Stephanie</forenames></author><author><keyname>Edwards</keyname><forenames>Benjamin</forenames></author><author><keyname>Stelle</keyname><forenames>George</forenames></author></authors><title>Modeling Internet-Scale Policies for Cleaning up Malware</title><categories>cs.NI cs.CR cs.MA</categories><comments>22 pages, 9 Figures, Presented at the Tenth Workshop on the Economics
  of Information Security, Jun 2011</comments><acm-class>K.5.5; K.6.m; C.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An emerging consensus among policy makers is that interventions undertaken by
Internet Service Providers are the best way to counter the rising incidence of
malware. However, assessing the suitability of countermeasures at this scale is
hard. In this paper, we use an agent-based model, called ASIM, to investigate
the impact of policy interventions at the Autonomous System level of the
Internet. For instance, we find that coordinated intervention by the
0.2%-biggest ASes is more effective than uncoordinated efforts adopted by 30%
of all ASes. Furthermore, countermeasures that block malicious transit traffic
appear more effective than ones that block outgoing traffic. The model allows
us to quantify and compare positive externalities created by different
countermeasures. Our results give an initial indication of the types and levels
of intervention that are most cost-effective at large scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4030</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4030</id><created>2012-02-17</created><authors><author><keyname>Shekhar</keyname><forenames>Shashi</forenames></author><author><keyname>Dietz</keyname><forenames>Michael</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>AdSplit: Separating smartphone advertising from applications</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wide variety of smartphone applications today rely on third-party
advertising services, which provide libraries that are linked into the hosting
application. This situation is undesirable for both the application author and
the advertiser. Advertising libraries require additional permissions, resulting
in additional permission requests to users. Likewise, a malicious application
could simulate the behavior of the advertising library, forging the user's
interaction and effectively stealing money from the advertiser. This paper
describes AdSplit, where we extended Android to allow an application and its
advertising to run as separate processes, under separate user-ids, eliminating
the need for applications to request permissions on behalf of their advertising
libraries.
  We also leverage mechanisms from Quire to allow the remote server to validate
the authenticity of client-side behavior. In this paper, we quantify the degree
of permission bloat caused by advertising, with a study of thousands of
downloaded apps. AdSplit automatically recompiles apps to extract their ad
services, and we measure minimal runtime overhead. We also observe that most ad
libraries just embed an HTML widget within and describe how AdSplit can be
designed with this in mind to avoid any need for ads to have native code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4033</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4033</id><created>2012-02-17</created><authors><author><keyname>Sridharan</keyname><forenames>Arun</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author></authors><title>Energy Efficient Greedy Link Scheduling and Power Control in wireless
  networks</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of joint link scheduling and power control for
wireless networks with average transmission power constraints. Due to the high
computational complexity of the optimal policies, we extend the class of greedy
link scheduling policies to handle average power constraints. We develop a
greedy link scheduling and power control scheme GECS, with provable performance
guarantees.
  We show that the performance of our greedy scheduler can be characterized
using the Local Pooling Factor (LPF) of a network graph, which has been
previously used to characterize the stability of the Greedy Maximal Scheduling
(GMS) policy for wireless networks. We also simulate the performance of GECS on
wireless network, and compare its performance to another candidate greedy link
scheduling and power control policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4034</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4034</id><created>2012-02-17</created><updated>2012-09-04</updated><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>PAR-Aware Large-Scale Multi-User MIMO-OFDM Downlink</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Journal on Selected Areas in Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate an orthogonal frequency-division multiplexing (OFDM)-based
downlink transmission scheme for large-scale multi-user (MU) multiple-input
multiple-output (MIMO) wireless systems. The use of OFDM causes a high
peak-to-average (power) ratio (PAR), which necessitates expensive and
power-inefficient radio-frequency (RF) components at the base station. In this
paper, we present a novel downlink transmission scheme, which exploits the
massive degrees-of-freedom available in large-scale MU-MIMO-OFDM systems to
achieve low PAR. Specifically, we propose to jointly perform MU precoding, OFDM
modulation, and PAR reduction by solving a convex optimization problem. We
develop a corresponding fast iterative truncation algorithm (FITRA) and show
numerical results to demonstrate tremendous PAR-reduction capabilities. The
significantly reduced linearity requirements eventually enable the use of
low-cost RF components for the large-scale MU-MIMO-OFDM downlink.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4041</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4041</id><created>2012-02-17</created><updated>2012-05-11</updated><authors><author><keyname>Bae</keyname><forenames>Jung Hyun</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author><author><keyname>Kang</keyname><forenames>Inyup</forenames></author></authors><title>Simple transmission strategies for interference channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate performances of simple transmission strategies.
We first consider two user SISO Gaussian symmetric interference channel (IC)
for which Etkin, Tse and Wang proposed a scheme (ETW scheme) which achieves one
bit gap to the capacity. We compare performance of point-to-point (p2p) codes
with that of the ETW scheme in practical range of transmitter power. It turns
out that p2p coding scheme performs better or as nearly good as the ETW scheme.
Next, we consider K user SISO Gaussian symmetric IC. We define interference
regimes for K user SISO Gaussian symmetric IC and provide closed-form
characterization of the symmetric rate achieved by the p2p scheme and the ETW
scheme. Using this characterization, we evaluate performances of simple
strategies with K=3, and show the similar trend to two user case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4044</identifier>
 <datestamp>2015-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4044</id><created>2012-02-17</created><updated>2014-08-11</updated><authors><author><keyname>Lerman</keyname><forenames>Gilad</forenames></author><author><keyname>McCoy</keyname><forenames>Michael</forenames></author><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author><author><keyname>Zhang</keyname><forenames>Teng</forenames></author></authors><title>Robust computation of linear models by convex relaxation</title><categories>cs.IT math.IT stat.CO stat.ML</categories><comments>Formerly titled &quot;Robust computation of linear models, or How to find
  a needle in a haystack&quot;</comments><msc-class>62H25, 65K05, 90C22</msc-class><journal-ref>Foundations of Computational Mathematics, April 2015, Volume 15,
  Issue 2, pp 363-410</journal-ref><doi>10.1007/s10208-014-9221-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a dataset of vector-valued observations that consists of noisy
inliers, which are explained well by a low-dimensional subspace, along with
some number of outliers. This work describes a convex optimization problem,
called REAPER, that can reliably fit a low-dimensional model to this type of
data. This approach parameterizes linear subspaces using orthogonal projectors,
and it uses a relaxation of the set of orthogonal projectors to reach the
convex formulation. The paper provides an efficient algorithm for solving the
REAPER problem, and it documents numerical experiments which confirm that
REAPER can dependably find linear structure in synthetic and natural data. In
addition, when the inliers lie near a low-dimensional subspace, there is a
rigorous theory that describes when REAPER can approximate this subspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4045</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4045</id><created>2012-02-17</created><updated>2012-08-26</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>Complementary vertices and adjacency testing in polytopes</title><categories>math.CO cs.CG</categories><comments>14 pages, 5 figures. v1: published in COCOON 2012. v2: full journal
  version, which strengthens and extends the results in Section 2 (see p1 of
  the paper for details)</comments><msc-class>52B05, 52B55</msc-class><journal-ref>Lecture Notes in Computer Science, vol. 7434, 2012, pp. 507-518</journal-ref><doi>10.1007/978-3-642-32241-9_43</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our main theoretical result is that, if a simple polytope has a pair of
complementary vertices (i.e., two vertices with no facets in common), then it
has at least two such pairs, which can be chosen to be disjoint. Using this
result, we improve adjacency testing for vertices in both simple and non-simple
polytopes: given a polytope in the standard form {x \in R^n | Ax = b and x \geq
0} and a list of its V vertices, we describe an O(n) test to identify whether
any two given vertices are adjacent. For simple polytopes this test is perfect;
for non-simple polytopes it may be indeterminate, and instead acts as a filter
to identify non-adjacent pairs. Our test requires an O(n^2 V + n V^2)
precomputation, which is acceptable in settings such as all-pairs adjacency
testing. These results improve upon the more general O(nV) combinatorial and
O(n^3) algebraic adjacency tests from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4050</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4050</id><created>2012-02-17</created><updated>2012-10-07</updated><authors><author><keyname>Mehta</keyname><forenames>Nishant A.</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author></authors><title>On the Sample Complexity of Predictive Sparse Coding</title><categories>cs.LG stat.ML</categories><comments>Sparse Coding Stability Theorem from version 1 has been relaxed
  considerably using a new notion of coding margin. Old Sparse Coding Stability
  Theorem still in new version, now as Theorem 2. Presentation of all proofs
  simplified/improved considerably. Paper reorganized. Empirical analysis
  showing new coding margin is non-trivial on real datasets</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of predictive sparse coding is to learn a representation of examples
as sparse linear combinations of elements from a dictionary, such that a
learned hypothesis linear in the new representation performs well on a
predictive task. Predictive sparse coding algorithms recently have demonstrated
impressive performance on a variety of supervised tasks, but their
generalization properties have not been studied. We establish the first
generalization error bounds for predictive sparse coding, covering two
settings: 1) the overcomplete setting, where the number of features k exceeds
the original dimensionality d; and 2) the high or infinite-dimensional setting,
where only dimension-free bounds are useful. Both learning bounds intimately
depend on stability properties of the learned sparse encoder, as measured on
the training sample. Consequently, we first present a fundamental stability
result for the LASSO, a result characterizing the stability of the sparse codes
with respect to perturbations to the dictionary. In the overcomplete setting,
we present an estimation error bound that decays as \tilde{O}(sqrt(d k/m)) with
respect to d and k. In the high or infinite-dimensional setting, we show a
dimension-free bound that is \tilde{O}(sqrt(k^2 s / m)) with respect to k and
s, where s is an upper bound on the number of non-zeros in the sparse code for
any training data point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4051</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4051</id><created>2012-02-17</created><updated>2012-03-01</updated><authors><author><keyname>Kenyon</keyname><forenames>Katherine H.</forenames></author><author><keyname>Paramasivam</keyname><forenames>Arjun</forenames></author><author><keyname>Tu</keyname><forenames>Jiachin</forenames></author><author><keyname>Zhang</keyname><forenames>Albert</forenames></author><author><keyname>Graham</keyname><forenames>Alister W.</forenames></author></authors><title>Citations to Australian Astronomy: 5 and 10 Year Benchmarks</title><categories>astro-ph.IM cs.DL</categories><comments>To appear in the Publications of the Astronomical Society of
  Australia. (This version includes a legitimate but accidentally missed
  astronomer who was publishing from Australia with a non-Australian
  affiliation at the time of the survey.)</comments><doi>10.1071/AS12011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expanding upon Pimbblet's informative 2011 analysis of career h-indices for
members of the Astronomical Society of Australia, we provide additional
citation metrics which are geared to a) quantifying the current performance of
b) all professional astronomers in Australia. We have trawled the staff
web-pages of Australian Universities, Observatories and Research Organisations
hosting professional astronomers, and identified 383 PhD-qualified,
research-active, astronomers in the nation - 131 of these are not members of
the Astronomical Society of Australia. Using the SAO/NASA Astrophysics Data
System, we provide the three following common metrics based on publications in
the first decade of the 21st century (2001-2010): h-index, author-normalised
citation count and lead-author citation count. We additionally present a
somewhat more inclusive analysis, applicable for many early-career researchers,
that is based on publications from 2006-2010. Histograms and percentiles, plus
top-performer lists, are presented for each category. Finally, building on
Hirsch's empirical equation, we find that the (10-year) h-index and (10-year)
total citation count T can be approximated by the relation h =
(0.5+sqrt{T})/sqrt{5} for h &gt; 5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4058</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4058</id><created>2012-02-17</created><updated>2013-09-04</updated><authors><author><keyname>Song</keyname><forenames>Yun</forenames></author><author><keyname>Li</keyname><forenames>Zhihui</forenames></author></authors><title>Secret sharing with a class of minimal linear codes</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author due to the wrong proof of
  Theorem 3.3 and unclear expression of Algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are several methods for constructing secret sharing schemes, one of
which is based on coding theory. Theoretically, every linear code can be used
to construct secret sharing schemes. However, in general, determining the
access structures of the schemes based on linear codes is very hard. This paper
proposed the concept of minimal linear code, which makes the determination of
the access structures of the schemes based on the duals of minimal linear codes
easier. It is proved that the shortening codes of minimal linear codes are also
minimal ones. Then the conditions whether several types of irreducible cyclic
codes are minimal linear codes are presented. Furthermore, the access
structures of secret sharing schemes based on the duals of minimal linear codes
are studied, and these access structures in specific examples are obtained
through programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4061</identifier>
 <datestamp>2012-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4061</id><created>2012-02-18</created><updated>2012-04-24</updated><authors><author><keyname>Walter</keyname><forenames>Matthias</forenames></author><author><keyname>Truemper</keyname><forenames>Klaus</forenames></author></authors><title>Implementation of a Unimodularity Test</title><categories>math.CO cs.MS</categories><comments>19 pages, minor reformulations</comments><msc-class>97N80 (Primary), 90C57 (Secondary), 52B40 (Secondary)</msc-class><acm-class>G.2.1; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes implementation and computational results of a polynomial
test of total unimodularity. The test is a simplified version of a prior
method. The program also decides two related unimodularity properties. The
software is available free of charge in source code form under the Boost
Software License.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4063</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4063</id><created>2012-02-18</created><authors><author><keyname>Hassan</keyname><forenames>Sundus</forenames></author><author><keyname>Rafi</keyname><forenames>Muhammad</forenames></author><author><keyname>Shaikh</keyname><forenames>Muhammad Shahid</forenames></author></authors><title>Comparing SVM and Naive Bayes classifiers for text categorization with
  Wikitology as knowledge enrichment</title><categories>cs.AI cs.IR</categories><comments>5 pages</comments><journal-ref>Multitopic Conference (INMIC), 2011 IEEE 14th International</journal-ref><doi>10.1109/INMIC.2011.6151495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The activity of labeling of documents according to their content is known as
text categorization. Many experiments have been carried out to enhance text
categorization by adding background knowledge to the document using knowledge
repositories like Word Net, Open Project Directory (OPD), Wikipedia and
Wikitology. In our previous work, we have carried out intensive experiments by
extracting knowledge from Wikitology and evaluating the experiment on Support
Vector Machine with 10- fold cross-validations. The results clearly indicate
Wikitology is far better than other knowledge bases. In this paper we are
comparing Support Vector Machine (SVM) and Na\&quot;ive Bayes (NB) classifiers under
text enrichment through Wikitology. We validated results with 10-fold cross
validation and shown that NB gives an improvement of +28.78%, on the other hand
SVM gives an improvement of +6.36% when compared with baseline results. Na\&quot;ive
Bayes classifier is better choice when external enriching is used through any
external knowledge base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4072</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4072</id><created>2012-02-18</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Levin</keyname><forenames>Asaf</forenames></author></authors><title>An efficient polynomial time approximation scheme for load balancing on
  uniformly related machines</title><categories>cs.DS</categories><msc-class>68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider basic problems of non-preemptive scheduling on uniformly related
machines. For a given schedule, defined by a partition of the jobs into m
subsets corresponding to the m machines, C_i denotes the completion time of
machine i. Our goal is to find a schedule which minimizes or maximizes
\sum_{i=1}^m C_i^p for a fixed value of p such that 0&lt;p&lt;\infty. For p&gt;1 the
minimization problem is equivalent to the well-known problem of minimizing the
\ell_p norm of the vector of the completion times of the machines, and for
0&lt;p&lt;1 the maximization problem is of interest. Our main result is an efficient
polynomial time approximation scheme (EPTAS) for each one of these problems.
Our schemes use a non-standard application of the so-called shifting technique.
We focus on the work (total size of jobs) assigned to each machine and
introduce intervals of forbidden work. These intervals are defined so that the
resulting effect on the goal function is sufficiently small. This allows the
partition of the problem into sub-problems (with subsets of machines and jobs)
whose solutions are combined into the final solution using dynamic programming.
Our results are the first EPTAS's for this natural class of load balancing
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4076</identifier>
 <datestamp>2012-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4076</id><created>2012-02-18</created><authors><author><keyname>Kucherov</keyname><forenames>Gregory</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author><author><keyname>Starikovskaya</keyname><forenames>Tatiana</forenames></author></authors><title>Cross-Document Pattern Matching</title><categories>cs.DS</categories><doi>10.1007/978-3-642-31265-6_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a new variant of the string matching problem called cross-document
string matching, which is the problem of indexing a collection of documents to
support an efficient search for a pattern in a selected document, where the
pattern itself is a substring of another document. Several variants of this
problem are considered, and efficient linear-space solutions are proposed with
query time bounds that either do not depend at all on the pattern size or
depend on it in a very limited way (doubly logarithmic). As a side result, we
propose an improved solution to the weighted level ancestor problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4080</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4080</id><created>2012-02-18</created><authors><author><keyname>Dosa</keyname><forenames>Gyorgy</forenames></author><author><keyname>Epstein</keyname><forenames>Leah</forenames></author></authors><title>Generalized selfish bin packing</title><categories>cs.GT cs.DS</categories><msc-class>91A99, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard bin packing is the problem of partitioning a set of items with
positive sizes no larger than 1 into a minimum number of subsets (called bins)
each having a total size of at most 1. In bin packing games, an item has a
positive weight, and given a valid packing or partition of the items, each item
has a cost or a payoff associated with it. We study a class of bin packing
games where the payoff of an item is the ratio between its weight and the total
weight of items packed with it, that is, the cost sharing is based linearly on
the weights of items. We study several types of pure Nash equilibria: standard
Nash equilibria, strong equilibria, strictly Pareto optimal equilibria, and
weakly Pareto optimal equilibria. We show that any game of this class admits
all these types of equilibria. We study the (asymptotic) prices of anarchy and
stability (PoA and PoS) of the problem with respect to these four types of
equilibria, for the two cases of general weights and of unit weights. We show
that while the case of general weights is strongly related to the well-known
First Fit algorithm, and all the four PoA values are equal to 1.7, this is not
true for unit weights. In particular, we show that all of them are strictly
below 1.7, the strong PoA is equal to approximately 1.691 (another well-known
number in bin packing) while the strictly Pareto optimal PoA is much lower. We
show that all the PoS values are equal to 1, except for those of strong
equilibria, which is equal to 1.7 for general weights, and to approximately
1.611824 for unit weights. This last value is not known to be the (asymptotic)
approximation ratio of any well-known algorithm for bin packing. Finally, we
study convergence to equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4087</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4087</id><created>2012-02-18</created><authors><author><keyname>Saumell-Mendiola</keyname><forenames>Anna</forenames></author><author><keyname>Serrano</keyname><forenames>M. &#xc1;ngeles</forenames></author><author><keyname>Bogu&#xf1;&#xe1;</keyname><forenames>Mari&#xe1;n</forenames></author></authors><title>Epidemic spreading on interconnected networks</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><doi>10.1103/PhysRevE.86.026106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real networks are not isolated from each other but form networks of
networks, often interrelated in non trivial ways. Here, we analyze an epidemic
spreading process taking place on top of two interconnected complex networks.
We develop a heterogeneous mean field approach that allows us to calculate the
conditions for the emergence of an endemic state. Interestingly, a global
endemic state may arise in the coupled system even though the epidemics is not
able to propagate on each network separately, and even when the number of
coupling connections is small. Our analytic results are successfully confronted
against large-scale numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4098</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4098</id><created>2012-02-18</created><updated>2012-05-21</updated><authors><author><keyname>Liu</keyname><forenames>Xi</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>Energy-Efficient Sensing and Communication of Parallel Gaussian Sources</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency is a key requirement in the design of wireless sensor
networks. While most theoretical studies only account for the energy
requirements of communication, the sensing process, which includes measurements
and compression, can also consume comparable energy. In this paper, the problem
of sensing and communicating parallel sources is studied by accounting for the
cost of both communication and sensing. In the first formulation of the
problem, the sensor has a separate energy budget for sensing and a rate budget
for communication, while, in the second, it has a single energy budget for both
tasks. Assuming that sources with larger variances have lower sensing costs,
the optimal allocation of sensing energy and rate that minimizes the overall
distortion is derived for the first problem. Moreover, structural results on
the solution of the second problem are derived under the assumption that the
sources with larger variances are transmitted on channels with lower noise.
Closed-form solutions are also obtained for the case where the energy budget is
sufficiently large. For an arbitrary order on the variances and costs, the
optimal solution to the first problem is also obtained numerically and compared
with several suboptimal strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4099</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4099</id><created>2012-02-18</created><authors><author><keyname>Belouadha</keyname><forenames>Fatima-Zahra</forenames></author><author><keyname>Omrana</keyname><forenames>Hajar</forenames></author><author><keyname>Roudi&#xe8;s</keyname><forenames>Ounsa</forenames></author></authors><title>Web Services-Enhanced Agile Modeling and Integrating Business Processes</title><categories>cs.SE</categories><comments>26 pages, 9 figures, Book chapter</comments><journal-ref>Book: E-Business - Applications and Global Ac ceptance ; ISBN
  978-953-51-0081-2; Edited by: Princely Ifinedo; Publisher: InTech, February
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a global business context with continuous changes, the enterprises have to
enhance their operational efficiency, to react more quickly, to ensure the
flexibility of their business processes, and to build new collaboration
pathways with external partners. To achieve this goal, they must use e-business
methods, mechanisms and techniques while capitalizing on the potential of new
information and communication technologies. In this context, we propose a
standards, model and Web services-based approach for modeling and integrating
agile enterprise business processes. The purpose is to benefit from Web
services characteristics to enhance the processes design and realize their
dynamic integration. The choice of focusing on Web services is essentially
justified by their broad adoption by enterprises as well as their capability to
warranty interoperability between both intra and inter-enterprises systems.
Thereby, we propose in this chapter a metamodel for describing business
processes, and discuss their dynamic integration by addressing the Web services
discovery issue. On the one hand, the proposed metamodel is in line with the
W3C Web services standards, namely, WSDL, SAWSDL and WS-Policy. It considers
the use of BPMN standard to describe the behavioral aspect of business
processes and completes their design using UML diagrams describing their
functional, non-functional and semantic aspects. On other hand, our approach
for integrating processes is in line with BPEL standard recommended to
orchestrate Web services. To realize executable business processes, this
approach recommends the use of semantic matching and selection mechanisms in
order to produce agile systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4107</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4107</id><created>2012-02-18</created><authors><author><keyname>Hale</keyname><forenames>Scott A.</forenames></author></authors><title>Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin
  Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition
  of Whale Images on a Network)</title><categories>cs.CV</categories><acm-class>I.4.6; H.5.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  At least two software packages---DARWIN, Eckerd College, and FinScan, Texas
A&amp;M---exist to facilitate the identification of cetaceans---whales, dolphins,
porpoises---based upon the naturally occurring features along the edges of
their dorsal fins. Such identification is useful for biological studies of
population, social interaction, migration, etc. The process whereby fin
outlines are extracted in current fin-recognition software packages is manually
intensive and represents a major user input bottleneck: it is both time
consuming and visually fatiguing. This research aims to develop automated
methods (employing unsupervised thresholding and morphological processing
techniques) to extract cetacean dorsal fin outlines from digital photographs
thereby reducing manual user input. Ideally, automatic outline generation will
improve the overall user experience and improve the ability of the software to
correctly identify cetaceans. Various transformations from color to gray space
were examined to determine which produced a grayscale image in which a suitable
threshold could be easily identified. To assist with unsupervised thresholding,
a new metric was developed to evaluate the jaggedness of figures (&quot;pixelarity&quot;)
in an image after thresholding. The metric indicates how cleanly a threshold
segments background and foreground elements and hence provides a good measure
of the quality of a given threshold. This research results in successful
extractions in roughly 93% of images, and significantly reduces user-input
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4116</identifier>
 <datestamp>2014-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4116</id><created>2012-02-18</created><updated>2014-01-14</updated><authors><author><keyname>Eisentraut</keyname><forenames>Christian</forenames></author><author><keyname>Godskesen</keyname><forenames>Jens Chr.</forenames></author><author><keyname>Hermanns</keyname><forenames>Holger</forenames></author><author><keyname>Song</keyname><forenames>Lei</forenames></author><author><keyname>Zhang</keyname><forenames>Lijun</forenames></author></authors><title>Late Weak Bisimulation for Markov Automata</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weak bisimilarity is a distribution-based equivalence notion for Markov
automata. It has gained some popularity as the coarsest reasonable behavioural
equivalence on Markov automata. This paper studies a strictly coarser notion:
Late weak bisimilarity enjoys valuable properties if restricting to important
subclasses of schedulers: Trace distribution equivalence is implied for partial
information schedulers, and compositionality is preserved by distributed
schedulers. The intersection of the two scheduler classes thus spans a coarser
and still reasonable compositional theory of Markov automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4128</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4128</id><created>2012-02-19</created><authors><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Khan</keyname><forenames>U.</forenames></author><author><keyname>Djouani</keyname><forenames>K.</forenames></author></authors><title>Evaluating Wireless Proactive Routing Protocols under Scalability and
  Traffic Constraints</title><categories>cs.NI</categories><comments>48th ICC-AHSN, 2012; Ottawa Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we evaluate and analyze the impact of different network loads
and varying no. of nodes on distance vector and link state routing algorithms.
We select three well known proactive protocols; Destination Sequenced Distance
Vector (DSDV) operates on distance vector routing, while Fisheye State Routing
(FSR) and Optimized Link State Routing (OLSR) protocols are based on link state
routing. Further, we evaluate and compare the effects on the performance of
protocols by changing the routing strategies of routing algorithms. We also
enhance selected protocols to achieve high performance. We take throughput,
End-to-End Delay (E2ED) and Normalized Routing Load (NRL) as performance
metrics for evaluation and comparison of chosen protocols both with default and
enhanced versions. Based upon extensive simulations in NS-2, we compare and
discuss performance trade-offs of the protocols, i.e., how a protocol achieves
high packet delivery by paying some cost in the form of increased E2ED and/or
routing overhead. FSR due to scope routing technique performs well in high data
rates, while, OLSR is more scalable in denser networks due to limited
retransmissions through Multi-Point Relays (MPRs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4133</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4133</id><created>2012-02-19</created><updated>2012-05-07</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>McCall's Area Transformation versus the Integrated Impact Indicator (I3)</title><categories>cs.DL</categories><comments>Letter to the Editor of the Journal of Informetrics in reaction to:
  Mutz, R., &amp; Daniel, H.-D. (2012). Skewed Citation Distributions and Bias
  Factors: Solutions to two core problems with the journal impact factor.
  Journal of Informetrics 6(2), 169-174</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a study entitled &quot;Skewed Citation Distributions and Bias Factors:
Solutions to two core problems with the journal impact factor,&quot; Mutz &amp; Daniel
(2012) propose (i) McCall's (1922) Area Transformation of the skewed citation
distribution so that this data can be considered as normally distributed (Krus
&amp; Kennedy, 1977), and (ii) to control for different document types as a
co-variate (Rubin, 1977). This approach provides an alternative to Leydesdorff
&amp; Bornmann's (2011) Integrated Impact Indicator (I3). As the authors note, the
two approaches are akin.
  Can something be said about the relative quality of the two approaches? To
that end, I replicated the study of Mutz &amp; Daniel for the 11 journals in the
Subject Category &quot;mathematical psychology,&quot; but using additionally I3 on the
basis of continuous quantiles (Leydesdorff &amp; Bornmann, in press) and its
variant PR6 based on the six percentile rank classes distinguished by Bornmann
&amp; Mutz (2011) as follows: the top-1%, 95-99%, 90-95%, 75-90%, 50-75%, and
bottom-50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4134</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4134</id><created>2012-02-19</created><authors><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Thain</keyname><forenames>Nithum</forenames></author><author><keyname>Vetta</keyname><forenames>Adrian</forenames></author></authors><title>On the Implications of Lookahead Search in Game Playing</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lookahead search is perhaps the most natural and widely used game playing
strategy. Given the practical importance of the method, the aim of this paper
is to provide a theoretical performance examination of lookahead search in a
wide variety of applications.
  To determine a strategy play using lookahead search}, each agent predicts
multiple levels of possible re-actions to her move (via the use of a search
tree), and then chooses the play that optimizes her future payoff accounting
for these re-actions. There are several choices of optimization function the
agents can choose, where the most appropriate choice of function will depend on
the specifics of the actual game - we illustrate this in our examples.
Furthermore, the type of search tree chosen by computationally-constrained
agent can vary. We focus on the case where agents can evaluate only a bounded
number, $k$, of moves into the future. That is, we use depth $k$ search trees
and call this approach {\em k-lookahead search}.
  We apply our method in five well-known settings: AdWord auctions; industrial
organization (Cournot's model); congestion games; valid-utility games and
basic-utility games; cost-sharing network design games. We consider two
questions. First, what is the expected social quality of outcome when agents
apply lookahead search? Second, what interactive behaviours can be exhibited
when players use lookahead search?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4137</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4137</id><created>2012-02-19</created><authors><author><keyname>Ahmed</keyname><forenames>Syed Hassan</forenames></author><author><keyname>Bouk</keyname><forenames>Safdar H.</forenames></author><author><keyname>Mehmood</keyname><forenames>Amjad</forenames></author><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Iwao</keyname><forenames>Sasase</forenames></author></authors><title>Effect of Fast Moving Object on RSSI in WSN: An Experimental Approach</title><categories>cs.NI</categories><comments>IMTIC 2012 conference, published in Communications in Computer and
  Information Science (CCIS) series by Springer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we experimentally investigate the effect of fast moving object
on the RSSI in the wireless sensor networks in presence of the ground effect
and antenna orientation in elevation direction. In experimental setup, MICAz
mote pair was placed on the ground, where one mote acts as a transmitter and
the other as a receiver. The trans- mitter mote's antenna was oriented in
elevation direction with respect to the receiver mote's antenna. The fast
moving object i.e. car, was passed between the motes and the fluctuations in
the RSSI are observed. The experimental results show some sequential pattern in
RSSI fluctuations when car moves at some relatively slow speed. However, some
irregu- larities were also observed when antenna was oriented at 45 and 90 in
elevation direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4140</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4140</id><created>2012-02-19</created><updated>2012-07-01</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Chmelik</keyname><forenames>Martin</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>Equivalence of Games with Probabilistic Uncertainty and
  Partial-observation Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce games with probabilistic uncertainty, a natural model for
controller synthesis in which the controller observes the state of the system
through imprecise sensors that provide correct information about the current
state with a fixed probability. That is, in each step, the sensors return an
observed state, and given the observed state, there is a probability
distribution (due to the estimation error) over the actual current state. The
controller must base its decision on the observed state (rather than the actual
current state, which it does not know). On the other hand, we assume that the
environment can perfectly observe the current state. We show that our model can
be reduced in polynomial time to standard partial-observation stochastic games,
and vice-versa. As a consequence we establish the precise decidability frontier
for the new class of games, and for most of the decidable problems establish
optimal complexity results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4144</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4144</id><created>2012-02-19</created><authors><author><keyname>Neto</keyname><forenames>Adolfo</forenames></author><author><keyname>Kaestner</keyname><forenames>Celso A. A.</forenames></author><author><keyname>Finger</keyname><forenames>Marcelo</forenames></author></authors><title>Towards an efficient prover for the C1 paraconsistent logic</title><categories>cs.LO cs.AI</categories><comments>16 pages</comments><journal-ref>Electronic Notes in Theoretical Computer Science. Volume 256, 2
  December 2009, Pages 87-102. Proceedings of the Fourth Workshop on Logical
  and Semantic Frameworks, with Applications (LSFA 2009)</journal-ref><doi>10.1016/j.entcs.2009.11.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The KE inference system is a tableau method developed by Marco Mondadori
which was presented as an improvement, in the computational efficiency sense,
over Analytic Tableaux. In the literature, there is no description of a theorem
prover based on the KE method for the C1 paraconsistent logic. Paraconsistent
logics have several applications, such as in robot control and medicine. These
applications could benefit from the existence of such a prover. We present a
sound and complete KE system for C1, an informal specification of a strategy
for the C1 prover as well as problem families that can be used to evaluate
provers for C1. The C1 KE system and the strategy described in this paper will
be used to implement a KE based prover for C1, which will be useful for those
who study and apply paraconsistent logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4146</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4146</id><created>2012-02-19</created><authors><author><keyname>Abu-Affash</keyname><forenames>A. Karim</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Katz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Trabelsi</keyname><forenames>Yohai</forenames></author></authors><title>Bottleneck Non-Crossing Matching in the Plane</title><categories>cs.CG</categories><comments>17 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of $2n$ points in the plane, and let $M_{\rm C}$ (resp.,
$M_{\rm NC}$) denote a bottleneck matching (resp., a bottleneck non-crossing
matching) of $P$. We study the problem of computing $M_{\rm NC}$. We first
prove that the problem is NP-hard and does not admit a PTAS. Then, we present
an $O(n^{1.5}\log^{0.5} n)$-time algorithm that computes a non-crossing
matching $M$ of $P$, such that $bn(M) \le 2\sqrt{10} \cdot bn(M_{\rm NC})$,
where $bn(M)$ is the length of a longest edge in $M$. An interesting
implication of our construction is that $bn(M_{\rm NC})/bn(M_{\rm C}) \le
2\sqrt{10}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4149</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4149</id><created>2012-02-19</created><authors><author><keyname>Huang</keyname><forenames>WenQi</forenames></author><author><keyname>Yu</keyname><forenames>Liang</forenames></author></authors><title>Serial Symmetrical Relocation Algorithm for the Equal Sphere Packing
  Problem</title><categories>cs.DM</categories><comments>19 pages, 3 figures, it was conjectured that a sphere of radius 5 can
  contain at most 67 spheres of radius 1. Now 68 sphere of radius 1 can be
  packed in it (https://oeis.org/A084828)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For dealing with the equal sphere packing problem, we propose a serial
symmetrical relocation algorithm, which is effective in terms of the quality of
the numerical results. We have densely packed up to 200 equal spheres in
spherical container and up to 150 equal spheres in cube container. All results
are rigorous because of a fake sphere trick. It was conjectured impossible to
pack 68 equal spheres of radius 1 into a sphere of radius 5. The serial
symmetrical relocation algorithm has proven wrong this conjecture by finding
one such packing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4160</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4160</id><created>2012-02-19</created><updated>2014-11-02</updated><authors><author><keyname>Gurski</keyname><forenames>Frank</forenames></author><author><keyname>Poullie</keyname><forenames>Patrick Gwydion</forenames></author></authors><title>Interval Routing Schemes for Circular-Arc Graphs</title><categories>cs.DS cs.DM</categories><comments>18 pages</comments><msc-class>05C78, 05C38, 05C20, 68P30</msc-class><acm-class>E.1; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interval routing is a space efficient method to realize a distributed routing
function. In this paper we show that every circular-arc graph allows a shortest
path strict 2-interval routing scheme, i.e., by introducing a global order on
the vertices and assigning at most two (strict) intervals in this order to the
ends of every edge allows to depict a routing function that implies exclusively
shortest paths. Since circular-arc graphs do not allow shortest path 1-interval
routing schemes in general, the result implies that the class of circular-arc
graphs has strict compactness 2, which was a hitherto open question.
Additionally, we show that the constructed 2-interval routing scheme is a
1-interval routing scheme with at most one additional interval assigned at each
vertex and we an outline algorithm to calculate the routing scheme for
circular-arc graphs in O(c+n^2) time, where n is the number of vertices and c
is the number of maximal cliques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4170</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4170</id><created>2012-02-19</created><authors><author><keyname>Kozyrev</keyname><forenames>S. V.</forenames></author></authors><title>Classification by Ensembles of Neural Networks</title><categories>cs.NE cond-mat.dis-nn</categories><comments>8 pages, LaTeX</comments><journal-ref>p-Adic Numbers, Ultrametric Analysis and Applications, 2012, Vol.
  4, No. 1, pp. 27-33</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new procedure for training of artificial neural networks by
using the approximation of an objective function by arithmetic mean of an
ensemble of selected randomly generated neural networks, and apply this
procedure to the classification (or pattern recognition) problem. This approach
differs from the standard one based on the optimization theory. In particular,
any neural network from the mentioned ensemble may not be an approximation of
the objective function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4174</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4174</id><created>2012-02-19</created><authors><author><keyname>Mahran</keyname><forenames>Ahmed M.</forenames></author></authors><title>Perception Lie Paradox: Mathematically Proved Uncertainty about Humans
  Perception Similarity</title><categories>q-bio.NC cs.AI</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agents' judgment depends on perception and previous knowledge. Assuming that
previous knowledge depends on perception, we can say that judgment depends on
perception. So, if judgment depends on perception, can agents judge that they
have the same perception? In few words, this is the addressed paradox through
this document. While illustrating on the paradox, it's found that to reach
agreement in communication, it's not necessary for parties to have the same
perception however the necessity is to have perception correspondence. The
attempted solution to this paradox reveals a potential uncertainty in judging
the matter thus supporting the skeptical view of the problem. Moreover,
relating perception to intelligence, the same uncertainty is inherited by
judging the level of intelligence of an agent compared to others not
necessarily from the same kind (e.g. machine intelligence compared to human
intelligence). Using a proposed simple mathematical model for perception and
action, a tool is developed to construct scenarios, and the problem is
addressed mathematically such that conclusions are drawn systematically based
on mathematically defined properties. When it comes to formalization,
philosophical arguments and views become more visible and explicit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4175</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4175</id><created>2012-02-19</created><updated>2014-11-19</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Joglekar</keyname><forenames>Manas</forenames></author><author><keyname>Shah</keyname><forenames>Nisarg</forenames></author></authors><title>Average Case Analysis of the Classical Algorithm for Markov Decision
  Processes with B\&quot;uchi Objectives</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Markov decision processes (MDPs) with $\omega$-regular
specifications given as parity objectives. We consider the problem of computing
the set of almost-sure winning vertices from where the objective can be ensured
with probability 1. The algorithms for the computation of the almost-sure
winning set for parity objectives iteratively use the solutions for the
almost-sure winning set for B\&quot;uchi objectives (a special case of parity
objectives). We study for the first time the average case complexity of the
classical algorithm for computing almost-sure winning vertices for MDPs with
B\&quot;uchi objectives. Our contributions are as follows: First, we show that for
MDPs with constant out-degree the expected number of iterations is at most
logarithmic and the average case running time is linear (as compared to the
worst case linear number of iterations and quadratic time complexity). Second,
we show that for general MDPs the expected number of iterations is constant and
the average case running time is linear (again as compared to the worst case
linear number of iterations and quadratic time complexity). Finally we also
show that given all graphs are equally likely, the probability that the
classical algorithm requires more than constant number of iterations is
exponentially small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4177</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4177</id><created>2012-02-19</created><updated>2015-02-03</updated><authors><author><keyname>Schulte</keyname><forenames>Phillip J.</forenames></author><author><keyname>Tsiatis</keyname><forenames>Anastasios A.</forenames></author><author><keyname>Laber</keyname><forenames>Eric B.</forenames></author><author><keyname>Davidian</keyname><forenames>Marie</forenames></author></authors><title>$Q$- and $A$-Learning Methods for Estimating Optimal Dynamic Treatment
  Regimes</title><categories>stat.ME cs.AI</categories><comments>Published in at http://dx.doi.org/10.1214/13-STS450 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS450</report-no><journal-ref>Statistical Science 2014, Vol. 29, No. 4, 640-661</journal-ref><doi>10.1214/13-STS450</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In clinical practice, physicians make a series of treatment decisions over
the course of a patient's disease based on his/her baseline and evolving
characteristics. A dynamic treatment regime is a set of sequential decision
rules that operationalizes this process. Each rule corresponds to a decision
point and dictates the next treatment action based on the accrued information.
Using existing data, a key goal is estimating the optimal regime, that, if
followed by the patient population, would yield the most favorable outcome on
average. Q- and A-learning are two main approaches for this purpose. We provide
a detailed account of these methods, study their performance, and illustrate
them using data from a depression study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4180</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4180</id><created>2012-02-19</created><authors><author><keyname>Khoozani</keyname><forenames>M. Heidari</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author><author><keyname>Azghani</keyname><forenames>E.</forenames></author><author><keyname>Ghassemian</keyname><forenames>M.</forenames></author></authors><title>On Finding Sub-optimum Signature Matrices for Overloaded CDMA Systems</title><categories>cs.IT math.IT</categories><comments>9 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to design optimal signature matrices for
binary inputs. For the determination of such optimal codes, we need certain
measures as objective functions. The sum-channel capacity and Bit Error Rate
(BER) measures are typical methods for the evaluation of signature matrices. In
this paper, in addition to these measures, we use distance criteria to evaluate
the optimality of signature matrices. The Genetic Algorithm (GA) and Particle
Swarm Optimization (PSO) are used to search the optimum signature matrices
based on these three measures (Sum channel capacity, BER and Distance). Since
the GA and PSO algorithms become computationally expensive for large signature
matrices, we propose suboptimal large signature matrices that can be derived
from small suboptimal matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4185</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4185</id><created>2012-02-19</created><authors><author><keyname>Cartledge</keyname><forenames>Charles L.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>When Should I Make Preservation Copies of Myself?</title><categories>cs.DL cs.DC</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how different preservation policies ranging from least
aggressive to Most aggressive affect the level of preservation achieved by
autonomic processes used by smart digital objects (DOs). The mechanisms used to
support preservation across different hosts can be used for automatic link
generation and support preservation activities by moving data preservation from
an archive centric perspective to a data centric preservation. Based on
simulations of small-world graphs of DOs created using the Unsupervised
Small-World algorithm, we report quantitative and qualitative results for
graphs ranging in size from 10 to 5000 DOs. Our results show that a Most
aggressive preservation policy makes the best use of distributed host resources
while using one half of the number of messages of a Moderately aggressive
preservation policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4190</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4190</id><created>2012-02-19</created><authors><author><keyname>Lin</keyname><forenames>Feng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author><author><keyname>Hu</keyname><forenames>Zhen</forenames></author><author><keyname>Hou</keyname><forenames>Shujie</forenames></author><author><keyname>Browning</keyname><forenames>James P.</forenames></author><author><keyname>Wicks</keyname><forenames>Michael C.</forenames></author></authors><title>Generalized FMD Detection for Spectrum Sensing Under Low Signal-to-Noise
  Ratio</title><categories>cs.AI</categories><comments>4 pages, 1 figure, 1 table</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Spectrum sensing is a fundamental problem in cognitive radio. We propose a
function of covariance matrix based detection algorithm for spectrum sensing in
cognitive radio network. Monotonically increasing property of function of
matrix involving trace operation is utilized as the cornerstone for this
algorithm. The advantage of proposed algorithm is it works under extremely low
signal-to-noise ratio, like lower than -30 dB with limited sample data.
Theoretical analysis of threshold setting for the algorithm is discussed. A
performance comparison between the proposed algorithm and other
state-of-the-art methods is provided, by the simulation on captured digital
television (DTV) signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4193</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4193</id><created>2012-02-19</created><updated>2012-05-13</updated><authors><author><keyname>Kikot</keyname><forenames>Stanislav</forenames></author><author><keyname>Kontchakov</keyname><forenames>Roman</forenames></author><author><keyname>Podolskii</keyname><forenames>Vladimir</forenames></author><author><keyname>Zakharyaschev</keyname><forenames>Michael</forenames></author></authors><title>Exponential Lower Bounds and Separation for Query Rewriting</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish connections between the size of circuits and formulas computing
monotone Boolean functions and the size of first-order and nonrecursive Datalog
rewritings for conjunctive queries over OWL 2 QL ontologies. We use known lower
bounds and separation results from circuit complexity to prove similar results
for the size of rewritings that do not use non-signature constants. For
example, we show that, in the worst case, positive existential and nonrecursive
Datalog rewritings are exponentially longer than the original queries;
nonrecursive Datalog rewritings are in general exponentially more succinct than
positive existential rewritings; while first-order rewritings can be
superpolynomially more succinct than positive existential rewritings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4207</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4207</id><created>2012-02-19</created><updated>2012-02-21</updated><authors><author><keyname>Yang</keyname><forenames>Meng</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Zhang</keyname><forenames>David</forenames></author></authors><title>Regularized Robust Coding for Face Recognition</title><categories>cs.CV</categories><doi>10.1109/TIP.2012.2235849</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recently the sparse representation based classification (SRC) has been
proposed for robust face recognition (FR). In SRC, the testing image is coded
as a sparse linear combination of the training samples, and the representation
fidelity is measured by the l2-norm or l1-norm of the coding residual. Such a
sparse coding model assumes that the coding residual follows Gaussian or
Laplacian distribution, which may not be effective enough to describe the
coding residual in practical FR systems. Meanwhile, the sparsity constraint on
the coding coefficients makes SRC's computational cost very high. In this
paper, we propose a new face coding model, namely regularized robust coding
(RRC), which could robustly regress a given signal with regularized regression
coefficients. By assuming that the coding residual and the coding coefficient
are respectively independent and identically distributed, the RRC seeks for a
maximum a posterior solution of the coding problem. An iteratively reweighted
regularized robust coding (IR3C) algorithm is proposed to solve the RRC model
efficiently. Extensive experiments on representative face databases demonstrate
that the RRC is much more effective and efficient than state-of-the-art sparse
representation based methods in dealing with face occlusion, corruption,
lighting and expression changes, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4212</identifier>
 <datestamp>2014-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4212</id><created>2012-02-19</created><updated>2014-06-09</updated><authors><author><keyname>Wilkerson</keyname><forenames>Daniel Shawcross</forenames></author></authors><title>Harmony Explained: Progress Towards A Scientific Theory of Music</title><categories>cs.SD</categories><comments>Say more directly that theory of Helmholtz implies harmony would not
  exist as a phenomenon at all. Elaborate on the mythical &quot;undertones&quot; red
  herring, saying it arises from the visual metaphor. Replace &quot;sustained&quot; with
  &quot;suspended&quot; as the term for chord of two interlocked fifths; point out that
  the metaphor originating the term &quot;suspended&quot; is a red herring. Thank some
  readers for their feedback</comments><acm-class>I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most music theory books are like medieval medical textbooks: they contain
unjustified superstition, non-reasoning, and funny symbols glorified by Latin
phrases. How does music, in particular harmony, actually work, presented as a
real, scientific theory of music?
  The core to our approach is to consider not only the Physical phenomena of
nature but also the Computational phenomena of any machine that must make sense
of sound, such as the human brain. In particular we derive the following three
fundamental phenomena of music:
  * the Major Scale,
  * the Standard Chord Dictionary, and
  * the difference in feeling between the Major and Minor Triads.
  While the Major Scale has been independently derived before by others in a
similar manner [Helmholtz1863, Birkhoff1933], I believe the derivation of the
Standard Chord Dictionary as well as the difference in feeling between the
Major and Minor Triads to be original.
  We show to be incomplete the theory of the heretofore agreed-upon authority
on this subject, 19th-century Physicist Hermann Helmholtz [Helmholtz1863]: he
says notes are in &quot;concord&quot; because the sound playing them together is &quot;less
worse&quot; than that of some other notes. But note that, in this theory, more notes
can only penalize, some merely less than others, and so the most harmonious
sound should be a single note by itself(!) and harmony would not exist as a
phenomenon of music at all.
  I intend this article to be satisfying to scientists as an original
contribution to science and art, yet I also intend it to be approachable by
musicians and other curious members of the general public who may have long
wondered at the curious properties of tonal music and been frustrated by the
lack of satisfying, readable exposition on the subject. Therefore I have
written in a deliberately plain and conversational style, avoiding
unnecessarily formal language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4229</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4229</id><created>2012-02-20</created><authors><author><keyname>Reich</keyname><forenames>Johannes</forenames><affiliation>SAP</affiliation></author><author><keyname>Finkbeiner</keyname><forenames>Bernd</forenames><affiliation>Universit&#xe4;t des Saarlandes</affiliation></author></authors><title>Proceedings Second International Workshop on Interactions, Games and
  Protocols</title><categories>cs.GT cs.DC</categories><comments>EPTCS 78, 2012</comments><proxy>EPTCS</proxy><doi>10.4204/EPTCS.78</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the second International Workshop on
Interactions, Games and Protocols (IWIGP 2012). The workshop was held in
Tallinn on March 25, 2012, as a satellite event of ETAPS 2012. The previous
workshop took place in Saarbr\&quot;ucken as part of ETAPS 2011.
  The goal of this workshop was to bring researchers from industry and academia
together and to explore how a better understanding of the interrelation between
interactions, games and protocols leads to better-designed and more reliable
interacting systems. We invited scientific contributions both from a
theoretical and a practical perspective.
  The program consisted of two invited talks and four refereed papers, selected
by a strong program committee of international reputation. The refereed papers
are contained in this volume.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4232</identifier>
 <datestamp>2015-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4232</id><created>2012-02-20</created><updated>2012-03-27</updated><authors><author><keyname>Fang</keyname><forenames>Chung-Chieh</forenames></author></authors><title>Boundary Conditions of Subharmonic Oscillations in
  Fixed-Switching-Frequency DC-DC Converters</title><categories>cs.SY math.DS nlin.CD</categories><comments>Title changed. Submitted to a journal on 2/24/11, and resubmitted to
  IJCTA on 8/10/11. Added: S-plot to determine the required ramp slope, V2
  control, a counterexample (Example 5) of the ripple index hypothesis. The key
  results traced back from my 1997 PhD thesis, available:
  http://www.lib.umd.edu/drum/. My five IJCTA papers in arXiv have two common
  reviewers</comments><journal-ref>Nonlinear Dynamics, 77(1-2), pp. 185-208, Jul. 2014</journal-ref><doi>10.1007/s11071-014-1283-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Design-oriented boundary conditions for subharmonic oscillations are of great
interest recently. Based on a subharmonic oscillation boundary condition
reported in a PhD thesis more than a decade ago, extended new boundary
conditions are derived in closed forms for general switching DC-DC converters.
Sampled-data and harmonic balance analyses are applied and generate equivalent
results. It is shown that equivalent series resistance causes the boundary
conditions for voltage/current mode control to have similar forms. Some
recently reported boundary conditions become special cases in view of the
general boundary conditions derived. New Nyquist-like design-oriented plots are
proposed to predict or prevent the occurrence of the subharmonic oscillation.
The relation between the crossover frequency and the subharmonic oscillation is
also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4237</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4237</id><created>2012-02-20</created><authors><author><keyname>Zhao</keyname><forenames>Qiyang</forenames></author></authors><title>A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP</title><categories>cs.CV</categories><comments>Submitted to IEEE SPL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Color image segmentation is an important topic in the image processing field.
MRF-MAP is often adopted in the unsupervised segmentation methods, but their
performance are far behind recent interactive segmentation tools supervised by
user inputs. Furthermore, the existing related unsupervised methods also suffer
from the low efficiency, and high risk of being trapped in the local optima,
because MRF-MAP is currently solved by iterative frameworks with inaccurate
initial color distribution models. To address these problems, the letter
designs an efficient method to calculate the energy functions approximately in
the non-iteration style, and proposes a new binary segmentation algorithm based
on the slightly tuned Lanczos eigensolver. The experiments demonstrate that the
new algorithm achieves competitive performance compared with two state-of-art
segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4238</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4238</id><created>2012-02-20</created><authors><author><keyname>Vafopoulos</keyname><forenames>Michalis</forenames></author><author><keyname>Stefaneas</keyname><forenames>Petros</forenames></author><author><keyname>Anagnostopoulos</keyname><forenames>Ioannis</forenames></author><author><keyname>O'Hara</keyname><forenames>Kieron</forenames></author></authors><title>A methodology for internal Web ethics</title><categories>cs.CY</categories><msc-class>68M14, 68M11</msc-class><acm-class>K.4.1; H.3.5; C.2.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vigorous impact of the Web in time and space arises from the fact that it
motivates massive creation, editing and distribution of information by Users
with little knowledge. This unprecedented continuum provides novel
opportunities for innovation but also puts under jeopardy its survival as a
stable construct that nurtures a complex system of connections. We examine the
Web as an ethics determined space by demonstrating Hayek's theory of freedom in
a three-leveled Web: technological, contextualized and economic. Our approach
accounts for the co-dependence of code and values, and assumes that the Web is
a self-contained system that exists in and by itself. This view of internal Web
ethics directly connects the concept of freedom with issues like centralization
of traffic and data control, rights on visiting log file, custom User profiles
and the interplay among function, structure and morality of the Web. It is also
demonstrated, in the case of Net Neutrality, that generic freedom-coercion
trade-offs are incomplete in treating specific cases at work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4245</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4245</id><created>2012-02-20</created><authors><author><keyname>Mandal</keyname><forenames>J. K.</forenames></author></authors><title>A Frequency Domain Steganography using Z Transform (FDSZT)</title><categories>cs.CR cs.MM</categories><comments>4 pages, International Workshop on Embedded Computing and
  Communication System(IWECC 2011), Rajagiri School of Engineering &amp;
  Technology, 22-23 December 2011, Kochin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image steganography is art of hiding information onto the cover image. In
this proposal a transformed domain based gray scale image authentication/data
hiding technique using Z transform (ZT) termed as FDSZT, has been proposed.
ZTransform is applied on 2x2 masks of the source image in row major order to
transform original sub image (cover image) block to its corresponding frequency
domain. One bit of the hidden image is embedded in each mask of the source
image onto the fourth LSB of transformed coefficient based on median value of
the mask. A delicate handle has also been performed as post embedding operation
for proper decoding. Stego sub image is obtained through a reverse transform as
final step of embedding in a mask. During the process of embedding, dimension
of the hidden image followed by the content of the message/hidden image are
embedded. Reverse process is followed during decoding. High PSNR obtained for
various images conform the quality of invisible watermark of FDSZT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4261</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4261</id><created>2012-02-20</created><authors><author><keyname>Raza</keyname><forenames>Ali</forenames></author><author><keyname>Fernandez</keyname><forenames>Benito R.</forenames></author></authors><title>Immuno-inspired robotic applications: a review</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial immune systems primarily mimic the adaptive nature of biological
immune functions. Their ability to adapt to varying pathogens makes such
systems a suitable choice for various robotic applications. Generally,
AIS-based robotic applications map local instantaneous sensory information into
either an antigen or a co-stimulatory signal, according to the choice of
representation schema. Algorithms then use relevant immune functions to output
either evolved antibodies or maturity of dendritic cells, in terms of actuation
signals. It is observed that researchers, in an attempt to solve the problem in
hand, do not try to replicate the biological immunity but select necessary
immune functions instead, resulting in an ad-hoc manner these applications are
reported. Authors, therefore, present a comprehensive review of immuno-inspired
robotic applications in an attempt to categorize them according to underlying
immune definitions. Implementation details are tabulated in terms of
corresponding mathematical expressions and their representation schema that
include binary, real or hybrid data. Limitations of reported applications are
also identified in light of modern immunological interpretations. As a result
of this study, authors suggest a renewed focus on innate immunity and also
emphasize that immunological representations should benefit from robot
embodiment and must be extended to include modern trends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4269</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4269</id><created>2012-02-20</created><authors><author><keyname>Thielemann</keyname><forenames>Henning</forenames></author></authors><title>Live-Musikprogrammierung in Haskell</title><categories>cs.PL cs.SD</categories><comments>12 pages, 2 figures, 5. Arbeitstagung Programmiersprachen 2012,
  ATPS'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We aim to compose algorithmic music in an interactive way with multiple
participants. To this end we develop an interpreter for a sub-language of the
non-strict functional programming language Haskell that allows to modify the
program during its execution. Our system can be used both for musical
live-coding and for demonstration and education of functional programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4281</identifier>
 <datestamp>2014-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4281</id><created>2012-02-20</created><updated>2014-04-30</updated><authors><author><keyname>Ben-Amram</keyname><forenames>Amir M.</forenames></author><author><keyname>Vainer</keyname><forenames>Michael</forenames></author></authors><title>Bounded Termination of Monotonicity-Constraint Transition Systems</title><categories>cs.LO cs.FL</categories><comments>46 pages. Research has been presented at DICE 2011 (Saarbruecken,
  Germany, March 2011), 2FC 2011 (Novi Sad, Serbia, May 2011) and DANSAS
  (Odense, Denmark, August 2011). Revised (twice) to correct errors in previous
  versions</comments><acm-class>D.2.4; F.3.1; D.2.8; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intuitively, if we can prove that a program terminates, we expect some
conclusion regarding its complexity. But the passage from termination proofs to
complexity bounds is not always clear. In this work we consider Monotonicity
Constraint Transition Systems, a program abstraction where termination is
decidable (based on the size-change termination principle). We show that these
programs also have a decidable complexity property: one can determine whether
the length of all transition sequences can be bounded in terms of the initial
state. This is the Bounded Termination problem. Interestingly, if a bound
exists, it must be polynomial. We prove that the bounded termination problem is
PSPACE-complete.
  We also discuss, theoretically, the use of bounds on the abstract program to
infer conclusions on a concrete program that has been abstracted. The
conclusion maybe a polynomial time bound, or in other cases polynomial space or
exponential time. We argue that the monotonicity-constraint abstraction
promises to be useful for practical complexity analysis of programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4285</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4285</id><created>2012-02-20</created><updated>2012-09-04</updated><authors><author><keyname>Barbulescu</keyname><forenames>Razvan</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author><author><keyname>Bos</keyname><forenames>Joppe W.</forenames><affiliation>LACAL</affiliation></author><author><keyname>Bouvier</keyname><forenames>Cyril</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author><author><keyname>Kleinjung</keyname><forenames>Thorsten</forenames><affiliation>LACAL</affiliation></author><author><keyname>Montgomery</keyname><forenames>Peter L.</forenames></author></authors><title>Finding ECM-friendly curves through a study of Galois properties</title><categories>math.NT cs.CR</categories><proxy>ccsd</proxy><journal-ref>Algorithmic Number Theory Symposium (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove some divisibility properties of the cardinality of
elliptic curves modulo primes. These proofs explain the good behavior of
certain parameters when using Montgomery or Edwards curves in the setting of
the elliptic curve method (ECM) for integer factorization. The ideas of the
proofs help us to find new families of elliptic curves with good division
properties which increase the success probability of ECM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4301</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4301</id><created>2012-02-20</created><authors><author><keyname>Mittmann</keyname><forenames>Johannes</forenames></author><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author><author><keyname>Scheiblechner</keyname><forenames>Peter</forenames></author></authors><title>Algebraic Independence in Positive Characteristic -- A p-Adic Calculus</title><categories>cs.CC math.AC</categories><msc-class>12Y05 (Primary) 13N05, 14F30, 03D15, 68Q17, 68W30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set of multivariate polynomials, over a field of zero or large
characteristic, can be tested for algebraic independence by the well-known
Jacobian criterion. For fields of other characteristic p&gt;0, there is no
analogous characterization known. In this paper we give the first such
criterion. Essentially, it boils down to a non-degeneracy condition on a lift
of the Jacobian polynomial over (an unramified extension of) the ring of p-adic
integers.
  Our proof builds on the de Rham-Witt complex, which was invented by Illusie
(1979) for crystalline cohomology computations, and we deduce a natural
generalization of the Jacobian. This new avatar we call the Witt-Jacobian. In
essence, we show how to faithfully differentiate polynomials over F_p (i.e.
somehow avoid dx^p/dx=0) and thus capture algebraic independence.
  We apply the new criterion to put the problem of testing algebraic
independence in the complexity class NP^#P (previously best was PSPACE). Also,
we give a modest application to the problem of identity testing in algebraic
complexity theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4302</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4302</id><created>2012-02-20</created><authors><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>D&#xfc;rr</keyname><forenames>Christoph</forenames></author><author><keyname>Thang</keyname><forenames>Nguyen Kim</forenames></author></authors><title>Smooth Inequalities and Equilibrium Inefficiency in Scheduling Games</title><categories>cs.GT cs.DS</categories><comments>25 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study coordination mechanisms for Scheduling Games (with unrelated
machines). In these games, each job represents a player, who needs to choose a
machine for its execution, and intends to complete earliest possible. Our goal
is to design scheduling policies that always admit a pure Nash equilibrium and
guarantee a small price of anarchy for the l_k-norm social cost --- the
objective balances overall quality of service and fairness. We consider
policies with different amount of knowledge about jobs: non-clairvoyant,
strongly-local and local. The analysis relies on the smooth argument together
with adequate inequalities, called smooth inequalities. With this unified
framework, we are able to prove the following results.
  First, we study the inefficiency in l_k-norm social costs of a strongly-local
policy SPT and a non-clairvoyant policy EQUI. We show that the price of anarchy
of policy SPT is O(k). We also prove a lower bound of Omega(k/log k) for all
deterministic, non-preemptive, strongly-local and non-waiting policies
(non-waiting policies produce schedules without idle times). These results
ensure that SPT is close to optimal with respect to the class of l_k-norm
social costs. Moreover, we prove that the non-clairvoyant policy EQUI has price
of anarchy O(2^k).
  Second, we consider the makespan (l_infty-norm) social cost by making
connection within the l_k-norm functions. We revisit some local policies and
provide simpler, unified proofs from the framework's point of view. With the
highlight of the approach, we derive a local policy Balance. This policy
guarantees a price of anarchy of O(log m), which makes it the currently best
known policy among the anonymous local policies that always admit a pure Nash
equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4303</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4303</id><created>2012-02-20</created><authors><author><keyname>Bl&#xfc;mlein</keyname><forenames>J.</forenames></author><author><keyname>Hasselhuhn</keyname><forenames>A.</forenames></author><author><keyname>Schneider</keyname><forenames>C.</forenames></author></authors><title>Evaluation of Multi-Sums for Large Scale Problems</title><categories>math-ph cs.SC hep-th math.MP</categories><comments>9 pages Latex, Contr. Proc. RADCOR 2011</comments><report-no>DESY 10-247, DO-TH 12/06, SFB/CPP-12-13, LPN 12-038</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A big class of Feynman integrals, in particular, the coefficients of their
Laurent series expansion w.r.t.\ the dimension parameter $\ep$ can be
transformed to multi-sums over hypergeometric terms and harmonic sums. In this
article, we present a general summation method based on difference fields that
simplifies these multi--sums by transforming them from inside to outside to
representations in terms of indefinite nested sums and products. In particular,
we present techniques that assist in the task to simplify huge expressions of
such multi-sums in a completely automatic fashion. The ideas are illustrated on
new calculations coming from 3-loop topologies of gluonic massive operator
matrix elements containing two fermion lines, which contribute to the
transition matrix elements in the variable flavor scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4304</identifier>
 <datestamp>2012-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4304</id><created>2012-02-20</created><updated>2012-04-18</updated><authors><author><keyname>Lekeas</keyname><forenames>Paraskevas V.</forenames></author></authors><title>Should I quit using my resource? Modeling Resource Usage through Game
  Theory</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing web infrastructures have supported the publication of a tremendous
amount of resources, and over the past few years Data Resource Usage is an
everyday task for millions of users all over the world. In this work we model
Resource Usage as a Cooperative Cournot Game in which a resource user and the
various resource services are engaged. We give quantified answers as to when it
is of interest for the user to stop using part of a resource and to switch to a
different one. Moreover, we do the same from the perspective of a resource's
provider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4307</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4307</id><created>2012-02-20</created><authors><author><keyname>Lekeas</keyname><forenames>Paraskevas V.</forenames></author></authors><title>Coalitional Beliefs of Cournot Network Agents</title><categories>cs.GT cs.NI</categories><comments>Appendix with 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Network cooperative games, due to computational complexity issues, agents
are not able to base their behavior on the &quot;whole network status&quot; but have to
follow certain &quot;beliefs&quot; as to how it is in their strategic interest to act.
This behavior constitutes the main interest of this paper. To this end, we
quantify and characterize the set of beliefs that support cooperation of such
agents. Assuming that they are engaged in a differentiated Cournot competition
and that they equally split the worth produced, we characterize the set of
coalitional beliefs that support core non-emptiness and thus guarantee
stability of the Network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4326</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4326</id><created>2012-02-20</created><updated>2015-03-11</updated><authors><author><keyname>Emek</keyname><forenames>Yuval</forenames></author><author><keyname>Halldorsson</keyname><forenames>Magnus M.</forenames></author><author><keyname>Rosen</keyname><forenames>Adi</forenames></author></authors><title>Space-Constrained Interval Selection</title><categories>cs.DS</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study streaming algorithms for the interval selection problem: finding a
maximum cardinality subset of disjoint intervals on the line. A deterministic
2-approximation streaming algorithm for this problem is developed, together
with an algorithm for the special case of proper intervals, achieving improved
approximation ratio of 3/2. We complement these upper bounds by proving that
they are essentially best possible in the streaming setting: it is shown that
an approximation ratio of $2 - \epsilon$ (or $3 / 2 - \epsilon$ for proper
intervals) cannot be achieved unless the space is linear in the input size. In
passing, we also answer an open question of Adler and Azar \cite{AdlerAzar03}
regarding the space complexity of constant-competitive randomized preemptive
online algorithms for the same problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4329</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4329</id><created>2012-02-20</created><authors><author><keyname>Riccaboni</keyname><forenames>Massimo</forenames></author><author><keyname>Rossi</keyname><forenames>Alessandro</forenames></author><author><keyname>Schiavo</keyname><forenames>Stefano</forenames></author></authors><title>Global Networks of Trade and Bits</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>25 pages, 6 figures</comments><report-no>Discussion Paper 2011.8, Department of Economics, University of
  Trento</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considerable efforts have been made in recent years to produce detailed
topologies of the Internet. Although Internet topology data have been brought
to the attention of a wide and somewhat diverse audience of scholars, so far
they have been overlooked by economists. In this paper, we suggest that such
data could be effectively treated as a proxy to characterize the size of the
&quot;digital economy&quot; at country level and outsourcing: thus, we analyse the
topological structure of the network of trade in digital services (trade in
bits) and compare it with that of the more traditional flow of manufactured
goods across countries. To perform meaningful comparisons across networks with
different characteristics, we define a stochastic benchmark for the number of
connections among each country-pair, based on hypergeometric distribution.
Original data are thus filtered by means of different thresholds, so that we
only focus on the strongest links, i.e., statistically significant links. We
find that trade in bits displays a sparser and less hierarchical network
structure, which is more similar to trade in high-skill manufactured goods than
total trade. Lastly, distance plays a more prominent role in shaping the
network of international trade in physical goods than trade in digital
services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4331</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4331</id><created>2012-02-20</created><updated>2012-03-06</updated><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Strong Backdoors to Nested Satisfiability</title><categories>cs.DS cs.AI cs.CC math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knuth (1990) introduced the class of nested formulas and showed that their
satisfiability can be decided in polynomial time. We show that, parameterized
by the size of a smallest strong backdoor set to the target class of nested
formulas, checking the satisfiability of any CNF formula is fixed-parameter
tractable. Thus, for any k&gt;0, the satisfiability problem can be solved in
polynomial time for any formula F for which there exists a variable set B of
size at most k such that for every truth assignment t to B, the formula F[t] is
nested; moreover, the degree of the polynomial is independent of k.
  Our algorithm uses the grid-minor theorem of Robertson and Seymour (1986) to
either find that the incidence graph of the formula has bounded treewidth - a
case that is solved using model checking for monadic second order logic - or to
find many vertex-disjoint obstructions in the incidence graph. For the latter
case, new combinatorial arguments are used to find a small backdoor set.
Combining both cases leads to an approximation algorithm producing a strong
backdoor set whose size is upper bounded by a function of the optimum. Going
through all assignments to this set of variables and using Knuth's algorithm,
the satisfiability of the input formula is decided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4347</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4347</id><created>2012-02-20</created><authors><author><keyname>Ghorpade</keyname><forenames>Jayshree</forenames></author><author><keyname>Parande</keyname><forenames>Jitendra</forenames></author><author><keyname>Kulkarni</keyname><forenames>Madhura</forenames></author><author><keyname>Bawaskar</keyname><forenames>Amit</forenames></author></authors><title>GPGPU Processing in CUDA Architecture</title><categories>cs.DC</categories><comments>16 pages, 5 figures, Advanced Computing: an International Journal
  (ACIJ) 2012</comments><doi>10.5121/acij.2012.3109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future of computation is the Graphical Processing Unit, i.e. the GPU. The
promise that the graphics cards have shown in the field of image processing and
accelerated rendering of 3D scenes, and the computational capability that these
GPUs possess, they are developing into great parallel computing units. It is
quite simple to program a graphics processor to perform general parallel tasks.
But after understanding the various architectural aspects of the graphics
processor, it can be used to perform other taxing tasks as well. In this paper,
we will show how CUDA can fully utilize the tremendous power of these GPUs.
CUDA is NVIDIA's parallel computing architecture. It enables dramatic increases
in computing performance, by harnessing the power of the GPU. This paper talks
about CUDA and its architecture. It takes us through a comparison of CUDA C/C++
with other parallel programming languages like OpenCL and DirectCompute. The
paper also lists out the common myths about CUDA and how the future seems to be
promising for CUDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4361</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4361</id><created>2012-02-20</created><authors><author><keyname>Augot</keyname><forenames>Daniel</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Morain</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIX</affiliation></author></authors><title>Discrete logarithm computations over finite fields using Reed-Solomon
  codes</title><categories>math.NT cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cheng and Wan have related the decoding of Reed-Solomon codes to the
computation of discrete logarithms over finite fields, with the aim of proving
the hardness of their decoding. In this work, we experiment with solving the
discrete logarithm over GF(q^h) using Reed-Solomon decoding. For fixed h and q
going to infinity, we introduce an algorithm (RSDL) needing O (h! q^2)
operations over GF(q), operating on a q x q matrix with (h+2) q non-zero
coefficients. We give faster variants including an incremental version and
another one that uses auxiliary finite fields that need not be subfields of
GF(q^h); this variant is very practical for moderate values of q and h. We
include some numerical results of our first implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4366</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4366</id><created>2012-02-20</created><authors><author><keyname>Purdy</keyname><forenames>George</forenames></author></authors><title>The Secure Generation of RSA Moduli Using Poor RNG</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a procedure, which should be called Lenstra's fix, for producing
secure RSA moduli even when the random number generation is very poor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4372</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4372</id><created>2012-02-20</created><authors><author><keyname>Gaite</keyname><forenames>Jose</forenames></author><author><keyname>Fernandez-Rico</keyname><forenames>German</forenames></author></authors><title>Linear approach to the orbiting spacecraft thermal problem</title><categories>cs.CE cs.SY physics.class-ph</categories><comments>20 pages, 11 figures, accepted in Journal of Thermophysics and Heat
  Transfer</comments><msc-class>93C73 (Primary) 70J10, 34.04 (Secondary)</msc-class><acm-class>J.2</acm-class><journal-ref>J. of Thermophysics and Heat Transfer 26 (2012) 511-522</journal-ref><doi>10.2514/1.T3748</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a linear method for solving the nonlinear differential equations
of a lumped-parameter thermal model of a spacecraft moving in a closed orbit.
Our method, based on perturbation theory, is compared with heuristic
linearizations of the same equations. The essential feature of the linear
approach is that it provides a decomposition in thermal modes, like the
decomposition of mechanical vibrations in normal modes. The stationary periodic
solution of the linear equations can be alternately expressed as an explicit
integral or as a Fourier series. We apply our method to a minimal thermal model
of a satellite with ten isothermal parts (nodes) and we compare the method with
direct numerical integration of the nonlinear equations. We briefly study the
computational complexity of our method for general thermal models of orbiting
spacecraft and conclude that it is certainly useful for reduced models and
conceptual design but it can also be more efficient than the direct integration
of the equations for large models. The results of the Fourier series
computations for the ten-node satellite model show that the periodic solution
at the second perturbative order is sufficiently accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4375</identifier>
 <datestamp>2016-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4375</id><created>2012-02-20</created><updated>2016-01-21</updated><authors><author><keyname>Esfahani</keyname><forenames>Peyman Mohajerin</forenames></author><author><keyname>Chatterjee</keyname><forenames>Debasish</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>The Stochastic Reach-Avoid Problem and Set Characterization for
  Diffusions</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we approach a class of stochastic reachability problems with
state constraints from an optimal control perspective. Preceding approaches to
solving these reachability problems are either confined to the deterministic
setting or address almost-sure stochastic requirements. In contrast, we propose
a methodology to tackle problems with less stringent requirements than almost
sure. To this end, we first establish a connection between two distinct
stochastic reach-avoid problems and three classes of stochastic optimal control
problems involving discontinuous payoff functions. Subsequently, we focus on
solutions of one of the classes of stochastic optimal control problems---the
exit-time problem, which solves both the two reach-avoid problems mentioned
above. We then derive a weak version of a dynamic programming principle (DPP)
for the corresponding value function; in this direction our contribution
compared to the existing literature is to develop techniques that admit
discontinuous payoff functions. Moreover, based on our DPP, we provide an
alternative characterization of the value function as a solution of a partial
differential equation in the sense of discontinuous viscosity solutions, along
with boundary conditions both in Dirichlet and viscosity senses. Theoretical
justifications are also discussed to pave the way for deployment of
off-the-shelf PDE solvers for numerical computations. Finally, we validate the
performance of the proposed framework on the stochastic Zermelo navigation
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4384</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4384</id><created>2012-02-20</created><authors><author><keyname>Lella</keyname><forenames>Paolo</forenames></author></authors><title>Computable Hilbert Schemes</title><categories>math.AG cs.MS cs.SC math.AC math.CO</categories><comments>This is the PhD thesis of the author. Most of the results appeared or
  are going to appear in some paper. However the thesis contains more detailed
  explanations, proofs and remarks and it can be used also as handbook for all
  algorithms proposed and available at
  http://www.personalweb.unito.it/paolo.lella/HSC/index.html . arXiv admin
  note: text overlap with arXiv:1101.2866 by other authors</comments><msc-class>14C05, 13P10, 13P99, 15A75, 13C99, 14Q20, 14H50, 14Q05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this PhD thesis we propose an algorithmic approach to the study of the
Hilbert scheme. Developing algorithmic methods, we also obtain general results
about Hilbert schemes. In Chapter 1 we discuss the equations defining the
Hilbert scheme as subscheme of a suitable Grassmannian and in Chapter 5 we
determine a new set of equations of degree lower than the degree of equations
known so far. In Chapter 2 we study the most important objects used to project
algorithmic techniques, namely Borel-fixed ideals. We determine an algorithm
computing all the saturated Borel-fixed ideals with Hilbert polynomial assigned
and we investigate their combinatorial properties. In Chapter 3 we show a new
type of flat deformations of Borel-fixed ideals which lead us to give a new
proof of the connectedness of the Hilbert scheme. In Chapter 4 we construct
families of ideals that generalize the notion of family of ideals sharing the
same initial ideal with respect to a fixed term ordering. Some of these
families correspond to open subsets of the Hilbert scheme and can be used to a
local study of the Hilbert scheme. In Chapter 6 we deal with the problem of the
connectedness of the Hilbert scheme of locally Cohen-Macaulay curves in the
projective 3-space. We show that one of the Hilbert scheme considered a &quot;good&quot;
candidate to be non-connected, is instead connected. Moreover there are three
appendices that present and explain how to use the implementations of the
algorithms proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4385</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4385</id><created>2012-02-20</created><updated>2012-02-21</updated><authors><author><keyname>Malik</keyname><forenames>Salman</forenames></author><author><keyname>Jacquet</keyname><forenames>Philippe</forenames></author></authors><title>An Overview of Local Capacity in Wireless Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>This work has been accepted to appear in Springer Telecommunication
  Systems journal. Part of this work was also presented at the Wireless Days
  2011 and WMNC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a metric for performance evaluation of medium access
schemes in wireless ad hoc networks known as local capacity. Although deriving
the end-to-end capacity of wireless ad hoc networks is a difficult problem, the
local capacity framework allows us to quantify the average information rate
received by a receiver node randomly located in the network. In this article,
the basic network model and analytical tools are first discussed and applied to
a simple network to derive the local capacity of various medium access schemes.
Our goal is to identify the most optimal scheme and also to see how does it
compare with more practical medium access schemes. We analyzed grid pattern
schemes where simultaneous transmitters are positioned in a regular grid
pattern, ALOHA schemes where simultaneous transmitters are dispatched according
to a uniform Poisson distribution and exclusion schemes where simultaneous
transmitters are dispatched according to an exclusion rule such as node
coloring and carrier sense schemes. Our analysis shows that local capacity is
optimal when simultaneous transmitters are positioned in a grid pattern based
on equilateral triangles and our results show that this optimal local capacity
is at most double the local capacity of ALOHA based scheme. Our results also
show that node coloring and carrier sense schemes approach the optimal local
capacity by an almost negligible difference. At the end, we also discuss the
shortcomings in our model as well as future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4387</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4387</id><created>2012-02-20</created><authors><author><keyname>Ziegelmeier</keyname><forenames>Lori</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author></authors><title>Locally Linear Embedding Clustering Algorithm for Natural Imagery</title><categories>math.GT cs.CG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to characterize the color content of natural imagery is an
important application of image processing. The pixel by pixel coloring of
images may be viewed naturally as points in color space, and the inherent
structure and distribution of these points affords a quantization, through
clustering, of the color information in the image. In this paper, we present a
novel topologically driven clustering algorithm that permits segmentation of
the color features in a digital image. The algorithm blends Locally Linear
Embedding (LLE) and vector quantization by mapping color information to a lower
dimensional space, identifying distinct color regions, and classifying pixels
together based on both a proximity measure and color content. It is observed
that these techniques permit a significant reduction in color resolution while
maintaining the visually important features of images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4393</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4393</id><created>2012-02-20</created><authors><author><keyname>Herda&#x11f;delen</keyname><forenames>Ama&#xe7;</forenames></author><author><keyname>Zuo</keyname><forenames>Wenyun</forenames></author><author><keyname>Gard-Murray</keyname><forenames>Alexander</forenames></author><author><keyname>Bar-Yam</keyname><forenames>Yaneer</forenames></author></authors><title>An Exploration of Social Identity: The Geography and Politics of
  News-Sharing Communities in Twitter</title><categories>physics.soc-ph cs.CY cs.SI nlin.AO</categories><comments>19 pages, 5 figures</comments><report-no>New England Complex Systems Institute (NECSI) Report 2012-02-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of collective social action in current events is manifest in
the Arab Spring and Occupy movements. Electronic social media have become a
pervasive channel for social interactions, and a basis of collective social
response to information. The study of social media can reveal how individual
actions combine to become the collective dynamics of society. Characterizing
the groups that form spontaneously may reveal both how individuals
self-identify and how they will act together. Here we map the social,
political, and geographical properties of news-sharing communities on Twitter,
a popular micro-blogging platform. We track user-generated messages that
contain links to New York Times online articles and we label users according to
the topic of the links they share, their geographic location, and their
self-descriptive keywords. When users are clustered based on who follows whom
in Twitter, we find social groups separate by whether they are interested in
local (NY), national (US) or global (cosmopolitan) issues. The national group
subdivides into liberal, conservative and other, the latter being a diverse but
mostly business oriented group with sports, arts and other splinters. The
national political groups are based across the US but are distinct from the
national group that is broadly interested in a variety of topics. A person who
is cosmopolitan associates with others who are cosmopolitan, and a US liberal /
conservative associates with others who are US liberal / conservative, creating
separated social groups with those identities. The existence of &quot;citizens&quot; of
local, national and cosmopolitan communities is a basis for dialog and action
at each of these levels of societal organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4406</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4406</id><created>2012-02-20</created><updated>2013-12-05</updated><authors><author><keyname>K&#xf6;bler</keyname><forenames>Johannes</forenames></author><author><keyname>Kuhnert</keyname><forenames>Sebastian</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Solving the Canonical Representation and Star System Problems for Proper
  Circular-Arc Graphs in Log-Space</title><categories>cs.CC cs.DM</categories><comments>19 pages, 3 figures, major revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a logspace algorithm that constructs a canonical intersection
model for a given proper circular-arc graph, where `canonical' means that
models of isomorphic graphs are equal. This implies that the recognition and
the isomorphism problems for this class of graphs are solvable in logspace. For
a broader class of concave-round graphs, that still possess (not necessarily
proper) circular-arc models, we show that those can also be constructed
canonically in logspace. As a building block for these results, we show how to
compute canonical models of circular-arc hypergraphs in logspace, which are
also known as matrices with the circular-ones property. Finally, we consider
the search version of the Star System Problem that consists in reconstructing a
graph from its closed neighborhood hypergraph. We solve it in logspace for the
classes of proper circular-arc, concave-round, and co-convex graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4407</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4407</id><created>2012-02-20</created><authors><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Gra&#xe7;a</keyname><forenames>Daniel S.</forenames></author><author><keyname>Pouly</keyname><forenames>Amaury</forenames></author></authors><title>On the complexity of solving initial value problems</title><categories>cs.NA cs.CC</categories><comments>8 pages (two columns per page), submitted to ISSAC'12 conference</comments><doi>10.1145/2442829.2442849</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove that computing the solution of an initial-value
problem $\dot{y}=p(y)$ with initial condition $y(t_0)=y_0\in\R^d$ at time
$t_0+T$ with precision $e^{-\mu}$ where $p$ is a vector of polynomials can be
done in time polynomial in the value of $T$, $\mu$ and $Y=\sup_{t_0\leqslant
u\leqslant T}\infnorm{y(u)}$. Contrary to existing results, our algorithm works
for any vector of polynomials $p$ over any bounded or unbounded domain and has
a guaranteed complexity and precision. In particular we do not assume $p$ to be
fixed, nor the solution to lie in a compact domain, nor we assume that $p$ has
a Lipschitz constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4411</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4411</id><created>2012-02-20</created><updated>2012-08-05</updated><authors><author><keyname>Goltsev</keyname><forenames>A. V.</forenames></author><author><keyname>Dorogovtsev</keyname><forenames>S. N.</forenames></author><author><keyname>Oliveira</keyname><forenames>J. G.</forenames></author><author><keyname>Mendes</keyname><forenames>J. F. F.</forenames></author></authors><title>Localization and Spreading of Diseases in Complex Networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI physics.bio-ph</categories><comments>5 pages, 3 figures</comments><journal-ref>Phys. Rev. Lett. 109, 128702 (2012)</journal-ref><doi>10.1103/PhysRevLett.109.128702</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the SIS model on unweighted and weighted networks, we consider the
disease localization phenomenon. In contrast to the well-recognized point of
view that diseases infect a finite fraction of vertices right above the
epidemic threshold, we show that diseases can be localized on a finite number
of vertices, where hubs and edges with large weights are centers of
localization. Our results follow from the analysis of standard models of
networks and empirical data for real-world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4419</identifier>
 <datestamp>2014-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4419</id><created>2012-02-20</created><updated>2014-03-06</updated><authors><author><keyname>Golovach</keyname><forenames>Petr A.</forenames></author><author><keyname>Paulusma</keyname><forenames>Daniel</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Erik Jan</forenames></author></authors><title>Induced Disjoint Paths in Claw-Free Graphs</title><categories>cs.DM cs.DS</categories><comments>Minor revision. Submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paths P1,...,Pk in a graph G=(V,E) are said to be mutually induced if for any
1 &lt;= i &lt; j &lt;= k, Pi and Pj have neither common vertices nor adjacent vertices
(except perhaps their end-vertices). The Induced Disjoint Paths problem is to
test whether a graph G with k pairs of specified vertices (si,ti) contains k
mutually induced paths Pi such that Pi connects si and ti for i=1,...,k. We
show that this problem is fixed-parameter tractable for claw-free graphs when
parameterized by k. Several related problems, such as the k-in-a-Path problem,
are proven to be fixed-parameter tractable for claw-free graphs as well. We
show that an improvement of these results in certain directions is unlikely,
for example by noting that the Induced Disjoint Paths problem cannot have a
polynomial kernel for line graphs (a type of claw-free graphs), unless NP
\subseteq coNP/poly. Moreover, the problem becomes NP-complete, even when k=2,
for the more general class of K_1,4-free graphs. Finally, we show that the
n^O(k)-time algorithm of Fiala et al. for testing whether a claw-free graph
contains some k-vertex graph H as a topological induced minor is essentially
optimal by proving that this problem is W[1]-hard even if G and H are line
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4423</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4423</id><created>2012-02-15</created><authors><author><keyname>Mann</keyname><forenames>Sarah Edge</forenames></author><author><keyname>Anderson</keyname><forenames>Michael</forenames></author><author><keyname>Rychlik</keyname><forenames>Marek</forenames></author></authors><title>On the Reliability of RAID Systems: An Argument for More Check Drives</title><categories>cs.PF math.PR</categories><comments>13 pages, 11 figures, 3 tables</comments><msc-class>60K10 (Primary) 62N05, 90B25 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address issues of reliability of RAID systems. We focus on
&quot;big data&quot; systems with a large number of drives and advanced error correction
schemes beyond \RAID{6}. Our RAID paradigm is based on Reed-Solomon codes, and
thus we assume that the RAID consists of $N$ data drives and $M$ check drives.
The RAID fails only if the combined number of failed drives and sector errors
exceeds $M$, a property of Reed-Solomon codes.
  We review a number of models considered in the literature and build upon them
to construct models usable for a large number of data and check drives. We
attempt to account for a significant number of factors that affect RAID
reliability, such as drive replacement or lack thereof, mistakes during service
such as replacing the wrong drive, delayed repair, and the finite duration of
RAID reconstruction. We evaluate the impact of sector failures that do not
result in drive replacement.
  The reader who needs to consider large $M$ and $N$ will find applicable
mathematical techniques concisely summarized here, and should be able to apply
them to similar problems. Most methods are based on the theory of continuous
time Markov chains, but we move beyond this framework when we consider the
fixed time to rebuild broken hard drives, which we model using systems of delay
and partial differential equations.
  One universal statement is applicable across various models: increasing the
number of check drives in all cases increases the reliability of the system,
and is vastly superior to other approaches of ensuring reliability such as
mirroring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4425</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4425</id><created>2012-02-20</created><authors><author><keyname>Bakanoglu</keyname><forenames>Kagan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Erkip</keyname><forenames>Elza</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Sholomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Relay Channel with Orthogonal Components and Structured Interference
  Known at the Source</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications, 28 pages, 11
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A relay channel with orthogonal components that is affected by an
interference signal that is noncausally available only at the source is
studied. The interference signal has structure in that it is produced by
another transmitter communicating with its own destination. Moreover, the
interferer is not willing to adjust its communication strategy to minimize the
interference. Knowledge of the interferer's signal may be acquired by the
source, for instance, by exploiting HARQ retransmissions on the interferer's
link. The source can then utilize the relay not only for communicating its own
message, but also for cooperative interference mitigation at the destination by
informing the relay about the interference signal. Proposed transmission
strategies are based on partial decode-and-forward (PDF) relaying and leverage
the interference structure. Achievable schemes are derived for discrete
memoryless models, Gaussian and Ricean fading channels. Furthermore, optimal
strategies are identified in some special cases. Finally, numerical results
bring insight into the advantages of utilizing the interference structure at
the source, relay or destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4438</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4438</id><created>2012-02-20</created><updated>2012-07-22</updated><authors><author><keyname>Ahmadi</keyname><forenames>Behzad</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author></authors><title>On Channels with Action-Dependent States</title><categories>cs.IT math.IT</categories><comments>Technical report. A shorter version will be presented at ITW 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Action-dependent channels model scenarios in which transmission takes place
in two successive phases. In the first phase, the encoder selects an &quot;action&quot;
sequence, with the twofold aim of conveying information to the receiver and of
affecting in a desired way the state of the channel to be used in the second
phase. In the second phase, communication takes place in the presence the
mentioned action-dependent state. In this work, two extensions of the original
action-dependent channel are studied. In the first, the decoder is interested
in estimating not only the message, but also the state sequence within an
average per-letter distortion. Under the constraint of common knowledge (i.e.,
the decoder's estimate of the state must be recoverable also at the encoder)
and assuming non-causal state knowledge at the encoder in the second phase, we
obtain a single-letter characterization of the achievable rate-distortion-cost
trade-off. In the second extension, we study an action-dependent degraded
broadcast channel. Under the assumption that the encoder knows the state
sequence causally in the second phase, the capacity-cost region is identified.
Various examples, including Gaussian channels and a model with a &quot;probing&quot;
encoder, are also provided to show the advantage of a proper joint design of
the two communication phases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4446</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4446</id><created>2012-02-20</created><authors><author><keyname>Sahu</keyname><forenames>Anit Kumar</forenames></author><author><keyname>Chakraborty</keyname><forenames>Mrityunjoy</forenames></author></authors><title>Fast and Accurate Frequency Estimation Using Sliding DFT</title><categories>cs.SY</categories><comments>4 pages,5 figures,To be submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency Estimation of a complex exponential is a problem relevant to a
large number of fields. In this paper a computationally efficient and accurate
frequency estimator is presented using the guaranteed stable Sliding DFT which
gives stability as well as computational efficiency. The estimator approaches
Jacobsen's estimator and Candan's estimator for large N with an extra
correction term multiplied to it for the stabilization of the sliding DFT.
Simulation results show that the performance of the proposed estimator were
found to be better than Jacobsen's estimator and Candan's estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4451</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4451</id><created>2012-02-18</created><authors><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Wireless Peer-to-Peer Scheduling in Mobile Networks</title><categories>cs.NI</categories><comments>This material will be presented in part at the 46th Annual Conference
  on Information Sciences and Systems (CISS), Princeton, NJ, March 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers peer-to-peer scheduling for a network with multiple
wireless devices. A subset of the devices are mobile users that desire specific
files. Each user may already have certain popular files in its cache. The
remaining devices are access points that typically have access to a larger set
of files. Users can download packets of their requested file from an access
point or from a nearby user. Our prior work optimizes peer scheduling in a
general setting, but the resulting delay can be large when applied to mobile
networks. This paper focuses on the mobile case, and develops a new algorithm
that reduces delay by opportunistically grabbing packets from current
neighbors. However, it treats a simpler model where each user desires a single
file with infinite length. An algorithm that provably optimizes throughput
utility while incentivizing participation is developed for this case. The
algorithm extends as a simple heuristic in more general cases with finite file
sizes and random active and idle periods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4465</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4465</id><created>2012-02-20</created><authors><author><keyname>Yosinski</keyname><forenames>Jason</forenames></author><author><keyname>Bills</keyname><forenames>Cooper</forenames></author></authors><title>MAV Stabilization using Machine Learning and Onboard Sensors</title><categories>cs.RO cs.AI</categories><comments>9 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In many situations, Miniature Aerial Vehicles (MAVs) are limited to using
only on-board sensors for navigation. This limits the data available to
algorithms used for stabilization and localization, and current control methods
are often insufficient to allow reliable hovering in place or trajectory
following. In this research, we explore using machine learning to predict the
drift (flight path errors) of an MAV while executing a desired flight path.
This predicted drift will allow the MAV to adjust it's flightpath to maintain a
desired course.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4473</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4473</id><created>2012-02-20</created><authors><author><keyname>Bubeck</keyname><forenames>Sebastien</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>The best of both worlds: stochastic and adversarial bandits</title><categories>cs.LG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new bandit algorithm, SAO (Stochastic and Adversarial Optimal),
whose regret is, essentially, optimal both for adversarial rewards and for
stochastic rewards. Specifically, SAO combines the square-root worst-case
regret of Exp3 (Auer et al., SIAM J. on Computing 2002) and the
(poly)logarithmic regret of UCB1 (Auer et al., Machine Learning 2002) for
stochastic rewards. Adversarial rewards and stochastic rewards are the two main
settings in the literature on (non-Bayesian) multi-armed bandits. Prior work on
multi-armed bandits treats them separately, and does not attempt to jointly
optimize for both. Our result falls into a general theme of achieving good
worst-case performance while also taking advantage of &quot;nice&quot; problem instances,
an important issue in the design of algorithms with partially known inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4478</identifier>
 <datestamp>2012-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4478</id><created>2012-02-20</created><authors><author><keyname>Hazan</keyname><forenames>Elad</forenames></author><author><keyname>Kakade</keyname><forenames>Sham</forenames></author></authors><title>(weak) Calibration is Computationally Hard</title><categories>cs.GT cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the existence of a computationally efficient calibration
algorithm, with a low weak calibration rate, would imply the existence of an
efficient algorithm for computing approximate Nash equilibria - thus implying
the unlikely conclusion that every problem in PPAD is solvable in polynomial
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4482</identifier>
 <datestamp>2013-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4482</id><created>2012-02-20</created><updated>2013-02-09</updated><authors><author><keyname>Balduzzi</keyname><forenames>David</forenames></author><author><keyname>Ortega</keyname><forenames>Pedro A</forenames></author><author><keyname>Besserve</keyname><forenames>Michel</forenames></author></authors><title>Metabolic cost as an organizing principle for cooperative learning</title><categories>q-bio.NC cs.LG nlin.AO</categories><comments>14 pages, 2 figures, to appear in Advances in Complex Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates how neurons can use metabolic cost to facilitate
learning at a population level. Although decision-making by individual neurons
has been extensively studied, questions regarding how neurons should behave to
cooperate effectively remain largely unaddressed. Under assumptions that
capture a few basic features of cortical neurons, we show that constraining
reward maximization by metabolic cost aligns the information content of actions
with their expected reward. Thus, metabolic cost provides a mechanism whereby
neurons encode expected reward into their outputs. Further, aside from reducing
energy expenditures, imposing a tight metabolic constraint also increases the
accuracy of empirical estimates of rewards, increasing the robustness of
distributed learning. Finally, we present two implementations of metabolically
constrained learning that confirm our theoretical finding. These results
suggest that metabolic cost may be an organizing principle underlying the
neural code, and may also provide a useful guide to the design and analysis of
other cooperating populations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4486</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4486</id><created>2012-02-20</created><authors><author><keyname>dieudonn&#xe9;</keyname><forenames>Yoann</forenames></author><author><keyname>Lev&#xe9;</keyname><forenames>Florence</forenames></author><author><keyname>Petit</keyname><forenames>Franck</forenames></author><author><keyname>Villain</keyname><forenames>Vincent</forenames></author></authors><title>Deterministic Leader Election Among Disoriented Anonymous Sensors</title><categories>cs.DC cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the Leader Election (LE) problem in networks of anonymous sensors
sharing no kind of common coordinate system. Leader Election is a fundamental
symmetry breaking problem in distributed computing. Its goal is to assign value
1 (leader) to one of the entities and value 0 (non-leader) to all others. In
this paper, assuming n &gt; 1 disoriented anonymous sensors, we provide a complete
charac- terization on the sensors positions to deterministically elect a
leader, provided that all the sensors' positions are known by every sensor.
More precisely, our contribution is twofold: First, assuming n anonymous
sensors agreeing on a common handedness (chirality) of their own coordinate
system, we provide a complete characterization on the sensors positions to
deterministically elect a leader. Second, we also provide such a complete
chararacterization for sensors devoided of a common handedness. Both
characterizations rely on a particular object from combinatorics on words,
namely the Lyndon Words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4495</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4495</id><created>2012-02-20</created><authors><author><keyname>Canals</keyname><forenames>V.</forenames></author><author><keyname>Morro</keyname><forenames>A.</forenames></author><author><keyname>Rossell&#xf3;</keyname><forenames>J. L.</forenames></author></authors><title>Stochastic-Based Pattern Recognition Analysis</title><categories>cs.CV</categories><journal-ref>Published in Pattern Recognition Letters in 2010</journal-ref><doi>10.1016/j.patrec.2010.07.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we review the basic principles of stochastic logic and propose
its application to probabilistic-based pattern-recognition analysis. The
proposed technique is intrinsically a parallel comparison of input data to
various pre-stored categories using Bayesian techniques. We design smart
pulse-based stochastic-logic blocks to provide an efficient pattern recognition
analysis. The proposed rchitecture is applied to a specific navigation problem.
The resulting system is orders of magnitude faster than processor-based
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4503</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4503</id><created>2012-02-20</created><authors><author><keyname>Narayanan</keyname><forenames>Arvind</forenames></author><author><keyname>Toubiana</keyname><forenames>Vincent</forenames></author><author><keyname>Barocas</keyname><forenames>Solon</forenames></author><author><keyname>Nissenbaum</keyname><forenames>Helen</forenames></author><author><keyname>Boneh</keyname><forenames>Dan</forenames></author></authors><title>A Critical Look at Decentralized Personal Data Architectures</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the Internet was conceived as a decentralized network, the most widely
used web applications today tend toward centralization. Control increasingly
rests with centralized service providers who, as a consequence, have also
amassed unprecedented amounts of data about the behaviors and personalities of
individuals.
  Developers, regulators, and consumer advocates have looked to alternative
decentralized architectures as the natural response to threats posed by these
centralized services. The result has been a great variety of solutions that
include personal data stores (PDS), infomediaries, Vendor Relationship
Management (VRM) systems, and federated and distributed social networks. And
yet, for all these efforts, decentralized personal data architectures have seen
little adoption.
  This position paper attempts to account for these failures, challenging the
accepted wisdom in the web community on the feasibility and desirability of
these approaches. We start with a historical discussion of the development of
various categories of decentralized personal data architectures. Then we survey
the main ideas to illustrate the common themes among these efforts. We tease
apart the design characteristics of these systems from the social values that
they (are intended to) promote. We use this understanding to point out numerous
drawbacks of the decentralization paradigm, some inherent and others
incidental. We end with recommendations for designers of these systems for
working towards goals that are achievable, but perhaps more limited in scope
and ambition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4504</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4504</id><created>2012-02-20</created><authors><author><keyname>Avigdor-Elgrabli</keyname><forenames>Noa</forenames></author><author><keyname>Rabani</keyname><forenames>Yuval</forenames></author></authors><title>A Constant Factor Approximation Algorithm for Reordering Buffer
  Management</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the reordering buffer management problem (RBM) a sequence of $n$ colored
items enters a buffer with limited capacity $k$. When the buffer is full, one
item is removed to the output sequence, making room for the next input item.
This step is repeated until the input sequence is exhausted and the buffer is
empty. The objective is to find a sequence of removals that minimizes the total
number of color changes in the output sequence. The problem formalizes numerous
applications in computer and production systems, and is known to be NP-hard.
  We give the first constant factor approximation guarantee for RBM. Our
algorithm is based on an intricate &quot;rounding&quot; of the solution to an LP
relaxation for RBM, so it also establishes a constant upper bound on the
integrality gap of this relaxation. Our results improve upon the best previous
bound of $O(\sqrt{\log k})$ of Adamaszek et al. (STOC 2011) that used different
methods and gave an online algorithm. Our constant factor approximation beats
the super-constant lower bounds on the competitive ratio given by Adamaszek et
al. This is the first demonstration of an offline algorithm for RBM that is
provably better than any online algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4506</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4506</id><created>2012-02-20</created><authors><author><keyname>Bulychev</keyname><forenames>Peter</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>David</keyname><forenames>Alexandre</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Larsen</keyname><forenames>Kim G.</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Legay</keyname><forenames>Axel</forenames><affiliation>INRIA Rennes, France/Aalborg University, Denmark</affiliation></author><author><keyname>Miku&#x10d;ionis</keyname><forenames>Marius</forenames><affiliation>Aalborg University, Denmark</affiliation></author></authors><title>Computing Nash Equilibrium in Wireless Ad Hoc Networks: A
  Simulation-Based Approach</title><categories>cs.GT cs.FL cs.NI</categories><comments>In Proceedings IWIGP 2012, arXiv:1202.4229</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 78, 2012, pp. 1-14</journal-ref><doi>10.4204/EPTCS.78.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of computing Nash equilibrium in wireless
networks modeled by Weighted Timed Automata. Such formalism comes together with
a logic that can be used to describe complex features such as timed energy
constraints. Our contribution is a method for solving this problem using
Statistical Model Checking. The method has been implemented in UPPAAL model
checker and has been applied to the analysis of Aloha CSMA/CD and IEEE 802.15.4
CSMA/CA protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4507</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4507</id><created>2012-02-20</created><authors><author><keyname>Manabe</keyname><forenames>Yoshifumi</forenames><affiliation>NTT</affiliation></author><author><keyname>Okamoto</keyname><forenames>Tatsuaki</forenames><affiliation>NTT</affiliation></author></authors><title>A Cryptographic Moving-Knife Cake-Cutting Protocol</title><categories>cs.GT cs.CR cs.MA</categories><comments>In Proceedings IWIGP 2012, arXiv:1202.4229</comments><proxy>EPTCS</proxy><acm-class>G.2.1; E.3</acm-class><journal-ref>EPTCS 78, 2012, pp. 15-23</journal-ref><doi>10.4204/EPTCS.78.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a cake-cutting protocol using cryptography when the cake
is a heterogeneous good that is represented by an interval on a real line.
Although the Dubins-Spanier moving-knife protocol with one knife achieves
simple fairness, all players must execute the protocol synchronously. Thus, the
protocol cannot be executed on asynchronous networks such as the Internet. We
show that the moving-knife protocol can be executed asynchronously by a
discrete protocol using a secure auction protocol. The number of cuts is n-1
where n is the number of players, which is the minimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4508</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4508</id><created>2012-02-20</created><authors><author><keyname>Reich</keyname><forenames>Johannes</forenames></author></authors><title>Processes, Roles and Their Interactions</title><categories>cs.DC</categories><comments>In Proceedings IWIGP 2012, arXiv:1202.4229</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 78, 2012, pp. 24-38</journal-ref><doi>10.4204/EPTCS.78.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Taking an interaction network oriented perspective in informatics raises the
challenge to describe deterministic finite systems which take part in networks
of nondeterministic interactions. The traditional approach to describe
processes as stepwise executable activities which are not based on the
ordinarily nondeterministic interaction shows strong centralization tendencies.
As suggested in this article, viewing processes and their interactions as
complementary can circumvent these centralization tendencies.
  The description of both, processes and their interactions is based on the
same building blocks, namely finite input output automata (or transducers).
Processes are viewed as finite systems that take part in multiple, ordinarily
nondeterministic interactions. The interactions between processes are described
as protocols.
  The effects of communication between processes as well as the necessary
coordination of different interactions within a processes are both based on the
restriction of the transition relation of product automata. The channel based
outer coupling represents the causal relation between the output and the input
of different systems. The coordination condition based inner coupling
represents the causal relation between the input and output of a single system.
  All steps are illustrated with the example of a network of resource
administration processes which is supposed to provide requesting user processes
exclusive access to a single resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4509</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4509</id><created>2012-02-20</created><authors><author><keyname>Busard</keyname><forenames>Simon</forenames><affiliation>UCLouvain, Belgium</affiliation></author><author><keyname>Pecheur</keyname><forenames>Charles</forenames><affiliation>UCLouvain, Belgium</affiliation></author></authors><title>Rich Counter-Examples for Temporal-Epistemic Logic Model Checking</title><categories>cs.LO cs.MA</categories><comments>In Proceedings IWIGP 2012, arXiv:1202.4229</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 78, 2012, pp. 39-53</journal-ref><doi>10.4204/EPTCS.78.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model checking verifies that a model of a system satisfies a given property,
and otherwise produces a counter-example explaining the violation. The verified
properties are formally expressed in temporal logics. Some temporal logics,
such as CTL, are branching: they allow to express facts about the whole
computation tree of the model, rather than on each single linear computation.
This branching aspect is even more critical when dealing with multi-modal
logics, i.e. logics expressing facts about systems with several transition
relations. A prominent example is CTLK, a logic that reasons about temporal and
epistemic properties of multi-agent systems. In general, model checkers produce
linear counter-examples for failed properties, composed of a single computation
path of the model. But some branching properties are only poorly and partially
explained by a linear counter-example.
  This paper proposes richer counter-example structures called tree-like
annotated counter-examples (TLACEs), for properties in Action-Restricted CTL
(ARCTL), an extension of CTL quantifying paths restricted in terms of actions
labeling transitions of the model. These counter-examples have a branching
structure that supports more complete description of property violations.
Elements of these counter-examples are annotated with parts of the property to
give a better understanding of their structure. Visualization and browsing of
these richer counter-examples become a critical issue, as the number of
branches and states can grow exponentially for deeply-nested properties.
  This paper formally defines the structure of TLACEs, characterizes adequate
counter-examples w.r.t. models and failed properties, and gives a generation
algorithm for ARCTL properties. It also illustrates the approach with examples
in CTLK, using a reduction of CTLK to ARCTL. The proposed approach has been
implemented, first by extending the NuSMV model checker to generate and export
branching counter-examples, secondly by providing an interactive graphical
interface to visualize and browse them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4514</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4514</id><created>2012-02-20</created><authors><author><keyname>Knill</keyname><forenames>Oliver</forenames></author></authors><title>On index expectation and curvature for networks</title><categories>math.DG cs.DM math.GN</categories><msc-class>05C10, 57M15, 68R10, 53A55, 60B99, 94C99, 97K30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the expectation value of the index function i(x) over a
probability space of injective function f on any finite simple graph G=(V,E) is
equal to the curvature K(x) at the vertex x. This result complements and links
Gauss-Bonnet sum K(x) = chi(G) and Poincare-Hopf sum i(x) = chi(G) which both
hold for arbitrary finite simple graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4527</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4527</id><created>2012-02-21</created><authors><author><keyname>Isabella</keyname><forenames>A.</forenames></author><author><keyname>Retna</keyname><forenames>Emi</forenames></author></authors><title>Study Paper on Test Case generation for GUI Based Testing</title><categories>cs.SE</categories><comments>GUI Testing, Test case generation</comments><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.3, No.1, January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of WWW and outburst in technology and software development,
testing the software became a major concern. Due to the importance of the
testing phase in a software development life cycle, testing has been divided
into graphical user interface (GUI) based testing, logical testing, integration
testing, etc.GUI Testing has become very important as it provides more
sophisticated way to interact with the software. The complexity of testing GUI
increased over time. The testing needs to be performed in a way that it
provides effectiveness, efficiency, increased fault detection rate and good
path coverage. To cover all use cases and to provide testing for all possible
(success/failure) scenarios the length of the test sequence is considered
important. Intent of this paper is to study some techniques used for test case
generation and process for various GUI based software applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4530</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4530</id><created>2012-02-21</created><authors><author><keyname>Prasad</keyname><forenames>K. Munivara</forenames></author><author><keyname>Reddy</keyname><forenames>A. Rama Mohan</forenames></author><author><keyname>Jyothsna</keyname><forenames>V</forenames></author></authors><title>IP Traceback for Flooding attacks on Internet Threat Monitors (ITM)
  Using Honeypots</title><categories>cs.NI</categories><comments>International Journal of Network Security &amp; Its Applications (IJNSA),
  Vol.4, No.1, January 2012. arXiv admin note: substantial text overlap with
  arXiv:1201.2481</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.4, No.1, January 2012</journal-ref><doi>10.5121/ijnsa.2012.4102</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Internet Threat Monitoring (ITM) is an efficient monitoring system used
globally to measure, detect, characterize and track threats such as denial of
service (DoS) and distributed Denial of Service (DDoS) attacks and worms. . To
block the monitoring system in the internet the attackers are targeted the ITM
system. In this paper we address the flooding attack of DDoS against ITM
monitors to exhaust the network resources, such as bandwidth, computing power,
or operating system data structures by sending the malicious traffic. We
propose an information-theoretic frame work that models the flooding attacks
using Botnet on ITM. One possible way to counter DDoS attacks is to trace the
attack sources and punish the perpetrators. we propose a novel traceback method
for DDoS using Honeypots. IP tracing through honeypot is a single packet
tracing method and is more efficient than commonly used packet marking
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4532</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4532</id><created>2012-02-21</created><authors><author><keyname>Sarkar</keyname><forenames>Anirban</forenames></author></authors><title>Conceptual Level Design of Semi-structured Database System:
  Graph-semantic Based Approach</title><categories>cs.SE cs.DB</categories><comments>10 Pages, 3 Tables, 12 Figures</comments><acm-class>D.2.10; D.2.2</acm-class><journal-ref>International Journal of Advanced Computer Science and
  Applications, The SAI Pubs., USA, Vol. 2 (10), 112 - 121, November, 2011.
  [ISSN: 2156-5570(Online) &amp; ISSN : 2158-107X(Print)]</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper has proposed a Graph - semantic based conceptual model for
semi-structured database system, called GOOSSDM, to conceptualize the different
facets of such system in object oriented paradigm. The model defines a set of
graph based formal constructs, variety of relationship types with participation
constraints and rich set of graphical notations to specify the conceptual level
design of semi-structured database system. The proposed design approach
facilitates modeling of irregular, heterogeneous, hierarchical and
non-hierarchical semi-structured data at the conceptual level. Moreover, the
proposed GOOSSDM is capable to model XML document at conceptual level with the
facility of document-centric design, ordering and disjunction characteristic. A
rule based transformation mechanism of GOOSSDM schema into the equivalent XML
Schema Definition (XSD) also has been proposed in this paper. The concepts of
the proposed conceptual model have been implemented using Generic Modeling
Environment (GME).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4533</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4533</id><created>2012-02-21</created><authors><author><keyname>Fang</keyname><forenames>Chung-Chieh</forenames></author></authors><title>Unified model of voltage/current mode control to predict saddle-node
  bifurcation</title><categories>cs.SY math.DS nlin.CD</categories><comments>Submitted to International Journal of Circuit Theory and Applications
  on December 23, 2010; Manuscript ID: CTA-10-0257</comments><journal-ref>International Journal of Electronics, 100(8), pp. 1147-1174, Aug.
  2013</journal-ref><doi>10.1080/00207217.2012.743072</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unified model of voltage mode control (VMC) and current mode control (CMC)
is proposed to predict the saddle-node bifurcation (SNB). Exact SNB boundary
conditions are derived, and can be further simplified in various forms for
design purpose. Many approaches, including steady-state, sampled-data, average,
harmonic balance, and loop gain analyses are applied to predict SNB. Each
approach has its own merits and complement the other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4534</identifier>
 <datestamp>2015-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4534</id><created>2012-02-21</created><authors><author><keyname>Fang</keyname><forenames>Chung-Chieh</forenames></author></authors><title>Bifurcation Boundary Conditions for Switching DC-DC Converters Under
  Constant On-Time Control</title><categories>cs.SY math.DS nlin.CD</categories><comments>Submitted to International Journal of Circuit Theory and Applications
  on August 10, 2011; Manuscript ID: CTA-11-0169</comments><journal-ref>Nonlinear Dynamics, 77(1-2), pp. 185-208, Jul. 2014</journal-ref><doi>10.1007/s11071-014-1283-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampled-data analysis and harmonic balance analysis are applied to analyze
switching DC-DC converters under constant on-time control. Design-oriented
boundary conditions for the period-doubling bifurcation and the saddle-node
bifurcation are derived. The required ramp slope to avoid the bifurcations and
the assigned pole locations associated with the ramp are also derived. The
derived boundary conditions are more general and accurate than those recently
obtained. Those recently obtained boundary conditions become special cases
under the general modeling approach presented in this paper. Different analyses
give different perspectives on the system dynamics and complement each other.
Under the sampled-data analysis, the boundary conditions are expressed in terms
of signal slopes and the ramp slope. Under the harmonic balance analysis, the
boundary conditions are expressed in terms of signal harmonics. The derived
boundary conditions are useful for a designer to design a converter to avoid
the occurrence of the period-doubling bifurcation and the saddle-node
bifurcation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4535</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4535</id><created>2012-02-21</created><authors><author><keyname>Quaresma</keyname><forenames>Pedro</forenames><affiliation>University of Coimbra, Portugal</affiliation></author><author><keyname>Back</keyname><forenames>Ralph-Johan</forenames><affiliation>&#xc5;bo Akademi University, Finland</affiliation></author></authors><title>Proceedings First Workshop on CTP Components for Educational Software</title><categories>cs.SY cs.LO cs.MS cs.SC</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 79, 2012</journal-ref><doi>10.4204/EPTCS.79</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The THedu'11 workshop received thirteen submissions, twelve of which were
accepted and presented during the workshop. For the post-conference proceedings
nine submission where received and accepted. The submissions are within the
scope of the following points, which have been announced in the call of papers:
CTP-based software tools for education; CTP technology combined with novel
interfaces, drag and drop, etc.; technologies to access ITP knowledge relevant
for a certain step of problem solving; usability considerations on representing
ITP knowledge; combination of deduction and computation; formal problem
specifications; effectiveness of ATP in checking user input; formats for
deductive content in proof documents, geometric constructions, etc; formal
domain models for e-learning in mathematics and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4537</identifier>
 <datestamp>2015-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4537</id><created>2012-02-21</created><authors><author><keyname>Fang</keyname><forenames>Chung-Chieh</forenames></author></authors><title>Sampled-Data and Harmonic Balance Analyses of Average Current-Mode
  Controlled Buck Converter</title><categories>cs.SY math.DS nlin.CD</categories><comments>Submitted to International Journal of Circuit Theory and Applications
  on August 9, 2011; Manuscript ID: CTA-11-0168</comments><journal-ref>Some parts of this manuscript are published in International
  Journal of Circuit Theory and Applications, 43(8), pp. 995-1014, Aug. 2015</journal-ref><doi>10.1002/cta.1989</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamics and stability of average current-mode control of buck converters are
analyzed by sampled-data and harmonic balance analyses. An exact sampled-data
model is derived. A new continuous-time model &quot;lifted&quot; from the sampled-data
model is also derived, and has frequency response matched with experimental
data reported previously. Orbital stability is studied and it is found
unrelated to the ripple size of the current-loop compensator output. An
unstable window of the current-loop compensator pole is found by simulations,
and it can be accurately predicted by sampled-data and harmonic balance
analyses. A new S plot accurately predicting the subharmonic oscillation is
proposed. The S plot assists pole assignment and shows the required ramp slope
to avoid instability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4553</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4553</id><created>2012-02-21</created><authors><author><keyname>Bentosela</keyname><forenames>Francois</forenames></author><author><keyname>Cornean</keyname><forenames>Horia D.</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author></authors><title>MIMO capacity for deterministic channel models: sublinear growth</title><categories>cs.IT math-ph math.IT math.MP</categories><comments>12 pages, to appear in Math. Meth. Appl. Sci</comments><doi>10.1002/mma.2565</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second paper of the authors in a series concerned with the
development of a deterministic model for the transfer matrix of a MIMO system.
Starting from the Maxwell equations, we have described in \cite{BCFM} the
generic structure of such a deterministic transfer matrix. In the current paper
we apply the results of \cite{BCFM} in order to study the (Shannon-Foschini)
capacity behavior of a MIMO system as a function of the deterministic spread
function of the environment, and the number of transmitting and receiving
antennas. The antennas are assumed to fill in a given, fixed volume. Under some
generic assumptions, we prove that the capacity grows much more slowly than
linearly with the number of antennas. These results reinforce previous
heuristic results obtained from statistical models of the transfer matrix,
which also predict a sublinear behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4554</identifier>
 <datestamp>2014-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4554</id><created>2012-02-21</created><authors><author><keyname>Bellomo</keyname><forenames>Nicola</forenames></author><author><keyname>Herrero</keyname><forenames>Miguel A.</forenames></author><author><keyname>Tosin</keyname><forenames>Andrea</forenames></author></authors><title>On the dynamics of social conflicts: looking for the Black Swan</title><categories>math-ph cs.SI math.MP physics.soc-ph</categories><comments>26 pages, 7 figures</comments><journal-ref>Kinet. Relat. Models, 6(3):459-479, 2013</journal-ref><doi>10.3934/krm.2013.6.459</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the modeling of social competition, possibly resulting
in the onset of extreme conflicts. More precisely, we discuss models describing
the interplay between individual competition for wealth distribution that, when
coupled with political stances coming from support or opposition to a
government, may give rise to strongly self-enhanced effects. The latter may be
thought of as the early stages of massive, unpredictable events known as Black
Swans, although no analysis of any fully-developed Black Swan is provided here.
Our approach makes use of the framework of the kinetic theory for active
particles, where nonlinear interactions among subjects are modeled according to
game-theoretical tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4576</identifier>
 <datestamp>2012-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4576</id><created>2012-02-21</created><updated>2012-05-14</updated><authors><author><keyname>Gilbert</keyname><forenames>Seth</forenames></author><author><keyname>Young</keyname><forenames>Maxwell</forenames></author></authors><title>Making Evildoers Pay: Resource-Competitive Broadcast in Sensor Networks</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a time-slotted, single-hop, wireless sensor network (WSN) consisting
of n correct devices and and t=f*n Byzantine devices where f&gt;=0 is any
constant; that is, the Byzantine devices may outnumber the correct ones. There
exists a trusted sender Alice who wishes to deliver a message m over a single
channel to the correct devices. There also exists a malicious user Carol who
controls the t Byzantine devices and uses them to disrupt the communication
channel. For a constant k&gt;=2, the correct and Byzantine devices each possess a
meager energy budget of O(n^{1/k}), Alice and Carol each possess a limited
budget of \tilde{O}(n^{1/k}), and sending or listening in a slot incurs unit
cost. This general setup captures the inherent challenges of guaranteeing
communication despite scarce resources and attacks on the network. Given this
Alice versus Carol scenario, we ask: Is communication of m feasible and, if so,
at what cost?
  We develop a protocol which, for an arbitrarily small constant \epsilon&gt;0,
ensures that at least (1-\epsilon)n correct devices receive m with high
probability. Furthermore, if Carol's devices expend T energy jamming the
channel, then Alice and the correct devices each spend only
\tilde{O}(T^{1/(k+1)}). In other words, delaying the transmission of m forces a
jammer to rapidly deplete its energy supply and, consequently, cease attacks on
the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4590</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4590</id><created>2012-02-21</created><authors><author><keyname>Sobieszek</keyname><forenames>Tomasz</forenames></author></authors><title>Noncontinous additive entropies of partitions</title><categories>cs.IT math.IT math.PR</categories><msc-class>94A17 (Primary), 60A10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper: A. Paszkiewicz, T. Sobieszek, Additive Entropies of
Partitions, we have given a description of additive partition entropies that is
real functions $I$ on the set of finite partitions that are additive on
stochastically independent partitions in a given probability space. We now
present an analogical result, this time without assuming continuity.
  As a by-product of our efforts we solve a 2-cocycle functional equation for
certain subsets of convex cones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4591</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4591</id><created>2012-02-21</created><updated>2012-02-27</updated><authors><author><keyname>Paszkiewicz</keyname><forenames>Adam</forenames></author><author><keyname>Sobieszek</keyname><forenames>Tomasz</forenames></author></authors><title>Additive Entropies of Partitions</title><categories>cs.IT math.IT math.PR</categories><comments>24 pages</comments><msc-class>94A17 (Primary), 60A10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide, under minimal continuity assumptions, a description of
\textsl{additive partition entropies}. They are real functions $I$ on the set
of finite partitions that are additive on stochastically independent partitions
in a given probability space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4596</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4596</id><created>2012-02-21</created><authors><author><keyname>Wright</keyname><forenames>John</forenames></author><author><keyname>Ganesh</keyname><forenames>Arvind</forenames></author><author><keyname>Min</keyname><forenames>Kerui</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Compressive Principal Component Pursuit</title><categories>cs.IT math.IT</categories><comments>30 pages, 1 figure, preliminary version submitted to ISIT'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering a target matrix that is a superposition
of low-rank and sparse components, from a small set of linear measurements.
This problem arises in compressed sensing of structured high-dimensional
signals such as videos and hyperspectral images, as well as in the analysis of
transformation invariant low-rank recovery. We analyze the performance of the
natural convex heuristic for solving this problem, under the assumption that
measurements are chosen uniformly at random. We prove that this heuristic
exactly recovers low-rank and sparse terms, provided the number of observations
exceeds the number of intrinsic degrees of freedom of the component signals by
a polylogarithmic factor. Our analysis introduces several ideas that may be of
independent interest for the more general problem of compressed sensing and
decomposing superpositions of multiple structured signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4626</identifier>
 <datestamp>2014-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4626</id><created>2012-02-21</created><updated>2014-03-20</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author></authors><title>The \v{C}erny conjecture</title><categories>cs.DM</categories><comments>13 pages, examples, wrong version. The proof of the \v{C}erny
  conjecture is wrong</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A word w is called a synchronizing word of deterministic finite automaton
(DFA) if w sends all states of the automaton to a unique state. In 1964, Jan
\v{C}erny discovered a sequence of n-state complete DFA possessing a minimal
synchronizing word of length (n-1)2. The \v{C}erny conjecture claims that it is
also the upper bound on the length of such a word for a complete DFA. The
problem has motivated great and constantly growing number of investigations and
generalizations and together with the Road Coloring problem is considered as a
most fascinating old problem in the theory of finite automata. An effort to
prove the \v{C}erny conjecture is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4628</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4628</id><created>2012-02-21</created><authors><author><keyname>Nikhil</keyname><forenames>Kumar</forenames></author><author><keyname>Agarwal</keyname><forenames>Swati</forenames></author><author><keyname>Sharma</keyname><forenames>Pankaj</forenames></author></authors><title>Securing a mobile adhoc network from routing attacks through the
  application of genetic algorithm</title><categories>cs.NI</categories><comments>6 pages,3 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In recent years, the static shortest path (SP) problem has been well
addressed using intelligent optimization techniques, e.g., artificial neural
networks, genetic algorithms (GAs), particle swarm optimization, etc. However,
with the advancement in wireless communications, more and more mobile wireless
networks appear, e.g., mobile networks [mobile ad hoc networks (MANETs)],
wireless sensor networks, etc. One of the most important characteristics in
mobile wireless networks is the topology dynamics, i.e., the network topology
changes over time due to energy conservation or node mobility. Therefore, the
SP routing problem in MANETs turns out to be a dynamic optimization problem.
GA's are able to find, if not the shortest, at least an optimal path between
source and destination in mobile ad-hoc network nodes. And we obtain the
alternative path or backup path to avoid reroute discovery in the case of link
failure or node failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4631</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4631</id><created>2012-02-21</created><authors><author><keyname>Calamoneri</keyname><forenames>Tiziana</forenames></author><author><keyname>Frascaria</keyname><forenames>Dario</forenames></author><author><keyname>Sinaimeri</keyname><forenames>Blerina</forenames></author></authors><title>All graphs with at most seven vertices are Pairwise Compatibility Graphs</title><categories>cs.DM</categories><comments>8 pages, 2 figures</comments><msc-class>68R10</msc-class><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is called a pairwise compatibility graph (PCG) if there exists an
edge-weighted tree $T$ and two non-negative real numbers $d_{min}$ and
$d_{max}$ such that each leaf $l_u$ of $T$ corresponds to a vertex $u \in V$
and there is an edge $(u,v) \in E$ if and only if $d_{min} \leq d_{T,w} (l_u,
l_v) \leq d_{max}$ where $d_{T,w} (l_u, l_v)$ is the sum of the weights of the
edges on the unique path from $l_u$ to $l_v$ in $T$.
  In this note, we show that all the graphs with at most seven vertices are
PCGs. In particular all these graphs except for the wheel on 7 vertices $W_7$
are PCGs of a particular structure of a tree: a centipede.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4646</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4646</id><created>2012-02-21</created><authors><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author></authors><title>Publication Trends in Astronomy: The Lone Author</title><categories>cs.DL astro-ph.IM</categories><comments>2 pages, 2 figures</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this short communication I highlight how the number of collaborators on
papers in the main astronomy journals has evolved over time. We see a trend of
moving away from single-author papers. This communication is based on data in
the holdings of the SAO/NASA Astrophysics Data System (ADS).
  The ADS is funded by NASA Grant NNX09AB39G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4661</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4661</id><created>2012-02-20</created><authors><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Tan</keyname><forenames>Jian</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author><author><keyname>El-Gamal</keyname><forenames>Hesham</forenames></author></authors><title>Delay Asymptotics with Retransmissions and Incremental Redundancy Codes
  over Erasure Channels</title><categories>cs.IT cs.PF math.IT</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies have shown that retransmissions can cause heavy-tailed
transmission delays even when packet sizes are light-tailed. Moreover, the
impact of heavy-tailed delays persists even when packets size are upper
bounded. The key question we study in this paper is how the use of coding
techniques to transmit information, together with different system
configurations, would affect the distribution of delay. To investigate this
problem, we model the underlying channel as a Markov modulated binary erasure
channel, where transmitted bits are either received successfully or erased.
Erasure codes are used to encode information prior to transmission, which
ensures that a fixed fraction of the bits in the codeword can lead to
successful decoding. We use incremental redundancy codes, where the codeword is
divided into codeword trunks and these trunks are transmitted one at a time to
provide incremental redundancies to the receiver until the information is
recovered. We characterize the distribution of delay under two different
scenarios: (I) Decoder uses memory to cache all previously successfully
received bits. (II) Decoder does not use memory, where received bits are
discarded if the corresponding information cannot be decoded. In both cases, we
consider codeword length with infinite and finite support. From a theoretical
perspective, our results provide a benchmark to quantify the tradeoff between
system complexity and the distribution of delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4663</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4663</id><created>2012-02-21</created><authors><author><keyname>Abyaneh</keyname><forenames>Mohammad Reza Sohizadeh</forenames></author></authors><title>On the Privacy of Two Tag Ownership Transfer Protocols for RFIDs</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the privacy of two recent RFID tag ownership transfer
protocols are investigated against the tag owners as adversaries. The first
protocol called ROTIV is a scheme which provides a privacy-preserving ownership
transfer by using an HMAC-based authentication with public key encryption.
However, our passive attack on this protocol shows that any legitimate owner
which has been the owner of a specific tag is able to trace it either in the
past or in the future. Tracing the tag is also possible via an active attack
for any adversary who is able to tamper the tag and extract its information.
The second protocol called, Chen et al.'s protocol, is an ownership transfer
protocol for passive RFID tags which conforms EPC Class1 Generation2 standard.
Our attack on this protocol shows that the previous owners of a particular tag
are able to trace it in future. Furthermore, they are able even to obtain the
tag's secret information at any time in the future which makes them capable of
impersonating the tag.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4664</identifier>
 <datestamp>2012-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4664</id><created>2012-02-20</created><updated>2012-10-30</updated><authors><author><keyname>Wang</keyname><forenames>Zhongfeng</forenames></author></authors><title>Super-FEC Codes for 40/100 Gbps Networking</title><categories>cs.IT math.IT</categories><comments>This work has been accepted by IEEE Communications Letters for future
  publication. Copyright may be transferred without notice, after which this
  version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a simple approach to evaluate the performance bound at
very low bit-error-rate (BER) range for binary pseudo-product codes and
true-product codes. Moreover it introduces a super-product BCH code that can
achieve near-Shannon limit performance with very low decoding complexity. This
work has been accepted by IEEE Communications Letters for future publication.
Copyright may be transferred without notice, after which this version may no
longer be accessible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4665</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4665</id><created>2012-02-21</created><updated>2012-10-16</updated><authors><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>Algorithms and Almost Tight Results for 3-Colorability of Small Diameter
  Graphs</title><categories>cs.DS cs.DM math.CO</categories><comments>25 pages, 10 figures, 2 tables, 1 algorithm</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spite of the extensive studies of the 3-coloring problem with respect to
several basic parameters, the complexity status of the 3-coloring problem on
graphs with small diameter, i.e. with diameter 2 or 3, has been a longstanding
and challenging open question. For graphs with diameter 2 we provide the first
subexponential algorithm with complexity $2^{O(\sqrt{n\log n})}$, which is
asymptotically the same as the currently best known time complexity for the
graph isomorphism (GI) problem. Moreover, we prove that the graph isomorphism
problem on 3-colorable graphs with diameter 2 is GI-complete. Furthermore we
present a subclass of graphs with diameter 2 that admits a polynomial algorithm
for 3-coloring. For graphs with diameter 3 we establish the complexity of
3-coloring by proving that for every $\varepsilon \in [0,1)$, 3-coloring is
NP-complete on triangle-free graphs of diameter 3 and radius 2 with $n$
vertices and minimum degree $\delta=\Theta(n^{\varepsilon})$. Moreover,
assuming ETH, we provide three different amplifications of our hardness results
to obtain for every $\varepsilon \in [0,1)$ subexponential lower bounds for the
complexity of 3-coloring on triangle-free graphs with diameter 3 and minimum
degree $\delta=\Theta(n^{\varepsilon})$. Finally, we provide a 3-coloring
algorithm with running time
$2^{O(\min\{\delta\Delta,\frac{n}{\delta}\log\delta\})}$ for graphs with
diameter 3, where $\delta$ (resp. $\Delta $) is the minimum (resp. maximum)
degree of the input graph. To the best of our knowledge, this algorithm is the
first subexponential algorithm for graphs with $\delta=\omega(1)$ and for
graphs with $\delta=O(1)$ and $\Delta=o(n)$. Due to the above lower bounds of
the complexity of 3-coloring, the running time of this algorithm is
asymptotically almost tight when the minimum degree if the input graph is
$\delta=\Theta(n^{\varepsilon})$, where $\varepsilon \in [1/2,1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4675</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4675</id><created>2012-02-21</created><authors><author><keyname>Krishnan</keyname><forenames>S. Venkata</forenames></author><author><keyname>Sriram</keyname><forenames>R.</forenames></author><author><keyname>Kumar</keyname><forenames>N. Senthil</forenames></author></authors><title>Adaptive and Dynamic Wireless Routers with Smart Antenna for Power
  Management</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent evolution of wireless technologies, the power management has
been a worrying factor. In order to overcome the power shortage, steps are
taken to find new kind of energy harvesting methods, power attenuation
reduction methods and power saving techniques. Wireless routers even though
consume not much of power, battery powered devices require a lot. Omni
directional antenna embedded with multiple antennae focusing the beam of radio
wave signals in the direction of nodes with least transmission angle can be a
solution for this problem which is called as &quot;Smart Antenna&quot;. To reduce power
maceration we are going for adaptive and dynamic transmission wherein the
transmission angle of antennae is varied in accordance with the movement of
nodes. Apart from saving the power considerably, it also improves the signal
strength
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4678</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4678</id><created>2012-02-21</created><updated>2012-03-05</updated><authors><author><keyname>Petit</keyname><forenames>Barbara</forenames></author></authors><title>A Categorical Model for the Lambda Calculus with Constructors</title><categories>cs.LO</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lambda calculus with constructors is an extension of the lambda calculus
with variadic constructors. It decomposes the pattern-matching a la ML into a
case analysis on constants and a commutation rule between case and application
constructs. Although this commutation rule does not match with the usual
computing intuitions, it makes the calculus expressive and confluent, with a
rather simple syntax. In this paper we define a sound notion of categorical
model for the lambda calculus with constructors. We then prove that this
definition is complete for the fragment of the calculus with no match-failure,
using the model of partial equivalence relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4707</identifier>
 <datestamp>2016-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4707</id><created>2012-02-21</created><updated>2016-01-24</updated><authors><author><keyname>Michel</keyname><forenames>Lo&#xef;c</forenames></author></authors><title>A para-model agent for dynamical systems</title><categories>math.OC cs.SY</categories><comments>34 pages, 31 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Consider a dynamical system $u \mapsto x, \dot{x} = f_{nl}(x,u)$ where
$f_{nl}$ is a nonlinear (convex or nonconvex) function, or a combination of
nonlinear functions that can eventually switch. We present, in this preliminary
work, a generalization of the standard model-free control, that can either
control the dynamical system, given an output reference trajectory, or optimize
the dynamical system as a derivative-free optimization based &quot;extremum-seeking&quot;
procedure. The cases under study include mix of different linear switched
systems, ballistic-fire control, control of a magnetic hysteresis system, and
the extremum-seeking control of nonlinear systems. The robustness of the
proposed method is studied in simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4720</identifier>
 <datestamp>2012-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4720</id><created>2012-02-21</created><updated>2012-04-05</updated><authors><author><keyname>Wei</keyname><forenames>Yun</forenames></author><author><keyname>Ji</keyname><forenames>Chuanyi</forenames></author><author><keyname>Galvan</keyname><forenames>Floyd</forenames></author><author><keyname>Couvillon</keyname><forenames>Stephen</forenames></author><author><keyname>Orellana</keyname><forenames>George</forenames></author><author><keyname>Momoh</keyname><forenames>James</forenames></author></authors><title>Non-Stationary Random Process for Large-Scale Failure and Recovery of
  Power Distributions</title><categories>cs.SY</categories><comments>11 pages, 8 figures, submitted to IEEE Sig. Proc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key objective of the smart grid is to improve reliability of utility
services to end users. This requires strengthening resilience of distribution
networks that lie at the edge of the grid. However, distribution networks are
exposed to external disturbances such as hurricanes and snow storms where
electricity service to customers is disrupted repeatedly. External disturbances
cause large-scale power failures that are neither well-understood, nor
formulated rigorously, nor studied systematically. This work studies resilience
of power distribution networks to large-scale disturbances in three aspects.
First, a non-stationary random process is derived to characterize an entire
life cycle of large-scale failure and recovery. Second, resilience is defined
based on the non-stationary random process. Close form analytical expressions
are derived under specific large-scale failure scenarios. Third, the
non-stationary model and the resilience metric are applied to a real life
example of large-scale disruptions due to Hurricane Ike. Real data on
large-scale failures from an operational network is used to learn time-varying
model parameters and resilience metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4736</identifier>
 <datestamp>2012-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4736</id><created>2012-02-21</created><updated>2012-02-23</updated><authors><author><keyname>Mehana</keyname><forenames>Ahmed Hesham</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Diversity of MIMO Linear Precoding</title><categories>cs.IT math.IT</categories><comments>46 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear precoding is a relatively simple method of MIMO signaling that can
also be optimal in certain special cases. This paper is dedicated to high-SNR
analysis of MIMO linear precoding. The Diversity-Multiplexing Tradeoff (DMT) of
a number of linear precoders is analyzed. Furthermore, since the diversity at
finite rate (also known as the fixed-rate regime, corresponding to multiplexing
gain of zero) does not always follow from the DMT, linear precoders are also
analyzed for their diversity at fixed rates. In several cases, the diversity at
multiplexing gain of zero is found not to be unique, but rather to depend on
spectral efficiency. The analysis includes the zero-forcing (ZF), regularized
ZF, matched filtering and Wiener filtering precoders. We calculate the DMT of
ZF precoding under two common design approaches, namely maximizing the
throughput and minimizing the transmit power. It is shown that regularized ZF
(RZF) or Matched filter (MF) suffer from error floors for all positive
multiplexing gains. However, in the fixed rate regime, RZF and MF precoding
achieve full diversity up to a certain spectral efficiency and zero diversity
at rates above it. When the regularization parameter in the RZF is optimized in
the MMSE sense, the structure is known as the Wiener precoder which in the
fixed-rate regime is shown to have diversity that depends not only on the
number of antennas, but also on the spectral efficiency. The diversity in the
presence of both precoding and equalization is also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1202.4741</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1202.4741</id><created>2012-02-21</created><updated>2012-02-26</updated><authors><author><keyname>Ligett</keyname><forenames>Katrina</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author></authors><title>Take it or Leave it: Running a Survey when Privacy Comes at a Cost</title><categories>cs.GT cs.CR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of estimating a potentially sensitive
(individually stigmatizing) statistic on a population. In our model,
individuals are concerned about their privacy, and experience some cost as a
function of their privacy loss. Nevertheless, they would be willing to
participate in the survey if they were compensated for their privacy cost.
These cost functions are not publicly known, however, nor do we make Bayesian
assumptions about their form or distribution. Individuals are rational and will
misreport their costs for privacy if doing so is in their best interest. Ghosh
and Roth recently showed in this setting, when costs for privacy loss may be
correlated with private types, if individuals value differential privacy, no
individually rational direct revelation mechanism can compute any non-trivial
estimate of the population statistic. In this paper, we circumvent this
impossibility result by proposing a modified notion of how individuals
experience cost as a function of their privacy loss, and by giving a mechanism
which does not operate by direct revelation. Instead, our mechanism has the
ability to randomly approach individuals from a population and offer them a
take-it-or-leave-it offer. This is intended to model the abilities of a
surveyor who may stand on a street corner and approach passers-by.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="28000" completeListSize="102538">1122234|29001</resumptionToken>
</ListRecords>
</OAI-PMH>
